---
revision_date: '2024-10-25'
tags:
- Develop
- DHIS核心 主版
template: single.html
---

# 总览 { #webapi } 

Web API 是一个组件，它使外部系统成为可能
访问和操作存储在 DHIS2 实例中的数据。更多的
准确地说，它为广泛的
为第三方等应用程序公开数据和服务方法
软件客户端、门户网站和内部 DHIS2 模块。

## 介绍 { #webapi_introduction } 

The Web API adheres to many of the principles behind the REST
architectural style. To mention some important ones:

1.  基本构建块称为*资源*。
    资源可以是任何暴露在 Web 上的东西，从文档到
    业务流程 - 客户可能想要与之交互的任何内容。
    可以检索或交换资源的信息方面
    通过资源*表示*。表示是一个视图
    resource's state at any given time. For instance, the *visualizations*
    resource in DHIS2 represents visualizations of aggregated data for
    一组特定的参数。该资源可以在
    variety of representation formats including JSON and CSV.
2.  所有资源都可以由 *URI* 唯一标识（也称为
    作为 *URL*）。所有资源都有一个默认表示。你可以
    通过以下方式表明您对特定表示感兴趣
    提供 *Accept* HTTP 标头、文件扩展名或 *格式*
    query parameter. So in order to retrieve a CSV representation of
    an analytics data response you can supply an *Accept: application/csv* 
    header or append *.csv* or *?format=csv* to your request URL.
3.  与 API 的交互需要正确使用 HTTP *方法* 或
    *动词*。这意味着对于资源，您必须发出 *GET*
    当你想要检索它时请求，当你想要时 *POST* 请求
    要创建一个，* PUT *（当您要更新时），* DELETE *（当您要删除时）
    you want to remove it.

## 认证方式 { #webapi_authentication } 

The DHIS2 Web API supports three protocols for authentication: 

- [Basic Authentication](#webapi_basic_authentication)
- [Personal Access Tokens (PAT)](#webapi_pat_authentication)
- [OAuth 2](#webapi_oauth2)

You can verify and get information about the currently authenticated 
user by making a GET request to the following URL:

    / api / 33 / me

以及有关权限的更多信息（如果用户有特定的
权限）通过使用端点：

    / api / 33 / me / authorities
    / api / 33 / me / authorities / ALL

## 基本认证 { #webapi_basic_authentication } 

DHIS2 Web API 支持*基本身份验证*。基本认证
是一种客户端通过 HTTP 将登录凭据发送到 Web 的技术
服务器。从技术上讲，用户名后附有冒号和
密码，Base64 编码，前缀 Basic 并作为值提供
*Authorization* HTTP 标头。更正式的是：

    授权：基本base64encode（用户名：password）

大多数网络感知开发环境都支持 Basic
身份验证，例如 *Apache HttpClient* 和 *Spring RestTemplate*。
一个重要的注意事项是此身份验证方案不提供安全性
因为用户名和密码是以纯文本形式发送的，可以很容易地
被攻击者观察到。仅当服务器是
使用 SSL/TLS (HTTPS) 加密与客户端的通信。考虑这个
为了提供与 Web 的安全交互的硬性要求
应用程序接口。

## 两因素验证 { #webapi_2fa } 

DHIS2 支持两因素身份验证。这可以为每个用户启用。
启用后，用户将被要求在登录时输入 2FA 代码。您
可以阅读更多关于 2FA [这里](https://www.google.com/landing/2step/)。

## Personal Access Token { #webapi_pat_authentication }
Personal access tokens (PATs) are an alternative to using passwords for
authentication to DHIS2 when using the API.

PATs can be a more secure alternative to HTTP Basic Authentication,
and should be your preferred choice when creating a new app/script etc. 

HTTP Basic Authentication is considered insecure because, among other things, 
it sends your username and password in clear text. It may be deprecated in 
future DHIS2 versions or made opt-in, meaning that basic authentication would 
need to be explicitly enabled in the configuration.

#### Important security concerns! { #important-security-concerns } 

Your PATs will automatically inherit all the permissions and authorizations your
user has. It is therefore extremely important that you limit the access granted to
your token depending on how you intend to use it, see **Configuring your token**.

**If you only want the token to have access to a narrow and specific part of the
server, it is advised to rather create a new special user that you assign only
the roles/authorities you want it to have access to.**


### Creating a token { #creating-a-token } 
To create a new PAT, you have two choices:
* A. Create a token in the UI on your account's profile page.
* B. Create a token via the API.

### A. Creating a token on the account's page { #a-creating-a-token-on-the-accounts-page } 
Log in with your username and password, go to your profile page
(Click top right corner, and chose "Edit profile" from the dropdown).
On your user profile page, choose "Personal access tokens" from the
left side menu.
You should now be on the "Manage personal access tokens" page and see the
text: "You don't have any active personal access tokens".
Click "Generate new token" to make a new token.
A "Generate new token" popup will be shown and present you with two choices:

#### 1. Server/script context: { #1-serverscript-context } 
_"This type is used for integrations and scripts that won't be accessed by a browser"._

If you plan to use the token in an application, a script or similar, this
type should be your choice.

#### 2. Browser context: { #2-browser-context } 
_"This type us used for applications, like public portals, that will be accessed with a web browser"._

If you need to link to DHIS2 on a webpage, or e.g. embed in an iframe,
this is probably the type of token you want.


### Configuring your token { #configuring-your-token } 

After choosing what token type you want, you can configure different access constraints on
your token. By constraint, we mean how to limit and narrow down how your token can be used.
This can be of crucial importance if you plan on using the token in a public environment,
e.g. on a public dashboard on another site, embedded in an iframe.
Since tokens always have the same access/authorities that your user currently has, taking special 
care is needed if you intend to use it in any environment you don't have 100% control over.

**NB**: If anyone else gets their hands on your token, they can do anything your user can do. 
It is not possible to distinguish between actions performed using the token and other actions
performed by your user.

**Important**: It is strongly advised that you create a separate unique user with only the roles/authorities
you want the token to have if you plan on using PAT tokens in a non-secure and/or public environment,
e.g. on a PC or server, you don't have 100% control over, or "embedded" in a webpage on another server.

#### The different constraint types are as follows: { #the-different-constraint-types-are-as-follows } 
* Expiry time
* Allowed UP addresses
* Allowed HTTP methods
* Allowed HTTP referrers

##### Expiry time { #expiry-time } 
Expiry time simply sets for how long you want your token to be usable, the default is 30
days. After the expiry time, the token will simply return a 401 (Unauthorized) message.
You can set any expiry time you want, but it is strongly advised that you set an expiry time 
that is reasonable for your use case.

#### Allowed IP addresses { #allowed-ip-addresses } 
This is a comma-separated list of IP addresses you want to limit where the token requests can come from.

**Important**: IP address validation relies on the X-Forwarded-For header, which can be spoofed.
For security, make sure a load balancer or reverse proxy overwrites this header.

#### Allowed HTTP methods { #allowed-http-methods } 
A comma-separated list of HTTP methods you want your token to be able to use.
If you only need your token to view data, not modify or delete, selecting only the GET HTTP method 
makes sense.

#### Allowed HTTP referrers { #allowed-http-referrers } 
HTTP referer is a header added to the request, when you click on a link, this says which site/page 
you were on when you clicked the link. 
Read more about the HTTP referer header here: https://en.wikipedia.org/wiki/HTTP_referer

This can be used to limit the use of a "public" token embedded on another page on another site. 
Making sure that the referer header match the site hostname in should come from, can
help avoid abuse of the token, e.g. if someone posts it on a public forum.

**Important**: this is not a security feature. The `referer` header can easily be spoofed.
This setting is intended to discourage unauthorized third-party developers from connecting
to public access instances.

#### Saving your token: { #saving-your-token } 
When you are done configuring your token, you can save it by clicking the "Generate new token"
button, on the bottom right of the pop-up.
When doing so the token will be saved and a secret token key will be generated on the server.
The new secret token key will be shown on the bottom of the PAT token list with a green background,
and the text "Newly created token".
The secret token key will look similar to this:
```
d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```
**Important**: This generated secret token key will only be shown once, so it is important 
that you copy the token key now and save it in a secure place for use later. 
The secret token key will be securely hashed on the server, and only the hash of this secret token 
key will be saved to the database. This is done to minimize the security impact if someone gets 
unauthorized access to the database, similar to the way passwords are handled.

### B. Creating a token via the API { #b-creating-a-token-via-the-api } 

Example of how to create a new Personal Access Token with the API:

```
POST https://play.dhis2.org/dev/api/apiToken
Content-Type: application/json
Authorization: Basic admin district

{}
```
**NB**: Remember the empty JSON body (`{}`) in the payload! 

This will return a response containing a token similar to this:
```json
{
  "httpStatus": "已创建",
  "httpStatusCode": 201,
  "status": "正常",
  "response": {
     "responseType": "ApiTokenCreationResponse",
     "key": "d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092",
     "uid": "jJYrtIVP7qU",
     "klass": "org.hisp.dhis.security.apikey.ApiToken",
     "errorReports": []
  }
}
```

**Important**: The token key will only be shown once here in this response.
You need to copy and save this is in a secure place for use later!

The token itself consists of three parts:
1. Prefix: (`d2pat_`) indicates what type of token this is.
2. Random bytes Base64 encoded: (`5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ`)
3. CRC32 checksum: (`1151814092`) the checksum part is padded with 0 so that it always stays ten characters long.


#### Configure your token via the API: { #configure-your-token-via-the-api } 
To change any of the constraints on your token, you can issue the following HTTP API request.

**NB**: Only the constraints are possible to modify after the token is created! 

```
PUT https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: Basic admin district
```

```json
{
  “版本”：1，
  “类型”：“PERSONAL_ACCESS_TOKEN”，
  “过期”：163465349603200，
  “属性”： [
      {
        "type": "IpAllowedList",
        “allowedIps”：[“192.168.0.1”]
      },
      {
        "type": "方法允许列表",
        “允许的方法”：[“GET”]
      }
  ]
}
```

### Using your Personal Access Token { #using-your-personal-access-token } 

To issue a request with your newly created token, use the Authorization header
accordingly.
The Authorization header format is:
```
Authorization: ApiToken [YOUR_SECRET_API_TOKEN_KEY]
```
**Example**:
```
GET https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


### Deleting your Personal Access Token { #deleting-your-personal-access-token } 
You can delete your PATs either in the UI on your profile page where you created it,
or via the API like this:
```
DELETE https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


## OAuth2 { #webapi_oauth2 } 

DHIS2支持* OAuth2 *身份验证协议。 OAuth2是开放的
授权标准，允许第三方客户代表DHIS2用户进行连接，并为对Web API的后续请求*bearer token* 。 DHIS2不支持细粒度
OAuth2角色，而是根据用户角色提供应用程序访问权限
DHIS2用户的身份。

您要允许其OAuth 2身份验证的每个客户端都必须
在DHIS2中注册。要添加新的OAuth2客户端，请转到`应用>设置> OAuth2客户端`。
在用户界面中，单击*添加新*，然后输入所需的客户端名称和授权类型。

#### 使用Web API添加客户端 { #adding-a-client-using-the-web-api } 

可以通过 Web API 添加 OAuth2 客户端。例如，我们可以
发送这样的有效载荷：

```json
{
  "name": "OAuth2 Demo Client",
  "cid": "demo",
  "secret": "1e6db50c-0fee-11e5-98d0-3c15c2c6caf6",
  "grantTypes": [
    "password",
    "refresh_token",
    "authorization_code"
  ],
  "redirectUris": [
    "http://www.example.org"
  ]
}
```

可用以下命令发送有效负载：

```bash
SERVER="https://play.dhis2.org/dev"
curl -X POST -H "Content-Type: application/json" -d @client.json
  -u admin:district "$SERVER/api/oAuth2Clients"
```

我们将使用此客户端作为下一个赠款类型示例的基础。

#### 授权类型密码 { #webapi_oauth2_password } 

所有授权类型中最简单的是 *password* 授权类型。这
授权类型类似于基本身份验证，因为它
要求客户端收集用户的用户名和密码。作为
例如，我们可以使用我们的演示服务器：

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d grant_type=password -d username=admin -d password=district
```

这将给您类似的响应：

```json
{
  "expires_in": 43175,
  "scope": "ALL",
  "access_token": "07fc551c-806c-41a4-9a8c-10658bd15435",
  "refresh_token": "a4e4de45-4743-481d-9345-2cfe34732fcc",
  "token_type": "bearer"
}
```

现在，我们将专注于 `access_token`，这就是我们
将用作我们的身份验证（承载）令牌。例如，我们将得到
使用我们的令牌的所有数据元素：

```bash
SERVER="https://play.dhis2.org/dev"
curl -H "Authorization: Bearer 07fc551c-806c-41a4-9a8c-10658bd15435" "$SERVER/api/33/dataElements.json"
```

#### 授予类型refresh \ _token { #webapi_refresh_token } 

通常，访问令牌的有效性有限。你可以看看
在上一个示例中响应的 `expires_in` 属性处
了解令牌何时到期。要获得新的`access_token`，您
可以再次往返服务器并使用`refresh_token`
这允许您获得更新的令牌而无需要求
再次使用用户凭据。

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"
REFRESH_TOKEN="a4e4de45-4743-481d-9345-2cfe34732fcc"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d "grant_type=refresh_token" -d "refresh_token=$REFRESH_TOKEN"
```

响应与获得令牌开始时的响应完全相同。

#### 授予类型authorization_code { #webapi_authorization_code } 

如果您不想的话，建议使用授权代码授予类型
在外部存储用户凭据。它允许DHIS2收集
用户名/密码直接来自用户而不是客户端
收集它们，然后代表用户进行身份验证。请成为
注意这种方法使用了客户端的` redirectUris`部分
有效载荷。

第 1 步：使用 Web 浏览器访问以下 URL。如果你有不止一个
重定向 URI，您可能需要添加 `&redirect_uri=http://www.example.org`
到网址：

```bash
SERVER="https://play.dhis2.org/dev"
$SERVER/uaa/oauth/authorize?client_id=demo&response_type=code
```

第 2 步：在用户成功登录并接受您的
客户端访问，它将重定向回您的重定向 uri，如下所示：

    http://www.example.org/?code=XYZ

第 3 步：这一步类似于我们在密码授予类型中所做的，
使用给定的代码，我们现在将要求访问令牌：

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -u demo:$SECRET -H "Accept: application/json" $SERVER/uaa/oauth/token
-d "grant_type=authorization_code" -d "code=XYZ"
```

## 错误和信息消息 { #webapi_error_info_messages } 

Web API 对所有错误/警告和
信息性消息：

```json
{
  "httpStatus": "Forbidden",
  "message": "You don't have the proper permissions to read objects of this type.",
  "httpStatusCode": 403,
  "status": "ERROR"
}
```

Here we can see from the message that the user tried to access a
resource I did not have access to. It uses the http status code 403, the
HTTP status message *forbidden* and a descriptive message.

Table: WebMessage properties

| 名称 | 描述 |
|---|---|
| httpStatus | HTTP Status message for this response, see RFC 2616 (Section 10) for more information. |
| httpStatusCode | HTTP Status code for this response, see RFC 2616 (Section 10) for more information. |
| status | DHIS2状态，可能的值为*OK* | *WARNING* | *ERROR*，其中`OK`表示一切顺利，`ERROR`表示操作未完成，`WARNING`表示操作部分成功，如果消息包含`response`属性，请在那里查找更多信息。 |
| message | A user-friendly message telling whether the operation was a success or not. |
| devMessage | A more technical, developer-friendly message (not currently in use). |
| response | Extension point for future extensions of the `WebMessage` format. |

## 日期和期间格式 { #webapi_date_perid_format } 

在整个 Web API 中，我们指的是日期和期间。日期格式
是：

    yyyy-MM-dd

例如，如果您想表达 2014 年 3 月 20 日，则必须使用
*2014-03-20*。

下表描述了期间格式（也可在
API 端点`/api/periodTypes`)

Table: Period format

| Interval | 格式 | 例 | 描述 |
|---|---|---|---|
| Day | yyyyMMdd | 20040315 | March 15, 2004 |
| Week | yyyyWn | 2004W10 | Week 10 2004 |
| Week Wednesday | yyyyWedWn | 2015WedW5 | Week 5 with start Wednesday |
| Week Thursday | yyyyThuWn | 2015年第6周星期四 | Week 6 with start Thursday |
| Week Saturday | yyyySatWn | 2015SatW7 | Week 7 with start Saturday |
| Week Sunday | yyyySunWn | 2015SunW8 | Week 8 with start Sunday |
| Bi-week | yyyyBiWn | 2015BiW1 | Week 1-2 20015 |
| Month | yyyyMM | 200403 | March 2004 |
| Bi-month | yyyyMMB | 200401B | January-February 2004 |
| Quarter | yyyyQn | 2004Q1 | January-March 2004 |
| Six-month | yyyySn | 2004S1 | January-June 2004 |
| Six-month April | yyyyAprilSn | 2004AprilS1 | April-September 2004 |
| Year | yyyy | 2004 | 2004 |
| Financial Year April | yyyyApril | 2004April | Apr 2004-Mar 2005 |
| Financial Year July | yyyyJuly | 2004July | July 2004-June 2005 |
| Financial Year Oct | yyyyOct | 2004Oct | Oct 2004-Sep 2005 |


### 相对时期 { #webapi_date_relative_period_values } 


在 API 的某些部分，例如分析资源，您可以
除了固定期间（如上定义）之外，还使用相对期间。
相对期间是相对于当前日期并允许例如
用于创建动态报告。可用的相对期间值是：

    THIS_WEEK, LAST_WEEK, LAST_4_WEEKS, LAST_12_WEEKS, LAST_52_WEEKS,
    THIS_MONTH, LAST_MONTH, THIS_BIMONTH, LAST_BIMONTH, THIS_QUARTER, LAST_QUARTER,
    THIS_SIX_MONTH, LAST_SIX_MONTH, MONTHS_THIS_YEAR, QUARTERS_THIS_YEAR,
    THIS_YEAR, MONTHS_LAST_YEAR, QUARTERS_LAST_YEAR, LAST_YEAR, LAST_5_YEARS, LAST_10_YEARS, LAST_10_FINANCIAL_YEARS, LAST_12_MONTHS, 
    LAST_3_MONTHS, LAST_6_BIMONTHS, LAST_4_QUARTERS, LAST_2_SIXMONTHS, THIS_FINANCIAL_YEAR,
    LAST_FINANCIAL_YEAR, LAST_5_FINANCIAL_YEARS

### Custom date periods { #webapi_date_custom_date_periods }

Analytics `query` resources support extra parameters to express periods.

Default `pe` dimension will fall back to:

- `eventDate` for `/analytics/events/query`
- `enrollmentDate` for `/analytics/enrollments/query`

Adding conditions on one or more date fields and combining them are allowed.

#### Usage of custom date periods { #usage-of-custom-date-periods } 

In resources supporting custom date periods, there are extra query parameters that will be combined to express conditions on the time dimension.

| custom date period | events query resource  | enrollment query resource |
|--------------------|------------------------|---------------------------|
| `eventDate`        | [x]                    | [ ]                       |
| `enrollmentDate`   | [x]                    | [x]                       |
| `scheduledDate`    | [x]                    | [ ]                       |
| `incidentDate`     | [x]                    | [x]                       |
| `lastUpdated`      | [x]                    | [x]                       |

Conditions can be expressed in the following form:

`analytics/events/query/...?...&eventDate=2021&...`

It's possible to combine more time fields in the same query:

`analytics/events/query/...?...&eventDate=2021&incidentDate=202102&...`

All of these conditions can be combined with `pe` dimension:

`analytics/events/query/...?...&dimension=pe:TODAY&enrollmentDate=2021&incidentDate=202102&...`

Supported formats are described in "date and period format" above. An extra format is provided to express a range of dates: `yyyyMMdd_yyyyMMdd` and `yyyy-MM-dd_yyyy-MM-dd`.

In the example bellow, the endpoint will return events that are scheduled to happen between 20210101 and 20210104:

`analytics/events/query/...?...&dimension=pe:TODAY&enrollmentDate=2021&incidentDate=202102&scheduledDate=20210101_20210104&...`


## Authorities { #authorities } 
System authority ids and names can be listed using:

    /api/authorities

It returns the following format:
```json
{
  "systemAuthorities": [
    {
      "id": "ALL",
      "name": "ALL"
    },
    {
      "id": "F_ACCEPT_DATA_LOWER_LEVELS",
      "name": "Accept data at lower levels"
    }
  ]
}
```

# Metadata { #webapi_metadata }

## 标识符方案 { #webapi_identifier_schemes } 

This section provides an explanation of the identifier scheme concept.
Identifier schemes are used to map metadata objects to other metadata
during import, and to render metadata as part of exports. Note
that not all schemes work for all API calls, and not all
schemes can be used for both input and output. This is outlined in the
sections explaining the various API endpoints.

列出了可用的全套标识符方案对象类型
下面，使用在查询中使用的属性名称：

  - 方案

  - 数据元素标识方案

  - categoryOptionComboIdScheme

  - orgUnitIdScheme

  - 程序标识方案

  - 程序阶段标识方案

  - 跟踪实体 ID 方案

  - trackedEntityAttributeIdScheme

通用 idScheme 适用于所有类型的对象。有可能
被特定的对象类型覆盖。

所有参数的默认方案是 UID（稳定的 DHIS2
身份标识）。支持的标识符方案在
下表。

Table: Scheme Values

| Scheme | 描述 |
|---|---|
| ID, UID | Match on DHIS2 stable Identifier, this is the default id scheme. |
| CODE | Match on DHIS2 Code, mainly used to exchange data with an external system. |
| 名称 | Match on DHIS2 Name, please note that this uses what is available as *object.name*, and not the translated name. Also note that names are not always unique, and in that case, they can not be used. |
| ATTRIBUTE:ID | Match on metadata attribute, this attribute needs to be assigned to the type you are matching on, and also that the unique property is set to *true*. The main usage of this is also to exchange data with external systems, it has some advantages over *CODE* since multiple attributes can be added, so it can be used to synchronize with more than one system. |

Note that identifier schemes is not an independent feature but needs to
be used in combination with resources such as data value import, metadata import and
GeoJson import.

例如，指定 CODE 作为通用 id 方案并覆盖
使用 UID 作为组织单位 ID 方案，您可以使用这些查询
参数：

    ？idScheme = CODE＆orgUnitIdScheme = UID

再举一个例子，为组织单位 id 指定一个属性
方案，数据元素 id 方案的代码并使用默认 UID id
您可以使用这些参数的所有其他对象的方案：

    ？orgUnitIdScheme =属性：j38fk2dKFsG＆dataElementIdScheme = CODE

## 浏览Web API { #webapi_browsing_the_web_api } 

浏览 Web API 的入口点是 `/api`。这个资源
提供所有可用资源的链接。四种资源表示
格式始终适用于所有资源：HTML、XML、JSON、
和 JSONP。某些资源将具有其他可用格式，例如 MS
Excel、PDF、CSV 和 PNG。要从 Web 浏览器探索 API，请导航
到 `/api` 入口点并按照链接到您想要的
资源，例如`/api/dataElements`。对于所有资源
返回元素列表，某些查询参数可用于修改
响应：

Table: Query parameters

| Parameter | Option values | Default option | 描述 |
|---|---|---|---|
| paging | true &#124; false | 真正 | Indicates whether to return lists of elements in pages. |
| page | number | 1 | Defines which page number to return. |
| pageSize | number | 50 | Defines the number of elements to return for each page. |
| order | property:asc/iasc/desc/idesc || Order the output using a specified order, only properties that are both persisted and simple (no collections, idObjects etc) are supported. iasc and idesc are case insensitive sorting. If it is wanted to sort for more than one property, separate them using a comma.  |

如何使用这些参数获取完整列表的示例
XML 响应格式的数据元素组是：

    /api/dataElementGroups.xml?links=false&paging=false

您可以在 name 属性上查询元素而不是返回
使用 *query* 查询变量的完整元素列表。在这个例子中
我们查询名称中带有“贫血”一词的所有数据元素：

    / api / dataElements？query =贫血

您可以像这样获取特定页面和对象的页面大小：

    /api/dataElements.json?page=2&pageSize=20

您可以像这样完全禁用分页：

    /api/indicatorGroups.json?paging=false

要基于特定属性对结果进行排序：

    /api/indicators.json?order=shortName:desc

To order the result based on created datetime property first (descending order) and then by name property (ascending order):

    /api/indicators.json?order=created:desc,name:asc

您可以通过以下方式在所有对象类型中根据对象的 ID 查找对象
*identifiableObjects* 资源：

    / api / identifiableObjects / <id>

### 翻译 { #webapi_translation } 

DHIS2 supports translations of database content, such as data elements,
indicators, and programs. All metadata objects in the Web API have
properties meant to be used for display / UI purposes, which include
*displayName*, *displayShortName*, *displayDescription* and
*displayFormName* (for data elements and tracked entity attributes).

Table: Translate options

| Parameter | Values | 描述 |
|---|---|---|
| translate | true &#124; false | Translate display\* properties in metadata output (displayName, displayShortName, displayDescription, and displayFormName for data elements and tracked entity attributes). Default value is true. |
| locale | Locale to use | Translate metadata output using a specified locale (requires translate=true). |

### 翻译API { #webapi_translation_api } 

对象的翻译呈现为对象本身的一部分
在* translation *数组中。请注意，
JSON / XML有效负载的*翻译*数组通常为您预先过滤，这意味着它们不能直接用于导入/导出翻译（因为那样会
通常会覆盖当前用户以外的语言环境）。

在用户语言环境中过滤了转换数组的数据元素示例：

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute French",
  "translations": [
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    }
  ]
}
```

转换关闭的数据元素示例：

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute Flaccid Paralysis (Deaths < 5 yrs)",
  "translations": [
    {
      "property": "FORM_NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "Accute Flaccid Paral"
    },
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "DESCRIPTION",
      "locale": "en_FK",
      "value": "aa"
    }
  ]
}
```

请注意，即使您得到未过滤的结果，并且正在使用
适当的类型端点，即我们不允许的 `/api/dataElements` 
更新，因为这样做很容易犯错误并覆盖
其他可用的语言环境。

要阅读和更新翻译，您可以使用特殊翻译
每个对象资源的端点。可以通过*GET*或访问
在适当的`/ api / <object-type> / <object-id> / translations `端点上* PUT *。

As an example, for a data element with identifier `FTRrcoaog83`, you could use
`/api/dataElements/FTRrcoaog83/translations` to get and update
translations. The fields available are `property` with options *NAME*,
*SHORT_NAME*, *FORM_NAME*, *DESCRIPTION*, `locale` which supports any valid
locale ID and the translated property `value`.

法语语言环境的NAME属性示例：

```json
{
  "property": "NAME",
  "locale": "fr",
  "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
}
```

然后将此有效负载添加到翻译数组中，并发回
到适当的端点：

```json
{
  "translations": [
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
    }
  ]
}
```

对于ID为* FTRrcoaog83 *的数据元素，您可以* PUT *此代码为
`/ api / dataElements / FTRrcoaog83 / translations`。确保发送全部
特定对象的翻译，而不仅仅是单个语言环境的翻译
（否则，您可能会覆盖其他区域的现有语言环境
语言环境）。

如果数据值已成功保存或更新，则状态代码将为`204 No Content`，如果存在验证错误（例如，同一`语言环境`有多个`SHORT_NAME`），则状态代码将为`404 Not Found`。


### Web API版本 { #webapi_api_versions } 

Web API的版本从DHIS 2.25开始。 API版本
遵循DHIS2主版本号。例如，API
DHIS 2.33的版本是`33`。

您可以通过包含版本号来访问特定的 API 版本
在`/api` 组件之后，作为这样的例子：

    / api / 33 / dataElements

如果省略 URL 的 version 部分，系统将使用当前的
API 版本。例如，对于 DHIS 2.25，在省略 API 部分时，
系统将使用 API 版本 25。在开发 API 客户端时，它是
建议使用显式 API 版本（而不是省略 API
版本），因为这将保护客户端免受不可预见的 API 更改。

将支持最后三个 API 版本。例如，DHIS
2.27 版本将支持 API 版本 27、26 和 25。

请注意，元数据模型没有版本控制，您可能
体验变化，例如在对象之间的关联中。这些变化
将记录在 DHIS2 主要版本发行说明中。

## 元数据对象过滤器 { #webapi_metadata_object_filter } 

To filter the metadata there are several filter operations that can be
applied to the returned list of metadata. The format of the filter
itself is straight-forward and follows the pattern
*property:operator:value*, where *property* is the property on the
metadata you want to filter on, *operator* is the comparison operator
you want to perform and *value* is the value to check against (not all
operators require value). 

Please see the *schema* section to discover which properties are available. 
In addition to the listed properties filters can apply to custom attribute 
values by using the attribute's ID as property name.

Recursive filtering, ie. filtering on associated objects or collection of 
objects, is supported as well.

Table: Available Operators

| Operator | Types | Value required | 描述 |
|---|---|---|---|
| eq | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | 真正 | Equality |
| !eq | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | 真正 | Inequality |
| ieq | string  | 真正  | Case insensitive string, match exact |
| ne | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | 真正 | Inequality |
| like | string | 真正 | Case sensitive string, match anywhere |
| !like | string | 真正 | Case sensitive string, not match anywhere |
| $like | string | 真正 | Case sensitive string, match start |
| !$like | string | 真正 | Case sensitive string, not match start |
| like$ | string | 真正 | Case sensitive string, match end |
| !like$ | string | 真正 | Case sensitive string, not match end |
| ilike | string | 真正 | Case insensitive string, match anywhere |
| !ilike | string | 真正 | Case insensitive string, not match anywhere |
| $ilike | string | 真正 | Case insensitive string, match start |
| !$ilike | string | 真正 | Case insensitive string, not match start |
| ilike$ | string | 真正 | Case insensitive string, match end |
| !ilike$ | string | 真正 | Case insensitive string, not match end |
| gt | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | 真正 | Greater than |
| ge | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | 真正 | Greater than or equal |
| lt | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | 真正 | Less than |
| le | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | 真正 | Less than or equal |
| null | all | 假 | Property is null |
| !null | all | 假 | Property is not null |
| empty | collection | 假 | Collection is empty |
| token | string | 真正 | Match on multiple tokens in search property |
| !token | string | 真正 | Not match on multiple tokens in search property |
| 在 | string &#124; boolean &#124; integer &#124; float &#124; date | 真正 | Find objects matching 1 or more values |
| !in | string &#124; boolean &#124; integer &#124; float &#124; date | 真正 | Find objects not matching 1 or more values |

Operators will be applied as logical *and* query. If you need a *or*
query, you can have a look at the *in* filter and the section below.
The filtering mechanism allows for recursion. See below for some examples.

获取ID属性为ID1或ID2的数据元素：

    / api / dataElements？filter = id：eq：ID1＆filter = id：eq：ID2

Get data elements, ignoring case, with name property MyDataElement:

    /api/dataElements?filter=name:ieq:mydataelement

Get all data elements which have a data set with id ID1:

    /api/dataElements?filter=dataSetElements.dataSet.id:eq:ID1

Get all data elements with aggregation operator *sum* and value type
*int*:

    /api/dataElements.json?filter=aggregationOperator:eq:sum&filter=type:eq:int

You can do filtering within collections, e.g. to get data elements which
are members of the *ANC* data element group you can use the following
query using the id property of the associated data element groups:

    /api/dataElements.json?filter=dataElementGroups.id:eq:qfxEYY9xAl6

To get data elements with a particular attribute value for a metadata 
attribute, a filter for the attribute ID and the attribute value can be 
specified using the same collection query syntax:

    /api/dataElements.json?filter=attributeValues.attribute.id:eq:n2xYlNbsfko&filter=attributeValues.value:eq:AFP

Get data elements which have any option set:

    /api/dataElements?filter=optionSet:!null

由于默认情况下所有运算符都是 *and*，因此您无法找到数据
匹配多个 id 的元素，为此您可以使用 *in*
操作员。

    /api/dataElements.json?filter=id:in:[fbfJHSPpUQD,cYeuwXTCPkU]

### 逻辑运算符 { #webapi_metadata_logical_operator } 

如前一节所述，应用了默认逻辑运算符
过滤器是 *AND* 这意味着所有对象过滤器必须是
匹配。但是，在某些情况下，您希望匹配其中之一
几个过滤器（可能是 id 和 code 字段），在这些情况下，它是
可以将根逻辑运算符从 *AND* 切换为 *OR*
使用 *rootJunction* 参数。

示例：正常过滤，其中 id 和 code 必须匹配才能具有
结果返回

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1

示例：过滤逻辑运算符已切换为 OR 的位置
现在只有一个过滤器必须匹配才能产生结果
    回

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1&rootJunction=OR

### 可识别的令牌过滤器 { #identifiable-token-filter } 

除了上述基于特定属性的过滤之外，
我们还通过* token *基于* AND *过滤了一组
属性：ID，代码和名称（如果可用，还包括shortName）。这些
属性通常称为*可识别*。这个想法是为了
过滤ID，名称，代码或简称中包含某些内容的元数据。

示例：过滤所有包含 *2nd* 的数据元素
如下： id,name,code,shortName

    /api/dataElements.json?filter=identifiable:token:2nd

也可以指定多个过滤值。

示例：获取在任何 *identifiable* 属性中找到 *ANC visit* 的所有数据元素。系统返回所有数据元素，其中在可识别属性中的任何地方都可以找到令牌（ANC 和访问）。

    /api/dataElements.json?filter=identifiable:token:ANC访问

也可以将可识别过滤器与基于属性的过滤器结合起来，并期望应用 *rootJunction*。

    /api/dataElements.json?filter=identifiable:token:ANC visit＆filter = displayName：ilike：tt1

    /api/dataElements.json?filter=identifiable:token:ANC访问
      ＆filter = displayName：ilike：tt1＆rootJunction = OR

### Indexable only filter for tracked entity attributes { #indexable-only-filter-for-tracked-entity-attributes } 

For tracked entity attributes, there is a special filter in addition to the previous mentioned filtering capabilities. 
Some of the tracked entity attributes are candidates for creating a trigram index for better lookup performance. 
Using the *indexableOnly* parameter set to true, the results can be filtered to include only the attributes that are trigram indexable.

Example: Get all tracked entity attributes that are indexable.

    /api/trackedEntityAttributtes.json?indexableOnly=true

Additional filters along with the `indexableOnly` parameter can be specified.

Example: Get all tracked entity attributes where *ANC* is found in any of the *name* property. The system returns the tracked entity attributes where the name matches the provided keyword as well as if the attribute is indexable.

    /api/trackedEntityAttributtes.json?filter=name:like:ANC&indexableOnly=true

## 元数据字段过滤器 { #webapi_metadata_field_filter } 

In many situations, the default views of the metadata can be too
verbose. A client might only need a few fields from each object and want
to remove unnecessary fields from the response. To discover which fields
are available for each object please see the *schema* section.
In addition to the listed properties custom attributes can be included
for top level objects by using the attribute's ID as property name.

The format for include/exclude allows for infinite recursion. To filter
at the "root" level you can just use the name of the field,
i.e. `?fields=id,name` which would only display the `id` and
`name` fields for every object. For objects that are either collections or
complex objects with properties on their own, you can use the format
`?fields=id,name,dataSets[id,name]` which would return `id`, `name` of
the root, and the `id` and `name` of every data set on that object.
Negation can be done with the exclamation operator, and we have a set of
presets of field select. Both XML and JSON formats are supported.

**示例**：在指标资源上获取`id`和`name`：

    / api / indicators？fields = id，名称

**Example**: Get `id` and `name` from data elements, and `id` and `name`
from the associated data sets:

    / api / dataElements？fields = id，name，dataSets [id，name]

**Example**: Get `id`, `name` and the value of a user defined attribute 
with ID `DnrLSdo4hMl` for organisation units:

    /api/organisationUnits?fields=id,name,DnrLSdo4hMl

The attribute is then included as property `DnrLSdo4hMl` of each
matching object in the response. This can be renamed using the `rename` 
transformer as shown in the next section.

要从输出中排除字段，可以使用感叹号`!`。
操作符。这是在查询中的任何地方都允许的，而根本不会
包括该属性，因为它可能已经插入了某些
预设。

一些预设（选定的字段组）可用并且可以应用
使用`:` 运算符。

Table: Property operators

| Operator | 描述 |
|---|---|
| <field-name\> | Include property with name, if it exists. |
| <object\>[<field-name\>, ...] | Includes a field within either a collection (will be applied to every object in that collection), or just on a single object. |
| !<field-name\>, <object\>[!<field-name\> | Do not include this field name, it also works inside objects/collections. Useful when you use a preset to include fields. |
| \*, <object\>[\*] | Include all fields on a certain object, if applied to a collection, it will include all fields on all objects on that collection. |
| :<preset\> | Alias to select multiple fields. Three presets are currently available, see the table below for descriptions. |

Table: Field presets

| Preset | 描述 |
|---|---|
| all | All fields of the object |
| \* | Alias for all |
| identifiable | Includes id, name, code, created, lastUpdated and lastUpdatedBy fields |
| nameable | Includes id, name, shortName, code, description, created and lastUpdated fields |
| persisted | Returns all persisted property on an object, does not take into consideration if the object is the owner of the relation. |
| owner | Returns all persisted property on an object where the object is the owner of all properties, this payload can be used to update through the API. |

**Example**: Include all fields from data sets except organisation units:

    / api / dataSets？fields =：all，！organizationUnits

**示例**：仅包含ID，名称和数据集中的组织单位集合，但不包含组织单位中的ID：

    / api / dataSets / BfMAe6Itzgt？fields = id，name，organisationUnits [：all，！id]

**示例**：包括所有指标的可命名属性：

    /api/indicators.json?fields=:nameable

### 现场变压器 { #webapi_field_transformers } 

Field transforms can be used to transform properties. The syntax is described below.

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

这会将 *id* 属性重命名为 *i*，将 *name* 属性重命名为 *n*。

Multiple transformers can be applied to a single property by repeating the transformer operator:

    /api/dataElementGroups.json?fields=id,displayName,dataElements~isNotEmpty~rename(haveDataElements）

The supported transformer operators are described in the table below.

Table: Available Transformers

| 名称 | Arguments | 描述 |
|---|---|---|
| size || Gives sizes of strings (length) and collections |
| isEmpty || Is string or collection empty |
| isNotEmpty || Is string or collection not empty |
| rename | Arg1: name | Renames the property name |
| paging | Arg1: page,Arg2: pageSize | Pages a collection, default pageSize is 50. |
| pluck | Optional Arg1: fieldName | Converts an array of objects to an array of a selected field of that object. By default, the first field that is returned by the collection is used (normally the ID). |
| keyBy | Optional Arg1: fieldName | Converts an array of objects to an object where the fieldName (default id) is used as the key. This can be useful for quick lookups in JavaScript for example |

#### 例子 { #webapi_field_transformers_examples } 

Examples of transformer usage are found below.

Get the size of a collection:

    /api/dataElements?fields=dataSets~size

Test if a collection is empty:

    /api/dataElements?fields=dataSets~isEmpty

Test if a collection is not empty:

    /api/dataElements?fields=dataSets~isNotEmpty

Rename properties:

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

Apply paging to a collection:

    /api/dataElementGroups?fields=id,displayName,dataElements~paging(1;20)

Get array with IDs of organisation units:

    /api/categoryOptions.json?fields=id,organisationUnits~pluck

Get array with names of organisation units:

    /api/categoryOptions.json?fields=id,organisationUnits~pluck[name]

通过`d`字段键入 dataElements 数组：

    /api/dataElementGroups.json?fields=id,name,dataElements~keyBy[id,name,valueType]

通过`valueType`字段键入 dataElements 数组，因为多次点击这将生成（数据元素的）数组：

    /api/dataElementGroups.json?fields=id,name,dataElements~keyBy(valueType)[id,name,valueType]

## 元数据创建，读取，更新，删除，验证 { #webapi_metadata_crud } 

DHIS2 中的所有元数据实体都有自己的 API 端点，支持
*CRUD* 操作（创建、读取、更新和删除）。端点 URL
遵循以下格式：

    / api / <entityName>

_entityName_ 使用驼峰命名法。例如，端点
对于_数据元素_是：

    / api / dataElements

> **_NOTE:_**  When updating objects, all existing property values will be overwritten, even if the new value is null. Please use [JSON Patch API](#webapi_partial_updates) in case you want do partial update to an object.

### 创建/更新参数 { #webapi_metadata_create_update } 

以下请求查询参数可用于所有元数据端点。

Table: Available Query Filters

| Param | 类型 | 需要 | 选项（默认为默认） | 描述 |
|---|---|---|---|---|
| preheatCache | boolean | 假 | true &#124; false | Turn cache-map preheating on/off. This is on by default, turning this off will make initial load time for importer much shorter (but will make the import itself slower). This is mostly used for cases where you have a small XML/JSON file you want to import, and don't want to wait for cache-map preheating. |
| importStrategy | enum | 假 | 创建_并_更新&#124;创建&#124;更新&#124;删除 | Import strategy to use, see below for more information. |

### 创建和更新对象 { #webapi_creating_updating_objects } 

要创建新对象，您需要知道端点、类型
格式，并确保您拥有所需的权限。作为
例如，我们将创建和更新一个*常量*。为了弄清楚
格式，我们可以使用新的 *schema* 端点来获取格式
描述。因此，我们将从获取该信息开始：

    http：// <server> /api/schemas/constant.json

从输出中，您可以看到创建所需的权限
是`F_CONSTANT_ADD`，重要的属性是：*name* 和
*价值*。由此，我们可以创建一个 JSON 负载并将其保存为文件
称为constant.json：

```json
{
  "name": "PI",
  "value": "3.14159265359"
}
```

与XML有效内容相同的内容：

```xml
<constant name="PI" xmlns="http://dhis2.org/schema/dxf/2.0">
  <value>3.14159265359</value>
</constant>
```

我们现在准备通过发送 POST 请求来创建新的*常量*
使用curl 的带有JSON 有效负载的`constants`端点：

```bash
curl -d @constant.json "http://server/api/constants" -X POST
  -H "Content-Type: application/json" -u user:password
```

将常量发布到演示中的具体示例
    服务器：

```bash
curl -d @constant.json "https://play.dhis2.org/api/constants" -X POST
  -H "Content-Type: application/json" -u admin:district
```

如果一切顺利，您应该看到类似以下的输出：

```json
{
  "status": "SUCCESS",
  "importCount": {
    "imported": 1,
    "updated": 0,
    "ignored": 0,
    "deleted": 0
  },
  "type": "Constant"
}
```

更新过程将完全相同，您进行更改
到 JSON/XML 负载，找出常量的 *ID*，然后
向端点发送包含 ID 的 PUT 请求：

```bash
curl -X PUT -d @pi.json -H "Content-Type: application/json"
  -u user:password "http://server/api/constants/ID"
```

### 删除物件 { #webapi_deleting_objects } 

删除对象非常简单，您需要知道
*ID* 和你要删除的类型的端点，让我们继续我们的
上一节中的示例并使用*常量*。让我们假设
id 是 *abc123*，那么你需要做的就是发送 DELETE
对端点的请求 + id：

```bash
curl -X DELETE -u user:password "http://server/api/constants/ID"
```

成功删除应返回HTTP状态204（无内容）。

### 在集合中添加和删除对象 { #webapi_adding_removing_objects_collections } 

集合资源允许您修改集合
对象。

#### 添加或删除单个对象 { #webapi_collections_adding_removing_single_objects } 

为了在对象集合中添加或删除对象，您
可以使用以下
    图案：

    / api / {collection-object} / {collection-object-id} / {collection-name} / {object-id}

应该使用POST方法添加，使用DELETE方法删除
一个东西。当对象之间存在多对多关系时，
您必须首先确定哪个对象拥有该关系。如果不是
清除这是哪个对象，尝试两种方式调用以查看哪个有效。

模式的组成部分是：

  - 集合对象：拥有您的集合的对象类型
    想修改。

  - 集合对象 id：拥有该对象的对象的标识符
    要修改的集合。

  - 集合名称：您要修改的集合的名称。

  - object id：要添加或删除的对象的标识符
    从集合。

例如，为了删除标识符为 IDB 的数据元素
从具有标识符 IDA 的数据元素组中，您可以执行 DELETE
要求：

    删除/ api / dataElementGroups / IDA / dataElements / IDB

将带有标识符 IDB 的类别选项添加到带有
标识符 IDA 你可以做一个 POST
要求：

    POST / api / categories / IDA / categoryOptions / IDB

#### 添加或删除多个对象 { #webapi_collections_adding_removing_multiple_objects } 

您可以在一个请求中从集合中添加或删除多个对象
具有这样的有效载荷：

```json
{
  "identifiableObjects": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ]
}
```

使用此有效负载，您可以添加，替换或删除项目：

*添加项目：*

    POST / api / categories / IDA / categoryOptions

*更换物品：*

    PUT /api/categories/IDA/categoryOptions

*删除
项目：*

    删除/ api / categories / IDA / categoryOptions

#### 在单个请求中添加和删除对象 { #webapi_collections_adding_removing_objects_single_request } 

您可以在单个 POST 中从集合中添加和删除对象
请求到以下 URL：

    POST / api / categories / IDA / categoryOptions

有效负载格式为：

```json
{
  "additions": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ],
  "deletions": [{
      "id": "IDD"
    }, {
      "id": "IDE"
    }, {
      "id": "IDF"
    }
  ]
}
```

### 验证有效载荷 { #webapi_validating_payloads } 

DHIS 2 支持元数据有效载荷的系统范围验证，这意味着
将检查 API 端点上的创建和更新操作
允许进行更改之前的有效负载。找出哪些验证
为特定端点准备好了，看看`/api/schemas`
端点，即要找出数据元素具有哪些约束，您
会去`/api/schemas/dataElement`。

您还可以手动验证您的有效负载，方法是将其发送到适当的
架构端点。如果您想从创建中验证常量
之前的部分，您可以这样发送：

    POST / api / schemas / constant

一个简单的（非验证）示例为：

```bash
curl -X POST -d "{\"name\": \"some name\"}" -H "Content-Type: application/json"
  -u admin:district "https://play.dhis2.org/dev/api/schemas/dataElement"
```

Which will yield the result:

```json
[
   {
      "message" : "Required property missing.",
      "property" : "type"
   },
   {
      "property" : "aggregationOperator",
      "message" : "Required property missing."
   },
   {
      "property" : "domainType",
      "message" : "Required property missing."
   },
   {
      "property" : "shortName",
      "message" : "Required property missing."
   }
]
```

### 部分更新 { #webapi_partial_updates } 

对于处理元数据的 API 端点，我们支持使用 JSON 补丁 [标准](https://tools.ietf.org/html/rfc6902) 进行部分更新 (PATCH)。有效负载基本上概述了您想要应用于现有元数据对象的一组操作。有关 JSON 补丁的详细信息和示例，请参阅 [jsonpatch.com](http://jsonpatch.com/)。支持三个运算符：`添加`、`删除`和`替换`。

Below is a few examples relevant to DHIS2. Note that any update to a payload should be thought of as a HTTP PUT operation, i.e. any mutation must result in a valid PUT metadata payload.

The default `importReportMode` for JSON patch is `ERRORS_NOT_OWNER` which implies that when updating any property which is not owned by that particular object (for example trying to add a indicator group directly to an indicator) you will get an error.

As per the JSON patch specification you must always use the mimetype `application/json-patch+json` when sending patches.

#### 例子 { #examples } 

##### Update name and value type of data element { #update-name-and-value-type-of-data-element } 

```
PATCH /api/dataElements/{id}
```

```json
[
  {"op": "add", "path": "/name", "value": "New Name"},
  {"op": "add", "path": "/valueType", "value": "INTEGER"}
] 
```

##### Add new data element to a data element group { #add-new-data-element-to-a-data-element-group } 

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "add", "path": "/dataElements/-", "value": {"id": "data-element-id"}}
]
```

##### Remove all data element associations from a data element group { #remove-all-data-element-associations-from-a-data-element-group } 

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "remove", "path": "/dataElements"}
]
```

##### Change domain and value type of a data element { #change-domain-and-value-type-of-a-data-element } 

```
PATCH /api/dataElements/{id}
```

```json
[
    {"op": "add", "path": "/domainType", "value": "TRACKER"},
    {"op": "add", "path": "/valueType", "value": "INTEGER"}
]
```

##### Remove a specific orgUnit from an orgUnit group { #remove-a-specific-orgunit-from-an-orgunit-group } 

```
PATCH /api/organisationUnitGroups/{id}
```

```json
[
  {"op": "remove", "path": "/organisationUnits/1"}
]
```

#### Blocked add dataElementGroup to dataElement { #blocked-add-dataelementgroup-to-dataelement } 

```
PATCH /api/dataElements/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "add", "path": "/dataElementGroups/-", "value": {"id": "data-element-group-id"}}
]
```

#### Blocked update name of dataElementGroup in dataElement { #blocked-update-name-of-dataelementgroup-in-dataelement } 

```
PATCH /api/dataElements/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "add", "path": "/dataElementGroups/0", "value": {"name": "new-name"}}
]
```
#### Remove collection item by id { #remove-collection-item-by-id } 

```
补丁 /api/dataSets/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "remove-by-id", "path": "/organisationUnits", "id": "u6CvKyF0Db5"}
]
```

#### Patch request with invalid path { #patch-request-with-invalid-path } 
如果`path`属性无效或不存在，则修补服务将返回如下错误。


```
补丁 /api/dataSets/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "remove-by-id", "path": "/test", "id": "u6CvKyF0Db5"}
]
```
Response
```json
{
    "httpStatus": "Bad Request",
    "httpStatusCode": 400,
    "status": "ERROR",
    "message": "Invalid path /test"
}
```

### Metadata CSV export { #webapi_metadata_csv_export } 

CSV字段过滤与CSV（请注意，在`/api/metadata`端点上使用CSV不受支持）几乎相同，但字段转换尚不支持。

对于支持CSV的端点（如`/api/dataElements` `/api/organisationUnits`等我们的元数据端点），您可以使用`Accept`头部和值`text/csv`，或者您可以使用扩展名`.csv`。请注意，不支持复杂对象，我们仅支持id-object集合（因此将返回一个UID列表）。

| 名称 | 选项 | 描述 |
|---|---|---|
| fields | Same as metadata field filter (with the caveats mentioned above) | 默认过滤器是`id，displayName` |
| skipHeader | false/true | Should the header (with column names) be included or not
| separator | Default: `.` | Column separator
| arraySeparator | Default: `;` | If one of the field is a collection of id-objects this separator will separate all the UIDs

#### 例子 { #examples } 

#### Get all data elements including their group associations { #get-all-data-elements-including-their-group-associations } 

```
/api/dataElements.csv?fields=id,displayName,dataElementGroups
```

#### Get all org units including geometry (which will get ignored) { #get-all-org-units-including-geometry-which-will-get-ignored } 

```
/api/organisationUnits.csv?fields=id,displayName,organisationUnitGroups,geometry
```

## 元数据导出 { #webapi_metadata_export } 

本节介绍了可在以下位置获得的元数据 API
`/api/元数据`。支持 XML 和 JSON 资源表示。

    / api /元数据

最常用的参数在下面的“导出参数”中描述
桌子。您还可以使用以下方法将其应用于所有可用类型
`type:fields=<filter>` 和 `type:filter=<filter>`。你也可以
通过设置 `type=true|false` 启用/禁用某些类型的导出。

Table: Export Parameter

| 名称 | 选项 | 描述 |
|---|---|---|
| fields | Same as metadata field filter | Default field filter to apply for all types, default is `:owner`. |
| filter | Same as metadata object filter | 适用于所有类型的默认对象过滤器，默认为`无`。 |
| order | Same as metadata order | Default order to apply to all types, default is `name` if available, or `created` if not. |
| translate | false/true | Enable translations. Be aware that this is turned off by default (in other endpoints this is on by default). |
| locale | <locale\> | Change from user locale, to your own custom locale. |
| defaults | INCLUDE/EXCLUDE | Should auto-generated category object be included or not in the payload. If you are moving metadata between 2 non-synced instances, it might make sense to set this to EXCLUDE to ease the handling of these generated objects. |
| skipSharing | false/true | Enabling this will strip the sharing properties from the exported objects. This includes *user*, *publicAccess*, *userGroupAccesses*, *userAccesses*, and *externalAccess*. |
| download | false/true | Enabling this will add HTTP header Content-Disposition that specifies that the data should be handled as an attachment and will be offered by web browsers as a download. |

### 元数据导出示例 { #webapi_metadata_export_examples } 

导出所有元数据。小心，因为响应可能非常大，具体取决于
关于您的元数据配置：

    / api /元数据

导出由lastUpdated降序排列的所有元数据：

    / api / metadata？defaultOrder = lastUpdated：desc

导出仅包括指标和指标组的元数据：

    / api / metadata？indicators = true＆indicatorGroups = true

导出所有数据元素的id和displayName，按displayName排序：

    / api / metadata？dataElements：fields = id，name＆dataElements：order = displayName：desc

导出名称以“ ANC”开头的数据元素和指示符：

    / api / metadata？filter = name：^ like：ANC＆dataElements = true＆indicators = true

### 具有依赖项的元数据导出 { #webapi_dataset_program_export_dependencies } 

When you want to exchange metadata for a data set, program, category combo,
dashboard, option set or data element group
from one DHIS2 instance to another instance there are six dedicated endpoints available:

```
/api/dataSets/{id}/metadata.json

/api/programs/{id}/metadata.json

/api/categoryCombos/{id}/metadata.json

/api/dashboards/{id}/metadata.json

/api/optionSets/{id}/metadata.json

/api/dataElementGroups/{id}/metadata.json
```

然后可以使用`/ api / metadata`导入这些导出。

这些端点还支持以下参数：

Table: Export Parameter

| 名称 | 选项 | 描述 |
|---|---|---|
| skipSharing | false/true | Enabling this will strip the sharing properties from the exported objects. This includes *user*, *publicAccess*, *userGroupAccesses*, *userAccesses*, and *externalAccess*. |
| download | false/true | Enabling this will add HTTP header Content-Disposition that specifies that the data should be handled as an attachment and will be offered by web browsers as a download. |

## 元数据导入 { #webapi_metadata_import } 

本节介绍元数据导入 API。 XML 和 JSON 资源
支持表示。可以使用 *POST* 请求导入元数据。

    / api /元数据

导入器允许您导入元数据有效负载，其中可能包括许多
不同的实体和每个实体的任意数量的对象。元数据导出
元数据导出API生成的可以直接导入。

元数据导入端点支持多种参数，分别是
下面列出。

Table: Import Parameter

| 名称 | Options (first is default) | 描述 |
|---|---|---|
| importMode | COMMIT, VALIDATE | 设置整体导入模式，决定是否仅 `VALIDATE` 或也 `COMMIT` 元数据，这与我们旧的 dryRun 标志具有相似的功能。 |
| identifier | UID, CODE, AUTO | Sets the identifier scheme to use for reference matching. `AUTO` means try `UID` first, then `CODE`. |
| importReportMode | ERRORS, FULL, DEBUG | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |
| preheatMode | REFERENCE, ALL, NONE | 设置预热器模式，用于指示是否应该对 `ALL` 进行预热（就像以前使用 *preheatCache=true* 一样）或对对象进行更智能的扫描以查看要预热的内容（现在是默认设置），将其设置为不推荐使用`无`。 |
| importStrategy | CREATE_AND_UPDATE, CREATE, UPDATE, DELETE | Sets import strategy, `CREATE_AND_UPDATE` will try and match on identifier, if it doesn't exist, it will create the object. |
| atomicMode | ALL, NONE | 设置原子模式，在旧的导入器中，我们总是进行*best effort*导入，这意味着即使某些引用不存在，我们仍然会导入（即数据元素组导入时缺少数据元素）。新进口商的默认设置是不允许这样做，并且类似地拒绝任何验证错误。设置 `NONE` 模式模拟了旧的行为. |
| flushMode | AUTO, OBJECT | 设置刷新模式，控制何时刷新内部缓存。*强烈*建议将其保留为`AUTO`（这是默认设置）。仅将 `OBJECT` 用于调试目的，您会看到休眠异常并想查明堆栈发生的确切位置（休眠只会在刷新时抛出，因此很难知道哪个对象有问题）。 | 
| skipSharing | false, true | Skip sharing properties, does not merge sharing when doing updates, and does not add user group access when creating new objects. |
| skipValidation | false, true | 跳过导入的验证。`不推荐`。 |
| async | false, true | Asynchronous import, returns immediately with a *Location* header pointing to the location of the *importReport*. The payload also contains a json object of the job created. |
| inclusionStrategy | NON_NULL, ALWAYS, NON_EMPTY | *NON_NULL* includes properties which are not null, *ALWAYS* include all properties, *NON_EMPTY* includes non empty properties (will not include strings of 0 length, collections of size 0, etc.) |
| userOverrideMode | NONE, CURRENT, SELECTED | Allows you to override the user property of every object you are importing, the options are NONE (do nothing), CURRENT (use import user), SELECTED (select a specific user using overrideUser=X) |
| overrideUser | User ID | If userOverrideMode is SELECTED, use this parameter to select the user you want override with. |

> **NOTE** When updating objects, all property values will be overwritten even if the new values are `null`. Please use [JSON Patch API](#webapi_partial_updates) in case you want do partial update to an object.


要导入的元数据负载的示例如下所示。注意如何
每个实体类型都有自己的属性和一个对象数组：

```json
{
  "dataElements": [
    {
      "name": "EPI - IPV 3 doses given",
      "shortName": "EPI - IPV 3 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    },
    {
      "name": "EPI - IPV 4 doses given",
      "shortName": "EPI - IPV 4 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    }
  ],
  "indicators": [
    {
      "name": "EPI - ADS stock used",
      "shortName": "ADS stock used",
      "numerator": "#{LTb8XeeqeqI}+#{Fs28ZQJET6V}-#{A3mHIZd2tPg}",
      "numeratorDescription": "ADS 0.05 ml used",
      "denominator": "1",
      "denominatorDescription": "1",
      "annualized": false,
      "indicatorType": {
        "id": "kHy61PbChXr"
      }
    }
  ]
}
```

将此有效负载发布到元数据端点时，响应将包含
有关导入过程中使用的参数的信息和每个摘要
实体类型，包括创建、更新、删除和
忽略：

```json
{
  "importParams": {
    "userOverrideMode": "NONE",
    "importMode": "COMMIT",
    "identifier": "UID",
    "preheatMode": "REFERENCE",
    "importStrategy": "CREATE_AND_UPDATE",
    "atomicMode": "ALL",
    "flushMode": "AUTO",
    "skipSharing": false,
    "skipTranslation": false,
    "skipValidation": false,
    "metadataSyncImport": false,
    "firstRowIsHeader": true,
    "username": "UNICEF_admin"
  },
  "status": "OK",
  "typeReports": [
    {
      "klass": "org.hisp.dhis.dataelement.DataElement",
      "stats": {
        "created": 2,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 2
      }
    },
    {
      "klass": "org.hisp.dhis.indicator.Indicator",
      "stats": {
        "created": 1,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 1
      }
    }
  ],
  "stats": {
    "created": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0,
    "total": 3
  }
}
```

## GeoJSON import <!-- DHIS2-EDIT:https://github.com/dhis2/dhis2-docs/edit/master/src/developer/web-api/geo-json.md --> { #geojson-import } 

The GeoJSON import is used to attach geometry data to organisation units.

For a bulk import a GeoJSON file with a feature collection is expected.
Each feature in the collection requires a reference to the organisation unit it
should be linked to.

默认情况下，文件中的几何图形存储为组织单位的`几何图形`属性。要存储额外的几何图形，可以创建`GEOJSON`类型的属性。当使用属性时，文件中的所有几何图形都存储为相同的属性，该属性提供了一个附加参数`attributeId`。

### GeoJSON Bulk Data Import { #webapi_geojson_bulk_import }

Table: Import Parameters

| 名称              | 类型                           | 默认 | 描述                                                                                                                       |
|-------------------|--------------------------------|---|-----------------------------------------------------------------------------------------------------------------------------------|
| `geoJsonId`       | `boolean`                      | `true` | 当`true`时，预期GeoJSON要素的`id`属性将保存组织单元标识符。                        |
| `geoJsonProperty` | `String`                       | _undefined_ | If `geoJsonId` is `false` this parameter names the property in the GeoJSON feature's `properties` that holds the organisation unit identifier |
| `orgUnitProperty` | `enum`: [`id`, `code`, `name`] | `id` | The property of the organisation unit that is referred to by the identifiers used in the GeoJSON file                             |
| `attributeId`     | `String` | _undefined_ | When set the geometry is stored as value of the attribute referenced  by ID                                                       |
| `dryRun`          | `boolean` | `false` | When `true` the import is processed without actually updating the organisation units |
| `async`           | `boolean` | `false` | When `true` the import is processed asnychronously |

Uasge:

    POST /api/organisationUnits/geometry

The post body is the GeoJSON file. Content type should be `application/json` or
`application/geo+json`. The file may be `.zip` or `.gzip` compressed.

For example, a default file where `id` is used to refer to an organisation unit 
id has this structure:

```json
{ 
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "id": "O6uvpzGd5pu",
      "geometry": { ... }
    },
    ...
  ]
}
```

A file where a feature property is used to refer to the organisation unit code
would have this structure:

```json
{ 
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": { "code": "OU1_CODE" },
      "geometry": { ... }
    },
    ...
  ]
}
```
The `coordinates` in a `geometry` may be pairs or triplets. 
If a third dimension is present it is stripped during the import.

A `geometry` may also be `null` to effectively clear or delete the geometry 
for specific organisation units. There is a special bulk deletion API that is
described in the next section.

When run synchronously an import report is returned directly.
The HTTP status code is always `OK`, the `status` in the message payload
indicates if all rows were imported successfully.
The import counts statistics contained in the report give further information:

* `imported`: number of organisation units that were successfully updated with a geometry that did not have one before for the updated property
* `updated`: number of organisation units that were successfully updated with a geometry that did have value for the updated property already
* `ignored`: number of organisation units that failed to update
* `deleted`: number of organisation units that where successfully update with a _empty_ geometry

When the import is run asynchronous the request returns immediately with status 
`OK` and job configuration response that contains a relative reference to 
the task endpoint that allows to track the status of the asynchronous import.
For example:

    /api/system/tasks/GEOJSON_IMPORT/{job-id}

The summary that is returned directly for synchronous execution is available at

    /api/system/taskSummaries/GEOJSON_IMPORT/{job-id}

once the import is finished.

### GeoJSON Bulk Data Deletion { #webapi_geojson_bulk_deletion }
要清除或取消设置所有组织单位的`几何`数据，请使用：

    DELETE /api/organisationUnits/geometry

To clear or unset the geometry data for a specific `GEOJSON` attribute for
all organisation units use:

    DELETE /api/organisationUnits/geometry?attributeId={attr-id}

Clearing is always synchronous and returns a similar report as the bulk import.
It does not support any other parameters. No `dry-run` can be performed.
Bulk clearing requires the `F_PERFORM_MAINTENANCE` authority.

### GeoJSON Single Data Import { #webapi_geojson_single_import }
The single import allows to update the geometry of a single organisation unit.

    POST /api/organisationUnits/{id}/geometry

The post body only contains the GeoJSON `geometry` value, for example:
```json
{
  "type": "Polygon",
  "coordinates": [...]
}
```
Single import only supports `attributeId` and `dryRun` parameters.

### GeoJSON Single Data Deletion { #webapi_geojson_single_deletion }
To clear the `geometry` GeoJSON data of an individual organisation unit use:

    DELETE /api/organisationUnits/{id}/geometry

Similarly to clear a `GEOJSON` attribute value for an individual organisation 
unit use:

    DELETE /api/organisationUnits/{id}/geometry?attributeId={attr-id}

Clearing is always synchronous returns a similar report as single import.
The `dry-run` parameter is supported as well. 
The performing user requires authority to modify the target organisation unit.



## 架构图 { #webapi_schema } 

可用于内省所有可用 DXF 2 对象的资源
可以在`/api/schemas` 上找到。对于特定资源，您可以拥有
查看`/api/schemas/<type>`。

要获取XML中所有可用的模式：

    GET /api/schemas.xml

要获取JSON中所有可用的模式，请执行以下操作：

    GET /api/schemas.json

要获取特定类的JSON模式：

    GET /api/schemas/dataElement.json


## 图示 { #webapi_icons } 

DHIS2 includes a collection of icons that can be used to give visual
context to metadata. There are two different kind of icons:
  - Default icons: they are pre-installed in the application and are not possible to modify nor delete.
  - Custom icons: can be created, updated and deleted at will.

Both of them be accessed through the icons resource.

    GET /api/icons

This endpoint returns a list of information about the available default and custom icons.
By default key, description, keywords and href will be included in response. But fields parameter can be used to change this behaviour.

```json
{
  key: "mosquito_outline",
  description: "Mosquito outline",
  keywords: [
    "malaria",
    "mosquito",
    "dengue"
  ],
  "created": "2024-02-12T09:50:11.794",
  "lastUpdated": "2024-02-12T09:50:11.794",
  href: "<dhis server>/api/icons/mosquito_outline/icon.svg"
}
```

It's also possible to get a particular icon directly by filtering by its key, in the example below, the key is mosquito_outline.

    GET /api/icons/mosquito_outline

### Custom icon operations { #webapi_icons_custom }

A list of custom icons can be fetched retrieved certain request parameters

    GET /api/icons?type=CUSTOM

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`type`|`Text`| DEFAULT,CUSTOM,ALL |What type of icons should be retrieved. Default is ALL|
|`keys`|`Text`| | List of keys custom icons should be retrieved for | 
|`keywords`|`Text`| | List of keywords custom icons should be retrieved for| 
|`search`|`Text`| | Search for a given text across icon keys and keywords, and retrieve all icons that contain this text in their key or keywords.| 
|`createdStartDate`|`Date`| | Starting point of created date|
|`createdEndDate`|`Date`| | End point of created date| 
|`lastUpdatedStartDate`|`Date`| | Starting point of last updated date| 
|`lastUpdatedEndDate`|`Date`| | End point of last updated date| 


#### Request parameters for pagination { #request-parameters-for-pagination } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`page`|`Integer`| Any positive integer |Page number to return. Defaults to 1 if missing|
|`pageSize`|`Integer`| Any positive integer |Page size. Defaults to 50. |
|`paging`|`Boolean`| `true`&#124;`false` |Indicates whether paging should be ignored and all rows should be returned. Defaults to `true`, meaning that by default all requests are paginated, unless `paging=false`|

#### Request parameters for ordering { #request-parameters-for-ordering } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`order`|`Text`| created:desc | Comma-separated list of property name and sort direction pairs in format propName:sortDirection. By default icons will be ordered based on key:asc|


#### Request parameter to filter responses { #request-parameter-to-filter-responses } 

The endpoints accept a `fields` parameter which controls which fields will be returned in the
JSON response. `fields` parameter accepts a comma separated list of field names. If nothing is specified, default fields will be used and those are 

`key,keywords,description,fileResourceUid,createdByUserUid,href`

A custom icon resource can be downloaded by providing the icon key:

    GET /api/icons/{key}/icon

Custom icons can be created, modified and deleted.
To create a custom icon, use the resource below.

    POST /api/icons

It expects a payload containing the icon key, description, list of keywords and the file resource uid to be linked to the data.

```json
{
    "key": "iconKey",
    "description": "description",
    "keywords": ["keyword 1","keyword 2"],
    "fileResourceUid": "ARsqBjfB2cf"
}
```

Only custom icons can be updated using below resource. 

    PUT /api/icons

With the following payload, the icon's description and keywords would be updated.

```json
{
    "key": "iconKey",
    "description": "new description",
    "keywords": ["new keyword 1", "new keyword 2"] 
}
```

Please notice that's also possible to just update one of the two. That means in case we would like to update the description while keeping the keywords, we would just need to provide the icon key and the descripton json field. Same would work the other way around, to update the keywords and leave the original description untouched.

Only custom icon can be deleted using below resource.

    DELETE /api/icons/{icon_key}


## 渲染类型 { #webapi_render_type } 

某些元数据类型具有名为 *renderType* 的属性。渲染类型
属性是 *device* 和 *renderingType* 之间的映射。应用
可以使用此信息作为有关如何呈现对象的提示
在特定设备上。例如，移动设备可能想要渲染
与台式计算机不同的数据元素。

当前有两种不同的renderingTypes可用：

1.  值类型渲染

2.  程序阶段部分渲染

还提供2种设备类型：

1.  移动

2.  桌面

下表列出了可用的元数据和呈现类型。
值类型呈现具有基于元数据的附加约束
配置，这将显示在第二个表中。

Table: Metadata and RenderingType overview

| Metadata type | Available RenderingTypes |
|---|---|
| 程序阶段部分 | * LISTING (default)<br> * SEQUENTIAL<br> * MATRIX |
| 数据元素 | * DEFAULT<br> * DROPDOWN<br> * VERTICAL_RADIOBUTTONS<br> * HORIZONTAL_RADIOBUTTONS<br> * VERTICAL_CHECKBOXES<br> * HORIZONTAL_CHECKBOXES<br> * SHARED_HEADER_RADIOBUTTONS<br> * ICONS_AS_BUTTONS<br> * SPINNER<br> * ICON<br> * TOGGLE<br> * VALUE<br> * SLIDER<br> * LINEAR_SCALE<br> * AUTOCOMPLETE<br> * QR_CODE<br> * BAR_CODE<br> * GS1_DATAMATRIX |

由于处理数据元素和跟踪实体的默认呈现
属性取决于对象的值类型，还有
一个 DEFAULT 类型告诉客户端它应该被正常处理。
程序阶段部分默认为“列表”。

Table: RenderingTypes allowed based on value types

| 值类型               | Is object an optionset? | RenderingTypes allowed |
|--------------------------|---|---|
| TRUE_ONLY                | 不 | DEFAULT, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, TOGGLE |
| BOOLEAN                  | 不 ||
| --                        | 是的 | DEFAULT, DROPDOWN, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, SHARED_HEADER_RADIOBUTTONS, ICONS_AS_BUTTONS, SPINNER, ICON |
| INTEGER                  | 不 | DEFAULT, VALUE, SLIDER, LINEAR_SCALE, SPINNER |
| TEXT                     | 不 | DEFAULT, VALUE, AUTOCOMPLETE, QR_CODE, BAR_CODE, GS1_DATAMATRIX |
| INTEGER_POSITIVE         | 不 ||
| INTEGER_NEGATIVE         | 不 ||
| INTEGER_ZERO_OR_POSITIVE | 不 ||
| NUMBER                   | 不 ||
| UNIT_INTERVAL            | 不 ||
| PERCENTAGE               | 不 ||

上表的完整参考也可以使用
以下端点：

    GET /api/staticConfiguration/renderingOptions

值类型渲染也有一些额外的属性，可以
设置，通常在渲染某些特定类型时需要：

Table: renderType object properties

| Property | 描述 | 类型 |
|---|---|---|
| type | The RenderingType of the object, as seen in the first table. This property is the same for both value type and program stage section, but is the only property available for program stage section. | Enum (See list in the Metadata and Rendering Type table) |
| min | Only for value type rendering. Represents the minimum value this field can have. | 整数 |
| max | Only for value type rendering. Represents the maximum value this field can have. | 整数 |
| step | Only for value type rendering. Represents the size of the steps the value should increase, for example for SLIDER og LINEAR_SCALE | 整数 |
| decimalPoints | Only for value type rendering. Represents the number of decimal points the value should use. | 整数 |

*renderingType* 可以在创建或更新第一个表中列出的元数据时设置。程序阶段部分的渲染类型的示例负载如下所示：

```json
{
  "renderingType": {
    "type": "MATRIX"
  }
}
```

对于数据元素和跟踪的实体属性：

```json
{
  "renderingType": {
    "type": "SLIDER",
    "min": 0,
    "max": 1000,
    "step": 50,
    "decimalPoints": 0
  }
}
```

## 对象样式 { #webapi_object_style } 

大多数元数据都有一个属性名称“样式”。可以使用此属性
由客户以某种方式表示对象。属性
目前支持的样式如下：

Table: Style properties

| Property | 描述 | 类型 |
|---|---|---|
| color | A color, represented by a hexadecimal. | String (#000000) |
| icon | An icon, represented by a icon-name. | 串 |

目前，没有官方列表或对图标库的支持，所以
这目前由客户提供。下面的列表显示
所有支持样式的对象：

  - 数据元素

  - 数据元素类别选项

  - 资料集

  - 指示符

  - 选项

  - 程序

  - 计划指标

  - 计划科

  - 程序阶段

  - 程序阶段部分

  - 关系（跟踪器）

  - 跟踪实体属性

  - 追踪实体类型

在创建或更新任何这些对象时，您可以包括
以下有效负载更改样式：

```json
{
  "style": {
    "color": "#ffffff",
    "icon": "my-beautiful-icon"
  }
}
```

## 数据元素 { #data-elements } 

### Merge data elements { #data_element_merge }

> **Caution**
>
> Merging DataElements should be carried out with the utmost care. Particular attention
> should be given to the merging of data values that have data element references involved in the
> merge. Knowing the potential side effects of a merge should be fully understood before performing
> the merge. The merging of DataElements has far-reaching effects. The information below
> will try to help show what's involved in a DataElement merge. A DataElement merge
> touches all the major parts of the system (metadata, data, tracker, analytics and audit).
> 
> System performance may be impacted if the source DataElements are linked to large amounts of Data/Audit records particularly.

The data element merge endpoint allows you to merge a number of data elements (sources) into a target data element.

#### Authorisation { #authorisation } 

The main authority required to perform a data element merge is `F_DATA_ELEMENT_MERGE`.  
Other authorities required relate to the general sharing and access of data elements, `F_DATAELEMENT_PUBLIC_ADD` and `F_DATAELEMENT_DELETE`.

#### Request { #request } 

Merge data elements with a POST request:

```
POST /api/dataElements/merge
```

The payload in JSON format looks like the following:

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "deleteSources": true,
  "dataMergeStrategy": "DISCARD"
}
```

The JSON properties are described in the following table.

Table: Merge payload fields

| 领域             | 需要 | 值                                                                                                                                                                                   |
|-------------------|----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| sources           | 是的      | Array of identifiers of the data elements to merge (the source data elements)                                                                                                           |
| target            | 是的      | Identifier of the data element to merge the sources into (the target data element)                                                                                                      |
| deleteSources     | 不       | Whether to delete the source data elements after the operation. Default is false. If true is chosen, then all source audit records will also be deleted.                                |
| dataMergeStrategy | 是的      | How to handle merging of data values. Options are 'DISCARD' or 'LAST_UPDATED'. DISCARD will delete all source data values. LAST_UPDATED will use the data value which was last updated. |

The merge operation will merge the source data elements into the target data element. One or many source data elements can be specified. Only one target should be specified.

The merge operation will transfer all source data element metadata associations to the target data element.
The following metadata get updated:


| 元数据                          | Property                  | Action taken               |
|-----------------------------------|---------------------------|----------------------------|
| DataDimensionItem                 | dataElement               | set to target              |
| EventVisualization                | dataElementValueDimension | set to target              |
| ProgramStageDataElement           | dataElement               | set to target              |
| ProgramNotificationTemplate       | recipientDataElement      | set to target              |
| ProgramRuleVariable               | dataElement               | set to target              |
| ProgramRuleAction                 | dataElement               | set to target              |
| TrackedEntityDataElementDimension | dataElement               | set to target              |
| MinMaxDataElement                 | dataElement               | set to target              |
| SMSCode                           | dataElement               | set to target              |
| SMSCode                           | dataElement               | set to target              |
| 预测变量                         | output                    | set to target              |
| DataSetElement                    | dataElement               | set to target              |
| DataElementOperand                | dataElement               | set to target              |
| ProgramStageDataElement           | dataElements              | remove sources, add target |
| Section                           | dataElements              | remove sources, add target |
| DataElementGroup                  | members                   | remove sources, add target |
| 事件                             | eventDataValues           | remove sources, add target |
| 指示符                         | numerator                 | replace source with target |
| 指示符                         | denominator               | replace source with target |
| 预测变量                         | generator                 | replace source with target |
| 预测变量                         | sampleSkipTest            | replace source with target |
| DataEntryForm                     | htmlCode                  | replace source with target |
| ProgramIndicator                  | expression                | replace source with target |
| ProgramIndicator                  | filter                    | replace source with target |
| DataValue                         | dataElement               |                            |


| 数据                            | Property        | Action taken                                                                                                                                                                                             |
|---------------------------------|-----------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| 事件                           | eventDataValues | action based on merge strategy (DISCARD / LAST_UPDATED). DISCARD will delete all source event data values. LAST_UPDATED will use the event data value which was last updated, when more than one exists. |
| DataValue                       | dataElement     | action based on merge strategy (DISCARD / LAST_UPDATED). DISCARD will delete all source data values. LAST_UPDATED will use the data value which was last updated, when more than one exists.             |
| TrackedEntityDataValueChangeLog |                 | deleted if sources are being deleted, otherwise no action.                                                                                                                                               |
| DataValueAudit                  |                 | deleted if sources are being deleted, otherwise no action.                                                                                                                                               |


#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| 错误代码 | 描述                                                                                                                                 |
|------------|---------------------------------------------------------------------------------------------------------------------------------------------|
| E1550      | At least one source data element must be specified                                                                                          |
| E1551      | Target data element must be specified                                                                                                       |
| E1552      | Target data element cannot be a source indicator                                                                                            |
| E1553      | Source/Target data element does not exist: `{uid}`                                                                                          |
| E1554      | All source ValueTypes must match target ValueType: `ValueType`. Other ValueTypes found: `ValueType`                                         |
| E1555      | All source DataElementDomains must match target DataElementDomain: `DataElementDomain`. Other DataElementDomains found: `DataElementDomain` |
| E1556      | dataMergeStrategy field must be specified. With value `DISCARD` or `LAST_UPDATED`                                                           |

#### Database constraints { #database-constraints } 
There are unique constraints in place that can prevent a successful merge. These constraints are set by DHIS2 in order to maintain a logical domain model.    
Below are a list of the known database unique key constraints at the time of writing. For example, you
can only have 1 data set element with the same dataset and data element.

Table: Database table unique key constraints

| Table                   | Unique key constraint                     |
|-------------------------|-------------------------------------------|
| minmaxdataelement       | orgunit, dataelement, categoryoptioncombo |
| programstagedataelement | programstage, dataelement                 |
| datasetelement          | dataset, dataelement                      |


#### Response { #response } 
##### Success { #success } 
Sample success response looks like:

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "response": {
        "mergeReport": {
            "mergeErrors": [],
            "mergeType": "DATA_ELEMENT",
            "sourcesDeleted": [
                "vQ0dGV9EDrw"
            ],
            "message": "DATA_ELEMENT merge complete"
        }
    }
}
```

##### Failure { #failure } 
Sample error response looks like:

```json
{
    "httpStatus": "Conflict",
    "httpStatusCode": 409,
    "status": "WARNING",
    "message": "One or more errors occurred, please see full details in merge report.",
    "response": {
        "mergeReport": {
            "mergeErrors": [
                {
                    "message": "At least one source data element must be specified",
                    "errorCode": "E1550",
                    "args": []
                },
                {
                    "message": "Target data element does not exist: `abcdefg1221`",
                    "errorCode": "E1553",
                    "args": [
                        "Target",
                        "abcdefg1221"
                    ]
                }
            ],
            "mergeType": "DATA_ELEMENT",
            "sourcesDeleted": [],
            "message": "DATA_ELEMENT merge has errors"
        }
    }
}
```

Another sample validation error response:

```json
{
    "httpStatus": "Conflict",
    "httpStatusCode": 409,
    "status": "WARNING",
    "message": "One or more errors occurred, please see full details in merge report.",
    "response": {
        "mergeReport": {
            "mergeErrors": [
                {
                    "message": "All source ValueTypes must match target ValueType: `TEXT`. Other ValueTypes found: `NUMBER`",
                    "errorCode": "E1554",
                    "args": []
                }
            ],
            "mergeType": "DATA_ELEMENT",
            "sourcesDeleted": [],
            "message": "DATA_ELEMENT merge has errors"
        }
    }
}
```

A database constraint sample error response:

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "ERROR: duplicate key value violates unique constraint \"minmaxdataelement_unique_key\"\n  Detail: Key (sourceid, dataelementid, categoryoptioncomboid)=(193236, 1148617, 167661) already exists."
}
```

## 指标 { #webapi_indicators } 

本节介绍指标和指标表达式。

### 综合指标 { #webapi_aggregate_indicators } 

要检索指标，您可以向指标发出 GET 请求
像这样的资源：

    / api /指标

指标表示可以计算和呈现的表达式
因此。指标表达式分为分子和
分母。分子和分母是数学的
可以包含对数据元素、其他指标、常量和
组织单位组。变量将替换为数据
使用时的值，例如在报告中。允许的变量
表达式在下表中描述。

Table: Indicator variables

| 变量 | 目的 | 描述 |
|---|---|---|
| #{<data-element-id\>.<category-option-combo-id\>.<attribute-option-combo-id\>} | 数据元素操作数 | Refers to a combination of an aggregate data element and a category option combination. Both category and attribute option combo ids are optional, and a wildcard "\*" symbol can be used to indicate any value. |
| #{<dataelement-id\>.<category-option-group-id\>.<attribute-option-combo-id\>} | Category Option Group | Refers to an aggregate data element and a category option group, containing multiple category option combinations. |
| #{<data-element-id\>} | 汇总数据元素 | 指所有类别选项组合中的聚合数据元素的总值。 |
| D{<program-id\>.<data-element-id\>} | 程序数据元素 | 引用程序中跟踪器数据元素的值。 |
| A{<program-id\>.<attribute-id\>} | 程序跟踪的实体属性 | 指程序中被跟踪实体属性的值。 |
| I{<program-indicator-id\>} | 计划指标 | 指程序指示器的值。 |
| R{<dataset-id\>.<metric\>} | 报告率 | 指报告率指标。指标可以是REPORTING_RATE，REPORTING_RATE_ON_TIME，ACTUAL_REPORTS，ACTUAL_REPORTS_ON_TIME，EXPECTED_REPORTS。 |
| C{<constant-id\>} | 不变 | 指恒定值。 |
| N{<indicator-id\>} | 指示符 | Refers to an existing Indicator. |
| OUG{<orgunitgroup-id\>} | 组织单位组 | 指组织单位组内组织单位的数量。 |

Within a Data element operand or an Aggregate data element, the following substitutions may be made:

| 项目 | 值 | 描述 |
|---|---|---|
| data-element-id | data-element-id | An aggregate data element |
| data-element-id | deGroup:data-element-group-id | All the aggregate data elements in a data element group |
| category-option-combo-id | category-option-combo-id | A category option combination |
| category-option-combo-id | co:category-option-id | All the category option combinations in a category option |
| category-option-combo-id | coGroup:category-option-group-id | All the category option combinations in a category option group |
| category-option-combo-id | coGroup:co-group-id1&co-group-id2... | All the category option combinations that are members of multiple category option groups |

语法看起来像
    这：

＃

相应的示例如下所示：

＃

请注意，对于数据元素变量，类别选项组合
标识符可以省略。该变量将代表总数
对于数据元素，例如在所有类别选项组合中。例子：

＃

数据元素操作数可以包括任何类别选项组合和
属性选项组合，并使用通配符表示任何
    价值：

＃

An example using a data element group:

    #{deGroup:oDkJh5Ddh7d} + #{deGroup:GBHN1a1Jddh.j8vBiBqGf6O}

An example using a category option, data element group, and a category option group:

    #{P3jJH5Tu5VC.co:FbLZS3ueWbQ} + #{deGroup:GBHN1a1Jddh.coGroup:OK2Nr4wdfrZ.j8vBiBqGf6O}

An example using multiple category option groups:

    #{P3jJH5Tu5VC.coGroup:OK2Nr4wdfrZ&j3C417uW6J7&ddAo6zmIHOk}

An example using a program data element and a program attribute:

    （D {eBAyeGv0exc.vV9UWAZohSf} * A {IpHINAT79UW.cejWyOfXge6}）/ D {eBAyeGv0exc.GieVkTxp4HH}

An example combining program indicators and aggregate indicators:

    I {EMOt6Fwhs1n} * 1000 /＃{WUg3MYWQ7pt}

An example using a reporting rate:

    R {BfMAe6Itzgt.REPORTING_RATE} *＃{P3jJH5Tu5VC.S34ULMcHMca}

Another reporting rate example using actual data set reports and expected reports:

    R {BfMAe6Itzgt.ACTUAL_REPORTS} / R {BfMAe6Itzgt.EXPECTED_REPORTS}

An example using an existing indicator:

    N {Rigf2d2Zbjp} *＃{P3jJH5Tu5VC.S34ULMcHMca}

表达式可以是任何类型的有效数学表达式，作为
例子：

    （2 *＃{P3jJH5Tu5VC.S34ULMcHMca}）/（＃{FQ2o8UBlcrS.S34ULMcHMca}-200）* 25

### 计划指标 { #webapi_program_indicators } 

要检索程序指标，您可以向程序发出 GET 请求
像这样的指标资源：

    / api / programIndicators

程序指示器可以包含在程序中收集的信息。
指标有一个表达式，可以包含对数据的引用
元素、属性、常量和程序变量。变量
下表中描述了允许在表达式中使用。



Table: Program indicator variables

| 变量 | 描述 |
|---|---|
| #{<programstage-id\>.<dataelement-id\>} | Refers to a combination of program stage and data element id. |
| A{<attribute-id\>} | Refers to a tracked entity attribute. |
| V{<variable-id\>} | Refers to a program variable. |
| C{<constant-id\>} | Refers to a constant. |

语法看起来像
    这：

＃

一个相应的例子看起来像
    这：

＃

### 表达方式 { #webapi_expressions } 

表达式是数学公式，可以包含对
数据元素、常量和组织单元组。验证和
获取表达式的文本描述，您可以发出 GET 请求
到表达式资源：

    / api / expressions / description？expression = <expression-string>

响应遵循标准的 JSON Web 消息格式。 *状态*
属性表示验证的结果，如果
成功和“错误”如果失败。 *message* 属性将为“有效”
如果成功并提供原因的文字描述
如果不是，则验证失败。 *描述*提供了文字说明
表达式的描述。

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Valid",
  "description": "Acute Flaccid Paralysis"
}
```

### Merge indicators { #webapi_indicator_merge }

The indicator merge endpoint allows you to merge a number of indicators (sources) into a target indicator.

#### Authorisation { #authorisation } 

The authority `F_INDICATOR_MERGE` is required to perform indicator merges.

#### Request { #request } 

Merge indicators with a POST request:

```
POST /api/indicators/merge
```

The payload in JSON format looks like the following:

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "deleteSources": true
}
```

The JSON properties are described in the following table.

Table: Merge payload fields

| 领域         | 需要 | 值                                                                         |
|---------------|----------|-------------------------------------------------------------------------------|
| sources       | 是的      | Array of identifiers of the indicators to merge (the source indicators)       |
| target        | 是的      | Identifier of the indicator to merge the sources into (the target indicator)  |
| deleteSources | 不       | Whether to delete the source indicators after the operation. Default is false |

The merge operation will merge the source indicators into the target indicator. One or many source indicators can be specified. Only one target should be specified.

The merge operation will transfer all source indicator metadata associations to the target indicator. 
The following metadata get updated:


| 元数据            | Property                                   | Action taken                                                                |
|---------------------|--------------------------------------------|-----------------------------------------------------------------------------|
| IndicatorGroup      | members                                    | Source indicator removed, target indicator added                            |
| 数据集             | 指标                                 | Source indicator removed, target indicator added                            |
| DataDimensionalItem | n/a                                        | Any linked data items with sources will be linked with the target           |
| Section             | 指标                                 | Source indicator removed, target indicator added                            |
| 组态       | infrastructuralIndicators (IndicatorGroup) | Source indicator removed, target indicator added                            |
| 指示符           | numerator / denominator                    | Replace any source reference with the target reference                      |
| DataEntryForm       | htmlCode                                   | Replace any source reference with the target reference                      |
| Visualization       | sorting                                    | Replace any source reference with the target reference as Sorting dimension |


#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| 错误代码 | 描述                                     |
|------------|-------------------------------------------------|
| E1540      | At least one source indicator must be specified |
| E1541      | Target indicator must be specified              |
| E1542      | Target indicator cannot be a source indicator   |
| E1543      | Source/Target indicator does not exist: `{uid}` |

#### Response { #response } 
##### Success { #success } 
Sample success response looks like:

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "response": {
        "mergeReport": {
            "mergeErrors": [],
            "mergeType": "INDICATOR",
            "sourcesDeleted": [
                "vQ0dGV9EDrw"
            ],
            "message": "INDICATOR merge complete"
        }
    }
}
```

Sample error response looks like:

```json
{
    "httpStatus": "Conflict",
    "httpStatusCode": 409,
    "status": "WARNING",
    "message": "One or more errors occurred, please see full details in merge report.",
    "response": {
        "mergeReport": {
            "mergeErrors": [
                {
                    "message": "At least one source indicator must be specified",
                    "errorCode": "E1540",
                    "args": []
                },
                {
                    "message": "Target indicator does not exist: `abcdefg1221`",
                    "errorCode": "E1543",
                    "args": [
                        "Target",
                        "abcdefg1221"
                    ]
                }
            ],
            "mergeType": "INDICATOR",
            "sourcesDeleted": [],
            "message": "INDICATOR merge has errors"
        }
    }
}
```

## Indicator Types { #webapi_indicator_types}

### Merge indicator types { #webapi_indicator_type_merge}

The indicator type merge endpoint allows you to merge a number of indicator types into a target indicator type.

#### Authorisation { #authorisation } 

The authority `F_INDICATOR_TYPE_MERGE` is required to perform indicator type merges.

#### Request { #request } 

Merge indicator types with a POST request:

```
POST /api/indicatorTypes/merge
```

The payload in JSON format looks like the following:

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "deleteSources": true
}
```

The JSON properties are described in the following table.

Table: Merge payload fields

| 领域         | 需要 | 值                                                                                   |
|---------------|----------|-----------------------------------------------------------------------------------------|
| sources       | 是的      | Array of identifiers of the indicator types to merge (the source indicator types).      |
| target        | 是的      | Identifier of the indicator type to merge the sources into (the target indicator type). |
| deleteSources | 不       | Whether to delete the source indicator types after the operation. Default is false.     |

The merge operation will merge the source indicator types into the target indicator type. One or many source indicator types can be specified. Only one target should be specified.

The merge operation will transfer all of the indicator metadata associations to the source indicator types over to the target indicator type.

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| 错误代码 | 描述                                             |
|------------|---------------------------------------------------------|
| E1530      | At least one source indicator type must be specified    |
| E1531      | Target indicator type must be specified                 |
| E1532      | Target indicator type cannot be a source indicator type |
| E1533      | Source/Target indicator type does not exist: `{uid}`    |

#### Response { #response } 
##### Success { #success } 
Sample success response looks like:

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "response": {
        "mergeReport": {
            "mergeErrors": [],
            "mergeType": "INDICATOR_TYPE",
            "sourcesDeleted": [
                "vQ0dGV9EDrw"
            ],
            "message": "INDICATOR_TYPE merge complete"
        }
    }
}
```

Sample error response looks like:

```json
{
    "httpStatus": "Conflict",
    "httpStatusCode": 409,
    "status": "WARNING",
    "message": "One or more errors occurred, please see full details in merge report.",
    "response": {
        "mergeReport": {
            "mergeErrors": [
                {
                    "message": "At least one source indicator type must be specified",
                    "errorCode": "E1530",
                    "args": []
                },
                {
                    "message": "Target indicator type does not exist: `abcdefg1221`",
                    "errorCode": "E1533",
                    "args": [
                        "Target",
                        "abcdefg1221"
                    ]
                }
            ],
            "mergeType": "INDICATOR_TYPE",
            "sourcesDeleted": [],
            "message": "INDICATOR_TYPE merge has errors"
        }
    }
}
```

## 组织单位 { #webapi_organisation_units } 

*organisationUnits* 资源遵循标准约定，如
DHIS2 中的其他元数据资源。该资源支持一些
附加查询参数。

### 获取组织单位列表 { #webapi_list_of_organisation_units } 

要获取组织单位的列表，可以使用以下资源。

    / api / 33 / organisationUnits

Table: Organisation units query parameters

| 查询参数 | 选项 | 描述 |
|---|---|---|
| userOnly | false &#124; true | Data capture organisation units associated with current user only. |
| userDataViewOnly | false &#124; true | Data view organisation units associated with current user only. |
| userDataViewFallback | false &#124; true | Data view organisation units associated with current user only with fallback to data capture organisation units. |
| query | string | Query against the name, code and ID properties. |
| level | 整数 | Organisation units at the given level in the hierarchy. |
| maxLevel | 整数 | Organisation units at the given max level or levels higher up in the hierarchy. |
| withinUserHierarchy | false &#124; true | Limits search and retrieval to organisation units that are within the users data capture scope. |
| withinUserSearchHierarchy | false &#124; true | Limits search and retrieval to organisation units that are within the current users search scope. Note: "withinUserHierarchy", if true, takes higher precedence. |
| memberCollection | string | For displaying count of members within a collection, refers to the name of the collection associated with organisation units. |
| memberObject | 用户标识 | For displaying count of members within a collection, refers to the identifier of the object member of the collection. |

### Get organisation unit with sub-hierarchy { #webapi_organisation_units_with_sub_hierarchy } 

To get an organisation unit including organisation units in its sub-hierarchy you can use the following resource.

    / api / 33 / organisationUnits / {id}

Table: Organisation unit parameters

| 查询参数 | 选项 | 描述 |
|---|---|---|
| includeChildren | false &#124; true | Include immediate children of the specified organisation unit, i.e. the units at the immediate level below in the subhierarchy. |
| includeDescendants | false &#124; true | Include all children of the specified organisation unit, i.e. all units in the sub-hierarchy. |
| includeAncestors | false &#124; true | Include all parents of the specified organisation unit. |
| level | 整数 | Include children of the specified organisation unit at the given level of the sub-hierarchy. This is relative to the organisation unit, starting on 1 for the level immediately below the org unit. |

### Get organisation units by category option  { #webapi_organisation_units_by_category_options }

Purpose-built endpoint to retrieve associations between category options and organisation units. This endpoint is the preferred way to retrieve program organisation unit associations.

    /api/33/categoryOptions/orgUnits?categoryOptions={categoryOptionIdA},{categoryOptionIdB}

responses will have the following format:

```json
{
  "<categoryOptionIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdC>": []
}
```

Category options that are accessible by all organisation units are returned with an empty array (`[]`) of organisation units.

### Get organisation units by programs { #webapi_organisation_units_by_programs } 

Purpose-built endpoint to retrieve associations between programs and organisation units. This endpoint is the preferred way to retrieve program organisation unit associations.

    /api/33/programs/orgUnits?programs={programIdA},{programIdB}

responses will have the following format:

```json
{
  "<programIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdC>": []
}
```

Programs which are accessible by all organisation units are returned with an empty array (`[]`) of organisation units.

### Split organisation unit { #webapi_organisation_unit_split }

The organisation unit split endpoint allows you to split organisation units into a number of target organisation units. 

#### Request { #request } 

Split organisation units with a POST request:

```
POST /api/organisationUnits/split
```

The payload in JSON format looks like the following:

```json
{
  "source": "rspjJHg4WY1",
  "targets": [
    "HT0w9YLMLyn",
    "rEpnzuNpRKM"
  ],
  "primaryTarget": "HT0w9YLMLyn",
  "deleteSource": true
}
```

The JSON properties are described in the following table.

Table: Split payload fields

| 领域         | 需要 | 值 |
| ------------- | -------- |------ |
| source        | 是的      | Identifier of the organisation unit to split (the source organisation unit). |
| targets       | 是的      | Array of identifiers of the organisation units to split the source into (the target organisation units). |
| primaryTarget | 不       | Identifier of the organisation unit to transfer the aggregate data, events and tracked entities associated with the source over to. If not specified, the first target will be used. |
| deleteSource  | 不       | 操作后是否删除源组织单位。默认为`真`。 |

The split operation will split the source org unit into the target org units. It is recommended to first create new target org units before performing the split, and at a minimum ensure that no aggregate data exists for the target org units. Any number of target org units can be specified.

The split operation will transfer all of the metadata associations of the source org unit over to the target org units. This includes data sets, programs, org unit groups, category options, users, visualizations, maps and event reports.

The operation will transfer all data records of the source org unit over to the org unit specified as the primary target, or if not specified, the first specified target org unit. This includes aggregate data values, data approval records, events, tracked entities and more.

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| 错误代码 | 描述                                     |
| ---------- | ----------------------------------------------- |
| E1510      | Source org unit must be specified               |
| E1511      | At least two target org units must be specified |
| E1512      | Source org unit cannot be a target org unit     |
| E1513      | Primary target must be specified                |
| E1514      | Primary target must be a target org unit        |
| E1515      | Target org unit does not exist                  |

### Merge organisation units { #webapi_organisation_unit_merge}

The organisation unit merge endpoint allows you to merge a number of organisation units into a target organisation unit.

#### Request { #request } 

Merge organisation units with a POST request:

```
POST /api/organisationUnits/merge
```

The payload in JSON format looks like the following:

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "dataValueMergeStrategy": "LAST_UPDATED",
  "dataApprovalMergeStrategy": "LAST_UPDATED",
  "deleteSources": true
}
```

The JSON properties are described in the following table.

Table: Merge payload fields

| 领域                     | 需要 | 值 |
| ------------------------- | -------- | ----- |
| sources                   | 是的      | Array of identifiers of the organisation units to merge (the source organisation units). |
| target                    | 是的      | Identifier of the organisation unit to merge the sources into (the target organisation unit). |
| dataValueMergeStrategy    | 不       | Strategy for merging data values. Options: `LAST_UPDATED` (default), `DISCARD`. |
| dataApprovalMergeStrategy | 不       | Strategy for merging data approval records. Options: `LAST_UPDATED` (default), `DISCARD`. |
| deleteSources             | 不       | Whether to delete the source organisation units after the operation. Default is true. |

The merge operation will merge the source org units into the target org unit. It is recommended to first create a new target org unit before performing the merge, and at a minimum ensure that no aggregate data exists for the target org unit. Any number of source org units can be specified.

The merge operation will transfer all of the metadata associations of the source org units over to the target org unit. This includes data sets, programs, org unit groups, category options, users, visualizations, maps and event reports. The operation will also transfer all event and tracker data, such as events, enrollments, ownership history, program ownership and tracked entities, over to the target org unit.

指定的数据值合并策略定义了如何处理数据值。对于`LAST_UPDATED`策略，所有源组织单位的数据值都将转移到目标组织单位，并且在相同参数存在数据值的情况下，将使用最后更新或创建的数据值。这样做是为了避免数据重复。对于`DISCARD`策略，数据值不会转移到目标组织单位，而是简单地删除。指定的数据审批合并策略定义了数据审批记录的处理方式，并遵循与数据值相同的逻辑。

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| 错误代码 | 描述                                     |
| ---------- | ----------------------------------------------- |
| E1500      | At least two source orgs unit must be specified |
| E1501      | Target org unit must be specified               |
| E1502      | Target org unit cannot be a source org unit     |
| E1503      | Source org unit does not exist                  |

## 数据集 { #webapi_data_sets } 

*dataSets* 资源遵循标准约定作为其他
DHIS2 中的元数据资源。此资源支持一些额外的
查询参数。

    / api / 33 / dataSets

要检索数据集的版本，您可以发出GET请求：

    GET /api/33/dataSets/<uid>/version

要提高（增加一个）数据集的版本，您可以发出 POST
要求：

    POST / api / 33 / dataSets / <uid> / version

### Data set notification template { #webapi_dataset_notifications } 

*数据集通知模板*资源遵循标准
DHIS2 中其他元数据资源的约定。

    GET /api/33/dataSetNotficationTemplates

要检索数据集通知模板，您可以发出GET请求：

    GET /api/33/dataSetNotficationTemplates/<uid>

要添加数据集通知模板，您可以发出POST请求：

    POST / api / 33 / dataSetNotficationTemplates

要删除数据集通知模板，您可以发出DELETE请求：

    删除/ api / 33 / dataSetNotficationTemplates / <uid>

JSON有效负载示例如下：

```json
{
  "name": "dataSetNotificationTemplate1",
  "dataSetNotificationTrigger": "DATA_SET_COMPLETION",
  "relativeScheduledDays": 0,
  "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
  "dataSets": [{
    "id": "eZDhcZi6FLP"
  }],
  "deliveryChannels": ["SMS","EMAIL"],
  "subjectTemplate": "V{data_set_name}",
  "messageTemplate": "V{data_set_name}V{registration_period}",
  "sendStrategy": "SINGLE_NOTIFICATION"
}

```

`notificationRecipient` can be one of:
- `USER_GROUP` for internal messages
- `ORGANISATION_UNIT_CONTACT` for external messages


## 填充的组织单位级别 { #webapi_filled_organisation_unit_levels } 

*fillOrganisationUnitLevels* 资源提供了一个有序的列表
组织单元级别，其中生成的级别被注入到
列表以填充不存在持久级别的位置。

    GET /api/33/filledOrganisationUnitLevels

To set the organisation unit levels you can issue a POST request with a
JSON payload and content type `application/json` looking like this:

```json
{
  "organisationUnitLevels": [{
    "name": "National",
    "level": 1,
    "offlineLevels": 3
  }, {
    "name": "District",
    "level": 2
  }, {
    "name": "Chiefdom",
    "level": 3
  }, {
    "name": "Facility",
    "level": 4
  }]
}
```

## 预测变量 { #webapi_predictors } 

预测器允许您根据表达式生成数据值。
这可以用于例如生成目标、阈值、
或估计值。

要检索预测器，您可以向预测器发出 GET 请求
像这样的资源：

    / api / predictors

### 创建预测变量 { #webapi_create_predictor } 

您可以使用对预测器的 POST 请求创建预测器
资源：

    POST / api / predictors

有效负载样本如下所示：

```json
{
  "id": "AG10KUJCrRk",
  "name": "Malaria Outbreak Threshold Predictor",
  "shortName": "Malaria Outbreak Predictor",
  "description": "Computes the threshold for potential malaria outbreaks based on the mean plus 1.5x the std dev",
  "output": {
    "id": "nXJJZNVAy0Y"
  },
  "generator": {
    "expression": "AVG(#{r6nrJANOqMw})+1.5*STDDEV(#{r6nrJANOqMw})",
    "description": "Maximum normal malaria case count",
    "missingValueStrategy": "NEVER_SKIP",
    "slidingWindow": false
  },
  "periodType": "Monthly",
  "sequentialSampleCount": 4,
  "sequentialSkipCount": 1,
  "annualSampleCount": 3,
  "organisationUnitLevels": [4]
}
```

输出元素是指数据元素的标识符
其中保存预测数据值。生成器元素是指
计算预测值时使用的表达式。

### 预测表达式 { #webapi_predictor_expressions } 

预测器总是有一个生成器表达式来描述
计算出预测值。预测器也可能有跳过测试
表达式返回一个布尔值。当跳过测试表达式为
目前，在每个采样周期中对其进行评估，以判断是否
应该跳过那个时期的值。

以下变量可用于生成器表达式
或跳过测试表达式：

| 变量    | 目的     | 描述 |
| ----------- | ---------- | ----------- |
| #{<dataelement-id>} | 汇总数据元素 | 指所有类别选项组合中的聚合数据元素的总值。 |
| #{<dataelement-id>.<categoryoptcombo-id> | 数据元素操作数 | 指聚合数据元素和类别选项组合的组合。 |
| D{<program-id>.<dataelement-id>} | 程序数据元素 | 引用程序中跟踪器数据元素的值。 |
| A{<program-id>.<attribute-id>} | 程序跟踪的实体属性 | 指程序中被跟踪实体属性的值。 |
| I{<program-indicator-id>} | 计划指标 | 指程序指示器的值。 |
| R{<dataset-id>.<metric>} | 报告率 | 指报告率指标。指标可以是REPORTING_RATE，REPORTING_RATE_ON_TIME，ACTUAL_REPORTS，ACTUAL_REPORTS_ON_TIME，EXPECTED_REPORTS。 |
| C{<constant-id>} | 不变 | 指恒定值。 |
| OUG{<orgunitgroup-id>} | 组织单位组 | 指组织单位组内组织单位的数量。 |
| [天] | 天数 | 当前期间的天数。 |

### 生成预测值 { #webapi_generating_predicted_values } 

要运行所有预测器（生成预测值），您可以进行 POST
请求运行资源：

    POST / api / predictors / run

要运行单个预测器，您可以向运行发出 POST 请求
预测器的资源：

    POST / api / predictors / AG10KUJCrRk / run

## 计划规则 { #webapi_program_rules } 

本节是关于发送和读取程序规则，并解释
程序规则数据模型。程序规则赋予功能
在 DHIS2 程序中配置动态行为。

### 程序规则模型 { #webapi_program_rule_model } 

程序规则数据模型由 programRuleVariables、
程序规则和程序规则操作。 programRule 包含一个
表达式 - 当这个表达式为真时，子程序RuleActions
被触发。 programRuleVariables 用于寻址数据元素，
跟踪实体数据值和运行所需的其他数据值
表达式。一个程序中的所有程序规则共享同一个程序库
programRuleVariables，一个 programRuleVariable 可以用于多个
程序规则的表达式。

![](resources/images/program_rules/program-rule-model.jpg)

#### 程序规则模型详细信息 { #program-rule-model-details } 

下表给出了程序规则的详细概述
模型。

Table: programRule

| 名称 | 描述 | Compulsory |
|---|---|---|
| program | The program of which the programRule is executed in. | Compulsory |
| 名称 | The name with which the program rule will be displayed to dhis2 configurators. Not visible to the end user of the program. | Compulsory |
| 描述 | The description of the program rule, can be used by configurators to describe the rule. Not visible to the end user of the program. | Compulsory |
| programStage | If a programStage is set for a program rule, the rule will only be evaluated inside the specified program stage. | optional |
| 健康）状况 | The expression that needs to be evaluated to true in order for the program rule to trigger its child actions. The expression is written using operators, function calls, hard coded values, constants and program rule variables. `d2:hasValue('hemoglobin') && #{hemoglobin} <= 7 `| Compulsory |
| priority | The priority to run the rule in cases where the order of the rules matters. In most cases the rules does not depend on being run before or after other rules, and in these cases the priority can be omitted. If no priority is set, the rule will be run after any rules that has a priority defined. If a priority(integer) is set, the rule with the lowest priority will be run before rules with higher priority. | optional |

#### 计划规则操作模型详细信息 { #program-rule-action-model-details } 

下表给出了对 programRuleAction 的详细概述
模型。

Table: programRuleAction

| 名称 | 描述 | Compulsory |
|---|---|---|
| programRule | The programRule that is the parent of this action. | Compulsory |
| programRule- ActionType | The type of action that is to be performed.<br>  * `DISPLAYTEXT` - Displays a text in a given widget.<br> * `DISPLAYKEYVALUEPAIR` - Displays a key and value pair(like a program indicator) in a given widget.<br> * `HIDEFIELD` - Hide a specified dataElement or trackedEntityAttribute.<br>    -         *content* - if defined, the text in *content* will be displayed to the end user in the instance where a value is previously entered into a field that is now about to be hidden (and therefore blanked). If *content* is not defined, a standard message will be shown to the user in this instance.<br>   -         *dataElement* - if defined, the HIDEFIELD action will hide this dataElement when the rule is effective.<br>   -         *trackedEntityDataValue* - if defined, the HIDEFIELD action will hide this trackedEntityDataValue when the rule is effective.<br>  * `HIDESECTION` - Hide a specified section.<br>    -         *programStageSection* - must be defined. This is the programStageSection that will be hidden in case the parent rule is effective.<br>  * `ASSIGN` - Assign a dataElement a value(help the user calculate something or fill in an obvious value somewhere)<br>    -         *content* - if defined, the value in *data* is assigned to this variable. If content id defined, and thus a variable is assigned for use in other rules, it is important to also assign a *programRule.priority* to make sure the rule with an ASSIGN action runs before the rule that will in turn evaluate the assigned variable.<br>   -         *data* - must be defined, data forms an expression that is evaluated and assigned to either a variable(#{myVariable}), a dataElement, or both.<br>   -         *dataElement* - if defined, the value in *data* is assigned to this data element.<br>  Either the content or dataElement must be defined for the ASSIGN action to be effective.<br> * `SHOWWARNING` - Show a warning to the user, not blocking the user from completing the event or registration.<br>    -         *content* - if defined, content is a static part that is displayed at the end of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the warning message.<br>   -         *dataElement* - if defined, the warning message is displayed next to this data element.<br>   -         *trackedEntityAttribute* - if defined, the warning message is displayed next to this tracked entity attribute.<br>  Either dataElement or trackedEntityAttribute must be specified.<br> * `SHOWERROR` - Show an error to the user, blocking the user from completing the event or registration.<br>    -         *content* - if defined, content is a static part that is displayed in the start of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the error message.<br>   -         *dataElement* - if defined, the error message is linked to this data element.<br>   -         *trackedEntityAttribute* - if defined, the error message is linked to this tracked entity attribute.<br>  Either dataElement or trackedEntityAttribute must be specified.<br> * `WARNINGONCOMPLETE` - Show a warning to the user on the "Complete form" dialog, but allowing the user to complete the event.<br>    -         *content* - if defined, content is a static part that is displayed at the end of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the warning message.<br>   -         *dataElement* - if defined, the warning message prefixed with the name/formName of the data element.<br>  * `ERRORONCOMPLETE` - Show an error to the user on in a modal window when the user tries to complete the event. The user is prevented from completing the event.<br>    -         *content* - if defined, content is a static part that is displayed in the start of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the error message.<br>   -         *dataElement* - if defined, the error message is linked to this data element.<br>  * `CREATEEVENT` - Create an event within the same enrollment.<br>    -         *content*<br>   -         *data* - if defined, contains data values to assign the created event. The format is <uid\>:<data value\>. Where several values is specified, these are separated with comma.<br> AcMrnleqHqc:100,AqK1IHqCkEE:'Polyhydramnios'   -         *programStage* - must be defined, and designates the program stage that the rule shall create an event of.<br>  * `SETMANDATORYFIELD` - Set a field to be mandatory.<br>    -         *dataElement* - if defined, this data element will be set to be mandatory in the data entry form.<br>   -         *trackedEntityAttribute* - if defined, this tracked entity attribute will be set to mandatory in the registration form or profile.<br>  * `SENDMESSAGE` - To send message at completion of event/enrollment or at data value update.<br>    -         *messageTemplate* - if defined, this template will be delivered either as SMS or EMAIL depending upon DeliveryChannel value in message template.<br>  * `SCHEDULEMESSAGE` - To schedule message at completion of event/enrollment or at data value update.<br>    -         *messageTemplate* - if defined, this template will be delivered either as SMS or EMAIL depending upon DeliveryChannel value in message template.<br>   -         *Date to send message* - Expression which is going to be used for evaluation of scheduled date. This expression should result in Date, any other resultant will be discarded and notification will not get scheduled. | Compulsory |
| location | Used for actionType DISPLAYKEYVALUEPAIR and DISPLAYTEXT to designate which widget to display the text or keyvaluepair in. Compulsory for DISPLAYKEYVALUEPAIR and DISPLAYTEXT. | See description |
| content | Used for user messages in the different actions. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, DISPLAYTEXT and DISPLAYKEYVALUEPAIR. Optional for HIDEFIELD and ASSIGN. | See description |
| 数据 | Used for expressions in the different actions. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for ASSIGN. Optional for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, DISPLAYTEXT, CREATEEVENT and DISPLAYKEYVALUEPAIR | See description |
| dataElement | Used for linking rule actions to dataElements. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, ASSIGN and HIDEFIELD | See description |
| trackedEntity- Attribute | Used for linking rule actions to trackedEntityAttributes. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for SHOWWARNING, SHOWERROR and HIDEFIELD. | See description |
| option | Used for linking rule actions to options. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for HIDEOPTION | See description |
| optionGroup | Used for linking rule actions to optionGroups. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for SHOWOPTIONGROUP, HIDEOPTIONGROUP. | See description |
| programStage | Only used for CREATEEVENT rule actions. Compulsory for CREATEEEVENT. | See description |
| programStage- Section | Only used for HIDESECTION rule actions. Compulsory for HIDESECTION | See description |

##### ProgramRuleAction Validation { #programruleaction-validation } 
There are certain validations added to ProgramRuleAction model in 2.37. Main purpose was to keep user from creating erroneous ProgramRules in order to keep the database consistent. These validations depends on program rule action type. Each action type has its own respective validation. 

Table: ProgramRuleAction Validations

| 名称 | validation check for id existence |
|---|---|
|SENDMESSAGE| Notification template id |
|SCHEDULEMESSAGE| Notification template id |
|HIDESECTION| ProgramStage section id |
|HIDEPROGRAMSTAGE| ProgramStage id |
|HIDEFIELD| DataElement or TrackedEntityAttribute id |
|HIDEOPTION| Option id |
|HIDEOPTIONGROUP| Option group id |
|SHOWOPTIONGROUP| Option group id |
|SETMANDATORYFIELD| DataElement or TrackedEntityAttribute id |
|SHOWERROR| Always valid |
|SHOWWARNING| Always valid |
|DISPLAYTEXT| DataElement or TrackedEntityAttribute id |
|DISPLAYKEYVALUEPAIR||
|ASSIGN| DataElement or TrackedEntityAttribute id |
|WARNINGONCOMPLETE| DataElement or TrackedEntityAttribute id |
|ERRORONCOMPLETE| DataElement or TrackedEntityAttribute id |

Apart from above validations, `data` field in program rule action which normally contains expression can also be evaluated using below api endpoint.

    POST /api/programRuleActions/data/expression/description?programId=<uid>


```json
{
  "condition": "1 + 1"
}
```

#### 程序规则变量模型的详细信息 { #program-rule-variable-model-details } 

下表详细概述了
程序规则变量模型。

Table: programRuleVariable

| 名称 | 描述 | Compulsory |
|---|---|---|
| 名称 | the name for the programRuleVariable - this name is used in expressions. #{myVariable} \> 5 | Compulsory |
| sourceType | Defines how this variable is populated with data from the enrollment and events. <br> * DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE - In tracker capture, gets the newest value that exists for a data element, within the events of a given program stage in the current enrollment. In event capture, gets the newest value among the 10 newest events on the organisation unit.<br> * DATAELEMENT_NEWEST_EVENT_PROGRAM - In tracker capture, get the newest value that exists for a data element across the whole enrollment. In event capture, gets the newest value among the 10 newest events on the organisation unit.<br> * DATAELEMENT_CURRENT_EVENT - Gets the value of the given data element in the current event only.<br> * DATAELEMENT_PREVIOUS_EVENT - In tracker capture, gets the newest value that exists among events in the program that precedes the current event. In event capture, gets the newvest value among the 10 preceeding events registered on the organisation unit.<br> * CALCULATED_VALUE - Used to reserve a variable name that will be assigned by a ASSIGN program rule action<br> * TEI_ATTRIBUTE - Gets the value of a given tracked entity attribute | Compulsory |
| valueType | valueType parameter defines the type of the value that this ProgramRuleVariable can contain. Its value is dependent on sourceType parameter. If source is DataElement or TrackedEntityAttribute<br> then valueType will be derived from valueType of the source. When the sourceType is CALCULATED_VALUE, then valueType should be provided by the user otherwise it will default <br> to ValueType.TEXT| Compulsory
| dataElement | Used for linking the programRuleVariable to a dataElement. Compulsory for all sourceTypes that starts with DATAELEMENT_. | See description |
| trackedEntity- Attribute | Used for linking the programRuleVariable to a trackedEntityAttribute. Compulsory for sourceType TEI_ATTRIBUTE. | See description |
| useCodeFor- OptionSet | If checked, the variable will be populated with the code - not the name - from any linked option set. Default is unchecked, meaning that the name of the option is populated. ||
| programStage | Used for specifying a specific program stage to retreive the programRuleVariable value from. Compulsory for DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE. | See description |

### 创建程序规则 { #webapi_creating_program_rules } 

- To perform crud operations, `programRules` resource is available in API.

要检索programRules的列表，您可以执行GET请求，如下所示：

    / api / programRules

要检索单个programRule，您可以执行GET请求，如下所示：

    / api / programRules / <program_rule_uid>

要保存/添加单个programRule，您可以执行POST请求，如下所示：

    / api / programRules / <program_rule_uid>

要更新单个programRule，您可以执行如下PUT请求：

    / api / programRules / <program_rule_uid>

要删除单个programRule，您可以执行以下DELETE请求：

    / api / programRules / <program_rule_uid>

要检索programRule条件的描述，可以使用POST并在POST正文中提供条件字符串。

    / api / programRules / condition / description？ <program_rule_uid>

## 形式 { #webapi_forms } 

To retrieve information about a form (which corresponds to a data set
and its sections) you can interact with the `form` resource. The form
response is accessible as XML and JSON and will provide information
about each section (group) in the form as well as each field in the
sections, including labels and identifiers. By supplying period and
organisation unit identifiers the form response will be populated with
data values.

Table: Form query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| 聚乙烯 | ISO period | Period for which to populate form data values. |
| 欧 | 用户标识 | Organisation unit for which to populate form data values. |
| metaData | false &#124; true | Whether to include metadata about each data element of form sections. |

要检索数据集的表单，您可以执行GET请求，如下所示：

    / api / dataSets / <dataset-id> /form.json

检索具有标识符“BfMAe6Itzgt”的数据集的表单
XML：

    / api / dataSets / BfMAe6Itzgt / form

要检索包含JSON中的元数据的表单，请执行以下操作：

    /api/dataSets/BfMAe6Itzgt/form.json?metaData=true

检索填充了特定时期数据值的表单，并
XML 中的组织单位：

    /api/dataSets/BfMAe6Itzgt/form.xml?ou=DiszpKrYNg8&pe=201401

当涉及自定义数据输入表单时，此资源还允许
直接为数据集创建此类表单。这可以通过一个
内容类型为 text/html 的 POST 或 PUT 请求，其中有效负载是
自定义表单标记，例如：

```bash
curl -d @form.html "localhost/api/dataSets/BfMAe6Itzgt/form"
  -H "Content-Type:text/html" -u admin:district -X PUT
```

## 文件资料 { #webapi_documents } 

对文件的引用可以与文档资源一起存储。



Table: Document fields

| Field name | 描述 |
|---|---|
| 名称 | unique name of document |
| external | flag identifying the location of the document. TRUE for external files, FALSE for internal ones |
| url | the location of the file. URL for external files. File resource id for internal ones (see [File resources](#webapi_file_resources)) |

对文档端点的GET请求将返回所有文档：

    / api / documents

对文档端点的POST请求将创建一个新文档：

```bash
curl -X POST -d @document.json -H "Content-type: application/json"
  "http://dhis.domain/api/documents"
```

```json
{
  "name": "dhis home",
  "external": true,
  "url": "https://www.dhis2.org"
}
```

带有附加文档 ID 的 GET 请求将返回信息
关于文件。对同一端点的 PUT 请求将更新
文档的字段：

    / api / documents / <documentId>

将 */data* 附加到 GET 请求将返回实际文件内容
文件的：

    / api / documents / <documentId> / data

## CSV元数据导入 { #webapi_csv_metadata_import } 

DHIS2支持以CSV格式导入元数据，例如数据元素，组织单位和验证规则。根据列顺序/列索引来标识各种元数据对象的属性（有关详细信息，请参见下文）。您可以省略不需要的对象属性/列，但是由于列顺序很重要，因此必须包括一个空列。换句话说，如果您要指定在列顺序中排在后面的属性/列，但不指定在列顺序中排在较早的位置的某些列，则可以为它们添加空白/空白列。

CSV文件的第一行被视为标题，在导入期间将被忽略。 _comma_字符应用作文本定界符。包含逗号的文本必须放在_双引号_中。

要上传CSV格式的元数据，您可以向元数据端点发出POST请求：

    POST / api / metadata？classKey = CLASS-KEY

支持以下对象类型。 `classKey` 查询参数是强制性的，可以在下表中的每个对象类型旁边找到。

Table: Object types and keys

| Object type | Class key |
|---|---|
| 资料元素 | DATA_ELEMENT |
| 数据元素组 | DATA_ELEMENT_GROUP |
| Category options | CATEGORY_OPTION |
| Category option groups | CATEGORY_OPTION_GROUP |
| 组织单位 | ORGANISATION_UNIT |
| Organisation unit groups | ORGANISATION_UNIT_GROUP |
| 验证规则 | VALIDATION_RULE |
| 选项集 | OPTION_SET |
| 翻译 | TRANSLATION |

> **提示**
>
> 如果使用 *curl*，应该使用 `--data-binary` 选项，因为它保留了换行符和换行符，这对于 CSV 数据是必不可少的。

例如，要使用`curl`上传CSV格式的数据元素文件，可以使用以下命令：

```bash
curl --data-binary @data_elements.csv "http://localhost/api/metadata?classKey=DATA_ELEMENT"
  -H "Content-Type:application/csv" -u admin:district
```

以下各节列出了CSV导入当前支持的对象类型的格式。

### 资料元素 { #webapi_csv_data_elements } 

Table: Data Element CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || Name. Max 230 char. Unique. |
| 2 | 用户标识 | 不 | 用户标识 | Stable identifier. Exactly 11 alpha-numeric characters, beginning with a letter. Will be generated by system if not specified. |
| 3 | 码 | 不 || Stable code. Max 50 char. |
| 4 | Short name | 不 | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 char. Unique. |
| 5 | 描述 | 不 || Free text description. |
| 6 | Form name | 不 || Max 230 char. |
| 7 | Domain type | 不 | AGGREGATE &#124; TRACKER | Domain type for data element, can be aggregate or tracker. Max 16 char. |
| 8 | 值类型 | 不 | INTEGER &#124; NUMBER &#124; UNIT_INTERVAL &#124; PERCENTAGE &#124; INTEGER_POSITIVE &#124; INTEGER_NEGATIVE &#124; INTEGER_ZERO_OR_POSITIVE &#124; FILE_RESOURCE &#124; COORDINATE &#124;TEXT &#124; LONG_TEXT &#124; LETTER &#124; PHONE_NUMBER &#124; EMAIL &#124; BOOLEAN &#124; TRUE_ONLY &#124; DATE &#124; DATETIME | Value type. Max 16 char. |
| 9 | 聚集类型 | 不 | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX &#124; NONE | Aggregation type indicating how to aggregate data in various dimensions. Max 16 char. |
| 10 | Category combination | 不 | 用户标识 | UID of category combination. Will default to default category combination if not specified. |
| 11 | Url | 不 || URL to data element resource. Max 255 char. |
| 12 | Zero is significant | 不 | false &#124; true | Indicates whether zero values will be stored for this data element. |
| 13 | Option set | 不 | 用户标识 | UID of option set to use for data. |
| 14 | Comment option set | 不 | 用户标识 | UID of option set to use for comments. |

下面是数据元素的 CSV 文件示例。首先
行将始终被忽略。请注意如何跳过列并依赖
系统使用的默认值。您还可以跳过列
你不使用出现在右边的

```csv
名称，uid，代码，简称，描述
“妇女参加技能发展培训”，“ D0001”，“妇女参加培训”
“妇女参与社区组织”，“ D0002”，“妇女参与组织”
```

### 组织单位 { #webapi_csv_org_units } 

Table: Organisation Unit CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || Name. Max 230 characters. Unique. |
| 2 | 用户标识 | 不 | 用户标识 | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 3 | 码 | 不 || Stable code. Max 50 char. |
| 4 | Parent | 不 | 用户标识 | UID of parent organisation unit. |
| 5 | Short name | 不 | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 characters. Unique. |
| 6 | 描述 | 不 || Free text description. |
| 7 | Opening date | 不 | 1970-01-01 | Opening date of organisation unit in YYYY-MM-DD format. |
| 8 | Closed date | 不 || Closed date of organisation unit in YYYY-MM-DD format, skip if currently open. |
| 9 | 评论 | 不 || Free text comment for organisation unit. |
| 10 | Feature type | 不 | NONE &#124; MULTI_POLYGON &#124; POLYGON &#124; POINT &#124; SYMBOL | Geospatial feature type. |
| 11 | Coordinates | 不 || Coordinates used for geospatial analysis in Geo JSON format. |
| 12 | 网址 | 不 || URL to organisation unit resource. Max 255 char. |
| 13 | 联系人 | 不 || Contact person for organisation unit. Max 255 char. |
| 14 | 地址 | 不 || Address for organisation unit. Max 255 char. |
| 15 | 电子邮件 | 不 || Email for organisation unit. Max 150 char. |
| 16 | 电话号码 | 不 || Phone number for organisation unit. Max 150 char. |

使用父单位导入组织单位的最小示例
看起来像这样：

```csv
名称，uid，代码，父项
“西部省份”，“ WESTP”，“ ImspTQPwCqd”
“东部省”，“ EASTP”，“ ImspTQPwCqd”
```

### 验证规则 { #webapi_csv_validation_rules } 

Table: Validation Rule CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || Name. Max 230 characters. Unique. |
| 2 | 用户标识 | 不 | 用户标识 | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 3 | 码 | 不 || Stable code. Max 50 |
| 4 | 描述 | 不 || Free text description. |
| 5 | Instruction | 不 || Free text instruction. |
| 6 | Importance | 不 | MEDIUM &#124; HIGH &#124; LOW | Importance of validation rule. |
| 7 | Rule type (ignored) | 不 | VALIDATION &#124; SURVEILLANCE | Type of validation rule. |
| 8 | Operator | 不 | equal_to &#124; not_equal_to &#124; greater_than &#124; greater_than_or_equal_to &#124; less_than &#124; less_than_or_equal_to &#124; compulsory_pair &#124; exclusive_pair | Expression operator. |
| 9 | 期间类型 | 不 | Monthly &#124; Daily &#124; Weekly &#124; Quarterly &#124; SixMontly &#124; Yearly | Period type. |
| 10 | Left side expression | 是的 || Mathematical formula based on data element and option combo UIDs. |
| 11 | Left side expression description | 是的 || Free text. |
| 12 | Left side missing value strategy | 不 | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124; NEVER_SKIP | Behavior in case of missing values in left side expression. |
| 13 | Right side expression | 是的 || Mathematical formula based on data element and option combo UIDs. |
| 14 | Right side expression description | 是的 || Free text. |
| 15 | Right side missing value strategy | 不 | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124; NEVER_SKIP | Behavior in case of missing values in right side expression. |

### 选项集 { #webapi_csv_option_sets } 

Table: Option Set CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | OptionSetName | 是的 || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionSetUID | 不 | 用户标识 | Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionSetCode | 不 || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionName | 是的 || Option name. Max 230 characters. |
| 5 | OptionUID | 不 | 用户标识 | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 6 | OptionCode | 是的 || Stable code. Max 50 char. |

选项集的格式很特殊。前三个值代表
一个选项集。最后三个值代表一个选项。首先
代表选项集的三个值应该对每个值重复
选项。

```csv
optionsetname，optionsetuid，optionsetcode，optionname，optionuid，optioncode
“颜色”，“颜色”，“蓝色”，“蓝色”
“颜色”，“颜色”，“绿色”，“绿色”
“颜色”，“颜色”，“黄色”，“黄色”
“性别”，“男”，“男”
“性别”，“女性”，“女性”
“性别”，“未知”，“未知”
“结果”，“高”，“高”
“结果”，“中”，“中”
“结果”，“低”，“低”
“ Impact”，“ cJ82jd8sd32”，“ IMPACT”，“ Great”，“ GREAT”
“影响”，“ cJ82jd8sd32”，“影响”，“中等”，“中等”
“影响”，“ cJ82jd8sd32”，“影响”，“不良”，“不良”
```

### 选项组 { #option-group } 

Table: Option Group CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | OptionGroupName | 是的 || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionGroupUid | 不 || Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionGroupCode | 不 || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionGroupShortName | 是的 || Short Name. Max 50 characters. Unique. Should be repeated for each option. |
| 5 | OptionSetUid | 是的 || Stable identifier. Max 11 char. Should be repeated for each option. |
| 6 | OptionUid | 不 || Stable identifier. Max 11 char. |
| 7 | OptionCode | 不 || Stable code. Max 50 char. |

OptionGroup CSV有效负载样本

```csv
optionGroupName，optionGroupUid，optionGroupCode，optionGroupShortName，optionSetUid，optionUid，optionCode
optionGroupA，groupA，xmRubJIhmaK，OptionA
optionGroupA，groupgroup，xmRubJIhmaK，OptionB
optionGroupB 、、 groupB，QYDAByFgTr1，OptionC
```
### 选项组集 { #option-group-set } 



Table: Option Group Set CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | OptionGroupSetName | 是的 || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionGroupSetUid | 不 || Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionGroupSetCode | 不 || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionGroupSetDescription | 不 || Description. Should be repeated for each option. |
| 5 | DataDimension | 不 || TRUE, FALSE |
| 6 | OptionSetUid | 不 || OptionSet UID. Stable identifier. Max 11 char. |

OptionGroupSet CSV有效负载样本

```csv
名称，uid，代码，描述，数据维度，选项
optiongroupsetA，...，xmRubJIhmaK
optiongroupsetB 、、、、 false，QYDAByFgTr1
```
要将OptionGroups添加到导入的OptionGroupSet中，请按照导入集合成员身份的步骤进行操作

### Indicators { #webapi_csv_indicators } 

Table: Indicator CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || Name. Max 230 char. Unique. |
| 2 | 用户标识 | 不 | 用户标识 | Stable identifier. Exactly 11 alpha-numeric characters, beginning with a letter. Will be generated by system if not specified. |
| 3 | 码 | 不 || Stable code. Max 50 char. |
| 4 | Short name | 是的 | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 char. Unique. |
| 5 | denominator | 是的 || Indicator expression. |
| 6 | denominatorDescription | 不 || Max 230 char. |
| 5 | numerator | 是的 || Indicator expression. |
| 6 | numeratorDescription | 不 || Max 230 char. |
| 6 | annualized | 是的 ||  TRUE, FALSE |
| 6 | decimals | 不 || Number of decimals to use for indicator value, null implies default.
| 6 | Indicator Type | 是的 || 用户标识 | UID of Indicator Type.

An example of a CSV file for Indicators can be seen below. The first
row will always be ignored. Note how you can skip columns and rely on
default values to be used by the system. You can also skip columns which
you do not use which appear to the right of the ones

```csv
Name,UID,Code,Description,shortName,denominator,denominatorDescription,numerator,numeratorDescription,annualized,decimals,indicatorType
Indicator A,yiAKjiZVoOU,CodeA,Indicator A description,Indicator A shortname,#{fbfJHSPpUQD},denominatorDescription,#{h0xKKjijTdI},numeratorDescription,false,2,sqGRzCziswD
Indicator B,Uvn6LCg7dVU,CodeB,Indicator B description,Indicator B shortname,#{fbfJHSPpUQD},denominatorDescription,#{h0xKKjijTdI},numeratorDescription,false,2,sqGRzCziswD
```

### 收藏会员 { #collection-membership } 

除了导入对象，您还可以选择只导入对象
对象和组之间的组成员关系。目前，该
支持以下组和对象对

  - 组织单位组-组织单位

  - 数据元素组-数据元素

  - 指标组-指标

  - 选项组集-选项组

这些导入的CSV格式相同



Table: Collection membership CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 用户标识 | 是的 | 用户标识 | The UID of the collection to add an object to |
| 2 | 用户标识 | 是的 | 用户标识 | The UID of the object to add to the collection |

### Category Option Group { #category-option-group } 

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || Name. Max 230 characters. Unique. |
| 2 | 用户标识 | 不 | 用户标识 | Stable identifier. Max 11 chars. Will be generated by system if not specified. |
| 3 | 码 | 不 || Stable code. Max 50 char. |
| 4 | Short name | 不 || Short name. Max 50 characters. |
| 5 | Data Dimension Type | 是的 || Data Dimension Type, can be either DISAGGREGATION or ATTRIBUTE |

### 其他物件 { #webapi_csv_other_objects } 

Table: Data Element Group, Category Option, Organisation Unit Group CSV Format

| Index | 柱 | 需要 | Value (default first) | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || Name. Max 230 characters. Unique. |
| 2 | 用户标识 | 不 | 用户标识 | Stable identifier. Max 11 chars. Will be generated by system if not specified. |
| 3 | 码 | 不 || Stable code. Max 50 char. |
| 4 | Short name | 不 || Short name. Max 50 characters. |

类别选项的示例如下所示：

```csv
名称，uid，代码，简称
“男”，“男”
“女性”，“女性”
```

## 删除的对象 { #webapi_deleted_objects } 

删除的对象资源提供了元数据对象的日志
删除。

    / api / deletedObjects

每当删除元数据类型的对象时，都会保留日志
uid、代码、类型和删除时间。这个 API 是
在`/api/deletedObjects` 字段过滤和对象过滤中可用
与其他元数据资源类似。

获取类型为数据元素的已删除对象：

    GET /api/deletedObjects.json?klass=DataElement

获取在 2015 年删除的指标类型的已删除对象和
向前：

    GET /api/deletedObjects.json?klass=Indicator&deletedAt=2015-01-01

## 收藏夹 { #webapi_favorites } 

某些类型的元数据对象可以标记为收藏夹
当前登录的用户。这目前适用于仪表板。

    / api / dashboards / <uid> /收藏

要使仪表板成为收藏夹，您可以发出 *POST* 请求（无内容
type required) 到这样的 URL：

    / api /仪表板/ iMnYyBfSxmM /收藏

要将仪表板删除为收藏夹，您可以发出 *DELETE* 请求
使用与上面相同的 URL。

收藏夹状态将显示为布尔值 *收藏夹* 字段
元数据响应中的对象（例如仪表板）。

## 订阅内容 { #webapi_subscription } 

A logged user can subscribe to certain types of objects. Currently
subscribable objects are those of type EventChart, EventReport,
Map, Visualization and EventVisualization.

> **Note**
>
> The EventChart and EventReport objects are deprecated. Use EventVisualization instead.

要获取对象的订阅者（返回用户 ID 数组），您
可以发出 *GET* 请求：

    / api / <object-type> / <object-id> /订阅者

请参见以下示例：

    /api/visualizations/DkPKc1EUmC2/subscribers

检查当前用户是否订阅了一个对象（返回一个
boolean) 您可以执行 *GET* 调用：

    / api / <object-type> / <object-id> /已订阅

请参见以下示例：

    /api/visualizations/DkPKc1EUmC2/subscribed

要订阅/取消订阅对象，请执行 *POST/DELETE*
请求（不需要内容类型）：

    / api / <object-type> / <object-id> / subscriber

## 文件资源 { #webapi_file_resources } 

*文件资源*是用于表示和存储二进制内容的对象。
*FileResource* 对象本身包含文件元数据（名称、
内容类型、大小等）以及允许检索
来自数据库外部文件存储的内容。 *FileResource* 对象
与其他数据库一样存储在数据库中，但内容（文件）是
存储在别处并可使用包含的引用检索
*（存储密钥）*。

    / api / fileResources

文件资源的内容不能直接访问，但可以
从其他对象（如数据值）引用来存储二进制
几乎无限大小的内容。

To create a file resource that does not require a corresponding data value,
POST to the endpoint `/api/fileResources` with a multipart upload:

```bash
curl "https://server/api/fileResources" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```
文件资源的` uid `可以在创建时提供，例如：
```bash
curl "https://server/api/fileResources?uid=0123456789x" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

To create both a file resource and a data value that references the file,
POST to the `/api/dataValues/file` endpoint in DHIS 2.36 or later:

```bash
curl "https://server/api/dataValues/file?de=xPTAT98T2Jd
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

For the `api/fileResources` endpoint, the only form parameter required is
*file*, which is the file to upload. For the `api/dataValues/file`
endpoint, the parameters required are the same as for a post to
`api/dataValues`, with the addition of *file*.

The filename and content-type should also be included in the request but
will be replaced with defaults when not supplied.

成功创建文件资源后，返回的数据将包含
一个 `response` 字段，它又包含这样的 `fileResource`：

```json
{
  "httpStatus": "Accepted",
  "httpStatusCode": 202,
  "status": "OK",
  "response": {
    "responseType": "FileResource",
    "fileResource": {
      "name": "name-of-file.png",
      "created": "2015-10-16T16:34:20.654+0000",
      "lastUpdated": "2015-10-16T16:34:20.667+0000",
      "externalAccess": false,
      "publicAccess": "--------",
      "user": { ... },
      "displayName": "name-of-file.png",
      "contentType": "image/png",
      "contentLength": 512571,
      "contentMd5": "4e1fc1c3f999e5aa3228d531e4adde58",
      "storageStatus": "PENDING",
      "id": "xm4JwRwke0i"
    }
  }
}
```

注意响应是*202 Accepted*，表示返回的
资源已提交后台处理（持续到
在这种情况下是外部文件存储）。另外，请注意 `storageStatus` 字段
指示内容是否已存储。在这
点，到外部存储的持久化还没有完成（它是
可能会上传到某个地方的基于云的商店）
`PENDING` 状态。

即使内容尚未完全存储，文件资源
现在可以使用，例如作为数据值中的引用内容（参见
[使用文件数据值](#datavalue_file))。如果我们需要检查
更新的 *storageStatus* 或以其他方式检索
文件，可以查询`fileResources`端点。

```bash
curl "https://server/api/fileResources/xm4JwRwke0i" -H "Accept: application/json"
```

此请求将返回 `FileResource` 对象，如
上面例子的反应。

### 文件资源限制 { #webapi_file_resources_constraints } 

  - 文件资源*必须*从另一个对象引用（分配）
    以便长期坚持。一个文件资源是
    创建但未被其他对象（例如数据值）引用
    被认为处于*分期*。此中的任何文件资源
    状态并且超过*两个小时*将被标记为删除
    并将最终从系统中清除。

  - 文件资源初始创建返回的ID不是
    可从任何其他位置检索，除非文件资源具有
    已被引用（其中 ID 将被存储为引用），
    所以丢失它需要重复 POST 请求和一个新的
    要创建的对象。 *孤立*文件资源将被清理
    自动起来。

  - 文件资源对象是*不可变的*，意味着修改不是
    允许并需要创建一个全新的资源。

### 文件资源阻止列表 { #file-resource-blocklist } 

出于安全原因，某些类型的文件被阻止上传。

以下内容类型被阻止。

| 内容类型 | 内容类型 |
| ------------------------------------- | ---- |
| 文字/ HTML                             | 应用程序/ x-ms-dos-可执行 |
| 文字/ css                              | application / vnd.microsoft.portable-executable |
| 文字/ javascript                       | application / vnd.apple.installer + xml |
| 字体/ otf                              | application / vnd.mozilla.xul + xml |
| 应用程序/ x-shockwave-flash         | 应用程序/ x-httpd-php  |
| application / vnd.debian.binary-package | 应用程序/ x-sh |
| 应用/ x-rpm                     | 应用程序/ x-csh |
| 应用程序/ Java归档              |  |

以下文件扩展名被阻止。

| 文件扩展名 | 文件扩展名 | 文件扩展名 |
| ---- | ---- | ---- |
| html | 黛比  | ul  |
| htm  | 转数  | 的PHP  |
| 的CSS  | 罐  | 箱子  |
| js   | jsp  | SH   |
| 微信  | 可执行程序  | csh  |
| OTF  | 微星  | 蝙蝠  |
| 瑞士法郎  | 每公斤 |      |

## 元数据版本控制 { #webapi_metadata_versioning } 

This section explains the metadata versioning APIs.

  - `/api/metadata/version`：这个端点将返回当前的元数据
    调用它的系统的版本。



Table: Query Parameters

| 名称 | 需要 | 描述 |
|---|---|---|
| versionName | 假 | If this parameter is not specified, it will return the current version of the system or otherwise it will return the details of the versionName passed as parameter. (versionName is of the syntax "Version_<id\>" |

### 获取元数据版本示例 { #webapi_metadata_versioning_examples } 

**示例：**获取此系统的当前元数据版本

请求：

```
/ api /元数据/版本
```

响应：

```json
{
  "name": "Version_4",
  "created": "2016-06-30T06:01:28.684+0000",
  "lastUpdated": "2016-06-30T06:01:28.685+0000",
  "externalAccess": false,
  "displayName": "Version_4",
  "type": "BEST_EFFORT",
  "hashCode": "848bf6edbaf4faeb7d1a1169445357b0",
  "id": "Ayz2AEMB6ry"
}
```

**示例：**获取名称为“ Version_2”的版本的详细信息

请求：

```
/ api / metadata / version？versionName = Version_2
```

响应：

```json
{
  "name": "Version_2",
  "created": "2016-06-30T05:59:33.238+0000",
  "lastUpdated": "2016-06-30T05:59:33.239+0000",
  "externalAccess": false,
  "displayName": "Version_2",
  "type": "BEST_EFFORT",
  "hashCode": "8050fb1a604e29d5566675c86d02d10b",
  "id": "SaNyhusVxBG"
}
```

  - `/api/metadata/version/history`：这个端点将返回所有
    调用它的系统的元数据版本。



Table: Query Parameters

| 名称 | 需要 | 描述 |
|---|---|---|
| baseline | 假 | If this parameter is not specified, it will return list of all metadata versions. Otherwise we need to pass a versionName parameter of the form "Version_<id\>". It will then return the list of versions present in the system which were created after the version name supplied as the query parameter. |

### 获取所有元数据版本的列表 { #webapi_get_list_of_metadata_versions } 

**示例：**获取此系统中所有版本的列表

请求：

```
/ api /元数据/版本/历史记录
```

响应：

```json
{
  "metadataversions": [{
    "name": "Version_1",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:54:41.139+0000",
    "id": "SjnhUp6r4hG",
    "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798"
  }, {
    "name": "Version_2",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:59:33.238+0000",
    "id": "SaNyhusVxBG",
    "hashCode": "8050fb1a604e29d5566675c86d02d10b"
  }, {
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }]
}
```

**示例：**获取此系统在“ Version_2”之后创建的所有版本的列表

请求：

```
/ api / metadata / version / history？baseline = Version_2
```

响应：

```json
{
  "metadataversions": [{
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }, {
    "name": "Version_4",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:28.684+0000",
    "id": "Ayz2AEMB6ry",
    "hashCode": "848bf6edbaf4faeb7d1a1169445357b0"
  }]
 }
```

  - `/api/metadata/version/create`：这个端点将创建元数据
    version 参数中指定的版本类型。



Table: Query Parameters

| 名称 | 需要 | 描述 |
|---|---|---|
| type | 真正 | The type of metadata version which needs to be created.<br>  * BEST_EFFORT<br> * ATOMIC |

用户可以选择需要创建的元数据类型。
元数据版本类型决定了进口商应该如何对待给定的
版本。导入元数据时将使用此类型。有
两种类型的元数据。

  - *BEST_EFFORT*：这种类型表明丢失的引用可以
    忽略，导入器可以继续导入元数据（例如
    数据元素组导入中缺少数据元素）。

  - *ATOMIC*：这种类型确保对元数据进行严格的类型检查
    如果有任何引用，则引用和元数据导入将失败
    不存在。

> **注意**
>
> 建议有一个 ATOMIC 类型的版本，以确保所有
> 系统（中央和本地）具有相同的元数据。任何遗漏
> 引用在验证阶段本身被捕获。请参阅
> 进口商详细信息的完整解释。

### 创建元数据版本 { #webapi_create_metadata_version } 

**示例：** 创建类型为 `BEST_EFFORT` 的元数据版本

请求：

```bash
curl -X POST -u admin:district "https://play.dhis2.org/dev/api/metadata/version/create?type=BEST_EFFORT"
```

响应：

```json
{
  "name": "Version_1",
  "created": "2016-06-30T05:54:41.139+0000",
  "lastUpdated": "2016-06-30T05:54:41.333+0000",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407+0000",
    "lastUpdated": "2016-04-06T00:06:06.571+0000",
    "externalAccess": false,
    "displayName": "John Traore",
    "id": "xE7jOejl9FI"
  },
  "displayName": "Version_1",
  "type": "BEST_EFFORT",
  "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798",
  "id": "SjnhUp6r4hG"
}
```

  - `/api/metadata/version/{versionName}/data`：这个端点将下载
    特定于作为路径传递的版本名称的实际元数据
    范围。

  - `/api/metadata/version/{versionName}/data.gz`：这个端点将下载
    特定于作为路径传递的版本名称的实际元数据
    压缩格式（gzipped）的参数。



Table: Path parameters

| 名称 | 需要 | 描述 |
|---|---|---|
| versionName | 真正 | Path parameter of the form "Version_<id\>" so that the API downloads the specific version |

### 下载版本元数据 { #webapi_download_version_metadata } 

**示例：**获取“版本5”的实际元数据

请求：

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/version/Version_5/data"
```

响应：

```json
{
  "date": "2016-06-30T06:10:23.120+0000",
  "dataElements": [
    {
      "code": "ANC 5th Visit",
      "created": "2016-06-30T06:10:09.870+0000",
      "lastUpdated": "2016-06-30T06:10:09.870+0000",
      "name": "ANC 5th Visit",
      "id": "sCuZKDsix7Y",
      "shortName": "ANC 5th Visit ",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "zeroIsSignificant": false,
      "valueType": "NUMBER",
      "categoryCombo": {
        "id": "p0KPaWEg3cf"
      },
      "user": {
        "id": "xE7jOejl9FI"
      }
    }
  ]
}
```

## Metadata synchronization { #webapi_metadata_synchronization } 

本节介绍了可用的元数据同步 API
2.24 开始

  - `/api/metadata/sync`：此端点执行元数据同步
    通过下载和在查询参数中传递的版本名称
    从远程服务器导入指定的版本，如定义
    设置应用程序。



Table: Query parameters

| 名称 | 需要 | 描述 |
|---|---|---|
| versionName | 真正 | versionName query parameter of the form "Version_<id\>" . The api downloads this version from the remote server and imports it in the local system. |

  - 使用此 API 时应格外小心。请注意，有
    以完全自动化的方式实现同步的另一种方法
    利用“数据管理”中的元数据同步任务
    应用程序。详见用户手册第 22 章 22.17 节
    关于元数据同步任务。

  - 此同步 API 也可用于同步元数据
    从元数据同步调度程序失败的版本。由于
    它依赖于给定的元数据版本号，应该注意
    为调用 this 的顺序而采用。例如。如果这个api是
    用于从中央实例同步一些更高版本，然后
    同步可能会失败，因为元数据依赖项不存在于
    本地实例。

  - 假设本地实例在 `Version_12` 并且如果使用这个端点
    从中央同步`Version_15`（类型`BEST_EFFORT`）
    例如，调度程序将从以下位置开始同步元数据
    `版本_16`。所以本地实例不会有元数据
    `Version_12` 和 `Version_15` 之间的版本。你需要手动
    仅使用这些端点同步丢失的版本。

### 同步元数据版本 { #webapi_metadata_synchronization_version } 

**示例：**将Version_6从中央系统同步到该系统

请求：

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/sync?versionName=Version_6"
```

## 元数据存储库 { #webapi_metadata_repository } 

DHIS2 提供了一个包含元数据包的元数据存储库
各种内容。元数据包是符合 DHIS2 的 JSON 文档
它描述了一组元数据对象。

要检索可用元数据包的索引，您可以发出
对 *metadataRepo* 资源的 GET 请求：

    GET /api/synchronization/metadataRepo

元数据包条目包含有关包的信息和
相关包的 URL。索引可能如下所示：

```json
{
  "packages": [
    {
      "id": "sierre-leone-demo",
      "name": "Sierra Leone demo",
      "description": "Sierra Leone demo database",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/sierra-leone-demo/metadata.json"
    },
    {
      "id": "trainingland-org-units",
      "name": "Trainingland organisation units",
      "description": "Trainingland organisation units with four levels",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
    }
  ]
}
```

客户端可以通过 URL 安装元数据包
带有元数据包的内容类型 *text/plain* 的 POST 请求
URL 作为 *metadataPull* 资源的有效负载：

    POST / api / synchronization / metadataPull

curl命令示例如下所示：

```bash
curl "localhost:8080/api/synchronization/metadataPull" -X POST
  -d "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
  -H "Content-Type:text/plain" -u admin:district
```


> **Note**
>
> The supplied URL will be checked against the config property `system.remote_servers_allowed` in the `dhis.conf` file.
> If the base URL is not one of the configured servers allowed then the operation will not be allowed. See failure example below.  
> Some examples where the config set is `system.remote_servers_allowed=https://server1.org/,https://server2.org/`
> - supply `https://server1.org/path/to/resource` -> this will be accepted
> - supply `https://server2.org/resource/path` -> this will be accepted
> - supply `https://oldserver.org/resource/path` -> this will be rejected
>
Sample failure response

```json
 {
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Provided URL is not in the remote servers allowed list",
  "errorCode": "E1004"
}
```


## Reference to created by user { #reference-to-created-by-user } 

Each object created in DHIS2 will have a property named `user` which is linked to `User` who created the object.

From version 2.36 we have changed the name of this property to `createdBy` to avoid confusion.

However, in order to keep the backwards compability, the legacy `user` property is still included in the payload and works normally as before.

```json
{
  "createdBy": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  },
  "user": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  }
}
```

## Metadata proposal workflow { #webapi_metadata_proposal_workflow }

The metadata proposal workflow endpoint allows for a workflow of proposing and accepting changes to metadata.

```
/api/metadata/proposals
```

### Propose a metadata change { #webapi_metadata_proposal_propose }

A proposal always targets a single metadata object using:

    POST /api/metadata/proposals

Depending on the payload the proposal could:

* Add a new metadata object.
* Update an existing metadata object references by ID.
* Remove an existing metadata object referenced by ID.

To propose adding a new metadata object send a JSON payload like the following:

```json
{
  "type": "ADD",
  "target": "ORGANISATION_UNIT",
  "change": {"name":"My Unit", "shortName":"MyOU", "openingDate": "2020-01-01"}
}
```
The `change` property contains the same JSON object that could directly be posted to the corresponding endpoint to create the object.

To propose updating an existing metadata object send a JSON payload like in the below example:

```json
{
  "type": "UPDATE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>",
  "change": [
    {"op": "replace", "path": "/name", "value": "New name"}
  ]
}
```
The `targetId` refers to the object by its ID which should be updated. The `change` property here contains a JSON patch payload. This is the same
patch payload that could be posted to the corresponding endpoint to directly apply the update.

To propose the removal of an existing object send a payload like in the last example:

```json
{
  "type": "REMOVE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>"
}
```
The `targetId` refers to the object  by its ID which should be removed. A free text `comment` can be added to any type of comment.

Only `target` type `ORGANISATION_UNIT` is supported currently.

### Accept a metadata change proposal { #webapi_metadata_proposal_accept }
要接受一个开放的提案，请在提案资源上使用`POST`

    POST /api/metadata/proposals/<uid>

成功后，提案的状态变为`接受`状态。一旦被接受，提案就不能再被拒绝。

Should a proposal fail to apply it changes to status `NEEDS_UPDATE`. The `reason` field contains a summary of the failures when this information is 
available.

### Oppose a metadata change proposal { #webapi_metadata_proposal_oppose }
如果提案不太正确并且需要调整，可以通过发送提案资源的`PATCH`来反对提案

    PATCH /api/metadata/proposals/<uid>

可选地，可以在其中添加纯文本正文，以给出提案遭到反对的`原因`。

反对的提案必须处于`PROPOSED`状态，并将更改为`NEEDS_UPDATE`状态。

### Adjust a metadata change proposal { #webapi_metadata_proposal_adjust }
A proposal in state `NEEDS_UPDATE` needs to be adjusted before it can be accepted. To adjust the proposal a `PUT` request is made for the proposal's 
resource

    PUT /api/metadata/proposals/<uid>

Such an adjustment can either be made without a body or with a JSON body containing an object with the updated `change` and `targetId` for the 
adjustment:

```json
{
  "targetId": "<id>",
  "change": ...
}
```
The JSON type of the `change` value depends on the proposal `type` analogous to when a proposal is initially made.

### Reject a metadata change proposal { #webapi_metadata_proposal_reject }
要拒绝打开的提案，请在提案资源上使用`DELETE`

    DELETE /api/metadata/proposals/<uid>

这最终将提案的状态更改为`拒绝`。不能对此提案进行进一步的更改。它作为事件的文档保存。

### List metadata change proposals { #webapi_metadata_proposal_list }
All proposals can be listed:

    GET /api/metadata/proposals/

The result list can be filtered using the `filter` parameter.
For example, to list only accepted proposals use:

    GET /api/metadata/proposals?filter=status:eq:ACCEPTED

Similarly to only show open proposals use:

    GET /api/metadata/proposals?filter=status:eq:PROPOSED

Filters can also be applied to any field except `change`. Supported filter operators are those described in the Gist Metadata API. This also includes property transformers described for Gist API.

List of available fields are:

| 领域       | 描述 |
| ----------- | -------------------------------------------------------------- |
| id          | unique identifier of the proposal |
| type        | `ADD` a new object, `UPDATE` an existing object, `REMOVE` an existing object |
| status      | `PROPOSED` (open proposal), `ACCEPTED` (successful), `NEEDS_UPDATE` (accepting caused error or opposed), `REJECTED` |
| target      | type of metadata object to add/update/remove; currently only `ORGANISATION_UNIT` |
| targetId    | 更新或删除对象的 UID，未为`添加`定义 |
| createdBy   | the user that created the proposal |
| created     | the date time when the proposal was created |
| finalisedBy | the user that accepted or rejected the proposal |
| finalised   | the date time when the proposal changed to a conclusive state of either accepted or rejected |
| comment     | optional plain text comment given for the initial proposal |
| reason      | optional plain text given when the proposal was opposed or the errors occurring when accepting a proposal failed | 
| change      | JSON object for `ADD` proposal, JSON array for `UPDATE` proposal, nothing for `REMOVE` proposal |

### Viewing metadata change proposals { #webapi_metadata_proposal_show }
Individual change proposals can be viewed using 

    GET /api/metadata/proposals/<uid>

The `fields` parameter can be used to narrow the fields included for the shown object. For example:

    GET /api/metadata/proposals/<uid>?fields=id,type,status,change

## Metadata Attribute Value Type and validations { #metadata-attribute-value-type-and-validations } 
| 类型 | Validation
|---| --- |
| TEXT | 没有
| LONG_TEXT | 没有
| LETTER | Value length = 1 AND is a letter
| PHONE_NUMBER  | Validation is based on this regex `^[0-9+\\(\\)#\\.\\s\\/ext-]{6,50}$`. Max length is 50.  <br /> Examples: +4733987937, (+47) 3398 7937, (47) 3398 7937.123
| EMAIL | General email format abc@email.com
| BOOLEAN | `true` or `false`
| TRUE_ONLY | Only accept `true`
| DATE | Use format `yyyy-MM-dd`
| DATETIME | Use format `yyyy-MM-dd HH:mm:ssZ` or `yyyy-MM-dd'T'HH:mm:ss`
| TIME | Use fornat `HH:mm`
| NUMBER | Value must be numberic with max length = 250
| UNIT_INTERVAL | Value is numeric and inclusive between 0 and 1
| PERCENTAGE | Value is a number in the inclusive range of 0 to 100
| INTEGER | Value is an integer
| INTEGER_POSITIVE | Value is a positive integer
| INTEGER_NEGATIVE | Value is a negative integer
| INTEGER_ZERO_OR_POSITIVE | Value is an positive or zero integer
| TRACKER_ASSOCIATE | 没有
| USERNAME | Value is a username of an existing `User`
| COORDINATE | 没有
| ORGANISATION_UNIT | Value is a valid UID of an existing `OrganisationUnit`
| REFERENCE | 没有
| AGE | Value is date of birth. Use format as in DATE type.
| 网址 | Value is a valid URL
| FILE_RESOURCE | Value is a valid UID of existing `FileResource`
| IMAGE | Value is a valid UID of existing `FileResource`
| GEOJSON |Follow [GeoJson Specification](https://geojson.org)
| MULTI_TEXT | 没有

## Copy Program { #copy-program } 

### 介绍 { #introduction } 

A user will often want to create many `Program`s which share many of the same characteristics, and instead of having to create a new `Program` from scratch, it is efficient and beneficial to copy an existing `Program` and make modifications to it.  
A template `Program` could theoretically be setup as a base to copy from, which may help with the consistency of `Program` setups also.

### API info { #api-info } 

#### Endpoint  { #endpoint } 

    POST /api/programs/{uid}/copy

Example with a `Program` with a `UID` of `Program123a`

    POST /api/programs/Program123a/copy

Successful response will include the new `Program` `UID` and will look like this:

```json
{
    "httpStatus": "Created",
    "httpStatusCode": 201,
    "status": "OK",
    "message": "Program created: 'Program456b'"
}
```

The response will also contain a `Location` header with a link to the newly-created `Program`. e.g. when run locally the `Location` value would be `http://localhost:9090/api/programs/Program456b`

#### Copy options { #copy-options } 

The API does allow the optional supplying of a custom prefix, which will be prefixed to the following properties.

| 目的           | Property  | Info                                     |
|------------------|-----------|------------------------------------------|
| 程序          | 名称      | Help identify the new Program            |
| ProgramIndicator | 名称      | Database constraint - needs to be unique |
| ProgramIndicator | shortName | Database constraint - needs to be unique |

In this example when a custom prefix is supplied, an original `Program` with a name of `My Simple Program` would be copied to a new `Program` with the name `my prefix My Simple Program` 

If no copy options are sent in the API call then the default `Copy of ` prefix will be used for the above properties.  
To send a custom prefix just add a HTTP request param `prefix` like so:  

     POST /api/programs/{uid}/copy?prefix=my prefix 

> **Note**
>
> The database does have limits for the number of characters allowed for properties. At the time of writing these limits are noted in the table below. Bear these in mind.

| Property  | character limit |
|-----------|-----------------|
| 名称      | 230             |
| shortName | 50              |

If a property has exceeded its character limit, then an error will be returned like so:

```json
{
    "httpStatus": "Conflict",
    "httpStatusCode": 409,
    "status": "ERROR",
    "message": "ERROR: value too long for type character varying(230)",
    "errorCode": "E1004"
}
```

If trying to copy a Program that is not found, a response like this will be returned:
```json
{
    "httpStatus": "Not Found",
    "httpStatusCode": 404,
    "status": "ERROR",
    "message": "Program with id {uid} could not be found.",
    "errorCode": "E1005"
}
```

### Authorisation { #authorisation } 

#### Authorities { #authorities } 

A `User` will need the following authorities to be able to copy a `Program`:

- F_PROGRAM_PUBLIC_ADD
- F_PROGRAM_INDICATOR_PUBLIC_ADD

#### 访问 { #access } 

A `Program` needs one of the following states for it to be able to be copied:

- Public `read` & `write` access
- A specific `User` to have sharing `read` & `write` access
- A `User` is part of a `UserGroup` that has sharing `read` & `write` access

If a `User` does not have the correct permissions, a `Forbidden` response is returned like so:

```json
{
    "httpStatus": "Forbidden",
    "httpStatusCode": 403,
    "status": "ERROR",
    "message": "You don't have write permissions for Program Program123a",
    "errorCode": "E1006"
}
```

### Points to note { #points-to-note } 

#### Deep and shallow copy { #deep-and-shallow-copy } 

When a `Program` is copied, certain properties of the `Program` need different kinds of copying. It is important to be aware of what has been deep-copied and what has been shallow-copied.  
First of all let's explain the difference between deep and shallow copying in this context.  

##### Deep copy { #deep-copy } 

A deep copy in this context means that a completely new instance of a `Program` or `Program` property has been created with its own unique identifiers. These include amongst others:

- id
- uid  

Deep copies of `Program` properties will all belong to the newly-created `Program` copy.

##### Shallow copy { #shallow-copy } 

A shallow copy in this context means that an existing `Program` property will be reused by the newly-created `Program` or `Program` property.

#### Properties that get deep copied { #properties-that-get-deep-copied } 

All properties below have been deep copied. Anything not in included in this table means that it has been shallow copied.

| 目的                         | Property of  |
|--------------------------------|--------------|
| 程序                        |              |
| ProgramSection                 | 程序      |
| ProgramIndicator               | 程序      |
| ProgramRuleVariable            | 程序      |
| 程序阶段                   | 程序      |
| ProgramStageSection            | 程序阶段 |
| ProgramStageSectionDataElement | 程序阶段 |
| 注册                     |              |

> **Note**
>
> The following properties have been set as empty as an initial approach. This approach should keep things simple to start off with.  

| 目的                        | Property          |
|-------------------------------|-------------------|
| ProgramIndicator              | groups            |
| ProgramStageSection           | programIndicators |
| 注册                    | events            |


# Metadata Gist API { #gist_api } 
<!--DHIS2-SECTION-ID:gist_api-->

The Metadata Gist API is a RESTful read-only JSON API to fetch and browse 
metadata. Items in this API contain the gist of the same item in the Metadata API.

The API is specifically designed to avoid:

* Large response payloads because of the inclusion of partial nested object 
  graphs.
* Resource intensive in memory processing of requests 
  (e.g. in memory filtering or object graph traversal).
* _n + 1_ database queries as a result of object graph traversal while rendering
  the response.

## Comparison with Metadata API { #gist_vs_metadata_api } 
<!--DHIS2-SECTION-ID:gist_vs_metadata_api-->

The standard Metadata API is a flexible and powerful API built to serve any and 
every use case.
The downside of this is that not all features and combinations can scale while 
keeping good performance in the presence of huge numbers of items.
In particular lists with items where each item itself has a property which is a 
large collection of complex objects have proven problematic as they quickly
reference a large part of the entire object graph.

The `/gist` API was added to provide a metadata API where scaling well is our 
first priority. The downside of this is that there are more distinct limits to
what features are technically reasonable, which means not all features of the 
standard Metadata API exist for the Gist API.

The Gist API uses a divide and conquer strategy to avoid responses with large
partial object graphs. Instead of including nested objects or lists it provides
a `/gist` endpoint URI where this object or list can be viewed in isolation.

**The `/gist` API refers to nested data using URIs rather than including it.**
This means if a client is interested in this nested information more requests
are required but each of them is kept reasonable small and will scale
well in context of huge number of potential items.

Known Differences:

* items only includes fields of referenced identifiable objects if these do not
  have an endpoint on their own
* it never includes identifiable collections of objects directly
* items by default do not include all available fields, but a subset that depends 
  on context and parameters
* lists cannot be used without pager (therefore there is no `pager` parameter)
* fields with collections are not paged using the `pager`-transformer but through
  a paged API endpoint for the particular collection property
* items in a list, a collection property size or boolean transformer result 
  always considers object sharing (the set of considered items is always the set
  visible to the user)
* Gist offers `member(<id>)` and `not-member(<id>)` collection field transformers
* Gist offers `canRead` and `canWrite` access check filter instead of filtering
  on the `access` property
* Gist offers using attribute UIDs as field and filter property names to allow
  listing or filtering based on custom attribute values
* Gist offers filter grouping
* Gist offers renaming the enrty list in a paged response using `pageListName`
* Gist offers to pluck multiple simple properties

Known Limitations:

* by default only persisted are included; a handful of special 
  non-persistent fields (synthetic fields) can be added explicitly; other 
  non-persistent fields might be possible to extract using `from` transformation
* filters can only be applied to persisted fields
* orders can only be applied to persisted fields
* token filters are not available
* order is always case-sensitive
* `pluck` transformer limited to text properties (or simple properties for multi-pluck)
* fields which hold collections of simple (non-identifiable) items cannot always
  be included depending on how they are stored

Where possible to use the `/gist` API should be considered the preferable way
of fetching metadata information.


## Endpoints { #gist_endpoints } 
<!--DHIS2-SECTION-ID:gist_endpoints-->

The `/gist` API has 3 kinds of endpoints:

* <code>/api/&lt;object-type><b>/gist</b></code>: paged list of all known and visible objects of the type (implicit `auto=S`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;<b>/gist</b></code>: view single object by ID (implicit `auto=L`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;/&lt;field-name&gt;<b>/gist</b></code>: paged list of all known and visible items in the collection of owner object's field (implicit `auto=M`; in case this is a simple field just the field value)

These endpoints correspond to the endpoints of the standard metadata API without 
the `/gist` suffix and share the majority of parameters and their options with 
that API.


## Browsing Data { #gist_browse } 
<!--DHIS2-SECTION-ID:gist_browse-->

Since `/gist` API avoids deeply nested data structures in the response the
details of referenced complex objects or list of objects is instead provided
in form of a URI to the gist endpoint that only returns the complex object or
list of objects. These URIs are provided by the `apiEndpoints` field of an item
which is automatically added to an item when such references exist.
The item property itself might contain a transformation result on the object
or collection such as its size, emptiness, non-emptiness, id(s) or plucked 
property such as its name.

To manually browse data it can be handy to use the `absoluteUrls=true` parameter.
Linkage between parts of the gist can now be followed directly in browsers that
render JSON responses.


## Parameters { #gist_parameters } 
<!--DHIS2-SECTION-ID:gist_parameters-->

All endpoints of the `/gist` API accept the same set of parameters.
Parameters and their options that do not make sense in the endpoint context are 
ignored.


### 总览 { #overview } 
Parameters in alphabetical order:

| Parameter      | 选项               | 默认                            | 描述          |
| -------------- | --------------------- |------------------------------------| ---------------------|
| `absoluteUrls` | `true` or `false`     | `false`                            | `true` use relative paths in links, `false` use absolute URLs in links |
| `auto`         | `XS`, `S`, `M`, `L`, `XL` | (context dependent)                | extent of fields selected by `*` field selector |
| `fields`       | (depends on endpoint) | `*`                                | comma separated list of fields or presets to include |
| `filter`       | `<field>:<operator>` or `<field>:<operator>:<value>` |                                    | comma separated list of query field filters (can be used more than once) |
| `headless`     | `true` or `false`     | `false`                            | `true` skip wrapping result in a pager (ignores `total`), `false` use a pager wrapper object around the result list |
| `inverse`      | `true` or `false`     | `false`                            | `true` return items **not** in the list, `false` return items in the list |
| `locale`       |                       | (user account configured language) | translation language override |
| `order`        | `<field>` or  `<field>:asc` or `<field>:desc` | `:asc`                             | comma separated list of query order fields (can be used more than once) |
| `page`         | 1-n                   | 1                                  | page number |
| `pageSize`     | 1-1000                | 50                                 | number of items on a page |
| `pageListName` | `<text>` | (object type plural) | overrides the property name of the result entry list | 
| `rootJunction` | `与`或`或`         | `AND`                              | logical combination of `filter`s, `AND`= all must match, `OR`= at least one must match |
| `total`/`totalPages`        | `true` or `false`     | `false`                            | `true` add total number of matches to the pager, `false` skip counting total number of matches |
| `translate`    | `true` or `false`     | `true`                             | `true` translate all translatable properties, `false` skip translation of translatable properties (no effect on synthetic display names) |



### The `absoluteUrls` Parameter { #gist_parameters_absoluteUrls } 
<!--DHIS2-SECTION-ID:gist_parameters_absoluteUrls-->

By default, URIs in `apiEndpoints`, `href` and the `pager` `prev` and `next` 
members are relative, starting with `/<object-type>/` path.

可以使用 `absoluteUrls` 参数将 URI 更改为绝对 URL。

For example, `/api/users/rWLrZL8rP3K/gist?fields=id,href` returns:

```json
{
  "id": "rWLrZL8rP3K",
  "href": "/users/rWLrZL8rP3K/gist"
}
```

whereas `/api/users/rWLrZL8rP3K/gist?fields=id,href&absoluteUrls=true` 
returns:

```json
{
  "id": "rWLrZL8rP3K",
  "href": "http://localhost:8080/api/users/rWLrZL8rP3K/gist?absoluteUrls=true"
}
```

As the example shows the `absoluteUrls` parameter is also forwarded or carried
over to the included URLs so allowing to browse the responses by following the 
provided URLs.


### The `auto` Parameter { #the-auto-parameter } 
Each endpoint implicitly sets a default for the extent of fields matched by the
`*` / `:all` fields selector:

* `/api/<object-type>/gist`: implies `auto=S`
* `/api/<object-type>/<object-id>/gist`: implies `auto=L`
* `/api/<object-type>/<object-id>/<field-name>/gist`: implies `auto=M`

The `auto` parameter is used to manually override the default to make list items
include more or less fields. This setting again acts as a default which can be
further overridden on a per field basis using an explicit transformation.

Possible options for `auto` are ("t-shirt sizes"):

* `XS`: includes only IDs and textual properties
* `S`: excludes complex (object) properties, collection are only linked (not counted)
* `M`: complex included as reference URL, references and collections as count and reference URL
* `L`: like `M` but references and collections included as IDs (OBS! unbound in size)
* `XL`: like `L` but references and collections included as ID objects: `{ "id": <id> }`

For example, `/api/users/gist` would list items with fields `id`, `surname`, 
`firstName`, `phoneNumber`, `email`, `lastUpdated` whereas 
`/api/users/gist?auto=XS` only lists `id`, `surname`,
`firstName`, `phoneNumber`, `email`. Using `/api/users/gist?auto=L` would also
include `organisationUnits`, `dataViewOrganisationUnits`, 
`teiSearchOrganisationUnits` and `userGroups` each with the list of IDs of the
members in the lists/sets.


### The `fields` Parameter { #gist_parameters_fields } 
<!--DHIS2-SECTION-ID:gist_parameters_fields-->

Specifies the list of fields to include for each list item.

Fields are included in the result JSON objects for an item in the provided order.
A preset in the list of fields is expanded to the fields it contains at the 
position in the `fields` list it appears.
Fields within the preset are ordered from simple to complex.

If no `fields` parameter is provided `fields=*` is assumed.
Note that the fields of the `*` preset also depend on the `auto` parameter

To remove a field use either `!<name>` or `-<name>` in the list of fields.
For example to remove the userGroups from a user, use:

    /api/users/gist?fields=*,!userGroups

The same principle can also be used to specify the transformer to use for a 
field. For example, to include the IDs of the user's user groups use:

    /api/users/gist?fields=*,userGroups::ids

The `fields` parameter does allow listing fields of nested objects. 
For example to add `userCredentials` with `id` and `name` of a user use:

    /api/users/gist?fields=*,userCredentials[id,username]

This creates items of the form:

```json
{
  ...
  "userCredentials": {
    "id": "Z9oOHPi3FHB",
    "username": "guest"
  }
}
```

When including nested fields of collections the nested field must be a text
property. 

例如，通过以下方式包含用户的`userGroups`的所有`名称`：

    /api/users/gist?fields=*,userGroups[name]

This lists the `userGroups` as:

```json
{
  "userGroups": {
    "name": [
      "_PROGRAM_Inpatient program",
      "_PROGRAM_TB program",
      "_DATASET_Superuser",
      "_PROGRAM_Superuser",
      "_DATASET_Data entry clerk",
      "_DATASET_M and E Officer"
    ]
  }
}
```
The above is functional identical to:

    /api/users/gist?fields=*,userGroups::pluck(name)~rename(userGroups.name)

When requesting a single field, like `/api/users/gist?fields=surname` the
response is a (still paged) list of simple values:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50
  },
  "users": [
    "Kamara",
    "Wakiki",
    "Nana",
    "Malai",
    ...
  ]
}
```

When requesting a single field of a specific owner object which has a simple
(non collection) value, like for example 
`/api/users/rWLrZL8rP3K/gist?fields=surname` the response only include the plain
JSON value:

```json
"Wakiki"
```

Further details on field presets can be found in section [Fields](#gist_fields).

### The `filter` Parameter { #gist_parameters_filter } 
<!--DHIS2-SECTION-ID:gist_parameters_filter-->

要过滤返回的项目列表，请添加一个或多个`过滤器`参数。

Multiple filters can either be specified as comma-separated list of a single 
`filter` parameter or as multiple `filter` parameters each with a single filter.

There are two types of filters:

* unary: `<field>:<operator>`
* binary: `<field>:<operator>:<value>`

A field can be: 

* a persisted field of the listed item type 
* a persisted field of a directly referenced object (1:1 relation)
* a UID of an attribute

Available unary operators are:

| Unary Operator | 描述                                                 |
| -------- | ----------------------------------------------------------------- |
| `null`   | field is _null_ (undefined)                                       |
| `!null`  | field is _not null_ (defined)                                     |
| `empty`  | field is a _empty_ collection or string                           |
| `!empty` | field is a _non-empty_ collection or string                       |

Available binary operators are:

| Binary Operator   | 描述                                              |
| ----------------- | -------------------------------------------------------- |
| `eq`              | field _equals_ value                                     |
| `ieq`             | field _equals_ value (case insensitive)                  |
| `!eq`, `neq`, `ne`| field is _not equal_ value                               |
| `lt`              | 字段_小于_值                               |
| `le`, `lte`       | field is _less than or equal to_ value                   |
| `gt`              | field is _greater than_ value                            |
| `ge`, `gte`       | field is _greater than or equal to_ value                |
| `in`              | field is a collection and value is an item _contained in_ the collection |
| `!in`             | field is a collection and value is an item _not contained in_ the collection |

If the `<value>` of an `in` or `!in` filter is a list it is given in the form
`[value1,value2,...]`, for example: `userGroups:in:[fbfJHSPpUQD,cYeuwXTCPkU]`.

Any `>`, `>=`, `<` `<=`, `==` or `!=` comparison applied to a collection field 
with a numeric value will compare the size of the collection to the value, for
example: `userGroups:gt:0`.

Any `>`, `>=`, `<` `<=`, `==` or `!=` comparison applied to a text field 
with a integer number value will compare the text length to the value, for 
example: `name:eq:4` (name has length 4).


Available binary pattern matching operators are:

| Binary Operator                   | 描述                              |
| --------------------------------- | ---------------------------------------- |
| `like`, `ilike`                   | field _contains_ `<value>` or field _matches_ pattern `<value>` (when wildcards `*` or `?` in value) |
| `!like`, `!ilike`                 | field does _not contain_ `<value>` or field does _not match_ pattern `<value>` (when wildcards `*` or `?` in value) |
| `$like`, `$ilike`, `startsWith`   | field _starts with_ `<value>`            |
| `!$like`, `!$ilike`, `!startsWith`| field does _not start with_ `<value>`    |
| `like$`, `ilike$`, `endsWith`     | field _ends with_ `<value>`              |
| `!like$`, `!ilike$`, `!endsWith`  | field does _not end with_ `<value>`      |

The `like` and `!like` operators can be used by either providing a search term
in which case a match is any value where the term occurs anywhere, or they can
be used by providing the search pattern using `*` as _any number of characters_
and `?` as _any single character_.

All pattern matching operators named `like` are case-sensitive. All others 
are case-insensitive. 

Note that filters on attribute values use text based comparison which means 
all text filters are supported.

For example, to only list organisations on second level use

    /api/organisationUnits/gist?filter=level:eq:2

Similarly, when listing the `children` of a particular organisation unit the
collection can be filtered. To only list those children that are connected to
a program one would use:

    /api/organisationUnits/rZxk3S0qN63/children/gist?filter=programs:gt:0

Binary operators for access (sharing) based filtering:

| Binary Operator   | 描述                                              |
| ----------------- | -------------------------------------------------------- |
| `canRead`         | Has user `<value>` metadata read permission to the object |
| `canWrite`        | Has user `<value>` metadata write permission to the object |
| `canDataRead`     | Has user `<value>` data read permission to the object    |
| `canDataWrite`    | Has user `<value>` data write permission to the object   |
| `canAccess`       | Has user `<value0>` permission `<value1>` to the object  |

When the user ID `<value>` is omitted the check is performed for the currently
logged-in user. Similarly, if `<value0>` is ommitted for `canAccess` filter
the check is performed for the currently logged-in user.

When applied to a simple value property, here `code`, the filter restricts the response to
those data elements (owner object) the user can read/write:

    /api/dataElements/gist?filter=code:canWrite:OYLGMiazHtW

When applied to a reference property, here `categoryCombo`, the filter restricts the response 
to those data elements having a category combo that the user can read/write:

    /api/dataElements/gist?filter=categoryCombo:canWrite:OYLGMiazHtW

When applied to a reference collection property, here `dataElementGroups`, the
filter restricts the response to those data elements where a data element group exists in the
collection property and which the user can read/write:

    /api/dataElements/gist?filter=dataElementGroups:canWrite:OYLGMiazHtW

The `canAccess` expects two arguments, 1st is user ID, 2nd the access pattern,
for example to check metadata read and write access the pattern is `rw%`:

    /api/dataElements/gist?filter=code:canAccess:[OYLGMiazHtW,rw%]


In addition, filter can be grouped to allow combining selected filters with 
logical OR when the general filter combinator is logical AND, or vice-versa 
with logical AND when the general combinator is logical OR.

For groups the filter pattern is extended as following:

* unary: `<group>:<field>:<operator>`
* binary: `<group>:<field>:<operator>:<value>`

The group is an arbitrary number between `0` and `9` (when omitted `0` is 
assumed). 

The behaviour is best explained with a small example for an imaginary object
type with an `age` and `name` property.

    ?filter=1:age:eq:50&filter=2:name:eq:foo&filter=2:name:eq:bar

The above filter has two groups `1` and `2`, and the `2` group has 2 members.
This is equivalent to the SQL (note the `and` and `or` as well as the 
grouping braces):

    e.age = 50 and (e.name = 'foo' or e.name = 'bar')

现在，如果将相同的`过滤器`与`rootJunction=OR`结合使用

    ?filter=1:age:eq:50&filter=2:name:eq:foo&filter=2:name:eq:bar&rootJunction=OR

the effect would be equivalent to the following SQL instead:

    e.age = 50 or (e.name = 'foo' and e.name = 'bar')


### The `headless` Parameter { #gist_parameters_headless } 
<!--DHIS2-SECTION-ID:gist_parameters_headless-->

Endpoints returning a list by default wrap the items with an envelope containing 
the `pager` and the list, which is named according to the type of object listed.

For example `/api/organisationUnits/gist` returns:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50,
    "nextPage": "/organisationUnits/gist?page=2"
  },
  "organisationUnits": [
    ...
  ]
}
```

With `headless=true` the response to `/api/organisationUnits/gist?headless=true` 
is just the `[...]` list part in above example.


### The `inverse` Parameter { #the-inverse-parameter } 
The `inverse` can be used in context of a collection field gist of the form 
`/api/<object-type>/<object-id>/<field-name>/gist` to not list all items that
are contained in the member collection but all items that are **not** contained
in the member collection.

For example, while 

    /api/organisationUnits/rZxk3S0qN63/children/gist

将列出作为`rZxk3S0qN63`子级的所有组织单位

    /api/organisationUnits/rZxk3S0qN63/children/gist?inverse=true

would list all organisation units that are not children of `rZxk3S0qN63`. 
This would e.g. be used to compose a list of all units that can be made a child 
of a particular unit.

Filters and orders do apply normally, meaning they filter or order the items
not contained in the member collection.


### The `locale` Parameter { #gist_parameters_locale } 
<!--DHIS2-SECTION-ID:gist_parameters_locale-->
The `locale` parameter is usually used for testing purposes to ad-hoc switch 
translation language of display names. 

If not specified the translation language is the one configured in the users
account settings.

Examples:

    /api/organisationUnits/gist?locale=en
    /api/organisationUnits/gist?locale=en_GB

### The `order` Parameter { #gist_parameters_order } 
<!--DHIS2-SECTION-ID:gist_parameters_order-->

To sort the list of items one or more order expressions can be given.

An order expression is either just a field name of a persisted field, or a field
name followed by `:asc` (ascending order - the default) or `:desc` 
(descending order).

For example, to sort organisation units alphabetically by name use:

    /api/organisationUnits/gist?order=name

Reverse alphabetical order would use:

    /api/organisationUnits/gist?order=name:desc

To sort organisation units first by level, then by name use:

    /api/organisationUnits/gist?order=level,name

This would start with root(s) at level 1. To start with the leaf units use:

    /api/organisationUnits/gist?order=level:desc,name

If no order is specified the result list will have a stable order based on 
internal data organisation.


### The `page` Parameter { #gist_parameters_page } 
<!--DHIS2-SECTION-ID:gist_parameters_page-->

指在分页列表中查看的页面，以`1`开头的第一页。

如果不存在`page`参数，则等于`page=1`。

The `page` is always in relation to the `pageSize`.
If a `page` is given beyond the number of existing matches an empty item list
is returned.


### The `pageSize` Parameter { #gist_parameters_pageSize } 
<!--DHIS2-SECTION-ID:gist_parameters_pageSize-->

指的是`页面`上的项目数。最多 1000 个项目。

如果没有`pageSize`参数，则等于`pageSize=50`。


### The `rootJunction` Parameter { #gist_parameters_rootJunction } 
<!--DHIS2-SECTION-ID:gist_parameters_rootJunction-->

The `rootJunction` parameter can be used to explicitly set the logic junction
used between filters. Possible are:

* `AND`: all filters have to match an entry for it to be included in the results
* `OR`: any of the filters matches an entry for it to be included in the results

默认为`与`。


### The `pageListName` Parameter { #gist_parameters_pageListName }
<!--DHIS2-SECTION-ID:gist_parameters_pageListName-->
The array property in a paged response that contains the matching entry list is 
named  after the object type contained in the list. 
For `/api/organisationUnits/gist` it would be named `organisationUnits`.

This default naming can be customized using the `pageListName` parameter.
For example, `/api/organisationUnits/gist?pageListName=matches` returns a
response root object with the format:

```json
{
  "pager": {},
  "matches": []
}
```
(details of the pager and matches are omitted here)


### The `total` or `totalPages` Parameter { #gist_parameters_total } 

<!--DHIS2-SECTION-ID:gist_parameters_total-->

By default, a gist query will **not** count the total number of matches should 
those exceed the `pageSize` limit. Instead, we opt-in to the additional costs
the total count implicates.

When not counting the total matches (`total=false`) the response `pager` will
assume that there is a `next` page in case `pageSize` items were found. This
could however turn out to be false when browsing to the page. Also, the `total`
field stating the number of total matches is not included in the `pager`.

For example, `/api/organisationUnits/gist` returns a `pager`:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50,
    "nextPage": "/organisationUnits/gist?page=2"
  }
}
```

When counting the total matches (`total=true`) the response `pager` will 
contain the `total` field with the actual number of total matches at the cost
of an additional database operation.

The response to `/api/organisationUnits/gist?total=true` now returns this `pager`:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50,
    "total": 1332,
    "nextPage": "/organisationUnits/gist?total=true&page=2",
    "pageCount": 27
  }
}
```


### The `translate` Parameter { #gist_parameters_translate } 
<!--DHIS2-SECTION-ID:gist_parameters_translate-->

像`name`或`shortName`这样的字段可以被翻译（国际化）。

By default, any translatable field that has a translation is returned translated
given that the user requesting the gist has an interface language configured.

要返回普通的非翻译字段，请使用 `translate=false`。

For example, `/api/organisationUnits/gist` returns items like this:

```json
{
  "name": "A translated name",
  ...
}
```

Whereas `/api/organisationUnits/gist?translate=false` would return items like:

```json
{
  "name"
  "Plain field name",
  ...
}
```

Note that synthetic fields `displayName` and `displayShortName` are always
returning the translated value independent of the `translate` parameter.


## Fields { #gist_fields } 
<!--DHIS2-SECTION-ID:gist_fields-->

The fields included by default (without `fields` parameter) correspond to 
`fields=*`. 
This means the list of fields shown depends on object type, endpoint context as 
well as the `auto` parameter.

Note that the `/gist` API always excludes certain fields that usually are of no 
interest to clients, like for example the `translations` or `sharing` fields. 
These can be added explicitly.

When not explicitly provided by name in the `fields` parameters the list of 
fields is computed from a preset.
A preset can be used in the list of fields like a field name. 
It expands to zero, one or many fields depending on the object type, used 
endpoint and selector.


### Field Presets { #field-presets } 

* `*` / `:all`: default fields depend on the context and `auto` parameter
* `:identifiable`: all persisted fields of the `IdentifiableObject` interface
* `:owner`: all persisted fields where the listed type is the owner
* `:nameable`: all persisted fields of the `NameableObject` interface
* `:persisted`: literally all persisted fields


### Field Transformers { #field-transformers } 
A transformer or transformation can be applied to a field by appending 
any of the indicators `::`, `~` or `@` followed by the transformer expression.

Available transformer expressions are:

| Transformer          | JSON Result Type       | 描述                                                                                           |
|----------------------|------------------------|-------------------------------------------------------------------------------------------------------|
| `rename(<name>)`     | --                      | renames the field in the response to `<name>`                                                         |
| `size`               | `number`               | number of items in the collection field                                                               |
| `isEmpty`            | `boolean`              | emptiness of a collection field                                                                       |
| `isNotEmpty`         | `boolean`              | non-emptiness of a collection field                                                                   |
| `ids`                | `string` or `[string]` | ID of an object or IDs of collection items                                                            |
| `id-objects`         | `[{ "id": <id> }]`     | IDs of collection items as object                                                                     |
| `member(<id>)`       | `boolean`              | 具有`<id>`的成员用于集合字段                                                           |
| `not-member(<id>)`   | `boolean`              | 集合字段中没有具有`<id>`的成员                                                       |
| `pluck(<field>,...)` | `string` or `[string]` | extract single text property or multiple simple properties from the object or of each collection item |
| `from(<field>,...)`  | depends on bean type   | extracts a non-persistent field from one or more persistent ones                                      |

A field can receive both the `rename` transformer and one of the other 
transformers, for example:

    /api/organisationUnits/gist?fields=*,children::size~rename(child-count)

The returned items now no longer have a `children` member but a `child-count`
member instead. Note that `rename` also affects the member name of the URI
reference given in `apiEndpoints`.

The `from` transformation can be used with one or more persistent fields as
parameter. These will be loaded from the database, set in an instance of the 
listed element object before the non-persistent property transformed with 
`from` is extracted from that instance by calling the getter. This allows to 
extract derived fields while using the same logic that is used in usual metadata API.

For example, a user's (non-persistent property) `name` is composed of the 
persistent property `firstName` and `surname`. It can be fetched like this:

    /api/users/gist?fields=id,name~from(firstName,surname)

Since a user's name is such a common case an auto-detection was added so that in
this special case the `from` transformation is added automatically to `name`.
We are allowed to just use the following which internally adds the `from` 
transformation:

    /api/users/gist?fields=id,name

While this makes non-persistent properties accessible in general these always 
have to be included in the `fields` explicitly. For a user this could be 
done using the following:

    /api/users/gist?fields=*,name


## Synthetic Fields { #gist_syntheticFields } 
<!--DHIS2-SECTION-ID:gist_syntheticFields-->

The `/gist` API is tightly coupled to properties that exist the database.
This means properties that aren't stored in the database usually aren't 
available.
The exception to this are the "synthetic" properties which are dynamically 
computed on the basis of one or more database stored properties.

Synthetic properties are available for all endpoints where the persisted 
properties needed to compute the synthetic property exist.

Except for the `apiEndpoints` property which is automatically added when needed 
all other synthetic properties are not included by default and have to be 
requested explicitly in the list of `fields`.


### 总览 { #overview } 
Synthetic fields in alphabetical order:

| 领域              | 描述                                             |
| ------------------ | ------------------------------------------------------- |
| `apiEndpoints`     | contains links to browse nested complex objects or collections |
| `href`             | link to the list item itself (single item view)         |
| `displayName`      | 已翻译的`名称`（始终已翻译）                   |
| `displayShortName` | translated `shortName` (always translated)              |
| `access`           | summary on ability of current user to read/write/modify the entry |


### The `href` Field { #gist_syntheticFields_href } 
<!--DHIS2-SECTION-ID:gist_syntheticFields_href-->

Each item in a `/gist` response can link to itself. This link is given in the 
`href` property.

To add the `href` field use (for example):

    /api/<object-type>/gist?fields=*,href

### The `displayName` and `displayShortName` Field { #gist_syntheticFields_displayName } 
<!--DHIS2-SECTION-ID:gist_syntheticFields_displayName-->

By definition the `displayName` is the translated `name` and the 
`displayShortName` is the translated `shortName`. 

To add `displayName` or `displayShortName` add it to the list use (for example):

    /api/<object-type>/gist?fields=*,displayName
    /api/<object-type>/gist?fields=*,displayShortName

Note that by default all translatable properties like `name` and `shortName` 
would also be translated. When `translate=false` is used to disable this 
`displayName` and `displayShortName` stay translated.


### The `apiEndpoints` Field { #gist_syntheticFields_apiEndpoints } 
<!--DHIS2-SECTION-ID:gist_syntheticFields_apiEndpoints-->

This property provides the links to further browse complex objects or list of 
items that are included in the `/gist` response in form of a transformed simple 
value like an item count.

The `apiEndpoints` object will have a member of the same name for every member 
in the item that was transformed to a simple value.

For example, 

    /api/users/gist?fields=id,userGroups::size,organisationUnits::size 

returns items in the form:

```json
{
  "id": "rWLrZL8rP3K",
  "userGroups": 0,
  "organisationUnits": 1,
  "apiEndpoints": {
    "organisationUnits": "/users/rWLrZL8rP3K/organisationUnits/gist",
    "userGroups": "/users/rWLrZL8rP3K/userGroups/gist"
  }
}
```

The list of `userGroups` and `organisationUnits` are included as their `size`. 
Each has a corresponding member in `apiEndpoints` with the path to browse the 
list.

The paths can be changed to URLs by using the `absoluteUrls` parameter. 

    /api/users/gist?fields=id,userGroups::size,organisationUnits::size&absoluteUrls=true

returns items in the form:

```json
{
  "id": "rWLrZL8rP3K",
  "userGroups": 0,
  "organisationUnits": 1,
  "apiEndpoints": {
    "organisationUnits": "http://{host}/api/users/rWLrZL8rP3K/organisationUnits/gist?absoluteUrls=true",
    "userGroups": "http://{host}/api/users/rWLrZL8rP3K/userGroups/gist?absoluteUrls=true"
  }
}
```

### The `access` Field { #the-access-field } 
The `access` summary is based on the `sharing` and the current user.
This means it is only applicable for objects that have a `sharing` property.

For example, when listing data elements with `access` field

    /api/dataElements/gist?fields=*,access

返回的数据元素项包含一个`访问`成员，如下所示：

```json
"access": {
  "manage": false,
  "externalize": false,
  "write": false,
  "read": true,
  "update": false,
  "delete": false
}
```

### Attributes as Fields { #gist_attributeFields }
DHIS2 allows creating and adding custom attributes to metadata objects.
Their values are contained in the `attributeValues` property of a metadata 
object in form of a map with the attribute UID as the map's key.

To directly list one or more specific attribute values from this map as if they
were usual fields of the metadata object the attribute UID can be used as if it
was a name of a usual field.

For example, to include the value of the attribute with UID `Y1LUDU8sWBR` as 
the property `unit-of-measure` in the list use:

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(unit-of-measure)

This results in list items of the form:
```json
{
  "id": "qrur9Dvnyt5",
  "name": "Age in years",
  "unit-of-measure": "years"
}
```

By default, the values are fetched as JSON and extracted from the map of 
attribute values. This means the listing will contain the proper JSON type for
the type of attribute value. This comes at the overhead of fetching all 
attribute values. To single out the value within the database the `PLUCK` 
transformation can be used.

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(unit-of-measure)~pluck

The result will look the same but now the value is extracted as text in the 
database turning any JSON value to a string in the property output. 

## 例子 { #gist_examples } 
<!--DHIS2-SECTION-ID:gist_examples-->
A few examples starting from simple listings moving on to very specific use cases. 

It is preferable to always supply an explicit list of `fields` so this section 
will do so. 

List organisation units with id and name:

    /api/organisationUnits/gist?fields=id,name

List organisation units with id and name and total count:

    /api/organisationUnits/gist?fields=id,name&total=true

List users with id and username:

    /api/users/gist?fields=id,userCredentials.username

List users with id, username and last login date:

    /api/users/gist?fields=id,userCredentials[username,lastLogin]

List only organisation units on second level with id, name and level:

    /api/organisationUnits/gist?fields=id,name,level&filter=level:eq:2

List only organisation units that have more than 1 child with id, name and
number of children:

    /api/organisationUnits/gist?fields=id,name,children::size&filter=children:gt:1

List only organisation units that are not yet a children of another unit
`zFDYIgyGmXG`:

    /api/organisationUnits/zFDYIgyGmXG/children/gist?fields=id,name&inverse=true

List users and flag whether they are a member of a specific user group 
`NTC8GjJ7p8P` and name that field `is-member` in the response:

    /api/users/gist?fields=id,userCredentials.username,userGroups::member(NTC8GjJ7p8P)~rename(is-member)

List links to all users in pages of 10 items:

    /api/users/gist?fields=href&absoluteUrls&pageSize=10




# 数据 { #data } 

## 数据值 { #webapi_data_values } 

本节关于发送和读取数据值。

    /api/dataValueSets

### 发送数据值 { #webapi_sending_data_values } 

To send data values you can make a POST request to the following resource.

```
POST /api/dataValueSets
```

A common use-case for system integration is the need to send a set of
data values from a third-party system into DHIS. In this example, we will
use the DHIS2 demo on `http://play.dhis2.org/demo` as basis. We assume
that we have collected case-based data using a simple software client
running on mobile phones for the *Mortality <5 years* data set in the
community of *Ngelehun CHC* (in *Badjia* chiefdom, *Bo* district) for
the month of January 2014. We have now aggregated our data into a
statistical report and want to send that data to the DHIS2 instance. The
base URL to the demo API is `http://play.dhis2.org/demo/api`. The following
links are relative to the base URL.


最适合我们发送数据的资源
values 是 `/api/dataValueSets` 资源。一个数据值集代表一个
一组具有关系的数据值，通常来自
从相同的数据输入表单中捕获。格式看起来像
这：

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="dataSetID"
  completeDate="date" period="period" orgUnit="orgUnitID" attributeOptionCombo="aocID">
  <dataValue dataElement="dataElementID" 
    categoryOptionCombo="cocID" value="1" comment="comment1"/>
  <dataValue dataElement="dataElementID" 
    categoryOptionCombo="cocID" value="2" comment="comment2"/>
  <dataValue dataElement="dataElementID" 
    categoryOptionCombo="cocID" value="3" comment="comment3"/>
</dataValueSet>
```

JSON支持以下格式：

```json
{
  "dataSet": "dataSetID",
  "completeDate": "date",
  "period": "period",
  "orgUnit": "orgUnitID",
  "attributeOptionCombo": "aocID",
  "dataValues": [
    {
      "dataElement": "dataElementID", 
      "categoryOptionCombo": "cocID", 
      "value": "1", 
      "comment": "comment1"
    },
    {
      "dataElement": "dataElementID", 
      "categoryOptionCombo": "cocID", 
      "value": "2", 
      "comment": "comment2"
    },
    {
      "dataElement": "dataElementID", 
      "categoryOptionCombo": "cocID", 
      "value": "3", 
      "comment": "comment3"
    }
  ]
}
```

CSV支持以下格式：

```csv
“ dataelement”，“ period”，“ orgunit”，“ catoptcombo”，“ attroptcombo”，“ value”，“ strby”，“ lstupd”，“ cmt”
“ dataElementID”，“ period”，“ orgUnitID”，“ cocID”，“ aocID”，“ 1”，“用户名”，“ 2015-04-01”，“ comment1”
“ dataElementID”，“ period”，“ orgUnitID”，“ cocID”，“ aocID”，“ 2”，“用户名”，“ 2015-04-01”，“ comment2”
“ dataElementID”，“ period”，“ orgUnitID”，“ cocID”，“ aocID”，“ 3”，“用户名”，“ 2015-04-01”，“ comment3”
```

> **Note**
>
> Please refer to the date and period section above for time formats.

> **Note**
>
> Any imported data value which is seen as unchanged will be ignored and the import summary will reflect this. An unchanged data value is classed as one which has the same value for all 3 of these properties:
> - value
> - comment
> - followUp

从这个例子中，我们可以看出我们需要识别周期，
数据集、组织单位（设施）和数据元素
报告。

To obtain the identifier for the data set we make a request to the
`/api/dataSets` resource. From there we find and follow the link to 
the *Mortality < 5 years* data set which leads us to `/api/dataSets/pBOMPrpg1QX`. 
The resource representation for the *Mortality < 5 years* data set conveniently
advertises links to the data elements which are members of it. From here
we can follow these links and obtain the identifiers of the data
elements. For brevity we will only report on three data elements:
*Measles* with id `f7n9E0hX8qk`, *Dysentery* with id `Ix2HsbDMLea` and
*Cholera* with id `eY5ehpbEsB7`.

剩下的就是掌握组织的标识符
单元。 *dataSet* 表示方便地提供了到组织的链接
报告它的单位，所以我们搜索 *Ngelehun CHC* 并按照
链接到 `/api/organisationUnits/DiszpKrYNg8` 中的 HTML 表示，其中
告诉我们这个组织单位的标识符是`DiszpKrYNg8`。

根据我们基于病例的数据，我们假设我们有 12 例麻疹病例，14
痢疾16例，霍乱16例。我们现在已经聚集了足够的
能够将 XML 数据值集放在一起的信息
信息：

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-02-03" period="201401" orgUnit="DiszpKrYNg8">
  <dataValue dataElement="f7n9E0hX8qk" value="12"/>
  <dataValue dataElement="Ix2HsbDMLea" value="14"/>
  <dataValue dataElement="eY5ehpbEsB7" value="16"/>
</dataValueSet>
```

JSON格式：

```json
{
  "dataSet": "pBOMPrpg1QX",
  "completeDate": "2014-02-03",
  "period": "201401",
  "orgUnit": "DiszpKrYNg8",
  "dataValues": [
    {
      "dataElement": "f7n9E0hX8qk", 
      "value": "1"
    },
    {
      "dataElement": "Ix2HsbDMLea", 
      "value": "2"
    },
    {
      "dataElement": "eY5ehpbEsB7", 
      "value": "3"
    }
  ]
}
```

To perform functional testing we will use the _curl_ tool which provides
an easy way of transferring data using HTTP. First, we save the data
value set XML content in a file called `datavalueset.xml`. From the
directory where this file resides we invoke the following from the
command line:

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

要发送 JSON 内容，您必须设置 content-type 标头
因此：

```bash
curl -d @datavalueset.json "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/json" -u admin:district
```

该命令将向演示 Web API 发送请求，设置
`application/xml` 作为内容类型并使用
`admin`/`district` 作为用户名/密码。如果一切顺利，这将返回一个
`200 OK` HTTP 状态代码。您可以验证数据是否已
通过在 DHIS2 中打开数据输入模块并选择组织来接收
本例中使用的单位、数据集和期间。

The API follows normal semantics for error handling and HTTP status
codes. If you supply an invalid username or password, `401 Unauthorized`
is returned. If you supply a content-type other than `application/xml`,
`415 Unsupported Media Type` is returned. If the XML content is invalid
according to the DXF namespace, `400 Bad Request` is returned. If you
provide an invalid identifier in the XML content, `409 Conflict` is
returned together with a descriptive message.

### 发送大量数据值 { #webapi_sending_bulks_data_values } 

前面的例子向我们展示了如何发送一组相关的数据值
共享同一时期和组织单位。这个例子将向我们展示
如何发送大量不一定是的数据值
逻辑相关。

我们将再次与`/api/dataValueSets` 资源交互。这次我们
不会指定 `dataSet` 和 `completeDate` 属性。此外，我们将
在单个数据值上指定 `period` 和 `orgUnit` 属性
元素而不是外部数据值集元素。这会
使我们能够发送不同时期和组织单位的数据值：

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0">
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201401" orgUnit="DiszpKrYNg8" value="12"/>
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201401" orgUnit="FNnj3jKGS7i" value="14"/>
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201402" orgUnit="DiszpKrYNg8" value="16"/>
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201402" orgUnit="Jkhdsf8sdf4" value="18"/>
</dataValueSet>
```

JSON格式：

```json
{
  "dataValues": [
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201401", 
      "orgUnit": "DiszpKrYNg8", 
      "value": "12"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201401", 
      "orgUnit": "FNnj3jKGS7i", 
      "value": "14"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201402", 
      "orgUnit": "DiszpKrYNg8", 
      "value": "16"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201402", 
      "orgUnit": "Jkhdsf8sdf4", 
      "value": "18"
    }
  ]
}
```

CSV格式：

```csv
“ dataelement”，“ period”，“ orgunit”，“ categoryoptioncombo”，“ attributeoptioncombo”，“ value”
“ f7n9E0hX8qk”，“ 201401”，“ DiszpKrYNg8”，“ bRowv6yZOF2”，“ bRowv6yZOF2”，“ 1”
“ Ix2HsbDMLea”，“ 201401”，“ DiszpKrYNg8”，“ bRowv6yZOF2”，“ bRowv6yZOF2”，“ 2”
“ eY5ehpbEsB7”，“ 201401”，“ DiszpKrYNg8”，“ bRowv6yZOF2”，“ bRowv6yZOF2”，“ 3”
```

我们通过使用curl以XML格式发送数据值进行测试：

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

请注意，使用 CSV 格式时，您必须使用二进制数据选项
保留 CSV 文件中的换行符：

```bash
curl --data-binary @datavalueset.csv "https://play.dhis2.org/demo/24/api/dataValueSets"
  -H "Content-Type:application/csv" -u admin:district
```

数据值集资源提供有用的 XML 响应
当您想验证您的请求所产生的影响时。我们第一次
发送上面的数据值设置请求，服务器将响应
以下导入摘要：

```xml
<importSummary>
  <dataValueCount imported="2" updated="1" ignored="1"/>
  <dataSetComplete>false</dataSetComplete>
</importSummary>
```

此消息告诉我们导入了 3 个数据值，1 个数据值是
在忽略零数据值时更新。单一更新来自
我们在上一个示例中发送该数据值的结果。一个数据
如果引用不存在的数据元素，值将被忽略，
期间、组织单位或数据集。在我们的例子中，这个被忽略的值是
由对组织单位的无效引用的最后一个数据值引起。
数据集完整元素将显示数据的日期
值集已完成，如果没有数据元素属性，则为 false
提供。

### 导入参数 { #webapi_data_values_import_parameters } 

The import process can be customized using a set of import parameters.

Table: Import parameters

| Parameter | Values (default first) | 描述 |
|---|---|---|
| 数据元素标识方案 | uid &#124; name &#124; code &#124; attribute:ID | Property of the data element object to use to map the data values. |
| orgUnitIdScheme | uid &#124; name &#124; code &#124; attribute:ID | Property of the org unit object to use to map the data values. |
| attributeOptionComboIdScheme | uid &#124; name &#124; code&#124; attribute:ID | Property of the attribute option combo object to use to map the data values. |
| categoryOptionComboIdScheme | uid &#124; name &#124; code &#124; attribute:ID | Property of the category option combo object to use to map the data values. |
| dataSetIdScheme | uid &#124; name &#124; code&#124; attribute:ID | Property of the data set object to use to map the data values. |
| categoryIdScheme | uid &#124; name &#124; code&#124; attribute:ID | Property of the category object to use to map the data values (ADX only). |
| categoryOptionIdScheme | uid &#124; name &#124; code&#124; attribute:ID | Property of the category option object to use to map the data values (ADX only). |
| 方案 | uid &#124; name &#124; code&#124; attribute:ID | Property of any of the above objects if they are not specified, to use to map the data values. |
| preheatCache | false &#124; true | Indicates whether to preload metadata caches before starting to import data values, will speed up large import payloads with high metadata cardinality. |
| dryRun | false &#124; true | Whether to save changes on the server or just return the import summary. |
| importStrategy | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | Save objects of all, new or update import status on the server. |
| skipExistingCheck | false &#124; true | Skip checks for existing data values. Improves performance. Only use for empty databases or when the data values to import do not exist already. |
| skipAudit | false &#124; true | Skip audit, meaning audit values will not be generated. Improves performance at the cost of ability to audit changes. Requires authority "F_SKIP_DATA_IMPORT_AUDIT". |
| async | false &#124; true | Indicates whether the import should be done asynchronous or synchronous. The former is suitable for very large imports as it ensures that the request does not time out, although it has a significant performance overhead. The latter is faster but requires the connection to persist until the process is finished. |
| force | false &#124; true | Indicates whether the import should be forced. Data import could be rejected for various reasons of data set locking for example due to approval, data input period, expiry days, etc. In order to override such locks and force data input one can use data import with force=true. However, one needs to be a \*superuser\* for this parameter to work. |
| dataSet | uid | Provide the data set ID for CSV import where the ID cannot be provided in the file itself |

所有参数都是可选的，可以作为查询参数提供
请求 URL 是这样的：

    /api/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=name
      &dryRun=true&importStrategy=CREATE

它们也可以作为数据值集上的 XML 属性提供
元素如下。 XML 属性将覆盖查询字符串
参数。

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataElementIdScheme="code"
  orgUnitIdScheme="name" dryRun="true" importStrategy="CREATE">
</dataValueSet>
```

请注意，`preheatCache` 参数会对
表现。对于小的导入文件，将其设置为 false 会很快。
对于包含大量不同数据的大型导入文件
元素和组织单位，将其设置为 true 将是
幅度更快。

#### 数据值要求 { #webapi_data_values_import_requirement } 

数据值导入支持一组值类型。对于每个值类型，
有一个特殊要求。下表列出了边缘情况
对于值类型。



Table: Value type requirements

| 值类型 | 要求 | 评论 |
|---|---|---|
| BOOLEAN | true &#124; True &#124; TRUE &#124; false &#124; False &#124; FALSE &#124; 1 &#124; 0 &#124; t &#124; f &#124; | Used when the value is a boolean, true or false value. The import service does not care if the input begins with an uppercase or lowercase letter, or if it's all uppercase. |

#### 标识符方案 { #webapi_data_values_identifier_schemes } 

Regarding the id schemes, by default the identifiers used in the XML
messages use the DHIS2 stable object identifiers referred to as `UID`.
In certain interoperability situations we might experience that an external
system decides the identifiers of the objects. In that case we can use
the `code` property of the organisation units and other objects to set
fixed identifiers. When importing data values we hence need to reference
the code property instead of the identifier property of these metadata
objects. Identifier schemes can be specified in the XML message as well
as in the request as query parameters. To specify it in the XML payload
you can do this:

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0"
  dataElementIdScheme="CODE" orgUnitIdScheme="UID" idScheme="CODE">
</dataValueSet>
```

上面的参数表解释了如何指定 id 方案
作为查询参数。以下规则适用于
优先级：

  - XML 或 JSON 负载中定义的 ID 方案优先于
    id 方案定义为 URL 查询参数。

  - Specific id schemes such as dataElementIdScheme or
    orgUnitIdScheme 优先于一般 idScheme。

  - If no explicit id scheme is defined, the default id scheme is `code`
    for ADX format, and `uid` for all other formats.

以下标识符方案可用。

  - uid

  - 码

  - 名称

  - 属性（后跟属性的UID）

属性选项是特殊的，指的是元数据属性
已被标记为*独特*。使用此选项时，`attribute` 必须
紧随其后的是属性的标识符，例如
“属性：DnrLSdo4hMl”。

#### 异步数据值导入 { #webapi_data_values_async_import } 

可以通过以下方式以异步方式发送和导入数据值
提供设置为 *true* 的 `async` 查询参数：

    /api/dataValueSets?async=true

这将启动一个异步导入作业，您可以对其进行监控
任务摘要 API 中的状态。 API 响应表明
作业的唯一标识符、作业类型和可用于的 URL
监控导入作业状态。响应将类似于以下内容：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Initiated dataValueImport",
  "response": {
    "name": "dataValueImport",
    "id": "YR1UxOUXmzT",
    "created": "2018-08-20T14:17:28.429",
    "jobType": "DATAVALUE_IMPORT",
    "relativeNotifierEndpoint": "/api/system/tasks/DATAVALUE_IMPORT/YR1UxOUXmzT"
  }
}
```

请阅读有关*异步任务状态*的部分了解更多信息
信息。

### CSV数据值格式 { #webapi_data_values_csv } 

以下部分描述了 DHIS2 中使用的 CSV 格式。首先
行被假定为标题行，在导入期间将被忽略。

Table: CSV format of DHIS2

||||
|---|---|---|
| 柱 | 需要 | 描述 |
| 数据元素 | 是的 | Refers to ID by default, can also be name and code based on selected id scheme |
| 期 | 是的 | In ISO format |
| 组织单位 | 是的 | Refers to ID by default, can also be name and code based on selected id scheme |
| 类别选项组合 | 不 | Refers to ID |
| Attribute option combo | 不 | Refers to ID (from version 2.16) |
| 值 | 不 | 资料值 |
| Stored by | 不 | Refers to username of user who entered the value |
| Last updated | 不 | Date in ISO format |
| 评论 | 不 | Free text comment |
| Follow up | 不 | true or false |

可以导入DHIS2的CSV文件示例如下所示。

```csv
“ dataelement”，“ period”，“ orgunit”，“ catoptcombo”，“ attroptcombo”，“ value”，“ storedby”，“ timestamp”
“ DUSpd8Jq3M7”，“ 201202”，“ gP6hn503KUX”，“ Prlt0C1RF0s”，“ 7”，“ bombali”，“ 2010-04-17”
“ DUSpd8Jq3M7”，“ 201202”，“ gP6hn503KUX”，“ V6L425pT3A0”，“ 10”，“ bombali”，“ 2010-04-17”
“ DUSpd8Jq3M7”，“ 201202”，“ OjTS752GbZE”，“ V6L425pT3A0”，“ 9”，“孟买”，“ 2010-04-06”
```

### 生成数据值集模板 { #webapi_data_values_template } 

要为特定数据集生成数据值集模板，您可以使用
`/api/dataSets/ <id> /dataValueSet` 资源。 XML 和 JSON 响应
支持格式。例子：

    /api/dataSets/BfMAe6Itzgt/dataValueSet

描述了可用于进一步调整输出的参数
以下：



Table: Data values query parameters

| 查询参数 | 需要 | 描述 |
|---|---|---|
| period | 不 | Period to use, will be included without any checks. |
| orgUnit | 不 | Organisation unit to use, supports multiple orgUnits, both id and code can be used. |
| comment | 不 | Should comments be include, default: Yes. |
| orgUnitIdScheme | 不 | Organisation unit scheme to use, supports id &#124; code. |
| 数据元素标识方案 | 不 | Data-element scheme to use, supports id &#124; code. |

### 读取数据值 { #webapi_reading_data_values } 

To read data values you can make a GET request to the following resource.

```
GET /api/dataValueSets
```

Data values can be retrieved in *XML*, *JSON*, *CSV*, and *ADX* format. Since we want to read data we will use the *GET* HTTP verb. We will also specify that we are
interested in the XML resource representation by including an `Accept` HTTP header with our request. The following query parameters are
available.

Table: Data value set query parameters

| Parameter | 描述 |
|---|---|
| dataSet | Data set identifier. Can be repeated any number of times. |
| dataElementGroup | Data element group identifier. Can be repeated any number of times (Not supported for ADX). |
| dataElement | Data element identifier. Can be repeated any number of times. |
| period | Period identifier in ISO format. Can be repeated any number of times. |
| 开始日期 | Start date for the time span of the values to export. |
| 结束日期 | End date for the time span of the values to export. |
| orgUnit | Organisation unit identifier. Can be repeated any number of times. |
| children | Whether to include the children in the hierarchy of the organisation units. |
| orgUnitGroup | Organisation unit group identifier. Can be repeated any number of times. |
| attributeOptionCombo | Attribute option combo identifier. Can be repeated any number of times. |
| includeDeleted | Whether to include deleted data values. |
| lastUpdated | Include only data values which are updated since the given time stamp. |
| lastUpdatedDuration | Include only data values which are updated within the given duration. The format is <value\><time-unit\>, where the supported time units are "d" (days), "h" (hours), "m" (minutes) and "s" (seconds). |
| limit | The max number of results in the response. |
| 数据元素标识方案 | Property of the data element object to use for data values in response. |
| orgUnitIdScheme | Property of the org unit object to use for data values in response. |
| categoryOptionComboIdScheme | Property of the category option combo to use for data values in response. |
| attributeOptionComboIdScheme | Property of the attribute option combo objects to use for data values in response. |
| dataSetIdScheme | Property of the data set object to use in the response. |
| categoryIdScheme | Property of the category object to use in the response (ADX only). |
| categoryOptionIdScheme | Property of the category option object to use in the response (ADX only). |
| 方案 | Property of any of the above objects if they are not specified, to use in the response. If not specified, the default idScheme for ADX is code, and for all other formats is uid. |
| inputOrgUnitIdScheme | Identifier property used for the provided `orgUnit` parameter values; `id` or `code` |
| inputDataSetIdScheme | Identifier property used for the provided `dataSet` parameter values; `id` or `code` |
| inputDataElementGroupIdScheme | Identifier property used for the provided `dataElementGroup` parameter values; `id` or `code` |
| inputDataElementIdScheme | Identifier property used for the provided `dataElement` parameter values; `id` or `code` |
| inputIdScheme | General identifier property used for all object types, specific identifier schemes will override the general scheme; `id` or `code` |
| compression | Whether to compress the response payload; `none`, `gzip` or `zip` |
| attachment | File name to use for the response, a non-blank value indicates rendering the response as an attachment. |

The following parameters from the list above are required:
- either dataSet or dataElementGroup (for ADX this must be dataSet)
- either period, both startDate and endDate, lastUpdated, or lastUpdatedDuration
- either orgUnit or orgUnitGroup

支持以下响应格式：

  - xml（应用程序/ xml）

  - json（应用程序/ json）

  - csv（应用程序/ csv）

  - adx（应用程序/ adx + xml）

假设我们已经根据
上一节称为 *发送数据值* 我们现在可以放在一起
我们对单个数据值集的请求并使用 cURL 请求它：

```bash
curl "https://play.dhis2.org/demo/api/dataValueSets?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8"
  -H "Accept:application/xml" -u admin:district
```

我们还可以使用开始和结束日期查询参数来请求一个
大量的数据值。 IE。您还可以请求数据值
多个数据集和组织单位以及一个时间跨度以便导出
更大的数据块。请注意，期间查询参数采用
优先于开始和结束日期参数。一个例子看起来像
这：

```bash
curl "https://play.dhis2.org/demo/api/dataValueSets?dataSet=pBOMPrpg1QX&dataSet=BfMAe6Itzgt
  &startDate=2013-01-01&endDate=2013-01-31&orgUnit=YuQRtpLP10I&orgUnit=vWbkYPRmKyS&children=true"
  -H "Accept:application/xml" -u admin:district
```

检索已创建或更新的数据值
过去 10 天，您可以提出这样的请求：

    / api / dataValueSets？dataSet = pBOMPrpg1QX＆orgUnit = DiszpKrYNg8＆lastUpdatedDuration = 10d

响应将如下所示：

```xml
<?xml version='1.0' encoding='UTF-8'?>
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-01-02" period="201401" orgUnit="DiszpKrYNg8">
<dataValue dataElement="eY5ehpbEsB7" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10003"/>
<dataValue dataElement="Ix2HsbDMLea" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10002"/>
<dataValue dataElement="f7n9E0hX8qk" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10001"/>
</dataValueSet>
```

您可以使用JSON格式请求数据，如下所示：

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8

响应将如下所示：

```json
{
  "dataSet": "pBOMPrpg1QX",
  "completeDate": "2014-02-03",
  "period": "201401",
  "orgUnit": "DiszpKrYNg8",
  "dataValues": [
    {
      "dataElement": "eY5ehpbEsB7", 
      "categoryOptionCombo": "bRowv6yZOF2", 
      "period": "201401",
      "orgUnit": "DiszpKrYNg8", 
      "value": "10003"
    }, 
    {
      "dataElement": "Ix2HsbDMLea", 
      "categoryOptionCombo": "bRowv6yZOF2", 
      "period": "201401",
      "orgUnit": "DiszpKrYNg8", 
      "value": "10002"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "categoryOptionCombo": "bRowv6yZOF2", 
      "period": "201401",
      "orgUnit": "DiszpKrYNg8", 
      "value": "10001"
    }
  ]
}
```

请注意，数据值是软删除的，即删除的值具有
`deleted` 属性设置为 true 而不是被永久删除。
这在集成多个系统以进行通信时很有用
删除。您可以在响应中包含已删除的值，如下所示：

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8&includeDeleted=true

您还可以请求CSV格式的数据，如下所示：

    /api/dataValueSets.csv?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8

响应将如下所示：

```csv
数据元素，期限，组织单位，catoptcombo，attroptcombo，值，存储于，最后更新，注释，开始
f7n9E0hX8qk，201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,12，system，2015-04-05T19：58：12.000，comment1，false
Ix2HsbDMLea，201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,14，system，2015-04-05T19：58：12.000，comment2，false
eY5ehpbEsB7,201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,16，系统，2015-04-05T19：58：12.000，comment3，false
FTRrcoaog83,201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,12，系统，2014-03-02T21：45：05.519，comment4，false
```

Request data values in CSV format compressed with `gzip`:

```
/api/dataValueSets.csv?dataSet=pBOMPrpg1QX&period=202401&orgUnit=DiszpKrYNg8&compression=gzip
```

The response will be in compressed CSV format. The content can be uncompressed with the `gunzip` tool.

以下约束适用于数据值集资源：

  - 必须至少指定一个数据集。

  - 必须是至少一个期间或开始日期和结束日期
    指定的。

  - 必须至少指定一个组织单位。

  - 组织单位必须在组织的层次结构内
    认证用户的单位。

  - 限制不能小于零。

### 发送，读取和删除单个数据值 { #webapi_sending_individual_data_values } 

此示例将显示如何发送要保存的单个数据值
一个要求。这可以通过发送一个 *POST* 请求到
`dataValues` 资源：

    POST /api/dataValues

此资源支持以下查询参数：

Table: Data values query parameters

| 查询参数 | 需要 | 描述 |
|---|---|---|
| 德 | 是的 | Data element identifier |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | Organisation unit identifier |
| co | 不 | Category option combo identifier, default will be used if omitted |
| cc | No (must be combined with cp) | Attribute category combo identifier |
| cp | No (must be combined with cc) | Attribute category option identifiers, separated with ; for multiple values |
| ds | 不 | Data set, to check if POST or DELETE is allowed for period and organisation unit. If specified, the data element must be assigned to this data set. If not specified, a data set containing the data element will be chosen to check if the operation is allowed. |
| 价值 | 不 | Data value. For boolean values, the following will be accepted: true &#124; True &#124; TRUE &#124; false &#124; False &#124; FALSE &#124; 1 &#124; 0 &#124; t &#124; f &#124; |
| comment | 不 | Data comment |
| 跟进 | 不 | Follow up on data value, will toggle the current boolean value |

如果给定的任何标识符无效，如果数据值或
评论无效或如果数据被锁定，响应将包含
*409 Conflict* 状态代码和描述性文本消息。如果
操作导致保存或更新的值，*200 OK* 将被返回。
请求的示例如下所示：

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s&value=12"
  -X POST -u admin:district
```

此资源还允许使用特殊语法将值关联到
一个属性选项组合。这可以通过发送
属性类别组合的标识符，连同标识符
值代表的属性类别选项
组合。类别组合由 `cc` 参数指定，而
类别选项被指定为分号分隔的字符串，带有`cp`
范围。有必要确保类别选项都是部分
的类别组合。一个示例如下所示：

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu&ou=DiszpKrYNg8
  &pe=201308&cc=dzjKKQq0cSO&cp=wbrDrL2aYEc;btOyqprQ9e8&value=26"
  -X POST -u admin:district
```

您可以使用 *GET* 方法通过请求检索数据值。这
value、comment 和 followUp 参数在这方面不适用：

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s"
  -u admin:district
```

您可以使用 *DELETE* 方法通过请求删除数据值。

### Sending individual data values as payload { #webapi_sending_individual_data_values_as_payload } 

You can send individual data values as a JSON payload using the following resource using `Content-Type: application/json`.

```
POST /api/dataValues
```

The resource will create a new data value or update a data value if it already exists. The JSON payload format is defined below.

```json
{
  "dataElement": "fbfJHSPpUQD",
  "categoryOptionCombo": "PT59n8BQbqM",
  "period": "202201",
  "orgUnit": "DiszpKrYNg8",
  "value": "10",
  "comment": "OK"
}
```

The endpoint supports specifying attribute option combos in a nested structure.

```json
{
  "dataElement": "BOSZApCrBni",
  "categoryOptionCombo": "TkDhg29x18A",
  "attribute": {
    "combo": "O4VaNks6tta",
    "options": [
      "C6nZpLKjEJr", "i4Nbp8S2G6A"
    ]
  },
  "dataSet": "lyLU2wR22tC",
  "period": "202201",
  "orgUnit": "DiszpKrYNg8",
  "value": "15",
  "comment": "Good"
}
```

如果数据值已成功保存或更新，则状态代码将为`201 Created`，如果存在验证错误，则状态代码将为`409 Conflict`。

### 处理文件数据值 { #datavalue_file } 

处理具有 *file* 类型数据元素的数据值时
与上述方法存在一些偏差。这些数据
值的特殊之处在于值的内容是一个 UID 引用
到 *FileResource* 对象而不是自包含常量。这些
数据值的行为就像其他存储文本的数据值一样
内容，但应以不同方式处理以产生
有意义的输入和输出。

There are two methods of storing file resource data values.

* Upload the file to the `/api/dataValues/file` endpoint as
  described in the file resource section.  This works on versions 2.36 and later.

* If you are writing code that needs to be compatible
  with versions of DHIS2 before 2.36, then the process is:

1.  如所述将文件上传到 `/api/fileResources` 端点
    在文件资源部分。

2.  Retrieve the `id` property of the returned file resource.

3.  Store the retrieved identifier using the `value` property of the data value using any
    上面描述的方法。

数据值和文件资源之间只有一对一的关系
允许。这是在内部强制执行的，以便保存文件资源 ID
在多个数据值中是不允许的，并且会返回错误。删除
数据值将删除引用的文件资源。直接删除
的文件资源是不可能的。

数据值现在可以作为除返回数据以外的任何其他值进行检索
将是文件资源的 UID。为了检索实际
内容（意味着存储在映射的文件资源中的文件
到数据值）必须向 `/api/dataValues/files` 发出 GET 请求
镜像查询参数，因为它们将用于数据值
本身。 `/api/dataValues/files` 端点仅支持 GET 请求。

值得注意的是，由于底层存储机制工作
异步文件内容可能不会立即准备好
从`/api/dataValues/files` 端点下载。这是特别真实的
对于可能需要耗时上传的大文件
外部文件存储的背景（取决于系统
配置）。从文件资源元数据中检索
`/api/fileResources/ <id> ` 端点允许检查 `storageStatus`
在尝试下载内容之前。

## ADX数据格式 { #webapi_adx_data_format } 

From version 2.20 we have included support for an international standard
for aggregate data exchange called ADX. ADX is developed and maintained
by the Quality Research and Public Health committee of the IHE
(Integrating the HealthCare Enterprise). The wiki page detailing QRPH
activity can be found at
[wiki.ihe.net](http://wiki.ihe.net/index.php?title=Quality,_Research_and_Public_Health#Current_Domain_Activities).
ADX is still under active development and has now been published for
trial implementation. Note that what is implemented currently in DHIS2
is the functionality to read and write ADX formatted data, i.e. what is
described as Content Consumer and Content Producer actors in the ADX
profile.

ADX 数据消息的结构与您可能的结构非常相似
从前面描述的 DXF 2 数据中已经熟悉了。有一个
几个重要的区别。我们将描述这些差异
参考一个小例子：

```xml
<adx xmlns="urn:ihe:qrph:adx:2015" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="urn:ihe:qrph:adx:2015 ../schema/adx_loose.xsd" 
  exported="2015-02-08T19:30:00Z">
  <group orgUnit="OU_559" period="2015-06-01/P1M" 
    completeDate="2015-07-01" dataSet="(TB/HIV)VCCT">
    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
  </group>
</adx>
```

### The ADX root element { #the-adx-root-element } 

The ADX root element has only one mandatory attribute, which is the
*exported* timestamp. In common with other ADX elements, the schema is
extensible in that it does not restrict additional application specific
attributes.

### The ADX group element { #the-adx-group-element } 

Unlike dxf2, ADX requires that the datavalues are grouped according to
orgUnit, period and dataSet. The example above shows a data report for
the "(TB/HIV) VCCT" dataset from the online demo database. This example
is using codes as identifiers instead of dhis2 uids. Codes are the
preferred form of identifier when using ADX.

The orgUnit, period and dataSet attributes are mandatory in ADX. The
group element may contain additional attributes. In our DHIS2
implementation any additional attributes are simply passed through to
the underlying importer. This means that all attributes which currently
have meaning in dxf2 (such as completeDate in the example above) can
continue to be used in ADX and they will be processed in the same way.

A significant difference between ADX and dxf2 is in the way that periods
are encoded. ADX makes strict use of ISO8601 and encodes the reporting
period as (date|datetime)/(duration). So the period in the example above
is a period of 1 month (P1M) starting on 2015-06-01. So it is the data
for June 2015. The notation is a bit more verbose, but it is very
flexible and allows us to support all existing period types in DHIS2

### ADX期间定义 { #adx-period-definitions } 

Periods begin with the date in which the duration begins, followed by
a "/" and then the duration notation as noted in the table. The
following table details all of the DHIS2 period types and how they are
represented in ADX, along with examples.

Table: ADX Periods

| 期间类型 | Duration notation | Example(s) | Duration(s) |
|---|---|---|---|
| 日常 | P1D | 2017-10-01/P1M | Oct 01 2017 |
| Weekly | P7D | 2017-10-02/P7D | Oct 02 2017-Oct 08-2017 |
| Weekly Wednesday | P7D | 2017-10-04/P7D | Oct 04 2017-Oct 10-2017 |
| Weekly Thursday | P7D | 2017-10-05/P7D | Oct 05 2017-Oct 011-2017 |
| Weekly Saturday | P7D | 2017-10-07/P7D | Oct 07 2017-Oct 13-2017 |
| Weekly Sunday | P7D | 2017-10-01/P7D | Oct 01 2017-Oct 07-2017 |
| Bi-weekly | P14D | 2017-10-02/P14D | Oct 02 2017-Oct 15 2017 |
| Monthly | P1M | 2017-10-01/P1M | Oct 01 2017-Oct 31 2017 |
| 双月刊 | P2M | 2017-11-01/P2M | Nov 01 2017-Dec 31 2017 |
| Quarterly | P3M | 2017-09-01/P3M | Sep 01 2017-Dec 31 2017 |
| Six-monthly | P6M | 2017-01-01/P6M<br>2017-07-01/P6M | Jan 01 2017-Jun 30 2017<br>Jul 01 2017-Dec 31 2017 |
| Six-monthly April | P6M | 2017-04-01/P6M<br>2017-10-01/P6M | Apr 01 2017-Sep 30 2017<br>Oct 01 2017-Mar 31 2018 |
| Six-monthly November | P6M | 2017-10-01/P6M<br>2018-05-01/P6M | Nov 01 2017-Apr 30 2018<br>May 01 2018-Oct 31 2018 |
| Yearly | P1Y | 2017-01-01/P1Y | Jan 01 2017-Dec 31 2017 |
| Financial April | P1Y | 2017-04-01/P1Y | April 1 2017-Mar 31 2018 |
| Financial July | P1Y | 2017-07-01/P1Y | July 1 2017-June 30 2018 |
| Financial October | P1Y | 2017-10-01/P1Y | Oct 01 2017-Sep 30 2018 |
| Financial November | P1Y | 2017-11-01/P1Y | Nov 01 2017-Oct 31 2018 |

### ADX Data values { #adx-data-values } 

The dataValue element in ADX is very similar to its equivalent in DXF.
The mandatory attributes are *dataElement* and *value*. The *orgUnit* and
*period* attributes don't appear in the dataValue as they are required
at the *group* level.

The most significant difference is the way that disaggregation is
represented. DXF uses the categoryOptionCombo to indicate the disaggregation
of data. In ADX the disaggregations (e.g. AGE_GROUP and SEX) are
expressed explicitly as attributes. If you use `code` as the id scheme for
`category`, not that you must assign a code to all the categories used for
dataElements in the dataSet, and further, that code must be of a form
which is suitable for use as an XML attribute. The exact constraint on
an XML attribute name is described in the W3C XML standard - in practice,
this means no spaces, no non-alphanumeric characters other than '_' and
it may not start with a letter. The example above shows examples of
'good' category codes ('GENDER' and 'HIV_AGE'). The same restrictions
apply if you use `name` or `attribute` as id schemes.

In ADX, only category identifiers are used as XML attributes; identifiers
for other metadata types do not have to be usalbe as XML attributes.
Note that this syntax is not enforced by DHIS2 when you are assigning
names, codes, or DHIS2 attributes, but you will get an informative error
message if you try to import ADX data and the category identifiers are
either not assigned or not suitable.

使用分解数据的显式维度的主要好处是
那

  - 生成数据的系统不必与
    DHIS2 中的 categoryOptionCombo。

  - 生产者和消费者可以将他们的代码与第三方进行匹配
    权威来源，例如 vterminology 服务。请注意，在
    上面的性别和年龄组代码示例使用的是代码列表
    来自[世卫组织全球卫生观察站](http://apps.who.int/gho/data/node.resources.api)。

Note that this feature may be extremely useful, for example when
producing disaggregated data from an EMR system, but there may be cases
where a *categoryOptionCombo* mapping is easier or more desirable. The
DHIS2 implementation of ADX will check for the existence of a
*categoryOptionCombo* attribute and, if it exists, it will use that in
preference to exploded dimension attributes. Similarly, an
*attributeOptionCombo* attribute on the *group* element will be
processed in the legacy way. Otherwise, the attributeOptionCombo can be
treated as exploded categories just as on the *dataValue*.

In the simple example above, each of the dataElements in the dataSet
have the same dimensionality (categorycombo) so the data is neatly
rectangular. This need not be the case. dataSets may contain
dataElements with different categoryCombos, resulting in a
*ragged-right* ADX data message (i.e. values for different dataElements
may have different numbers of categories.)

### Importing ADX data { #importing-adx-data } 

DHIS2 exposes an endpoint for POST ADX data at `/api/dataValueSets`
using *application/xml+adx* as content type. So, for example, the
following curl command can be used to POST the example data above to the
DHIS2 demo server:

```bash
curl -u admin:district -X POST -H "Content-Type: application/adx+xml"
  -d @data.xml "https://play.dhis2.org/demo/api/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=code"
```

Note the query parameters are the same as are used with DXF data. The
ADX endpoint should interpret all the existing DXF parameters with the
same semantics as DXF.

### Exporting ADX data { #exporting-adx-data } 

DHIS2 exposes an endpoint to GET ADX data sets at `/api/dataValueSets`
using *application/xml+adx* as the accepted content type. So, for
example, the following curl command can be used to retrieve the ADX
data:

```bash
curl -u admin:district -H "Accept: application/adx+xml"
 "https://play.dhis2.org/demo/api/dataValueSets?dataValueSets?orgUnit=M_CLINIC&dataSet=MALARIA&period=201501"
```

Note the query parameters are the same as are used with DXF data. An
important difference is that the identifiers for dataSet and orgUnit may
be either uids or codes.

## 后续行动 { #webapi_follow_up } 

本节介绍了后续的标记数据。

### 数据值跟踪 { #data-value-follow-up } 

数据值跟踪端点允许标记数据值以进行跟踪。

```
PUT / api / 36 / dataValues /跟进
```

The payload in `JSON` format looks like this:

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "categoryOptionCombo": "psbwp3CQEhs",
  "attributeOptionCombo": "HllvX50cXC0",
  "followup": true
}
```

The `categoryOptionCombo` and `attributeOptionCombo` fields are optional. A minimal `JSON` payload looks like this:

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "followup": false
}
```

The `followup` field should be set to `true` to mark a data value for follow-up, and `false` to remove the mark.

如果操作成功，响应状态代码将为`200 OK`，如果请求出错，则响应状态代码为`409 Conflict`。

To bulk update data values for follow-up use:

    PUT /api/dataValues/followups

with `JSON` payload:

```json
{
  "values": [
    {
      "dataElement": "s46m5MS0hxu",
      "period": "202005",
      "orgUnit": "DiszpKrYNg8",
      "categoryOptionCombo": "psbwp3CQEhs",
      "attributeOptionCombo": "HllvX50cXC0",
      "followup": true
    }
  ]
}
```

Each item of the bulk update has the same fields and requirements as the single
update endpoint.

Bulk update equally confirms with a `200 OK` on success or returns a 
`409 Conflict` in case of input errors.



# 数据验证 { #data-validation } 

## 验证方式 { #webapi_validation } 

要生成数据验证摘要，您可以与
验证资源。数据集资源针对数据输入进行了优化
用于验证数据集/表单的客户端，可以像这样访问：

    GET /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

除了基于数据集验证规则外，还有两种
执行验证的其他方法：自定义验证和
预定验证。

第一个路径变量是引用数据集的标识符
证实。支持 XML 和 JSON 资源表示。这
响应包含违反验证规则。这将延长
在即将到来的版本中有更多的验证类型。

要检索与特定数据集相关的验证规则，
意思是所有数据元素都是一部分的带有公式的验证规则
的特定数据集，您可以向
`validationRules` 资源如下：

    GET /api/validationRules?dataSet=<dataset-id>

验证规则有左边和右边，也就是
根据运营商比较有效性。有效的运算符
值见下表。



Table: Operators

| 值 | 描述 |
|---|---|
| equal_to | Equal to |
| not_equal_to | Not equal to |
| greater_than | Greater than |
| greater_than_or_equal_to | Greater than or equal to |
| less_than | Less than |
| less_than_or_equal_to | Less than or equal to |
| compulsory_pair | If either side is present, the other must also be |
| exclusive_pair | If either side is present, the other must not be |

左边和右边的表达式是数学表达式
其中可以包含对数据元素和类别选项的引用
以下格式的组合：

    $ {<dataelement-id>。 <catoptcombo-id>}

左侧和右侧表达式有一个 *missing 值
战略*。这是指系统应该如何处理数据值
缺少数据元素/类别选项组合引用
在公式中是否应该检查验证规则
为有效性或跳过。有效的缺失值策略见于
下表。



Table: Missing value strategies

| 值 | 描述 |
|---|---|
| SKIP_IF_ANY_VALUE_MISSING | Skip validation rule if any data value is missing |
| SKIP_IF_ALL_VALUES_MISSING | Skip validation rule if all data values are missing |
| NEVER_SKIP | Never skip validation rule irrespective of missing data values |

## Validation results { #webapi_validation_results } 

验证结果是在执行期间发现的违规的持久结果
验证分析。如果您在开始时选择“持久结果”或
安排验证分析，发现的任何违规将存储在
数据库。当结果存储在数据库中时，它将被使用
对于 3 件事：

1.  根据存储的结果生成分析。

2.  未生成通知的持久结果将这样做，
    一次。

3.  跟踪结果是否产生了
    通知。

4.  跳过运行时已经检查过的规则
    验证分析。

这意味着如果你不坚持你的结果，你将无法
为验证结果生成分析，如果选中，结果将
每次找到并运行验证时生成通知
分析可能会更慢。

### Query validation results { #query-validation-results } 

持久化的验证结果可以在下面查看
端点：

    GET /api/33/validationResults

您还可以使用验证结果 ID 检查单个结果
在这个端点：

    GET /api/33/validationResults/<id>

验证结果也可以通过以下属性过滤：

* 组织单位：`ou = <UID>`
* 验证规则：`vr = <UID>`
* 期间：`pe = <ISO-expression>`

上面的每个过滤器属性可以多次出现，例如：

    GET /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

同一过滤器的多个值与OR组合，结果必须匹配给定值之一。

如果使用了一个以上的过滤器属性，则将它们与AND组合在一起，结果必须与每个属性的值之一匹配。

对于时段过滤器，匹配结果必须与任何指定的时段重叠。

此外，验证结果还可以按其创建日期进行过滤：

    GET /api/36/validationResults?createdDate=<date>

该过滤器可以与其他任何过滤器结合使用。

### Trigger validation result notifications { #trigger-validation-result-notifications } 

Validation results are sent out to the appropriate users once every day,
but can also be manually triggered to run on demand using the following
API endpoint:

    POST / api / 33 / validation / sendNotifications

使用此端点仅发送未发送的结果。

### Delete validation results { #delete-validation-results } 

验证结果可以通过ID手动删除，

    删除/ api / 36 / validationResults / <id>

或使用过滤器

    删除/ api / 36 / validationResults？ <filters>

Supported filter parameters include:

* `ou = <UID>`以匹配组织单位的所有验证结果；提供多个参数时，多个单元组合或
* `vr = <UID>`以匹配验证规则的所有验证结果；提供多个参数时，多个规则组合或
* `pe = <ISO-expression>`以匹配与与指定时期重叠的时期相关的所有验证结果
* `created = <ISO-expression>`以匹配在规定时间内创建的所有验证结果
* `notificationSent=<boolean>` to match either only validation results for which a notification was or wasn't sent

如果组合了过滤器，则所有条件都必须为真（AND逻辑）。

Some examples:

要删除 2020 年第一季度与 UID 为`NqwvaQC1ni4`的组织单位相关的所有验证结果，请使用：

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

要删除在2019年第1周创建的且已发送通知的所有验证结果，请使用：

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

Any delete operation will require the authority _Perform maintenance tasks_.


## 离群值检测 { #outlier-detection } 

The outlier detection endpoint allows for detecting outliers in aggregate data values.

```
GET / api / 36 / outlierDetection
```

该端点支持两种用于检测离群值的算法：

* ** Z分数：** Z分数定义为分数与平均值之间的绝对偏差除以标准偏差。必须使用z分数算法指定一个阈值参数，该阈值参数表示与平均值之间的标准偏差，以定义异常值的上限和下限。
* **Modified Z-score:** Same as z-score except it uses the median instead of the mean as measure of central tendency. Parameters are same as for Z-score.
* ** Min-max：** Min-max数据元素值是指可以根据数据元素，组织单位和类别选项组合插入DHIS 2的自定义边界。

离群值将*根据显着性*排序，默认情况下是与均值的绝对偏差，最高有效值在前。这有助于快速识别对数据质量和数据分析影响最大的离群值。

### 请求查询参数 { #request-query-parameters } 

支持以下查询参数。

| 查询参数 | 描述                                                  | 强制的 | 选项（默认为默认）                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | 数据集，可以多次指定。                   | 不 [*]    | 数据集标识符。                      |
| 德              | 数据元素，可以多次指定。               | 不 [*]    | 数据元素标识符。                  |
| 开始日期       | 间隔的开始日期，以检查异常值。               | 是的       | 日期（yyyy-MM-dd）。                        |
| 结束日期         | 检查异常值的时间间隔的结束日期。                 | 是的       | 日期（yyyy-MM-dd）。                        |
| 欧              | 组织单位，可以多次指定。          | 是的       | 组织单位标识符。             |
| 算法       | 用于离群值检测的算法。                      | 不        | `Z_SCORE`, `MIN_MAX`, `MOD_Z_SCORE`       |
| 临界点       | Threshold for outlier values. `Z_SCORE` and `MOD_Z_SCORE` algorithm only. | 不        | 数值，大于零。默认值：3.0。 |
| dataStartDate   | Start date for interval for mean and std dev calculation. `Z_SCORE` and `MOD_Z_SCORE` algorithm only. | 不        | 日期（yyyy-MM-dd）。 |
| dataEndDate     | End date for interval for mean and std dev calculation. `Z_SCORE` and `MOD_Z_SCORE` algorithm only. | 不        | 日期（yyyy-MM-dd）。   |
| 订购         | Field to order by. `Z_SCORE` and `MOD_Z_SCORE`algorithm only.| 不        | `MEAN_ABS_DEV`，`Z_SCORE`                 |
| maxResults      | 输出的最大限制。                                    | 不        | 整数，大于零。默认值：500。 |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.

必须定义至少一个数据集或数据元素，开始日期和结束日期以及至少一个组织单位。

The `startDate` and `endDate` parameters are mandatory and refer to the time interval for which you want to detect outliers. The `dataStartDate` and `dataEndDate` parameters are optional and refer to the time interval for the data to use when calculating the mean and std dev, which are used to eventually calculate the z-score.

### Usage and examples { #usage-and-examples } 

使用默认的z分数算法获取异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆ou = fdc6uOvgoji＆startDate = 2020-01-01＆endDate = 2020-12-31
```

使用特定算法和特定阈值获取异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆algorithm = Z_SCORE＆threshold = 2.5
```

获取按z分数排序的异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆orderBy = Z_SCORE
```

获取前10个离群值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆maxResults = 10
```

获取具有定义间隔的离群值，以供在计算均值和标准差开发数据时使用的数据：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆dataStartDate = 2018-01-01＆dataEndDate = 2020-12-31
```

使用最小-最大算法获取离群值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆ou = fdc6uOvgoji＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆algorithm = MIN_MAX
```

### 回应格式 { #response-format } 

支持以下响应格式。

| 格式 | API格式                                                   |
| ------ | ------------------------------------------------------------ |
| JSON格式   | `/ api / 36 / outlierDetection.json`或`Accept：application / json`（默认格式） |
| CSV    | `/ api / 36 / outlierDetection.csv`或`接受：application / csv`  |

响应包含以下字段：

| 领域      | 描述                                                  |
| ---------- | ------------------------------------------------------------ |
| 德         | 数据元素标识符。                                     |
| 取消命名     | 数据元素名称。                                           |
| 聚乙烯         | 期间ISO标识符。                                       |
| 欧         | 组织单位标识符。                                |
| ouName     | 组织单位名称。                                      |
| 可可        | 类别选项组合标识符。                      |
| cocName    | 类别选项组合名称。                            |
| 冠捷        | 属性选项组合标识符。                     |
| aocName    | 属性选项组合名称。                           |
| 价值      | 数据值。                                                  |
| 意思是       | 时间维度中数据值的平均值。                   |
| 标准差     | 标准偏差。                                          |
| 绝对值     | 对于z得分，与均值的绝对偏差。对于最小-最大，与最小或最大边界的绝对偏差。 |
| 分数     | Z分数。仅Z分数算法。                         |
| 下界 | 下边界。                                          |
| 上限 | 上限。                                          |
| 跟进   | 数据值是否标记为后续。                  |

The `mean`, `stdDev` and `zScore` fields are only present when `algorithm` is `Z_SCORE`.

响应将与此类似。 `元数据`部分包含请求和响应的元数据。 `outlierValues` 部分包含异常值。

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### 约束与验证 { #constraints-and-validation } 

在查询验证期间，以下约束适用。每个验证错误都有一个对应的错误代码。

| 错误代码 | 信息                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | 必须至少指定一个数据元素                  |
| E2201      | 必须指定开始日期和结束日期                    |
| E2202      | 开始日期必须早于结束日期                           |
| E2203      | 必须至少指定一个组织单位             |
| E2204      | 阈值必须为正数                          |
| E2205      | 最高结果必须为正数                        |
| E2206      | 最大结果超出了允许的最大限制：{d}               |
| E2207      | 数据开始日期必须早于数据结束日期                 |
| E2208      | 离群值检测期间遇到的非数字数据值 |

## 数据分析 { #webapi_data_analysis } 

用于执行数据分析和查找数据质量的多种资源
并提供验证问题。

**注意：**不建议使用此端点，该端点将在2.38中删除。请改用`outlierAnalysis`端点。

### 验证规则分析 { #webapi_data_analysis_validation_rules } 

要运行验证规则并检索违规：

    GET /api/dataAnalysis/validationRules

支持以下查询参数：



Table: Validation rule analysis query parameters

| 查询参数 | 描述 | 选项 |
|---|---|---|
| vrg | Validation rule group | ID |
| 欧 | 组织单位 | ID |
| 开始日期 | Start date for the timespan | 日期 |
| 结束日期 | End date for the timespan | 日期 |
| persist | Whether to persist violations in the system | false &#124; true |
| notification | Whether to send notifications about violations | false &#124; true |

样本输出：
```json
    [{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### 基于标准差的离群分析 { #webapi_data_analysis_std_dev_outlier } 

根据平均值的标准偏差识别数据异常值
价值：

    GET /api/dataAnalysis/stdDevOutlier

支持以下查询参数：



Table: Standard deviation outlier analysis query parameters

| 查询参数 | 描述 | 选项 |
|---|---|---|
| 欧 | 组织单位 | ID |
| 开始日期 | Start date for the timespan | 日期 |
| 结束日期 | End date for the timespan | 日期 |
| ds | Data sets, parameter can be repeated | ID |
| standardDeviation | Number of standard deviations from the average | Numeric value |

### 基于最小值/最大值的离群值分析 { #webapi_data_analysis_min_max_outlier } 

要基于最小/最大值来识别数据离群值：

    GET /api/dataAnalysis/minMaxOutlier

支持的查询参数等于基于 *std dev 的异常值
上面描述的分析*资源。

### 后续数据分析 { #follow-up-data-analysis } 

要识别标记为后续的数据：

    GET /api/dataAnalysis/followup

At least one data set or data element, start date and end date or period, and at least one organisation unit must be defined.

支持以下查询参数。

| Parameter  | 描述                                                  | 强制的 | 选项（默认为默认）                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| 欧         | 组织单位，可以多次指定。          | 是的       | 组织单位标识符。             |
| ds         | 数据集，可以多次指定。                   | 不 [*]    | 数据集标识符。                      |
| 德         | 数据元素，可以多次指定。               | 不 [*]    | 数据元素标识符。                  |
| 开始日期  | 间隔的开始日期，以检查异常值。               | 不 [*]    | 日期（yyyy-MM-dd）。                        |
| 结束日期    | 检查异常值的时间间隔的结束日期。                 | 不 [*]    | 日期（yyyy-MM-dd）。                        |
| 聚乙烯         | ISO period ID.                                               | 不 [*]    | Period ISO ID.                        |
| peType     | ISO period.                                                  | 不 [*]    | Period ISO string.                        |
| 可可        | Category option combos, can be specified multiple times.     | 不        | Category option combo identifier.         |
| maxResults | 输出的最大限制。                                    | 不        | Integer, greater than zero. Default: 50.  |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.
     Equally, either `startDate` and `endDate` _or_ `period` must be specified.

The `startDate` and `endDate` parameters refer to the time interval for which you want to detect outliers.
If a period `pe` is provided instead the interval start and end is that of the period.

如果未提供选项组合`coc`，则考虑所有数值类型的数据元素。


## 数据的完整性 { #webapi_data_integrity } 

The data integrity capabilities of the data administration module are
available through the web API. This section describes how to run the
data integrity process and retrieve the results. The specific
details regarding each check are described in the user manual.

### Listing the available data integrity checks { #webapi_data_integrity_list }
A description of the available checks is returned by a request to:

    GET /api/dataIntegrity

```
[
    {
        "name": "data_elements_without_groups",
        "displayName": "Data elements lacking groups",
        "section": "Data Elements",
        "severity": "WARNING",
        "description": "Lists all data elements that have no data element groups",
        "issuesIdType": "dataElements",
        "isSlow": false
    }
]
```

The `name` member of the returned check elements is the identifier used for the
`checks` parameter to declare the set of checks to run.

> **Note**
> 
> Each check will indicate whether it may require significant time and resources to complete with the `isSlow` field. 
> Users should be cautious about running these
> checks on production systems as they could lead to decreased performance. 
> These checks can be run individually, but will 
> not be run unless specifically requested.

Checks are grouped semantically by the `section` member and categorised in 
one of four `severity` levels:

| Severity | 描述                                                                                                                   |
| -------- |-------------------------------------------------------------------------------------------------------------------------------|
| INFO     | Indicates that this is for information only.                                                                                  |
| WARNING  | A warning indicates that this may be a problem, but not necessarily an error. It is however recommended to triage these issues. |
| SEVERE   | An error that should be fixed but which may not necessarily lead to the system not functioning.                               |
| CRITICAL | An error that must be fixed and which may lead to end-user error or system crashes.                                           |

The available checks can be filtered using the `checks` parameter.

    GET /api/dataIntegrity?checks=<pattern1>,<pattern2>

One or more exact names or patterns using `*` as a wildcard can be provided.

Additional results can be filtered using a `section` parameter.

    GET /api/dataIntegrity?section=Categories

The `section` filter will return all exact matches which have the specified section. 

Furthermore, to filter (select) only checks marked as `isSlow` use `slow=true`,

    GET /api/dataIntegrity?slow=true

or to filter (select) only checks that are not performed via database query 
(programmed checks) use `programmatic=true`:

    GET /api/dataIntegrity?programmatic=true

The `slow`, `programmatic` and `section` filters can be combined in which case
all conditions must be met.

### Running data integrity summaries { #webapi_data_integrity_run_summary }

Since version 2.38, data integrity checks have two levels of specificity: 
- a `summary` level that provides an overview of the number of issues
- a `details` level that provides a list of issues pointing to individual data integrity violations.

To trigger a summary analysis for a set of checks run:

    POST /api/dataIntegrity/summary?checks=<name1>,<name2>

This triggers a job that runs the check(s) asynchronously. Individual check results
will be returned to the application cache as soon as the check has completed.

Alternatively the list of checks can also be given as BODY of the POST request.
This can be useful if the list becomes to long to be used in the URL.

To fetch the data integrity summary of the triggered check(s) use:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>

When the `checks` parameter is omitted, all checks are fetched from the server cache.

The response is a "map" of check results, one for each check that has completed already.
This information is cached for one hour or until the check is rerun.

To wait for the summary to be available in the cache a `timeout` in milliseconds can be added:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>&timeout=500

An example of a summary response could look like: 
```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 12,
    "percentage": 2.3
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 4,
    "percentage": 5.1
  }
}
```

Each summary response will contain the `name`, `section`, `severity`, 
`description` and optionally  an `introduction` and `recommendation`.  
Each summary contains the number of issues found in the `count` field. When possible,
an optional `percentage` field will provide the percentage of objects with data
integrity issues when compared to all objects of the same type.
The `startTime` field indicates when the check was initiated. Using the `finishedTime`
the duration which was required to execute the check can be calculated.

Should a check analysis fail due to programming error or unforeseen data inconsistencies
both the summary and the details will have an `error` field describing the error that occurred.
The `count` of any checks which failed will be set to -1. 
No `percentage` will be returned in such cases.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "error": "what has happened",
    "issues": []
  }
}
```

> **Note**
> 
> Each metadata check is run asynchronously on the server.  Results
> will be returned as soon as each check completes. The safest way to ensure 
> that you have retrieved the latest set of results which has been 
> requested is to compare the timestamp of when the request was made
> with the `finishedTime` in the response.

To get a list of the names of checks that are currently being performed by the 
server use:

    GET /api/dataIntegrity/summary/running

To get a list of the names of checks for which results are available already use:

    GET /api/dataIntegrity/summary/completed


### Running data integrity details { #webapi_data_integrity_run_details }

To run a selection of details checks first trigger them using a  `POST` request:

    POST /api/dataIntegrity/details?checks=<name1>,<name2>

Similar to the summary the list of checks can also be given as the POST body.

Then fetch the results from the cache using:

    GET /api/dataIntegrity/details?checks=<name1>,<name2>&timeout=500

When the `checks` parameter is not provided,  all checks which 
have not been marked as `isSlow` will be scheduled to be run on the server.

Omitting the `timeout` will not wait for results to be found in the cache, 
but instead not have a result for the requested check.

The `/details` response returns a map similar to the `summary`, but does not contain
a `count` or `percentage`. Instead, a list of `issues` is returned.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": [{
      "id": "<id-or-other-identifier>",
      "name": "<name-of-the-id-obj>",
      "comment": "optional plain text description or hint of the issue",
      "refs": ["<id1>", "<id2>"]
    }]
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": []
  }
}
```
Each issue will always have `id` and `name` members.  Often the `issuesIdType`
is available to indicate the type of objects the `id` refers to. If the 
`issuesIdType` is not available, the `id` often is not available either and the
`name` is used for an aggregate key of an issue that has no object equivalent.

The `comment` and `refs` fields are optional for each issue.
A `comment` may provide more context or
insight into why this particular issue is regarded to be a data integrity problem. 
The `refs` list may also give the identifiers of other objects that contributed to the violation.
The `finishedTime` field shows when the particular check finished processing on the server.
The cache will store the result of each completed check for one hour.

> **Tip**
>
> A set of checks can also be specified using wild-cards. To include all 
> checks with _element_ in the name use `checks=*element*`. Like full names 
> such patterns can be used in a comma-separated list and be mixed with full 
> names as well. Duplicates will be eliminated. 
> Also a check can be given by its code. A code consists of the first letters
> of each word in the name as upper case letter. 
> For example, `orgunits_invalid_geometry` has the code `OIG`.

Similar to the summary a set of names of the currently performed and the
already completed details checks can be obtained using:

    GET /api/dataIntegrity/details/running
    GET /api/dataIntegrity/details/completed

### Custom Data Integrity Checks { #custom_data_integrity_checks } 

Users of DHIS2 can now create and supply their own Data Integrity Checks. This can be useful if users
want to avail of this functionality and extend upon the supplied set of core data integrity checks.

> **Tip**
> 
> Users are also encouraged to share their custom checks with others by opening a pull request in the 
> [dhis2-core](https://github.com/dhis2/dhis2-core) repository containing their `.yaml` file(s).
> Please select `platform-backend` as reviewer to put the PR on our radar early on. The team will 
> take care of checking and linking the check correctly, so it becomes part of the provided suite of 
> checks with the next release. 

An example of a custom check could be for determining if certain users are members of specific user groups.
This type of check would be very specific to an implementation, and not generally applicable across all installs.
These types of metadata checks can be used to extend the default checks which are included with DHIS2.

Custom checks can be implemented by satisfying the following requirements, each of which we will go into detail:
- Supplying your own list of custom data integrity checks in a list file named `custom-data-integrity-checks.yaml`
 in your `DHIS2_HOME` directory
- Having a directory named `custom-data-integrity-checks` in your `DHIS2_HOME` directory
- Supplying your valid custom data integrity check yaml files

#### Custom Data Integrity Check List File { #custom-data-integrity-check-list-file } 

DHIS2 will only try to load data integrity files when they are needed. e.g. when making a call to view all
data integrity checks:

    GET /api/dataIntegrity

DHIS2 will look for a file named `custom-data-integrity-checks.yaml` in your `DHIS2_HOME` directory when loading
data integrity files. If you are not using custom checks and the file is not present, a warning log like this will
be present:

```text
08:29:57.729  WARN o.h.d.d.DataIntegrityYamlReader: Failed to load data integrity check from YAML. Error message `{DHIS2_HOME}/custom-data-integrity-checks.yaml (No such file or directory)
```

If you are implementing custom data integrity checks then this file must be present. To see what the core data integrity checks
file looks like as an example, check out [this file](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks.yaml).


The `custom-data-integrity-checks.yaml` file should list all of your custom data integrity checks.
As an example, it could look something like this:

```yaml
checks:
  - categories/my_custom_check.yaml
  - users/my_user_group_check.yaml
  - base_check.yaml
```

Check names in this file can be preceded with a directory name for logical grouping. From the 3 example checks listed 
above, the directory structure should look like this:

```
├── DHIS2_HOME
│   ├── dhis.conf
│   ├── custom-data-integrity-checks.yaml
│   ├── custom-data-integrity-checks
│   │   ├── categories
│   │   │   ├── my_custom_check.yaml
│   │   ├── users
│   │   │   ├── my_user_group_check.yaml
│   │   ├── base_check.yaml
```

#### Name and Code constraints { #name-and-code-constraints } 

Each data integrity check `name` and `code` must be unique. If there are any clashes then the violating custom
check will not be loaded.

> **Note**
>
> System data integrity checks are always loaded first. Any name or code clashes resulting from
> custom checks will not affect these core system checks.

An example data integrity check yaml file is located [here](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks/orgunits/orgunits_orphaned.yaml)
for reference. Note the `name` property.

The data integrity `code` is calculated dynamically by using the first letter of each word in the `name`. Some examples:

| 名称                   | 码 |
|------------------------|------|
| my_custom_check        | MCC  |
| my_second_custom_check | MSCC |
| another_custom_check   | ACC  |

If there is a `name` clash, a warning log like this will be present:
```text
09:48:43.138  WARN o.h.d.d.DefaultDataIntegrityService: Data Integrity Check `my_custom_check` not added as a check with that name already exists
```

If there is a `code` clash, a warning log like this will be present:
```text
09:48:43.138  WARN o.h.d.d.DefaultDataIntegrityService: Data Integrity Check `my_custom_check` not added as a check with the code `MCC` already exists
```

#### Data Integrity Check Schema { #data-integrity-check-schema } 

A data integrity check file must comply with this [JSON schema](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks/integrity_check_schema.json).
If a check does not comply with the schema then a warning like this will be present:
```text
09:48:43.136  WARN o.h.d.d.DataIntegrityYamlReader: JsonSchema validation errors found for Data Integrity Check `categories/my_custom_check.yaml`. Errors: [$.name: is missing but it is required]
```

Any schema violations must be fixed before that check can be loaded and used.

If a data integrity check file contains invalid yaml then a warning log like this could be present:
```text
10:30:37.858  WARN o.h.d.d.DataIntegrityYamlReader: JsonSchema validation errors found for Data Integrity Check `my_custom_check.yaml`. Errors: [$: string found, object expected]
```

To view and use the custom checks please refer to the main [Data Integrity section](#webapi_data_integrity)

> **Note**
>
> It is recommended to follow any naming and format conventions seen in the provided examples above when implementing
> your own custom checks to help avoid any issues

#### Data Integrity File { #data-integrity-file } 

Details of the data integrity check yaml file, taken from the JSON schema file

| property        | required | info                                                                                                                          |
|-----------------|----------|-------------------------------------------------------------------------------------------------------------------------------|
| 名称            | yes      | unique name of the check                                                                                                      |
| 描述     | yes      | 描述                                                                                                                   |
| section         | yes      | used for logical grouping of checks e.g. categories, users                                                                    |
| section_order   | yes      | the order of the check when displayed in the UI                                                                               |
| summary_sql     | yes      | an SQL query which should return a single result which represents the total count of issues                                   |
| details_sql     | yes      | an SQL query which should return a list of identified objects from this particular issue. Should return at least uid and name |
| details_id_type | yes      | a short string which identifies the section of the details SQL                                                                |
| severity        | yes      | level of severity of the issue. One of [INFO, WARNING, SEVERE, CRITICAL]                                                      |
| introduction    | yes      | outlining the objective of the check                                                                                          |
| recommendation  | yes      | outlining how to resolve identified issues                                                                                    |

### Example custom data integrity check { #example-custom-data-integrity-check } 


An example of a custom check could be for determining if users have an email. Emails are useful to be
able to communicate with users and sent them notifications, as well as password recovery. So, in some
instllations of DHIS2, it could be a policy that all users should have emails. An example of this type
of custom check is shown below.

```
---
name: users_should_have_emails
description: Users should have emails.
section: Users
section_order: 6
summary_sql: >-
  WITH users_no_email as (
  SELECT uid,username from
  userinfo where email IS NULL)
  SELECT COUNT(*) as value,
  100*COUNT(*) / NULLIF( ( select COUNT(*) from userinfo), 0) as percent
  from users_no_email;
details_sql: >-
  WITH users_no_email as (
  SELECT uid,username from
  userinfo where email IS NULL)
  SELECT uid,username as from users_no_email;
severity: WARNING
introduction: >
  Users should have defined emails. This is important for password recovery and to be able
  to send notifications to users.
recommendation: >
  Make sure that all users have defined emails.
details_id_type: users
```

More examples of different types of metadata integrity checks can be found in the DHIS2 source code [here](https://github.com/dhis2/dhis2-core/tree/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks).

## 完整的数据集注册 { #webapi_complete_data_set_registrations }

本节是关于数据集的完整数据集注册。一种
注册标记作为完全捕获的数据集。

### 完成数据集 { #webapi_completing_data_sets }

本节说明如何将数据集注册为完整。这是
通过与 *completeDataSetRegistrations* 交互实现
资源：

    GET /api/33/completeDataSetRegistrations

端点支持*POST*方法注册数据集
完成。端点在功能上非常类似于
*dataValueSets* 端点，支持批量导入完整
注册。

支持导入 *XML* 和 *JSON* 格式的有效负载。这
这个有效负载的基本格式，在这个例子中以 *XML* 给出，就像
所以：

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP" 
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP" 
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

*storedBy* 属性是可选的（因为它是
完整的注册对象）。您还可以选择设置
*date* 属性（注册时间）作为属性。是时候了
未设置，将使用当前时间。

导入过程支持以下查询参数：



Table: Complete data set registrations query parameters

| Parameter | Values | 描述 |
|---|---|---|
| dataSetIdScheme | id &#124; name &#124; code &#124; attribute:ID | Property of the data set to use to map the complete registrations. |
| orgUnitIdScheme | id &#124; name &#124; code &#124; attribute:ID | Property of the organisation unit to use to map the complete registrations. |
| attributeOptionComboIdScheme | id &#124; name &#124; code &#124; attribute:ID | Property of the attribute option combos to use to map the complete registrations. |
| 方案 | id &#124; name &#124; code &#124; attribute:ID | Property of all objects including data sets, org units and attribute option combos, to use to map the complete registrations. |
| preheatCache | false &#124; true | Whether to save changes on the server or just return the import summary. |
| dryRun | false &#124; true | Whether registration applies to sub units |
| importStrategy | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | Save objects of all, new or update import status on the server. |
| skipExistingCheck | false &#124; true | Skip checks for existing complete registrations. Improves performance. Only use for empty databases or when the registrations to import do not exist already. |
| async | false &#124; true | Indicates whether the import should be done asynchronous or synchronous. The former is suitable for very large imports as it ensures that the request does not time out, although it has a significant performance overhead. The latter is faster but requires the connection to persist until the process is finished. |

The `idScheme`, `dataSetIdScheme`, `orgUnitIdScheme`, `attributeOptionComboIdScheme`, 
`dryRun` and `strategy` (note the dissimilar naming to parameter `importStrategy`) 
can also be set as part of the payload.
In case of XML these are attributes, in case of JSON these are members in the
`completeDataSetRegistrations` node.

例如：
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

Should both URL parameter and payload set a scheme the payload takes precedence. 

### 读取完整的数据集注册 { #webapi_reading_complete_data_sets } 

本节说明如何检索数据集完整性
注册。我们将使用 *completeDataSetRegistrations*
资源。要使用的查询参数如下：



Table: Data value set query parameters

| Parameter | 描述 |
|---|---|
| dataSet | Data set identifier, multiple data sets are allowed |
| period | Period identifier in ISO format. Multiple periods are allowed. |
| 开始日期 | Start date for the time span of the values to export |
| 结束日期 | End date for the time span of the values to export |
| created | Include only registrations which were created since the given timestamp |
| createdDuration | Include only registrations which were created within the given duration. The format is <value\><time-unit\>, where the supported time units are "d", "h", "m", "s" *(days, hours, minutes, seconds).* The time unit is relative to the current time. |
| orgUnit | Organisation unit identifier, can be specified multiple times. Not applicable if orgUnitGroup is given. |
| orgUnitGroup | Organisation unit group identifier, can be specified multiple times. Not applicable if orgUnit is given. |
| children | Whether to include the children in the hierarchy of the organisation units |
| limit | The maximum number of registrations to include in the response. |
| 方案 | Identifier property used for meta data objects in the response. |
| dataSetIdScheme | Identifier property used for data sets in the response. Overrides idScheme. |
| orgUnitIdScheme | Identifier property used for organisation units in the response. Overrides idScheme. |
| attributeOptionComboIdScheme | Identifier property used for attribute option combos in the response. Overrides idScheme. |
The `dataSet` and `orgUnit` parameters can be repeated in order to include multiple data sets and organisation units.

The `period`, `startDate`,  `endDate`, `created` and `createdDuration` parameters provide multiple ways to set the time dimension for the request, thus only
one can be used. For example, it doesn't make sense to both set the start/end date and to set the periods.

请求示例如下所示：

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

您可以获得 *xml* 和 *json* 格式的响应。你可以指出
通过 *Accept* HTTP 标头，您更喜欢哪种响应格式
在上面的例子中。对于 xml，您使用 *application/xml*；对于 json 你
使用*应用程序/json*。

### 未完成的数据集 { #webapi_uncompleting_data_sets } 

本节说明如何取消注册数据的完整性
放。要取消完成数据集，您将与
completeDataSetRegistrations 资源：

    GET /api/33/completeDataSetRegistrations

此资源支持*DELETE* 取消注册。以下查询
支持参数：



Table: Complete data set registrations query parameters

| 查询参数 | 需要 | 描述 |
|---|---|---|
| ds | 是的 | Data set identifier |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | Organisation unit identifier |
| cc | No (must combine with cp) | Attribute combo identifier (for locking check) |
| cp | No (must combine with cp) | Attribute option identifiers, separated with ; for multiple values (for locking check) |
| multiOu | No (default false) | Whether registration applies to sub units |



# 数据审批 { #data-approval } 

## 数据审批 { #webapi_data_approval } 

本节说明如何批准、取消批准和检查批准
使用 *dataApprovals* 资源的状态。批准是按数据完成的
审批工作流、期间、组织单位和属性选项组合。

    /api/33/dataApprovals

数据批准工作流与多个实体相关联：

* 定义批准频率的期间类型
* 可选类别组合
* 工作流程中的一个或多个数据批准级别
* 一个或多个用于数据收集的数据集

### 获取批准状态 { #webapi_data_approval_get_status } 

要获取数据集的批准信息，您可以发出GET请求：

    / api / dataApprovals？wf = rIUL3hYOjJc＆pe = 201801＆ou = YuQRtpLP10I



Table: Data approval query parameters

| 查询参数 | 需要 | 描述 |
|---|---|---|
| wf | 是的 | 数据批准工作流标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | Organisation unit identifier |
| 冠捷 | 不 | 属性选项组合标识符 |

> **注意**
>
> 为了向后兼容，在此和其他数据批准请求中，可能会为数据集提供参数`ds`而不是`wf`，如下所述。如果给出了数据集，则将使用与该数据集关联的工作流。

这将产生类似于以下的响应：

```json
{
  "mayApprove": false,
  "mayUnapprove": false,
  "mayAccept": false,
  "mayUnaccept": false,
  "state": "APPROVED_HERE",
  "approvedBy": "User A",
  "approvedAt": "2022-01-13T12:56:07.005",
  "acceptedBy": "User A",
  "acceptedAt": "2022-01-13T12:56:07.005"
}
```

返回的参数是：

Table: Data approval returned parameters

| 返回参数 | 描述 |
|---|---|
| mayApprove        | Whether the current user may approve this data selection. |
| mayUnapprove      | Whether the current user may unapprove this data selection. |
| mayAccept         | Whether the current user may accept this data selection. |
| mayUnaccept       | Whether the current user may unaccept this data selection. |
| 州             | One of the data approval states from the table below. |
| approvedBy        | If the selection is approved, and if present (not always needed), the user's name who made this approval. |
| approvedAt        | If the selection is approved, and if present (not always needed), the date and time at which the highest level of approval was created. |
| acceptedBy        | If the selection is approved, and if present (not always needed), the user's name who made the last update. |
| acceptedAt        | If the selection is approved, and if present (not always needed), the date and time at which the highest level of approval was last updated. |


Table: Data approval states

| State | 描述 |
|---|---|
| UNAPPROVABLE | Data approval does not apply to this selection. (Data is neither approved nor unapproved.) |
| UNAPPROVED_WAITING | Data could be approved for this selection, but is waiting for some lower-level approval before it is ready to be approved. |
| UNAPPROVED_ELSEWHERE | Data is unapproved, and is waiting for approval somewhere else (not approvable here.) |
| UNAPPROVED_READY | Data is unapproved, and is ready to be approved for this selection. |
| APPROVED_HERE | Data is approved, and was approved here (so could be unapproved here.) |
| APPROVED_ELSEWHERE | Data is approved, but was not approved here (so cannot be unapproved here.) This covers the following cases: <br> * Data is approved at a higher level.<br> * Data is approved for wider scope of category options.<br> * Data is approved for all sub-periods in selected period.<br>  In the first two cases, there is a single data approval object that covers the selection. In the third case there is not. |
| ACCEPTED_HERE | Data is approved and accepted here (so could be unapproved here.) |
| ACCEPTED_ELSEWHERE | Data is approved and accepted, but elsewhere. |

注意查询数据审批状态时，可以指定
查询参数的任意组合。您指定的组合
不需要描述数据被批准的地方
审批级别。例如：

  - 组织单位可能不在审批级别。这
    批准状态取决于数据是否在某个时间被批准
    组织单位上级的批准级别。

  - 您可以指定单个属性类别选项。批准
    状态取决于数据是否被批准用于属性
    包含其中一项或多项的类别选项组合
    选项。

  - 您可以指定一个时间段，该时间段长于
    数据输入和批准的数据集。批准
    状态取决于数据是否被批准用于所有
    指定期间内的数据集期间。

对于与您可能需要的类别组合关联的数据集
获取单个属性选项组合的数据批准记录
从具有 GET 请求的以下资源：

    /api/dataApprovals/categoryOptionCombos?wf=rIUL3hYOjJc&pe=201801&ou=YuQRtpLP10I

### 批量获取批准状态 { #bulk-get-approval-status } 

要获取多个批准状态的列表，可以发出类似于以下内容的GET请求：

    /api/dataApprovals/approvals?wf=rIUL3hYOjJc&pe=201801,201802&ou=YuQRtpLP10I

参数 `wf`、`pe`、`ou` 和 `aoc` 与获取单个批准状态的参数相同，但您可以为每个参数提供一个以逗号分隔的一个或多个值的列表。

这将为您提供一个包含批准参数和状态列表的响应，如下所示：

```json
[
  {
    "aoc": "HllvX50cXC0",
    "pe": "201801",
    "level": "KaTJLhGmU95",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "mayApprove": false,
      "mayUnapprove": true,
      "mayAccept": true,
      "mayUnaccept": false,
      "mayReadData": true,
      "approvedBy": "User A",
      "approvedAt": "2022-01-13T12:56:07.005",
      "acceptedBy": "User A",
      "acceptedAt": "2022-01-13T12:56:07.005"      
    },
    "state": "APPROVED_HERE",
    "wf": "rIUL3hYOjJc"
  },
  {
    "aoc": "HllvX50cXC0",
    "pe": "201802",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "mayApprove": true,
      "mayUnapprove": false,
      "mayAccept": false,
      "mayUnaccept": false,
      "mayReadData": true
    },
    "state": "UNAPPROVED_READY",
    "wf": "rIUL3hYOjJc"
  }
]
```

下表描述了返回的字段。

| 领域       | 描述 |
| ----------- | ----------- |
| 冠捷         | 属性选项组合标识符 |
| 聚乙烯          | 期间标识符 |
| 欧          | 组织单位标识符 |
| 权限 | The permissions: same definitions as for get single approval status (see table _Data approval returned parameters_) . |
| 州       | 数据批准状态之一（与获取单个批准状态相同）。 |
| wf          | 数据批准工作流标识符 |

### 批准数据 { #webapi_data_approval_approve_data } 

要批准数据，您可以向 *dataApprovals* 发出 *POST* 请求
资源。要取消批准数据，您可以发送*DELETE*请求到数据批准资源。

    POST DELETE /api/33/dataApprovals

要接受已经批准的数据，您可以发出 *POST* 请求
到 *dataAcceptances* 资源。要取消接受数据，您可以发出
*DELETE* 对 *dataAcceptances* 资源的请求。

    POST DELETE /api/33/dataAcceptances

这些请求包含以下参数：



Table: Data approval action parameters

| Action parameter | 需要 | 描述 |
|---|---|---|
| wf | 是的 | 数据批准工作流标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | Organisation unit identifier |
| 冠捷 | 不 | 属性选项组合标识符 |

注意，与查询数据审批状态不同，必须指定
对应于可以选择的数据的参数
得到正式认可的。特别是，以下两项都必须为真：

  - 组织单位的级别必须由审批级别指定
    在工作流程中。

  - 指定的时间段必须与
    工作流程。

### 批量批准数据 { #webapi_data_approval_bulk_approve_data } 

您可以通过发布到批准大量数据记录
`/api/dataApprovals/approvals` 资源。

    POST /api/33/dataApprovals/approvals

您可以通过发布到
`/api/dataApprovals/unapprovals` 资源。

    POST /api/33/dataApprovals/unapprovals

您可以通过发布到
`/api/dataAcceptances/acceptances` 资源。

    POST /api/33/dataAcceptances/acceptances

您可以通过发布到
`/api/dataAcceptances/unacceptances` 资源。

    POST /api/33/dataAcceptances/unacceptances

批准有效负载受JSON支持，如下所示：

```json
{
  "wf": [
    "pBOMPrpg1QX", "lyLU2wR22tC"
  ],
  "pe": [
    "201601", "201602"
  ],
  "approvals": [
    {
      "ou": "cDw53Ej8rju",
      "aoc": "ranftQIH5M9"
    }, 
    {
      "ou": "cDw53Ej8rju",
      "aoc": "fC3z1lcAW5x"
    }
  ]
}
```

### 获取数据批准级别 { #get-data-approval-levels } 

要检索数据审批工作流及其数据审批级别，您
可以发出类似这样的 GET 请求：

    /api/dataApprovalWorkflows?
      fields=id,name,periodType,dataApprovalLevels[id,name,level,orgUnitLevel]


### Authorities for data approval { #authorities-for-data-approval } 

- `F_DATA_APPROVAL_WORKFLOW` : allow user to Add/Update Data Approval Workflow
- `F_DATA_APPROVAL_LEVEL` : allow user to Add/Update Data Approval Level


# 分享中 { #sharing } 

## 分享中 { #webapi_sharing } 

共享解决方案允许您共享系统中的大多数对象
特定的用户组并定义对象是否应该公开
可访问或私有。要获取和设置对象的共享状态，您可以
与*共享*资源互动。

    /api/33/sharing

### 获取共享状态 { #webapi_get_sharing_status } 

要请求对象的共享状态，请使用GET请求执行以下操作：

    / api / 33 / sharing？type = dataElement＆id = fbfJHSPpUQD

响应如下所示。

```json
{
  "meta": {
    "allowPublicAccess": true,
    "allowExternalAccess": false
  },
  "object": {
    "id": "fbfJHSPpUQD",
    "name": "ANC 1st visit",
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

### 设定分享状态 { #webapi_set_sharing_status } 

您可以使用相同的 URL 定义对象的共享状态
一个 POST 请求，其中 JSON 格式的有效负载如下所示：

```json
{
  "object": {
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

在此示例中，有效负载定义了具有读写权限的对象
公共访问，无外部访问（无需登录），读写访问
一个用户组和另一个用户组的只读访问权限。你可以
使用 curl 将其提交到共享资源：

```bash
curl -d @sharing.json "localhost/api/33/sharing?type=dataElement&id=fbfJHSPpUQD"
  -H "Content-Type:application/json" -u admin:district
```
**Note**
> It is possible to create surprising sharing combinations. For
> instance, if `externalAccess` is set to `true` but `publicAccess` is
> set to `--------`, then users will have access to the object 
> only when they are logged out.




## New Sharing object { #new-sharing-object } 
From 2.36 a new `sharing` property has been introduced in order to replace the old sharing properties `userAccesses`, `userGroupAccesses`, `publicAccess`, `externalAccess` in all metadata classes that have sharing enabled. This `Sharing` object is saved as a JSONB column in database. 
However, in order make it backward compatible the old sharing objects still work normally as before, for both import and export. In backend sharing data will be saved to new  JSONb `sharing` column instead of the old `*accesses` tables.

The format looks like this:
```json
{
  "name": "ANC 1st visit",
  "publicAccess": "rw------",
  "externalAccess": false,
  "userGroupAccesses": [
      {
          "access": "r-r-----",
          "userGroupUid": "Rg8wusV7QYi",
          "displayName": "HIV Program Coordinators",
          "id": "Rg8wusV7QYi"
      }
  ],
  "userAccesses": [],
  "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
  },
  "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {
          "Rg8wusV7QYi": {
              "access": "r-r-----",
              "id": "Rg8wusV7QYi"
          }
      },
      "public": "rw------"
  }
}
```

### Set sharing status using new JSON Patch Api { #webapi_set_sharing_status_using_json_patch_api } 
You can use [JSON Patch API](#webapi_partial_updates) to update sharing for an object by sending a `PATCH` request to this endpoint with header `Content-Type: application/json-patch+json`
```
api/dataElements/fbfJHSPpUQD
```
Please note that this function ***only supports*** new `sharing` format. The payload in JSON format looks like this:
```json
[
  {
    "op": "replace",
    "path": "/sharing/users",
    "value": {
      "NOOF56dveaZ": {
        "access": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "access": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
You can add users to `sharing` property of an object like this
```json
[
  {
    "op": "add",
    "path": "/sharing/users",
    "value": {
      "NOOF56dveaZ": {
        "access": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "access": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
You can add one user to `sharing` like this
```json
[
  {
    "op": "add",
    "path": "/sharing/users/NOOF56dveaZ",
    "value": {
      "access": "rw------",
      "id": "NOOF56dveaZ"
    }
  }
]
```
You can remove one user from `sharing` like this
```json
[
  { 
    "op": "remove", 
    "path": "/sharing/users/N3PZBUlN8vq"
  }
]
```

## Cascade Sharing for Dashboard { #cascade-sharing-for-dashboard } 

### 总览 { #overview } 

- `cascadeSharing` is available for Dashboards. This function copies the `userAccesses` and `userGroupAccesses` of a Dashboard to all of the objects in its `DashboardItems`, including `Map`, `EventReport`, `EventChart`, `Visualization`. 
- This function will not copy `METADATA_WRITE` access. The copied `UserAccess` and `UserGroupAccess` will **only** receive the `METADATA_READ` permission. 
- The `publicAccess` setting of the Dashboard is not copied.
- If any target object has `publicAccess` enabled, then it will be skipped and will not receive the `UserAccesses` or `UserGroupAccesses` from the Dashboard.
- The current user must have `METADATA_READ` sharing permission to all target objects. If the user does not, error `E5001` is thrown.
- The current user must have `METADATA_WRITE` sharing permission to update any target objects. If a target object should be updated and the user does not have this permission, error `E3001` is thrown.

### Sample use case { #sample-use-case } 

- DashboardA is shared to userA with `METADATA_READ_WRITE` permission. 
- DashboardA has VisualizationA which has DataElementA.
- VisualizationA, DataElementA have `publicAccess` *disabled* and are *not shared* to userA.
- After executing cascade sharing for DashboardA, userA will have `METADATA_READ` access to VisualizationA and DataElementA.

### API endpoint  { #api-endpoint } 

- Send `POST` request to endpoint 
```
api/dashboards/cascadeSharing/{dashboardUID}
```


### API Parameters { #api-parameters } 

| 名称 | 默认 | 描述 |
| --- | --- | -- |
| dryRun | 假 | If this is set to `true`, then cascade sharing function will proceed without updating any objects. </br> The response will includes errors if any and all objects which will be updated. </br>This helps user to know the result before actually executing the cascade sharing function.
| atomic | 假 | If this is set to `true`, then the cascade sharing function will stop and not updating any objects if there is an error. </br>Otherwise, if this is `false` then the function will try to proceed with best effort mode.

Sample response: 

```json
{
  "errorReports": [
    {
      "message": "No matching object for reference. Identifier was s46m5MS0hxu, and object was DataElement.",
      "mainKlass": "org.hisp.dhis.dataelement.DataElement",
      "errorCode": "E5001",
      "errorProperties": [
        "s46m5MS0hxu",
        "DataElement"
      ]
    }
  ],
  "countUpdatedDashBoardItems": 1,
  "updateObjects": {
    "dataElements": [
      {
        "id": "YtbsuPPo010",
        "name": "Measles doses given"
      },
      {
        "id": "l6byfWFUGaP",
        "name": "Yellow Fever doses given"
      }
    ]
  }
}
```

### Response properties: { #response-properties } 

- `errorReports`: includes all errors during cascade sharing process.
- `countUpdatedDashBoardItems`: Number of `DashboardItem` will be or has been updated depends on `dryRun` mode.
- `updateObjects`: List of all objects which will be or has been updated depends on `dryRun` mode.

## Bulk Sharing patch API { #webapi_bulk_sharing } 
- The bulk sharing API allow you to apply sharing settings to multiple metadata objects. This means the ability to add or remove many users and user groups to many objects in one API operation.
- This API should not support keeping metadata objects in sync over time, and instead treat it as a one-time operation.
- The API needs to respect the sharing access control, in that the current user must have access to edit the sharing of the objects being updated.
- There are two new api endpoints introduced from 2.38 that allow bulk sharing patch update as described below.
- Please note that those `PATCH` request must use header `Content-type:application/json-patch+json`

### Using `/api/{object-type}/sharing` with `PATCH` request
- This endpoint allows user to apply one set of Sharing settings for multiple metadata objects of *one object-type*.
- Note that we still support JsonPatch request for one object with endpoint `api/{object-type}/{uid}`. For instance, you can still update sharing of a DataElement by sending PATCH request to `api/dataElements/cYeuwXTCPkU/sharing`

Example: 
```
curl -X PATCH -d @payload.json -H "Content-Type: application/json-patch+json" "https://play.dhis2.org/dev/api/dataElements/sharing"
```

### Using `/api/metadata/sharing` with `PATCH` request { #using-apimetadatasharing-with-patch-request } 
- This endpoint allows user to apply Sharing settings for *multiple object-types* in one payload.

例：
```
curl -X PATCH -d @payload.json -H "Content-Type: application/json-patch+json" "https://play.dhis2.org/dev/api/metadata/sharing"
```

## Parameters { #parameters } 
- Both patch api endpoints have same parameter:

| 名称  |  默认  |  描述  |
| ---- | ---- | -------------------- |
| atomic | 假 | If this is set to true, then the batch function will stop and not updating any objects if there is an error <br> Otherwise, if this is false then the function will try to proceed with best effort mode. |


## Validation { #validation } 
- All object ID will be validated for existence.
- Current User need to have metadata READ/WRITE permission on updating objects.
- All existing validations from metadata import service will also be applied.

## Response { #response } 
- Response format should be same as from `/api/metadata` api.

## Payload formats { #payload-formats } 
- Payload for single object type using `/api/{object-type}/sharing` looks like this
```json
{
  "dataSets":[
    "cYeuwXTCPkU",
    "aYeuwXTCPkU"
  ],
  "patch":[
    {
      "op":"add",
      "path":"/sharing/users/DXyJmlo9rge",
      "value":{
        "access":"rw------",
        "id":"DXyJmlo9rge"
      }
    },
    {
      "op":"remove",
      "path":"/sharing/users/N3PZBUlN8vq"
    }
  ]
}
```

- Payload for multiple object types in one payload using `api/metadata/sharing`
```json
{
  "dataElements": {
    "fbfJHSPpUQD": [
      {
        "op": "replace",
        "path": "/sharing/users",
        "value": {
          "NOOF56dveaZ": {
            "access": "rw------",
            "id": "CotVI2NX0rI"
          },
          "Kh68cDMwZsg": {
            "access": "rw------",
            "id": "DLjZWMsVsq2"
          }
        }
      }
    ]
  },
  "dataSets": {
    "cYeuwXTCPkA": [
      {
        "op": "remove",
        "path": "/sharing/users/N3PZBUlN8vq"
      }
    ],
    "cYeuwXTCPkU": [
      {
        "op": "add",
        "path": "/sharing/users/DXyJmlo9rge",
        "value": {
          "access": "rw------",
          "id": "DXyJmlo9rge"
        }
      }
    ]
  },
  "programs": {
    "GOLswS44mh8": [
      {
        "op": "add",
        "path": "/sharing/userGroups",
        "value": {
          "NOOF56dveaZ": {
            "access": "rw------",
            "id": "NOOF56dveaZ"
          },
          "Kh68cDMwZsg": {
            "access": "rw------",
            "id": "Kh68cDMwZsg"
          }
        }
      }
    ]
  }
}
```


# 排程 { #webapi_scheduling }

## Get available job types { #types }

要获取所有可用作业类型的列表，可以使用以下端点：

    GET /api/jobConfigurations/jobTypes

响应包含有关每个作业类型的信息，包括名称、作业类型、键、调度类型和可用参数。调度类型可以是 `CRON`，这意味着可以使用带有 `cronExpression` 字段的 cron 表达式来调度作业，或者是`FIXED_DELAY`，意味着可以使用 `delay` 字段将作业调度为以固定延迟运行.场延迟以秒为单位。

响应将类似于以下内容：

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

## Job Configurations  { #job-configurations } 
DHIS2允许安排各种类型的作业。每种类型的作业都有不同的配置属性，可让您更好地控制作业的运行方式。此外，如果需要，您可以将同一作业配置为以不同的配置和不同的时间间隔运行。

Table: Main properties

| Property | 描述 | 类型 |
|---|---|---|
| 名称 | Name of the job. | 串 |
| cronExpression | The cron expression which defines the interval for when the job should run. | String (Cron expression) |
| jobType | The job type represent which task is run. In the next table, you can get an overview of existing job types. Each job type can have a specific set of parameters for job configuration. | String (Enum) |
| jobParameters | Job parameters, if applicable for job type. | (See list of job types) |
| enabled | A job can be added to the system without it being scheduled by setting `enabled` to false in the JSON payload. Use this if you want to temporarily stop scheduling for a job, or if a job configuration is not complete yet. | Boolean |



### Job Parameters { #job-parameters }

Table: `DATA_INTEGRITY` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `checks` | array of string | `[]` = all | names of the checks to run in order of execution |
| `type`   | enum            | `REPORT`   | REPORT, SUMMARY or DETAILS                       |

Table: `ANALYTICS_TABLE` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `lastYears` | int  | 0       | Number of years back to include |
| `skipTableTypes` | array of enum  | `[]`    | Skip generation of tables; Possible values: `DATA_VALUE`, `COMPLETENESS`, `COMPLETENESS_TARGET`, `ORG_UNIT_TARGET`, `EVENT`, `ENROLLMENT`, `VALIDATION_RESULT` |
| `skipResourceTables` | boolean | `false`   | Skip generation of resource tables |
| `skipPrograms` | array of string | `[]`    | Optional list of programs (IDs) that should be skipped |

Table: `CONTINUOUS_ANALYTICS_TABLE` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `lastYears` | int           | `0`     | Number of years back to include |
| `skipTableTypes` | array of enum | `[]`    | Skip generation of tables; Possible values: `DATA_VALUE`, `COMPLETENESS`, `COMPLETENESS_TARGET`, `ORG_UNIT_TARGET`, `EVENT`, `ENROLLMENT`, `VALIDATION_RESULT` |
| `fullUpdateHourOfDay` | int           | `0`     | Hour of day for full update of analytics tables (0-23) |

Table: `DATA_SYNC` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `pageSize` | int | `10000` | number of data values processed as a unit |

Table: `META_DATA_SYNC` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `trackerProgramPageSize` | int | `20` | number of tracked entities processed as a unit |
| `eventProgramPageSize` | int | `60` | number of events processed as a unit           |
| `dataValuesPageSize` | int | `10000` | number of data values processed as a unit  |

Table: `MONITORING` (Validation rule analysis) job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `relativeStart` | int | `0` | A number related to date of execution which resembles the start of the period to monitor |
| `relativeEnd` | int | `0` | A number related to date of execution which resembles the end of the period to monitor |
| `validationRuleGroups` | array of string | `[]` | Validation rule groups (UIDs) to include in job |
| `sendNotification` | boolean | `false` | Set `true` if job should send notifications based on validation rule groups |
| `persistsResults` | boolean | `false` | Set `true` if job should persist validation results |

Table: `PUSH_ANALYSIS` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `pushAnalysis` | array of string | `[]` |  The UIDs of the push analysis you want to run |

Table: `PREDICTOR` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `relativeStart` | int | `0` | A number related to date of execution which resembles the start of the period to monitor |
| `relativeEnd` | int | `0` | A number related to date of execution which resembles the start of the period to monitor |
| `predictors` | array of string | `[]` | Predictors (UIDs) to include in job                                                      |
| `predictorGroups` | array of string | `[]` | Predictor groups (UIDs) to include in job                                                |

Table: `MATERIALIZED_SQL_VIEW_UPDATE` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `sqlViews`    | array of string | `[]` | The UIDs of the SQL views that are updated by the job |


### Create a Job Configuration { #create-a-job-configuration } 

要配置作业，您可以对以下资源发出POST请求：

    /api/jobConfigurations

不含JSON格式参数的作业如下所示：

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

参数为JSON格式的分析表作业的示例：

```json
{
  "name": "Analytics tables last two years",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * * ? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

作为带有JSON格式参数的推送分析作业的示例：

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

An example of a job with scheduling type `FIXED_DELAY` and 120 seconds delay:

```json
{
  "name": "Continuous analytics table",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "delay": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
```

### Get Job Configurations { #get-job-configurations } 

列出所有作业配置：

    GET /api/jobConfigurations

检索作业：

    GET /api/jobConfigurations/{id}

响应有效负载如下所示：

```json
{
  "lastUpdated": "2018-02-22T15:15:34.067",
  "id": "KBcP6Qw37gT",
  "href": "http://localhost:8080/api/jobConfigurations/KBcP6Qw37gT",
  "created": "2018-02-22T15:15:34.067",
  "name": "analytics last two years",
  "jobStatus": "SCHEDULED",
  "displayName": "analytics last two years",
  "enabled": true,
  "externalAccess": false,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "2018-02-26T03:00:00.000",
  "cronExpression": "0 0 3 ? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorite": false,
  "configurable": true,
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "manage": true
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favorites": [],
  "translations": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
```

### Update a Job Configuration { #update-a-job-configuration } 

使用以下端点和JSON有效负载格式，通过参数更新作业：

    PUT /api/jobConfigurations/{id}

```json
{
  "name": "analytics last two years",
  "enabled": true,
  "cronExpression": "0 0 3 ? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

### Delete a Job Configuration { #delete-a-job-configuration } 

使用以下方法删除作业：

    DELETE /api/jobConfigurations/{id}

请注意，某些具有自定义配置参数的作业可能不会被添加，如果
未配置所需的系统设置。一个例子是数据
同步，这需要远程服务器配置。

### Run Jobs Manually { #execute }

Jobs can be run manually using:

    POST /api/jobConfigurations/{id}/execute


### Searching for jobs with execution errors { #searching-for-jobs-with-execution-errors } 

Since version 2.41 jobs can store errors of the job run to allow inspection
at a later point in time. 

> **Note** This feature is only accessible for administrator
> with the `F_JOB_LOG_READ` authority and superusers.

To view the errors associated with a specific job use:

    GET /api/jobConfigurations/{id}/errors

To search for jobs that match user specified search criteria use:

    GET /api/jobConfigurations/errors

with one or more of the following search parameters

* `user`: include jobs ran by this user
* `from`: include jobs that started after this point in time
* `to`: include jobs that did not start later than this point in time
* `code`: include jobs that have errors with one of the given error codes
* `object`: include jobs that have errors linked to one of the given object IDs
* `type`: include job with errors of the specified type(s)

When multiple criteria are used all have to be met (AND logic).
If multiple `code`, `object` or `type` parameters are given just one has to match (OR logic).

For example, to find tracker import errors for the 1. of January 2024 with error code `E1002` 
(tracked entity already exists) the following search is made:

    GET /api/jobConfigurations/errors?type=TRACKER_IMPORT_JOB&code=E1002&from=2024-01-01&to=2024-01-02

The results show the job run error details. By default, the `input` (the payload of the impport) 
is excluded from the results. To include it add `includeInput=true`:

    GET /api/jobConfigurations/errors?includeInput=true

> **Note**
> Not all job types do store their errors. Currently, this feature is mostly
> supported by import jobs.


## Scheduler API { #scheduler-api } 
While `/api/jobConfigurations` is centered around the job configuration objects
the `/api/scheduler` API reflects the state of the scheduler 
and the `/api/scheduling` API provides job progress tracking information.  

### Observe Running Jobs { #running}
The execution steps and state can be observed while the job is running.
A list of all types of jobs that are currently running is provided by:

    GET /api/scheduling/running/types

To get an overview of all running jobs by job type use:

    GET /api/scheduling/running

As there only can be one job running for each type at a time the status of a
running job can be viewed in details using:

    GET /api/scheduling/running/{type}

For example, to see status of a running `ANALYTICS_TABLE` job use

    GET /api/scheduling/running/ANALYTICS_TABLE

A job is a sequence of processes. Each process has a sequence of `stages`.
Within each stage there might be zero, one or many `items`. Items could be
processed strictly sequential or parallel, n items at a time. Often the
number of `totalItems` is known up-front.

In general the stages in a process and the items in a stage are "discovered"
as a "side effect" of processing the data. While most processes have a fixed
sequence of stages some processed might have varying stages depending on the
data processed. Items are usually data dependent. Most jobs just include a
single process.

Each of the nodes in the process-stage-item tree has a status that is either
* `RUNNING`: is currently processed (not yet finished)
* `SUCCESS`: when completed successful
* `ERROR`: when completed with errors or when an exception has occurred
* `CANCELLED`: when cancellation was requested and the item will not complete

### See Completed Job Runs { #completed }
Once a job has completed successful or with a failure as a consequence of an
exception or cancellation the status moves from the set of running states to
the completed job states. This set keeps only the most recent execution
state for each job type. The overview is available at:

    GET /api/scheduling/completed

Details on a particular job type are accordingly provided at:

    GET /api/scheduling/completed/{type}

In case of the `ANALYTICS_TABLE` job this would be:

    GET /api/scheduling/completed/ANALYTICS_TABLE

### Request Cancelling a Running Jobs { #cancel }
Once a job is started it works through a sequence of steps. Each step might
in turn have collections of items that are processed. While jobs usually
cannot be stopped at any point in time we can request cancellation and the
process gives up cooperatively once it has completed an item or step and
recognises that a cancellation was requested. This means jobs do not stop
immediately and leave at an unknown point right in the middle of some
processing. Instead, they give up when there is an opportunity to skip to
the end. This still means that the overall process is unfinished and is not
rolled back. It might just have done a number of steps and skipped others at
the end.

To cancel a running job use:

    POST /api/scheduling/cancel/{type}

For example, to cancel the `ANALYTICS_TABLE` job run:

    POST /api/scheduling/cancel/ANALYTICS_TABLE

Depending on the current step and item performed this can take from
milliseconds to minutes before the cancellation becomes effective.
However, the status of the overall process will be shown as `CANCELLED`
immediately when check using

    GET /api/scheduling/running/ANALYTICS_TABLE

Only jobs that have been split into processes, stages and items can be
cancelled effectively. Not all jobs have been split yet. These will run till
completion even if cancellation has been requested.


## Job Queues { #queues }
Sequences of jobs (configurations) can be created using job queues.
The queue always uses a unique name and a CRON expression trigger. 
Once a queue is started it runs all jobs in the queue in the given sequence.
The second in sequence starts when the first is finished and so forth.

### List Names of Job Queues { #queues-list } 
To list the unique names of existing queues use:

    GET /api/scheduler/queues

The response is a array of the names:
```json
["queue_a", "queue_b"]
```

### Get A Job Queue { #queues-info }
To get all details of a specific queue use:

    GET /api/scheduler/queues/{name}

The details include its name, CRON expression and job sequence:

```json
{
  "name": "myQ",
  "cronExpression": "0 0 1 ? * *",
  "sequence": ["FgAxa6eRSzQ", "BeclVERfWbg" ]
}
```

### Create a new Job Queue { #queues-add }
To create a new queue send a POST request with a payload object having name, 
CRON expression and the job sequence:

    POST /api/scheduler/queues/{name}

To create a queue with name `myQ` use a POST to `/api/scheduler/queues/myQ`:

```json
{
  "cronExpression": "0 0 1 ? * *",
  "sequence": ["FgAxa6eRSzQ", "BeclVERfWbg" ]
}
```
A `name` can be present in the payload as well but name specified in the URL
path takes precedence. 

> **NOTE**
>
> The cron expression of all job configurations but the first in a queue is
> cleared as they do not have a trigger on their own any longer. It needs to
> be restored manually once a job is removed from a queue.

### Update a Job Queue { #queues-update }
To update an existing queue CRON expression or sequence use a PUT request   

    PUT /api/scheduler/queues/{name}

The payload has to state both new CRON expression and job sequence like in 
the example above to create a new queue.

To rename a queue the new name can be stated in the payload, while the old name 
is used in the URL path.  

### Delete a Job Queue { #queues-delete }
To delete a job queue send a DELETE request to its resource URL:

    DELETE /api/scheduler/queues/{name}

> **NOTE**
>
> Deleting a queue does not delete any referenced job configurations. Any job
> configuration that is removed from a queue either by changing the sequence or
> deleting the queue is disabled. To use it individually supply a CRON 
> expression and enable the configuration again.


## Job Scheduler { #scheduler }
The schedule within the scheduler is a list that is based on job configurations
and job queues. Either an entry in the schedule is a simple job configuration,
or it is a job queue. Both are represented using the same entry format.

To get the scheduler listing use: 

    GET /api/scheduler

A job configuration in this list looks like this:

```json
  {
    "name": "User account expiry alert",
    "type": "ACCOUNT_EXPIRY_ALERT",
    "cronExpression": "0 0 2 ? * *",
    "nextExecutionTime": "2023-03-15T02:00:00.000",
    "status": "SCHEDULED",
    "enabled": true,
    "configurable": false,
    "sequence": [
      {
        "id": "fUWM1At1TUx",
        "name": "User account expiry alert",
        "type": "ACCOUNT_EXPIRY_ALERT",
        "cronExpression": "0 0 2 ? * *",
        "nextExecutionTime": "2023-03-15T02:00:00.000",
        "status": "SCHEDULED"
      }
    ]
  }
```
Most notably the `sequence` has only a single item. Information on top level
object and the object in the `sequence` both originate from the job configuration.

A job queue in the list looks like this:

```json
  {
    "name": "myQ",
    "type": "Sequence",
    "cronExpression": "0 0 1 ? * *",
    "nextExecutionTime": "2023-03-15T01:00:00.000",
    "status": "SCHEDULED",
    "enabled": true,
    "configurable": true,
    "sequence": [
      {
        "id": "FgAxa6eRSzQ",
        "name": "test Q1",
        "type": "ANALYTICS_TABLE",
        "cronExpression": "0 0 1 ? * *",
        "nextExecutionTime": "2023-03-15T01:00:00.000",
        "status": "SCHEDULED"
      },
      {
        "id": "BeclVERfWbg",
        "name": "est Q2",
        "type": "DATA_INTEGRITY",
        "status": "SCHEDULED"
      }
    ]
  }
```
The top level object originates from the queue and aggregate information.
The objects within the sequence originate from the job configurations that are
part of the sequence.

### List Jobs Entries addable to a Job Queue { #queueable }
Not all jon configurations can be added to a queue. 
System jobs and jobs that are already part of a queue cannot be used in another 
queue. To list job configurations that can be part of any queue use:

    GET /api/scheduler/queueable

To list job configurations that can be part of a particular queue use:

    GET /api/scheduler/queueable?name={queue}

This will also exclude all jobs that are already part the named queue.


# 同步化 { #webapi_synchronization }

本节介绍数据和元数据的提取和推送。

## 数据值推送 { #webapi_sync_data_push }

要将数据值推送到远程服务器，必须首先配置
系统设置 > 中相关服务器的 URL 和凭据
同步，然后向以下资源发出 POST 请求：

    / api / 33 / synchronization / dataPush

## 元数据拉取 { #webapi_sync_metadata_pull }

要从远程 JSON 文档中启动元数据拉取，您可以创建一个
使用 *url* 作为请求负载的 POST 请求到以下资源：

    / api / 33 / synchronization / metadataPull

> **Note**
>
> The supplied URL will be checked against the config property `system.remote_servers_allowed` in the `dhis.conf` file.
> If the base URL is not one of the configured servers allowed then the operation will not be allowed. See failure example below.  
> Some examples where the config set is `system.remote_servers_allowed=https://server1.org/,https://server2.org/`
> - supply `https://server1.org/path/to/resource` -> this will be accepted
> - supply `https://server2.org/resource/path` -> this will be accepted
> - supply `https://oldserver.org/resource/path` -> this will be rejected
>
Sample failure response

```json
 {
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Provided URL is not in the remote servers allowed list",
  "errorCode": "E1004"
}
```

## 可用性检查 { #webapi_sync_availability_check }

检查远程数据服务器的可用性并验证用户
您可以向以下资源发出 GET 请求：

    / api / 33 /同步/可用性



# 审核 { #audit } 

## 稽核 { #webapi_auditing }

DHIS2 will audit updates and deletions of aggregate data values, tracked entity data values, tracked entity attribute values and data approval records. This section explains how to retrieve audit records for the mentioned entities. Note that several of the query parameters can be repeated any number of times.

### 汇总数据价值审核 { #webapi_auditing_aggregate_audits }

The endpoint for aggregate data value audits is located at:

```
/api/audits/dataValue
```

Table: Aggregate data value query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| ds | Data set ID | One or more data set identifiers to get data elements from |
| 德 | Data element ID | One or more data element identifiers |
| 聚乙烯 | ISO period | One or more period ISO identifiers |
| 欧 | Organisation unit ID | One or more org unit identifiers |
| auditType | UPDATE &#124; DELETE | Filter by one or more audit types |
| skipPaging | false &#124; true | Turn paging on / off |
| paging | false \| 真正 | Enable or disable paging |
| page | 数 | Page number (default 1) |
| pageSize | 数 | Page size (default 50) |

Example: Get audits for a data set `lyLU2wR22tC` and audit type `CREATE` or `UPDATE`:

    /api/33/audits/dataValue?ds=lyLU2wR22tC&auditType=CREATE,UPDATE

Example: Get audits for data element `BOSZApCrBni`, org unit `DiszpKrYNg8` and category option combination `TkDhg29x18A`:

    /api/33/audits/dataValue?de=BOSZApCrBni&ou=DiszpKrYNg8&co=TkDhg29x18A

### 跟踪实体数据价值审核 { #webapi_tracked_entity_data_value_audits }
**deprecated for removal in version 43 use [tracked entity data value change log endpoint](https://github.com/dhis2/dhis2-docs/blob/master/src/developer/web-api/tracker.md#event-data-value-change-logs--webapi_event_data_value_change_logs-)**

The endpoint for tracked entity data value audits is located at:

```
/api/audits/trackedEntityDataValue
```

Table: Tracked entity data value query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| 德 | Data element ID | One or more data element identifiers |
| 欧 | Organisation unit ID | One or more organisation unit identifiers of the audited event |
| events | Events ID | One or more event identifiers of the audited event (comma separated) |
| ps | Program stage ID | One or more program sages of the audit event program |
| 开始日期 | Start date | Return only audit records created after date |
| 结束日期 | End date | Return only audit records created before date |
| ouMode | Organisation unit selection mode | SELECTED \| DESCENDANTS |
| auditType | UPDATE &#124; DELETE | Filter by one or more audit types |
| skipPaging | false &#124; true | Turn paging on / off |
| paging | false \| 真正 | Whether to enable or disable paging |
| page | 数 | Page number (default 1) |
| pageSize | 数 | Page size (default 50) |

Example: Get audits for data elements `eMyVanycQSC` and `qrur9Dvnyt5`:

    / api / 33 / audits / trackedEntityDataValue？de = eMyVanycQSC＆de = qrur9Dvnyt5

Example: Get audits for org unit `O6uvpzGd5pu` including descendant org units in the org unit hierarchy:

    /api/audits/trackedEntityDataValue?ou=O6uvpzGd5pu&ouMode=DESCENDANTS

### 跟踪实体属性值审核 { #webapi_tracked_entity_attribute_value_audits }

**deprecated for removal in version 43 use [tracked entity attribute change log endpoint](https://github.com/dhis2/dhis2-docs/blob/master/src/developer/web-api/tracker.md#tracked-entity-attribute-value-change-logs--webapi_tracker_attribute_change_logs-)**

The endpoint for tracked entity attribute value audits is located at:

```
/api/audits/trackedEntityAttributeValue
```

Table: Tracked entity attribute value query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| tea | Tracked entity attribute ID | One or more tracked entity attribute identifiers |
| trackedEntities | Tracked entity ID | One or more tracked entity identifiers (comma separated) |
| auditType | UPDATE &#124; DELETE | Filter by one or more audit types |
| skipPaging | false &#124; true | Turn paging on / off |
| paging | false \| 真正 | Whether to enable or disable paging |
| page | 数 | Page number (default 1) |
| pageSize | 数 | Page size (default 50) |

Example: Get audits for tracked entity attribute `VqEFza8wbwA`:

    / api / 33 / audits / trackedEntityAttributeValue？tea = VqEFza8wbwA

Example: Get audits for tracked entity instance `wNiQ2coVZ39` and audit type `DELETE`:

    /api/33/audits/trackedEntityAttributeValue?trackedEntities=wNiQ2coVZ39&auditType=DELETE

### 跟踪实体实例审核 { #webapi_tracked_entity_instance_audits }

Once auditing is enabled for tracked entities (by setting `allowAuditLog` of tracked entity types to `true`), all read and search operations are logged. The endpoint for accessing audit logs is located at:

```
/api/audits/trackedEntity
```

Table: Tracked entity audit query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| trackedEntities | Tracked Entity UIDS | One or more tracked entity identifiers (comma separated) |
| user | 用户 | One or more user identifiers |
| auditType | SEARCH &#124; READ | Filter by one or more audit types |
| 开始日期 | Start date | Start date for audits in `yyyy-mm-dd` format |
| 结束日期 | End date | End date for audits in `yyyy-mm-dd` format |
| skipPaging | false &#124; true | Turn paging on / off. |
| paging | false \| 真正 | Whether to enable or disable paging |
| page | 数 | Page number  (default 1) |
| pageSize | 数 | Page size  (default 50) |

Example: Get audits of audit type `READ` with `startDate` 2018-03-01 and `endDate` 2018-04-24 with a page size of 5:

    /api/33/audits/trackedEntity.json?startDate=2021-03-01&endDate=2022-04-24&auditType=READ&pageSize=5

Example: Get audits for tracked entity `wNiQ2coVZ39`:

    /api/33/audits/trackedEntity.json?trackedEntities=wNiQ2coVZ39

### ***DEPRECATED*** Tracked entity instance audits { #webapi_tracked_entity_instance_audits }

Once auditing is enabled for tracked entity instances (by setting `allowAuditLog` of tracked entity types to `true`), all read and search operations are logged. The endpoint for accessing audit logs is located at:

```
/api/audits/trackedEntityInstance
```

Table: Tracked entity instance audit query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| trackedEntities | Tracked Entity UIDS | One or more tracked entity identifiers (comma separated) |
| user | 用户 | One or more user identifiers |
| auditType | SEARCH &#124; READ | Filter by one or more audit types |
| 开始日期 | Start date | Start date for audits in `yyyy-mm-dd` format |
| 结束日期 | End date | End date for audits in `yyyy-mm-dd` format |
| skipPaging | false &#124; true | Turn paging on / off. |
| paging | false \| 真正 | Whether to enable or disable paging |
| page | 数 | Page number  (default 1) |
| pageSize | 数 | Page size  (default 50) |

Example: Get audits of audit type `READ` with `startDate` 2018-03-01 and `endDate` 2018-04-24 with a page size of 5:

    /api/33/audits/trackedEntityInstance.json?startDate=2021-03-01&endDate=2022-04-24&auditType=READ&pageSize=5

Example: Get audits for tracked entity `wNiQ2coVZ39`:

    /api/33/audits/trackedEntityInstance.json?trackedEntities=wNiQ2coVZ39


### 数据审批审核 { #data-approval-audits } 

The endpoint for data approval audits is located at:

```
/api/audits/dataApproval
```

Table: Data approval query parameters

| Parameter | 选项 | 描述 |
|---|---|---|
| dal | Data approval level ID | One or more data approval level identifiers |
| wf | Data approval workflow ID | One or more data approval workflow identifiers |
| 欧 | Organisation unit ID | One or more organisation unit identifiers |
| 冠捷 | Attribute option combo ID | One or more attribute option combination identifiers |
| 开始日期 | Start date | Start date for approvals in `yyyy-mm-dd` format |
| 结束日期 | End date | End date for approvals in `yyyy-mm-dd` format |
| skipPaging | false &#124; true | Turn paging on / off |
| page | 数 | Page number (default 1) |
| pageSize | 数 | Page size (default 50) |

Example: Get audits for data approval workflow `i5m0JPw4DQi`:

    /api/33/audits/dataApproval?wf=i5m0JPw4DQi

Exaple: Get audits between `2021-01-01` and `2022-01-01` for org unit `DiszpKrYNg8`:

    /api/33/audits/dataApproval?ou=DiszpKrYNg8&startDate=2021-01-01&endDate=2022-01-01



# 讯息传递 { #messaging } 

## 讯息对话 { #webapi_message_conversations } 

DHIS2 具有发送消息的机制，例如
用户反馈、通知和给用户的一般信息。留言
被分组到对话中。与消息对话交互
您可以向 *messageConversations* 发送 POST 和 GET 请求
资源。

    / api / 33 / messageConversations

消息会传送到 DHIS2 消息收件箱，但也可以发送
以短信形式发送到用户的电子邮件地址和手机。在这个例子中，
我们将看到如何利用 Web API 来发送、读取和管理
消息。我们将伪装成*DHIS2管理员*用户并发送
给*移动*用户的消息。然后我们会假装是手机
用户并阅读我们的新消息。在此之后，我们将管理管理员
用户收件箱通过标记和删除邮件。

### 撰写和阅读邮件 { #webapi_writing_messages } 

我们在发送和阅读消息时需要交互的资源
是 *messageConversations* 资源。我们首先访问 Web API
在 <http://play.dhis2.org/demo/api> 的入口点我们找到并跟随
*messageConversations* 资源的链接位于
 <http://play.dhis2.org/demo/api/messageConversations> 。说明
告诉我们可以使用 POST 请求来创建新消息
发送给多个用户的以下 XML 格式：

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <users>
    <user id="user1ID" />
    <user id="user2ID" />
    <user id="user3ID" />
  </users>
</message>
```

为了发送给一个或多个用户组中的所有用户，我们可以
用：

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <userGroups>
    <userGroup id="userGroup1ID" />
    <userGroup id="userGroup2ID" />
    <userGroup id="userGroup3ID" />
  </userGroups>
</message>
```

为了发送给连接到一个或多个组织单位的所有用户，我们
可以使用：

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <organisationUnits>
    <organisationUnit id="ou1ID" />
    <organisationUnit id="ou2ID" />
    <organisationUnit id="ou3ID" />
  </organisationUnits>
</message>
```

Since we want to send a message to our friend the mobile user we need to
look up her identifier. We do so by going to the Web API entry point and
follow the link to the *users* resource at `/api/users`. We continue by 
following link to the mobile user at `/api/users/PhzytPW3g2J` where we learn
that her identifier is *PhzytPW3g2J*. We are now ready to put our XML
message together to form a message where we want to ask the mobile user
whether she has reported data for January 2014:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>Mortality data reporting</subject>
  <text>Have you reported data for the Mortality data set for January 2014?</text>
  <users>
    <user id="PhzytPW3g2J" />
  </users>
</message>
```

为了测试这一点，我们将 XML 内容保存到一个名为 *message.xml* 的文件中。
我们使用 cURL 将消息发送到 DHIS2 演示实例
指示内容类型是 XML 并以 *admin* 身份进行身份验证
用户：

```bash
curl -d @message.xml "https://play.dhis2.org/demo/api/messageConversations"
  -H "Content-Type:application/xml" -u admin:district -X POST
```

JSON和POST命令中的相应有效负载如下所示：

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}
```

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Content-Type:application/json" -u admin:district -X POST
```

如果一切顺利，我们会收到一个 *201 Created* HTTP 状态代码。另外，请注意
我们收到一个 *Location* HTTP 标头，该标头的值通知我们
新创建的消息对话资源的 URL - 这可以是
消费者使用它来执行进一步的操作。

我们现在将假装是移动用户并阅读消息
刚刚通过向 *messageConversations* 发送 GET 请求发送
资源。我们提供一个带有 *application/xml* 的 *Accept* 标头作为
表示我们对 XML 资源感兴趣的值
表示，我们以*移动*用户身份进行身份验证：

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Accept:application/xml" -u mobile:district
```

作为响应，我们得到以下XML：

```xml
<messageConversations xmlns="http://dhis2.org/schema/dxf/2.0"
  link="https://play.dhis2.org/demo/api/messageConversations">
  <messageConversation name="Mortality data reporting" id="ZjHHSjyyeJ2"
    link="https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"/>
  <messageConversation name="DHIS2 version 2.7 is deployed" id="GDBqVfkmnp2"
    link="https://play.dhis2.org/demo/api/messageConversations/GDBqVfkmnp2"/>
</messageConversations>
```

从响应中，我们能够读取新发送的标识符
消息是 *ZjHHSjyyeJ2*。注意具体链接
资源已嵌入，可以关注以阅读完整内容
信息。一旦我们知道，我们可以直接回复现有的消息对话
通过包含消息文本作为请求负载来获取 URL。我们
现在可以构造一个 URL 来发送我们的回复：

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

如果一切按计划进行，您将收到 *200 OK* 状态代码。

在2.30中，我们添加了URL搜索参数：

    queryString =？＆queryOperator =？

过滤器在主题、文本和发件人中搜索消息的匹配项
对话。默认查询运算符是 *token*，但是其他运算符
可以在查询中定义。

### 管理讯息 { #webapi_managing_messages } 

随着用户接收和发送消息，对话将开始堆积
在他们的收件箱中，最终变得难以跟踪。我们现在将
看看通过删除和标记来管理用户的消息收件箱
通过 Web-API 进行对话。我们将通过执行一些
在“DHIS 管理员”用户的收件箱中维护。

首先，让我们看看从收件箱中删除一些邮件。是
一定要注意这里描述的所有删除操作只删除
用户和消息对话之间的关系。实际上
这意味着我们不会删除消息本身（或任何
内容），但只是从
用户使其不再列在
`/api/messageConversations` 资源。

To remove a message conversation from a users inbox we need to issue a
*DELETE* request to the resource identified by the id of the message
conversation and the participating user. For example, to remove the user
with id `xE7jOejl9FI` from the conversation with id `jMe43trzrdi`:

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations/jMe43trzrdi
```

如果请求成功，服务器将回复 *200 OK*。这
响应正文包含一个 XML 或 JSON 对象（根据接受
请求的标头）包含已删除用户的 ID。

```json
{
  "removed" : ["xE7jOejl9FI"]
}
```

失败时，返回的对象将包含一个消息有效负载
描述错误。

```json
{
  "message" : "No user with uid: dMV6G0tPAEa"
}
```

细心的读者已经注意到对象返回了
在我们的例子中，成功实际上是一个 id 列表（包含一个
入口）。这是因为端点也支持批量删除。这
对相同的 *messageConversations* 资源发出请求，但遵循
语义略有不同。对于批处理操作，会话 ID
作为查询字符串参数给出。以下示例删除了两个
当前用户的单独消息对话：

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm"
  -X DELETE -u admin:district
```

如果您有足够的权限，可以删除对话
通过提供可选的用户 ID 参数代表另一个用户。

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm&user=PhzytPW3g2J"
  -X DELETE -u admin:district
```

如上所述，批量删除将返回与
单一操作。删除的对象列表将反映成功
执行的移除。部分错误的请求（即不存在的 ID）
因此不会取消整个批处理操作。

消息带有布尔 *read* 属性。这允许跟踪是否
用户是否看到（打开）了一条消息。在典型应用中
场景（例如 DHIS2 网络门户），消息将被标记为已读
用户第一次打开它。然而，用户可能想要
管理他们的消息的已读或未读状态，以保持
跟踪某些对话。

标记消息已读或未读遵循与批处理类似的语义
移除，并且还支持批量操作。将消息标记为已读
我们向 `messageConversations/read` 资源发出一个 *POST*
包含一个或多个消息 ID 的请求正文。将消息标记为
未读我们向 `messageConversations/unread` 发出相同的请求
资源。与删除的情况一样，可选的 *user* 请求参数
可以给。

让我们将几条消息标记为当前用户已读：

```bash
curl "https://play.dhis2.org/dev/api/messageConversations/read"
  -d '["ZrKML5WiyFm","Gc03smoTm6q"]' -X POST
  -H "Content-Type: application/json" -u admin:district
```

响应是带有以下 JSON 正文的 *200 OK*：

```json
{
  "markedRead": ["ZrKML5WiyFm", "Gc03smoTm6q"]
}
```

您可以将收件人添加到现有的消息对话中。该资源位于：

    / api / 33 / messageConversations / id /收件人

此资源的选项是用户、用户组和
组织单位。请求应如下所示：

```json
{
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}

```

### 邮件附件 { #webapi_message_attachments } 

创建带附件的消息分两步完成：上传
文件添加到 *attachments* 资源，然后包括一个或几个
创建新邮件时的附件 ID。

对 *attachments* 资源的 POST 请求会将文件上传到
服务器。

```
curl -F file=@attachment.png“ https://play.dhis2.org/demo/api/messageConversations/attachments”
  -u管理员：区
```

该请求返回一个表示附件的对象。的标识
创建消息时必须使用此对象以链接
邮件附件。

```json
{
  "created": "2018-07-20T16:54:18.210",
  "lastUpdated": "2018-07-20T16:54:18.212",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407",
    "lastUpdated": "2018-03-09T23:06:54.512",
    "externalAccess": false,
    "displayName": "John Traore",
    "favorite": false,
    "id": "xE7jOejl9FI"
  },
  "lastUpdatedBy": {
    "id": "xE7jOejl9FI",
    "name": "John Traore"
  },
  "favorite": false,
  "id": "fTpI4GOmujz"
}
```

创建新消息时，可以在请求正文中传递 id
将上传的文件链接到正在创建的消息。

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "attachments": [
    "fTpI4GOmujz",
    "h2ZsOxMFMfq"
  ]
}
```

回复消息时，可以将 id 作为请求传递
范围。

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?attachments=fTpI4GOmujz,h2ZsOxMFMfq"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

创建带有附件的邮件后，附加文件
可以通过对以下 URL 的 GET 请求访问：

    / api / messageConversations / <mcv-id> / <msg-id> / attachments / <attachment-id>

其中 <mcv-id> 是*消息对话* ID，<msg-id> 是
包含附件和 <attachment-id> 的 *message* 是
特定*消息附件*的 ID。

### 票证和验证结果通知 { #webapi_messaging_tickets } 

您可以使用“写反馈”工具来创建工单和消息。
一张票和一条消息的唯一区别是你可以给
票证的状态和优先级。设置状态：

    POST / api / messageConversations / <uid> / status

设置优先级：

    POST / api / messageConversations / <uid> / priority

在 2.29 中，验证分析生成的消息现在也用于
状态和优先级属性。默认情况下，消息由
验证分析将继承验证规则的优先级
问题，或者如果消息包含多个最重要的
规则。

在 2.30 中，可以将验证规则分配给任何用户，同时工单
仍然需要分配给系统反馈接收者中的一个用户
团体。



Table: A list of valid status and priority values

| 状态 | Priority |
|---|---|
| OPEN | LOW |
| PENDING | MEDIUM |
| INVALID | HIGH |
| SOLVED ||

也可以给工单添加内部消息，只能看到
拥有“管理票证”权限的用户。创建一个内部
回复，包括“内部”参数，并将其设置为

```bash
curl -d "This is an internal message"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?internal=true"
  -H "Content-Type:text/plain" -u admin:district -X POST
```




# 可视化 { #visualizations } 
## 仪表板 { #webapi_dashboard } 

仪表板旨在为您提供多个分析的概览
地图、图表、数据透视表和报告等项目，它们一起可以
提供您数据的全面概览。仪表板可用
通过 *dashboards* 资源在 Web API 中。仪表板包含一个
仪表板*项目*列表。一个项目可以代表一个单一的资源，比如
图表、地图或报告表，或表示指向分析的链接列表
资源，如报告、资源、表格报告和用户。一种
仪表板项目最多可以包含八个链接。通常，仪表板
客户可以选择直接在一个
用户界面，同时将多对象项目渲染为可点击
链接。

    / api /仪表板

### 浏览仪表板 { #webapi_browsing_dashboards } 

获取包含基本信息的仪表板列表，包括
JSON 格式的标识符、名称和链接，您可以向其发出 *GET* 请求
以下网址：

    /api/dashboards.json

仪表板资源将提供仪表板列表。请记住
仪表板对象是共享的，因此列表将受
当前已验证的用户。您可以检索有关一个的更多信息
特定的仪表板，请点击其链接，类似于：

    /api/dashboards/vQFhmLJU5sK.json

仪表板包含名称和创建日期等信息以及
仪表板项目数组。 JSON 格式的响应看起来类似
对此回复（某些信息已被删除，以便
简洁）。

```json
{
  "lastUpdated" : "2013-10-15T18:17:34.084+0000",
  "id": "vQFhmLJU5sK",
  "created": "2013-09-08T20:55:58.060+0000",
  "name": "Mother and Child Health",
  "href": "https://play.dhis2.org/demo/api/dashboards/vQFhmLJU5sK",
  "publicAccess": "--------",
  "restrictFilters": false,
  "externalAccess": false,
  "itemCount": 17,
  "displayName": "Mother and Child Health",
  "access": {
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "read": true,
    "manage": true
  },
  "user": {
    "id": "xE7jOejl9FI",
    "name": "John Traore",
    "created": "2013-04-18T15:15:08.407+0000",
    "lastUpdated": "2014-12-05T03:50:04.148+0000",
    "href": "https://play.dhis2.org/demo/api/users/xE7jOejl9FI"
  },
  "dashboardItems": [{
    "id": "bu1IAnPFa9H",
    "created": "2013-09-09T12:12:58.095+0000",
    "lastUpdated": "2013-09-09T12:12:58.095+0000"
    }, {
    "id": "ppFEJmWWDa1",
    "created": "2013-09-10T13:57:02.480+0000",
    "lastUpdated": "2013-09-10T13:57:02.480+0000"
  }],
  "layout": {
    "spacing": {
      "column": 5,
      "row": 5
    },
    "columns": [{
      "index": 0,
      "span": 2
    }, {
      "index": 1,
      "span": 1
    }]
  },
  "userGroupAccesses": []
}
```

通过指定特定字段可以获得更定制的响应
在请求中。下面提供了一个示例，它将返回更多
有关用户仪表板上每个对象的详细信息。

    / api / dashboards / vQFhmLJU5sK /？fields =：all，dashboardItems [：all]

### 搜索仪表板 { #webapi_searching_dasboards } 

When a user is building a dashboard it is convenient
to be able to search for various analytical resources using the
*/dashboards/q* or */dashboards/search* resources. 
These resources let you search for matches on
the name property of the following objects: visualizations, eventVisualizations maps,
users, reports and resources. You can do a search by making a *GET*
request on the following resource URL pattern, where my-query should be
replaced by the preferred search query:

    /api/dashboards/q/my-query.json
    /api/dashboards/search?q=my-query

例如，此查询：

    /api/dashboards/q/ma?count=6&maxCount=20&max=REPORT&max=MAP
    /api/dashboards/search?q=ma?count=6&maxCount=20&max=REPORT&max=MAP

将搜索以下内容：

* 分析对象名称包含字符串“ ma”
* 每种类型最多返回6
* For REPORT and MAP types, return up to 20 items



Table: dashboards/q and dashboards/search query parameters

| 查询参数 | 描述 | 类型 | 默认 |
|---|---|---|---|
| 计数 | The number of items of each type to return | Positive integer | 6 |
| maxCount | The number of items of max types to return | Positive integer | 25 |
| max | The type to return the maxCount for | String [MAP&#124;USER&#124;REPORT&#124;RESOURCE&#124;VISUALIZATION#124;EVENT_VISUALIZATION,EVENT_CHART,EVENT_REPORT] | 不适用 |

支持 JSON 和 XML 响应格式。 JSON 格式的响应
将包含对匹配资源的引用和数量
总共找到匹配项，并为每种类型的资源找到匹配项。它会看起来
类似于：

```json
{
  "visualizations": [{
    "name": "ANC: ANC 3 Visits Cumulative Numbers",
    "id": "arf9OiyV7df",
    "type": "LINE"
  }, {
    "name": "ANC: 1st and 2rd trends Monthly",
    "id": "jkf6OiyV7el",
    "type": "PIVOT_TABLE"
  }],
  "eventVisualizations": [{
    "name": "Inpatient: Cases 5 to 15 years this year (case)",
    "id": "TIuOzZ0ID0V",
    "type": "LINE_LIST"
  }, {
    "name": "Inpatient: Cases last quarter (case)",
    "id": "R4wAb2yMLik",
    "type": "LINE_LIST"
  }],
  "maps": [{
    "name": "ANC: 1st visit at facility (fixed) 2013",
    "id": "YOEGBvxjAY0"
  }, {
    "name": "ANC: 3rd visit coverage 2014 by district",
    "id": "ytkZY3ChM6J"
  }],
  "reports": [{
    "name": "ANC: 1st Visit Cumulative Chart",
    "id": "Kvg1AhYHM8Q"
  }, {
    "name": "ANC: Coverages This Year",
    "id": "qYVNH1wkZR0"
  }],
  "searchCount": 8,
  "visualizationCount": 2,
  "eventVisualizationCount": 2,
  "mapCount": 2,
  "reportCount": 2,
  "userCount": 0,
  "eventReports": 0,
  "eventCharts" :0,
  "resourceCount": 0
}
```

### 创建，更新和删除仪表板 { #webapi_creating_updating_removing_dashboards } 

创建、更新和删除仪表板遵循标准 REST
语义。为了创建一个新的仪表板，您可以创建一个 *POST*
请求`/api/dashboards` 资源。从消费者的角度
首先创建仪表板然后添加项目可能会很方便
到它。请求有效负载支持 JSON 和 XML 格式。至
创建一个名为“我的仪表板”的仪表板，您可以在其中使用有效负载
像这样的 JSON：

    {
      “名称”：“我的仪表板”
    }

更新，例如重命名，仪表板，您可以使用 *PUT* 请求
类似的请求负载相同的 api/dashboards 资源。

要删除仪表板，您可以向特定的人发出 *DELETE* 请求
与此类似的仪表板资源：

    / api /仪表板/ vQFhmLJU5sK

### 添加，移动和删除仪表板项目和内容 { #webapi_adding_moving_removing_dashboard_items } 

In order to add dashboard items a consumer can use the
`/api/dashboards/<dashboard-id>/items/content` resource, where
<dashboard-id\> should be replaced by the relevant dashboard
identifier. The request must use the *POST* method. The URL syntax and
parameters are described in detail in the following table.



Table: Items content parameters

| 查询参数 | 描述 | 选项 |
|---|---|---|
| type | Type of the resource to be represented by the dashboard item | visualization &#124; map &#124; eventVisualization &#124; users &#124; reports &#124; resources &#124; app |
| id | Identifier of the resource to be represented by the dashboard item | Resource identifier |

A *POST* request URL for adding a visualization to a specific dashboard could look like this, where the last id query parameter value is the chart resource identifier:

    /api/dashboards/vQFhmLJU5sK/items/content?type=visualization&id=LW0O27b7TdD

When adding resource of type map, visualization and app, the API
will create and add a new item to the dashboard. When adding a resource
of type users, reports and resources, the API will try to
add the resource to an existing dashboard item of the same type. If no
item of same type or no item of same type with less than eight resources
associated with it exists, the API will create a new dashboard item and
add the resource to it.

In order to move a dashboard item to a new position within the list of
items in a dashboard, a consumer can make a *POST* request to the
following resource URL, where `<dashboard-id>` should be replaced by the
identifier of the dashboard, `<item-id>` should be replaced by the
identifier of the dashboard item and `<index>` should be replaced by the
new position of the item in the dashboard, where the index is
zero-based:

    / api /仪表板/ <dashboard-id> / items / <item-id> / position / <index>

要从特定仪表板中完全删除仪表板项目
消费者可以向以下资源 URL 发出 *DELETE* 请求，其中
` <dashboard-id> ` 应替换为仪表板的标识符
和 `<item-id>` 应替换为仪表板的标识符
物品。可以通过 GET 检索仪表板项目标识符
对仪表板资源 URL 的请求。

    / api /仪表板/ <dashboard-id> / items / <item-id>

要删除仪表板项目中的特定内容资源，消费者
可以向以下资源 URL 发出 *DELETE* 请求，其中
` <content-resource-id> ` 应替换为
与仪表板项目关联的资源；例如a 的标识符
报告或用户。例如，这可用于删除单个
报告类型的仪表板项目中的报告，而不是删除
仪表板项目完全：

    / api /仪表板/ <dashboard-id> / items / <item-id> / content / <content-resource-id>

### Defining a dashboard layout { #webapi_dasboard_layout } 

You can define and save a layout for each dashboard. The following object is responsible to hold this setting.

    {
      "layout": {
        "spacing": {
          "column": 5,
          "row": 5
        },
        "columns": [{
          "index": 0,
          "span": 2
        }, {
          "index": 1,
          "span": 1
        }]
      }
    }

The layout definition will be applied for all dashboard items related to the given dashboard, respecting layout attributes like spacing, columns, span and so on. See, below, a brief description of each attribute.

Table: Layout attributes

| 属性 | 描述 | 类型 |
|---|---|---|
| layout | This is the root object | 目的 |
| spacing | Defines the spacing for specific layout components. Currently, it supports columns and rows. | 目的 |
| 列 | Stores specific parameters related to columns (at the moment, index and span) | Array of objects |

## 可视化 { #webapi_visualization } 

Visualization API旨在帮助客户与图表和数据透视表/报表交互。数据可视化应用程序使用此API的端点，该应用程序允许基于客户端的定义创建，配置和管理图表和数据透视表。主要思想是使客户和用户拥有一个独特的集中式API，该API提供所有类型的图表和数据透视表以及每种可视化类型的特定参数和配置。

This API was introduced to unify both `charts` and `reportTables` APIs and entirely replace them by the `visualizations` API.

一个可视化对象由很多属性组成（有些与图表相关，有些与数据透视表相关），但负责反映对象核心信息的最重要的属性是：*"id"、"name"、"type" ”、“dataDimensionItems”、“列”、“行”和“过滤器”。*

API的根端点是`/ api / visualizations`，下表中描述了当前属性和元素的列表。



Table: Visualization attributes

| 领域 | 描述 |
|---|---|
| id | The unique identifier. |
| 码 | A custom code to identify the Visualization. |
| 名称 | The name of the Visualization |
| type | The type of the Visualization. The valid types are: COLUMN, STACKED_COLUMN, BAR, STACKED_BAR, LINE, AREA, PIE, RADAR, GAUGE, YEAR_OVER_YEAR_LINE YEAR_OVER_YEAR_COLUMN, SINGLE_VALUE, PIVOT_TABLE. |
| title | A custom title. |
| subtitle | A custom subtitle. |
| 描述 | Defines a custom description for the Visualization. |
| created | The date/time of the Visualization creation. |
| 开始日期 | The beginning date used during the filtering. |
| 结束日期 | The ending date used during the filtering. |
| sortOrder | The sorting order of this Visualization. Integer value. |
| user | An object representing the creator of the Visualization. |
| publicAccess | Sets the permissions for public access. |
| displayDensity | The display density of the text. |
| fontSize | The font size of the text. |
| fontStyle | Custom font styles for: visualizationTitle, visualizationSubtitle, horizontalAxisTitle, verticalAxisTitle, targetLineLabel, baseLineLabel, seriesAxisLabel, categoryAxisLabel, legend. |
| relativePeriods | An object representing the relative periods used in the analytics query. |
| legendSet | An object representing the definitions for the legend. |
| legendDisplayStyle | The legend's display style. It can be: FILL or TEXT. |
| legendDisplayStrategy | The legend's display style. It can be: FIXED or BY_DATA_ITEM. |
| aggregationType | Determines how the values in the pivot table are aggregated. Valid options: SUM, AVERAGE, AVERAGE_SUM_ORG_UNIT, LAST, LAST_AVERAGE_ORG_UNIT, FIRST, FIRST_AVERAGE_ORG_UNIT, COUNT, STDDEV, VARIANCE, MIN, MAX, NONE, CUSTOM or DEFAULT. |
| regressionType | A valid regression type: NONE, LINEAR, POLYNOMIAL or LOESS. |
| targetLineValue | The chart target line. Accepts a Double type. |
| targetLineLabel | The chart target line label. |
| rangeAxisLabel | The chart vertical axis (y) label/title. |
| domainAxisLabel | The chart horizontal axis (x) label/title. |
| rangeAxisMaxValue | The chart axis maximum value. Values outside of the range will not be displayed. |
| rangeAxisMinValue | The chart axis minimum value. Values outside of the range will not be displayed. |
| rangeAxisSteps | The number of axis steps between the minimum and maximum values. |
| rangeAxisDecimals | The number of decimals for the axes values. |
| baseLineValue | A chart baseline value. |
| baseLineLabel | A chart baseline label. |
| digitGroupSeparator | The digit group separator. Valid values: COMMA, SPACE or NONE. |
| topLimit | The top limit set for the Pivot table. |
| measureCriteria | Describes the criteria applied to this measure. |
| percentStackedValues | Uses stacked values or not. More likely to be applied for graphics/charts. Boolean value. |
| noSpaceBetweenColumns | Show/hide space between columns. Boolean value. |
| regression | Indicates whether the Visualization contains regression columns. More likely to be applicable to Pivot/Report. Boolean value. |
| externalAccess | Indicates whether the Visualization is available as external read-only. Only applies when no user is logged in. Boolean value. |
| userOrganisationUnit | Indicates if the user has an organisation unit. Boolean value. |
| userOrganisationUnitChildren | Indicates if the user has a children organisation unit. Boolean value. |
| userOrganisationUnitGrandChildren | Indicates if the user has a grand children organisation unit . Boolean value. |
| reportingParams | Object used to define boolean attributes related to reporting. |
| rowTotals | Displays (or not) the row totals. Boolean value. |
| colTotals | Displays (or not) the columns totals. Boolean value. |
| rowSubTotals | Displays (or not) the row sub-totals. Boolean value. |
| colSubTotals | Displays (or not) the columns sub-totals. Boolean value. |
| cumulativeValues | Indicates whether the visualization is using cumulative values. Boolean value. |
| hideEmptyColumns | Indicates whether to hide columns with no data values. Boolean value. |
| hideEmptyRows | Indicates whether to hide rows with no data values. Boolean value. |
| fixColumnHeaders | Keeps the columns' headers fixed (or not) in a Pivot Table. Boolean value. |
| fixRowHeaders | Keeps the rows' headers fixed (or not) in a Pivot Table. Boolean value. |
| completedOnly | Flag used in analytics requests. If true, only completed events/enrollments will be taken into consideration. Boolean value. |
| skipRounding | Apply or not rounding. Boolean value. |
| showDimensionLabels | Shows the dimension labels or not. Boolean value. |
| hideTitle | Hides the title or not. Boolean value. |
| hideSubtitle | Hides the subtitle or not. Boolean value. |
| hideLegend | Show/hide the legend. Very likely to be used by charts. Boolean value. |
| showHierarchy | Displays (or not) the organisation unit hierarchy names. Boolean value. |
| showData | Used by charts to hide or not data/values within the rendered model. Boolean value. |
| lastUpdatedBy | Object that represents the user that applied the last changes to the Visualization. |
| lastUpdated | The date/time of the last time the Visualization was changed. |
| favorites | List of user ids who have marked this object as a favorite. |
| subscribers | List of user ids who have subscribed to this Visualization. |
| translations | Set of available object translation, normally filtered by locale. |
| outlierAnalysis | Object responsible to keep settings related to outlier analysis. The internal attribute 'outlierMethod' supports: IQR, STANDARD_Z_SCORE, MODIFIED_Z_SCORE. The 'normalizationMethod' accepts only Y_RESIDUALS_LINEAR for now. |
| seriesKey | Styling options for and whether or not to display the series key. |
| 传说 | Options for and whether or not to apply legend colors to the chart series. |

### 检索可视化 { #webapi_visualization_retrieving_visualizations } 

To retrieve a list of all existing visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared visualizations plus your private ones.

    GET /api/visualizations.json

如果要检索特定可视化的JSON定义，可以将其各自的标识符添加到URL：

    GET /api/visualizations/hQxZGXqnLS9.json

以下表示是JSON格式的响应示例（为简便起见，某些信息已被删除）。对于完整的模式，请使用`GET / api / schemas / visualization`。

```json
{
  "lastUpdated": "2020-02-06T11:57:09.678",
  "href": "http://my-domain/dhis/api/visualizations/hQxZGXqnLS9",
  "id": "hQxZGXqnLS9",
  "created": "2017-05-19T17:22:00.785",
  "name": "ANC: ANC 1st visits last 12 months cumulative values",
  "publicAccess": "rw------",
  "userOrganisationUnitChildren": false,
  "type": "LINE",
  "access": {},
  "reportingParams": {
    "parentOrganisationUnit": false,
    "reportingPeriod": false,
    "organisationUnit": false,
    "grandParentOrganisationUnit": false
  },
  "dataElementGroupSetDimensions": [],
  "attributeDimensions": [],
  "yearlySeries": [],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "title": {
        "textMode": "CUSTOM",
        "text": "Any Title"
      }
    }
  ],
  "filterDimensions": [
    "dx"
  ],
  "columns": [
    {
      "id": "ou"
    }
  ],
  "dataElementDimensions": [],
  "categoryDimensions": [],
  "rowDimensions": [
    "pe"
  ],
  "columnDimensions": [
    "ou"
  ],
  "dataDimensionItems": [
    {
      "dataDimensionItemType": "DATA_ELEMENT",
      "dataElement": {
        "id": "fbfJHSPpUQD"
      }
    }
  ],
  "filters": [
    {
      "id": "dx"
    }
  ],
  "rows": [
    {
      "id": "pe"
    }
  ]
}
```
通过在URL中指定要提取的字段，可以获得更定制的响应。即：

    GET /api/visualizations/hQxZGXqnLS9.json?fields=interpretations

将返回

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### 创建，更新和删除可视化 { #webapi_visualization_add_update_remove_visualizations } 

These operations follow the standard *REST* semantics. A new Visualization can be created through a `POST` request to the `/api/visualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
  "columns": [
    {
      "dimension": "J5jldMd8OHv",
      "items": [
        {
          "name": "CHP",
          "id": "uYxK4wmcPqA",
          "displayName": "CHP",
          "displayShortName": "CHP",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        },
        {
          "name": "Hospital",
          "id": "tDZVQ1WtwpA",
          "displayName": "Hospital",
          "displayShortName": "Hospital",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        }
      ]
    }
  ],
  "rows": [
    {
      "dimension": "SooXFOUnciJ",
      "items": [
        {
          "name": "DOD",
          "id": "B0bjKC0szQX",
          "displayName": "DOD",
          "displayShortName": "DOD",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        },
        {
          "name": "CDC",
          "id": "OK2Nr4wdfrZ",
          "displayName": "CDC",
          "displayShortName": "CDC",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        }
      ]
    }
  ],
  "filters": [
    {
      "dimension": "ou",
      "items": [
        {
          "name": "Sierra Leone",
          "id": "ImspTQPwCqd",
          "displayName": "Sierra Leone",
          "displayShortName": "Sierra Leone",
          "dimensionItemType": "ORGANISATION_UNIT"
        },
        {
          "name": "LEVEL-1",
          "id": "LEVEL-H1KlN4QIauv",
          "displayName": "LEVEL-1"
        }
      ]
    }
  ],
  "name": "HIV Cases Monthly",
  "description": "Cases of HIV across the months",
  "category": "XY1vwCQskjX",
  "showDimensionLabels": true,
  "hideEmptyRows": true,
  "hideEmptyColumns": true,
  "skipRounding": true,
  "aggregationType": "SUM",
  "regressionType": "LINEAR",
  "type": "PIVOT_TABLE",
  "numberType": "VALUE",
  "measureCriteria": "Some criteria",
  "showHierarchy": true,
  "completedOnly": true,
  "displayDensity": "NORMAL",
  "fontSize": "NORMAL",
  "digitGroupSeparator": "SPACE",
  "legendDisplayStyle": "FILL",
  "legendDisplayStrategy": "FIXED",
  "hideEmptyRowItems": "BEFORE_FIRST_AFTER_LAST",
  "fixColumnHeaders": true,
  "fixRowHeaders": false,
  "regression": false,
  "cumulative": true,
  "sortOrder": 1,
  "topLimit": 2,
  "rowTotals": true,
  "colTotals": true,
  "hideTitle": true,
  "hideSubtitle": true,
  "hideLegend": true,
  "showData": true,
  "percentStackedValues": true,
  "noSpaceBetweenColumns": true,
  "rowSubTotals": true,
  "colSubTotals": true,
  "userOrgUnitType": "TEI_SEARCH",
  "externalAccess": false,
  "publicAccess": "--------",
  "reportingParams": {
    "reportingPeriod": true,
    "organisationUnit": true,
    "parentOrganisationUnit": true,
    "grandParentOrganisationUnit": true
  },
  "parentGraphMap": {
    "ImspTQPwCqd": ""
  },
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": false,
    "write": true,
    "manage": false
  },
  "optionalAxes": [
    {
      "dimensionalItem": "fbfJHSPpUQD",
      "axis": 1
    },
    {
      "dimensionalItem": "cYeuwXTCPkU",
      "axis": 2
    }
  ],
  "relativePeriods": {
    "thisYear": false,
    "quartersLastYear": true,
    "last52Weeks": false,
    "thisWeek": false,
    "lastMonth": false,
    "last14Days": false,
    "biMonthsThisYear": false,
    "monthsThisYear": false,
    "last2SixMonths": false,
    "yesterday": false,
    "thisQuarter": false,
    "last12Months": false,
    "last5FinancialYears": false,
    "thisSixMonth": false,
    "lastQuarter": false,
    "thisFinancialYear": false,
    "last4Weeks": false,
    "last3Months": false,
    "thisDay": false,
    "thisMonth": false,
    "last5Years": false,
    "last6BiMonths": false,
    "last4BiWeeks": false,
    "lastFinancialYear": false,
    "lastBiWeek": false,
    "weeksThisYear": false,
    "last6Months": false,
    "last3Days": false,
    "quartersThisYear": false,
    "monthsLastYear": false,
    "lastWeek": false,
    "last7Days": false,
    "thisBimonth": false,
    "lastBimonth": false,
    "lastSixMonth": false,
    "thisBiWeek": false,
    "lastYear": false,
    "last12Weeks": false,
    "last4Quarters": false
  },
  "user": {},
  "yearlySeries": [
    "THIS_YEAR"
  ],
  "userGroupAccesses": [
    {
      "access": "rwx-----",
      "userGroupUid": "ZoHNWQajIoe",
      "displayName": "Bo District M&E officers",
      "id": "ZoHNWQajIoe"
    }
  ],
  "userAccesses": [
    {
      "access": "--------",
      "displayName": "John Barnes",
      "id": "DXyJmlo9rge",
      "userUid": "DXyJmlo9rge"
    }
  ],
  "legendSet": {
    "name": "Death rate up",
    "id": "ham2eIDJ9k6",
    "legends": [
      {
        "startValue": 1,
        "endValue": 2,
        "color": "red",
        "image": "some-image"
      },
      {
        "startValue": 2,
        "endValue": 3,
        "color": "blue",
        "image": "other-image"
      }
    ]
  },
  "outlierAnalysis": {
    "enabled": true,
    "outlierMethod": "IQR",
    "thresholdFactor": 1.5,
    "normalizationMethod": "Y_RESIDUALS_LINEAR",
    "extremeLines": {
      "enabled": true,
      "value": 3.5
    }
  },
  "legend": {
    "strategy": "FIXED",
    "style": "FILL",
    "set": {
      "id": "fqs276KXCXi",
      "displayName": "ANC Coverage"
    },
    "showKey": false
  },
  "seriesKey": {
    "hidden": true,
    "label": {
      "fontStyle": {
        "textColor": "#cccddd"
      }
    }
  },
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ]
}
```

要更新特定的可视化，您可以向相同的 `/api/visualizations` 资源发送一个 `PUT` 请求，该资源具有类似的负载 `PLUS` 以及相应的可视化的标识符，即：

    PUT /api/visualizations/hQxZGXqnLS9

最后，要删除现有的可视化，您可以发出一个 `DELETE` 请求，指定要删除的可视化的标识符，如下所示：

    删除/ api / visualizations / hQxZGXqnLS9

## Event visualization { #webapi_event_visualization } 
<!--DHIS2-SECTION-ID:webapi_event_visualization-->
The EventVisualization API is designed to help clients to interact with event charts and reports. The endpoints of this API are used by the Event Visualization application which allows the creation, configuration and management of charts and reports based on the client's definitions. The main idea is to enable clients and users to have a unique and centralized API providing all types of event charts and reports as well as specific parameters and configuration for each type of event visualization.
This API was introduced with the expectation to unify both `eventCharts` and `eventReports` APIs and entirely replace them in favour of the `eventVisualizations` API (which means that the usage of `eventCharts` and `eventReports` APIs should be avoided). In summary, the following resources/APIs:
    /api/eventCharts, /api/eventReports
*are being replaced by*
    /api/eventVisualizations

> **Note**
>
> New applications and clients should avoid using the `eventCharts` and `eventReports` APIs because they are deprecated. Use the `eventVisualizations` API instead.

An EventVisualization object is composed of many attributes (some of them related to charting and others related to reporting), but the most important ones responsible to reflect the core information of the object are: *"id", "name", "type", "dataDimensionItems", "columns", "rows" and "filters".*
The root endpoint of the API is `/api/eventVisualizations`, and the list of current attributes and elements are described in the table below.



Table: EventVisualization attributes

| 领域 | 描述 |
|---|---|
| id | The unique identifier. |
| 码 | A custom code to identify the EventVisualiation. |
| 名称 | The name of the EventVisualiation |
| type | The type of the EventVisualiation. The valid types are: COLUMN, STACKED_COLUMN, BAR, STACKED_BAR, LINE, LINE_LIST, AREA, STACKED_AREA, PIE, RADAR, GAUGE, YEAR_OVER_YEAR_LINE, YEAR_OVER_YEAR_COLUMN, SINGLE_VALUE, PIVOT_TABLE, SCATTER, BUBBLE. |
| title | A custom title. |
| subtitle | A custom subtitle. |
| 描述 | Defines a custom description for the EventVisualiation. |
| created | The date/time of the EventVisualiation creation. |
| 开始日期 | The beginning date used during the filtering. |
| 结束日期 | The ending date used during the filtering. |
| sortOrder | The sorting order of this EventVisualiation. Integer value. |
| user | An object representing the creator of the Visualization. |
| publicAccess | Sets the permissions for public access. |
| displayDensity | The display density of the text. |
| fontSize | The font size of the text. |
| relativePeriods | An object representing the relative periods used in the analytics query. |
| 传说 | An object representing the definitions for the legend and legend set, display style (FILL or TEXT) and display strategy (FIXED or BY_DATA_ITEM). |
| aggregationType | Determines how the values are aggregated (if applicable). Valid options: SUM, AVERAGE, AVERAGE_SUM_ORG_UNIT, LAST, LAST_AVERAGE_ORG_UNIT, FIRST, FIRST_AVERAGE_ORG_UNIT, COUNT, STDDEV, VARIANCE, MIN, MAX, NONE, CUSTOM or DEFAULT. |
| regressionType | A valid regression type: NONE, LINEAR, POLYNOMIAL or LOESS. |
| targetLineValue | The chart target line. Accepts a Double type. |
| targetLineLabel | The chart target line label. |
| rangeAxisLabel | The chart vertical axis (y) label/title. |
| domainAxisLabel | The chart horizontal axis (x) label/title. |
| rangeAxisMaxValue | The chart axis maximum value. Values outside of the range will not be displayed. |
| rangeAxisMinValue | The chart axis minimum value. Values outside of the range will not be displayed. |
| rangeAxisSteps | The number of axis steps between the minimum and maximum values. |
| rangeAxisDecimals | The number of decimals for the axes values. |
| baseLineValue | A chart baseline value. |
| baseLineLabel | A chart baseline label. |
| digitGroupSeparator | The digit group separator. Valid values: COMMA, SPACE or NONE. |
| topLimit | The top limit set for the Pivot table. |
| measureCriteria | Describes the criteria applied to this measure. |
| percentStackedValues | Uses stacked values or not. More likely to be applied for graphics/charts. Boolean value. |
| noSpaceBetweenColumns | Show/hide space between columns. Boolean value. |
| externalAccess | Indicates whether the EventVisualization is available as external read-only. Boolean value. |
| userOrganisationUnit | Indicates if the user has an organisation unit. Boolean value. |
| userOrganisationUnitChildren | Indicates if the user has a children organisation unit. Boolean value. |
| userOrganisationUnitGrandChildren | Indicates if the user has a grand children organisation unit. Boolean value. |
| rowTotals | Displays (or not) the row totals. Boolean value. |
| colTotals | Displays (or not) the columns totals. Boolean value. |
| rowSubTotals | Displays (or not) the row sub-totals. Boolean value. |
| colSubTotals | Displays (or not) the columns sub-totals. Boolean value. |
| cumulativeValues | Indicates whether the EventVisualization is using cumulative values. Boolean value. |
| hideEmptyRows | Indicates whether to hide rows with no data values. Boolean value. |
| completedOnly | Flag used in analytics requests. If true, only completed events/enrollments will be taken into consideration. Boolean value. |
| showDimensionLabels | Shows the dimension labels or not. Boolean value. |
| hideTitle | Hides the title or not. Boolean value. |
| hideSubtitle | Hides the subtitle or not. Boolean value. |
| showHierarchy | Displays (or not) the organisation unit hierarchy names. Boolean value. |
| showData | Used by charts to hide or not data/values within the rendered model. Boolean value. |
| lastUpdatedBy | Object that represents the user that applied the last changes to the EventVisualization. |
| lastUpdated | The date/time of the last time the EventVisualization was changed. |
| favorites | List of user ids who have marked this object as a favorite. |
| subscribers | List of user ids who have subscribed to this EventVisualization. |
| translations | Set of available object translation, normally filtered by locale. |
| program | The program associated. |
| programStage | The program stage associated. |
| programStatus | The program status. It can be ACTIVE, COMPLETED, CANCELLED. |
| eventStatus | The event status. It can be ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED. |
| dataType | The event data type. It can be AGGREGATED_VALUES or EVENTS. |
| columnDimensions | The dimensions defined for the columns. |
| rowDimensions | The dimensions defined for the rows. |
| filterDimensions | The dimensions defined for the filters. |
| outputType | Indicates output type of the EventVisualization. It can be EVENT, ENROLLMENT or TRACKED_ENTITY_INSTANCE. |
| collapseDataDimensions | Indicates whether to collapse all data dimensions into a single dimension. Boolean value. |
| hideNaData | Indicates whether to hide N/A data. Boolean value. |

### Retrieving event visualizations { #webapi_event_visualization_retrieving_event_visualizations } 
<!--DHIS2-SECTION-ID:webapi_event_visualization_retrieving_event_visualizations-->
To retrieve a list of all existing event visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared event visualizations plus your private ones.
    GET /api/eventVisualizations.json
If you want to retrieve the JSON definition of a specific EventVisualization you can add its respective identifier to the URL:
    GET /api/eventVisualizations/hQxZGXqnLS9.json
The following representation is an example of a response in JSON format (for brevity, certain information has been removed). For the complete schema, please use `GET /api/schemas/eventVisualization`.

```json
{
    "lastUpdated": "2021-11-25T17:18:03.834",
    "href": "http://localhost:8080/dhis/api/eventVisualizations/EZ5jbRTxRGh",
    "id": "EZ5jbRTxRGh",
    "created": "2021-11-25T17:18:03.834",
    "name": "Inpatient: Mode of discharge by facility type this year",
    "publicAccess": "rw------",
    "userOrganisationUnitChildren": false,
    "type": "STACKED_COLUMN",
    "subscribed": false,
    "userOrganisationUnit": false,
    "rowSubTotals": false,
    "cumulativeValues": false,
    "showDimensionLabels": false,
    "sortOrder": 0,
    "favorite": false,
    "topLimit": 0,
    "collapseDataDimensions": false,
    "userOrganisationUnitGrandChildren": false,
    "displayName": "Inpatient: Mode of discharge by facility type this year",
    "percentStackedValues": false,
    "noSpaceBetweenColumns": false,
    "showHierarchy": false,
    "hideTitle": false,
    "showData": true,
    "hideEmptyRows": false,
    "hideNaData": false,
    "regressionType": "NONE",
    "completedOnly": false,
    "colTotals": false,
    "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {},
      "public": "rw------"
    },
    "programStatus": "CANCELLED",
    "hideEmptyRowItems": "NONE",
    "hideSubtitle": false,
    "outputType": "EVENT",
    "hideLegend": false,
    "externalAccess": false,
    "colSubTotals": false,
    "rowTotals": false,
    "digitGroupSeparator": "SPACE",
    "program": {
      "id": "IpHINAT79UW"
    },
    "access": {
      "read": true,
      "update": true,
      "externalize": true,
      "delete": true,
      "write": true,
      "manage": true
    },
    "lastUpdatedBy": {
      "displayName": "John Traore",
      "name": "John Traore",
      "id": "xE7jOejl9FI",
      "username": "admin"
    },
    "relativePeriods": {
      "thisYear": false,
      ...
    },
    "programStage": {
      "id": "A03MvHHogjR"
    },
    "createdBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "attributeDimensions": [],
    "translations": [],
    "legend": {
      "set": {
        "id": "gFJUXah1uRH"
      },
      "showKey": false,
      "style": "FILL",
      "strategy": "FIXED"
    },
    "filterDimensions": [
      "ou",
      "H6uSAMO5WLD"
    ],
    "interpretations": [],
    "userGroupAccesses": [],
    "subscribers": [],
    "columns": [
      {
        "id": "X8zyunlgUfM"
      }
    ]
    "periods": [],
    "categoryDimensions": [],
    "rowDimensions": [
      "pe"
    ],
    "itemOrganisationUnitGroups": [],
    "programIndicatorDimensions": [],
    "attributeValues": [],
    "columnDimensions": [
      "X8zyunlgUfM"
    ],
    "userAccesses": [],
    "favorites": [],
    "dataDimensionItems": [],
    "categoryOptionGroupSetDimensions": [],
    "organisationUnitGroupSetDimensions": [],
    "organisationUnitLevels": [],
    "organisationUnits": [
      {
        "id": "ImspTQPwCqd"
      }
    ],
    "filters": [
      {
        "id": "ou"
      },
      {
        "id": "H6uSAMO5WLD"
      }
    ],
    "rows": [
      {
        "id": "pe"
      }
    ]
}
```

A more tailored response can be obtained by specifying, in the URL, the fields you want to extract. Ie.:
    GET /api/eventVisualizations/hQxZGXqnLS9.json?fields=interpretations
will return

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### Creating, updating and removing event visualizations { #webapi_event_visualization_add_update_remove_event_visualizations } 
<!--DHIS2-SECTION-ID:webapi_event_visualization_add_update_remove_event_visualizations-->
These operations follow the standard *REST* semantics. A new EventVisualization can be created through a `POST` request to the `/api/eventVisualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
    "name": "Inpatient: Cases under 10 years last 4 quarters",
    "publicAccess": "rw------",
    "userOrganisationUnitChildren": false,
    "type": "STACKED_COLUMN",
    "subscribed": false,
    "userOrganisationUnit": false,
    "rowSubTotals": false,
    "cumulativeValues": false,
    "showDimensionLabels": false,
    "sortOrder": 0,
    "favorite": false,
    "topLimit": 0,
    "collapseDataDimensions": false,
    "userOrganisationUnitGrandChildren": false,
    "displayName": "Inpatient: Cases under 10 years last 4 quarters",
    "percentStackedValues": false,
    "noSpaceBetweenColumns": false,
    "showHierarchy": false,
    "hideTitle": false,
    "showData": true,
    "hideEmptyRows": false,
    "userAccesses": [],
    "userGroupAccesses": [],
    "hideNaData": false,
    "regressionType": "NONE",
    "completedOnly": false,
    "colTotals": false,
    "programStatus": "CANCELLED",
    "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {},
      "public": "rw------"
    },
    "displayFormName": "Inpatient: Cases under 10 years last 4 quarters",
    "hideEmptyRowItems": "NONE",
    "hideSubtitle": false,
    "outputType": "EVENT",
    "hideLegend": false,
    "externalAccess": false,
    "colSubTotals": false,
    "rowTotals": false,
    "digitGroupSeparator": "SPACE",
    "access": {
      "read": true,
      "update": true,
      "externalize": false,
      "delete": true,
      "write": true,
      "manage": true
    },
    "lastUpdatedBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "legend": {
      "set": {
        "id": "gFJUXah1uRH"
      },
      "showKey": false,
      "style": "FILL",
      "strategy": "FIXED"
    },
    "relativePeriods": {
      "thisYear": false,
    ...
    },
    "program": {
      "id": "IpHINAT79UW",
      "enrollmentDateLabel": "Date of enrollment",
      "incidentDateLabel": "Date of birth",
      "name": "Child Programme"
    },
    "programStage": {
      "id": "A03MvHHogjR",
      "executionDateLabel": "Report date",
      "name": "Birth"
    },
    "createdBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "translations": [],
    "filterDimensions": [
      "ou"
    ],
    "interpretations": [],
    "dataElementDimensions": [
      {
        "filter": "LE:10",
        "dataElement": {
          "id": "qrur9Dvnyt5"
        }
      }
    ],
    "periods": [],
    "categoryDimensions": [],
    "rowDimensions": [
      "pe"
    ],
    "columnDimensions": [
      "qrur9Dvnyt5"
    ],
    "organisationUnits": [
      {
        "id": "ImspTQPwCqd"
      }
    ],
    "filters": [
      {
        "dimension": "ou",
        "items": [
          {
            "id": "ImspTQPwCqd"
          }
        ]
      },
      {
        "dimension": "H6uSAMO5WLD",
        "items": []
      }
    ],
    "columns": [
      {
        "dimension": "X8zyunlgUfM",
        "items": [],
        "repetition": {
          "indexes": [1, 2, 3, -2, -1, 0]
        }
      },
      {
        "dimension": "eventDate",
        "items": [
          {
            "id": "2021-07-21_2021-08-01"
          },
          {
            "id": "2021-01-21_2021-02-01"
          }
        ]
      },
      {
        "dimension": "incidentDate",
        "items": [
          {
            "id": "2021-10-01_2021-10-30"
          }
        ]
      },
      {
        "dimension": "eventStatus",
        "items": [
          {
            "id": "ACTIVE"
          },
          {
            "id": "COMPLETED"
          }
        ]
      },
      {
        "dimension": "createdBy",
        "items": [
          {
            "id": "userA"
          }
        ]
      },
      {
        "dimension": "lastUpdatedBy",
        "items": [
          {
            "id": "userB"
          }
        ]
      }
    ],
    "rows": [
      {
        "dimension": "pe",
        "items": [
          {
            "id": "LAST_12_MONTHS"
          }
        ]
      }
    ]
}
```

For multi-program support, the root `program` should not be specified. This will turn the `eventVisualization` into a multi-program. Consequently, we have to specify the `program` and `programStage` (when applicable) for each `dimension` in `rows`, `columns`, and `filters`.

例：

```json
"program": null,
"columns": [
  {
    "dimension": "ou",
    "items": [
        {
            "id": "O6uvpzGd5pu"
        }
    ],
    "program": {
        "id": "IpHINAT79UW"
    }
  },
  {
    "dimensionType": "CATEGORY_OPTION_GROUP_SET",
    "items": [
      {
          "id": "JLGV7lRQRAg"
      },
      {
          "id": "p916ZCVGNyq"
      }
    ],
    "dimension": "C31vHZqu0qU",
    "program": {
        "id": "kla3mAPgvCH"
    },
    "programStage": {
        "id": "aNLq9ZYoy9W"
    }
  }
]
```

> **Note**
>
> The `repetition` attribute (in `rows`, `columns` or `filters`) indicates the events indexes to be retrieved. Taking the example above (in the previous `json` payload), it can be read as follows:
> 
    1 = First event
    2 = Second event
    3 = Third event
    ...
    -2 = Third latest event
    -1 = Second latest event
    0 = Latest event (default)

To update a specific EventVisualization, you can send a `PUT` request to the same `/api/eventVisualizations` resource with a similar payload `PLUS` the respective EventVisualization's identifier, ie.:
    PUT /api/eventVisualizations/hQxZGXqnLS9
Finally, to delete an existing EventVisualization, you can make a `DELETE` request specifying the identifier of the EventVisualization to be removed, as shown:
    DELETE /api/eventVisualizations/hQxZGXqnLS9

## 释义 { #webapi_interpretations } 

For resources related to data analysis in DHIS2, such as visualizations, maps, event reports, event charts and even visualizations you can write and share data interpretations. An interpretation can be a comment, question, observation or interpretation about a data report or visualization.

    / api /解释

### 阅读口译 { #webapi_reading_interpretations } 

为了阅读解释，我们将与
`/api/interpretations` 资源。使用字段的典型 GET 请求
过滤可以是这样的：

    GET /api/interpretations?fields=*,comments[id,text,user,mentions]

JSON 响应格式的输出可能如下所示（附加
为简洁起见省略了字段）：

```json
{
  "interpretations": [
    {
      "id": "XSHiFlHAhhh",
      "created": "2013-05-30T10:24:06.181+0000",
      "text": "Data looks suspicious, could be a data entry mistake.",
      "type": "MAP",
      "likes": 2,
      "user": {
        "id": "uk7diLujYif"
      },
      "reportTable": {
        "id": "LcSxnfeBxyi"
      },
      "visualization": {
        "id": "LcSxnfeBxyi"
      }
    }, {
      "id": "kr4AnZmYL43",
      "created": "2013-05-29T14:47:13.081+0000",
      "text": "Delivery rates in Bo looks high.",
      "type": "VISUALIZATION",
      "likes": 3,
      "user": {
        "id": "uk7diLujYif"
      },
      "visualization": {
        "id": "HDEDqV3yv3H"
      },
      "mentions": [
        {
          "created": "2018-06-25T10:25:54.498",
          "username": "boateng"
        }
      ],
      "comments": [
        {
          "id": "iB4Etq8yTE6",
          "text": "This report indicates a surge.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "iB4Etq8yTE6",
          "text": "Likely caused by heavy rainfall.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "SIjkdENan8p",
          "text": "Have a look at this @boateng.",
          "user": {
            "id": "xE7jOejl9FI"
          },
          "mentions": [
            {
              "created": "2018-06-25T10:03:52.316",
              "username": "boateng"
            }
          ]
        }
      ]
    }
  ]
}
```



Table: Interpretation fields

| 领域 | 描述 |
|---|---|
| id | The interpretation identifier. |
| created | The time of when the interpretation was created. |
| type | The type of analytical object being interpreted. Valid options: VISUALIZATION, MAP, EVENT_REPORT, EVENT_CHART, EVENT_VISUALIZATION, DATASET_REPORT. |
| user | Association to the user who created the interpretation. |
| visualization | Association to the visualization if type is VISUALIZATION |
| eventVisualization | Association to the event visualization if type is EVENT_VISUALIZATION |
| map | Association to the map if type is MAP. |
| eventReport | Association to the event report is type is EVENT_REPORT. |
| eventChart | Association to the event chart if type is EVENT_CHART. |
| dataSet | Association to the data set if type is DATASET_REPORT. |
| comments | Array of comments for the interpretation. The text field holds the actual comment. |
| mentions | Array of mentions for the interpretation. A list of users identifiers. |

对于所有分析对象，您可以将 */data* 附加到 URL 以检索
与资源关联的数据（相对于元数据）。作为
一个例子，通过跟随地图链接并附加 /data 可以
通过检索主题地图的 PNG（图像）表示
以下网址：

    https://play.dhis2.org/demo/api/maps/bhmHJ4ZCdCd/data

对于所有分析对象，您可以通过*提及*进行过滤。检索所有
您提到的用户的解释/评论
三个选项。您可以通过解释提及（提及
在解释中
    描述）：

    GET /api/interpretations?fields=*,comments[*]&filter=mentions.username:in:[boateng]

您可以通过解释评论提及（在任何
评论）：

    GET / api / interpretations？fields = *，评论[*]
      ＆filter = comments.mentions.username：in：[boateng]

您可以按包含提及的解释进行过滤
在解释或任何评论中（或结点）：

    GET /api/interpretations?fields=*,comments[*]&filter=mentions:in:[boateng]

### 写作解释 { #webapi_writing_interpretations } 

在编写解释时，您将提供解释文本作为
使用内容类型为“text/plain”的 POST 请求的请求正文。
URL 模式如下所示，其中 {object-type} 指的是
被解释的对象的类型，{object-id} 指的是
被解释对象的标识符。

    / api / interpretations / {object-type} / {object-id}

Valid options for object type are *visualization*, *map*,
*eventReport*, *eventChart*, *eventVisualization* and *dataSetReport*.

下面列出了一些有效的解释示例。

> **Note**
>
> The `eventCharts` and `eventReports` APIs are deprecated. We recommend using the `eventVisualizations` API instead.

    /api/interpretations/visualization/hQxZGXqnLS9
    /api/interpretations/map/FwLHSMCejFu
    /api/interpretations/eventReport/xJmPLGP3Cde
    /api/interpretations/eventChart/nEzXB2M9YBz
    /api/interpretations/eventVisualization/nEzXB2M9YBz
    /api/interpretations/dataSetReport/tL7eCjmDIgM

As an example, we will start by writing an interpretation for the visualization with identifier *EbRN2VIbPdV*. To write visualization interpretations we will interact with the `/api/interpretations/visualization/{visualizationId}` resource.
The interpretation will be the request body. Based on this we can put
together the following request using cURL:

```bash
curl -d "This visualization shows a significant ANC 1-3 dropout" -X POST
  "https://play.dhis2.org/demo/api/interpretations/visualization/EbRN2VIbPdV" -H "Content-Type:text/plain" -u admin:district
```

请注意，响应提供了一个带有值的 Location 标头
指示创建的解释的位置。这很有用
从客户的角度来看，当您想向
解释。

### 更新和删除解释 { #webapi_updating_removing_interpretations } 

要更新现有解释，您可以使用 PUT 请求，其中
解释文本是使用以下 URL 模式的请求正文，
其中 {id} 指的是解释标识符：

    / api / interpretations / {id}

基于此，我们可以使用curl来更新解释：

```bash
curl -d "This visualization shows a high dropout" -X PUT
  "https://play.dhis2.org/demo/api/interpretations/visualization/EV08iI1cJRA" -H "Content-Type:text/plain" -u admin:district
```

您可以使用与上面相同的 URL 模式使用 DELETE 请求来
删除解释。

### 创建解释注释 { #webapi_creating_interpretation_comments } 

在为解释撰写评论时，您将提供评论
text 作为使用内容类型的 POST 请求的请求正文
“文本/纯文本”。 URL 模式如下所示，其中
{interpretation-id} 指的是解释标识符。

    / api / interpretations / {interpretation-id} /评论

其次，我们将对我们在
上面的例子。通过查看解释响应，您将看到
返回一个 *Location* 标头。这个标题告诉我们的 URL
新创建的解释，从中我们可以阅读它的
标识符。此标识符是随机生成的，因此您必须
用您自己的命令替换下面命令中的那个。写评论
我们可以与`/api/interpretations/{id}/comments`进行交互
像这样的资源：

```bash
curl -d "An intervention is needed" -X POST
  "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments"
  -H "Content-Type:text/plain" -u admin:district
```

### 更新和删除解释注释 { #webapi_updating_removing_interpretation_comments } 

要更新解释注释，您可以使用 PUT 请求，其中
评论文本是使用以下 URL 模式的请求正文：

    / api / interpretations / {interpretation-id} / comments / {comment-id}

基于此，我们可以使用curl来更新注释：

```bash
curl "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments/idAzzhVWvh2"
  -d "I agree with that." -X PUT -H "Content-Type:text/plain" -u admin:district
```

您可以使用与上面相同的 URL 模式，使用 DELETE 请求到
删除解释注释。

### 喜欢的解释 { #webapi_liking_interpretations } 

要喜欢一个解释，你可以使用一个空的 POST 请求到
*喜欢*资源：

    POST / api / interpretations / {id} / like

将为当前经过身份验证的用户添加一个赞。一个用户可以
只喜欢解释一次。

要删除解释的赞，您可以使用 DELETE 请求
与类似操作相同的资源。

可以通过查看解释的类似状态来查看
常规 Web API 表示：

    GET /api/interpretations/{id}

在 *likes* 字段中可以找到喜欢的信息，它代表
喜欢的数量，以及 *likedBy* 数组，它枚举了喜欢的用户
喜欢这个解释。

```json
{
  "id": "XSHiFlHAhhh",
  "text": "Data looks suspicious, could be a data entry mistake.",
  "type": "VISUALIZATION",
  "likes": 2,
  "likedBy": [
    {
      "id": "k7Hg12fJ2f1"
    },
    {
      "id": "gYhf26fFkjFS"
    }
  ]
}
```
## SQL视图 { #webapi_sql_views } 

SQL 视图资源允许您创建和检索结果集
SQL 视图。 SQL 视图可以直接针对
数据库并通过 Web API 资源呈现结果集。

    / api / sqlViews

SQL 视图对于创建可能更容易的数据视图很有用
用SQL构造比较结合Web的多个对象
应用程序接口。举个例子，假设我们被要求提供一个视图
所有组织单位及其名称、父名称、组织单位
级别和名称，以及数据库中列出的坐标。风景
可能看起来像这样：

```sql
select ou.name as orgunit, par.name as parent, ou.coordinates, ous.level, oul.name 
from organisationunit ou
inner join _orgunitstructure ous on ou.organisationunitid = ous.organisationunitid
inner join organisationunit par on ou.parentid = par.organisationunitid
inner join orgunitlevel oul on ous.level = oul.level
where ou.coordinates is not null
order by oul.level, par.name, ou.name;
```

我们将使用 *curl* 首先在 DHIS2 服务器上执行视图。这
本质上是一个物化过程，并确保我们拥有
检索时可通过 SQL 视图获得的最新数据
从服务器。您可以先从 SQL 视图中查找
api/sqlViews 资源，然后使用以下命令进行 POST：

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/execute" -X POST -u admin:district
```

The next step in the process is the retrieval of the data. The endpoint is available at:

    /api/sqlViews/{id}/data(.csv)

The `id` path represents the SQL view identifier. The path extensions refers to the format of the data download. Append either `data` for JSON data or `data.csv` for comma separated  values. Support response formats are json, xml, csv, xls, html and html+css. 

As an example, the following command would retrieve CSV data for the SQL view defined above.

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv" -u admin:district
```

SQL视图有三种类型：

  - *SQL 视图：* 标准 SQL 视图。

  - *物化的SQL视图：*物化的SQL视图，意思是
    写入磁盘。需要更新以反映变化
    底层表。支持过滤结果集的标准。

  - *SQL 查询：* 普通 SQL 查询。支持内联变量
    自定义查询。

### 标准 { #webapi_sql_view_criteria } 

您可以通过以下方式对结果集中的列进行简单过滤
使用列名将 *criteria* 查询参数附加到 URL
并过滤由列分隔的值作为参数值，在
以下格式：

    / api / sqlViews / {id} / data？criteria = col1：value1＆criteria = col2：value2

As an example, to filter the SQL view result set above to only return
organisation units at level 4 you can use the following URL:

    https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv?criteria=level:4

### 变数 { #webapi_sql_view_variables } 

SQL 视图支持变量替换。变量替换只是
可用于 *query* 类型的 SQL 视图，这意味着 SQL 视图不是
在数据库中创建，但只是作为常规 SQL 查询执行。
变量可以直接插入到 SQL 查询中，并且必须在
这种格式：

    $ {variable-key}

例如，检索给定的所有数据元素的 SQL 查询
通过变量定义值类型的值类型可以看
像这样：

    从dataelement中选择*，其中valuetype ='$ {valueType}';

然后可以在请求时将这些变量作为 URL 的一部分提供
通过 *sqlViews* Web API 资源。可以提供变量
以下格式：

    / api / sqlViews / {id} / data？var = key1：value1＆var = key2：value2

与上面的示例相对应的示例查询如下所示：

    /api/sqlViews/dI68mLkP1wN/data.json?var=valueType:int

*valueType* 变量将替换为 *int* 值，并且
查询将返回具有 int 值类型的数据元素。

变量参数必须仅包含字母数字字符。这
变量必须包含字母数字、破折号、下划线和空格
仅字符。

*query* 类型的 SQL 视图还支持两个系统定义的变量，这些变量允许查询访问有关执行视图的用户的信息：

| 变量 | 手段 |
| -------- | ----- |
| ${_current_user_id} | 用户的数据库ID |
| ${_current_username} | 用户的用户名 |

这些变量的值不能作为URL的一部分提供。它们始终充满有关用户的信息。

例如，以下 *query* 类型的 SQL 视图显示分配给用户的所有组织单位：

```sql
select ou.path, ou.name
from organisationunit ou_user
join organisationunit ou on ou.path like ou_user.path || '%'
join usermembership um on um.organisationunitid = ou_user.organisationunitid
where um.userinfoid = ${_current_user_id}
order by ou.path;
```

### 筛选 { #webapi_sql_view_filtering } 

The SQL view API supports data filtering, equal to the [metadata object_filter](#webapi_metadata_object_filter). For a complete list of filter operators you can look at the documentation for [metadata object_filter](#webapi_metadata_object_filter).

To use filters, simply add them as parameters at the end of the request URL for your SQL view like this. This request will return a result including org units with "bo" in the name at level 2 of the org unit hierarchy:

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:eq:2&filter=orgunit_name:ilike:bo

以下示例将返回所有带有 `orgunit_level` 2 或
4：

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:in:[2,4]

And last, an example to return all org units that does not start with "Bo":

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_name:!like:Bo


## 数据项 { #webapi_data_items } 

This endpoint allows the user to query data related to a few different dimensional items. These items are: `INDICATOR`, `DATA_ELEMENT`, `DATA_SET`, `PROGRAM_INDICATOR`, `PROGRAM_DATA_ELEMENT`, `PROGRAM_ATTRIBUTE`. The endpoint supports only `GET` requests and, as other endpoints, can return responses in JSON or XML format.

该URL是`/ api / dataItems`，并且可以想象，它能够在同一`GET`请求中通过同一端点检索不同的对象。因此，某些可用的可查询属性将根据要查询的维项目而有所不同。

为了理解上面的陈述，让我们看一下以下请求示例：

1)`GET /api/dataItems?filter=dimensionItemType:eq:DATA_ELEMENT&filter=valueType:eq:TEXT`
在这个例子中，项目类型`DATA_ELEMENT` 有一个`valueType` 属性，可以在查询中使用。

2) `GET /api/dataItems?pageSize=50&order=displayName:asc&filter=dimensionItemType:eq:PROGRAM_INDICATOR&filter=displayName:ilike:someName&filter=programId:eq:WSGAb5XwJ3Y`

Here, the `PROGRAM_INDICATOR` allows filtering by `programId`.

So, based on the examples `1)` and `2)` if you try filtering a `DATA_ELEMENT` by `programId` or filter a `PROGRAM_INDICATOR` by `valueType`, you should get no results.
In other words, the filter will be applied only when the attribute actually exists for the respective data item.

Another important aspect to be highlighted is that this endpoint does NOT follow the same querying standards as other existing endpoints, like [Metadata object filter](#webapi_metadata_object_filter) for example. As a consequence, it supports a smaller set of features and querying.
The main reason for that is the need for querying multiple different items that have different relationships, which is not possible using the existing filtering components (used by the others endpoints).

### Endpoint responses { #webapi_data_items_possible_responses } 

Base on the `GET` request/query, the following status codes and responses are can be returned.

#### Results found (status code 200) { #results-found-status-code-200 } 

```json
{
  "pager": {
    "page": 1,
    "pageCount": 27,
    "total": 1339,
    "pageSize": 50
  },
  "dataItems": [
    {
      "simplifiedValueType": "TEXT",
      "displayName": "TB program Gender",
      "displayShortName": "TB prog. Gen.",
      "valueType": "TEXT",
      "name": "TB program Gender",
      "shortName": "TB prog Gen",
      "id": "ur1Edk5Oe2n.cejWyOfXge6",
      "programId": "ur1Edk5Oe2n",
      "dimensionItemType": "PROGRAM_ATTRIBUTE"
    }
  ]
}
```

#### Results not found (status code 200) { #results-not-found-status-code-200 } 

```json
{
  "pager": {
    "page": 1,
    "pageCount": 1,
    "total": 0,
    "pageSize": 50
  },
  "dataItems": [
  ]
}
```

#### Invalid query (status code 409) { #invalid-query-status-code-409 } 

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Unable to parse element `INVALID_TYPE` on filter dimensionItemType`. The values available are: [INDICATOR, DATA_ELEMENT, DATA_ELEMENT_OPERAND, DATA_SET, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE]",
  "errorCode": "E2016"
}
```

### 分页 { #webapi_data_items_pagination } 

This endpoint also supports pagination as a default option. If needed, you can disable pagination by adding `paging=false` to the `GET` request, i.e.: `/api/dataItems?filter=dimensionItemType:in:[INDICATOR]&paging=false`.

这是启用分页时的有效负载示例。请记住，分页是默认选项，不需要显式设置。

```json
{
  "pager": {
    "page": 1,
    "pageCount": 20,
    "total": 969,
    "pageSize": 50
  },
  "dataItems": [...]
}
```

> **Note**
>
> For elements where there is an associated Program, the program name should also be returned as part of the element name (as a prefix). The only exception is `Program Indicators`. We will not prefix the element name in this case, in order to keep the same behavior as existing endpoints.
>
> The /dataItems endpoint will bring only data items that are defined as aggregatable type. The current list of valid aggregatable types is:
`TEXT, LONG_TEXT`, `LETTER`, `BOOLEAN`, `TRUE_ONLY`, `NUMBER`, `UNIT_INTERVAL`, `PERCENTAGE`, `INTEGER`, `INTEGER_POSITIVE`, `INTEGER_NEGATIVE`, `INTEGER_ZERO_OR_POSITIVE`, `COORDINATE`.
>
> Even though the response returns several different attributes, the filtering can only be applied to specific ones: `displayName`, `name`, `valueType`, `id`, `dimensionItemType`, `programId`.
>
> The `order` will be considered invalid if it is set on top of `name` (ie.: order=*name:asc*) and a `filter` is set to `displayName` (ie.: filter=*displayName:ilike:aName*), and vice-versa.

### 响应属性 { #webapi_data_items_response_attributes } 

现在，我们已经了解了此端点的主要功能和用法，让我们看一下响应中返回的属性列表。

Table: Data items attributes

| 领域 | 描述 |
|---|---|
| id | The unique identifier. |
| 码 | A custom code to identify the dimensional item. |
| 名称 | The name given for the item. |
| displayName | The display name defined. |
| shortName | The short name given for the item. |
| displayShortName | The display short name defined. |
| dimensionItemType | The dimension type. Possible types: INDICATOR, DATA_ELEMENT, REPORTING_RATE, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE. |
| valueType | The item value type (more specific definition). Possitble types: TEXT, LONG_TEXT, LETTER, BOOLEAN, TRUE_ONLY, UNIT_INTERVAL, PERCENTAGE, INTEGER, INTEGER_POSITIVE, INTEGER_NEGATIVE, INTEGER_ZERO_OR_POSITIVE, COORDINATE |
| simplifiedValueType | The genereal representation of a value type. Valid values: NUMBER, BOOLEAN, DATE, FILE_RESOURCE, COORDINATE, TEXT |
| programId | The associated programId. |

## 查看分析性资源表示 { #webapi_viewing_analytical_resource_representations } 

DHIS2 has several resources for data analysis. These resources include
*maps*, *visualizations*, *eventVisualizations*, *reports* and *documents*. By visiting these resources you will retrieve information about the resource. For instance, by navigating to `/api/visualizations/R0DVGvXDUNP` the response will contain the name, last date of modification and so on for the chart. To retrieve the analytical representation, for instance, a PNG representation of the visualization, you can append */data* to all these resources. For instance, by visiting `/api/visualizations/R0DVGvXDUNP/data` the system will return a PNG image of the visualization.

Table: Analytical resources

| Resource | 描述 | Data URL | Resource representations |
|---|---|---|---|
| eventCharts | 活动图 | /api/eventCharts/<identifier\>/data | png |
| maps | 地图 | /api/maps/<identifier\>/data | png |
| visualizations | Pivot tables and charts | /api/visualizations/<identifier\>/data | json &#124; jsonp &#124; html &#124; xml &#124; pdf &#124; xls &#124; csv 
| eventVisualizations | 活动图 | /api/eventVisualizations/<identifier\>/data | png 
| png |
| reports | 标准报告 | /api/reports/<identifier\>/data | pdf &#124; xls &#124; html |
| documents | 资源资源 | /api/documents/<identifier\>/data | <follows document\> |

解析表示的数据内容可以通过以下方式修改
提供 *date* 查询参数。这就要求分析
为期间维度的相对期间设置资源。

Table: Data query parameters

| 查询参数 | 值 | 描述 |
|---|---|---|
| date | Date in yyyy-MM-dd format | Basis for relative periods in report (requires relative periods) |

Table: Query parameters for png / image types (visualizations, maps)

| 查询参数 | 描述 |
|---|---|
| width | Width of image in pixels |
| height | Height of image in pixels |

用于检索各种分析的有效 URL 的一些示例
代表如下。

    /api/visualizations/R0DVGvXDUNP/data
    /api/visualizations/R0DVGvXDUNP/data?date=2013-06-01

    /api/visualizations/jIISuEWxmoI/data.html
    /api/visualizations/jIISuEWxmoI/data.html?date=2013-01-01
    /api/visualizations/FPmvWs7bn2P/data.xls
    /api/visualizations/FPmvWs7bn2P/data.pdf

    /api/eventVisualizations/x5FVFVt5CDI/data
    /api/eventVisualizations/x5FVFVt5CDI/data.png

    /api/maps/DHE98Gsynpr/data
    /api/maps/DHE98Gsynpr/data?date=2013-07-01

    /api/reports/OeJsA6K1Otx/data.pdf
    /api/reports/OeJsA6K1Otx/data.pdf?date=2014-01-01



# 分析工具 { #analytics } 

## 分析工具 { #webapi_analytics } 

要访问 DHIS2 中的分析汇总数据，您可以使用
*分析*资源。分析资源非常强大，因为它可以让您
查询和检索沿所有可用数据维度聚合的数据。
例如，您可以要求分析资源提供
一组数据元素、时间段和
组织单位。此外，您可以检索聚合数据
基于数据元素的任意数量维度的组合和
组织单位组集。

    /api/analytics

### 请求查询参数 { #webapi_analytics_query_parameters } 

分析资源可让您指定一系列查询参数：



Table: Query parameters

| 查询参数 | 需要 | 描述 | 选项（默认为默认） |
|---|---|---|---|
| 维度 | 是的 | Dimensions and dimension items to be retrieved, repeated for each. | Any dimension |
| filter | 不 | Filters and filter items to apply to the query, repeated for each. | Any dimension |
| aggregationType | 不 | Aggregation type to use in the aggregation process. | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; LAST &#124; LAST_AVERAGE_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX |
| measureCriteria | 不 | Filters for the data/measures. | EQ &#124; GT &#124; GE &#124; LT &#124; LE |
| preAggregationMeasureCriteria | 不 | Filters for the data/measure, applied before aggregation is performed. | EQ &#124; GT &#124; GE &#124; LT &#124; LE |
| 开始日期 | 不 | Start date for a date range. Will be applied as a filter. Can not be used together with a period dimension or filter. | 日期 |
| 结束日期 | 不 | End date for date range. Will be applied as a filter. Can not be used together with a period dimension or filter. | 日期 |
| skipMeta | 不 | Exclude the metadata part of the response (improves performance). | false &#124; true |
| skipData | 不 | Exclude the data part of the response. | false &#124; true |
| skipRounding | 不 | Skip rounding of data values, i.e. provide full precision. | false &#124; true |
| hierarchyMeta | 不 | Include names of organisation unit ancestors and hierarchy paths of organisation units in the metadata. | false &#124; true |
| ignoreLimit | 不 | Ignore limit on max 50 000 records in response - use with care. | false &#124; true |
| tableLayout | 不 | Use plain data source or table layout for the response. | false &#124; true |
| hideEmptyRows | 不 | Hides empty rows in response, applicable when table layout is true. | false &#124; true |
| hideEmptyColumns | 不 | Hides empty columns in response, applicable when table layout is true. | false &#124; true |
| showHierarchy | 不 | Display full org unit hierarchy path together with org unit name. | false &#124; true |
| includeNumDen | 不 | Include the numerator and denominator used to calculate the value in the response. | false &#124; true |
| includeMetadataDetails | 不 | Include metadata details to raw data response. | false &#124; true |
| displayProperty | 不 | Property to display for metadata. | NAME &#124; SHORTNAME |
| outputIdScheme | 不 | Identifier scheme used for metadata items in the query response. It accepts identifier, code or attributes. | UID &#124; UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| outputOrgUnitIdScheme | 不 | Identifier scheme used for metadata items in the query response. This parameter overrides the "outputIdScheme" specifically for for Org Units. It accepts identifier, code or attributes. | UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| outputDataElementIdScheme | 不 | Identifier scheme used for metadata items in the query response. This parameter overrides the "outputIdScheme" specifically for Data Elements. It accepts identifier, code or attributes. | UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| inputIdScheme | 不 | Identifier scheme to use for metadata items in the query request, can be an identifier, code or attributes. | UID &#124; CODE &#124; ATTRIBUTE:<ID\> |
| approvalLevel | 不 | Include data which has been approved at least up to the given approval level, refers to identifier of approval level. | Identifier of approval level |
| relativePeriodDate | 不 | Date used as basis for relative periods. | Date. |
| userOrgUnit | 不 | Explicitly define the user org units to utilize, overrides organisation units associated with the current user, multiple identifiers can be separated by semicolon. | Organisation unit identifiers. |
| 列 | 不 | Dimensions to use as columns for table layout. | Any dimension (must be query dimension) |
| rows | 不 | Dimensions to use as rows for table layout. | Any dimension (must be query dimension) |
| order | 不 | Specify the ordering of rows based on value. | ASC &#124; DESC |
| timeField | 不 | The time field to base event aggregation on. Applies to event data items only. Can be a predefined option or the ID of an attribute or data element with a time-based value type. | EVENT_DATE &#124; ENROLLMENT_DATE &#124; INCIDENT_DATE &#124; DUE_DATE &#124; COMPLETED_DATE &#124; CREATED &#124; LAST_UPDATED &#124; <Attribute ID\> &#124; <Data element ID\> |
| orgUnitField | 不 | The organisation unit field to base event aggregation on. Applies to event data items only. Can be the ID of an attribute or data element with the Organisation unit value type. The default option is specified as omitting the query parameter. | <Attribute ID\> &#124; <Data element ID\> &#124; REGISTRATION &#124; ENROLLMENT &#124; OWNER_AT_START &#124; OWNER_AT_END |
| enhancedConditions           | 不       | Enable enhanced conditions for dimensions/filters | false &#124; true |

*dimension* 查询参数定义了哪些维度应该是
包含在分析查询中。可以是任意数量的维度
指定的。每个维度都应该重复维度参数
包含在查询响应中。查询响应可能
包含指定的所有组合的聚合值
维度项。

*filter* 参数定义应将哪些维度用作
在分析查询中检索到的数据的过滤器。任意数量
可以指定过滤器。过滤器参数应该重复
要在查询中使用的每个过滤器。过滤器与维度的不同之处在于
过滤器维度不会成为查询响应的一部分
内容，并且响应中的聚合值将是
在过滤器尺寸上折叠。换句话说，数据在
响应将在过滤器维度上聚合，但过滤器
不会作为维度包含在实际响应中。作为
例如，查询按句点过滤的某些数据元素和
您可以使用以下 URL 的组织单位：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&filter=pe:2014Q1;2014Q2
      &filter=ou:O6uvpzGd5pu;lc3eMKXaEfw

*aggregationType* 查询参数允许您定义哪个聚合
运算符应该用于查询。默认情况下，聚合
将使用为查询中包含的数据元素定义的运算符。
如果您的查询不包含任何数据元素但包含数据
元素组，第一个数据元素的聚合运算符
将使用第一组。组和数据元素的顺序是
不明确的。此查询参数允许您覆盖默认值和
指定特定的聚合运算符。例如，您可以设置
使用以下 URL 进行“计数”的聚合运算符：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2014Q1&dimension=ou:O6uvpzGd5pu
      &aggregationType=COUNT

*measureCriteria* 查询参数可让您过滤掉数据范围
要返回的记录。您可以指示系统仅返回记录
其中聚合数据值等于、大于、大于或
等于、小于或小于或等于某些值。您可以指定任何
以下格式的标准数量，其中 *criteria* 和
*value* 应替换为实际值：

    /api/analytics?measureCriteria=criteria:value;criteria:value

例如，以下查询将仅返回以下记录
数据值大于或等于 6500 且小于 33000：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&measureCriteria=GE:6500;LT:33000

类似于 *measureCriteria*，*preAggregationMeasureCriteria* 查询
参数让你过滤掉数据，只有在聚合之前
执行。例如，以下查询仅聚合数据，其中
原始值在定义的标准内：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&preAggregationMeasureCriteria=GE:10;LT:100

*startDate* 和 *endDate* 参数可用于指定自定义
要汇总的日期范围。指定日期范围时，您不能
将相对或固定期间指定为维度或过滤器。日期范围
将过滤分析响应。你可以这样使用它：

    /api/analytics.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=ou:ImspTQPwCqd&startDate=2018-01-01&endDate=2018-06-01

为了让分析资源生成形状中的数据
一个现成的表格，你可以提供 *tableLayout* 参数
true 作为值。而不是生成一个普通的、规范化的数据源，
分析资源现在将生成表格布局中的数据。你
可以将 *columns* 和 *rows* 参数与维度标识符一起使用
用分号分隔作为值以指示使用哪些值
表格列和行。列和行维度必须存在
作为查询中的数据维度（不是过滤器）。这样的请求可以看
像这样：

    /api/analytics.html?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014Q1;2014Q2
      &dimension=ou:O6uvpzGd5pu&tableLayout=true&columns=dx;ou&rows=pe

*order* 参数可用于分析资源生成
有序数据。数据将按升序（或降序）排序
值。以降序对值进行排序的示例请求
顺序是：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:LAST_12_MONTHS
      &dimension=ou:O6uvpzGd5pu&order=DESC

### 尺寸和项目 { #webapi_analytics_dimensions_and_items } 

DHIS2 features a multi-dimensional data model with several fixed and
dynamic data dimensions. The fixed dimensions are the data element,
period (time) and organisation unit dimension. You can dynamically add
dimensions through categories, category option group sets, 
organisation unit group sets, data element group sets and organisation
unit group sets. The table below displays the available data dimensions
in DHIS2. Each data dimension has a corresponding *dimension
identifier*, and each dimension can have a set of *dimension items*:



Table: Dimensions and dimension items

| 尺寸 | Dimension id | Dimension items |
|---|---|---|
| Data elements, indicators, data set reporting rate metrics, data element operands, program indicators, program data elements, program attributes, validation rules | dx | Data element, indicator, data set reporting rate metrics, data element operand, program indicator, program attribute identifiers, keyword DE_GROUP-<group-id\>, IN_GROUP-<group-id\>, use <dataelement-id\>.<optioncombo-id\> for data element operands, <program-id\>.<dataelement-id\> for program data elements, <program-id\>.<attribute-id\> for program attributes, <validationrule-id\> for validation results. |
| Periods (time) | 聚乙烯 | ISO periods and relative periods, see "date and period format" |
| Organisation unit hierarchy | 欧 | Organisation unit identifiers, and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |
| Category option combinations | co | Category option combo identifiers  (omit to get all items) |
| Attribute option combinations | ao | Category option combo identifiers (omit to get all items) |
| 分类目录 | <category id\> | Category option identifiers (omit to get all items) |
| 数据元素组集 | <group set id\> | Data element group identifiers (omit to get all items) |
| Organisation unit group sets | <group set id\> | Organisation unit group identifiers (omit to get all items) |
| Category option group sets | <group set id\> | Category option group identifiers (omit to get all items) |

没有必要知道哪些对象用于
设计分析查询时的各种动态维度。你可以得到
通过访问 Web API 中的此 URL 获得动态维度的完整列表：

    /api/dimensions

If you want to retrieve only the dimensional items for a given dynamic dimension you can
use the example below. Pagination is disabled by default. It can be enabled by adding
the pagination parameter `paging=true` to the URL.

    /api/dimensions/J5jldMd8OHv/items?paging=true

The `/dimensions` API also provides an endpoint where the clients can get the *recomendations* for a given set of *dimensions*. For example:

    /api/33/dimensions/recommendations?fields=id&dimension=dx:fbfJHSPpUQD

In the example above, the client will receive back all the *Categories* that are configured as `Data dimension`s and associated (through data sets and category combos) with the data element `fbfJHSPpUQD`.
In addition, all *Organization Unit Group Set*s that are configured as `Data dimension`s will also (and always) be returned as part of the response.


The endpoint supports multiple data elements. If one wishes to send multiple data elements, they should be separated by `;`. For example:

    /api/33/dimensions/recommendations?fields=id&dimension=dx:fbfJHSPpUQD;JuTpJ2Ywq5b

> Note
>
> This endpoint returns only dimensions that can be read by the current logged user. It will check if the current user can read the data or the metadata of the respective recommended dimension. Non-authorized dimensions are omitted from the list.


分析资源的基本 URL 是`/api/analytics`。请求
您可以在其上使用查询字符串的特定维度和维度项目
以下格式，其中 `dim-id` 和 `dim-item` 应替换为实际值：

    /api/analytics?dimension=dim-id:dim-item;dim-item&dimension=dim-id:dim-item;dim-item

如上所示，维度标识符后跟一个冒号
而维度项之间用分号分隔。例如，一个
查询两个数据元素，两个期间和两个组织单位可以
使用以下 URL 完成：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2016Q1;2016Q2&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

查询按类别选项组合细分的数据，而不是
您可以在查询中包含类别维度的数据元素总计
字符串，例如像这样：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=co&dimension=pe:201601&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

When selecting data elements you can also select all data elements in a
group as items by using the `DE_GROUP-<id>` syntax:

    /api/analytics?dimension=dx:DE_GROUP-h9cuJOkOwY2
      &dimension=pe:201601&dimension=ou:O6uvpzGd5pu

选择数据集报告率时，语法包含数据
设置标识符后跟报告率指标：

    /api/analytics?dimension=dx:BfMAe6Itzgt.REPORTING_RATE;BfMAe6Itzgt.ACTUAL_REPORTS
      &dimension=pe:201601&dimension=ou:O6uvpzGd5pu

To query for program data elements (of tracker domain type) you can get
those by specifying the program for each data element using the
`<program-id>.<dataelement-id>` syntax:

    /api/analytics.json?dimension=dx:eBAyeGv0exc.qrur9Dvnyt5;eBAyeGv0exc.GieVkTxp4HH
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

To query for program attributes (tracked entity attributes) you can get
those by specifying the program for each attribute using the
`<program.id>.<attribute-id>` syntax:

    /api/analytics.json?dimension=dx:IpHINAT79UW.a3kGcGDCuk6;IpHINAT79UW.UXz7xuGCEhU
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:ImspTQPwCqd

要查询可以使用的组织单位组集和数据元素
以下网址。请注意如何将组集标识符用作
维度标识符和作为维度项的组：

    /api/analytics?dimension=Bpx0589u8y0:oRVt7g429ZO;MAs88nJc9nL
      &dimension=pe:2016&dimension=ou:ImspTQPwCqd

要查询数据元素和类别，您可以使用此 URL。使用
类别标识符作为维度标识符，类别选项作为
维度项目：

    /api/analytics?dimension=dx:s46m5MS0hxu;fClA2Erf6IO&dimension=pe:2016
      &dimension=YNZyaJHiHYq:btOyqprQ9e8;GEqzEKCHoGA&filter=ou:ImspTQPwCqd

使用相关期间和组织单位进行查询
当前用户可以使用这样的 URL：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:LAST_12_MONTHS&dimension=ou:USER_ORGUNIT

When selecting organisation units for a dimension you can select an
entire level optionally constrained by any number of boundary
organisation units with the `LEVEL-<level>` syntax. Boundary refers to a
top node in a sub-hierarchy, meaning that all organisation units at the
given level below the given boundary organisation unit in the hierarchy
will be included in the response, and is provided as regular organisation unit 
dimension items. The level value can either be a numerical level or refer to the identifier
of the organisation unit level entity. A simple query for all org units at level three:

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016&dimension=ou:LEVEL-3

具有两个边界组织单位的三级和四级查询可以是
指定如下：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:LEVEL-3;LEVEL-4;O6uvpzGd5pu;lc3eMKXaEf

When selecting organisation units you can also select all organisation
units in an organisation unit group to be included as dimension items
using the `OU_GROUP-<id>` syntax. The organisation units in the groups
can optionally be constrained by any number of boundary organisation
units. Both the level and the group items can be repeated any number of
times:

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:OU_GROUP-w0gFTTmsUcF;OU_GROUP-EYbopBOJWsW;O6uvpzGd5pu;lc3eMKXaEf

您可以将标识符方案用于元数据部分
具有 outputIdScheme 属性的分析响应，如下所示。你可以
使用 ID、代码和属性作为标识符方案：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2017Q1;2017Q2&dimension=ou:O6uvpzGd5pu&outputIdScheme=CODE

列出了使用分析资源时需要注意的一些事项
以下。

  - 数据元素、指标、数据集报告率、计划数据
    要素和计划指标是共同数据维度的一部分，
    标识为“dx”。这意味着您可以使用任何数据
    元素、指标和数据集标识符以及“dx”
    查询中的维度标识符。

  - 对于类别、数据元素组集和组织单元组
    设置维度，如果没有，将在查询中使用所有维度项
    维度项目被指定。

  - 对于期间维度，维度项为 ISO 期间
    标识符和/或相对周期。请参阅部分
    上面称为“日期和期间格式”的期间格式和
    可用的相对时期。

  - 对于组织单位维度，您可以指定要处理的项目
    组织单位或组织单位的子单位
    与当前针对请求进行身份验证的用户相关联
    使用键 `USER_ORGUNIT` 或 `USER_ORGUNIT_CHILDREN` 作为项目，
    分别。您还可以指定组织单位标识符
    直接，或两者结合。

  - 对于组织单位维度，您可以指定组织
    层次结构级别和用于请求的边界单元
    格式`LEVEL-<level>-<boundary-id>`;举个例子
    `LEVEL-3-ImspTQPwCqd`意味着低于给定的所有组织单位
    层次结构中第 3 级的边界单元。

  - 对于组织单位维度，维度项是
    组织单位及其子层次结构 - 数据将被聚合
    对于指定组织单位下的所有组织单位
    等级制度。

  - 您不能为类别选项指定维度项目
    组合维度。相反，响应将包含项目
    链接到数据值。

### dx尺寸 { #webapi_analytics_dx_dimension } 

`dx` 维度是一个特殊的维度，它可以包含所有的
以下数据类型。



Table: Data dx dimension types

| 类型 | Syntax | 描述 | 数据源 |
|---|---|---|---|
| 指示符 | <indicator-id\> | Indicator identifier. | 汇总数据 |
| Indicator grop | IN_GROUP-<indicatorgroup-id\> | Keyword followed by an indicator group identifier. Will include all indicators in the group in the response. | 汇总数据 |
| 数据元素 | <dataelement-id\> | 数据元素标识符。 | 汇总数据 |
| 数据元素组 | DE_GROUP-<dataelementgroup-id\> | Keyword followed by a data element group identifier. Will include all data elements in the group in the response. | 汇总数据 |
| 数据元素操作数 | <dataelement-id\>.<categoryoptcombo-id\>.<attributeoptcombo-id\> | Data element identifier followed by one or both of category option combination and attribute option combo identifier. Wildcard "\*" symbol can be used to indicate any option combination value. The attribute option combination identifier can be completely left out. | 汇总数据 |
| 资料集 | <dataset-id\>.<reporting-rate-metric\> | Data set identifier followed by reporting rate metric. Can be REPORTING_RATE &#124; REPORTING_RATE_ON_TIME &#124; ACTUAL_REPORTS &#124; ACTUAL_REPORTS_ON_TIME &#124; EXPECTED_REPORTS. | Data set completeness registrations |
| 程序数据元素 | <program-id\>.<dataelement-id\> | Program identifier followed by data element identifier. Reads from events within the specified program. | Events from the given program |
| 计划指标 | <programindicator-id\> | Program indicator identifier. Reads from events from within the program associated with the program identifier. | Events from the program of the program indicator |
| Validation result | <validationrule-id\> | Validation rule identifier. Will include validation rule violations for the validation rule, requires that validation results are generated and persisted. | Validation results |

Items from all of the various `dx` types can be combined in an analytics
request. An example looks like this:

    /api/analytics.json
      ?dimension=dx:Uvn6LCg7dVU;BfMAe6Itzgt.REPORTING_RATE;IpHINAT79UW.a3kGcGDCuk6
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

组语法也可以与任何其他项目一起使用。一个
示例如下所示：

    /api/analytics.json
      ?dimension=dx:DE_GROUP-qfxEYY9xAl6;IN_GROUP-oehv9EO3vP7;BfMAe6Itzgt.REPORTING_RATE
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

数据元素操作数可以选择性地指定属性选项
组合并使用通配符，例如指定所有类别选项
组合值：

    /api/analytics.json
      ?dimension=dx:Uvn6LCg7dVU.*.j8vBiBqGf6O;Uvn6LCg7dVU.Z4oQs46iTeR
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

> **Tip**
>
> A great way to learn how to use the analytics API is to use the DHIS2
> Data Visualizer web app and create a pivot table. You can play around 
> with pivot tables using the various dimensions and items and click 
> **Download** > **Plain data source** > **JSON** to see the resulting analytics 
> API calls in the address bar of your web browser.

### 回应格式 { #webapi_analytics_response_formats } 

包含聚合数据的分析响应可以在
各种表现形式。像往常一样，您可以表示对某个项目感兴趣
通过将文件扩展名附加到 URL，通过
`Accept` HTTP 标头或通过 `format` 查询参数。这
默认格式为 JSON。可用的格式和内容类型是
下面列出。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xml（应用程序/ xml）

  - csv（应用程序/ csv）

  - html（text / html）

  - html + css（text / html）

  - xls（application / vnd.ms-excel）

例如，要请求 XML 格式的分析响应，您可以
使用以下网址：

    /api/analytics.xml?dimension=dx:fbfJHSPpUQD
      &dimension=pe:2016&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

JSON响应如下所示：

```json
{
  "headers": [
    {
      "name": "dx",
      "column": "Data",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "pe",
      "column": "Period",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "value",
      "column": "Value",
      "meta": false,
      "type": "java.lang.Double"
    }
  ],
  "height": 4,
  "metaData": {
    "pe": [
      "2016Q1",
      "2016Q2"
    ],
    "ou": [
      "ImspTQPwCqd"
    ],
    "names": {
      "2016Q1": "Jan to Mar 2016",
      "2016Q2": "Apr to Jun 2016",
      "FbKK4ofIv5R": "Measles Coverage <1 y",
      "ImspTQPwCqd": "Sierra Leone",
      "eTDtyyaSA7f": "Fully Immunized Coverage"
    }
  },
  "rows": [
    [
      "eTDtyyaSA7f",
      "2016Q2",
      "81.1"
    ],
    [
      "eTDtyyaSA7f",
      "2016Q1",
      "74.7"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q2",
      "88.9"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q1",
      "84.0"
    ]
  ],
  "width": 3
}
```

响应表示维度数据表。 *headers* 数组
概述了表中包含哪些列以及哪些列
列包含。 *column* 属性显示列维度
标识符，或者如果列包含度量，则为“值”一词。这
*meta* 属性为 *true* 如果列包含维度项或
*false* 如果列包含度量（聚合数据值）。这
*name* 属性类似于 column 属性，不同之处在于它显示
如果列包含度量，则为“值”。 *type* 属性
表示列值的 Java 类类型。

*height* 和 *width* 属性表示有多少数据列和
行分别包含在响应中。

*metaData period* 属性包含一个唯一的有序数组
响应中包含的时间段。 *metaData ou* 属性包含一个
响应中包含的组织单位标识符数组。
*metaData names* 属性包含标识符之间的映射
用于数据响应和它们代表的对象的名称。
客户端可以使用它来替换数据中的标识符
响应名称以提供更有意义的数据视图
桌子。

*rows* 数组包含维度数据表。它包含
具有维度项（对象或期间标识符）和一列的列
具有聚合数据值。上面的示例响应有一个
数据/指标列、期间列和值列。首先
列包含指标标识符，第二列包含 ISO 句点
标识符，第三个包含聚合数据值。

### 约束与验证 { #webapi_analytics_constraints } 

您可以提供给
分析资源。如果违反任何约束，API 将
返回一个 *409 Conflict* 响应和一个类似于下面的响应消息：

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Only a single indicator can be specified as filter",
  "errorCode": "E7108"
}
```

`httpStatus` 和 `httpStatusCode` 字段表示 HTTP 状态和
根据 HTTP 规范的状态代码。 `message` 字段提供了一个
验证错误的人类可读描述。 `errorCode` 字段
提供一个机器可读的代码，客户端可以使用它来处理
验证错误。聚合分析的可能验证错误
API 如下表所述。

| 错误代码 | 信息 |
| ---------- | ------- |
| E7100      | 查询参数不能为空 |
| E7101      | 必须至少指定一个尺寸 |
| E7102      | 必须至少指定一个数据维项目或数据元素组集合维项目 |
| E7103      | 尺寸不能同时指定为尺寸和过滤器 |
| E7104      | 必须至少指定一个期间作为维度或过滤器，或者开始和日期 |
| E7105      | 不能同时指定期间，开始日期和结束日期 |
| E7106      | 开始日期不能晚于结束日期 |
| E7107      | 无法为报告费率指定开始日期和结束日期 |
| E7108      | 只能将一个指标指定为过滤器 |
| E7109      | 只能将单个报告率指定为过滤器 |
| E7110      | 类别选项组合不能指定为过滤器 |
| E7111      | 尺寸不能多次指定 |
| E7112      | 只能与类型的尺寸一起指定报告率 |
| E7113      | 未指定数据元素时无法指定分配的类别 |
| E7114      | 指定的类别只能与数据元素一起指定，不能与指标或报告率一起指定 |
| E7115      | 数据元素必须具有允许聚合的值和聚合类型 |
| E7116      | 指标表达式不能包含循环引用 |
| E7117      | 当输出格式为DATA_VALUE_SET时，必须指定数据尺寸“ dx” |
| E7118      | 当输出格式为DATA_VALUE_SET时，必须指定期间尺寸“ pe” |
| E7119      | 当输出格式为DATA_VALUE_SET时，必须指定组织单位维度“ ou” |
| E7120      | 不允许用户查看组织单位 |
| E7121      | 不允许用户读取对象的数据 |
| E7122      | 数据批准级别不存在 |
| E7123      | 当前用户受维度限制，但无权访问任何维度项目 |
| E7124      | 维度存在于查询中，没有任何有效的维度选项 |
| E7125      | 维度标识符未引用任何维度 |
| E7126      | 列必须作为查询中的维存在 |
| E7127      | 行必须作为查询中的维存在 |
| E7128      | 查询结果集超出最大限制 |
| E7129      | 程序已指定但不存在 |
| E7130      | 已指定程序阶段，但不存在 |
| E7131      | 查询失败，可能是因为查询超时 |

### 数据值设定格式 { #webapi_analytics_data_value_set_format } 

分析 *dataValueSet* 资源允许返回聚合
数据值集格式的数据。这种格式代表原始数据
值，而不是按照各种方式汇总的数据
方面。将聚合数据导出为常规数据值很有用
当目标系统包含数据时，用于系统之间的数据交换
与目标系统存储的内容相比具有更精细的粒度。

例如，可以在目标系统中指定一个指标来
汇总多个数据元素的数据并将此数据导入
目标系统中的单个数据元素。再举一个例子，一个
可以汇总在目标的组织单位级别 4 收集的数据
系统级别 2 并将该数据导入目标系统。

您可以从原始数据值集格式中检索数据
数据值集资源：

    /api/analytics/dataValueSet

支持以下资源表示形式：

  - json（应用程序/ json）

  - xml（应用程序/ xml）

使用数据值集格式时，必须正好三个维度
指定为分析维度，每个维度至少有一个维度项目：

  - 资料（dx）

  - 周期（pe）

  - 组织单位（ou）

任何其他维度都将被忽略。过滤器将被应用
定期分析请求。请注意，任何数据维度类型都可以
指定，包括指示符、数据元素、数据元素操作数、
数据集和计划指标。

汇总特定指标数据的示例请求，
期间和组织单位并将其作为常规数据值返回
XML 看起来像这样：

    api / analytics / dataValueSet.xml？dimension = dx：Uvn6LCg7dVU; OdiHJayrsKo
      ＆dimension = pe：LAST_4_QUARTERS＆dimension = ou：lc3eMKXaEfw; PMa2VCrupOd

聚合数据元素操作数的数据并使用 CODE 的请求
因为输出标识符方案如下所示。当定义
输出标识符方案，响应的所有元数据对象部分都是
做作的：

    api / analytics / dataValueSet.json？dimension = dx：fbfJHSPpUQD.pq2XI5kz2BY; fbfJHSPpUQD.PT59n8BQbqM
      ＆dimension = pe：LAST_12_MONTHS＆dimension = ou：ImspTQPwCqd＆outputIdScheme = CODE

使用基于属性的标识符方案进行导出时存在风险
产生重复的数据值。布尔查询参数
duplicatesOnly 可用于调试目的仅返回
重复数据值。此响应可用于清理
重复：

    api / analytics / dataValueSet.xml？dimension = dx：Uvn6LCg7dVU; OdiHJayrsKo
      ＆dimension = pe：LAST_4_QUARTERS＆dimension = ou：lc3eMKXaEfw＆duplicatesOnly = true

### 原始数据格式 { #webapi_analytics_raw_data } 

分析 *rawData* 资源允许返回存储在
未执行任何聚合的分析数据表。这
对于想要执行聚合和的客户很有用
自行过滤，而无需对数据进行非规范化
可用的数据维度本身。

    / api / analytics / rawData

支持以下资源表示形式：

  - json（应用程序/ json）

  - csv（应用程序/ csv）

此资源遵循常规分析资源的语法。仅有的
支持查询参数的子集。此外，一个
*startDate* 和 *endDate* 参数可用。支持的
参数如下表所示。



Table: Query parameters

| 查询参数 | Required / Notes |
|---|---|
| 维度 | 是的 |
| 开始日期 | No / yyyy-MM-dd |
| 结束日期 | No / yyyy-MM-dd |
| skipMeta | 不 |
| skipData | 不 |
| hierarchyMeta | 不 |
| showHierarchy | 不 |
| displayProperty | 不 |
| outputIdScheme | 不 |
| outputOrgUnitIdScheme | 不 |
| outputDataElementIdScheme | 不 |
| inputIdScheme | 不 |
| userOrgUnit | 不 |

*dimension* 查询参数定义了哪些维度（表列）
应包含在响应中。它可以选择性地受到约束
与项目。 *filter* 查询参数定义了哪些项目和
维度（表格列）应用作响应的过滤器。

对于组织单位维度，响应将包含数据
与组织单位和该组织中的所有组织单位相关联
子层次结构（树中的孩子）。这与
常规分析资源，其中只有明确选择的
包括组织单位。

要检索具有特定数据元素、特定时间段的响应，
两个自定义维度的特定组织单位和所有数据
可以发出这样的请求：

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      ＆dimension = J5jldMd8OHv＆dimension = Bpx0589u8y0
      ＆dimension = pe：LAST_12_MONTHS
      ＆dimension = ou：O6uvpzGd5pu; fdc6uOvgoji

*startDate* 和 *endDate* 参数允许获取链接的数据
到这些日期之间的任何时间段。这避免了定义所有
期间明确在
    要求：

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      ＆dimension = J5jldMd8OHv＆dimension = Bpx0589u8y0
      ＆startDate = 2015-01-01＆endDate = 2015-12-31
      ＆dimension = ou：O6uvpzGd5pu; fdc6uOvgoji

*filter* 参数可用于过滤响应，而无需
包括该维度作为响应的一部分，这次是在 CSV 中
格式：

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      ＆filter = J5jldMd8OHv：uYxK4wmcPqA; tDZVQ1WtwpA
      ＆startDate = 2015-01-01＆endDate = 2015-12-31
      ＆dimension = ou：O6uvpzGd5pu

如果您想要人类可读的数据，*outputIdScheme* 参数很有用
响应，因为它可以像这样设置为 *NAME*：

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      ＆filter = J5jldMd8OHv：uYxK4wmcPqA; tDZVQ1WtwpA
      ＆startDate = 2017-01-01＆endDate = 2017-12-31
      ＆dimension = ou：O6uvpzGd5pu
      ＆outputIdScheme = NAME

来自 *rawData* 资源的响应看起来与
定期分析资源；不同之处在于响应包含
原始的、非聚合的数据，适合进一步聚合
第三方系统。

### 调试 { #webapi_analytics_debugging } 

在调试分析请求时，检查数据会很有用
聚合分析响应的价值来源。这
*analytics/debug/sql* 资源将提供一个 SQL 语句
返回数据值表的相关内容。你可以生产
通过执行内容类型为“text/html”的 GET 请求或
如下所示的“文本/纯文本”。维度和过滤器语法与
常规分析查询：

    / api / analytics / debug / sql？dimension = dx：fbfJHSPpUQD; cYeuwXTCPkU
      ＆filter = pe：2016Q1; 2016Q2＆filter = ou：O6uvpzGd5pu

## 事件分析 { #webapi_event_analytics } 

事件分析 API 允许您访问聚合的事件数据和查询
*事件*在 DHIS2 中捕获。此资源可让您检索基于事件的
在程序和可选的程序阶段，并让您检索和
在任何事件维度上过滤事件。

    /api/analytics/events

### 尺寸和项目 { #webapi_event_analytics_dimensions_items } 

事件维度包括数据元素、属性、组织单位
和时期。聚合的事件分析资源将返回
聚合信息，例如计数或平均值。查询分析
资源将简单地返回匹配一组条件的事件，并且不会
不执行任何聚合。您可以在表单中指定维度项
来自选项集的选项和来自数据图例集的图例
与此相关的元素和属性。事件
尺寸如下表所示。



Table: Event dimensions

| 尺寸 | Dimension id | 描述 |
|---|---|---|
| 资料元素 | <id\> | Data element identifiers |
| 属性 | <id\> | Attribute identifiers |
| 句号 | 聚乙烯 | ISO periods and relative periods, see "date and period format" |
| 组织单位 | 欧 | Organisation unit identifiers and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |
| Organisation unit group sets | <org unit group set id\> | Organisation unit group set identifiers |
| 分类目录 | <category id\> | Category identifiers (program attribute categories only) |

### 请求查询参数 { #webapi_event_analytics_request_query_parameters } 

Analytics事件API可让您指定一系列查询参数。



Table: Query parameters for both event query and aggregate analytics

| 查询参数 | 需要 | 描述 | 选项（默认为默认） |
|---|---|---|---|
| program | 是的 | Program identifier. | Any program identifier |
| stage | 不 | Program stage identifier. | Any program stage identifier |
| 开始日期 | 是的 | Start date for events. | Date in yyyy-MM-dd format |
| 结束日期 | 是的 | End date for events. | Date in yyyy-MM-dd format |
| 维度 | 是的 | 维度标识符包括数据元素、属性、程序指标、期间、组织单元和组织单元组集。参数可以重复任意次数。项目过滤器可以应用于维度的格式<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 | Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN |
| filter | 不 | 维度标识符包括数据元素、属性、期间、组织单位和组织单位组集。参数可以重复任意次数。项目过滤器可以应用于维度，格式为<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 ||
| hierarchyMeta | 不 | Include names of organisation unit ancestors and hierarchy paths of organisation units in the metadata. | false &#124; true |
| eventStatus | 不 | Specify status of events to include. | ACTIVE &#124; COMPLETED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED. Can be comma separated (*for query only*). |
| programStatus | 不 | Specify enrollment status of events to include. | ACTIVE &#124; COMPLETED &#124; CANCELLED. Can be comma separated (*for query only*). |
| relativePeriodDate | string | 不 | Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |
| 列 | 不 | Dimensions to use as columns for table layout. | Any dimension (must be query dimension) |
| rows | 不 | Dimensions to use as rows for table layout. | Any dimension (must be query dimension) |
| timeField | 不 | Time field used in aggregations/queries on events. Applies to event data items only. Can be a predefined option or the ID of an attribute or data element with a time-based value type. For "/analytics/events/" endpoints, the default "timeField" is EVENT_DATE. | EVENT_DATE &#124; SCHEDULED_DATE &#124; <Attribute ID\> &#124; <Data element ID\> |



Table: Query parameters for event query analytics only

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| ouMode | 不 | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. More details [here](#webapi_tracker_orgunit_scope) | DESCENDANTS, CHILDREN, SELECTED |
| asc | 不 | Dimensions to be sorted ascending, can reference event date, org unit name and code and any item identifiers. | `ouname` &#124; `programstatus` &#124; `eventstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `eventdate` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| desc | 不 | Dimensions to be sorted descending, can reference event date, org unit name and code and any item identifiers. | `ouname` &#124; `programstatus` &#124; `eventstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `eventdate` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| coordinatesOnly | 不 | Whether to only return events which have coordinates. | false &#124; true |
| coordinateOuFallback | 不 | Program instance geometry is applied whenever organization unit geometry is missing. | false &#124; true |
| dataIdScheme | 不 | Id scheme to be used for data, more specifically data elements and attributes which have an option set or legend set, e.g. return the name of the option instead of the code, or the name of the legend instead of the legend ID, in the data response. | NAME &#124; CODE &#124; UID |
| 标头 | 不 | 作为响应的一部分返回的标头的名称。 | One or more headers name separated by comma |
| page | 不 | The page number. Default page is 1. | Numeric positive value |
| pageSize | 不 | The page size. Default size is 50 items per page. | Numeric zero or positive value |
| eventDate | no | (`events` resource only) Custom period on `eventDate` (see "custom date periods" section) | see "date and period format" section |
| enrollmentDate | no | Custom period on `enrollmentDate` (see "custom date periods" section) | see "date and period format" section |
| scheduledDate | no | (`events` resource only) Custom period on `scheduledDate` (see "custom date periods" section) | see "date and period format" section |
| incidentDate | no | Custom period on `incidentDate` (see "custom date periods" section) | see "date and period format" section |
| lastUpdated | no | Custom period on `lastUpdated` (see "custom date periods" section) | see "date and period format" section |



Table: Query parameters for aggregate event analytics only

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 价值 | 不 | Value dimension identifier. Can be a data element or an attribute which must be of numeric value type. | Data element or attribute identifier |
| aggregationType | 不 | Aggregation type for the value dimension. Default is AVERAGE. | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; LAST &#124; LAST_AVERAGE_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX |
| showHierarchy | 不 | Display full org unit hierarchy path together with org unit name. | false &#124; true |
| displayProperty | 不 | Property to display for metadata. | NAME &#124; SHORTNAME |
| sortOrder | 不 | Sort the records on the value column in ascending or descending order. | ASC &#124; DESC |
| limit | 不 | The maximum number of records to return. Cannot be larger than 10 000. | Numeric positive value |
| outputType | 不 | Specify output type for analytical data which can be events, enrollments or tracked entity instances. The two last options apply to programs with registration only. | EVENT &#124; ENROLLMENT &#124; TRACKED_ENTITY_INSTANCE |
| collapseDataDimensions | 不 | Collapse all data dimensions (data elements and attributes) into a single dimension in the response. | false &#124; true |
| skipMeta | 不 | Exclude the meta data part of the response (improves performance). | false &#124; true |
| skipData | 不 | Exclude the data part of the response. | false &#124; true |
| skipRounding | 不 | Skip rounding of aggregate data values. | false &#124; true |
| aggregateData | 不 | Produce aggregate values for the data dimensions (as opposed to dimension items). | false &#124; true |
| orgUnitField | 不 | The organisation unit field to base event aggregation on. Applies to event data items only. Can be the ID of an attribute or data element with the Organisation unit value type. The default option is specified as omitting the query parameter. | <Attribute ID\> &#124; <Data element ID\> &#124; REGISTRATION &#124; ENROLLMENT &#124; OWNER_AT_START &#124; OWNER_AT_END |




Table: Query parameters for cluster event analytics only

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| clusterSize | 是的 | Size of clusters in meters. | Numeric positive value |
| coordinateField | 不 | Field to base geospatial event analytics on. Default is event. Can be set to identifiers of attributes and data elements of value type coordinate. | EVENT &#124; <attribute-id\> &#124; <dataelement-id\> |
| bbox | 是的 | Bounding box / area of events to include in the response on the format "min longitude, min latitude, max longitude , max latitude". | 串 |
| includeClusterPoints | 不 | Include information about underlying points for each cluster, be careful if cluster represent a very high number of points. | false &#124; true |

### 事件查询分析 { #webapi_event_query_analytics } 

*analytics/events/query* 资源可让您查询捕获的
事件。此资源不执行任何聚合，而是让
您查询和过滤有关事件的信息。

    /api/analytics/events/query

您可以指定任意数量的维度和任意数量的过滤器
询问。维度项标识符可以引用任何数据元素，
人员属性、人员标识符、固定和相对时间段以及
组织单位。维度可以选择有一个查询运算符和
一个过滤器。事件查询应采用所描述的格式
    以下。

    /api/analytics/events/query/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

例如，要从“住院发病率和
2016 年 1 月至 10 月期间的死亡率”计划，其中“性别”
和“年龄”数据元素被包括在内并且“年龄”维度被过滤
在“18”上，您可以使用以下内容
    询问：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji&dimension=oZg33kd9taw&dimension=qrur9Dvnyt5:EQ:18

检索“Child”的“Birth”程序阶段的事件
2016 年 3 月至 12 月期间的“计划”计划，其中“重量”
数据元素，过滤大于
    2000年：

    /api/analytics/events/query/IpHINAT79UW?stage=A03MvHHogjR&startDate=2016-03-01
      &endDate=2016-12-31&dimension=ou:O6uvpzGd5pu&dimension=UXz7xuGCEhU:GT:2000

排序可以应用于查询事件的事件日期和
任何尺寸。按事件日期降序和升序排序
您可以使用的“年龄”数据元素维度
    用：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&desc=EVENTDATE&asc=qrur9Dvnyt5

分页可以通过指定页码和
页面大小参数。如果指定了页码但未指定页面大小，
将使用 50 的页面大小。如果指定了页面大小但页面
number 不是，将使用页码 1。获取第三页
页面大小为 20 的响应，您可以使用类似的查询
    这：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&page=3&pageSize=20

#### 筛选 { #filtering } 

过滤器可以应用于数据元素，人员属性和人员标识符。过滤是通过以下格式的查询参数值完成的：

    ＆dimension = <item-id>：<operator>：<filter-value>

例如，您可以过滤“ Weight”数据元素以获取大于2000且小于4000的值，如下所示：

    ＆dimension = UXz7xuGCEhU：GT：2000＆dimension = UXz7xuGCEhU：LT：4000

您可以使用以下方法过滤多个特定年龄的“年龄”数据元素
像这样的 IN 运算符：

    ＆dimension = qrur9Dvnyt5：IN：18; 19; 20

您可以通过重复运算符和过滤器组件为给定项目指定多个过滤器，所有组件均用分号分隔：

    ＆dimension = qrur9Dvnyt5：GT：5：LT：15

下面列出了可用的运算符。



Table: Filter operators

| Operator | 描述 |
|---|---|
| EQ | Equal to |
| !EQ | Not equal to |
| IEQ | Equal to, ignoring case |
| !IEQ | Not equal to, ignoring case |
| GT | Greater than |
| GE | Greater than or equal to |
| LT | Less than |
| LE | Less than or equal to |
| NE | Not equal to |
| LIKE | Like (free text match) |
| !LIKE | Not like (free text match) |
| ILIKE | Like, ignoring case (free text match) |
| !ILIKE | Not like, ignoring case (free text match) |
| IN | Equal to one of multiple values separated by ";" |

#### Time Field Filtering { #time-field-filtering } 

By default, the `query` endpoints filter periods based on `eventDate`.
However, it is possible to filter entries based on `lastUpdated` or `schedule` instead, by using the `timeField` query parameter.
For example:

    &timeField=LAST_UPDATED
    &timeField=SCHEDULED_DATE

#### Enhanced conditions { #enhanced-conditions } 

By default `enhancedConditions` flag is set to `false`. This means all conditions expressed in `dimension` and `filter` are meant as `AND` conditions.
For example:

    dimension=a:GT:20:LT:40&dimension=b:GT:1:LT:5

translates into the following logical condition:

    a>20 and a<40 and b>1 and b<5 

However, there are cases in which more control on conditions might be needed and can be enabled by setting `enhancedConditions` query parameter to `true`.
By doing so, a client can use a special `_OR_` separator to join conditions using `OR` logical operator.

例：

    dimension=a:GT:20:LT:40_OR_b:GT:1:LT:5&dimension=c:EQ:test

translates into the following logical condition:

    ((a>20 and a<40) or (b>1 and b<5)) and c = "test"

#### 回应格式 { #response-formats } 

默认的响应表示格式是 JSON。请求必须使用 HTTP *GET* 方法。支持以下响应格式。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xls（application / vnd.ms-excel）

例如，要获得Excel格式的响应，可以在请求URL中使用文件扩展名，如下所示：

    /api/analytics/events/query/eBAyeGv0exc.xls?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=oZg33kd9taw&dimension=qrur9Dvnyt5

您可以将hierarchyMeta 查询参数设置为true，以便
在元部分中包括所有祖先组织单位的名称
响应：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:YuQRtpLP10I&dimension=qrur9Dvnyt5:EQ:50&hierarchyMeta=true

默认响应JSON格式将类似于以下内容：

```json
{
  "headers": [
    {
      "name": "psi",
      "column": "Event",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ps",
      "column": "Program stage",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "eventdate",
      "column": "Event date",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdated",
      "column": "Last Updated",
      "valueType": "DATE",
      "type": "java.time.LocalDate",
      "hidden": false,
      "meta": true
    },
    {
      "name": "createdbydisplayname",
      "column": "Created by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdatedbydisplayname",
      "column": "Last updated by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "coordinates",
      "column": "Coordinates",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "qrur9Dvnyt5": "Age",
      "eBAyeGv0exc": "Inpatient morbidity and mortality",
      "ImspTQPwCqd": "Sierra Leone",
      "O6uvpzGd5pu": "Bo",
      "YuQRtpLP10I": "Badjia",
      "oZg33kd9taw": "Gender"
    },
    "ouHierarchy": {
      "YuQRtpLP10I": "/ImspTQPwCqd/O6uvpzGd5pu"
    }
  },
  "width": 8,
  "height": 4,
  "rows": [
    [
      "yx9IDINf82o",
      "Zj7UnCAulEk",
      "2016-08-05",
      "system",
      "2018-08-07",
      "[5.12, 1.23]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "IPNa7AsCyFt",
      "Zj7UnCAulEk",
      "2016-06-12",
      "system",
      "2018-08-07",
      "[5.22, 1.43]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "ZY9JL9dkhD2",
      "Zj7UnCAulEk",
      "2016-06-15",
      "system",
      "2018-08-07",
      "[5.42, 1.33]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "MYvh4WAUdWt",
      "Zj7UnCAulEk",
      "2016-06-16",
      "system",
      "2018-08-07",
      "[5.32, 1.53]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ]
  ]
}
```

响应的 *headers* 部分描述了查询的内容
结果。事件唯一标识符、节目阶段标识符、
事件日期、组织单位名称、组织单位代码和
组织单位标识符显示为前六个维度
响应并将始终存在。接下来是数据元素，
指定为的人员属性和人员标识符
请求中的维度，在本例中为“性别”和“年龄”数据
元素尺寸。标题部分包含的标识符
“名称”属性中的维度项和可读维度
“列”属性中的描述。

*metaData* 部分，*ou* 对象包含映射到表示层次结构的字符串的响应中存在的所有组织单位的标识符。此层次结构字符串从根开始列出组织单位的祖先（父）的标识符。 *names* 对象包含响应中映射到其名称的所有项目的标识符。

*rows* 部分包含查询产生的事件。每一行
正好代表一个事件。

为了让事件分析资源在
一个现成的表格的形状，你可以提供*行*和*列*
具有请求的维度标识符的参数以分号分隔
作为值来指示哪些用作表列和行。
事件不是生成一个普通的、规范化的数据源
分析资源现在将生成表格布局中的数据。这
列和行维度必须作为数据维度出现在
查询（不是过滤器）。这样的请求可能如下所示：

    /api/analytics.html+css?dimension=dx:cYeuwXTCPkU;fbfJHSPpUQD&dimension=pe:WEEKS_THIS_YEAR
      &filter=ou:ImspTQPwCqd&displayProperty=SHORTNAME&columns=dx&rows=pe

### 事件汇总分析 { #webapi_event_aggregate_analytics } 

`/analytics/events/aggregate` 资源可让您检索 *aggregated
DHIS2 中捕获的事件数量*。此资源可让您检索
基于程序和可选的程序阶段聚合数据，以及
允许您过滤任何事件维度。

    /api/analytics/events/aggregate

事件聚合资源不返回事件信息
本身，而不是与请求匹配的事件总数
询问。事件维度包括数据元素、人员属性、人员
标识符、期间和组织单位。聚合事件查询
应该是下面描述的格式。

    /api/analytics/events/aggregate/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

例如，要从
1 月至 10 月期间的“住院发病率和死亡率”计划
2016 年，其中包含“性别”和“年龄”数据元素，“年龄”
维度项目在“18”上过滤，“性别”项目在过滤上
“女性”，您可以使用以下查询：

    /api/analytics/events/aggregate/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=oZg33kd9taw:EQ:Female&dimension=qrur9Dvnyt5:GT:50

检索固定和相对时期的数据，而不是开始和结束
日期，在本例中为 2016 年 5 月和过去 12 个月，以及组织
与当前用户关联的单位，可以使用以下查询：

    /api/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:201605;LAST_12_MONTHS
      &dimension=ou:USER_ORGUNIT;fdc6uOvgo7ji&dimension=oZg33kd9taw

为了将“女性”指定为数据的“性别”过滤器
响应，意思是“性别”不会是响应的一部分，但会
过滤其中的聚合数字，您可以使用以下语法：

    /api/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:2016;
      &dimension=ou:O6uvpzGd5pu&filter=oZg33kd9taw:EQ:Female

要将“Bo”组织单位和期间“2016”指定为过滤器，
和“放电方式”和“性别”作为维度，其中“性别”是
在“男性”项目上过滤，您可以使用这样的查询：

    /api/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&dimension=oZg33kd9taw:EQ:Male

要为_出院模式_创建“前 3 名报告”，您可以使用限制
和 sortOrder 查询参数类似：

    /api/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&limit=3&sortOrder=DESC

要指定具有相应聚合类型的值维度，您
可以使用 value 和aggregationType 查询参数。指定一个
值维度将使分析引擎返回聚合值
对于响应中该维度的值，而不是计数
事件。

    /api/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &dimension=ou:ImspTQPwCqd&dimension=pe:LAST_12_MONTHS&dimension=fWIAEtYVEGk
      &value=qrur9Dvnyt5&aggregationType=AVERAGE

基于特定数据元素或属性的事件分析聚合
对于值类型日期或日期时间，您可以使用 `timeField` 参数：

    /api/analytics/events/aggregate/IpHINAT79UW.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:LAST_12_MONTHS&dimension=cejWyOfXge6&stage=A03MvHHogjR
      &timeField=ENROLLMENT_DATE

基于特定数据元素或属性的事件分析聚合
对于值类型的组织单元，您可以使用 `orgUnitField` 参数：

    /api/analytics/events/aggregate/eBAyeGv0exc.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:THIS_YEAR&dimension=oZg33kd9taw&stage=Zj7UnCAulEk
      &orgUnitField=S33cRBsnXPo

The `orgUnitField` parameter value may be one of the following:

| orgUnitField | 描述 |
| --- | --- |
| <Attribute ID\> | ID of an attribute with the organisation unit value type |
| <Data element ID\> | ID of a data element with the organisation unit value type |
| REGISTRATION | The organization unit at which the tracked entity instance was registered (created) |
| 注册 | The organization unit at which the tracked entity instance was enrolled in the program |
| OWNER_AT_START | The tracked entity instance's owning organisation unit at the start of the reporting period |
| OWNER_AT_END | The tracked entity instance's owning organisation unit at the end of the reporting period |

#### 范围/图例集 { #ranges-legend-sets } 

对于聚合查询，您可以为数值指定范围/图例集
数据元素和属性维度。目的是将
数值范围内。举个例子，而不是生成数据
对于不同年份的“年龄”数据元素，您可以将
年龄组的信息。为了实现这一点，数据元素或
属性必须与图例集相关联。格式是
如下面所描述的：

    ？dimension = <item-id>-<legend-set-id>

一个示例如下所示：

    /api/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &dimension=qrur9Dvnyt5-Yf6UHoPkdS6&dimension=ou:ImspTQPwCqd&dimension=pe:LAST_MONTH

#### 回应格式 { #response-formats } 

默认的响应表示格式是 JSON。请求必须是
使用 HTTP *GET* 方法。响应将类似于以下内容：

```json
{
  "headers": [
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "pe",
      "column": "Period",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "value",
      "column": "Value",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "eBAyeGv0exc": "Inpatient morbidity and mortality"
    }
  },
  "width": 5,
  "height": 39,
  "rows": [
    [
      "Female",
      "95",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "63",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "67",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "71",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "75",
      "201605",
      "O6uvpzGd5pu",
      "14"
    ],
    [
      "Female",
      "73",
      "201605",
      "O6uvpzGd5pu",
      "5"
    ]
  ]
}
```

请注意，单个响应中返回的行的最大限制为 10 000。
如果查询产生超过最大限制，*409 Conflict* 状态代码
将被退回。

### 事件聚类分析 { #webapi_event_clustering_analytics } 

*analytics/events/cluster* 资源提供集群地理空间
事件数据。请求如下所示：

    /api/analytics/events/cluster/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:LEVEL-2&clusterSize=100000
      &bbox=-13.2682125,7.3721619,-10.4261178,9.904012&includeClusterPoints=false

集群响应提供基础点的计数，中心
每个集群的点和范围。如果 `includeClusterPoints` 查询
参数设置为 true，以逗号分隔的字符串与标识符
包括基础事件。示例响应如下所示：

```json
{
  "headers": [
    {
      "name": "count",
      "column": "Count",
      "type": "java.lang.Long",
      "meta": false
    },
    {
      "name": "center",
      "column": "Center",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "extent",
      "column": "Extent",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "points",
      "column": "Points",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "width": 3,
  "height": 4,
  "rows": [
    [
      "3",
      "POINT(-13.15818 8.47567)",
      "BOX(-13.26821 8.4St7215,-13.08711 8.47807)",
      ""
    ],
    [
      "9",
      "POINT(-13.11184 8.66424)",
      "BOX(-13.24982 8.51961,-13.05816 8.87696)",
      ""
    ],
    [
      "1",
      "POINT(-12.46144 7.50597)",
      "BOX(-12.46144 7.50597,-12.46144 7.50597)",
      ""
    ],
    [
      "7",
      "POINT(-12.47964 8.21533)",
      "BOX(-12.91769 7.66775,-12.21011 8.49713)",
      ""
    ]
  ]
}
```

### 事件计数和范围分析 { #webapi_event_count_extent_analytics } 

The *analytics/events/count* resource is suitable for geometry-related
requests for retrieving the count and extent (bounding box) of events
for a specific query. The query syntax is equal to the *events/query*
resource. A request looks like this:

    /api/analytics/events/count/eBAyeGv0exc?startDate=2016-01-01
      &endDate=2016-10-31&dimension=ou:O6uvpzGd5pu

响应将以JSON格式提供计数和范围：

```json
{
  extent: "BOX(-13.2682125910096 7.38679562779441,-10.4261178860988 9.90401290212795)",
  count: 59
}
```

### 约束与验证 { #webapi_event_analytics_constraints } 

您可以提供给
事件分析资源。如果违反任何约束，API 将
返回一个 *409 Conflict* 响应和一个类似于下面的响应消息：

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "At least one organisation unit must be specified",
  "errorCode": "E7200"
}
```

描述了事件分析 API 的可能验证错误
在下表中。

| 错误代码 | 信息 |
| ---------- | ------- |
| E7200      | 必须至少指定一个组织单位 |
| E7201      | 尺寸不能多次指定 |
| E7202      | 不能多次指定查询项 |
| E7203      | 值维也不能指定为项目或项目过滤器 |
| E7204      | 指定聚合类型时，必须指定值维或聚合数据 |
| E7205      | 必须指定开始和结束日期或至少一个期间 |
| E7206      | 开始日期晚于结束日期 |
| E7207      | 页码必须为正数 |
| E7208      | 页面大小必须为零或正数 |
| E7209      | 限制大于最大限制 |
| E7210      | 时间字段无效 |
| E7211      | 组织单位字段无效 |
| E7212      | 群集大小必须为正数 |
| E7213      | Bbox无效，必须采用以下格式：'min-lng，min-lat，max-lng，max-lat' |
| E7214      | 当指定bbox或集群大小时，必须指定集群字段 |
| E7215      | 查询项目不能同时指定图例集和选项集 |
| E7216      | 在汇总查询中使用时，查询项必须是可汇总的 |
| E7217      | 不允许用户查看事件分析数据 |
| E7218      | 未启用空间数据库支持 |
| E7219      | 数据元素必须是值类型坐标才能用作坐标字段 |
| E7220      | 属性必须是坐标值类型，才能用作坐标域 |
| E7221      | 座标栏位无效 |
| E7222      | 查询项目或过滤器无效 |
| E7223      | 值不引用数字元素或程序一部分的数据元素或属性 |
| E7224      | 项目标识符未引用程序的任何数据元素，属性或指标部分 |
| E7225      | 计划阶段对于注册分析查询中的数据元素维度是必需的 |
| E7226      | 维度不是有效的查询项目 |
| E7227      | 不支持关系实体类型 |
| E7228      | Fallback coordinate field is invalid |
| E7229      | Operator does not allow missing value |

## 入学分析 { #webapi_enrollment_analytics } 

注册分析 API 允许您访问聚合事件数据并查询*注册及其在 DHIS2 中捕获的事件数据*。除了跟踪的实体属性之外，此资源还允许您根据程序阶段和数据元素检索程序的数据。在每个注册中查询特定程序阶段的事件数据时，每个程序阶段的数据元素值将作为来自 api 的响应中的一行返回。如果在可重复的程序阶段查询数据元素，则最新的数据元素值将用于 api 响应中的该数据元素。

### 尺寸和项目 { #webapi_enrollment_analytics_dimensions } 

注册维度包括数据元素，属性，组织单位和期间。查询分析资源将仅返回符合一组条件的注册，并且不执行任何汇总。



Table: Enrollment dimensions

| 尺寸 | Dimension id | 描述 |
|---|---|---|
| Data elements in program stages | <program stage id\>.<data element id\> | Data element identifiers must include the program stage when querying data for enrollments.      dimension=edqlbukwRfQ.vANAXwtLwcT |
| 属性 | <id\> | Attribute identifiers |
| 句号 | 聚乙烯 | ISO periods and relative periods, see "date and period format" |
| 组织单位 | 欧 | Organisation unit identifiers and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |

#### Repeatable stages { #repeatable-stages } 

Data element identifier must include program stage. The program stage can be repeatable. For example the dimension edqlbukwRfQ.vANAXwtLwcT can refer to repeatable program stage. The data element of this stage is accessible via index parameters (enclosed with [ ]).

Table: Possible indexing of repeatable stages

| 尺寸                                  | Index parameters             | DataElement value refers to                                                                |
|--------------------------------------------|------------------------------|--------------------------------------------------------------------------------------------|
| edqlbukwRfQ.vANAXwtLwcT                    | 不适用                          | last execution date                                                                        |
| edqlbukwRfQ[0].vANAXwtLwcT                 | 0                            | last execution date                                                                        |
| dqlbukwRfQ[-2].vANAXwtLwcT                 | -2                           | second from last execution date                                                            |
| dqlbukwRfQ[1].vANAXwtLwcT                  | 1                            | first execution date                                                                       |
| dqlbukwRfQ[3].vANAXwtLwcT                  | 3                            | third execution date                                                                       |
| edqlbukwRfQ[*].vANAXwtLwcT                 | *                            | all repetitions                                                                            |
| edqlbukwRfQ[-1~3].vANAXwtLwcT              | -1, 3                        | 3 repetitions starting with -1 (first after last execution date)                           |
| edqlbukwRfQ[0~5~LAST_3_MONTHS ].vANAXwtLwcT | 0, 5, LAST_3_MONTHS          | 5 repetitions starting with last execution date down to the fifth one within last 3 months |
| edqlbukwRfQ[-1~3~2021-01-01~2022-05-31].vANAXwtLwcT            | -1, 3, 2021-01-01,2022-05-31 | 3 repetitions starting with -1 (first after last execution date) within specified dates                                     |

Warning: Indexing of non-repeatable program stage leads to parameter validation error.

### 注册查询分析 { #webapi_enrollment_query_analytics } 

The `analytics/enrollments/query` resource lets you query for captured enrollments. This resource does not perform any aggregation, rather it lets you query and filter for information about enrollments.

    /api/analytics/enrollments/query

您可以在查询中指定任意数量的维度和任意数量的过滤器。维项目标识符可以引用程序阶段，已跟踪实体属性，固定和相对期间以及组织单位中的任何数据元素。维度可以选择具有查询运算符和过滤器。注册查询应采用以下所述的格式。

    /api/analytics/enrollments/query/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

例如，要从2019年1月起从“产前护理”计划中检索入学申请，该计划从属性中提取“名字”，则在第一个计划阶段包括“慢性病”和“吸烟”数据元素，并且来自以下程序阶段的“血红蛋白值”，并且仅包括具有“疯子病”的女性，您可以使用以下查询：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=w75KJ2mc4zz&dimension=WZbXY0S00lP.de0FEHSIoxh:eq:1&dimension=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=edqlbukwRfQ.vANAXwtLwcT
      &startDate=2019-01-01&endDate=2019-01-31

要从上个月（相对于执行查询的时间点）的“产前护理”程序中检索入学登记，其中“慢性病”和“吸烟”数据元素包含在第一程序阶段，而“后续计划阶段的“血红蛋白价值”，仅包括吸烟的血红蛋白少于20岁的女性：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&dimension=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD:eq:1&dimension=edqlbukwRfQ.vANAXwtLwcT:lt:20
      &dimension=pe:LAST_MONTH

可以将排序应用于注册的查询和注册的事件日期：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &columns=w75KJ2mc4zz&dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=pe:LAST_MONTH
      &stage=WZbXY0S00lP&pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

通过指定页码和页面大小参数，可以将分页应用于查询。如果指定了页码，但未指定页码，则将使用50页码。如果指定了页面大小，但未指定页面号，则将使用页面号1。要获得页面大小为10的响应的第二页，可以使用如下查询：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&dimension=w75KJ2mc4zz&dimension=pe:LAST_MONTH
      &dimension=WZbXY0S00lP.sWoqcoByYmD&pageSize=10&page=2

#### 筛选 { #filtering } 

过滤器可以应用于数据元素，人员属性和人员标识符。过滤是通过以下格式的查询参数值完成的：

    ＆dimension = <item-id>：<operator>：<filter-value>

例如，您可以过滤“ Weight”数据元素以获取大于2000且小于4000的值，如下所示：

    ＆dimension = WZbXY0S00lP.UXz7xuGCEhU：GT：2000＆dimension = WZbXY0S00lP.UXz7xuGCEhU：LT：4000

您可以使用IN运算符过滤多个特定年龄的“年龄”属性，如下所示：

    ＆dimension = qrur9Dvnyt5：IN：18; 19; 20

您可以通过重复运算符和过滤器组件为给定项目指定多个过滤器，所有组件均用分号分隔：

    ＆dimension = qrur9Dvnyt5：GT：5：LT：15

#### Time Field Filtering { #time-field-filtering } 

By default, the `query` endpoints filter periods based on `enrollmentDate`.
However, it is possible to filter entries based on `lastUpdated` instead, by using the `timeField` query parameter.

    &timeField=LAST_UPDATED

##### NV keyword { #nv-keyword } 
A special keyword `NV` can be used to filter by `null` values

Filter by AGE is null

    &dimension=qrur9Dvnyt5:EQ:NV

Filter by AGE is not null

    &dimension=qrur9Dvnyt5:NE:NV

Filter by AGE is 18, 19 or is null

    &dimension=qrur9Dvnyt5:IN:18;19;NV

`NV` can be used with `EQ`, `NE` and `IN` operators

##### Operators { #operators } 

下面列出了可用的运算符。

Table: Filter operators

| Operator | 描述 |
|---|---|
| EQ | Equal to |
| GT | Greater than |
| GE | Greater than or equal to |
| LT | Less than |
| LE | Less than or equal to |
| NE | Not equal to |
| LIKE | Like (free text match) |
| IN | Equal to one of multiple values separated by ";" |

### 请求查询参数 { #webapi_enrollment_analytics_query_parameters } 

借助Analytics（分析）注册查询API，您可以指定一系列查询参数。



Table: Query parameters for enrollment query endpoint

| 查询参数 | 需要 | 描述 | 选项（默认为默认） |
|---|---|---|---|
| program | 是的 | Program identifier. | Any program identifier |
| 开始日期 | 不 | Start date for enrollments. | Date in yyyy-MM-dd format |
| 结束日期 | 不 | End date for enrollments. | Date in yyyy-MM-dd format |
| 维度 | 是的 | 维度标识符包括数据元素、属性、程序指标、期间、组织单元和组织单元组集。参数可以重复任意次数。项目过滤器可以应用于维度的格式<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 | Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN |
| filter | 不 | 维度标识符包括数据元素、属性、期间、组织单位和组织单位组集。参数可以重复任意次数。项目过滤器可以应用于维度，格式为<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 ||
| programStatus | 不 | Specify enrollment status of enrollments to include. | ACTIVE &#124; COMPLETED &#124; CANCELLED |
| relativePeriodDate | string | 不 | Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |
| ouMode | 不 | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. More details [here](#webapi_tracker_orgunit_scope) | DESCENDANTS, CHILDREN, SELECTED |
| asc | 不 | Dimensions to be sorted ascending, can reference enrollment date, incident date, org unit name and code. | `ouname` &#124; `programstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| desc | 不 | Dimensions to be sorted descending, can reference enrollment date, incident date, org unit name and code. | `ouname` &#124; `programstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| coordinatesOnly | 不 | Whether to only return enrollments which have coordinates. | false &#124; true |
| 标头 | 不 | 作为响应的一部分返回的标头的名称。 | One or more headers name separated by comma |
| page | 不 | The page number. Default page is 1. | Numeric positive value |
| pageSize | 不 | The page size. Default size is 50 items per page. | Numeric zero or positive value |
| timeField | 不 | Time field used in aggregations/queries on enrollments. Applies to enrollment data items only. Can be a predefined option or the ID of an attribute or data element with a time-based value type. For "/analytics/enrollments/" endpoints, the default "timeField" is ENROLLMENT_DATE. | ENROLLMENT_DATE &#124; LAST_UPDATED &#124; <Attribute ID\> &#124; <Data element ID\> |

#### 回应格式 { #response-formats } 

默认的响应表示格式是 JSON。请求必须使用 HTTP *GET* 方法。支持以下响应格式。

  - json（应用程序/ json）
  - xml（应用程序/ xml）
  - xls（application / vnd.ms-excel）
  - csv（应用程序/ csv）
  - html（text / html）
  - html + css（text / html）

例如，要获得Excel格式的响应，可以在请求URL中使用文件扩展名，如下所示：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&columns=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=pe:LAST_MONTH&stage=WZbXY0S00lP
      &pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

默认响应JSON格式将类似于以下内容：

```json
{
  "headers": [
    {
      "name": "pi",
      "column": "Enrollment",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "tei",
      "column": "Tracked entity instance",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "enrollmentdate",
      "column": "Enrollment date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "incidentdate",
      "column": "Incident date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdated",
      "column": "Last Updated",
      "valueType": "DATE",
      "type": "java.time.LocalDate",
      "hidden": false,
      "meta": true
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "createdbydisplayname",
      "column": "Created by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdatedbydisplayname",
      "column": "Last updated by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "geometry",
      "column": "Geometry",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "longitude",
      "column": "Longitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "latitude",
      "column": "Latitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "de0FEHSIoxh",
      "column": "WHOMCH Chronic conditions",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    },
    {
      "name": "sWoqcoByYmD",
      "column": "WHOMCH Smoking",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    }
  ],
  "metaData": {
    "pager": {
      "page": 2,
      "total": 163,
      "pageSize": 4,
      "pageCount": 41
    },
    "items": {
      "ImspTQPwCqd": {
        "name": "Sierra Leone"
      },
      "PFDfvmGpsR3": {
        "name": "Care at birth"
      },
      "bbKtnxRZKEP": {
        "name": "Postpartum care visit"
      },
      "ou": {
        "name": "Organisation unit"
      },
      "PUZaKR0Jh2k": {
        "name": "Previous deliveries"
      },
      "edqlbukwRfQ": {
        "name": "Antenatal care visit"
      },
      "WZbXY0S00lP": {
        "name": "First antenatal care visit"
      },
      "sWoqcoByYmD": {
        "name": "WHOMCH Smoking"
      },
      "WSGAb5XwJ3Y": {
        "name": "WHO RMNCH Tracker"
      },
      "de0FEHSIoxh": {
        "name": "WHOMCH Chronic conditions"
      }
    },
    "dimensions": {
      "pe": [],
      "ou": [
        "ImspTQPwCqd"
      ],
      "sWoqcoByYmD": [],
      "de0FEHSIoxh": []
    }
  },
  "width": 12,
  "rows": [
    [
      "A0cP533hIQv",
      "to8G9jAprnx",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Tonkomba MCHP",
      "OU_193264",
      "xIMxph4NMP1",
      "0",
      "1"
    ],
    [
      "ZqiUn2uXmBi",
      "SJtv0WzoYki",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Mawoma MCHP",
      "OU_254973",
      "Srnpwq8jKbp",
      "0",
      "0"
    ],
    [
      "lE747mUAtbz",
      "PGzTv2A1xzn",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Kunsho CHP",
      "OU_193254",
      "tdhB1JXYBx2",
      "",
      "0"
    ],
    [
      "nmcqu9QF8ow",
      "pav3tGLjYuq",
      "2019-02-03 12:05:00.0",
      "2019-02-03 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Korbu MCHP",
      "OU_678893",
      "m73lWmo5BDG",
      "",
      "1"
    ]
  ],
  "height": 4
}
```

响应的 *headers* 部分描述了查询结果的内容。注册唯一标识符、被跟踪实体实例标识符、注册日期、事件日期、几何形状、纬度、经度、组织单位名称和组织单位代码作为响应中的第一个维度出现并且将始终存在。接下来是数据元素和在请求中指定为维度的跟踪实体属性，在本例中为“WHOMCH 慢性条件”和“WHOMCH 吸烟”数据元素维度。标题部分在“名称”属性中包含维度项的标识符，在“列”属性中包含可读的维度描述。

*metaData* 部分，*ou* 对象包含映射到表示层次结构的字符串的响应中存在的所有组织单位的标识符。此层次结构字符串从根开始列出组织单位的祖先（父）的标识符。 *names* 对象包含响应中映射到其名称的所有项目的标识符。

*rows* 部分包含查询生成的注册。每一行正好代表一个注册。

### 使用计划指标{ #analytics-across-tei-relationships-with-program-indicators }进行TEI关系分析 { #analytics-across-tei-relationships-with-program-indicators } 

非汇总注册分析API还支持将程序指示器链接到关系类型，以显示应用于所列出的跟踪实体实例的相关实体的特定程序指示器的计算结果。

![](resources/images/enrollments/enrollments-pi-relationship.jpg)

For the Program Indicator/Relationship Type link to work, the `/api/analytics/enrollments/query` API requires an additional dimension which must include the chosen Relationship Type UID and the chosen Program Indicator UID:

    /api/analytics/enrollments/query/<program-id>
      ?dimension=<relationshiptype-id>.<programindicator-id>

例如，要从“ WHO RMNCH Tracker”程序中检索2019年1月的注册列表，并按“与人相关的疟疾病例”类型的关系显示与该注册相关的疟疾病例数，则可以使用以下查询

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=mxZDvSZYxlw.nFICjJluo74
      &startDate=2019-01-01&endDate=2019-01-31    

API 支持使用与“主”程序（即在`/query/` 之后指定的程序 ID）无关的程序指示符。

## Tracked entity analytics { #webapi_te_analytics } 

The tracked entity (TE) analytics API allows querying *TEs with their enrollments and event data* captured in DHIS2. 
This resource retrieves data from TE, enrollments, events, and data elements across multiple programs, for a given tracked entity type.

### Dimensions and items { #webapi_te_analytics_dimensions } 

Tracked entity instance dimensions include program attributes (TE attributes), data elements, 
organization units, and different kinds of periods. The analytics query will simply return TEs matching a set of criteria.
It does not perform any aggregation.

Table: TE dimensions

| 尺寸                          | Dimension id                                                | 描述 |
|------------------------------------|-------------------------------------------------------------|---|
| Program attributes (TE attributes) | `<attribute id>`                                            | The identifier of the program attribute.
| Data elements in program stages    | `<program id>.<program stage id>[offset].<data element id>` | Data element identifiers must include the program and program stage. ie: `dimension=IpHINAT79UW.ZzYYXq4fJie.GQY2lXrypjO` |
| 句号                            | N.A.                                                        | There's no direct support for `period` dimension. Periods are supported through several different specific parameters. See the *Periods* section below. |
| TEI Organisation units             | `ou`                                                        | Organisation unit identifiers, and also the keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\>. |
| Enrollment Organisation units      | `<program id>.ou`                                           | Organisation unit identifiers, and also the keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\>. |
| Event Organisation units           | `<program id><program stage id>.ou`                         | Organisation unit identifiers, and also the keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\>. |

#### Offset { #offset } 

Dimensions referring to items in repeatable events can include an optional offset.
The offset is used to specify which repetition of the event to use.
The order of the repetitions is based on the occurred date, with the most recent event being the latest repetition.
The offset is an integer value, where 0 refers to the last repetition, -1 to the second last, and so on.
Positive values refer to the first (oldest) repetition, second repetition, and so on.
The offset is enclosed in square brackets [ ].

例：

    IpHINAT79UW.ZzYYXq4fJie.GQY2lXrypjO -- refers to the last repetition
    IpHINAT79UW.ZzYYXq4fJie[-1].GQY2lXrypjO -- refers to the second last repetition
    IpHINAT79UW.ZzYYXq4fJie[2].GQY2lXrypjO -- refers to the second repetition 

### Tracked entity (TE) query analytics { #webapi_te_query_analytics } 

The *analytics/trackedEntities/query* endpoint provides queries for captured TEs, allowing querying and filtering for information related to TEs, along with their respective enrollments and events. It does not perform any aggregation.

    /api/41/analytics/trackedEntities/query

You can specify any number of dimensions and any number of filters in a query. Dimension item identifiers can refer to any of the data elements in program stages, program attributes, tracked entity attributes, fixed and relative periods, and organization units. Dimensions can optionally have a query operator and a filter. TEs queries should be in the format described below.

    /api/41/analytics/trackedEntities/query/<tracked-entity-type-id>?dimension=ou:<ou-id>;<ou-id>&
        dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve TEs of type `Person` from the "Child Program" and "Antenatal care" programs, where the "First name" is "James":

    /api/41/analytics/trackedEntities/query/nEenWmSyUEp?program=IpHINAT79UW,WSGAb5XwJ3Y&dimension=IpHINAT79UW.w75KJ2mc4zz:eq:James

Paging can be applied to the query by specifying the page number and the page size parameters. If the page number is specified but the page size is not, a page size of 50 will be used. If the page size is specified but the page number is not, a page number of 1 will be used. To get the second page of the response with a page size of 10 you can use a query like this:

    /api/41/analytics/trackedEntities/query/nEenWmSyUEp?program=IpHINAT79UW,WSGAb5XwJ3Y&dimension=IpHINAT79UW.w75KJ2mc4zz:eq:James
        &pageSize=10&page=2

#### 筛选 { #filtering } 

Filters can be applied to data elements, tracked entity attributes, and tracked entity identifiers. The filtering is done through a query parameter in the following format:

    ＆dimension = <item-id>：<operator>：<filter-value>

For example, you can filter the "MCH Infant Weight (g)" data element, of the program "Child Program" and program stage "Baby Postnatal" looking for values greater than 2000 and lower than 4000. The filter is defined like this:

    &dimension=IpHINAT79UW.ZzYYXq4fJie.GQY2lXrypjO:GT:2000&dimension=IpHINAT79UW.ZzYYXq4fJie.GQY2lXrypjO:LT:4000

#### Periods  { #periods } 

Unlike enrollment and event query endpoints, the TE endpoint supports multiple ways to specify the period the data belongs to. They are based on different *date* params as shown below:

| Parameter      | 描述                                                                      | 
|----------------|----------------------------------------------------------------------------------|
| eventDate      | TEs will be filtered based on the date the event occurred.                       |
| enrollmentDate | TEs will be filtered based on the date of enrollment.                            |
| scheduledDate  | TEs will be filtered based on the date the event was scheduled.                  |
| incidentDate   | TEs will be filtered based on enrollment's incident date.                        |
| lastUpdated    | TEs will be filtered based on the date the TE/enrollment/event was last updated. |
| created        | TEs will be filtered based on the date the TE/enrollment/event was created.      |

Some periods, mentioned above, can be applied to Tracked Entities, Enrollments, or Events, depending on the way they are expressed.

例子：

* filtering TEs that have been updated during the last year:

`lastUpdated=LAST_YEAR`

* filtering TEs whose latest enrollment in the program "Child Program" has been updated during the last year:

`lastUpdated=IpHINAT79UW.LAST_YEAR`

* filtering TEs whose latest event in the program stage "Baby Postnatal", in the latest enrollment in the program "Child Program" has been updated during the last year:

`lastUpdated=IpHINAT79UW.ZzYYXq4fJie.LAST_YEAR`

* filtering TEs whose latest enrollment in the "Child Program" occurred in the last year:

`enrollmentDate=IpHINAT79UW.LAST_YEAR`

### Request query parameters { #webapi_te_analytics_query_parameters } 

The analytics TE query API supports a range of query parameters.

Table: Query parameters for the TE query endpoint

| 查询参数         | 需要 | 描述                                                                                                                                                                                                                                                                                                                                                               | 选项（默认为默认）                                                                                                                                                                              |
|-------------------------|----------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| trackedEntityType       | 是的      | Tracked entity type identifier.                                                                                                                                                                                                                                                                                                                                           | Any tracked entity type identifier.                                                                                                                                                                  |
| program                 | 不       | Program identifiers.                                                                                                                                                                                                                                                                                                                                                      | Any program identifier. Accepts multiple comma-separated identifiers.                                                                                                                                |
| 维度               | 不       | Dimension identifier including data elements, attributes, program indicators, periods, organization units and organization unit group sets. This parameter can be specified multiple times. Dimension filters can be applied to a dimension in the format <dimension-id\>:<operator\>:<filter-value\>. Filter values can be case-insensitive (depending on the operator). | Operators supported: EQ &#124; IEQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; ILIKE &#124; IN                                                                              |
| filter                  | 不       | Dimension identifier including data elements, attributes, periods, organization units and organization unit group sets. This parameter can be specified multiple times. Dimension filters can be applied to a dimension in the format <dimension-id\>:<operator\>:<filter-value\>. Filter values can be case-insensitive (depending on the operator).                     | Operators supported: EQ &#124; IEQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; ILIKE &#124; IN                                                                              |
| 标头                 | 不       | 作为响应的一部分返回的标头的名称。                                                                                                                                                                                                                                                                                                           | One or more header names (separated by a comma).                                                                                                                                                     |
| relativePeriodDate      | 不       | Overrides the start date, so relative periods will use this date as the starting date.                                                                                                                                                                                                                                                                                    | Example: "2016-01-01"                                                                                                                                                                                |
| ouMode                  | 不       | The mode for the selection of organization units. The default is DESCENDANTS, meaning all subunits in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organization units only.                                                                                                                                     | DESCENDANTS, CHILDREN, SELECTED                                                                                                                                                                      |
| asc                     | 不       | Dimensions to be sorted ascending. Can reference to enrollment date, incident date, org unit name, and code.                                                                                                                                                                                                                                                              | `ouname` &#124; `programstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; `<dimension identifier>`   |
| desc                    | 不       | Dimensions to be sorted descending, can reference to enrollment date, incident date, org unit name and code.                                                                                                                                                                                                                                                              | `ouname` &#124; `programstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; `<dimension identifier>`   |
| page                    | 不       | The page number. The default value is 1.                                                                                                                                                                                                                                                                                                                                  | Numeric positive value.                                                                                                                                                                              |
| pageSize                | 不       | The page size. The default value is 50 (which means 50 items per page).                                                                                                                                                                                                                                                                                                   | Numeric zero or positive value.                                                                                                                                                                      |
| displayProperty         | 不       | Property to display for metadata.                                                                                                                                                                                                                                                                                                                                         | NAME &#124; SHORTNAME                                                                                                                                                                                |
| includeMetadataDetails  | 不       | Include metadata details to raw data response.                                                                                                                                                                                                                                                                                                                            | false &#124; true                                                                                                                                                                                    |
| outputIdScheme          | 不       | Identifier scheme used for metadata items in the query response. It accepts identifiers, codes, or attributes.                                                                                                                                                                                                                                                            | UID &#124; UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\>                                                                                                                                       |
| dataIdScheme            | 不       | Id scheme to be used for data, more specifically data elements and attributes that have an option set or legend set, e.g. return the name of the option instead of the code, or the name of the legend instead of the legend ID, in the data response.                                                                                                                    | NAME &#124; CODE &#124; UID                                                                                                                                                                          |
| programStatus           | 不       | Specify enrollment status of events to include. *DEPRECATED, prefer `enrollmentStatus`*                                                                                                                                                                                                                                                                                   | ACTIVE &#124; COMPLETED &#124; CANCELLED. Can be comma separated (*for query only*).                                                                                                                 |
| enrollmentStatus        | 不       | Specify enrollment status of events to include.                                                                                                                                                                                                                                                                                                                           | ACTIVE &#124; COMPLETED &#124; CANCELLED. Can be comma separated (*for query only*).                                                                                                                 |
| eventStatus             | 不       | Specify the status of events to include.                                                                                                                                                                                                                                                                                                                                  | ACTIVE &#124; COMPLETED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED. Can be comma separated (*for query only*).                                                                                    |
| coordinatesOnly         | 不       | Whether to only return events that have coordinates.                                                                                                                                                                                                                                                                                                                      | false &#124; true                                                                                                                                                                                    |
| geometryOnly            | 不       | Whether to only return events that have geometries.                                                                                                                                                                                                                                                                                                                       | false &#124; true                                                                                                                                                                                    |
| userOrgUnit             | 不       | User organization unit identifier.                                                                                                                                                                                                                                                                                                                                        | Any organization unit identifier.                                                                                                                                                                    | 
| skipMeta                | 不       | Skip metadata in the response.                                                                                                                                                                                                                                                                                                                                            | false &#124; true                                                                                                                                                                                    |
| skipData                | 不       | Skip data in the response.                                                                                                                                                                                                                                                                                                                                                | false &#124; true                                                                                                                                                                                    |
| skipRounding            | 不       | Skip rounding of data values.                                                                                                                                                                                                                                                                                                                                             | false &#124; true                                                                                                                                                                                    |
| skipHeaders             | 不       | Skip headers in the response.                                                                                                                                                                                                                                                                                                                                             | false &#124; true                                                                                                                                                                                    |
| totalPages              | 不       | Include the total number of pages in the response.                                                                                                                                                                                                                                                                                                                        | false &#124; true                                                                                                                                                                                    |
| displayProperty         | 不       | Property to display for metadata.                                                                                                                                                                                                                                                                                                                                         | NAME &#124; SHORTNAME                                                                                                                                                                                |

## Dimensions { #webapi_dimensions }

Five resources allow to easily retrieve data dimensions:

- [Event Query data dimensions](#webapi_event_query_analytics_dimension)`/analytics/events/query/dimensions` 
- [Event Aggregate data dimensions](#webapi_event_aggregate_analytics_dimension) `/analytics/events/aggregate/dimensions`
- [Enrollment Query data dimensions](#webapi_enrollment_query_analytics_dimension) `/analytics/enrollments/query/dimensions`
- [Enrollment Aggregate data dimensions](#webapi_enrollment_aggregate_analytics_dimension) `/analytics/enrollments/aggregate/dimensions`
- [Tracked Entities query data dimensions](#webapi_teis_query_analytics_dimensions)) `/analytics/teis/query/dimensions`

Resources mentioned above share the following request parameter:

| 查询参数 | required                                         | 描述                                                                                       | 选项                                                                                                                                              |
|-----------------|--------------------------------------------------|---------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| filter          | no                                               | Allows field value filtering on the format: <br/> `filter=field:OP:value&filter=field:OP:value&...` | See [dimension filters section].(#webapi_analytics_dimension_filters)                                                                                |
| fields          | no                                               | Allows field filtering                                                  |
| page            | no | Page number                                                                                       | Defaults to 1 (first page)                                                                                                                           |
| pageSize        | no | Page size                                                                                         | Defaults to 50 elements per page                                                                                                                     |
| paging          | no | Disables pagination when `false`                                                                  | `true` or `false`, defaults to `true`                                                                                                                |
| order           | no | Allows sorting on the format: `order=field:direction`                                                                   | Sortable fields: `created` (default), `lastUpdated`, `code`, `uid`, `id`, `name`, `displayName`, `dimensionType`<br/><br/> Direction can be `ASC` (default) or `DESC` |

#### Dimension filters { #webapi_analytics_dimension_filters }

Dimensions endpoints support filtering the output to narrow down the response to desired elements.
Filters are in the format `filter=field:op:value&filter=field:op:value&...&filter=field:op:value`.

Supported `field` values are:

- **id**/**uid** - dimension id
- **code** - dimension code
- **valueType** - dimension value type
- **name** - the name of the dimension
- **dimensionType** - the type of the dimension 
    - `DATA_ELEMENT`
    - `PROGRAM_INDICATOR`
    - `PROGRAM_ATTRIBUTE`
    - `CATEGORY`
    - `CATEGORY_OPTION_GROUP_SET`
- **displayName** - displayName of the dimension
- **displayShortName** - displayShortName of the dimension

Supported `op`values are:

- `startsWith` - field starts with
- `!startsWith` - field does not start with
- `endsWith` - field ends with
- `!endsWith` - field does not end with- 
- `eq` - equals
- `ieq` - equals ignoring case
- `ne` - not equals
- `like` - contains
- `!like` - does not contain
- `ilike` - contains ignoring case
- `!ilike` - does not contain ignoring case

### Event analytics dimensions { #event-analytics-dimensions } 
#### Event query analytics dimensions { #webapi_event_query_analytics_dimension }

The `/analytics/events/query/dimensions?programId={programId}&programStageId={programStageId}` resource accepts:

- a tracker `program`
- a tracker `programStage`
- both `program` and `programStage`

There are constraints on the combination of program and programStage:

- If only `program` is specified, the resource returns data dimensions for each program stage in the provided program
- If only `programStage` is specified, the resource returns data dimensions for the provided `programStage`
- If both `program` and `programStage` are specified, the resource returns data dimensions for the provided `programStage` if it belongs to the provided `program`. Returns an error otherwise.

the returned data dimensions are:

- **Program indicators** associated with the program (derived from programStageId)
- **Data elements** of *supported types* in the program stage
- **Tracked entity attributes** of *supported types* associated with the program (derived from programStageId)
- **Categories** in category combo associated with the program (derived from programStageId)
- **Category option group sets** of type `ATTRIBUTE`

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

#### Event aggregate dimensions { #webapi_event_aggregate_analytics_dimension }

The `/analytics/events/aggregate/dimensions?programStageId=...` resource accepts a mandatory `programStageId` parameter and returns the following data dimensions:

- **Data elements** of *supported types* in the program stage
- **Tracked entity attributes** of *supported types* associated with the program (derived from programStageId)
- **Categories** in category combo associated with the program (derived from programStageId)
- **Category option group sets** of type `ATTRIBUTE` associated with program (derived from programStageId)

Data elements and tracked entity attributes are considered *supported types* if their value type is one of the following:

- `NUMBER`
- `UNIT_INTERVAL`
- `PERCENTAGE`
- `INTEGER`
- `INTEGER_POSITIVE`
- `INTEGER_NEGATIVE`
- `INTEGER_ZERO_OR_POSITIVE`
- `BOOLEAN`
- `TRUE_ONLY`

### Enrollment analytics dimensions { #enrollment-analytics-dimensions } 

#### Enrollment query analytics dimensions { #webapi_enrollment_query_analytics_dimension }

The `/analytics/enrollments/query/dimensions?programId=...` resource accepts a mandatory id of a tracker program and returns the following data dimensions:

- **Program indicators** connected to the program
- **Data elements** of *supported types* in the program, with program stage for each data element
- **Tracked entity attributes** of *supported types* associated with the program that are not confidential

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

#### Enrollment aggregate dimensions { #webapi_enrollment_aggregate_analytics_dimension }

The `/analytics/enrollments/aggregate/dimensions?programId=...` resource accepts a mandatory id of a tracker program, referring to a program with registration, and returns the following data dimensions:

- **Data elements** of *supported types* in the program, with program stage for each data element
- **Tracked entity attributes** of *supported types* associated with the program that are not confidential

Data elements and tracked entity attributes are considered *supported types* if their value type is one of the following:

- `NUMBER`
- `UNIT_INTERVAL`
- `PERCENTAGE`
- `INTEGER`
- `INTEGER_POSITIVE`
- `INTEGER_NEGATIVE`
- `INTEGER_ZERO_OR_POSITIVE`
- `BOOLEAN`
- `TRUE_ONLY`

### Tracked Entities analytics dimensions { #tracked-entities-analytics-dimensions } 

#### Tracked Entities query analytics dimensions { #webapi_teis_query_analytics_dimensions }

The `/analytics/teis/query/dimensions?trackedEntityType=TET` resource accepts a mandatory id of a tracked entity type `TET` and returns the following data dimensions:

for each program `P` associated with a tracked entity instance of type `TET`:
- **Program indicators** associated to `P`
- **Data elements** of *supported types* in `P`, with program stage for each data element
- **Tracked entity attributes** of *supported types* associated with the program that are not confidential
- **Program attributes** of `P`

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

### Sample request and response { #sample-request-and-response } 

    GET /api/analytics/teis/query/dimensions?programStageId=A03MvHHogjR&order=code&filter=name:ilike:weight

```json
{
   "page":1,
   "total":5,
   "pageSize":50,
   "dimensions":[
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-08-06T22:49:20.128",
         "lastUpdated":"2015-08-06T22:51:19.787",
         "name":"Measles + Yellow fever doses low infant weight",
         "displayName":"Measles + Yellow fever doses low infant weight",
         "id":"tt54DiKuQ9c",
         "uid":"tt54DiKuQ9c",
         "displayShortName":"Measles + Yellow fever doses low infant weight"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2017-01-20T10:32:26.388",
         "lastUpdated":"2017-01-20T10:32:26.388",
         "name":"Weight gain(in g) between birth and last postnatal",
         "displayName":"Weight gain(in g) between birth and last postnatal",
         "id":"qhTkqwAJLMv",
         "uid":"qhTkqwAJLMv",
         "displayShortName":"Weight gain(g)"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-09-14T20:25:55.543",
         "lastUpdated":"2018-08-28T12:22:47.857",
         "name":"Average weight (g)",
         "displayName":"Average weight (g)",
         "id":"GxdhnY5wmHq",
         "uid":"GxdhnY5wmHq",
         "displayShortName":"Average weight (g)"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-08-06T22:35:40.391",
         "lastUpdated":"2015-08-06T22:35:40.391",
         "name":"BCG doses low birth weight",
         "displayName":"BCG doses low birth weight",
         "id":"hCYU0G5Ti2T",
         "uid":"hCYU0G5Ti2T",
         "displayShortName":"BCG doses low birth weight"
      },
      {
         "valueType":"NUMBER",
         "dimensionType":"DATA_ELEMENT",
         "created":"2012-09-20T17:37:45.474",
         "lastUpdated":"2014-11-11T21:56:05.418",
         "name":"MCH Weight (g)",
         "displayName":"MCH Weight (g)",
         "id":"A03MvHHogjR.UXz7xuGCEhU",
         "uid":"UXz7xuGCEhU",
         "code":"DE_2005736",
         "displayShortName":"Weight (g)"
      }
   ]
}
```

## 组织单位分析 { #webapi_org_unit_analytics } 

组织单位分析API提供有关按组织单位组集分类的组织单位的统计信息，即组织单位组集中每个组织单位组的组织单位计数。

    GET /api/orgUnitAnalytics?ou=<org-unit-id>&ougs=<org-unit-group-set-id>

该API需要至少一个组织单位和至少一个组织单位组集。可以提供多个组织单位和组集，以分号分隔。

### 请求查询参数 { #request-query-parameters } 

组织单位分析资源使您可以指定一系列查询参数：



Table: Org unit analytics query parameters

| Property | 描述 | 需要 |
|---|---|---|
| 欧 | Org unit identifiers, potentially separated by a semicolon. | 是的 |
| ougs | Org unit group set identifiers, potentially separated by a semicolon. | 是的 |
| 列 | Org unit group set identifiers, potentially separated by a semicolon. Defines which group sets are rendered as columns in a table layout. | 不 |

响应将包含用于父组织单位的列，用于请求的每个组织单位组集部分的列以及用于计数的列。统计信息包括组织单位的数量，该组织单位是请求中指定的组织单位的子层次结构的一部分。该响应包含一个元数据部分，该元数据部分指定由其标识符引用的响应的每个组织单位和组织单位组部分的名称。

默认响应使用单个 `count` 列进行标准化。通过使用 `columns` 查询参数指定至少一个组织单位组集，可以在表格布局中呈现响应。

### 回应格式 { #response-formats } 

组织单位分析端点支持以下表示格式：

- json（应用程序/ json）
- csv（应用程序/ csv）
- xls（application / vnd.ms-excel）
- pdf（应用程序/ pdf）

### 例子 { #examples } 

要获取组织单位和组织单位组集的组织单位分析，请执行以下操作：

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw&ougs=J5jldMd8OHv

要获取两个组织单位和两个组织单位组集合的组织单位分析数据：

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw;PMa2VCrupOd&ougs=J5jldMd8OHv;Bpx0589u8y0

要以表格模式获取组织单位分析数据，并将一组设置为列：

    GET / api / orgUnitAnalytics？ou = fdc6uOvgoji; jUb8gELQApl; lc3eMKXaEfw; PMa2VCrupOd
      ＆ougs = J5jldMd8OHv＆列= J5jldMd8OHv

### 约束与验证 { #constraints-and-validation } 

下表描述了专门针对组织单位分析API的可能的验证错误。为汇总分析API指定的某些错误也相关。

| 错误代码 | 信息 |
| ---------- | ------- |
| E7300      | 必须至少指定一个组织单位 |
| E7301      | 必须至少指定一个组织单位组集 |

## 数据集报告 { #webapi_data_set_report } 

可以使用 web api 生成数据集报告
`/dataSetReport` 资源。此资源生成有关数据集的报告
并以 HTML 表格的形式返回结果。

    /api/dataSetReport

### 请求查询参数 { #request-query-parameters } 

该请求支持以下参数：



Table: Data set report query parameters

| Parameter | 描述 | 类型 | 需要 |
|---|---|---|---|
| ds | Data set to create the report from. | Data set UID | 是的 |
| 聚乙烯 | Period(s) to create the report from. May be a comma-separated list. | ISO String | 是的 |
| 欧 | Organisation unit to create the report from. | Organisation unit UID | 是的 |
| filter | Filters to be used as filters for the report. Can be repeated any number of times. Follows the analytics API syntax. | One or more UIDs | 不 |
| selectedUnitOnly | Whether to use captured data only or aggregated data. | Boolean | 不 |

The data set report resource accepts `GET` requests only. The response content type is `application/json` and returns data in a grid. This endpoint works for all types of data sets, including default, section and custom forms.

An example request to retrieve a report for a monthly data set and org unit for October 2018 looks like this:

    GET /api/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd&selectedUnitOnly=false

An example request to retrieve a report for a monthly data set and org unit for October, November, and December 2018 looks like this:

    GET /api/dataSetReport?ds=BfMAe6Itzgt&pe=201810,201811,201812&ou=ImspTQPwCqd&selectedUnitOnly=false

要获得带有过滤器的数据集报告，可以使用`filter`参数。在这种情况下，过滤器基于一个组织单位组集和两个组织单位组：

    GET /api/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd
      &filter=J5jldMd8OHv:RXL3lPSK8oG;tDZVQ1WtwpA

### 回应格式 { #response-formats } 

数据集报告端点支持以下格式的输出。您可以使用文件扩展名或 `Accept` HTTP 标头检索特定端点。

- json（应用程序/ json）
- pdf（应用程序/ pdf）
- xls（application / vnd.ms-excel）

### 自订表格 { #custom-forms } 

A dedicated endpoint is available for data sets with custom HTML forms. This endpoint returns the HTML form content with content type `text/html` with data inserted into it. Note that you can use the general data set report endpoint also for data sets with custom forms; however, that will return the report in JSON format as a grid. This endpoint only works for data sets with custom HTML forms.

    GET /api/dataSetReport/custom

否则，此端点的语法等于常规数据集报告端点。要检索自定义HTML数据集报告，您可以发出如下请求：

    GET /api/dataSetReport/custom?ds=lyLU2wR22tC&pe=201810&ou=ImspTQPwCqd


## 推送分析 { #webapi_push_analysis } 

推送分析 API 包括用于预览推送分析的端点
报告登录用户并手动触发系统
生成和发送推送分析报告，除了正常的 CRUD
操作。使用创建和更新端点进行推送时
分析，推送分析将根据
推分析的性质。删除或更新一个
禁用推送分析，作业也将停止运行
将来。

要获得现有推送分析的 HTML 预览，您可以执行 GET
请求到以下端点：

    /api/pushAnalysis/<id>/render

要手动触发推送分析作业，您可以执行 POST 请求以
这个端点：

    /api/pushAnalysis/<id>/run

推送分析包含以下属性，其中一些是
自动运行推送分析作业所需：



Table: Push analysis properties

| Property | 描述 | 类型 | 需要 |
|---|---|---|---|
| dashboard | Dashboard on which reports are based | Dashboard UID | 是的 |
| message | Appears after title in reports | 串 | 不 |
| recipientUserGroups | A set of user groups who should receive the reports | One or more user Group UID | No. Scheduled jobs without any recipient will be skipped. |
| enabled | Indicated whether this push analysis should be scheduled or not. False by default. | Boolean | Yes. Must be true to be scheduled. |
| schedulingFrequency | The frequency of which reports should be scheduled. | "DAILY", "WEEKLY", "MONTHLY" | No. Push analysis without a frequency will not be scheduled |
| schedulingDayOfFrequency | The day in the frequency the job should be scheduled. | Integer. Any value when frequency is "DAILY". 0-7 when frequency is "WEEKLY". 1-31 when frequency is "MONTHLY" | No. Push analysis without a valid day of frequency for the frequency set will not be scheduled. |

## 数据使用情况分析 { #webapi_usage_analytics } 

使用情况分析 API 可让您访问有关人们使用情况的信息
使用基于数据分析的 DHIS2。当用户访问收藏夹时，
事件被记录。事件由用户名、UID 组成
最喜欢的、事件发生的时间以及事件的类型。这
表中列出了不同类型的事件。

    /api/dataStatistics

使用情况分析 API 可让您检索使用情况的汇总快照
基于时间间隔的分析。 API 捕获用户视图（对于
例如，图表或数据透视表被用户查看的次数
用户）和保存的分析收藏夹（例如收藏夹图表和
数据透视表）。 DHIS2 将捕获夜间快照，然后
应要求汇总。

### 请求查询参数 { #webapi_usage_analytics_request_query_parameters } 

使用情况分析（数据统计）API支持两种操作：

  - *POST:* 创建一个视图事件

  - *GET:* 检索汇总统计信息

### 创建视图事件（POST） { #webapi_usage_analytics_create_view_events } 

使用情况分析 API 可让您创建事件视图。这
dataStatisticsEventType 参数描述了项目的类型
看过。最喜欢的参数表示相关的标识符
最喜欢的。

创建新事件视图的 URL
    图表：

    POST /api/dataStatistics?eventType=CHART_VIEW&favorite=LW0O27b7TdD

成功的保存操作会返回 HTTP 状态代码 201。表
下面显示了支持的事件类型。


Table: Supported event types

| 键 | 描述 |
|---|---|
| VISUALIZATION_VIEW | Visualization view |
| MAP_VIEW | Map view (GIS) |
| EVENT_REPORT_VIEW | Event report view |
| EVENT_CHART_VIEW | Event chart view |
| EVENT_VISUALIZATION_VIEW | Event visualization view |
| DASHBOARD_VIEW | Dashboard view |
| PASSIVE_DASHBOARD_VIEW | Dashboard view (when not explicitly selecting the dashboard) |
| DATA_SET_REPORT_VIEW | Data set report view |

### 检索汇总的使用情况分析报告（GET） { #webapi_aggregated_usage_analytics } 

使用情况分析（数据统计）API 允许您指定特定查询
请求汇总报告时的参数。



Table: Query parameters for aggregated usage analytics (data statistics)

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 开始日期 | 是的 | Start date for period | Date in yyyy-MM-dd format |
| 结束日期 | 是的 | End date for period | Date in yyyy-MM-dd format |
| interval | 是的 | Type of interval to be aggregated | DAY, WEEK, MONTH, YEAR |

startDate 和 endDate 参数指定期间
将在聚合中使用快照。您必须格式化日期
如上图所示。如果在指定时间段内没有保存快照，则
空列表被送回。称为间隔的参数指定了什么
将进行聚合类型。

用于创建每月查询的 API 查询
    聚合：

    GET /api/dataStatistics?startDate=2014-01-02&endDate=2016-01-01&interval=MONTH

### 检索热门收藏夹 { #webapi_usage_analytics_top_favorites } 

使用情况分析 API 可让您检索最常用的
DHIS2，并由用户。


Table: Query parameters for top favorites

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| eventType | 是的 | The data statistics event type | See above table |
| pageSize | 不 | Size of the list returned | For example 5, 10, 25. Default is 25 |
| sortOrder | 不 | Descending or ascending | ASC or DESC. Default is DESC. |
| 用户名 | 不 | If specified, the response will only contain favorites by this user. | For example 'admin' |

API 查询可以不用用户名，然后会找到顶部
系统的最爱。

    /api/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25&sortOrder=ASC

如果指定了用户名，则响应将仅包含该用户的最爱。

    /api/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25
      &sortOrder=ASC&username=admin

### 回应格式 { #webapi_usage_analytics_response_format } 

您可以在使用情况分析响应中返回聚合数据
几种表示格式。默认格式为 JSON。这
可用的格式和内容类型有：

  - json（应用程序/ json）

  - xml（应用程序/ xml）

  - html（text / html）

请求 XML 格式的使用情况分析响应的 API 查询
    格式：

    /api/dataStatistics.xml?startDate=2014-01-01&endDate=2016-01-01&interval=WEEK

要以 JSON 格式获取使用情况分析响应：

    /api/dataStatistics?startDate=2016-02-01&endDate=2016-02-14&interval=WEEK

JSON响应如下所示：

```json
[
  {
    "year": 2016,
    "week": 5,
    "mapViews": 2181,
    "chartViews": 2227,
    "reportTableViews": 5633,
    "eventReportViews": 6757,
    "eventChartViews": 9860,
    "eventVisualizationViews": 2387,
    "dashboardViews": 10082,
    "passiveDashboardViews": 0,
    "totalViews": 46346,
    "averageViews": 468,
    "averageMapViews": 22,
    "averageChartViews": 22,
    "averageReportTableViews": 56,
    "averageEventReportViews": 68,
    "averageEventChartViews": 99,
    "averageEventVisualizationViews": 10,
    "averageDashboardViews": 101,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1805,
    "savedCharts": 2205,
    "savedReportTables": 1995,
    "savedEventReports": 1679,
    "savedEventCharts": 1613,
    "savedEventVisualizations": 1231,
    "savedDashboards": 0,
    "savedIndicators": 1831,
    "activeUsers": 99,
    "users": 969
  },
  {
    "year": 2016,
    "week": 6,
    "mapViews": 2018,
    "chartViews": 2267,
    "reportTableViews": 4714,
    "eventReportViews": 6697,
    "eventChartViews": 9511,
    "dashboardViews": 12181,
    "passiveDashboardViews": 0,
    "totalViews": 47746,
    "averageViews": 497,
    "averageMapViews": 21,
    "averageChartViews": 23,
    "averageReportTableViews": 49,
    "averageEventReportViews": 69,
    "averageEventChartViews": 99,
    "averageDashboardViews": 126,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1643,
    "savedCharts": 1935,
    "savedReportTables": 1867,
    "savedEventReports": 1977,
    "savedEventCharts": 1714,
    "savedDashboards": 0,
    "savedIndicators": 1646,
    "activeUsers": 96,
    "users": 953
  }
]
```

Note that the number of `activeUsers` indicates the number of distinct users who had any events during the requested time period. The number of `users` represents the total number of users in the system (both enabled and disabled).

### 检索收藏的统计信息 { #webapi_usage_analytics_retrieve_favorite_statistics }

您可以使用
*收藏夹* 资源，其中 *{favorite-id}* 应替换为
感兴趣的收藏夹的标识符：

    /api/dataStatistics/favorites/{favorite-id}.json

响应将包含给定收藏的观看次数和
看起来像这样：

```json
{
  "views": 3
}
```

## 地理空间特征 { #webapi_geospatial_features } 

*geoFeatures* 资源可让您从中检索地理空间信息
DHIS2。地理空间特征与组织单位一起存储。
检索特征的语法与用于检索特征的语法相同
分析资源的组织单位维度。这是
建议在继续之前阅读分析 api 资源
阅读本节。您必须使用 GET 请求类型，并且只能使用 JSON
支持响应格式。

例如，在以下位置检索所有组织单位的地理特征
组织单位层次结构中的第 3 级，您可以使用 GET 请求
使用以下网址：

    /api/geoFeatures.json?ou=ou:LEVEL-3

检索组织单位内某个级别的地理特征
组织单位的边界（例如在第 2 级），您可以使用以下 URL：

    /api/geoFeatures.json?ou=ou:LEVEL-4;O6uvpzGd5pu

The response coordinates value can be read from two properties which is decided by the parameter `coordinateField`.
  - The `geometry` property of the OrganisationUnit: this is the default behaviour which is applied when parameter `coordinateField` is not provided.
  - The OrgansationUnit attribute of value type GeoJSON: the api will use the provided `coordinateField={attributeId}` to get the GeoJSON coordinates from this attribute value.

For example, to retrieve geo features for all organisation units at level 3 as above but get the coordinates from OrganisationUnit attribute `tJqtSV4quLb`

    /api/geoFeatures.json?ou=ou:LEVEL-3&coordinateField=tJqtSV4quLb

响应属性的语义描述如下
桌子。

Table: Geo features response

| Property | 描述 |
|---|---|
| id | Organisation unit / geo feature identifier |
| na | Organisation unit / geo feature name |
| hcd | Has coordinates down, indicating whether one or more children organisation units exist with coordinates (below in the hierarchy) |
| hcu | Has coordinates up, indicating whether the parent organisation unit has coordinates (above in the hierarchy) |
| le | Level of this organisation unit / geo feature. |
| pg | Parent graph, the graph of parent organisation unit identifiers up to the root in the hierarchy |
| pi | Parent identifier, the identifier of the parent of this organisation unit |
| pn | Parent name, the name of the parent of this organisation unit |
| ty | Geo feature type, 1 = point and 2 = polygon or multi-polygon |
| co | Coordinates of this geo feature |


### GeoJSON { #geojson } 

要导出 GeoJSON，您只需添加 *.geosjon* 作为扩展名
端点 */api/organisationUnits*，或者您可以使用 *Accept* 标头
*应用程序/json+geojson*。

支持两个参数：`level`（默认为 1）和 `parent`（默认为根组织单位）。两者都可以多次包含。一些例子：

获得第2级和第4级的所有功能：

    /api/organisationUnits.geojson?level=2&level=4

使用边界组织单位获取级别3的所有功能：

    /api/organisationUnits.geojson?parent=fdc6uOvgoji&level=3

## 分析表挂钩 { #webapi_analytics_table_hooks } 

Analytics 表挂钩提供了一种调用 SQL 脚本的机制
在分析表生成过程的不同阶段。这
对于自定义资源和分析表中的数据很有用，例如在
以实现计算和聚合的特定逻辑。
可以在以下 API 端点操作分析表挂钩：

    / api / analyticsTableHooks

分析表钩子 API 支持标准的 HTTP CRUD 操作
用于创建（POST）、更新（PUT）、检索（GET）和删除
（删除）实体。

### 钩场 { #webapi_analytics_table_hook_fields } 

Analytics表挂钩具有以下字段：



Table: Analytics table hook fields

| 领域 | 选项 | 描述 |
|---|---|---|
| 名称 | 文本 | Name of the hook. |
| phase | RESOURCE_TABLE_POPULATED, ANALYTICS_TABLE_POPULATED | The phase for when the SQL script should be invoked. |
| resourceTableType | See column "Table type" in table "Phases, table types and temporary tables" below | The type of resource table for which to invoke the SQL script. Applies only for hooks defined with the RESOURCE_TABLE_POPULATED phase. |
| analyticsTableType | See column "Table type" in table "Phases, table types and temporary tables" below | The type of analytics table for which to invoke the SQL script. Applies only for hooks defined with the ANALYTICS_TABLE_POPULATED phase. |
| sql | 文本 | The SQL script to invoke. |

The *ANALYTICS_TABLE_POPULATED* phase takes place after the analytics
table has been populated, but before indexes have been created and the
temp table has been swapped with the main table. As a result, the SQL
script should refer to the analytics temp table, e.g. *analytics_temp*,
*analytics_completeness_temp*, *analytics_event_temp_ebayegv0exc*.

这也适用于 *RESOURCE_TABLE_POPULATED* 阶段，它需要
放置在资源表被填充之后，索引之前
已创建并且临时表已与主表交换
桌子。因此，SQL 脚本应参考资源临时
表，例如*_orgunitstructure_temp*，*_categorystructure_temp*。

您应该只定义 *resourceTableType* 和
*analyticsTableType* 字段，取决于定义的 *phase*。

可以参考匹配的临时数据库表
仅指定挂钩表类型（其他临时表不会
可用的）。例如，如果您指定 *ORG_UNIT_STRUCTURE* 作为
资源表类型，可以参考*_orgunitstructure_temp*
仅临时数据库表。

下表显示了阶段、表格类型的有效组合
和临时表。



Table: Phases, table types and temporary tables

| 相 | Table type | Temporary table |
|---|---|---|
| RESOURCE_TABLE_POPULATED | ORG_UNIT_STRUCTURE | \_orgunitstructure\_temp |
|| DATA_SET_ORG_UNIT_CATEGORY |\_datasetorgunitcategory\_temp |
|| CATEGORY_OPTION_COMBO_NAME | \_categoryoptioncomboname\_temp |
|| DATA_ELEMENT_GROUP_SET_STRUCTURE | \_dataelementgroupsetstructure\_temp |
|| INDICATOR_GROUP_SET_STRUCTURE |\_indicatorgroupsetstructure\_temp |
|| ORG_UNIT_GROUP_SET_STRUCTURE | \_organisationunitgroupsetstructure\_temp |
|| CATEGORY_STRUCTURE | \_categorystructure\_temp |
|| DATA_ELEMENT_STRUCTURE | \_dataelementstructure\_temp |
|| PERIOD_STRUCTURE | \_periodstructure\_temp |
|| DATE_PERIOD_STRUCTURE | \_dateperiodstructure\_temp |
|| DATA_ELEMENT_CATEGORY_OPTION_COMBO | \_dataelementcategoryoptioncombo\_temp |
|| DATA_APPROVAL_MIN_LEVEL | \_dataapprovalminlevel\_temp |
| ANALYTICS_TABLE_POPULATED | DATA_VALUE | analytics\_temp |
|| COMPLETENESS | analytics\_completeness\_temp |
|| COMPLETENESS_TARGET | analytics\_completenesstarget\_temp |
|| ORG_UNIT_TARGET | analytics\_orgunittarget\_temp |
|| EVENT | analytics\_event\_temp\_{program-uid} |
|| 注册 | analytics\_enrollment\_temp\_{program-uid} |
|| VALIDATION_RESULT | analytics\_validationresult\_temp |

### 创建钩子 { #webapi_create_analytics_table_hook } 

To create a hook which should run after the resource tables have been populated you can do a *POST* request like this using *JSON* as content type:

```
POST /api/analyticsTableHooks
```

```json
{
  "name": "Update 'Area' in org unit group set resource table",
  "phase": "RESOURCE_TABLE_POPULATED",
  "resourceTableType": "ORG_UNIT_GROUP_SET_STRUCTURE",
  "sql": "update _organisationunitgroupsetstructure_temp set \"uIuxlbV1vRT\" = 'b0EsAxm8Nge'"
}
```

To create a hook which should run after the data value analytics table has been populated you can do a *POST* request like this using *JSON* format:

```json
{
  "name": "Update 'Currently on treatment' data in analytics table",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "DATA_VALUE",
  "sql": "update analytics_temp set monthly = '200212' where monthly in ('200210', '200211')"
}
```

To create a hook which should run after the event analytics tables are populated you can do a *POST* request like this using *JSON* format:

```json
{
  "name": "Delete data for a data element",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "EVENT",
  "sql": "delete from analytics_event_temp_lxaq7zs9vyr where dx = 'uDX9LKGRwaH'"
}
```



## SVG转换 { #webapi_svg_conversion } 

Web API 提供了可用于转换 SVG 内容的资源
转换为更广泛使用的格式，例如 PNG 和 PDF。理想情况下这个
转换应该发生在客户端，但不是所有的客户端
技术能够完成这项任务。目前为 PNG 和 PDF
支持输出格式。 SVG 内容本身应该通过
一个 *svg* 查询参数和一个可选的查询参数 *filename* 可以
用于指定响应附件文件的文件名。笔记
应该省略文件扩展名。对于 PNG，您可以发送 *POST*
使用 Content-type 请求以下 URL
`application/x-www-form-urlencoded`，与常规 HTML 表单相同
提交。

    api / svg.png

对于 PDF，您可以将 *POST* 请求发送到以下 URL
内容类型`application/x-www-form-urlencoded`。

    api / svg.pdf

Table: Query parameters

| 查询参数 | 需要 | 描述 |
|---|---|---|
| svg | 是的 | The SVG content |
| filename | 不 | The file name for the returned attachment without file extension |

## Analytics outlier detection { #webapi_analytics_outlier_detection } 

The analytics outliert API provides endpoints for investigation of the data quality based on Z Score and Modified Z Score. Both scores are statistical measures that help analyze and interpret data in the context of deviations from the middle value. They are particularly useful in identifying outliers or extreme values in a dataset. The API is implemented as a single analytics endpoint:

- /api/analytics/outlierDetection

### Request  { #webapi_analytics_outlier_detection_request } 

**Query parameters**

| 查询参数    | 描述                                                                                                 | 需要                                            | 选项（默认为默认）                                                                          |                                                                          
|--------------------|-------------------------------------------------------------------------------------------------------------|-----------------------------------------------------|--------------------------------------------------------------------------------------------------|
| ds                 | 资料集                                                                                                    | 是的                                                 | Data set identifier                                                                              |
| 开始日期          | Start date for interval tocheck for outliers                                                                | No (relative date period is mandatory in this case) | Date (yyyy-MM-dd)                                                                                |
| 结束日期            | End date for interval to check for outliers                                                                 | No (relative date period is mandatory in this case) | Date (yyyy-MM-dd)                                                                                |
| 聚乙烯                 | ISO periods and relative periods                                                                            | No (start and end date is mandatory in this case)   | see "date and period format"                                                                     |
| relativePeriodDate | Date used as basis for relative periods.                                                                    | 不                                                  | Date (yyyy-MM-dd)                                                                                |
| 欧                 | Organisation unit, organisation unit level or groups (can be combined)                                      | 不                                                  | Organisation unit (level, group) identifier                                                      |
| 标头            | The name of the headers to be returned as part of the response. One or more headers name separated by comma | 不                                                  | (NULL), dx, dxname, pename, pe ...                                                               |
| 订购            | Sort the records on the value column                                                                        | 不                                                  | absdev, zscore, modifiedzscore, median, mean, stddev, medianabsdeviation, lowerbound, upperbound |
| sortOrder          | Sort the records on the value column in ascending or descending order                                       | 不                                                  | ASC, DESC                                                                                        |
| 算法          | Algorithm to use for outlier detection                                                                      | 不                                                  | Z_SCORE, MODIFIED_Z_SCORE                                                                        |
| 临界点          | Threshold for outlier values Z_SCORE or MODIFIED_Z_SCORE                                                    | 不                                                  | Numeric, greater than zero. Default: 3.0                                                         |
| inputIdScheme      | Identifier scheme to use for metadata items in the query request, can be an identifier, code or attributes. | 不                                                  | UID, ID, CODE, NAME                                                                              |
| maxResults         | Maximum rows (responses)                                                                                    | 不                                                  | 500                                                                                              |
| skipRounding       | Skip rounding of data values, i.e. provide fine precision (scale 10).                                       | 不                                                  | false, true                                                                                      |

**Request example**

    GET api/analytics/outlierDetection?ds=BfMAe6Itzgt&ou=ImspTQPwCqd&startDate=2022-07-26&endDate=2022-10-26&algorithm=Z_SCORE&maxResults=30&orderBy=value&threshold=3.0&sortOrder=asc&outputIdScheme=code


### Response { #webapi_analytics_outlier_detection_response } 

Response is delivered in several representation formats. The default format is JSON. The
available formats and content types are:

  - json（应用程序/ json）
  - xml（应用程序/ xml）
  - xsl (application/vnd.ms-excel)
  - csv（应用程序/ csv）
  - html（text / html）
  - html + css（text / html）

**Response example**

```json
{
    "headers": [
        {
            "name": "dx",
            "column": "Data",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "dxname",
            "column": "Data name",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "pe",
            "column": "Period",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "pename",
            "column": "Period name",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "ou",
            "column": "Organisation unit",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "ouname",
            "column": "Organisation unit name",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "ounamehierarchy",
            "column": "Organisation unit name hierarchy",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "coc",
            "column": "Category option combo",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "cocname",
            "column": "Category option combo name",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "aoc",
            "column": "Attribute option combo",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "aocname",
            "column": "Attribute option combo name",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": false
        },
        {
            "name": "value",
            "column": "Value",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        },
        {
            "name": "mean",
            "column": "Mean",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        },
        {
            "name": "stddev",
            "column": "Standard deviation",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        },
        {
            "name": "absdev",
            "column": "Absolute deviation",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        },
        {
            "name": "zscore",
            "column": "zScore",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        },
        {
            "name": "lowerbound",
            "column": "Lower boundary",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        },
        {
            "name": "upperbound",
            "column": "Upper boundary",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        }
    ],
    "metaData": {
        "maxResults": 30,
        "count": 3,
        "orderBy": "VALUE",
        "threshold": 3.0,
        "algorithm": "Z_SCORE"
    },
    "rowContext": {},
    "width": 18,
    "rows": [
        [
            "DE_22",
            "Q_Early breastfeeding (within 1 hr after delivery) at BCG",
            "202209",
            "September 2022",
            "OU_204860",
            "Sandaru CHC",
            "/Sierra Leone/Kailahun/Penguia/Sandaru CHC",
            "COC_292",
            "Fixed, <1y",
            "default",
            "default",
            "105.0",
            "18.3",
            "28.7",
            "86.7",
            "3.0",
            "-67.9",
            "104.4"
        ],
        [
            "DE_359706",
            "BCG doses given",
            "202208",
            "August 2022",
            "OU_595",
            "Ngalu CHC",
            "/Sierra Leone/Bo/Bargbe/Ngalu CHC",
            "COC_292",
            "Fixed, <1y",
            "default",
            "default",
            "220.0",
            "41.6",
            "57.4",
            "178.3",
            "3.1",
            "-130.7",
            "213.9"
        ],
        [
            "DE_35",
            "Yellow Fever doses given",
            "202209",
            "September 2022",
            "OU_1027",
            "Yemoh Town CHC",
            "/Sierra Leone/Bo/Kakua/Yemoh Town CHC",
            "COC_292",
            "Fixed, <1y",
            "default",
            "default",
            "466.0",
            "48.1",
            "114.2",
            "417.8",
            "3.6",
            "-294.6",
            "391.0"
        ]
    ],
    "headerWidth": 18,
    "height": 3
}
```
### Statistics in response { #webapi_analytics_outlier_detection_stats_in_response }

| Statistical Measure | Header name | 描述 | 链接 |
|---|---|---|---|
| 值 | 价值 | The data set/ data element numeric value (Penta1 doses given, Measles doses given, etc.) | |
| Mean | 意思是 |The average value of a set of numbers. Calculated by summing all values and dividing by the count.| https://www.khanacademy.org/math/statistics-probability/summarizing-quantitative-data |
| Standard Deviation | stddev | A measure of the amount of variation or dispersion in a set of values. | https://www.statisticshowto.com/probability-and-statistics/standard-deviation/ |
| Absolute Deviation | absdev | The absolute difference between each data value and the middle value. | https://www.mathsisfun.com/data/mean-absolute-deviation.html |
| Z Score | zscore | A standardized score that represents how many standard deviations a data value is from the mean. | https://www.statisticshowto.com/probability-and-statistics/z-score/ |
| Modified Z Score | modifiedzscore | Similar to the Z score but robust to outliers. It uses the median and median absolute deviation. | https://www.statisticshowto.com/modified-z-scores/ |
| Median Absolute Deviation | medianabsdeviation | A robust measure of the spread of data values, calculated as the median of the absolute deviations from the median. | https://math.stackexchange.com/questions/2232309/median-absolute-deviation-mad-formula |
| Minimum | lowerbound | The minimum is the smallest value in a dataset. It represents the lowest observed value among all the data values. | |
| Maximum| upperbound | The maximum is the largest value in a dataset. It represents the highest observed value among all the data values. | |


### Error messages { #webapi_analytics_outlier_detection_error_messages } 

**_NOTE:_** *All messages are delivered with http status code 409.*

| 码 | 信息 |
|---|---|
| E2200 | At least one data element must be specified. |
| E2201 | Start date and end date or relative period must be specified. |
| E2202 | Start date must be before end date. |
| E2203 | 必须至少指定一个组织单位。 | 
| E2204 | Threshold must be a positive number. |
| E2205 | Max results must be a positive number. |
| E2206 | Max results exceeds the allowed max limit: *500*. |
| E2207 | Data start date must be before data end date. |
| E2208 | Non-numeric data values encountered during outlier value detection. |
| E2209 | Data start date not allowed. |
| E2210 | Data end date not allowed. |
| E2211 | Algorithm min-max values not allowed. |
| E2212 | Specifying both a start date/end date and a relative period is not allowed. |
| E2213 | Value of param orderBy is not compatible with algorithm *Z_SCORE*. |
| E7180 | The analytics outliers data does not exist. Please ensure analytics job was run and did not skip the outliers. |
| E7181 | Column *dxname* specified in orderBy, is not eligible for orderBy or does not exist. |

**_NOTE:_** *The values in error messages are examples only*

**Error message example**
```json
{
    "httpStatus": "Conflict",
    "httpStatusCode": 409,
    "status": "ERROR",
    "message": "Start date and end date or relative period must be specified",
    "errorCode": "E2201"
}
```
## Analytics query execution plan and costs including execution time estimation { #analytics-query-execution-plan-and-costs-including-execution-time-estimation } 

The analytics API provides endpoints for investigation of query performance issues. It is implemented as part of all analytics endpoints:

- analytics/explain
- analytics/event/explain
- analytics/enrollment/explain

**例**

    GET /api/analytics/explain?displayProperty=NAME
      &dimension=dx:Uvn6LCg7dVU;sB79w2hiLp8,ou:USER_ORGUNIT
      &filter=pe:THIS_YEAR&includeNumDen=false&skipMeta=false
      &skipData=true&includeMetadataDetails=true

The response looks like this.

```json
{
    "headers": [
        {
            "name": "dx",
            "column": "Data",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": true
        },
        {
            "name": "ou",
            "column": "Organisation unit",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": true
        },
        {
            "name": "value",
            "column": "Value",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        }
    ],
    "metaData": {
        "items": {
            "ImspTQPwCqd": {
                "uid": "ImspTQPwCqd",
                "code": "OU_525",
                "name": "Sierra Leone",
                "dimensionItemType": "ORGANISATION_UNIT",
                "valueType": "NUMBER",
                "totalAggregationType": "SUM"
            },
            "sB79w2hiLp8": {
                "uid": "sB79w2hiLp8",
                "name": "ANC 3 Coverage",
                "description": "Total 3rd ANC visits (Fixed and outreach) by expected number of pregnant women.",
                "legendSet": "fqs276KXCXi",
                "dimensionItemType": "INDICATOR",
                "valueType": "NUMBER",
                "totalAggregationType": "AVERAGE",
                "indicatorType": {
                    "name": "Per cent",
                    "displayName": "Per cent",
                    "factor": 100,
                    "number": false
                }
            },
            "dx": {
                "uid": "dx",
                "name": "Data",
                "dimensionType": "DATA_X"
            },
            "pe": {
                "uid": "pe",
                "name": "Period",
                "dimensionType": "PERIOD"
            },
            "ou": {
                "uid": "ou",
                "name": "Organisation unit",
                "dimensionType": "ORGANISATION_UNIT"
            },
            "Uvn6LCg7dVU": {
                "uid": "Uvn6LCg7dVU",
                "code": "IN_52486",
                "name": "ANC 1 Coverage",
                "description": "Total 1st ANC visits (Fixed and outreach) by expected number of pregnant women.",
                "legendSet": "fqs276KXCXi",
                "dimensionItemType": "INDICATOR",
                "valueType": "NUMBER",
                "totalAggregationType": "AVERAGE",
                "indicatorType": {
                    "name": "Per cent",
                    "displayName": "Per cent",
                    "factor": 100,
                    "number": false
                }
            },
            "THIS_YEAR": {
                "name": "This year"
            },
            "2022": {
                "uid": "2022",
                "code": "2022",
                "name": "2022",
                "dimensionItemType": "PERIOD",
                "valueType": "NUMBER",
                "totalAggregationType": "SUM",
                "startDate": "2022-01-01T00:00:00.000",
                "endDate": "2022-12-31T00:00:00.000"
            }
        },
        "dimensions": {
            "dx": [
                "Uvn6LCg7dVU",
                "sB79w2hiLp8"
            ],
            "pe": [
                "2022"
            ],
            "ou": [
                "ImspTQPwCqd"
            ],
            "co": []
        }
    },
    "performanceMetrics": {
        "totalTimeInMillis": 90.894,
        "executionPlans": [
            {
                "timeInMillis": 12.314,
                "planningTime": 6.801,
                "executionTime": 5.513,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(daysxvalue) / 365 as value from analytics_2022 as ax where ax.\"dx\" in ('h0xKKjijTdI') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 20.21,
                    "Total Cost": 5602.98,
                    "Plan Rows": 260,
                    "Plan Width": 32,
                    "Actual Startup Time": 5.448,
                    "Actual Total Time": 5.449,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 20.21,
                            "Total Cost": 5588.33,
                            "Plan Rows": 1520,
                            "Plan Width": 32,
                            "Actual Startup Time": 0.446,
                            "Actual Total Time": 5.003,
                            "Actual Rows": 1032,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'h0xKKjijTdI'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 46,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ao_ax_2022_MClNI",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 19.83,
                                    "Plan Rows": 1520,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 0.406,
                                    "Actual Total Time": 0.407,
                                    "Actual Rows": 1032,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'h0xKKjijTdI'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            },
            {
                "timeInMillis": 38.35,
                "planningTime": 0.627,
                "executionTime": 37.723,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(value) as value from analytics_2022 as ax where ax.\"dx\" in ('Jtf34kNZhzP') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 193.57,
                    "Total Cost": 47322.83,
                    "Plan Rows": 261,
                    "Plan Width": 32,
                    "Actual Startup Time": 37.685,
                    "Actual Total Time": 37.685,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 193.57,
                            "Total Cost": 47191.38,
                            "Plan Rows": 17179,
                            "Plan Width": 32,
                            "Actual Startup Time": 1.981,
                            "Actual Total Time": 32.332,
                            "Actual Rows": 17462,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'Jtf34kNZhzP'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 1165,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ax_2022_Eb64F",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 189.27,
                                    "Plan Rows": 17179,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 1.765,
                                    "Actual Total Time": 1.765,
                                    "Actual Rows": 17462,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'Jtf34kNZhzP'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            }
        ]
    },
    "width": 0,
    "rows": [],
    "height": 0,
    "headerWidth": 2
}
```

This response displays the execution plan that the PostgreSQL planner generates for the supplied statement.

The execution plan shows how the table(s) referenced by the statement will be scanned: by plain sequential scan, index scan,and if multiple tables are referenced, what joins will be used to bring together the required rows from each input table.

The most critical part of the display is the estimated statement execution cost, which is the query planner's estimate at how long it will take to run the statement.

All entry points are secured by authorization. The `F_PERFORM_ANALYTICS_EXPLAIN` role is required.

## Analytics explain { #webapi_analytics_explain }

    /api/analytics/explain

## Event analytics explain { #webapi_event_analytics_explain }

    /api/analytics/event/aggregate/{program}/explain

    /api/analytics/event/query/{program}/explain

## Enrollment analytics explain { #webapi_enrollment_analytics_explain }

    /api/analytics/enrollment/query/{program}/explain

## Outliers analytics explain  { #webapi_analytics_outlier_detection_explain } 

    /api/analytics/outlierDetection/explain



# 保养 { #maintenance } 

## Resource and analytics tables { #webapi_generating_resource_analytics_tables } 

DHIS2 具有一组生成的数据库表，用作
各种系统功能的基础。这些表可以执行
立即或计划通过定期执行
用户界面。它们也可以通过 Web API 生成为
本节说明。此任务通常是针对系统的一项任务
管理员而不使用客户端。

资源表由 DHIS2 应用程序内部使用
各种分析功能。这些表对用户也很有价值
编写高级 SQL 报告。它们可以通过 POST 或 PUT 生成
请求到以下 URL：

    / api / 33 / resourceTables

分析表针对数据聚合进行了优化并使用
目前在 DHIS2 中用于数据透视表模块。分析表可以
使用 POST 或 PUT 请求生成：

    / api / 33 / resourceTables / analytics



Table: Analytics tables optional query parameters

| 查询参数 | 选项 | 描述 |
|---|---|---|
| skipResourceTables | false &#124; true | Skip generation of resource tables |
| skipAggregate | false &#124; true | Skip generation of aggregate data and completeness data |
| skipEvents | false &#124; true | Skip generation of event data |
| skipEnrollment | false &#124; true | Skip generation of enrollment data |
| skipOrgUnitOwnership | false &#124; true | Skip generation of organization unit ownership data |
| lastYears | 整数 | Number of last years of data to include |

> **Note**
>
> lastYears=0 means latest or continuous analytics, as defined in
[Continuous analytics table](../../../use/user-guides/dhis-core-version-master/maintaining-the-system/scheduling.html#scheduling_continuous_analytics_table).


“数据质量”和“数据监控”可通过监控运行
任务，由以下端点触发：

    / api / 33 / resourceTables / monitoring

此任务将分析您的验证规则，查找任何违规并
将它们保存为验证结果。

这些请求将立即返回并启动服务器端
过程。

## 保养 { #webapi_maintenance } 

要执行维护，您可以与 *maintenance* 资源进行交互。您应该使用 *POST* 或 *PUT* 作为请求方法。可以使用以下方法。

清除分析表将删除所有分析表。

    开机自检/ api / maintenance / analyticsTablesClear

分析表分析将收集有关数据库中分析表内容的统计信息。

    开机自检/ api / maintenance / analyticsTablesAnalyze

清除过期邀请将删除所有用户帐户邀请
已过期。

    开机自检/ api / maintenance / expiredInvitationsClear

期间修剪将删除未链接到任何数据的期间
值。

    开机自检/ api / maintenance / periodPruning

零数据值删除将删除链接到数据的零数据值
零数据被定义为不重要的元素：

    开机自检/ api / maintenance / zeroDataValueRemoval

软删除的数据值删除将永久删除软删除的数据值。

    开机自检/ api / maintenance / softDeletedDataValueRemoval

软删除的程序阶段实例删除将永久删除软删除的事件。

    开机自检/ api / maintenance / softDeletedProgramStageInstanceRemoval

软删除程序实例的删除将永久删除软删除的注册。

    开机自检/ api / maintenance / softDeletedProgramInstanceRemoval

软删除的跟踪实体实例的删除将永久删除软删除的跟踪实体实例。

    开机自检/ api / maintenance / softDeletedTrackedEntityInstanceRemoval

删除SQL视图将删除数据库中的所有SQL视图。请注意，它不会删除DHIS2 SQL视图实体。

    开机自检/ api / maintenance / sqlViewsDrop

创建SQL视图将重新创建数据库中的所有SQL视图。

    开机自检/ api / maintenance / sqlViewsCreate

类别选项组合更新将删除过时并为所有类别组合生成缺少的类别选项组合。

    开机自检/ api / maintenance / categoryOptionComboUpdate

也可以使用以下端点为单个类别组合更新类别选项组合。

    开机自检/ api / maintenance / categoryOptionComboUpdate / categoryCombo / <category-combo-uid>

缓存清除将清除应用程序Hibernate缓存和分析分区缓存。

    开机自检/ api / maintenance / cacheClear

组织单位路径更新将重新生成组织单位路径属性。这可能是有用的，例如如果您使用SQL导入组织单位。

    开机自检/ api / maintenance / ouPathsUpdate

数据修剪将删除完整的数据集注册，数据批准，数据价值审核和数据价值，在这种情况下是组织单位。

    开机自检/ api / maintenance / dataPruning / organisationUnits / <org-unit-id>

数据元素的数据修剪，这将删除数据值审核和数据值。

    开机自检/ api / maintenance / dataPruning / dataElement / <data-element-uid>

元数据验证将应用所有元数据验证规则，并返回操作结果。

    开机自检/ api / metadataValidation

应用程序重新加载将通过从文件系统读取来刷新已安装应用程序的DHIS2托管缓存。

    开机自检/ api / appReload

通过对api / maintenance资源的POST请求以批处理方式支持维护操作，在api / maintenance资源中，该操作作为查询参数提供：

    开机自检/ api / maintenance？analyticsTablesClear = true＆expiredInvitationsClear = true
      ＆periodPruning = true＆zeroDataValueRemoval = true＆sqlViewsDrop = true＆sqlViewsCreate = true
      ＆categoryOptionComboUpdate = true＆cacheClear = true＆ouPathsUpdate = true

## 系统信息 { #webapi_system_resource } 

系统资源为您提供方便的信息和
职能。系统资源可以在 */api/system* 中找到。

### 产生识别码 { #webapi_system_resource_generate_identifiers } 

要生成有效的随机 DHIS2 标识符，您可以执行 GET 请求
此资源：

    / api / 33 / system / id？limit = 3

*limit* 查询参数是可选的，表示有多少
您希望与响应一起返回的标识符。默认为
返回一个标识符。响应将包含一个带有
数组命名代码，类似于：

```json
{
  "codes": [
    "Y0moqFplrX4",
    "WI0VHXuWQuV",
    "BRJNBBpu4ki"
  ]
}
```

DHIS2 UID格式具有以下要求：

  - 长11个字符。

  - 仅字母数字字符，即。字母或数字字符
    (A-Za-z0-9)。

  - 以字母字符（A-Za-z）开头。

### 查看系统信息 { #webapi_system_resource_view_system_information } 

要获取有关当前系统的信息，您可以执行 GET 请求
这个网址：

    / api / 33 / system / info

支持 JSON 和 JSONP 响应格式。系统信息响应
目前包括以下属性。

```json
{
  "contextPath": "http://yourdomain.com",
  "userAgent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/29.0.1547.62",
  "calendar": "iso8601",
  "dateFormat": "yyyy-mm-dd",
  "serverDate": "2021-01-05T09:16:03.548",
  "serverTimeZoneId": "Etc/UTC",
  "serverTimeZoneDisplayName": "Coordinated Universal Time",
  "version": "2.13-SNAPSHOT",
  "revision": "11852",
  "buildTime": "2013-09-01T21:36:21.000+0000",
  "serverDate": "2013-09-02T12:35:54.311+0000",
  "environmentVariable": "DHIS2_HOME",
  "javaVersion": "1.7.0_06",
  "javaVendor": "Oracle Corporation",
  "javaIoTmpDir": "/tmp",
  "javaOpts": "-Xms600m -Xmx1500m -XX:PermSize=400m -XX:MaxPermSize=500m",
  "osName": "Linux",
  "osArchitecture": "amd64",
  "osVersion": "3.2.0-52-generic",
  "externalDirectory": "/home/dhis/config/dhis2",
  "databaseInfo": {
    "type": "PostgreSQL",
    "name": "dhis2",
    "user": "dhis",
    "spatialSupport": false
  },
  "memoryInfo": "Mem Total in JVM: 848 Free in JVM: 581 Max Limit: 1333",
  "cpuCores": 8
}
```

> **注意**
>
>如果请求此资源的用户不具有完全权限，则仅包括不被视为敏感的属性。

仅获取有关系统上下文的信息，即`contextPath` 和
`userAgent`，您可以向以下 URL 发出 GET 请求。 JSON 和
支持 JSONP 响应格式：

    / api / 33 / system / context

### 检查用户名和密码组合是否正确 { #webapi_system_resource_check_username_password } 

检查某些用户凭据（用户名和密码组合）
是正确的，您可以使用以下资源向以下资源发出 *GET* 请求
*基本认证*：

    / api / 33 / system / ping

您可以通过检查 *HTTP 来检测身份验证的结果
响应头的状态码*。可能状态的含义
代码如下。请注意，这适用于 Web API 请求
一般的。



Table: HTTP Status codes

| HTTP Status code | 描述 | Outcome |
|---|---|---|
| 200 | OK | Authentication was successful |
| 302 | Found | No credentials were supplied with the request - no authentication took place |
| 401 | Unauthorized | The username and password combination was incorrect - authentication failed |

### 查看异步任务状态 { #webapi_system_resource_view_async_task_status } 

Tasks which often take a long time to complete can be performed
asynchronously. After initiating an async task you can poll the status
through the `system/tasks` resource by supplying the task category and
the task identifier of interest.

轮询任务状态时，您需要进行身份验证
启动任务的用户。以下任务类别是
支持的：



Table: Task categories

| 识别码 | 描述 |
|---|---|
| ANALYTICS_TABLE | Generation of the analytics tables. |
| RESOURCE_TABLE | Generation of the resource tables. |
| MONITORING | Processing of data surveillance/monitoring validation rules. |
| DATAVALUE_IMPORT | Import of data values. |
| EVENT_IMPORT | Import of events. |
| ENROLLMENT_IMPORT | Import of enrollments. |
| TEI_IMPORT | Import of tracked entity instances. |
| METADATA_IMPORT | Import of metadata. |
| DATA_INTEGRITY | Processing of data integrity checks. |

每个异步任务都会自动分配一个标识符，该标识符可以
用于监视任务的状态。这个任务标识符是
当您通过各种方式启动异步任务时由 API 返回
启用异步的端点。

#### 监控任务 { #monitoring-a-task } 

您可以通过对系统任务的 GET 请求轮询任务状态
像这样的资源：

    / api / 33 / system / tasks / {task-category-id} / {task-id}

一个示例请求可能看起来像这样：

    / api / 33 / system / tasks / DATAVALUE_IMPORT / j8Ki6TgreFw

响应将提供有关状态的信息，例如
通知级别、类别、时间和状态。 *已完成的*属性
指示该过程是否被认为是完整的。

```json
[{
  "uid": "hpiaeMy7wFX",
  "level": "INFO",
  "category": "DATAVALUE_IMPORT",
  "time": "2015-09-02T07:43:14.595+0000",
  "message": "Import done",
  "completed": true
}]
```

#### 监视类别的所有任务 { #monitoring-all-tasks-for-a-category } 

您可以通过 GET 请求轮询特定类别的所有任务
系统任务资源：

    / api / 33 / system / tasks / {task-category-id}

轮询数据值导入任务状态的示例请求
看起来像这样：

    / api / 33 / system / tasks / DATAVALUE_IMPORT

#### 监控所有任务 { #monitor-all-tasks } 

您可以使用以下命令请求系统中所有当前正在运行的任务的列表
对系统任务资源的 GET 请求：

    / api / 33 / system / tasks

响应将类似于以下内容：

```json
[{
  "EVENT_IMPORT": {},
  "DATA_STATISTICS": {},
  "RESOURCE_TABLE": {},
  "FILE_RESOURCE_CLEANUP": {},
  "METADATA_IMPORT": {},
  "CREDENTIALS_EXPIRY_ALERT": {},
  "SMS_SEND": {},
  "MOCK": {},
  "ANALYTICSTABLE_UPDATE": {},
  "COMPLETE_DATA_SET_REGISTRATION_IMPORT": {},
  "DATAVALUE_IMPORT": {},
  "DATA_SET_NOTIFICATION": {},
  "DATA_INTEGRITY": {
    "OB1qGRlCzap": [{
      "uid": "LdHQK0PXZyF",
      "level": "INFO",
      "category": "DATA_INTEGRITY",
      "time": "2018-03-26T15:02:32.171",
      "message": "Data integrity checks completed in 38.31 seconds.",
      "completed": true
    }]
  },
  "PUSH_ANALYSIS": {},
  "MONITORING": {},
  "VALIDATION_RESULTS_NOTIFICATION": {},
  "REMOVE_EXPIRED_RESERVED_VALUES": {},
  "DATA_SYNC": {},
  "SEND_SCHEDULED_MESSAGE": {},
  "DATAVALUE_IMPORT_INTERNAL": {},
  "PROGRAM_NOTIFICATIONS": {},
  "META_DATA_SYNC": {},
  "ANALYTICS_TABLE": {},
  "PREDICTOR": {}
}]
```

### 查看异步任务摘要 { #view-asynchronous-task-summaries } 

任务摘要资源允许您检索任务摘要
异步任务调用。您需要指定类别和
可选的任务标识符。任务标识符可以是
从发起请求的 API 请求的响应中检索
异步任务。

要检索特定任务的摘要，您可以发出以下请求：

    / api / 33 / system / taskSummaries / {task-category-id} / {task-id}

一个示例请求可能看起来像这样：

    / api / 33 / system / taskSummaries / DATAVALUE_IMPORT / k72jHfF13J1

响应将类似于以下内容：

```json
{
  "responseType": "ImportSummary",
  "status": "SUCCESS",
  "importOptions": {
    "idSchemes": {},
    "dryRun": false,
    "async": true,
    "importStrategy": "CREATE_AND_UPDATE",
    "reportMode": "FULL",
    "skipExistingCheck": false,
    "sharing": false,
    "skipNotifications": false,
    "datasetAllowsPeriods": false,
    "strictPeriods": false,
    "strictCategoryOptionCombos": false,
    "strictAttributeOptionCombos": false,
    "strictOrganisationUnits": false,
    "requireCategoryOptionCombo": false,
    "requireAttributeOptionCombo": false,
    "skipPatternValidation": false
  },
  "description": "Import process completed successfully",
  "importCount": {
    "imported": 0,
    "updated": 431,
    "ignored": 0,
    "deleted": 0
  },
  "dataSetComplete": "false"
}
```

您还可以检索多个任务的导入摘要
具有类似请求的特定类别
这：

    / api / 33 / system / taskSummaries / {task-category-id}

### 获取外观信息 { #webapi_system_resource_get_appearance_information } 

您可以使用 GET 以 JSON 格式检索可用的标志图标
要求：

    / api / 33 / system / flags

您可以使用 GET 以 JSON 格式检索可用的 UI 样式
要求：

    / api / 33 / system / styles


## Trigram Index Summary { #trigram-index-summary } 

Trigram indexes can be created using Tracker Search Optimization jobs. It is useful to know which tracked entity attributes are indexed and which ones are not. The following API can be used to get a summary of the trigram index status. The API supports field selection and filtering using the field query parameter.

The attributes corresponding to the property "indexedAttributes" are currently indexed in the system. The attributes corresponding to the property "indexableAttributes" are not indexed currently but are candidates for creating indexes if required. The attributes corresponding to the property "obsoleteIndexedAttributes" are indexed in the system, but those indexes are obsolete due to changes in the attribute configuration which do not qualify them as indexable anymore.

```
GET /api/39/trigramSummary
```

A sample JSON response looks like this:

```json
{
    "indexedAttributes": [{
        "displayName": "First name",
        "id": "w75KJ2mc4zz"
    }, {
        "displayName": "Last name",
        "id": "zDhUuAYrxNC"
    }],
    "indexableAttributes": [{
        "displayName": "Phone number",
        "id": "P2cwLGskgxn"
    }],
    "obsoleteIndexedAttributes": [{
        "displayName": "TB identifier",
        "id": "xs8A6tQJY0s"
    }, {
        "displayName": "Provider ID",
        "id": "DODgdr5Oo2v"
    }]
}
```

## Cluster info { #cluster-info } 

When DHIS 2 is set up in a cluster configuration, it is useful to know which node in the cluster acts as the leader of the cluster. The following API can be used to get the details of the leader node instance. The API supports both JSON and XML formats.

```
GET /api/36/cluster/leader
```

A sample JSON response looks like this:

```json
{
  "leaderNodeId": "play-dhis2-org-dev",
  "leaderNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "currentNodeId": "play-dhis2-org-dev",
  "currentNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "leader": true
}
```

## 最小-最大数据元素 { #webapi_min_max_data_elements } 

min-max 数据元素资源允许您设置最小值和最大值
数据元素的值范围。它是独一无二的
组织单位、数据元素和类别选项组合。

    / api / minMaxDataElements



Table: Min-max data element data structure

| 项目 | 描述 | 数据类型 |
|---|---|---|
| source | Organisation unit identifier | 串 |
| dataElement | Data element identifier | 串 |
| optionCombo | Data element category option combo identifier | 串 |
| min | Minimum value | 整数 |
| max | Maximum value | 整数 |
| generated | Indicates whether this object is generated by the system (and not set manually). | Boolean |

您可以从以下位置检索所有最小-最大数据元素的列表
资源：

    GET /api/minMaxDataElements.json

您可以像这样过滤响应：

    GET /api/minMaxDataElements.json?filter=dataElement.id:eq:UOlfIjgN8X6

    GET /api/minMaxDataElements.json?filter=dataElement.id:in:[UOlfIjgN8X6,xc8gmAKfO95]

min-max 数据元素的过滤器参数支持两种运算符：
eq 和 in。您还可以使用 `fields` 查询参数。

    GET /api/minMaxDataElements.json?fields=:all,dataElement[id,name]

### 添加/更新最小-最大数据元素 { #webapi_add_update_min_max_data_element } 

要添加新的最小-最大数据元素，请使用POST请求执行以下操作：

    POST /api/minMaxDataElements.json

JSON内容格式如下所示：

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

如果数据元素、组织单位和类别的组合
选项组合存在，最小值-最大值将被更新。

### 删除最小-最大数据元素 { #webapi_delete_min_max_data_element } 

要删除最小-最大数据元素，请使用DELETE方法发送请求：

    删除/api/minMaxDataElements.json

JSON内容的格式与上述类似：

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

## 锁定异常 { #webapi_lock_exceptions } 

锁定异常资源允许您打开其他锁定的数据
用于特定数据集、时期和组织的数据输入集
单元。您可以从以下资源中读取锁定异常：

    / api / lockExceptions

要创建新的锁定异常，您可以使用 POST 请求并指定
数据集、期间和组织单位：

    POST / api / lockExceptions？ds = BfMAe6Itzgt＆pe = 201709＆ou = DiszpKrYNg8

要删除锁定异常，您可以使用类似的请求语法
删除请求：

    删除/ api / lockExceptions？ds = BfMAe6Itzgt＆pe = 201709＆ou = DiszpKrYNg8




# Data exchange { #data-exchange } 

## Aggregate data exchange { #aggregate-data-exchange } 

This section describes the aggregate data exchange service and API.

### 介绍 { #introduction } 

The aggregate data exchange service offers the ability to exchange data between instances of DHIS 2, and possibly other software which supports the DHIS 2 data value set JSON format. It also allows for data exchange within a single instance of DHIS 2, for instance for aggregation of tracker data and saving the result as aggregate data. 

The aggregate data exchange service is suitable for use-cases such as:

* Data exchange between an HMIS instance to a data portal or data warehouse instance of DHIS 2.
* Data exchange between a DHIS 2 tracker instance with individual data to an aggregate HMIS instance.
* Precomputation of tracker data with program indicators saved as aggregate data values.
* Data reporting from a national HMIS to a global donor.

### 总览 { #overview } 

The aggregate data exchange service allows for data exchange between a *source* instance of DHIS 2 and a *target* instance of DHIS 2. A data exchange can be *external*, for which the target instance is different/external to the source instance. A data exchange can also be *internal*, for which the target instance is the same as the source instance. The aggregate data exchange source can contain multiple source requests, where a source request roughly corresponds to an analytics API request.

The data value will be retrieved and transformed into the *data value set* format, and then pushed to the target instance of DHIS 2. The aggregate data exchange service supports *identifier schemes* to allow for flexibility in mapping metadata between instances.

Data will be retrieved and aggregated from the source instance using the analytics engine. This implies that data elements, aggregate indicators, data set reporting rates and program indicators can be referenced in the request to the source instance. A source request also contains periods, where both fixed and relative periods are supported, and organisation units. Any number of *filters* can be applied to a source request.

A data exchange can be run as a scheduled job, where the data exchange can be set to run at a specific interval. A data exchange can also be run on demand through the API.

要创建和操作聚合数据交换，需要`F_AGGREGATE_DATA_EXCHANGE_PUBLIC_ADD` / `F_AGGREGATE_DATA_EXCHANGE_PRIVATE_ADD` and `F_AGGREGATE_DATA_EXCHANGE_DELETE`权限。

The aggregate data exchange definitions are regular metadata in DHIS 2, meaning that the definitions can be imported and exported between instances of DHIS 2. The exception is credentials (usernames and access tokens) which will not be exposed in metadata exports. Credentials are encrypted in storage to provide an additional layer of security.

The aggregate data exchange service was introduced in version 2.39, which means that the source instance of DHIS 2 must be version 2.39 or later. The target instance of DHIS 2 must be version 2.38 or later.

### Authentication { #authentication } 

For data exchanges of type external, the base URL and authentication credentials for the target DHIS 2 instance must be specified. For authentication, basic authentication and personal access tokens (PAT) are supported.

It is recommended to either specify basic authentication or PAT authentication. If both are specified, PAT authentication takes precedence.

Note that PAT support was introduced in version 2.38.1, which means that in order to use PAT authentication, the target DHIS 2 instance must be version 2.38.1 or later.

### 分享中 { #sharing } 
Like other metadata objects, fine-grained security can be associated with aggregate data exchanges. Each exchange can be shared with individual users and/or user groups to control which users have access to the specific exchange. External data exchanges contain authentication details of users on the target system, thus great care should be
taken to ensure that only authorized users have access to actually submit data which results from the exchange.

The following table summarizes how sharing can be used with aggregate data exchanges.


| 分享中 | Effective permissions                                                              |
| -------- |-----------------------------------------------------------------------------------|
| "r-------" | Can view metadata of the data exchange. |
| "-w------" | Can edit metadata of the data exchange. |
| "--r-----" | Can view data which is part of the exchange. |
| "---w----" | Can submit data which is part of the exchange. |

### API { #api } 

The aggregate data exchange API is covered in the following section.

#### Create aggregate data exchange { #create-aggregate-data-exchange } 

```
POST /api/aggregateDataExchanges
```

```
Content-Type: application/json
```

Example internal data exchange payload, where event data is computed with program indicators and saved as aggregate data values: 

```json
{
  "name": "Internal data exchange",
  "source": {
    "params": {
      "periodTypes": [
        "MONTHLY",
        "QUARTERLY"
      ]
    },
    "requests": [
      {
        "name": "ANC",
        "visualization": null,
        "dx": [
          "fbfJHSPpUQD",
          "cYeuwXTCPkU",
          "Jtf34kNZhzP"
        ],
        "pe": [
          "LAST_12_MONTHS",
          "202201"
        ],
        "ou": [
          "ImspTQPwCqd"
        ],
        "filters": [
          {
            "dimension": "Bpx0589u8y0",
            "items": [
              "oRVt7g429ZO",
              "MAs88nJc9nL"
            ]
          }
        ],
        "inputIdScheme": "UID",
        "outputDataElementIdScheme": "UID",
        "outputOrgUnitIdScheme": "UID",
        "outputIdScheme": "UID"
      }
    ]
  },
  "target": {
    "type": "INTERNAL",
    "request": {
      "dataElementIdScheme": "UID",
      "orgUnitIdScheme": "UID",
      "categoryOptionComboIdScheme": "UID",
      "idScheme": "UID"
    }
  }
}
```

Example external data exchange payload with basic authentication and ID scheme *code*, where data is pushed to an external DHIS 2 instance:

```json
{
  "name": "External data exchange with basic authentication",
  "source": {
    "requests": [
      {
        "name": "ANC",
        "visualization": null,
        "dx": [
          "fbfJHSPpUQD",
          "cYeuwXTCPkU",
          "Jtf34kNZhzP"
        ],
        "pe": [
          "LAST_12_MONTHS",
          "202201"
        ],
        "ou": [
          "ImspTQPwCqd"
        ],
        "inputIdScheme": "UID",
        "outputIdScheme": "CODE"
      }
    ]
  },
  "target": {
    "type": "EXTERNAL",
    "api": {
        "url": "https://play.dhis2.org/2.38.2.1",
        "username": "admin",
        "password": "district"
    },
    "request": {
      "idScheme": "CODE"
    }
  }
}
```

Example external data exchange payload with PAT authentication and ID scheme *code*, where data is pushed to an external DHIS 2 instance:

```json
{
  "name": "External data exchange with PAT authentication",
  "source": {
    "requests": [
      {
        "name": "ANC",
        "dx": [
          "fbfJHSPpUQD",
          "cYeuwXTCPkU",
          "Jtf34kNZhzP"
        ],
        "pe": [
          "LAST_12_MONTHS",
          "202201"
        ],
        "ou": [
          "ImspTQPwCqd"
        ],
        "inputIdScheme": "UID",
        "outputIdScheme": "CODE"
      }
    ]
  },
  "target": {
    "type": "EXTERNAL",
    "api": {
        "url": "https://play.dhis2.org/2.38.2.1",
        "accessToken": "d2pat_XIrqgAGjW935LLPuSP2hXSZwpTxTW2pg3580716988"
    },
    "request": {
      "idScheme": "CODE"
    }
  }
}
```

The syntax for the source requests follow the analytics endpoint API syntax. This means that for the `dx` part, data elements, indicators, data set reporting rates, program data elements and program indicators are supported. Note that for program data elements, the data element must be prefixed with the program identifier. For the `pe` part, relative periods as well as fixed periods are supported. For the `ou` part, user org units, org unit levels and org unit groups as well as individual org units are supported. Consult the *Analytics* chapter > the *Dimensions and items* and *The dx dimension* sections for a full explanation.

##### Response { #response } 

```
201 Created
```

```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "response": {
    "responseType": "ObjectReport",
    "uid": "pG4bBTMiCqO",
    "klass": "org.hisp.dhis.dataexchange.aggregate.AggregateDataExchange",
    "errorReports": []
  }
}
```

#### Update aggregate data exchange { #update-aggregate-data-exchange } 

```
PUT /api/aggregateDataExchanges/{id}
```

```
Content-Type: application/json
```

The request payload is identical to the create operation.

##### Response { #response } 

```
200 OK
```

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "response": {
    "responseType": "ObjectReport",
    "uid": "pG4bBTMiCqO",
    "klass": "org.hisp.dhis.dataexchange.aggregate.AggregateDataExchange",
    "errorReports": []
  }
}
```

#### Get aggregate data exchange { #get-aggregate-data-exchange } 

```
GET /api/aggregateDataExchanges/{id}
```

``` 
Accept: application/json
```

The retrieval endpoints follow the regular metadata endpoint field filtering and object filtering semantics. JSON is the only supported response format.

##### Response { #response } 

```
200 OK
```

#### Delete aggregate data exchange { #delete-aggregate-data-exchange } 

```
DELETE /api/aggregateDataExchanges/{id}
```

##### Response { #response } 

```
204 No Content
```

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "response": {
    "responseType": "ObjectReport",
    "uid": "pG4bBTMiCqO",
    "klass": "org.hisp.dhis.dataexchange.aggregate.AggregateDataExchange",
    "errorReports": []
  }
}
```

#### Run aggregate data exchange { #run-aggregate-data-exchange } 

An aggregate data exchange can be run directly with a POST request to the following endpoint:

```
POST /api/aggregateDataExchanges/{id}/exchange
```

##### Response { #response } 

```
200 OK
```

```json
{
  "responseType": "ImportSummaries",
  "status": "SUCCESS",
  "imported": 36,
  "updated": 0,
  "deleted": 0,
  "ignored": 0,
  "importSummaries": ["<import summaries here>"]
}
```

An import summary describing the outcome of the data exchange will be returned, including the number of data values which were imported, updated, deleted and ignored.

#### Get source data { #get-source-data } 

The aggregate data for the source request of an aggregated data exchange can be retrieved in the analytics data format with a GET request to the following endpoint:

```
GET /api/aggregateDataExchanges/{id}/sourceData
```

```
Accept: application/json
```

##### Response { #response } 

```
200 OK
```

##### Query parameters { #query-parameters } 

| 查询参数 | 需要 | 描述                                                  | 选项                       |
| --------------- | -------- | ------------------------------------------------------------ | ----------------------------- |
| outputIdScheme  | 不       | Override the output identifier scheme for the data response. | UID \| CODE \| ATTRIBUTE:{ID} |

The response payload format is identical with the analytics API endpoint. This endpoint is useful for debugging purposes. Consult the analytics API guide for additional details.

#### Get source data value sets { #get-source-data-value-sets } 

The aggregate data for the source request of an aggregated data exchange can be retrieved in the data value set format with a GET request to the following endpoint:

```
GET /api/aggregateDataExchanges/{id}/sourceDataValueSets
```

```
Accept: application/json
```

##### Response { #response } 

```
200 OK
```

##### Query parameters { #query-parameters } 

| 查询参数 | 需要 | 描述                                                  | 选项                       |
| --------------- | -------- | ------------------------------------------------------------ | ----------------------------- |
| outputIdScheme  | 不       | Override the output identifier scheme for the data response. | UID \| CODE \| ATTRIBUTE:{ID} |

The response payload format is identical with the data value sets API endpoint. This endpoint is useful for debugging purposes. Consult the data value sets API guide for additional details.

### 数据模型 { #data-model } 

The aggregate data exchange data model / payload is described in the following section.

| 领域                                             | 数据类型      | 强制的   | 描述                                                  |
| ------------------------------------------------- | -------------- | ----------- | ------------------------------------------------------------ |
| 名称                                              | 串         | 是的         | Name of aggregate data exchange. Unique.                     |
| source                                            | 目的         | 是的         | Source for aggregate data exchange.                          |
| source.params                                     | 目的         | 不          | Parameters for source request.                               |
| source.params.periodTypes                         | Array/String   | 不          | Allowed period types for overriding periods in source request. |
| source.requests                                   | Array/Object   | 是的         | Source requests.                                             |
| source.requests.name                              | 串         | 是的         | Name of source request.                                      |
| source.requests.visualization                     | 串         | 不          | Identifier of associated visualization object.               |
| source.requests.dx                                | Array/String   | 是的         | Identifiers of data elements, indicators, data sets and program indicators for the source request. |
| source.requests.pe                                | Array/String   | 是的         | Identifiers of fixed and relative periods for the source request. |
| source.requests.ou                                | Array/String   | 是的         | Identifiers of organisation units for the source request.    |
| source.requests.filters                           | Array (Object) | 不          | Filters for the source request.                              |
| source.requests.filters.dimension                 | 串         | 不          | Dimension identifier for the filter.                         |
| source.requests.filters.items                     | Array/String   | 不          | Item identifiers for the filter.                             |
| source.requests.inputIdScheme                     | 串         | 不          | Input ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`.     |
| source.requests.outputDataElementIdScheme         | 串         | 不          | Output data element ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.requests.outputDataItemIdScheme         | 串         | 不          | Output data item ID scheme applies to data elements, indicators and program indicators, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.requests.outputOrgUnitIdScheme             | 串         | 不          | Output org unit ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.requests.outputIdScheme                    | 串         | 不          | Output general ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.target                                     | 目的         | 是的         | Target for  aggregate data exchange.                         |
| source.target.type                                | 串         | 是的         | Type of target, can be `EXTERNAL`, `INTERNAL`.               |
| source.target.api                                 | 目的         | Conditional | 目标 API 信息，仅对`EXTERNAL`类型是必需的。  |
| source.target.api.url                             | 串         | Conditional | Base URL of target DHIS 2 instance, do not include the `/api` part. |
| source.target.api.accessToken                     | 串         | Conditional | Access token (PAT) for target DHIS 2 instance, used for PAT authentication. |
| source.target.api.username                        | 串         | Conditional | Username for target DHIS 2 instance, used for basic authentication. |
| source.target.api.password                        | 串         | Conditional | Password for target DHIS 2 instance, used for basic authentication. |
| source.target.request                             | 目的         | 不          | Target request information.                                  |
| source.target.request.dataElementIdScheme         | 串         | 不          | Input data element ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.target.request.orgUnitIdScheme             | 串         | 不          | Input org unit ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.target.request.categoryOptionComboIdScheme | 串         | 不          | Input category option combo ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.target.request.idScheme                    | 串         | 不          | Input general ID scheme, can be `UID`, `CODE`, `ATTRIBUTE:{ID}`. |
| source.target.request.importStrategy                    | 串         | 不          | Import strategy, can be `CREATE_AND_UPDATE`, `CREATE`, `UPDATE`, `DELETE`. |
| source.target.request.skipAudit                    | Boolean         | 不          | Skip audit, meaning audit values will not be generated. Improves performance at the cost of ability to audit changes. Requires authority "F_SKIP_DATA_IMPORT_AUDIT". |
| source.target.request.dryRun                    | Boolean         | 不          | Whether to save changes on the server or just return the import summary. |

### Error handling { #error-handling } 

When running a data exchange by identifier, information about the outcome of the operation will be available in the response payload. The response will contain a list of import summaries, i.e. one import summary per source request. The import summary will indicate any potential conflicts as a result of data retrieval from the source instance and data import in the target instance.

### 例子 { #examples } 

#### External data exchange with identifier scheme code { #external-data-exchange-with-identifier-scheme-code } 

This example will demonstrate how to exchange data based on program indicators in the source DHIS 2 instance and data elements in the target instance. The `code` identifier scheme, which means the data exchange will use the `code` property on the metadata to reference the data. Using codes is useful when the ID properties don't match across DHIS 2 instances. The example will demonstrate how data can be aggregated in the source instance, including aggregation in time and the unit hierarchy, before being exchanged with the target instance.

The example will exchange data using the DHIS 2 play environment, and refer to the 2.39 version at `https://play.dhis2.org/2.39` as the *source instance*, and the 2.38 version at `https://play.dhis2.org/2.38.2.1` as the *target instance*. Note that the URLs will change over time as new patch versions are released, so make sure to update the target URLs.

* Log in to the **source** instance, navigate to the Maintenance app and observe that three program indicators exist.

  * _BCG doses_ with code `BCG_DOSE`
  * _Measles doses_ with code `MEASLES_DOSE` 
  * _Yellow fever doses_ with code `YELLOW_FEVER_DOSE`

* 请注意，根组织单位是`塞拉利昂`，代码为`OU_525`。

* Log in to the **target** instance and navigate to the *Maintenance* app. Create three data elements, where the codes match the previously mentioned program indicators:

  * Name _BCG doses_ and code `BCG_DOSE`
  * Name _Measles doses_ and code `MEASLES_DOSE`
  * 用代码`YELLOW_FEVER_DOSE`命名_黄热病剂量_

* In the **target** instance, create a new data set with any name, e.g. _Data exchange_, select the tree newly created data elements, and assign the data set to the root org unit _Sierra Leone_.

* Observe that the root org unit `Sierra Leone` has the code `OU_525`, which is equal to the source instance.

* Open an HTTP tool such as _Postman_ and put together the following aggregate data exchange payload in JSON.
  ```
  POST /api/aggregateDataExchanges
  ```

  ```
  Content-Type: application/json
  ```

  ```json
  {
    "name": "Immunization doses program indicators to data elements",
    "source": {
      "requests": [
        {
          "name": "Immunization doses",
          "dx": [
            "BCG_DOSE",
            "MEASLES_DOSE",
            "YELLOW_FEVER_DOSE"
          ],
          "pe": [
            "202201"
          ],
          "ou": [
            "OU_525"
          ],
          "inputIdScheme": "code",
          "outputIdScheme": "code"
        }
      ]
    },
    "target": {
      "type": "EXTERNAL",
      "api": {
        "url": "https://play.dhis2.org/2.38.2.1",
        "username": "admin",
        "password": "district"
      },
      "request": {
        "idScheme": "code"
      }
    }
  }
  ```

* In this payload, observe that for the source request, program indicators are referred to using codes. The `inputIdScheme` is set to `code`, which means that the DHIS 2 analytics engine will use the `code` property to reference metadata, such as program indicators. The `outputIdScheme` is set to `code`, which means that the `code` property will be used to reference metadata in the output. For the target request, the `idScheme` is also set to `code`, which means that the `code` property will be used to reference metadata during the data value import. Note that ID schemes can be specified per entity type, such as `dataElementIdScheme` and `orgUnitIdScheme`. 

* 请注意，期间为`202201`或_2022 年1 月_。请注意，时间段可能需要随着时间的推移而更新。

* Run the POST request to create the aggregate data exchange definition. Confirm that the API response status code is 201. Note that the name of the data exchange is unique. Take a note of the ID of the newly created object by looking at `response` > `uid` in the response body.

* Run the newly created data exchange with a POST request (replace `{id}` with the ID of the data exchange):
  ```
  POST /api/aggregateDataExchanges/{id}/exchange
  ```

* Confirm that the API response indicates that three data values were successfully imported. 
  ```json
  {
    "responseType": "ImportSummaries",
    "status": "SUCCESS",
    "imported": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0
  }
  ```

* In the **target** instance, navigate to the *Data entry* app, select org unit _Sierra Leone_, data set _Data exchange_ and period _January 2022_. Observe that the exchanged data values are visible in the form.

总而言之，在此示例中，事件数据记录在组织单位层次结构中从设施级别汇总到国家级别，并使用计划指标从事件数据汇总到每月数据值。通过使用`代码`属性引用元数据，数据值与目标 DHIS 2 实例交换。


# I18n { #i18n } 

## 语言环境 { #webapi_locales } 

DHIS2 支持用户界面和数据库的翻译
内容。

### UI语言环境 { #ui-locales } 

您可以通过以下方式检索用户界面的可用区域设置
以下资源带有 GET 请求。 XML 和 JSON 资源
支持表示。

    / api / 33 / locales / ui

### 数据库内容语言环境 { #database-content-locales } 

You can retrieve and create locales for the database content with GET and POST requests through the `dbLocales` resource. XML and JSON resource representations are supported. To POST data, there are two required parameters: `country` and `language`. 

    /api/locales/dbLocales?country=US&language=en

## 翻译 { #webapi_translations } 

DHIS2 allows for translations of database content. 
If a metadata is translatable, then it will have a `translations` property.

That means you can retrieve and update translations using metadata class resources such as `api/dataElements`, `api/organisationUnits`, `api/dataSets`, etc.

### 获取翻译 { #get-translations } 

You can get translations for a metadata object such as DataElement by sending a GET request to `api/dataElements/{dataElementUID}`

The response contains full details of the DataElement which also includes the `translations` property as below

```json
{
  "id": "fbfJHSPpUQD",
  "href": "https://play.dhis2.org/dev/api/29/dataElements/fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```
You can also get only the `translations` property of an object by sending a GET request to 
`api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

### Create/Update translations { #createupdate-translations } 

You can create translations by sending a PUT request with same JSON format to `api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "DESCRIPTION",
      "locale": "fr",
      "value": "description in french"
    },
    {
      "property": "FORM_NAME",
      "locale": "fr",
      "value": "name in french"
    }
  ]
}
```

Alternatively, you can also just update the object with payload including the `translations` property.

Send PUT request to `api/dataElements/{dataElementUID}` with full object payload as below:

```json
{
  "id": "fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

The status code will be `204 No Content` if the data value was successfully saved or updated, or `409 Conflict` if there was a validation error (e.g. more than one `SHORT_NAME` for the same `locale`).

The common properties which support translations are listed in the table below.

Table: Property names

| Property name | 描述 |
|---|---|
| 名称 | Object name |
| shortName | Object short name |
| 描述 | Object description |

下表列出了支持翻译的类。

Table: Class names

| Class name | 描述 | Other translatable Properties |
|---|---|---|
| DataElementCategoryOption | 类别选项 | |
| DataElementCategory | 类别 | |
| DataElementCategoryCombo | Category combination | |
| 数据元素 | 数据元素 | |
| DataElementGroup | 数据元素组 | |
| DataElementGroupSet | Data element group set | |
| 指示符 | 指示符 | numeratorDescription, denominatorDescription |
| IndicatorType | Indicator type | |
| IndicatorGroup | Indicator group | |
| IndicatorGroupSet | Indicator group set | |
| 组织单位 | 组织单位 | |
| OrganisationUnitGroup | 组织单位组 | |
| OrganisationUnitGroupSet | Organisation unit group set | |
| 数据集 | 资料集 | |
| Section | Data set section | |
| ValidationRule | Validation rule | instruction |
| ValidationRuleGroup | Validation rule group | |
| 程序 | 程序 | enrollmentDateLabel, incidentDateLabel |
| 程序阶段 | 程序阶段 | executionDateLabel, dueDateLabel |
| 跟踪实体属性 | 跟踪实体属性 | |
| TrackedEntity | Tracked entity | |
| 关系类型 | Relationship type for tracked entity instances | fromToName, toFromName |
| 选项集 | Option set | |
| 选项 | 选项 | |
| 属性 | Attribute for metadata | |
| ProgramNotificationTemplate | Program Notification template | subjectTemplate, messageTemplate |
| ValidationNotificationTemplate | Validation Notification template | subjectTemplate, messageTemplate |
| DataSetNotificationTemplate | DataSet Notification template | subjectTemplate, messageTemplate |
| Visualization | Visualization | title, subtitle, rangeAxisLabel, baseLineLabel, targetLineLabel, domainAxisLabel |
| ProgramRuleAction | Program Rule Actions | content |
| 预测变量 | 预测变量 | Name, ShortName, Description, Generator Description  |
| ValidationRule | ValidationRule | Name, Description, Instruction, Leftside expression, Rightside expression |

## 国际化 { #webapi_i18n } 

为了检索翻译字符串的键值对，您可以使用
*i18n* 资源。

    / api / 33 / i18n

端点位于 */api/i18n* 并且请求格式是一个简单的
键值对数组：

```json
[
  "access_denied",
  "uploading_data_notification"
]
```

请求必须是 *POST* 类型并使用 *application/json* 作为
内容类型。使用 curl 的示例，假设请求数据已保存
作为文件`keys.json`：

```bash
curl -d @keys.json "play.dhis2.org/demo/api/33/i18n" -X POST
  -H "Content-Type: application/json" -u admin:district
```

结果将如下所示：

```json
{
  "access_denied":"Access denied",
  "uploading_data_notification":"Uploading locally stored data to the server"
}
```





# 短信 { #sms } 

## 短消息服务（SMS） { #webapi_sms } 

本节介绍用于发送和接收短文本的 SMS Web API
消息。

### 出站短信服务 { #outbound-sms-service } 

Web API 支持使用 POST 方法发送外发 SMS。短信可以
发送到单个或多个目的地。一个或多个网关需要
在使用服务之前进行配置。如果出现以下情况，将不会发送短信
没有配置网关。它需要一组接收者和
JSON 格式的消息文本，如下所示。

    / api / sms / outbound

```json
{
  "message":"Sms Text",
  "recipients": [
    "004712341234",
    "004712341235"
  ]
}
```

> **Note**
>
> Recipients list will be partitioned if the size exceeds `MAX_ALLOWED_RECIPIENTS` limit of 200.

Web API 也支持查询参数版本，但
参数化 API 只能用于发送短信到单个
目的地。

    / api / sms / outbound？message = text＆recipient = 004712341234

可以使用GET资源提取出站邮件。

    GET / api / sms / outbound
    GET / api / sms / outbound？filter = status：eq：SENT
    GET / api / sms / outbound？filter = status：eq：SENT＆fields = *

可以使用DELETE资源删除出站邮件。

    删除/ api / sms / outbound / {uid}
    删除/ api / sms / outbound？ids = uid1，uid2

#### 网关响应码 { #gateway-response-codes } 

网关可以使用以下响应代码进行响应。



Table: Gateway response codes

| Response code | Response Message | Detail Description |
|---|---|---|
| RESULT_CODE_0 | success | Message has been sent successfully |
| RESULT_CODE_1 | scheduled | Message has been scheduled successfully |
| RESULT_CODE_22 | internal fatal error | Internal fatal error |
| RESULT_CODE_23 | authentication failure | Authentication credentials are incorrect |
| RESULT_CODE_24 | data validation failed | Parameters provided in request are incorrect |
| RESULT_CODE_25 | insufficient credits | Credit is not enough to send message |
| RESULT_CODE_26 | upstream credits not available | Upstream credits not available |
| RESULT_CODE_27 | exceeded your daily quota | You have exceeded your daily quota |
| RESULT_CODE_40 | temporarily unavailable | Service is temporarily down |
| RESULT_CODE_201 | maximum batch size exceeded | Maximum batch size exceeded |
| RESULT_CODE_200 | success | The request was successfully completed |
| RESULT_CODE_202 | accepted | The message(s) will be processed |
| RESULT_CODE_207 | multi-status | More than one message was submitted to the API; however, not all messages have the same status |
| RESULT_CODE_400 | bad request | Validation failure (such as missing/invalid parameters or headers) |
| RESULT_CODE_401 | unauthorized | Authentication failure. This can also be caused by IP lockdown settings |
| RESULT_CODE_402 | payment required | Not enough credit to send message |
| RESULT_CODE_404 | not found | Resource does not exist |
| RESULT_CODE_405 | method not allowed | Http method is not support on the resource |
| RESULT_CODE_410 | gone | Mobile number is blocked |
| RESULT_CODE_429 | too many requests | Generic rate limiting error |
| RESULT_CODE_503 | service unavailable | A temporary error has occurred on our platform - please retry |

### 入站短信服务 { #inbound-sms-service } 

Web API 支持使用 POST 收集传入的 SMS 消息
方法。路由到 DHIS2 Web API 的传入消息可以是
使用此 API 接收。 API 收集入站 SMS 消息和
根据短信内容（SMS
命令）。下面给出了 JSON 格式的示例负载。文本，
发起者、接收日期和发送日期是强制性参数。这
其余是可选的，但系统将使用这些默认值
参数。

    / api / sms / inbound

```json
{
  "text": "sample text",
  "originator": "004712341234",
  "gatewayid": "unknown",
  "receiveddate": "2016-05-01",
  "sentdate":"2016-05-01",
  "smsencoding": "1",
  "smsstatus":"1"
}
```

可以使用GET resourcef获取入站消息

    GET / api / sms / inbound
    GET / api / sms / inbound？fields = *＆filter = smsstatus = INCOMING

可以使用DELETE资源删除入站邮件

    删除/ api / sms / inbound / {uid}
    删除/ api / sms / inbound？ids = uid1，uid2

导入所有未解析的消息

    POST /api/sms/入站/导入



Table: User query parameters

| Parameter | 类型 | 描述 |
|---|---|---|
| message | 串 | This is mandatory parameter which carries the actual text message. |
| originator | 串 | This is mandatory parameter which shows by whom this message was actually sent from. |
| gateway | 串 | This is an optional parameter which gives gateway id. If not present default text "UNKNOWN" will be stored |
| receiveTime | 日期 | This is an optional parameter. It is timestamp at which message was received at the gateway. |

### 网关服务管理 { #gateway-service-administration } 

Web API 公开资源，这些资源提供了一种配置和
更新短信网关配置。

可以使用 GET 检索配置的不同网关的列表
方法。

    GET /api/33/gateways

还可以使用特定网关类型检索配置
获取方法。

    GET /api/33/gateways/{uid}

可以使用 POST 添加新的网关配置。 POST api 需要类型请求参数，目前它的值可以有一个 *http,bulksms,clickatell,smpp*。第一个添加的网关将设置为默认值。一次只能默认一个网关。默认网关只能通过其 api 更改。如果删除了默认网关，则列表中的下一个网关将自动变为默认网关。

    POST / api / 33 / gateways

可以通过提供如下所述的uid和网关配置来更新配置

    PUT /api/33/gateways/{uids}

可以使用 DELETE 删除特定网关类型的配置
方法。

    删除/ api / 33 / gateways / {uid}

可以检索和更新默认网关。

    GET /api/33/gateways/default

可以使用PUT方法设置默认网关。

    PUT /api/33/gateways/default/{uid}

### 网关配置 { #gateway-configuration } 

Web API 允许您创建和更新网关配置。对于每个
网关类型 JSON 有效负载中有不同的参数。
下面给出了每个网关的示例 JSON 有效负载。 POST 用于
create 和 PUT 以更新配置。标头参数可用于
GenericHttpGateway 将一个或多个参数作为 http 标头发送的情况。

#### Clickatell { #clickatell } 

```json
{
  "type" : "clickatell",
  "name" : "clickatell",
  "username": "clickatelluser",
  "authToken": "XXXXXXXXXXXXXXXXXXXX",
  "urlTemplate": "https://platform.clickatell.com/messages"
}
```

#### 散装 { #bulksms } 

```json
{
  "type": "bulksms",
  "name": "bulkSMS",
  "username": "bulkuser",
  "password": "abc123"
}
```

#### SMPP网关 { #smpp-gateway } 

```json
{
  "type": "smpp",
  "name": "smpp gateway2",
  "systemId": "smppclient1",
  "host": "localhost",
  "systemType": "cp",
  "numberPlanIndicator": "UNKNOWN",
  "typeOfNumber": "UNKNOWN",
  "bindType": "BIND_TX",
  "port": 2775,
  "password":"password",
  "compressed": false
}
```

#### 通用HTTP { #generic-http } 

```json
{
  "type": "http",
  "name": "Generic",
  "configurationTemplate": "username=${username}&password=${password}&to=${recipients}&countrycode=880&message=${text$}&messageid=0",
  "useGet": false,
  "sendUrlParameters":false,
  "contentType": "APPLICATION_JSON",
  "urlTemplate":"https://samplegateway.com/messages",
  "parameters": [
    {
      "header": true,
      "encode": false,
      "key": "username",
      "value": "user_uio",
      "confidential": true
    },
    {
      "header": true,
      "encode": false,
      "key": "password",
      "value": "123abcxyz",
      "confidential": true
    },
    {
      "header": false,
      "encode": false,
      "key": "deliveryReport",
      "value": "yes",
      "confidential": false
    }
  ],
  "isDefault": false
}
```

在通用的http网关中，可以添加任意数量的参数。



Table: Generic SMS gateway parameters

| Parameter | 类型 | 描述 |
|---|---|---|
| 名称 | 串 | name of the gateway |
| configurationTemplate | 串 | Configuration template which get populated with parameter values. For example configuration template given above will be populated like this { "to": "+27001234567", "body": "Hello World!"} |
| useGet | Boolean | Http POST nethod will be used by default. In order to change it and Http GET, user can set useGet flag to true. |
| contentType | 串 | Content type specify what type of data is being sent. Supported types are APPLICATION_JSON, APPLICATION_XML, FORM_URL_ENCODED, TEXT_PLAIN |
| urlTemplate | 串 | Url template |
| header | Boolean | If parameter needs to be sent in Http headers |
| encode | Boolean | If parameter needs to be encoded |
| key | 串 | parameter key |
| 价值 | 串 | parameter value |
| confidential | Boolean | If parameter is confidential. This parameter will not be exposed through API |
| sendUrlParameters | Boolean | If this flag is checked then urlTemplate can be appended with query parameters. This is usefull if gateway API only support HTTP GET. Sample urlTemplate looks like this `"urlTemplate":"https://samplegateway.com/messages?apiKey={apiKey}&to={recipients},content={text},deliveryreport={dp}"` |

如果配置保存成功则返回 HTTP.OK 否则 *Error*

## 短信命令 { #webapi_sms_commands } 

SMS 命令用于通过 SMS 收集数据。这些命令
属于特定的解析器类型。每个解析器都有不同的功能。

可以使用GET检索命令列表。

    GET /api/smsCommands

可以使用GET检索一个特定的命令。

    GET /api/smsCommands/uid

可以使用PUT更新一个特定的命令。

    PUT /api/smsCommands/uid

可以使用POST创建命令。

    POST / api / smsCommands

可以使用DELETE删除一个特定命令。

    删除/ api / smsCommands / uid

#### 短信命令类型 { #sms-command-types } 

| 类型 | 用法 |
|---|---|
|KEY_VALUE_PARSER | 用于汇总数据收集。|
|ALERT_PARSER | 发送警报消息。|
|未注册_解析器 | 用于疾病监测病例报告。|
|TRACKED_ENTITY_REGISTRATION_PARSER | 用于跟踪器实体注册。|
|PROGRAM_STAGE_DATAENTRY_PARSER | 程序阶段的数据收集。 （根据phoneNumner确定TEI）|
|EVENT_REGISTRATION_PARSER | 单个事件的注册。这用于事件程序。|

#### Android的SMS命令类型 { #sms-command-types-for-android } 

当互联网不可用时，Android应用程序可以使用这些命令类型通过SMS提交数据。 SMS由Android应用程序组成。

| 类型 | 用法 |
|---|---|
|AGGREGATE_DATASET | 用于汇总数据收集。|
|注册 | 用于跟踪器实体注册。|
|TRACKER_EVENT | 跟踪器程序的事件注册。|
|SIMPLE_EVENT | 活动节目的活动注册。|
|关系 | 建立关系。|
|删除 | 删除事件。|



# 用户数 { #users } 

## 用户数 { #webapi_users } 

本节介绍用户资源方法。

    /api/users

### 用户查询 { #webapi_users_query } 

*users* 资源提供了额外的查询参数
标准参数（例如分页）。在用户处查询用户
资源可以使用以下参数。

Table: User query parameters

| Parameter | 类型 | 描述 |
|---|---|---|
| query | 文本 | Query value for first name, surname, username and email, case in-sensitive. |
| phoneNumber | 文本 | Query for phone number. |
| canManage | false &#124; true | Filter on whether the current user can manage the returned users through the managed user group relationships. |
| authSubset | false &#124; true | Filter on whether the returned users have a subset of the authorities of the current user. |
| lastLogin | 日期 | Filter on users who have logged in later than the given date. |
| inactiveMonths | 数 | Filter on users who have not logged in for the given number of months. |
| inactiveSince | 日期 | Filter on users who have not logged in later than the given date. |
| selfRegistered | false &#124; true | Filter on users who have self-registered their user account. |
| invitationStatus | none &#124; all &#124; expired | Filter on user invitations, including all or expired invitations. |
| 欧 | 识别码 | Filter on users who are associated with the organisation unit with the given identifier. |
| userOrgUnits | false &#124; true | Filter on users who are associated with the organisation units linked to the currently logged in user. |
| includeChildren | false &#124; true | Includes users from all children organisation units of the ou parameter. |
| page | 数 | The page number. |
| pageSize | 数 | The page size. |
| orgUnitBoundary | data_capture &#124; data_output &#124; tei_search | Restrict search to users having a common organisation unit with the current user for the given boundary        |

以“konan”作为名字或姓氏的最多 10 个用户的查询（案例
不敏感）与当前相比拥有部分权限的人
用户：

    /api/users?query=konan&authSubset=true&pageSize=10

To retrieve all user accounts which were initially self-registered:

```
/api/users?selfRegistered=true
```

#### User query by identifier { #user-query-by-identifier } 

You can retrieve full information about a user with a particular identifier with the following syntax.

```
/api/users/{id}
```

An example for a particular identifier looks like this:

```
/api/users/OYLGMiazHtW
```

### 用户查找 { #user-lookup } 

用户查找 API 提供了一个端点来检索用户
响应包含最少的信息集。它不需要一个
特定权限，适合客户端查询信息
例如用户名和姓氏，不会暴露潜在的敏感信息
用户信息。

```
/ api / userLookup
```

用户查找端点有两种方法。

#### 通过标识符查找用户 { #user-lookup-by-identifier } 

您可以使用以下API请求按标识符进行用户查找。

```
GET / api / userLookup / {id}
```

用户 `id` 将与以下用户属性匹配
按照指定的顺序：

- 用户标识
- 用户名
- 用户名

请求示例如下所示：

```
/ api / userLookup / QqvaU7JjkUV
```

该响应将包含有关用户的最少信息。

```json
{
  "id": "QqvaU7JjkUV",
  "username": "nkono",
  "firstName": "Thomas",
  "surname": "Nkono",
  "displayName": "Thomas Nkono"
}
```

#### 用户查询 { #user-lookup-query } 

您可以使用以下API请求向用户查询。

```
GET / api / userLookup？query = {string}
```

`query` 请求参数是强制性的。查询`string`将被匹配
针对以下用户属性：

- 名字
- 姓
- 电子邮件
- 用户名

In addition to the `query` parameter the search can be restricted by the
`orgUnitBoundary` parameter as described in table of parameters for users above.

请求示例如下所示：

```
/ api / userLookup？query = John
```

响应将包含有关与请求匹配的用户的信息。

```json
{
  "users": [
    {
      "id": "DXyJmlo9rge",
      "username": "jbarnes",
      "firstName": "John",
      "surname": "Barnes",
      "displayName": "John Barnes"
    },
    {
      "id": "N3PZBUlN8vq",
      "username": "jkamara",
      "firstName": "John",
      "surname": "Kamara",
      "displayName": "John Kamara"
    }
  ]
}
```

### 用户帐户创建和更新 { #webapi_users_create_update } 

通过 API 支持创建和更新用户。一个基本的
创建用户的有效负载类似于以下示例。注意密码
将以纯文本形式发送，因此请记住为网络传输启用 SSL/HTTPS。

```json
{
  "id": "Mj8balLULKp",
  "firstName": "John",
  "surname": "Doe",
  "email": "johndoe@mail.com",
  "userCredentials": {
    "id": "lWCkJ4etppc",
    "userInfo": {
    "id": "Mj8balLULKp"
  },
  "username": "johndoe123",
  "password": "Your-password-123",
  "skype": "john.doe",
  "telegram": "joh.doe",
  "whatsApp": "+1-541-754-3010",
  "facebookMessenger": "john.doe",
  "avatar": {
    "id": "<fileResource id>"
  },
  "userRoles": [
    {
      "id": "Ufph3mGRmMo"
    }
  ]
  },
  "organisationUnits": [
    {
      "id": "Rp268JB6Ne4"
    }
  ],
  "userGroups": [
    {
      "id": "wl5cDMuUhmF"
    }
  ]
}
```

```bash
curl -X POST -d @u.json "http://server/api/33/users" -u user:pass 
  -H "Content-Type: application/json" 
```

在用户创建负载中，仅在导入时支持用户组
或一次*发布*一个用户。如果您尝试创建多个
user 在指定用户组时，您将不会收到错误，并且
将创建用户，但不会分配用户组。这是设计使然
并且由于用户和用户之间的多对多关系而受到限制
用户组，其中用户组是关系的所有者。更新
或者创建多个用户和他们的用户组，考虑一个程序来*POST*
一次一个，或 *POST* 所有用户，然后执行另一个操作
在指定新用户的标识符的同时更新他们的用户组。

When creating a user the payload may also contain user settings.
These are added as `settings` object to the root object.
Each key-value pair becomes a member in the `settings` object, for example:
```json
{
    "id": "Mj8balLULKp",
    "firstName": "John",
    "surname": "Doe",
    "settings": {
        "keyUiLocale": "de"
    },
    //...
}
```

创建用户后，*Location* 标头与
新生成的 ID（你也可以使用 `/api/system/id` 提供你自己的
端点）。然后可以使用相同的有效负载进行更新，但请记住
然后使用 *PUT* 而不是 *POST* 并且端点现在是`/api/users/ID`。

```bash
curl -X PUT -d @u.json "http://server/api/33/users/ID" -u user:pass 
  -H "Content-Type: application/json" 
```

有关可用的全部有效负载的更多信息，请参见`/ api / schemas / user`。

有关上传和检索用户头像的更多信息，请参阅
`/fileResources` 端点。

### 用户帐户邀请 { #webapi_user_invitations } 

The Web API supports inviting people to create user accounts through the
`invite` resource. To create an invitation you should POST a user in XML
or JSON format to the invite resource. A specific username can be forced
by defining the username in the posted entity. By omitting the username,
the person will be able to specify it herself. The system will send out
an invitation through email. This requires that email settings have been
properly configured.

邀请资源可用于安全地
允许人们在其他人不知道密码的情况下创建帐户
或通过以纯文本形式传输密码。用于的有效载荷
邀请与创建用户相同。 JSON 格式的示例负载
看起来像这样：

```json
{
  "firstName": "John",
  "surname": "Doe",
  "email": "johndoe@mail.com",
  "userCredentials": {
    "username": "johndoe",
    "userRoles": [{
      "id": "Euq3XfEIEbx"
    }]
  },
  "organisationUnits": [ {
    "id": "ImspTQPwCqd"
  } ],
  "userGroups": [ {
    "id": "vAvEltyXGbD"
  }]
}
```

用户邀请实体可以这样发布：

```bash
curl -d @invite.json "localhost/api/33/users/invite" -u admin:district
  -H "Content-Type:application/json" 
```

要同时向多个用户发送邀请，您必须使用
格式略有不同。对于 JSON：

```json
{
  "users": [ {
    "firstName": "John",
    "surname": "Doe",
    "email": "johndoe@mail.com",
    "userCredentials": {
      "username": "johndoe",
      "userRoles": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "organisationUnits": [ {
      "id": "ImspTQPwCqd"
      } ]
    }, {
    "firstName": "Tom",
    "surname": "Johnson",
    "email": "tomj@mail.com",
    "userCredentials": {
      "userRoles": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "organisationUnits": [ {
      "id": "ImspTQPwCqd"
      } ]
    }
  ]
}
```

要创建多个邀请，您可以将有效负载发布到
api/users/invites 资源如下：

```bash
curl -d @invites.json "localhost/api/33/users/invites" -u admin:district
  -H "Content-Type:application/json"
```

发送用户账号邀请有一定的要求
出去：

  - 电子邮件SMTP服务器必须在服务器上正确配置。

  - 被邀请的用户必须指定了有效的电子邮件。

  - 如果指定了用户名，则它不得已被其他人使用
    现有用户。

如果不满足这些要求中的任何一个，邀请资源将返回
带有 *409 Conflict* 状态代码和描述性消息。


### User login (Experimental) { #webapi_user_login }

This endpoint is not meant for external use, unless you are implementing a custom login app, which you probably should not do, unless you have a very good reason.

A user can log in and get a session cookie with the following example:  
`POST` `/api/auth/login`  
with `JSON` body:

```json
{
    "username": "username",
    "password": "password",
    "twoFactorCode": "two_factor_code"
}

```
Successful response looks like:  

```json
{
    "loginStatus": "SUCCESS",
    "redirectUrl": "/dhis-web-dashboard/"
}
```


### User account confirm invite (Experimental) { #webapi_user_confirm_invite }

> **Important**  
> Before confirming an invitation, an admin user should have set up the User and sent an invitation link. That prerequisite also adds some required data in the `userinfo` database table (`idToken`, `restoreToken`, `restoreExpiry`) for that user, in order to complete the invite.

A user can confirm an invitation through the following endpoint:  
`POST` `/api/auth/invite`  
with `JSON` body:

```json
{
    "username": "TestUser",
    "firstName": "Test",
    "surname": "User",
    "password": "Test123!",
    "email": "test@test.com",
    "phoneNumber": "123456789",
    "g-recaptcha-response": "recaptchaResponse",
    "token": "aWRUb2tlbjpJRHJlc3RvcmVUb2tlbg=="
}
```

> **Note**  
> The `g-recaptcha-response` value would be populated through the use of the core Login App UI normally.  
> The `token` field expects a Base64-encoded value. In this example, decoded, it's `idToken:IDrestoreToken`. This would be sent by email to the invited user (it is actually created internally (and populated in the database) during the `/api/users/invite` operation).

Successful response looks like:  

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "message": "Account updated"
}
```

### User account registration (Experimental) { #webapi_user_registration }
A user can register directly through the following endpoint:  
`POST` `/api/auth/registration` with `JSON` body:  

```json
{
    "username": "testSelfReg",
    "firstName": "test",
    "surname": "selfReg",
    "password": "P@ssword123",
    "email": "test@test.com",
    "phoneNumber": "12345oooo",
    "g-recaptcha-response": "recap response"
}

```

A successful response looks like:  

```json
{
    "httpStatus": "Created",
    "httpStatusCode": 201,
    "status": "OK",
    "message": "Account created"
}
```

### User forgot password (Experimental) { #webapi_user_forgot_password }

This endpoint is used to trigger the forgotten password flow. It can be triggered by supplying the username or email of the user whose password needs resetting.  
`POST` `/api/auth/forgotPassword` with `JSON` body:  

```json
{
    "emailOrUsername": "testUsername1"
}
```

A successful response returns an empty `200 OK`. This should trigger an email to be sent to the user which allows them to reset their password.

### User password reset (Experimental) { #webapi_user_password_reset }

Once a user has received an email with a link to reset their password, it will contain a token which can be used to reset their password.  
`POST` `/api/auth/passwordReset` with `JSON` body:  

```json
{
    "newPassword": "ChangeMe123!",
    "resetToken": "token-value-from-email-link"
}
```

A successful response returns an empty `200 OK`. The user should now be able to log in using the new password.


### 用户复制 { #webapi_user_replication }

要复制用户，您可以使用 *replica* 资源。复制一个
用户在调试或重现报告的问题时很有用
特定用户。您需要提供新的用户名和密码
您稍后将用于验证的复制用户。请注意，您
需要 ALL 权限才能执行此操作。要复制用户，您
可以发布如下所示的 JSON 有效负载：

```json
{
  "username": "user_replica",
  "password": "SecretPassword"
}
```

此有效负载可以发布到您提供的副本资源
要在 URL 中复制的用户标识符：

    / api / 33 / users / <uid> /副本

使用curl复制用户的示例如下所示：

```bash
curl -d @replica.json "localhost/api/33/users/N3PZBUlN8vq/replica"
  -H "Content-Type:application/json" -u admin:district
```

### Reset user password { #webapi_user_reset }

User administrators (with appropriate rights) can reset another user's account
by triggering password recovery. Once triggered an email is sent to the user
containing a recovery link. Users following the link get to a form which allows
to set a new password.

To trigger this workflow for user `tH7WIiIJ0O3` use:

    POST /api/37/users/tH7WIiIJ0O3/reset

### 禁用和启用用户帐户 { #webapi_user_disable } 

可以将用户帐户标记为禁用。
禁用的用户无法再登录。

要将具有UID`tH7WIiIJ0O3`的用户标记为已禁用（需要具有适当权限的用户）：

    POST / api / 36 / users / tH7WIiIJ0O3 / disabled

要再次启用禁用的用户，请相应地使用（要求具有适当权限的用户）：

    POST / api / 36 / users / tH7WIiIJ0O3 / enabled

### 用户有效期 { #webapi_user_expiration } 

可以为用户帐户设置到期日期。
它标记了用户帐户已过期的时间点
并且无法再使用。过期的用户无法再登录。

To update the expiration date of user with UID `tH7WIiIJ0O3` 
and set it to the date `2021-01-01` use (requires user with appropriate rights):

    POST / api / 36 / users / tH7WIiIJ0O3 / expired？date = 2021-01-01

取消设置到期日期，以使帐户永不过期
相应地使用（需要具有适当权限的用户）：

    POST / api / 36 / users / tH7WIiIJ0O3 /未过期

### 用户数据批准工作流程 { #user-data-approval-workflows } 

要查看用户可以访问哪些数据批准工作流和级别，
您可以按以下方式使用* dataApprovalWorkflows *资源：

```
GET / api / users / {id} / dataApprovalWorkflows
```

### Switching between user accounts connected to the same identity provider account { #switching-between-user-accounts-connected-to-the-same-identity-provider-account } 

If [linked accounts are enabled in dhis.conf](../../../manage/performing-system-administration/dhis-core-version-master/installation.html#connecting-a-single-identity-provider-account-to-multiple-dhis2-accounts) and a user has logged in via OIDC, then it is possible for the user to switch between DHIS2 accounts that are linked to the same identity provider account using this API call:

```
GET /dhis-web-commons-security/logout.action?current={current_username}&switch={username_to_switch_to}
```

This has the effect of signing out the current user and signing in the new user. It looks seamless as it is happening, except that the new user ends up on the default page of the DHIS2 instance.

Note that this API call will likely change in the future, but its general function will remain the same.

To see a list of users that can be switched to, use this API call:

```
GET /api/account/linkedAccounts
```

## 当前用户信息 { #webapi_current_user_information } 

为了获取有关当前已验证用户的信息和
它与其他资源的关联，您可以使用 *me* 资源
（您也可以通过其旧名称 *currentUser* 来引用它）。目前
用户相关资源为您提供有用的信息
构建客户端，例如用于数据输入和用户管理。这
下面描述了这些资源及其用途。

提供有关您当前登录的用户的基本信息
in as，包括用户名、用户凭据、分配的组织
单位：

    / api / me

提供有关当前未读消息和解释的信息：

    / api / me / dashboard

为了更改密码，此端点可用于验证
新输入的密码。密码验证将基于
系统中配置的 PasswordValidationRules。这个端点支持
POST 和密码字符串应在 POST 正文中发送。

    / api / me / validatePassword

更改密码时，此端点（支持 POST）可用于
验证旧密码。密码字符串应在 POST 正文中发送。

    / api / me / verifyPassword

返回授予当前用户的权限集：

    / api / me / authorization

返回 true 或 false，表示当前用户是否已被
授予给定的`<auth>`授权：

    / api / me / authorization / <auth>

给出与当前用户相关的数据批准级别：

    / api / me / dataApprovalLevels

提供当前用户可以访问的数据批准工作流。
对于每个工作流程，显示用户可能看到的数据批准级别，以及
他们在每个级别上具有什么权限：

    / api / me / dataApprovalWorkflows


# 设置和配置 { #settings-and-configuration } 

## 系统设置 { #webapi_system_settings } 

您可以通过与
*系统设置*资源。系统设置是一个简单的键值对，
其中键和值都是纯文本字符串。保存或
更新系统设置，您可以向以下 URL 发出 *POST* 请求：

    / api / 33 / systemSettings / my-key？value = my-val

或者，您可以将设置值作为请求正文提交，
其中内容类型设置为“文本/纯文本”。例如，您可以使用
像这样卷曲：

```bash
curl "play.dhis2.org/demo/api/33/systemSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

要批量设置系统设置，您可以发送带有
使用 POST 请求的每个系统设置键值对的属性和值：

```json
{
  "keyApplicationNotification": "Welcome",
  "keyApplicationIntro": "DHIS2",
  "keyApplicationFooter": "Read more at dhis2.org"
}
```

可以通过指定语言环境来设置可翻译设置键的翻译
可以指定的查询参数和翻译值
作为查询参数或与正文有效负载一起使用。查看示例网址：

    / api / 33 / systemSettings / <my-key>？locale = <my-locale>＆value = <my-translated-value>

您应该将 my-key 替换为您的真实密钥，并将 my-val 替换为您的真实密钥
价值。检索给定键的值（以 JSON 或纯文本形式）
您可以向以下 URL 发出 *GET* 请求：

    / api / 33 / systemSettings / my-key

或者，您可以将键指定为查询参数：

    / api / 33 / systemSettings？key =我的密钥

If a key is not found or marked confidential then a `404` response will be returned like so:

```json
{
    "httpStatus": "Not Found",
    "httpStatusCode": 404,
    "status": "ERROR",
    "message": "Setting does not exist or is marked as confidential",
    "errorCode": "E1005"
}
```

您可以通过重复键以 JSON 形式检索特定的系统设置
查询参数：

```bash
curl "play.dhis2.org/demo/api/33/systemSettings?key=keyApplicationNotification&key=keyApplicationIntro"
  -u admin:district
```

您可以使用GET请求检索所有系统设置：

    / api / 33 / systemSettings

要检索给定可翻译键的特定翻译，您可以指定
作为查询参数的语言环境：

    / api / 33 / systemSettings / <my-key>？locale = <my-locale>

如果存在，则返回给定语言环境的翻译。否则默认
值被返回。如果没有为可翻译键指定语言环境，则用户默认
UI 语言环境用于获取正确的翻译。如果给定的翻译不是
现在，再次返回默认值。

可翻译键的优先级如下：

    指定的区域设置>用户的默认UI区域设置> defaut值

要删除系统设置，您可以向 URL 发出 *DELETE* 请求
类似于上面用于检索的那个。如果一个可翻译的键是
使用，所有现有的翻译也将被删除。

仅删除可翻译键的特定翻译，相同的 URL
至于添加翻译应该使用，空值应该是
假如：

    / api / 33 / systemSettings / <my-key>？locale = <my-locale>＆value =

可用的系统设置在下面列出。

Table: System settings

| 键 | 描述 | Translatable |
|---|---|---|
| keyUiLocale | Locale for the user interface | 不 |
| keyDbLocale | Locale for the database | 不 |
| keyAnalysisDisplayProperty | The property to display in analysis. Default: "name" | 不 |
| keyAnalysisDigitGroupSeparator | The separator used to separate digit groups | 不 |
| keyCurrentDomainType | Not yet in use | 不 |
| keyTrackerDashboardLayout | Used by tracker capture | 不 |
| applicationTitle | The application title. Default: "DHIS2" | 是的 |
| keyApplicationIntro | The application introduction | 是的 |
| keyApplicationNotification | Application notification | 是的 |
| keyApplicationFooter | Application left footer | 是的 |
| keyApplicationRightFooter | Application right footer | 是的 |
| keyFlag | Application flag | 不 |
| keyFlagImage | Flag used in dashboard menu | 不 |
| startModule | The startpage of the application. Default: "dhis-web-dashboard-integration" | 不 |
| startModuleEnableLightweight | The starting page app to render a light-weight landing page. Default: "false" | 不 |
| factorDeviation | Data analysis standard deviation factor. Default: "2d" | 不 |
| keyEmailHostName | Email server hostname | 不 |
| keyEmailPort | Email server port | 不 |
| keyEmailTls | Use TLS. Default: "true" | 不 |
| keyEmailSender | Email sender | 不 |
| keyEmailUsername | Email server username | 不 |
| keyEmailPassword | Email server password | 不 |
| minPasswordLength | Minimum length of password | 不 |
| maxPasswordLength | Maximum length of password | 不 |
| keySmsSetting | SMS configuration | 不 |
| keyCacheStrategy | Cache strategy. Default: "CACHE_6AM_TOMORROW" | 不 |
| keyCacheability | PUBLIC or PRIVATE. Determines if proxy servers are allowed to cache data or not. | 不 |
| phoneNumberAreaCode | Phonenumber area code | 不 |
| multiOrganisationUnitForms | Enable multi-organisation unit forms. Default: "false" | 不 |
| keyConfig || 不 |
| keyAccountRecovery | Enable user account recovery. Default: "false" | 不 |
| keyLockMultipleFailedLogins | Enable locking access after multiple failed logins | 不 |
| googleAnalyticsUA | Google Analytic UA key for tracking site-usage | 不 |
| credentialsExpires | Require user account password change. Default: "0" (Never) | 不 |
| credentialsExpiryAlert | Enable alert when credentials are close to expiration date | 不 |
| credentialsExpiresReminderInDays | Number of days the credential expiry alert should be send in advance of the actual expiry. Default: 28 | 不 |
| accountExpiryAlert | Send an alert email to users whose account is about to expire due to expiry date being set. Default: "false" | 不 |
| accountExpiresInDays | Number of days the account expiry alert should be send in advance of the actual expiry. Default: 7 | 不 |
| keySelfRegistrationNoRecaptcha | Do not require recaptcha for self registration. Default: "false" | 不 |
| recaptchaSecret | Google API recaptcha secret. Default: dhis2 play instance API secret, but this will only works on you local instance and not in production. | 不 |
| recaptchaSite | Google API recaptcha site. Default: dhis2 play instance API site, but this will only works on you local instance and not in production. | 不 |
| keyCanGrantOwnUserAuthorityGroups | Allow users to grant own user roles. Default: "false" | 不 |
| keySqlViewMaxLimit | Max limit for SQL view | 不 |
| keyRespectMetaDataStartEndDatesInAnalyticsTableExport | When "true", analytics will skip data not within category option's start and end dates. Default: "false" | 不 |
| keySkipDataTypeValidationInAnalyticsTableExport | Skips data type validation in analytics table export | 不 |
| keyCustomLoginPageLogo | Logo for custom login page | 不 |
| keyCustomTopMenuLogo | Logo for custom top menu | 不 |
| keyCacheAnalyticsDataYearThreshold | Analytics data older than this value (in years) will always be cached. "0" disabled this setting. Default: 0 | 不 |
| analyticsFinancialYearStart | Set financial year start. Default: October | 不 |
| keyIgnoreAnalyticsApprovalYearThreshold | "0" check approval for all data. "-1" disable approval checking. "1" or higher checks approval for all data that is newer than "1" year. | 不 |
| keyAnalyticsMaxLimit | Maximum number of analytics records. Default: "50000" | 不 |
| KeyTrackedEntityMaxLimit | Maximum number of tracked entities. Default: "50000" | 不 |
| keyAnalyticsMaintenanceMode | Put analytics in maintenance mode. Default: "false" | 不 |
| keyAnalyticsPeriodYearsOffset | Defines the years' offset to be used in the analytics export process. If the year of a respective date is out of the offset the system sends back a warning message during the process. At this point, the period generation step is skipped. ie.: suppose the system user sets the offset value to `5`, and we are in the year 2023. It means that analytics will accept exporting dates from 2018 (inclusive) to 2028 (inclusive). Which translates to: [2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028]. NOTE: The offset will have a significant influence on resource usage. Higher values will trigger higher usage of memory RAM/HEAP and CPU. Setting negative numbers to this key will disable any kind of validation (which means no warnings) and the internal range of years will be used (1970 to current year plus 10) Default: 22 | 不 |
| keyDatabaseServerCpus | Number of database server CPUs. Default: "0" (Automatic) | 不 |
| keyLastSuccessfulAnalyticsTablesRuntime | Keeps timestamp of last successful analytics tables run | 不 |
| keyLastSuccessfulLatestAnalyticsPartitionRuntime | Keeps timestamp of last successful latest analytics partition run | 不 |
| keyLastMonitoringRun | Keeps timestamp of last monitoring run | 不 |
| keyLastSuccessfulDataSynch | Keeps timestamp of last successful data values synchronization | 不 |
| keyLastSuccessfulEventsDataSynch | Keeps timestamp of last successful Event programs data synchronization | 不 |
| keyLastCompleteDataSetRegistrationSyncSuccess | Keeps timestamp of last successful completeness synchronization | 不 |
| syncSkipSyncForDataChangedBefore | Specifies timestamp used to skip synchronization of all the data changed before this point in time | 不 |
| keyLastSuccessfulAnalyticsTablesUpdate | Keeps timestamp of last successful analytics tables update | 不 |
| keyLastSuccessfulLatestAnalyticsPartitionUpdate | Keeps timestamp of last successful latest analytics partition update | 不 |
| keyLastSuccessfulResourceTablesUpdate | Keeps timestamp of last successful resource tables update | 不 |
| keyLastSuccessfulSystemMonitoringPush | Keeps timestamp of last successful system monitoring push | 不 |
| keyLastSuccessfulMonitoring | Keeps timestamp of last successful monitoring | 不 |
| keyNextAnalyticsTableUpdate | Keeps timestamp of next analytics table update | 不 |
| helpPageLink | Link to help page. Default: "[https://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html](http://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html) | 不 |
| keyAcceptanceRequiredForApproval | Acceptance required before approval. Default: "false" | 不 |
| keySystemNotificationsEmail | Where to email system notifications | 不 |
| keyAnalysisRelativePeriod | Default relative period for analysis. Default: "LAST_12_MONTHS" | 不 |
| keyRequireAddToView | Require authority to add to view object lists. Default: "false" | 不 |
| keyAllowObjectAssignment | Allow assigning object to related objects during add or update. Default: "false" | 不 |
| keyUseCustomLogoFront | Enables the usage of a custom logo on the front page. Default: "false" | 不 |
| keyUseCustomLogoBanner | Enables the usage of a custom banner on the website. Default: "false" | 不 |
| keyDataImportStrictPeriods || 不 |
| keyDataImportStrictPeriods | Require periods to match period type of data set. Default: "false" | 不 |
| keyDataImportStrictDataElements | Require data elements to be part of data set. Default: "false" | 不 |
| keyDataImportStrictCategoryOptionCombos | Require category option combos to match category combo of data element. Default: "false" | 不 |
| keyDataImportStrictOrganisationUnits | Require organisation units to match assignment of data set. Default: "false" | 不 |
| keyDataImportStrictAttributeOptionsCombos | Require attribute option combis to match category combo of data set. Default: "false" | 不 |
| keyDataImportStrictDataSetApproval | true: If an already approved dataset exists for a given data value entry is not permitted; false: If a not yet approved dataset exists for a given data value entry is permitted. Default: "true" | 不 |
| keyDataImportStrictDataSetLocking | true: If a dataset exists for which entry expired without lock exception for a given data value entry is not permitted; false: If a dataset exists for which entry is not expired or a lock exception applies for a given data value entry is permitted. Default: "true" | 不 |
| keyDataImportStrictDataSetInputPeriods | true: If a dataset exists for which the input period is closed for a given data value entry is not permitted; false: If a dataset exists for which data the input period is open for a given data value entry is permitted. Default: "true" | 不 |
| keyDataImportRequireCategoryOptionCombo | Require category option combo to be specified. Default: "false" | 不 |
| keyDataImportRequireAttributeOptionCombo | Require attribute option combo to be specified. Default: "false" | 不 |
| keyCustomJs | Custom JavaScript to be used on the website | 不 |
| keyCustomCss | Custom CSS to be used on the website | 不 |
| keyCalendar | The calendar type. Default: "iso8601". | 不 |
| keyDateFormat | The format in which dates should be displayed. Default: "yyyy-MM-dd". | 不 |
| keyStyle | The style used on the DHIS2 webpages. Default: "light_blue/light_blue.css". | 不 |
| keyRemoteInstanceUrl | Url used to connect to remote instance | 不 |
| keyRemoteInstanceUsername | Username used to connect to remote DHIS2 instance | 不 |
| keyRemoteInstancePassword | Password used to connect to remote DHIS2 instance | 不 |
| keyGoogleMapsApiKey | Google Maps API key | 不 |
| keyGoogleCloudApiKey | Google Cloud API key | 不 |
| keyLastMetaDataSyncSuccess | Keeps timestamp of last successful metadata synchronization | 不 |
| keyVersionEnabled | Enables metadata versioning | 不 |
| keyMetadataFailedVersion | Keeps details about failed metadata version sync | 不 |
| keyMetadataLastFailedTime | Keeps timestamp of last metadata synchronization failure | 不 |
| keyLastSuccessfulScheduledProgramNotifications || 不 |
| keyLastSuccessfulScheduledDataSetNotifications || 不 |
| keyRemoteMetadataVersion | Details about metadata version of remote instance | 不 |
| keySystemMetadataVersion | Details about metadata version of the system | 不 |
| keyStopMetadataSync | Flag to stop metadata synchronization | 不 |
| keyFileResourceRetentionStrategy | 确定与已删除或更新的值相关联的文件资源保留的时间长度。NONE，THREE_MONTHS，ONE_YEAR或FOREVER。 | 不 |
| syncMaxRemoteServerAvailabilityCheckAttempts | Specifies how many times the availability of remote server will be checked before synchronization jobs fail. | 不 |
| syncMaxAttempts | Specifies max attempts for synchronization jobs | 不 |
| syncDelayBetweenRemoteServerAvailabilityCheckAttempts | Delay between remote server availability checks | 不 |
| lastSuccessfulDataStatistics | Keeps timestamp of last successful data analytics | 不 |
| keyHideDailyPeriods | Not in use | 不 |
| keyHideWeeklyPeriods || 不 |
| keyHideBiWeeklyPeriods | Boolean flag used to hide/show bi-weekly periods | 不 |
| keyHideMonthlyPeriods || 不 |
| keyHideBiMonthlyPeriods || 不 |
| keyGatherAnalyticalObjectStatisticsInDashboardViews | Whether to gather analytical statistics on objects when they are viewed within a dashboard | 不 |
| keyCountPassiveDashboardViewsInUsageAnalytics | Counts "passive" dashboard views (not selecting a particular dashboard) in usage analytics | 不 |
| keyDashboardContextMenuItemSwitchViewType | Allow users to switch dashboard favorites' view type | 是的 |
| keyDashboardContextMenuItemOpenInRelevantApp | Allow users to open dashboard favorites in relevant apps | 是的 |
| keyDashboardContextMenuItemShowInterpretationsAndDetails | Allow users to show dashboard favorites' interpretations and details | 是的 |
| keyDashboardContextMenuItemViewFullscreen | Allow users to view dashboard favorites in fullscreen | 是的 |
| jobsRescheduleAfterMinutes | If a job is in state `RUNNING` for this amount of minutes or longer without making progress in form of updating its `lastAlive` timestamp the job is considered stale and reset to `SCHEDULED` state | 不 |
| jobsCleanupAfterMinutes | A "run once" job is deleted when this amount of minutes has passed since it finished successful or unsuccessful | 不 |                                                                                                                                                                                                                        
| jobsMaxCronDelayHours | A CRON expression triggered job will only trigger in the window between its target time of the day and this amount of hours later. If it wasn't able to run in that window the execution is skipped and next execution according to the CRON expression is the next target execution | 不 |
| jobsLogDebugBelowSeconds | A job with an execution interval below this number of seconds logs its information on debug rather than info | 不 |
| keyParallelJobsInAnalyticsTableExport | Returns the number of parallel jobs to use for processing analytics tables. It takes priority over "keyDatabaseServerCpus". Default: -1 | 不 |

## 用户设置 { #webapi_user_settings } 

您可以通过与 *userSettings* 交互来操作用户设置
资源。用户设置是一个简单的键值对，其中键
并且值是纯文本字符串。用户设置将链接到
已针对 Web API 请求进行身份验证的用户。返回列表
在所有用户设置中，您可以向以下 URL 发送 *GET* 请求：

    / api / 33 / userSettings

用户未设置的用户设置，将回退到等效的
系统设置。只返回用户明确设置的值，
您可以将 ?useFallback=false 附加到上述 URL，如下所示：

    / api / 33 / userSettings？useFallback = false

要为当前经过身份验证的用户保存或更新设置，您可以
向以下 URL 发出 *POST* 请求：

    / api / 33 / userSettings / my-key？value = my-val

您可以指定要为其显式保存设置的用户
这个语法：

    / api / 33 / userSettings / my-key？user = username＆value = my-val

或者，您可以将设置值作为请求正文提交，
其中内容类型设置为“文本/纯文本”。例如，您可以使用
像这样卷曲：

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

例如，要将当前用户的 UI 语言环境设置为法语，您
可以使用以下命令。

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/keyUiLocale?value=fr" 
  -X POST -u admin:district
```

您应该将 my-key 替换为您的真实密钥，并将 my-val 替换为您的真实密钥
价值。要以纯文本形式检索给定键的值，您可以
对以下 URL 的 *GET* 请求：

    / api / 33 / userSettings / my-key

要删除用户设置，您可以向 URL 发出 *DELETE* 请求
类似于上面用于检索的那个。

可用的系统设置在下面列出。



Table: User settings

| 键 | 选项 | 描述 |
|---|---|---|
| keyStyle | light_blue/light_blue.css &#124; green/green.css &#124; vietnam/vietnam.css | User interface stylesheet. |
| keyMessageEmailNotification | false &#124; true | Whether to send email notifications. |
| keyMessageSmsNotification | false &#124; true | Whether to send SMS notifications. |
| keyUiLocale | Locale value | User interface locale. |
| keyDbLocale | Locale value | Database content locale. |
| keyAnalysisDisplayProperty | name &#124; shortName | Property to display for metadata in analysis apps. |
| keyCurrentDomainType | all &#124; aggregate &#124; tracker | Data element domain type to display in lists. |
| keyAutoSaveCaseEntryForm | false &#124; true | Save case entry forms periodically. |
| keyAutoSaveTrackedEntityForm | false &#124; true | Save person registration forms periodically. |
| keyAutoSaveDataEntryForm | false &#124; true | Save aggregate data entry forms periodically. |
| keyTrackerDashboardLayout | false &#124; true | Tracker dasboard layout. |

## 组态 { #webapi_configuration } 

要访问配置，您可以与 *configuration* 交互
资源。您可以通过 *Accept* 标头获取 XML 和 JSON 响应
或使用 .json 或 .xml 扩展名。你可以*GET*所有属性
配置来自：

    / api / 33 /配置

您可以将 *GET* 和 *POST* 请求发送到以下特定
资源：

    GET /api/33/configuration/systemId

    GET POST DELETE /api/configuration/feedbackRecipients

    GET POST DELETE /api/configuration/offlineOrganisationUnitLevel

    GET POST /api/configuration/infrastructuralDataElements

    GET POST /api/configuration/infrastructuralIndicators

    GET POST /api/configuration/infrastructuralPeriodType

    GET POST DELETE /api/configuration/selfRegistrationRole

    GET POST DELETE /api/configuration/selfRegistrationOrgUnit

    GET POST /api/facilityOrgUnitGroupSet

    GET POST /api/facilityOrgUnitLevel

For the CORS allowlist configuration you can make a POST request with an
array of URLs to allowlist as payload using "application/json" as
content-type, for instance:

```json
["www.google.com", "www.dhis2.org", "www.who.int"]
```

    GET POST /api/33/configuration/corsAllowlist

对于 POST 请求，配置值应作为请求发送
有效载荷为文本。下表显示了适当的配置
每个属性的值。



Table: Configuration values

| Configuration property | 值 |
|---|---|
| feedbackRecipients | User group ID |
| offlineOrganisationUnitLevel | Organisation unit level ID |
| infrastructuralDataElements | Data element group ID |
| infrastructuralIndicators | Indicator group ID |
| infrastructuralPeriodType | Period type name (e.g. "Monthly") |
| selfRegistrationRole | User role ID |
| selfRegistrationOrgUnit | Organisation unit ID |
| smtpPassword | SMTP email server password |
| remoteServerUrl | URL to remote server |
| remoteServerUsername | Username for remote server authentication |
| remoteServerPassword | Password for remote server authentication |
| corsAllowlist | JSON list of URLs |

例如，要设置反馈接收者用户组，您可以调用
以下 curl 命令：

```bash
curl "localhost/api/33/configuration/feedbackRecipients" -d "wl5cDMuUhmF"
  -H "Content-Type:text/plain"-u admin:district
```

## 只读配置 { #webapi_readonly_configuration_interface } 

要访问所有配置设置和属性，您可以使用只读配置端点。这将提供对 *UserSettings、SystemSettings 和 DHIS2 服务器配置*的只读访问权限。您可以通过 *Accept* 标头获得 XML 和 JSON 响应。您可以*获取*所有设置：

    / api / 33 / configuration / settings

您可以根据设置类型获得过滤设置：

    GET / api / 33 / configuration / settings / filter？type = USER_SETTING

    GET / api / 33 / configuration / settings / filter？type = CONFIGURATION

可以提供一种以上的类型：

    GET /api/33/configuration/settings/filter?type=USER_SETTING&type=SYSTEM_SETTING



Table: SettingType values

| 值 | 描述 |
|---|---|
| 用户_设置 | To get user settings |
| SYSTEM_SETTING | To get system settings |
| CONFIGURATION | To get DHIS server settings |

> **注意**
>
>将在输出中提供机密字段，但没有值。

## 代币 { #webapi_tokens } 

*tokens* 资源提供对各种服务的访问令牌。

### Google服务帐号 { #webapi_tokens_google_service_account } 

您可以使用以下命令检索 Google 服务帐户 OAuth 2.0 访问令牌
对以下资源的 GET 请求。

    GET /api/tokens/google

令牌将在一定时间内有效，之后
必须从此资源请求另一个令牌。响应
包含匹配令牌到期的缓存控制标头。这
响应将包含以下 JSON 格式的属性。



Table: Token response

| Property | 描述 |
|---|---|
| access_token | The OAuth 2.0 access token to be used when authentication against Google services. |
| expires_in | The number of seconds until the access token expires, typically 3600 seconds (1 hour). |
| client_id | The Google service account client id. |

假定已为DHIS2设置并配置了Google服务帐户。请查阅安装指南以获取更多信息。

## 静态内容 { #webapi_static_content } 

*staticContent* 资源允许您上传和检索自定义
DHIS2 中使用的徽标。该资源允许用户上传带有
关联的密钥，稍后可以使用密钥检索。只有 PNG
文件受支持，只能上传到`logo_banner` 和
`logo_front` 键。

    / api / 33 / staticContent



Table: Static content keys

| 键 | 描述 |
|---|---|
| logo_banner | Logo in the application top menu on the left side. |
| logo_front | Logo on the login-page above the login form. |

要上传文件，请将带有 *POST* 请求的文件发送至：

    POST / api / 33 / staticContent / <key>

请求将logo.png上传到`logo_front`键的示例：

```bash
curl -F "file=@logo.png;type=image/png" "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -X POST -H "Content-Type: multipart/form-data" -u admin:district
```

使用相同的密钥上传多个文件将覆盖现有的
文件。这样，检索任何给定键的文件只会返回
最新上传的文件。

要检索徽标，您可以*获取*以下内容：

    GET /api/33/staticContent/<key>

Example of requests to retrieve the file stored for `logo_front`:

* 将“Accept: text/html”添加到 HTTP 标头。*__ 在这种情况下，如果未定义任何内容，端点将返回默认图像。找到自定义或默认图像时将返回图像流。

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front" 
  -H "Accept: text/html" -L -u admin:district
```

* 将“Accept: application/json”添加到 HTTP 标头。*__ 设置此参数后，如果未找到自定义徽标，端点将永远不会返回默认图像。相反，将返回一条错误消息。找到自定义图像后，此端点将返回一个 JSON 响应，其中包含相应图像的路径/URL。

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front" 
  -H "Accept: application/json" -L -u admin:district
```

成功和错误消息将如下所示：

```json
{
  "images": {
    "png": "http://localhost:8080/dhis/api/staticContent/logo_front"
  }
}
```

```json
{
  "httpStatus": "Not Found",
  "httpStatusCode": 404,
  "status": "ERROR",
  "message": "No custom file found."
}
```

要使用自定义标志，您需要启用相应的系统
通过将其设置为 *true* 来设置。如果相应的设置为false，
将提供默认徽标。

## 用户界面定制 { #webapi_ui_customization } 

要自定义 DHIS2 应用程序的 UI，您可以插入自定义
JavaScript 和 CSS 样式通过 *files* 资源。

```
POST删除后/ api / 33 / files / script
POST GET DELETE / api / 33 / files / style
```

通过此资源插入的 JavaScript 和 CSS 内容将由
DHIS2 网络应用程序。这在某些情况下特别有用：

  - 覆盖 DHIS2 应用程序的 CSS 样式，例如
    登录页面或主页。

  - 定义几个自定义的通用 JavaScript 函数
    数据输入表单和基于 HTML 的报告。

  - 包括用于自定义数据输入表单的 CSS 样式和
    基于 HTML 的报告。

## Login App customization { #login_app_customization }

The Settings App allows users to define a variety of elements (text, logo, flag) that can be used to customize the login page of DHIS2. Additionally, it is possible to choose between two preconfigured layouts (the default and a sidebar layout).

If needed, the login app's styling and layout can be further customized by uploading an HTML template (also definable in the settings app). This HTML template replaces certain elements (based on ID); the reserved IDs are listed in the table below. In this way, it is possible to combine custom styling (using css) and custom layout (using HTML) to change the look of the login app. The custom template does not support custom scripts, and script tags will be removed from any uploaded template.

To create a custom template, it is recommended to start with one of the existing templates (these are available for download from within the login app at the extension dhis-web-login/#download).

ID | Replaced by |
|---|---|
| **login-box** | The main login dialog, which prompts the user to enter their username/password. **This must be included for the login app to work as intended.**  |
| **application-title** | Text for the application title.  |
| **application-introduction** | Text for the application introduction. |
| **flag** | The selected flag. |
| **logo** | The logo (DHIS2 logo is used if custom logo is not defined). |
| **powered-by** | A link to DHIS2.org. |
| **application-left-footer** | Text for the left-side footer. |
| **application-right-footer** | Text for the right-side footer. |
| **language-select** | Selection to control the language of the login app. |

The appearance of the login dialog can also be modified by defining css variables within the HTML template. The following css variables are available for customization:
```
--form-container-margin-block-start
--form-container-margin-block-end
--form-container-margin-inline-start, auto
--form-container-margin-inline-end
--form-container-default-width
--form-container-padding
--form-container-background-color
--form-container-box-border-radius
--form-container-box-shadow
--form-container-font-color
--form-title-font-size
--form-title-font-weight
--form-container-title-color
```



# Tracker { #webapi_tracker }

> **Caution**
>
> Tracker has been re-implemented in DHIS2 2.36. This document describes the new tracker endpoints
>
> * `POST /api/tracker`
> * `GET  /api/tracker/trackedEntities`
> * `GET  /api/tracker/enrollments`
> * `GET  /api/tracker/events`
> * `GET  /api/tracker/relationships`
>
> The deprecated tracker endpoints
>
> * `GET/POST/PUT/DELETE /api/trackedEntityInstance`
> * `GET/POST/PUT/DELETE /api/enrollments`
> * `GET/POST/PUT/DELETE /api/events`
> * `GET/POST/PUT/DELETE /api/relationships`
>
> have been removed in version **42**!
>
> [Migrating to new tracker
> endpoints](https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-241/tracker-deprecated.html#webapi_tracker_migration)
> should help you get started with your migration. Reach out on the [community of
> practice](https://community.dhis2.org) if you need further assistance.

## Tracker Objects { #webapi_tracker_objects }

Tracker consists of a few different types of objects that are nested together to represent the data.
In this section, we will show and describe each of the objects used in the Tracker API.

### Tracked Entities { #tracked-entities } 

`跟踪实体`是跟踪器模型的根对象。

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| trackedEntity | The identifier of the tracked entity. Generated if not supplied | 不 | 是的 | String:Uid | ABCDEF12345 |
| trackedEntityType | The type of tracked entity. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| createdAt | Timestamp when the user created the tracked entity. Set on the server. | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the tracked entity on the client. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the object was last updated. Set on the server. | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAtClient | Timestamp when the object was last updated on the client. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| orgUnit | The organisation unit where the user created the tracked entity. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| inactive | Indicates whether the tracked entity is inactive or not. | 不 | 是的 | Boolean | Default: false, true |
| deleted | Indicates whether the tracked entity has been deleted. It can only change when deleting. | 不 | 不 | Boolean | false until deleted |
| potentialDuplicate | Indicates whether the tracked entity is a potential duplicate. | 不 | 不 | Boolean | Default: false |
| geometry | A  geographical representation of the tracked entity. Based on the "featureType" of the TrackedEntityType. | 不 | 是的 | GeoJson | {<br>"type": "POINT",<br>"coordinates": [123.0, 123.0]<br>} |
| storedBy | Client reference for who stored/created the tracked entity. | 不 | 是的 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| 属性 | A list of tracked entity attribute values owned by the tracked entity. | 不 | 是的 | List of TrackedEntityAttributeValue | See Attribute |
| enrollments | A list of enrollments owned by the tracked entity. | 不 | 是的 | List of Enrollment | See Enrollment |
| relationships | A list of relationships connected to the tracked entity. | 不 | 是的 | List of Relationship | See Relationship |
| programOwners | A list of organisation units that have access through specific programs to this tracked entity. See "Program Ownership" for more. | 不 | 是的 | List of ProgramOwner | See section "Program Ownership" |

> **Note**
>
> `Tracked Entities` "owns" all `Tracked Entity Attribute Values` (Or "attributes" as described in
> the previous table). However, `Tracked Entity Attributes` are either connected to a `Tracked
> Entity` through its `Tracked Entity Type` or a `Program`. We often refer to this separation as
> `Tracked Entity Type Attributes` and `Tracked Entity Program Attributes`. The importance of this
> separation is related to access control and limiting what information the user can see.
>
> The "attributes" referred to in the `Tracked Entity` are `Tracked Entity Type Attributes`.

### Enrollments { #enrollments } 

`Tracked Entities` can enroll into `Programs` for which they are eligible. Tracked entities are
eligible as long as the program is configured with the same `Tracked Entity Type` as the tracked
entity. We represent the enrollment with the `Enrollment` object, which we describe in this section.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| enrollment | The identifier of the enrollment. Generated if not supplied | 不 | 是的 | String:Uid | ABCDEF12345 |
| program | The program the enrollment represents. | 是的 | 不 | String:Uid | ABCDEF12345 |
| trackedEntity | A reference to the tracked entity enrolled. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| status | Status of the enrollment. ACTIVE if not supplied. | 不 | 不 | Enum | ACTIVE, COMPLETED, CANCELLED |
| orgUnit | The organisation unit where the user enrolled the tracked entity. | 是的 | 不 | String:Uid | ABCDEF12345 |
| createdAt | Timestamp when the user created the object. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the object on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the object was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAtClient | Timestamp when the object was last updated on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| enrolledAt | Timestamp when the user enrolled the tracked entity. | 是的 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| occurredAt | Timestamp when enrollment occurred. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedAt | Timestamp when the user completed the enrollment. Set on the server if not passed by the client | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedBy | Only for reading data. User that completed the enrollment. Set on the server | 不 | 不 | String:any | John Doe |
| 跟进 | Indicates whether the enrollment requires follow-up. False if not supplied | 不 | 不 | Booelan | Default: False, True |
| deleted | Indicates whether the enrollment has been deleted. It can only change when deleting. | 不 | 是的 | Boolean | False until deleted |
| geometry | A  geographical representation of the enrollment. Based on the "featureType" of the Program | 不 | 不 | GeoJson | {<br>"type": "POINT",<br>"coordinates": [123.0, 123.0]<br>} |
| storedBy | Client reference for who stored/created the enrollment. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| 属性 | A list of tracked entity attribute values connected to the enrollment. | 不 | 不 | List of TrackedEntityAttributeValue | See Attribute |
| events | A list of events owned by the enrollment. | 不 | 不 | List of Event | See Event |
| relationships | A list of relationships connected to the enrollment. | 不 | 不 | List of Relationship | See Relationship |
| notes | Notes connected to the enrollment. It can only be created. | 不 | 是的 | List of Note | See Note |

> **Note**
>
> `Tracked Entities` "owns" all `Tracked Entity Attribute Values` (Or "attributes" as described in
> the previous table). However, `Tracked Entity Attributes` are either connected to a `Tracked
> Entity` through its `Tracked Entity Type` or a `Program`. We often refer to this separation as
> `Tracked Entity Type Attributes` and `Tracked Entity Program Attributes`. The importance of this
> separation is related to access control and limiting what information the user can see.
>
> The "attributes" referred to in the `Enrollment` are `Tracked Entity Program Attributes`.

### 大事记 { #events } 

`Events` are either part of an `EVENT PROGRAM` or `TRACKER PROGRAM`. For `TRACKER PROGRAM`, events
belong to an `Enrollment`, which again belongs to a `Tracked Entity`. On the other hand, `EVENT
PROGRAM` is `Events` not connected to a specific `Enrollment` or `Tracked Entity`. The difference is
related to whether we track a specific `Tracked Entity` or not. We sometimes refer to `EVENT
PROGRAM` events as "anonymous events" or "single events" since they only represent themselves and
not another `Tracked Entity`.

In the API, the significant difference is that all events are either connected to the same
enrollment (`EVENT PROGRAM`) or different enrollments (`TRACKER PROGRAM`). The table below will
point out any exceptional cases between these two.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| event | The identifier of the event. Generated if not supplied | 不 | 是的 | String:Uid | ABCDEF12345 |
| programStage | The program stage the event represents. | 是的 | 不 | String:Uid | ABCDEF12345 |
| enrollment | A reference to the enrollment which owns the event. ***Not applicable for `EVENT PROGRAM`*** | 是的 | 是的 | String:Uid | ABCDEF12345 |
| program | Only for reading data. The type of program the enrollment which owns the event has. | 不 | 是的 | String:Uid | ABCDEF12345 |
| trackedEntity | Only for reading data. The tracked entity which owns the event. ***Not applicable for `EVENT PROGRAM`*** | 不 | 不 | String:Uid | ABCDEF12345 |
| status | Status of the event. ACTIVE if not supplied. | 不 | 不 | Enum | ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED |
| orgUnit | The organisation unit where the user registered the event. | 是的 | 不 | String:Uid | ABCDEF12345 |
| createdAt | Only for reading data. Timestamp when the user created the event. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the event on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Only for reading data. Timestamp when the event was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAtClient | Timestamp when the event was last updated on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| scheduledAt | Timestamp when the event was scheduled for. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| occurredAt | Timestamp when something occurred. | 是的 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedAt | Timestamp when the user completed the event. Set on the server if not passed by the client | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedBy | Only for reading data. User that completed the event. Set on the server | 不 | 不 | String:any | John Doe |
| 跟进 | Only for reading data. Indicates whether the event has been flagged for follow-up. | 不 | 不 | Boolean | False, True |
| deleted | Only for reading data. Indicates whether the event has been deleted. It can only change when deleting. | 不 | 是的 | Boolean | False until deleted |
| geometry | A  geographical representation of the event. Based on the "featureType" of the Program Stage | 不 | 不 | GeoJson | {<br>"type": "POINT",<br>"coordinates": [123.0, 123.0]<br>} |
| storedBy | Client reference for who stored/created the event. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| attributeOptionCombo | Attribute option combo for the event. Default if not supplied or configured. | 不 | 不 | String:Uid | ABCDEF12345
| attributeCategoryOptions | Attribute category option for the event. Default if not supplied or configured. | 不 | 不 | String:Uid | ABCDEF12345
| assignedUser | A reference to a user who has been assigned to the event. | 不 | 不 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| dataValues | A list of data values connected to the event. | 不 | 不 | List of TrackedEntityAttributeValue | See Attribute |
| relationships | A list of relationships connected to the event. | 不 | 不 | List of Relationship | See Relationship |
| notes | Notes connected to the event. It can only be created. | 不 | 是的 | List of Note | See Note |

### 人际关系 { #relationships } 

`Relationships` are objects that link together two other tracker objects. The constraints each side
of the relationship must conform to are based on the `Relationship Type` of the `Relationship`.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| relationship | The identifier of the relationship. Generated if not supplied. | 不 | 是的 | String:Uid | ABCDEF12345 |
| relationshipType | The type of the relationship. Decides what objects can be linked in a relationship. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| relationshipName | Only for reading data. The name of the relationship type of this relationship | 不 | 不 | String:Any | Sibling |
| createdAt | Timestamp when the user created the relationship. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the relationship was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the relationship on the client. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| bidirectional | Only for reading data. Indicated whether the relationship type is bidirectional or not. | 不 | 不 | Boolean | True or False |
| from, to | A reference to each side of the relationship. Must conform to the constraints set in the relationship type | 是的 | 是的 | RelationshipItem | {"trackedEntity": {"trackedEntity": "ABCEF12345"}}, {"enrollment": {"enrollment": "ABCDEF12345"}} or {"event": {"event": "ABCDEF12345" }} |

> **Note**
>
> `Relationship item` represents a link to an object. Since a `relationship` can be between any
> tracker object like `tracked entity`, `enrollment`, and `event`, the value depends on the
> `relationship type`. For example, if a `relationship type` connects from an `event` to a `tracked
> entity`, the format is strict:

> ```json
> {
>   "from": {
>     "event": { "event": "ABCDEF12345" }
>   },
>   "to": {
>     "trackedEntity": { "trackedEntity": "FEDCBA12345" }
>   }
> }
> ```

### 属性 { #attributes } 

Attributes are the values describing the tracked entities. Attributes can be associated either
through a tracked entity type or a program. This implies that attributes can be part of both a
tracked entity and an enrollment. Importantly, an attribute can only have one value, even if a
tracked entity has multiple enrollments that define that attribute. This is because the tracked
entity ultimately owns the attribute value.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| attribute | A reference to the tracked entity attribute represented. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| 码 | Only for reading data. The code of the tracked entity attribute. | 不 | 不 | String:Any | ABC |
| displayName | Only for reading data. The displayName of the tracked entity attribute. | 不 | 不 | String:Any | 名称 |
| createdAt | Timestamp when the value was added. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the value was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| storedBy | Client reference for who stored/created the value. | 不 | 不 | String:Any | John Doe |
| valueType | Only for reading data. The type of value the attribute represents. | 不 | 不 | Enum | TEXT, INTEGER, and more |
| 价值 | The value of the tracked entity attribute. | 不 | 不 | String:Any | John Doe |

> **Note**
>
> When adding or updating an attribute, only the `attribute` and `value` properties are required. To
> remove an attribute from a tracked entity or enrollment, set the `value` to `null` [see
> example](#delete-attribute-values).
>
> In the context of the tracker, we refer to `Tracked Entity Attributes` and `Tracked Entity
> Attribute Values` simply as attributes. However, it's important to note that attributes and
> attribute values are also concepts within metadata. Therefore, distinguishing between tracker
> attributes and metadata attributes is essential. In the tracker API, you can reference metadata
> attributes by specifying the `idScheme` (see [request
> parameters](#webapi_tracker_import_request_parameters) for more information).

### Data Values { #data-values } 

While attributes describe a tracked entity, data values describe an event.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| dataElement | The data element this value represents. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| 价值 | The value of the data value. | 不 | 不 | String:Any | 123 |
| providedElsewhere | Indicates whether the user provided the value elsewhere or not. False if not supplied. | 不 | 不 | Boolean | False or True |
| createdAt | Timestamp when the user added the value. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the value was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| storedBy | Client reference for who stored/created the value. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |

> **Note**
>
> When adding or updating a data value, only the `dataElement` and `value` properties are required. To
> remove a data value from an event, set the `value` to `null` [see example](#delete-data-values).

### 笔记 { #notes } 

The Tracker system enables the capture of data using data elements and tracked entity attributes.
However, there are situations where additional information or notes about specific issues need to be
recorded. These additional details can be captured using notes, similar to data value notes in the
DHIS2 aggregate side.

There are two types of notes: enrollment-level notes and event-level notes. An enrollment can
consist of one or more events, and notes can be recorded for each event to document reasons such as
why an event was missed, rescheduled, or partially completed. Each event within an enrollment can
have its own notes. Additionally, overall observations of these events can be recorded using a
parent enrollment note. Enrollment notes are useful for documenting reasons such as why an
enrollment was canceled. The use of notes is flexible and can be tailored to the user's needs and
specific use cases.

Both enrollment and event notes can have an unlimited number of entries; there is no limit to the
number of notes that can be added. However, it is not possible to delete or update these notes once
they are created. They function like a logbook. To amend a note, a new note can be created. The only
way to delete a note is by deleting the parent object, either the event or the enrollment.

Notes do not have a dedicated endpoint; they are exchanged as part of the parent event and/or
enrollment payload. Below is a sample payload:

```json
{
  "trackedEntity": "oi3PMIGYJH8",
  "enrollments": [
    {
      "enrollment": "EbRsJr8LSSO",
      "notes": [
        {
          "note": "vxmCvYcPdaW",
          "value": "Enrollment note 1"
        },
        {
          "value": "Enrollment note 2."
        }
      ],
      "events": [
        {
          "event": "zfzS9WeO0uM",
          "notes": [
            {
              "note": "MAQFb7fAggS",
              "value": "Event Note 1."
            },
            {
              "value": "Event Note 2."
            }
          ]
        }
      ]
    }
  ]
}
```

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| note | The reference of the note. Generated if empty | 不 | 是的 | String:Uid | ABCDEF12345 |
| 价值 | The content of the note. | 是的 | 是的 | String:Any | This is a note |
| storedAt | Timestamp when the user added the note. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| storedBy | Client reference for who stored/created the note. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |

### 用户数 { #users } 

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| uid | The identifier of the user. | Yes* | 是的 | String:Uid | ABCDEF12345 |
| 用户名 | Username used by the user. | Yes* | 是的 | String:Any | 123 |
| firstName | Only for reading data. First name of the user. | 不 | 是的 | String:Any | John |
| surname | Only for reading data. Last name of the user. | 不 | 是的 | String:Any | Doe |

> One between `uid` or `username` field must be provided. If both are provided, only username is
> considered.

## Tracker Import (`POST /api/tracker`) { #webapi_tracker_import }

The endpoint `POST /api/tracker` is also called the tracker importer. This endpoint allows clients
to import i.e. create, update and delete

* **Tracked entities**
* **Enrollments**
* **Events**
* **Relationships**
* and data embedded in other [tracker objects](#webapi_tracker_objects)

### Request parameters { #webapi_tracker_import_request_parameters }

The tracker importer supports the following parameters:

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| async | Indicates whether the import should happen asynchronously or synchronously. | Boolean | `TRUE`, `FALSE` |
| reportMode | Only when performing synchronous import. See importSummary for more info. | Enum | `FULL`, `ERRORS`, `WARNINGS` |
| importMode | Can either be `VALIDATE` which will report errors in the payload without making changes to the database or `COMMIT` (default) which will validate the payload and make changes to the database. | Enum | `VALIDATE`, `COMMIT` |
| 方案 | Indicates the overall idScheme to use for metadata references when importing. Default is UID. Can be overridden for specific metadata (Listed below) | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| 数据元素标识方案 | Indicates the idScheme to use for data elements when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| orgUnitIdScheme | Indicates the idScheme to use for organisation units when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| 程序标识方案 | Indicates the idScheme to use for programs when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| 程序阶段标识方案 | Indicates the idScheme to use for program stages when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| categoryOptionComboIdScheme | Indicates the idScheme to use for category option combos when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| categoryOptionIdScheme | Indicates the idScheme to use for category options when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| importStrategy | Indicates the effect the import should have. Can either be `CREATE`, `UPDATE`, `CREATE_AND_UPDATE` and `DELETE`, which respectively only allows importing new data, importing changes to existing data, importing any new or updates to existing data, and finally deleting data. | Enum | `CREATE`, `UPDATE`, `CREATE_AND_UPDATE`, `DELETE` |
| atomicMode | Indicates how the import responds to validation errors. If `ALL`, all data imported must be valid for any data to be committed. For `OBJECT`, only the data committed needs to be valid, while other data can be invalid. | Enum | `ALL`, `OBJECT` |
| flushMode | Indicates the frequency of flushing. This is related to how often data is pushed into the database during the import. Primarily used for debugging reasons, and should not be changed in a production setting | Enum | `AUTO`, `OBJECT` |
| validationMode | Indicates the completeness of the validation step. It can be skipped, set to fail fast (Return on the first error), or full(Default), which will return any errors found | Enum | `FULL`, `FAIL_FAST`, `SKIP` |
| skipPatternValidation | If true, it will skip validating the pattern of generated attributes. | Boolean | `TRUE`, `FALSE` |
| skipSideEffects | If true, it will skip running any side effects for the import | Boolean | `TRUE`, `FALSE` |
| skipRuleEngine | If true, it will skip running any program rules for the import | Boolean | `TRUE`, `FALSE` |

**NOTE**: idScheme and its metadata specific idScheme parameters like orgUnitIdScheme,
programIdScheme, ... used to allow and use the default `AUTO`. `AUTO` has been removed. The default
idScheme has already been `UID`. Any requests sent with idScheme `AUTO` will see the same behavior
as before, namely matching done using `UID`.

#### SYNC and ASYNC { #sync-and-async } 

The main difference for the user between synchronous and asynchronous imports is the timing of the
API's response. Synchronous imports provide an immediate [import
summary](#webapi_tracker_import_summary) once the import is finished. In contrast, asynchronous imports
return a reference to the import job right away. The progress of the import job can be tracked using
this `response.location`. Here is an example of an asynchronous import response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Tracker job added",
  "response": {
    "id": "cHh2OCTJvRw",
    "location": "https://play.im.dhis2.org/dev/api/tracker/jobs/cHh2OCTJvRw"
  }
}
```

For large imports, opting for asynchronous import can be advantageous for clients, as it prevents
prolonged waiting periods for a response.

### Payload { #payload } 

The importer supports both flat and nested payloads.

#### ***FLAT*** payload { #flat-payload } 

The flat payload can include collections for each of the core tracker objects: tracked entities,
enrollments, events, and relationships. This format integrates well with existing data that already
has UIDs assigned. However, for new data, the client must provide new UIDs for any references
between objects. For instance, if you import a new tracked entity with a new enrollment, the client
must provide a UID for the tracked entity so that the enrollment can be linked to it.

```json
{
  "trackedEntities": [
    {
      "orgUnit": "y77LiPqLMoq",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "nEenWmSyUEp"
    },
    {
      "orgUnit": "y77LiPqLMoq",
      "trackedEntity": "Gjaiu3ea38E",
      "trackedEntityType": "nEenWmSyUEp"
    }
  ],
  "enrollments": [
    {
      "enrolledAt": "2019-08-19T00:00:00.000",
      "enrollment": "MNWZ6hnuhSw",
      "occurredAt": "2019-08-19T00:00:00.000",
      "orgUnit": "y77LiPqLMoq",
      "program": "IpHINAT79UW",
      "status": "ACTIVE",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "nEenWmSyUEp"
    }
  ],
  "events": [
    {
      "attributeCategoryOptions": "xYerKDKCefk",
      "attributeOptionCombo": "HllvX50cXC0",
      "dataValues": [
        {
          "dataElement": "bx6fsa0t90x",
          "value": "true"
        },
        {
          "dataElement": "UXz7xuGCEhU",
          "value": "5.7"
        }
      ],
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "event": "ZwwuwNp6gVd",
      "occurredAt": "2019-08-01T00:00:00.000",
      "orgUnit": "y77LiPqLMoq",
      "program": "IpHINAT79UW",
      "programStage": "A03MvHHogjR",
      "scheduledAt": "2019-08-19T13:59:13.688",
      "status": "ACTIVE",
      "trackedEntity": "Kj6vYde4LHh"
    },
    {
      "attributeCategoryOptions": "xYerKDKCefk",
      "attributeOptionCombo": "HllvX50cXC0",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "event": "XwwuwNp6gVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "orgUnit": "y77LiPqLMoq",
      "program": "IpHINAT79UW",
      "programStage": "ZzYYXq4fJie",
      "scheduledAt": "2019-08-19T13:59:13.688",
      "status": "ACTIVE",
      "trackedEntity": "Kj6vYde4LHh"
    }
  ],
  "relationships": [
    {
      "from": {
        "trackedEntity": {
          "trackedEntity": "Kj6vYde4LHh"
        }
      },
      "relationshipType": "dDrh5UyCyvQ",
      "to": {
        "trackedEntity": {
          "trackedEntity": "Gjaiu3ea38E"
        }
      }
    }
  ]
}
```

#### ***NESTED*** payload { #nested-payload } 

Nested payloads are the most commonly used structure, where tracker objects are embedded within
their parent objects, such as an enrollment within a tracked entity. The advantage of this structure
is that the client does not need to provide UIDs for these references, as this is handled
automatically.

> **NOTE**
>
> Although nested payloads can be easier for clients to manage, the payload will always be flattened
> before the import. For large imports, using a flat structured payload offers more control and
> reduces overhead during the import process.
>
> That being said, you cannot nest new tracked entities, enrollments or events in a relationship.

```json
{
  "trackedEntities": [
    {
      "enrollments": [
        {
          "attributes": [
            {
              "attribute": "zDhUuAYrxNC",
              "displayName": "Last name",
              "value": "Kelly"
            },
            {
              "attribute": "w75KJ2mc4zz",
              "displayName": "First name",
              "value": "John"
            }
          ],
          "enrolledAt": "2019-08-19T00:00:00.000",
          "events": [
            {
              "attributeCategoryOptions": "xYerKDKCefk",
              "attributeOptionCombo": "HllvX50cXC0",
              "dataValues": [
                {
                  "dataElement": "bx6fsa0t90x",
                  "value": "true"
                },
                {
                  "dataElement": "UXz7xuGCEhU",
                  "value": "5.7"
                }
              ],
              "enrollmentStatus": "ACTIVE",
              "notes": [
                {
                  "value": "need to follow up"
                }
              ],
              "occurredAt": "2019-08-01T00:00:00.000",
              "orgUnit": "y77LiPqLMoq",
              "program": "IpHINAT79UW",
              "programStage": "A03MvHHogjR",
              "scheduledAt": "2019-08-19T13:59:13.688",
              "status": "ACTIVE"
            }
          ],
          "occurredAt": "2019-08-19T00:00:00.000",
          "orgUnit": "y77LiPqLMoq",
          "program": "IpHINAT79UW",
          "status": "ACTIVE",
          "trackedEntityType": "nEenWmSyUEp"
        }
      ],
      "orgUnit": "y77LiPqLMoq",
      "trackedEntityType": "nEenWmSyUEp"
    }
  ]
}
```

### Create { #create } 

Make a `POST` to `/api/tracker` with the `importStrategy` set to `CREATE` or `CREATE_AND_UPDATE` and
a payload as described [here](#payload).

### Update { #update } 

Make a `POST` to `/api/tracker` with the `importStrategy` set to `UPDATE` or `CREATE_AND_UPDATE` and
a payload as described [here](#payload).

The payload must include all fields of the object you are updating, even if they have not been
modified. The only exception is collections. Items in a collection that should not be changed can be
omitted, as demonstrated in [update attribute values](#update-data-values) and [update data
values](#update-data-values).

> **Note**
>
> * Deleted tracker objects cannot be updated.
> * Relationships cannot be updated.

#### Update attribute values { #update-attribute-values } 

The following updates one of the attribute values of a [tracked entity](#payload):

    POST /api/tracker?async=false

```json
{
  "trackedEntities": [
    {
      "trackedEntity": "PQfMcpmXeFE",
      "trackedEntityType": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "code": "MMD_PER_NAM",
          "displayName": "First name",
          "createdAt": "2016-08-03T23:49:43.308",
          "updatedAt": "2016-08-03T23:49:43.308",
          "valueType": "TEXT",
          "value": "Johnny"
        }
      ]
    }
  ]
}
```

Note that it is not necessary to specify the tracked entity's enrollments. However, you must specify
the non-collection fields of the tracked entity, even if you are not changing them.

#### Delete attribute values { #delete-attribute-values } 

The following deletes one of the attribute values of a [tracked entity](#payload):

    POST /api/tracker?async=false

```json
{
  "trackedEntities": [
    {
      "trackedEntity": "PQfMcpmXeFE",
      "trackedEntityType": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": null
        }
      ]
    }
  ]
}
```

#### Update data values { #update-data-values } 

The following updates one of the data values of an [event](#payload):

    POST /api/tracker?async=false

```json
{
  "events": [
    {
      "event": "ZwwuwNp6gVd",
      "dataValues": [
        {
          "dataElement": "bx6fsa0t90x",
          "value": "true"
        }
      ],
      "attributeOptionCombo": "HllvX50cXC0",
      "attributeCategoryOptions": "xYerKDKCefk",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "orgUnit": "y77LiPqLMoq",
      "program": "IpHINAT79UW",
      "programStage": "A03MvHHogjR",
      "scheduledAt": "2019-08-19T13:59:13.688",
      "status": "ACTIVE",
      "trackedEntity": "Kj6vYde4LHh"
    }
  ]
}
```

#### Delete data values { #delete-data-values } 

The following deletes one of the data values of an [event](#payload):

    POST /api/tracker?async=false

```json
{
  "events": [
    {
      "event": "ZwwuwNp6gVd",
      "dataValues": [
        {
          "dataElement": "bx6fsa0t90x",
          "value": null
        }
      ],
      "attributeOptionCombo": "HllvX50cXC0",
      "attributeCategoryOptions": "xYerKDKCefk",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "orgUnit": "y77LiPqLMoq",
      "program": "IpHINAT79UW",
      "programStage": "A03MvHHogjR",
      "scheduledAt": "2019-08-19T13:59:13.688",
      "status": "ACTIVE",
      "trackedEntity": "Kj6vYde4LHh"
    }
  ]
}
```

### Delete { #delete } 

Make a `POST` to `/api/tracker` with `importStrategy` set to `DELETE`. The payload should include
only the UIDs of the `trackedEntities`, `enrollments`, `events` or `relationships` you wish to
delete.

The following deletes the events created with [this payload](#payload):

    POST /api/tracker?async=false&importStrategy=delete

```json
{
  "events": [
    {
      "event": "ZwwuwNp6gVd",
    },
    {
      "event": "XwwuwNp6gVE",
    }
  ]
}
```

The following deletes the tracked entities and all its child tracker objects which are enrollments,
events and relationships:

    POST /api/tracker?async=false&importStrategy=delete

```json
{
  "trackedEntities": [
    {
      "trackedEntity": "Kj6vYde4LHh",
    },
    {
      "trackedEntity": "Gjaiu3ea38E",
    }
  ]
}
```

All the children of a tracker object will be deleted if the user making the request has the
authorities `F_TEI_CASCADE_DELETE` and `F_ENROLLMENT_CASCADE_DELETE`.
Relationships linked to an entity are always deleted, without the need of any authority.

### CSV import { #csv-import } 

To import events using CSV make a `POST` request with CSV body file and the `Content-Type` set to
***application/csv*** or ***text/csv***.

#### 大事记 { #events } 

Every row of the CSV payload represents an event and a data value. So, for events with multiple
data values, the CSV file will have `x` rows per event, where `x` is the number of data values
in that event.

##### ***CSV PAYLOAD*** example { #csv-payload-example } 

Your CSV file can look like:

```csv
event,status,program,programStage,enrollment,orgUnit,occurredAt,scheduledAt,geometry,latitude,longitude,followUp,deleted,createdAt,createdAtClient,updatedAt,updatedAtClient,completedBy,completedAt,updatedBy,attributeOptionCombo,attributeCategoryOptions,assignedUser,dataElement,value,storedBy,providedElsewhere,storedByDataValue,updatedAtDataValue,createdAtDataValue
A7rzcnZTe2T,ACTIVE,eBAyeGv0exc,Zj7UnCAulEk,RiLEKhWHlxZ,DwpbWkiqjMy,2023-02-12T23:00:00Z,2023-02-12T23:00:00Z,"POINT (-11.468912037323042 7.515913998868316)",7.515913998868316,-11.468912037323042,false,false,2017-09-08T19:40:22Z,,2017-09-08T19:40:22Z,,,,,HllvX50cXC0,xYerKDKCefk,,F3ogKBuviRA,"[-11.4880220438585,7.50978830548003]",admin,false,,2016-12-06T17:22:34.438Z,2016-12-06T17:22:34.438Z
```

See [Events CSV](#events-csv) in the export section for a more detailed definition of the CSV fields.

### Import Summary { #webapi_tracker_import_summary }

The Tracker API has two primary endpoints for consumers to acquire feedback from their imports.
These endpoints are most relevant for async import jobs but are available for sync jobs as well.
These endpoints will return either the log related to the import or the import summary itself.

> **Note**
>
> These endpoints rely on information stored in the application memory. This means the information
> will be unavailable after certain cases, as an application restart or after a large number of
> import requests have started after this one.

After submitting a tracker import request, we can access the following endpoints in order to monitor
the job progress based on logs:

`GET /tracker/jobs/{uid}`

| Parameter|描述|例
|---|---|---|
|`{uid}`| The UID of an existing tracker import job | ABCDEF12345

#### ***REQUEST*** example { #request-example } 

`GET /tracker/jobs/PQK63sMwjQp`

#### ***RESPONSE*** example { #response-example } 

```json
[
  {
    "uid": "PQK63sMwjQp",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.370",
    "message": "Import complete with status OK, 0 created, 0 updated, 0 deleted, 0 ignored",
    "completed": true,
    "id": "PQK63sMwjQp"
  },
  {
    "uid": "XIfTJ1UUNcd",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.369",
    "message": "PostCommit",
    "completed": false,
    "id": "XIfTJ1UUNcd"
  },
  {
    "uid": "uCG4FNJLLBJ",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.364",
    "message": "Commit Transaction",
    "completed": false,
    "id": "uCG4FNJLLBJ"
  },
  {
    "uid": "xfOUv2Lk2MC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.361",
    "message": "Running Rule Engine Validation",
    "completed": false,
    "id": "xfOUv2Lk2MC"
  },
  {
    "uid": "cSPfA776obb",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.325",
    "message": "Running Rule Engine",
    "completed": false,
    "id": "cSPfA776obb"
  },
  {
    "uid": "mru3HJrFGKA",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.313",
    "message": "Running Validation",
    "completed": false,
    "id": "mru3HJrFGKA"
  },
  {
    "uid": "oTbCUJ2RnA6",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.312",
    "message": "Running PreProcess",
    "completed": false,
    "id": "oTbCUJ2RnA6"
  },
  {
    "uid": "lcUNbWTn6uh",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:16.312",
    "message": "Calculating Payload Size",
    "completed": false,
    "id": "lcUNbWTn6uh"
  },
  {
    "uid": "l4jQiSS9qdK",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:15.903",
    "message": "Running PreHeat",
    "completed": false,
    "id": "l4jQiSS9qdK"
  },
  {
    "uid": "qGbiuqgwPX5",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:15.850",
    "message": "Loading file content",
    "completed": false,
    "id": "qGbiuqgwPX5"
  },
  {
    "uid": "eWNHzVf7iAj",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:15.838",
    "message": "Loading file resource",
    "completed": false,
    "id": "eWNHzVf7iAj"
  },
  {
    "uid": "t9gOjotekQt",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2024-03-19T13:18:15.837",
    "message": "Tracker import started",
    "completed": false,
    "dataType": "PARAMETERS",
    "data": {
      "userId": "xE7jOejl9FI",
      "importMode": "VALIDATE",
      "idSchemes": {
        "dataElementIdScheme": {
          "idScheme": "UID",
          "attributeUid": null
        },
        "orgUnitIdScheme": {
          "idScheme": "UID",
          "attributeUid": null
        },
        "programIdScheme": {
          "idScheme": "UID",
          "attributeUid": null
        },
        "programStageIdScheme": {
          "idScheme": "UID",
          "attributeUid": null
        },
        "idScheme": {
          "idScheme": "UID",
          "attributeUid": null
        },
        "categoryOptionComboIdScheme": {
          "idScheme": "UID",
          "attributeUid": null
        },
        "categoryOptionIdScheme": {
          "idScheme": "UID",
          "attributeUid": null
        }
      },
      "importStrategy": "CREATE_AND_UPDATE",
      "atomicMode": "ALL",
      "flushMode": "AUTO",
      "validationMode": "FULL",
      "skipPatternValidation": false,
      "skipSideEffects": false,
      "skipRuleEngine": false,
      "filename": null,
      "reportMode": "ERRORS"
    },
    "id": "t9gOjotekQt"
  }
]
```

Additionally, the following endpoint will return the import summary of the import job. This import
summary will only be available after the import has completed:

`GET /tracker/jobs/{uid}/report`

| Parameter|描述|例
|---|---|---|
|path `/{uid}`|The UID of an existing tracker import job.|ABCDEF12345|
|`reportMode`|The level of detail the report should have.|`FULL`&#124;`ERRORS`&#124;`WARNINGS`|

#### ***REQUEST*** example { #request-example } 

`GET /tracker/jobs/mEfEaFSCKCC/report`

#### ***RESPONSE*** example { #response-example } 

The response payload is the same as the one returned after a sync import request.

> **Note**
>
> Both endpoints are used primarily for async import; however, `GET /tracker/jobs/{uid}` would also
> work for sync requests as it eventually uses the same import process and logging as async
> requests.

### Import Summary Structure { #import-summary-structure } 

Import summaries have the following overall structure, depending on the requested `reportMode`:

```json
{
  "status": "OK",
  "validationReport": {
    "errorReports": [],
    "warningReports": []
  },
  "stats": {
    "created": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0,
    "total": 3
  },
  "bundleReport": {
    "typeReportMap": {
      "EVENT": {
        "trackerType": "EVENT",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "EVENT",
            "uid": "gTZBPT3Jq39",
            "errorReports": []
          }
        ]
      },
      "ENROLLMENT": {
        "trackerType": "ENROLLMENT",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "ENROLLMENT",
            "uid": "ffcvJvWjiNZ",
            "errorReports": []
          }
        ]
      },
      "RELATIONSHIP": {
        "trackerType": "RELATIONSHIP",
        "stats": {
          "created": 0,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 0
        },
        "objectReports": []
      },
      "TRACKED_ENTITY": {
        "trackerType": "TRACKED_ENTITY",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "TRACKED_ENTITY",
            "uid": "aVcGf9iO8Xp",
            "errorReports": []
          }
        ]
      }
    }
  }
}
```

***status***

The property, `status`, of the import summary indicates the overall status of the import. If no
errors or warnings were raised during the import, the `status` is reported as `OK`. The presence of
any error or warnings in the import will result in a status of type `ERROR` or `WARNING`.

`status` is based on the presence of the most significant `validationReport`. `ERROR` has the
highest significance, followed by `WARNING` and finally `OK`. This implies that `ERROR` is reported
as long as a single error was found during the import, regardless of how many warnings occurred.

> **Note**
>
> If the import is performed using the AtomicMode "OBJECT", where the import will import any data
> without validation errors, the overall status will still be `ERROR` if any errors were found.

***validationReport***

The `validationReport` might include `errorReports` and `warningReports` if any errors or warnings
were present during the import. When present, they provide a detailed list of any errors or warnings
encountered.

For example, a validation error while importing a `TRACKED_ENTITY`:

```json
{
  "validationReport": {
    "errorReports": [
      {
        "message": "Could not find TrackedEntityType: `Q9GufDoplCL`.",
        "errorCode": "E1005",
        "trackerType": "TRACKED_ENTITY",
        "uid": "Kj6vYde4LHh"
      },
      ...
    ],
    "warningReports" : [ ... ]
  }
}
```

The report contains a message and a code describing the actual error (See the [error
codes](#error-codes) section for more information about errors). Additionally, the report includes
the `trackerType` and `uid`, which aims to describe where in the data the error was found. In this
case, there was a `TRACKED_ENTITY` with the uid `Kj6vYde4LHh`, which had a reference to a tracked
entity type that was not found.

> **Note**
>
> When referring to the `uid` of tracker objects, they are labeled as their object names in the
> payload. For example, the `uid` of a tracked entity would in the payload have the name
> "trackedEntity". The same goes for "enrollment", "event" and "relationship" for enrollments,
> events, and relationships, respectively.
>
> If no uid is provided in the payload, the import process will generate new uids. This means the
> error report might refer to a uid that does not exist in your payload.
>
> Errors represent issues with the payload which the importer can not circumvent. Any errors will
> block that data from being imported. Warnings, on the other hand, are issues where it's safe to
> circumvent them, but the user should be made aware that it happened. Warnings will not block data
> from being imported.

***stats***

The stats provide a quick overview of the import. After an import is completed, these will be the
actual counts representing how much data was created, updated, deleted, or ignored.

例：

```json
{
  "stats": {
    "created": 2,
    "updated": 2,
    "deleted": 1,
    "ignored": 5,
    "total": 10
  }
}
```

`created` refers to how many new objects were created. In general, objects without an existing uid
in the payload will be treated as new objects.

`updated` refers to the number of objects updated. If an object has a uid set in the payload, it
will be treated as an update as long as that same uid exists in the database.

`deleted` refers to the number of objects deleted during the import. Deletion only happens when the
import is configured to delete data and only then when the objects in the payload have existing uids
set.

`ignored` refers to objects that were not persisted. Objects can be ignored for several reasons, for
example trying to create something that already exists. Ignores should always be safe, so if
something was ignored, it was not necessary, or it was due to the configuration of the import.

***bundleReport***

When the import is completed, the `bundleReport` contains all the [tracker
objects](#tracker-objects) imported.

For example, `TRACKED_ENTITY`:

```json
{
  "bundleReport": {
    "typeReportMap": {
      "TRACKED_ENTITY": {
        "trackerType": "TRACKED_ENTITY",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "TRACKED_ENTITY",
            "uid": "aVcGf9iO8Xp",
            "errorReports": []
          }
        ]
      }
    }
  }
}
```

As seen, each type of tracker object will be reported, and each has its own stats and
`objectReports`. These `objectReports` will provide details about each imported object, like their
type, their uid, and any error or warning reports is applicable.

***message***

If the import ended abruptly, the `message` would contain further information in relation to what
happened.

### Import Summary Report Level { #import-summary-report-level } 

As previously stated, `GET /tracker/jobs/{uid}/report` can be retrieved using a specific
`reportMode` parameter. By default the endpoint will return an `importSummary` with `reportMode`
`ERROR`.

| Parameter | 描述 |
|---|---|
| `FULL` | Returns everything from `WARNINGS`, plus `timingsStats` |
| `WARNINGS` | Returns everything from `ERRORS`, plus `warningReports` in `validationReports` |
| `ERRORS` (default) | Returns only `errorReports` in `validationReports` |

In addition, all `reportModes` will return `status`, `stats`, `bundleReport` and `message` when
applicable.

### Error Codes { #webapi_tracker_error_codes }

There are various error codes for different error scenarios. The following table has the list of
error codes thrown from the new Tracker API, along with the error messages and some additional
descriptions. The placeholders in the error messages (`{0}`,`{1}`,`{2}`..) are usually uids unless
otherwise specified.

| Error Code | Error Message | 描述 |
|:--|:----|:----|
| E1000 | User: `{0}`, has no write access to OrganisationUnit: `{1}`. | This typically means that the OrganisationUnit `{1}` is not in the capture scope of the user `{0}` for the write operation to be authorized. |
| E1001 | User: `{0}`, has no data write access to TrackedEntityType: `{1}`. | The error occurs when the user is not authorized to create or modify data of the TrackedEntityType `{1}`  
| E1002 | TrackedEntity: `{0}`, already exists. | This error is thrown when trying to create a new TrackedEntity with an already existing uid. Make sure a new uid is used when adding a new TrackedEntity. |
| E1003 | OrganisationUnit: `{0}` of TrackedEntity is outside search scope of User: `{1}`. | |
| E1005 | Could not find TrackedEntityType: `{0}`. | Error thrown when trying to fetch a non existing TrackedEntityType with uid `{0}` . This might also mean that the user does not have read access to the TrackedEntityType. |
| E1006 | Attribute: `{0}`, does not exist. | Error thrown when the system was not able to find a matching TrackedEntityAttribute with uid `{0}`. This might also mean that the user does not have access to the TrackedEntityAttribute. |
| E1007 | Error validating attribute value type: `{0}`; Error: `{1}`. | Mismatch between value type of a TrackedEntityAttribute and its provided attribute value. The actual validation error will be displayed in `{1}`. |
| E1008 | Program stage `{0}` has no reference to a program. Check the program stage configuration | |
| E1009 | File resource: `{0}`, has already been assigned to a different object. | The File resource uid `{0}` is already assigned to another object in the system. |
| E1010 | Could not find Program: `{0}`, linked to Event. | The system was unable to find a Program with the uid `{0}` specified inside the Event payload. This might also mean that the specific Program is not accessible by the logged in user. |
| E1011 | Could not find OrganisationUnit: `{0}`, linked to Event. | The system was unable to find a OrganisationUnit with uid `{0}` specified inside the Event payload.  |
| E1012 | Geometry does not conform to FeatureType: `{0}`. | FeatureType provided is either NONE or an incompatible one for the provided geometry value. |
| E1013 | Could not find ProgramStage: `{0}`, linked to Event. | The system was unable to find a ProgramStage with uid `{0}` specified inside the Event payload. This might also mean that the ProgramStage is not accessible to the logged in user.  |
| E1014 | Provided Program: `{0}`, is a Program without registration. An Enrollment cannot be created into Program without registration. | Enrollments can only be created for Programs with registration. |
| E1015 | TrackedEntity: `{0}`, already has an active Enrollment in Program `{1}`. | Cannot enroll into a Program if another active enrollment already exists for the Program. The active enrollment will have to be completed first at least.|
| E1016 | TrackedEntity: `{0}`, already has an active enrollment in Program: `{1}`, and this program only allows enrolling one time. | As per the Program `{1}` configuration, a TrackedEntity can only be enrolled into that Program once. It looks like the TrackedEntity `{0}` already has either an ACTIVE or COMPLETED enrollment in that Program. Hence another enrollment cannot be added. |
| E1018 | Attribute: `{0}`, is mandatory in program `{1}` but not declared in enrollment `{2}`. | Attribute value is missing in payload, for an attribute that is defined as mandatory for a Program. Make sure that attribute values for mandatory attributes are provided in the payload.  |
| E1019 | Only Program attributes is allowed for enrollment; Non valid attribute: `{0}`. | Attribute uid `{0}` specified in the enrollment payload is not associated with the Program.  |
| E1020 | Enrollment date: `{0}`, can`t be future date. | Cannot enroll into a future date unless the Program allows for it in its configuration. |
| E1021 | Incident date: `{0}`, can`t be future date. | Incident date cannot be a future date unless the Program allows for it in its configuration. |
| E1022 | TrackedEntity: `{0}`, must have same TrackedEntityType as Program `{1}`. | The Program is configured to accept TrackedEntityType uid that is different from what is provided in the enrollment payload. |
| E1023 | DisplayIncidentDate is true but property occurredAt is null. | Program is configured with DisplayIncidentDate but it is null in the payload. |
| E1025 | Property enrolledAt is null. | EnrolledAt Date is mandatory for an Enrollment. Make sure it is not null. |
| E1029 | Event OrganisationUnit: `{0}`, and Program: `{1}`, don't match. | The Event payload uses a Program `{1}` which is not configured to be accessible by OrganisationUnit `{0}`. |
| E1030 | Event: `{0}`, already exists. | This error is thrown when trying to add a new Event with an already existing uid. Make sure a new uid is used when adding a new Event. |
| E1031 | Event OccurredAt date is missing. | OccuredAt property is either null or has an invalidate date format in the payload. |
| E1032 | Event: `{0}`, do not exist. | |
| E1033 | Event: `{0}`, Enrollment value is NULL. | |
| E1035 | Event: `{0}`, ProgramStage value is NULL. | |
| E1039 | ProgramStage: `{0}`, is not repeatable and an event already exists. | An Event already exists for the ProgramStage for the specific Enrollment. Since the ProgramStage is configured to be non-repeatable, another Event for the same ProgramStage cannot be added.  |
| E1041 | Enrollment OrganisationUnit: `{0}`, and Program: `{1}`, don't match. | The Enrollment payload contains a Program `{1}` which is not configured to be accessible by the OrganisationUnit  `{0}`. |
| E1043 | Event: `{0}`, completeness date has expired. Not possible to make changes to this event. | A user without 'F_EDIT_EXPIRED' authority cannot update an Event that has passed its expiry days as configured in its Program. |
| E1045 | Program: `{0}`, expiry date has passed. It is not possible to make changes to this event. | |
| E1046 | Event: `{0}`, needs to have at least one (event or schedule) date. | Either of occuredAt or scheduledAt property should be present in the Event payload. |
| E1047 | Event: `{0}`, date belongs to an expired period. It is not possible to create such event. | Event occuredAt or scheduledAt has a value that is earlier than the PeriodType start date.  |
| E1048 | Object: `{0}`, uid: `{1}`, has an invalid uid format. | 有效的 uid 有 11 个字符。第一个字符必须是字母（a-z 或 A-Z），其余 10 个字符可以是字母数字（a-z 或 A-Z 或 0-9）。 |
| E1049 | Could not find OrganisationUnit: `{0}`, linked to Tracked Entity. | The system could not find an OrganisationUnit with uid `{0}`. |
| E1050 | Event ScheduledAt date is missing. | ScheduledAt property in the Event payload is either missing or an invalid date format. |
| E1051 | Event: `{0}`, completedAt must be null when status is `{1}`. | Event completedAt can only be passed in the payload if status is COMPLETED |
| E1052 | Enrollment: `{0}`, completedAt must be null when status is `{1}`. | Enrollment completedAt can only be passed in the payload if status is COMPLETED |
| E1054 | AttributeOptionCombo `{0}` is not in the event programs category combo `{1}`. |
| E1055 | Default AttributeOptionCombo is not allowed since program has non-default CategoryCombo. | The Program is configured to contain non-default CategoryCombo but the request uses the Default AttributeOptionCombo. |
| E1056 | Event date: `{0}`, is before start date: `{1}`, for AttributeOption: `{2}`. | The CategoryOption has a start date configured , the Event date in the payload cannot be earlier than this start date. |
| E1057 | Event date: `{0}`, is after end date: `{1}`, for AttributeOption; `{2}`. | The CategoryOption has an end date configured, the Event date in the payload cannot be later than this end date.  |
| E1063 | TrackedEntity: `{0}`, does not exist. | Error thrown when trying to fetch a non existing TrackedEntity with uid `{0}` . This might also mean that the user does not have read access to the TrackedEntity. |
| E1064 | Non-unique attribute value `{0}` for attribute `{1}` | The attribute value has to be unique within the defined scope. The error indicates that the attribute value already exists for another TrackedEntity. |
| E1068 | Could not find TrackedEntity: `{0}`, linked to Enrollment. | The system could not find the TrackedEntity specified in the Enrollment payload. This might also mean that the user does not have read access to the TrackedEntity. |
| E1069 | Could not find Program: `{0}`, linked to Enrollment. | The system could not find the Program specified in the Enrollment payload. This might also mean that the user does not have read access to the Program. |
| E1070 | Could not find OrganisationUnit: `{0}`, linked to Enrollment. | The system could not find the OrganisationUnit specified in the Enrollment payload. |
| E1074 | FeatureType is missing. | |
| E1075 | Attribute: `{0}`, is missing uid. | |
| E1076 | `{0}` `{1}` is mandatory and can't be null | |
| E1077 | Attribute: `{0}`, text value exceed the maximum allowed length: `{0}`. | |
| E1079 | Event: `{0}`, program: `{1}` is different from program defined in enrollment `{2}`. | |
| E1080 | Enrollment: `{0}`, already exists. | This error is thrown when trying to create a new Enrollmentt with an already existing uid. Make sure a new uid is used when adding a new Enrollment. |
| E1081 | Enrollment: `{0}`, do not exist. | Error thrown when trying to fetch a non existing Enrollment with uid `{0}` . This might also mean that the user does not have read access to the Enrollment. |
| E1082 | Event: `{0}`, is already deleted and can't be modified. | If the event is soft deleted, no modifications on it are allowed. |
| E1083 | User: `{0}`, is not authorized to modify completed events. | Only a super user or a user with the authority "F_UNCOMPLETE_EVENT" can modify completed events. Completed Events are those Events with status as COMPLETED. |
| E1084 | File resource: `{0}`, reference could not be found. | |
| E1085 | Attribute: `{0}`, value does not match value type: `{1}`. | Mismatch between value type of an attribute and its provided attribute value. |
| E1086 | Event: `{0}`, has a program: `{1}`, that is a registration but its ProgramStage is not valid or missing. | |
| E1087 | Event: `{0}`, could not find DataElement: `{1}`, linked to a data value. | |
| E1088 | Event: `{0}`, program: `{1}`, and ProgramStage: `{2}`, could not be found. | |
| E1089 | Event: `{0}`, references a Program Stage `{1}` that does not belong to Program `{2}`. | The ProgramStage uid and Program uid in the Event payload is incompatible. |
| E1090 | Attribute: `{0}`, is mandatory in tracked entity type `{1}` but not declared in tracked entity `{2}`. | The payload has missing values for mandatory TrackedEntityTypeAttributes. |
| E1091 | User: `{0}`, has no data write access to Program: `{1}`. | The Program sharing configuration is such that, the user does not have write access for this Program. |
| E1094 | Not allowed to update Enrollment: `{0}`, existing Program `{1}`. | The Enrollment payload for an existing Enrollment has a different Program uid than the one it was originally enrolled with. |
| E1095 | User: `{0}`, has no data write access to ProgramStage: `{1}`. | The ProgramStage sharing configuration is such that, the user does not have write access for this ProgramStage.  |
| E1096 | User: `{0}`, has no data read access to Program: `{1}`. | The Program sharing configuration is such that, the user does not have read access for this Program. |
| E1099 | User: `{0}`, has no write access to CategoryOption: `{1}`. | The CategoryOption sharing configuration is such that, the user does not have write access for this CategoryOption |
| E1100 | User: `{0}`, is lacking 'F_TEI_CASCADE_DELETE' authority to delete TrackedEntity: `{1}`. | There exists undeleted Enrollments for this TrackedEntity. If the user does not have 'F_TEI_CASCADE_DELETE' authority, then these Enrollments has to be deleted first explicitly to be able to delete the TrackedEntity. |
| E1102 | User: `{0}`, does not have access to the tracked entity: `{1}`, Program: `{2}`, combination. | This error is thrown when the user's OrganisationUnit does not have the ownership of this TrackedEntity for this specific Program. The owning OrganisationUnit of the TrackedEntity-Program combination should fall into the capture scope (in some cases the search scope) of the user. |
| E1103 | User: `{0}`, is lacking 'F_ENROLLMENT_CASCADE_DELETE' authority to delete Enrollment : `{1}`. | There exists undeleted Events for this Enrollment. If the user does not have 'F_ENROLLMENT_CASCADE_DELETE' authority, then these Events has to be deleted first explicitly to be able to delete the Enrollment. |
| E1104 | User: `{0}`, has no data read access to program: `{1}`, TrackedEntityType: `{2}`. | The sharing configuration of the TrackedEntityType associated with the Program is such that, the user does not have data read access to it. |
| E1110 | Not allowed to update Event: `{0}`, existing Program `{1}`. | The Event payload for an existing Event has a different Program uid than the one it was originally created with.  |
| E1112 | Attribute value: `{0}`, is set to confidential but system is not properly configured to encrypt data. | Either JCE files is missing or the configuration property `encryption.password` might be missing in `dhis.conf`. |
| E1113 | Enrollment: `{0}`, is already deleted and can't be modified. | If the Enrollment is soft deleted, no modifications on it are allowed. |
| E1114 | TrackedEntity: `{0}`, is already deleted and can't be modified. | If the TrackedEntity is soft deleted, no modifications on it are allowed. |
| E1115 | Could not find CategoryOptionCombo: `{0}`. | |
| E1116 | Could not find CategoryOption: `{0}`. | This might also mean the CategoryOption is not accessible to the user.|
| E1117 | CategoryOptionCombo does not exist for given category combo and category options: `{0}`. | |
| E1118 | Assigned user `{0}` is not a valid uid. | |
| E1119 | A Tracker Note with uid `{0}` already exists. | |
| E1120 | ProgramStage `{0}` does not allow user assignment | Event payload has assignedUserId but the ProgramStage is not configured to allow user assignment. |
| E1121 | Missing required tracked entity property: `{0}`. | |
| E1122 | Missing required enrollment property: `{0}`. | |
| E1123 | Missing required event property: `{0}`. | |
| E1124 | Missing required relationship property: `{0}`. | |
| E1125 | Value `{0}` is not a valid option code in option set `{1}` | |
| E1126 | Not allowed to update Tracked Entity property: {0}. | |
| E1127 | Not allowed to update Enrollment property: {0}. | |
| E1128 | Not allowed to update Event property: {0}. | |
| E1300 | Generated by program rule (`{0}`) - `{1}` | |
| E1301 | Generated by program rule (`{0}`) - Mandatory DataElement `{1}` is not present | |
| E1302 | Generated by program rule (`{0}`) - DataElement `{1}` is not valid: `{2}` | |
| E1303 | Mandatory DataElement `{0}` is not present | |
| E1304 | Generated by program rule (`{0}`) - DataElement `{1}` is not a valid data element | |
| E1305 | Generated by program rule (`{0}`) - DataElement `{1}` is not part of `{2}` program stage | |
| E1306 | Generated by program rule (`{0}`) - Mandatory Attribute `{1}` is not present | |
| E1307 | Generated by program rule (`{0}`) - Unable to assign value to data element `{1}`. The provided value must be empty or match the calculated value `{2}` | |
| E1308 | Generated by program rule (`{0}`) - DataElement `{1}` is being replaced in event `{2}` | |
| E1309 | Generated by program rule (`{0}`) - Unable to assign value to attribute `{1}`. The provided value must be empty or match the calculated value `{2}` | |
| E1310 | Generated by program rule (`{0}`) - Attribute `{1}` is being replaced in te `{2}` | |
| E1311 | Referral events need to have at least one complete relationship | |
| E1312 | Referral events need to have both sides of a relationship | |
| E1313 | Event {0} of an enrollment does not point to an existing tracked entity. The data in your system might be corrupted | Indicates an anomaly in the existing data whereby enrollments might not reference a tracked entity |
| E1314 | Generated by program rule (`{0}`) - DataElement `{1}` is mandatory and cannot be deleted. | |
| E4000 | Relationship: `{0}` cannot link to itself | |
| E4001 | Relationship Item `{0}` for Relationship `{1}` is invalid: an Item can link only one Tracker entity. | |
| E4006 | Could not find relationship Type: `{0}`. | |
| E4010 | Relationship Type `{0}` constraint requires a {1} but a {2} was found. | |
| E4011 | Relationship: `{0}` cannot be persisted because {1} {2} referenced by this relationship is not valid. | |
| E4012 | Could not find `{0}`: `{1}`, linked to Relationship. | |
| E4014 | Relationship type `{0}` constraint requires a tracked entity having type `{1}` but `{2}` was found. | |
| E4015 | Relationship: `{0}`, already exists. | |
| E4016 | Relationship: `{0}`, do not exist. | |
| E4017 | Relationship: `{0}`, is already deleted and cannot be modified. | |
| E4018 | Relationship: `{0}`, linking {1}: `{2}` to {3}: `{4}` already exists. | |
| E4019 | User: `{0}`, has no data write access to relationship type: `{1}`. | |
| E5000 | "{0}" `{1}` cannot be persisted because "{2}" `{3}` referenced by it cannot be persisted. | The importer can't persist a tracker object because a reference cannot be persisted. |
| E5001 | "{0}" `{1}` cannot be deleted because "{2}" `{3}` referenced by it cannot be deleted. | The importer can't deleted a tracker object because a reference cannot be deleted. |
| E9999 | 不适用 | Undefined error message. |

### Validation { #webapi_tracker_validation }

While importing data using the tracker importer, a series of validations are performed to ensure the
validity of the data. This section will describe some of the different types of validation performed
to provide a better understanding if validation fails for your import.

#### Required properties { #required-properties } 

Each of the tracker objects has a few required properties that need to be present when importing
data. For an exhaustive list of required properties, have a look at the [Tracker Object
section](#webapi_tracker_objects).

When validating required properties, we are usually talking about references to other data or
metadata. In these cases, there are three main criteria:

1. The reference is present and not null in the payload.
2. The reference points to the correct type of data and exists in the database
3. The user has access to see the reference

If the first condition fails, the import will fail with a message about a missing reference.
However, suppose the reference points to something that doesn't exist or which the user cannot
access. In that case, both cases will result in a message about the reference not being found.

#### Formats { #formats } 

Some of the properties of tracker objects require a specific format. When importing data, each of
these properties is validated against the expected format and will return different errors depending
on which property has a wrong format. Some examples of properties that are validated this way:

- UIDs (These cover all references to other data or metadata in DHIS2.)
- Dates
- Geometry (The coordinates must match the format as specified by its type)

#### User access { #user-access } 

All data imported will be validated based on the metadata  ([Sharing](#webapi_tracker_metadata_sharing))
and the organisation units ([Organisation Unit Scopes](#webapi_tracker_orgunit_scope)) referenced in the
data. You can find more information about sharing and organisation unit scopes in the following
sections.

Sharing is validated at the same time as references are looked up in the database. Metadata outside
of the user's access will be treated as if it doesn't exist. The import will validate any metadata
referenced in the data.

Organisation units, on the other hand, serve a dual purpose. It will primarily make sure that data
can only be imported when imported for an organisation unit the user has within their "capture
scope". Secondly, organisation units are also used to restrict what programs are available. That
means if you are trying to import data for an organisation unit that does not have access to the
Program you are importing, the import will be invalid.

Users with the `ALL` authority will ignore the limits of sharing and organisation unit scopes when
they import data. However, they can not import enrollments in organisation units that do not have
access to the enrollment program.

#### Attribute and Data values { #attribute-and-data-values } 

Attributes and data values are part of a tracked entity and an event, respectively. However,
attributes can be linked to a tracked entity either through its type (TrackedEntityType) or its
Program (Program). Additionally, attributes can also be unique.

The initial validation done in the import is to make sure the value provided for an attribute or
data element conforms to the type of value expected. For example, suppose you import a value for a
data element with a numeric type. In that case, the value is expected to be numeric. Any errors
related to a mismatch between a type and a value will result in the same error code but with a
specific message related to the type of violation.

Mandatory attributes and data values are also checked on creation, on update mandatory attributes
and data values are not required in the payload. Currently, removing mandatory attributes and data values is
never allowed. Some use-cases require values to be sent separately, while others require all values to
be sent as one. Programs can be configured to either validate mandatory attributes `ON_COMPLETE` or
`ON_UPDATE_AND_INSERT` to accommodate these use-cases.

The import will validate unique attributes at the time of import. That means as long as the provided
value is unique for the attribute in the whole system, it will pass. However, if the unique value is
found to be used by any other tracked entity other than the one being imported, it will fail.

#### 组态 { #configuration } 

The last part of validations in the importer are validations based on the user's configuration of
relevant metadata. For more information about each configuration, check out the relevant sections.
Some examples of configurable validations:

- Feature type (For geometry)
- User-assignable events
- Allow future dates
- Enroll once
- And more.

These configurations will further change how validation is performed during import.

### Generated tracked entity attributes { #webapi_generate_te_attributes }

Tracked entity attributes that use automatic generation of unique values
have three endpoints utilized by apps for generating and reserving these values.
> More info on how TextPattern works can be found [here](https://docs.dhis2.org/en/use/user-guides/dhis-core-version-master/additional-information/dhis2-tutorials.html#working-with-textpattern)

#### Finding Required Values { #finding-required-values } 

A TextPattern may include variables that change based on different factors. Some of these factors are unknown to the server;
thus, the values for these variables must be supplied when generating and reserving values.

This endpoint returns a map of required and optional values that the server will inject into the TextPattern when generating new values.
Required variables must be supplied for generation, whereas optional variables should only be provided if necessary.

  GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/requiredValues

```json
{
  "REQUIRED": [
    "ORG_UNIT_CODE"
  ],
  "OPTIONAL": [
    "RANDOM"
  ]
}
```

####   Generate value endpoint { #webapi_generate_values }

Online web apps and other clients can use this endpoint to generate a unique value for immediate use.
The generated value is guaranteed to be unique at the time of generation and is reserved for 3 days.
If your TextPattern includes required values, they can be passed as parameters.

To override the expiration time, add `?expiration=<number-of-days>` to the request.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generate?ORG_UNIT_CODE=OSLO

```json
{
  "ownerObject": "TRACKEDENTITYATTRIBUTE",
  "ownerUid": "Gs1ICEQTPlG",
  "key": "RANDOM(X)-OSL",
  "value": "C-OSL",
  "created": "2018-03-02T12:01:36.680",
  "expiryDate": "2018-03-05T12:01:36.678"
}
```

#### 产生并保留价值终点 { #webapi_generate_reserve_values }

Offline clients can use this endpoint to reserve a number of unique IDs for later use when registering new tracked entity instances.
The number of IDs to generate can be specified with the `numberToReserve` parameter (default is 1).

To override the default expiration time of 60 days, add `?expiration=<number-of-days>` to the request.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generateAndReserve?numberToReserve=3&ORG_UNIT_CODE=OSLO

```json
[
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "B-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "Q-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "S-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  }
]
```

#### 保留值 { #reserved-values } 

目前无法通过 api 访问保留值，但是，它们
由`generate` 和`generateAndReserve` 端点返回。这
下表解释了保留值对象的属性：

Table: Reserved values

| Property | 描述 |
|---|---|
| ownerObject | The metadata type referenced when generating and reserving the value. Currently only TRACKEDENTITYATTRIBUTE is supported. |
| ownerUid | The uid of the metadata object referenced when generating and reserving the value. |
| key | A partially generated value where generated segments are not yet added. |
| 价值 | The fully resolved value reserved. This is the value you send to the server when storing data. |
| created | The timestamp when the reservation was made |
| expiryDate | The timestamp when the reservation will no longer be reserved |

过期的预订每天都会被删除。如果模式发生变化，则值
存储数据时将接受已经保留的数据，即使
它们与新模式不匹配，只要预订没有
已到期。

### Program Rules { #webapi_tracker_program_rules }

Users can configure [Program Rules](#webapi_program_rules), which adds conditional behavior to
tracker forms. In addition to running these rules in the tracker apps, the tracker importer will
also run a selection of these rules. Since the importer is also running these rules, we can ensure
an additional level of validation.

Not all program rule actions are supported since they are only suitable for a frontend presentation.
A complete list of the supported program rule actions is presented below.

  |Program Rule Action|支持的|
  |---|:---:|
  |**DISPLAYTEXT**| |
  |**DISPLAYKEYVALUEPAIR**| |
  |**HIDEFIELD**||
  |**HIDESECTION**||
  |**ASSIGN**|**X**|
  |**SHOWWARNING**|**X**|
  |**SHOWERROR**|**X**|
  |**WARNINGONCOMPLETION**|**X**|
  |**ERRORONCOMPLETION**|**X**|
  |**CREATEEVENT**||
  |**SETMANDATORYFIELD**|**X**|
  |**SENDMESSAGE**|**X**|
  |**SCHEDULEMESSAGE**|**X**|

Program rules are evaluated in the importer in the same way they are evaluated in the Tracker apps.
To summarize, the following conditions are considered when enforcing the program rules:

* The program rule must be linked to the data being imported. For example, a program stage or a data
元件。
* The Program rule's condition must be evaluated to true

The results of the program rules depend on the actions defined in those rules:

* Program rule actions may end in 2 different results: Warnings or Errors.
  * Errors will make the validation fail, while the warnings will be reported as a message in the
  import summary.
    * SHOWWARNING and WARNINGONCOMPLETION actions can generate only Warnings.
    * SHOWERROR, ERRORONCOMPLETION, and SETMANDATORYFIELD actions can generate only Errors.
    * ASSIGN action can generate both Warnings and Errors.
      * When the action is assigning a value to an empty attribute/data element, a warning is
      generated.
      * When the action is assigning a value to an attribute/data element that already has the same
      value to be assigned, a warning is generated.
      * When the action is assigning a value to an attribute/data element that already has a value
      and the value to be assigned is different, an error is generated unless the
      `RULE_ENGINE_ASSIGN_OVERWRITE` system setting is set to true.

Additionally, program rules can also result in side-effects, like send and schedule messages. More
information about side effects can be found in the following section.

> **NOTE**
>
> Program rules can be skipped during import using the `skipProgramRules` parameter.

### Side Effects { #webapi_tracker_side_effects }

After an import has been completed, specific tasks might be triggered as a result of the import.
These tasks are what we refer to as "Side effects". These tasks perform operations that do not
affect the import itself.

Side effects are tasks running detached from the import but are always triggered by an import. Since
side effects are detached from the import, they can fail even when the import is successful.
Additionally, side effects are only run when the import is successful, so they cannot fail the other
way around.

The following side effects are currently supported:

|Side Effects|支持的|描述|
|---|:---:|---|
|**Tracker Notification**|**X**| Updates can trigger notifications. Updates which trigger notifications are **enrollment**, **event update**, **event or enrollment completion**. |
|**ProgramRule Notification**|**X**| Program rules can trigger notifications. Note that these notifications are part of program rule effects which are generated through the DHIS2 rule engine.|

> **NOTE**
>
> Certain configurations can control the execution of side effects. `skipSideEffects` flag can be set during the import to skip side effects entirely. This parameter can be useful if you import something you don't want to trigger notifications for, as an example.

### Assign user to events { #webapi_tracker_user_event_assignment }

Specific workflows benefit from treating events like tasks, and for this reason, you can assign a
user to an event.

Assigning a user to an event will not change the access or permissions for users but will create a
link between the Event and the user. When an event has a user assigned, you can query events from
the API using the `assignedUser` field as a parameter.

When you want to assign a user to an event, you simply provide the UID of the user you want to
assign in the `assignedUser` field. See the following example:

```json
{
  ...
  "events": [
    {
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "enrollment": "MNWZ6hnuhSw",
      "assignedUser" : "M0fCOxtkURr"
    }
  ],
  ...
}
```

In this example, the user with uid `M0fCOxtkURr` will be assigned to the Event with uid
`ZwwuwNp6gVd`. Only one user can be assigned to a single event.

To use this feature, the relevant program stage needs to have user assignment enabled, and the uid
provided for the user must refer to a valid, existing user.

## Tracker Export { #webapi_tracker_export }

Tracker export endpoints allow you to retrieve the previously imported objects which are:

- **tracked entities**
- **events**
- **enrollments**
- **relationships**

> **NOTE**
>
> * All tracker export endpoints default to a `JSON` response content. `CSV` is only supported
>   by tracked entities and events.
> * You can export a CSV file by adding the `Accept` header ***text/csv*** or ***application/csv***
>   to the request.
> * You can download in zip and gzip formats:
>     *  CSV for Tracked entities
>     *  JSON and CSV for Events
> * You can export a Gzip file by adding the `Accept` header ***application/csv+gzip*** for CSV
> or ***application/json+gzip*** for JSON.
> * You can export a Zip file by adding the `Accept` header ***application/csv+zip*** for CSV or  
> ***application/json+zip*** for JSON.

### Common request parameters { #common-request-parameters } 

The following endpoint supports standard parameters for pagination.

- **Tracked entities** `GET /api/tracker/trackedEntities`
- **Events** `GET /api/tracker/events`
- **Enrollments** `GET /api/tracker/enrollments`
- **Relationships** `GET /api/tracker/relationships`

#### Request parameters for pagination { #request-parameters-for-pagination } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`page`|`Integer`|Any positive integer|Page number to return. Defaults to 1.|
|`pageSize`|`Integer`|Any positive integer|Page size. Defaults to 50.|
|`totalPages`|`Boolean`|`true`&#124;`false`|Indicates whether to return the total number of elements and pages. Defaults to `false` as getting the totals is an expensive operation.|
|`paging`|`Boolean`|`true`&#124;`false`|Indicates whether paging should be ignored and all rows should be returned. Defaults to `true`, meaning that by default all requests are paginated, unless `paging=false`.|
|`skipPaging` **deprecated for removal in version 42 use `paging`**|`Boolean`|`true`&#124;`false`|Indicates whether paging should be ignored and all rows should be returned. Defaults to `false`, meaning that by default all requests are paginated, unless `skipPaging=true`.|
|`order`|`String`|Comma-separated list of property name and sort direction pairs in format `propName:sortDirection`.<br><br>Example: `createdAt:desc`<br><br>Entities are ordered by newest (internal id desc) by default, meaning when no order parameter is provided.<br><br>**Note:** `propName` is case sensitive. Valid `sortDirections` are `asc` and `desc`. `sortDirection` is case-insensitive. `sortDirection` defaults to `asc` for properties or UIDs without explicit `sortDirection`.||

> **Caution**
>
> Be aware that the performance is directly related to the amount of data requested. Larger pages
> will take more time to return.

#### Request parameters for Organisational Unit selection mode { #request-parameters-for-organisational-unit-selection-mode } 

The available organisation unit selection modes are `SELECTED`, `CHILDREN`, `DESCENDANTS`,
`ACCESSIBLE`, `CAPTURE` and `ALL`. Each mode is explained in detail in [this
section](#webapi_tracker_orgunit_scope).

#### Request parameter to filter responses { #webapi_tracker_field_filter }

All export endpoints accept a `fields` parameter which controls which fields will be returned in the
JSON response. `fields` parameter accepts a comma separated list of field names or patterns. A few
possible `fields` filters are shown below. Refer to [Metadata field
filter](#webapi_metadata_field_filter) for a more complete guide on how to use `fields`.

##### 例子 { #examples } 

|Parameter example|Meaning|
|:---|:---|
|`fields=*`|returns all fields|
|`fields=createdAt,uid`|only returns fields `createdAt` and `uid`|
|`fields=enrollments[*,!uid]`|returns all fields of `enrollments` except `uid`|
|`fields=enrollments[uid]`|only returns `enrollments` field `uid`|
|`fields=enrollments[uid,enrolledAt]`|only returns `enrollments` fields `uid` and `enrolledAt`|

### Tracked Entities (`GET /api/tracker/trackedEntities`) { #tracked-entities-get-apitrackertrackedentities } 

Two endpoints are dedicated to tracked entities:

- `GET /api/tracker/trackedEntities`
  - retrieves tracked entities matching given criteria
- `GET /api/tracker/trackedEntities/{id}`
  - retrieves a tracked entity given the provided id

If not otherwise specified, JSON is the default response for the `GET` method.
The API also supports CSV export for single and collection endpoints. Furthermore, compressed
CSV types is an option for the collection endpoint.

#### CSV { #csv } 

In the case of CSV, the `fields` request parameter has no effect, and the response will always
contain the following fields:

  - trackedEntity (UID)
  - trackedEntityType (UID)
  - createdAt (Datetime)
  - createdAtClient (Datetime)
  - updatedAt (Datetime)
  - updatedAtClient (Datetime)
  - orgUnit (UID)
  - inactive (boolean)
  - deleted (boolean)
  - potentialDuplicate (boolean)
  - geometry (WKT, https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry.
    You can omit it in case of a `Point` type and with `latitude` and `longitude` provided)
  - latitude (Latitude of a `Point` type of Geometry)
  - longitude (Longitude of a `Point` type of Geometry)
  - attribute (UID)
  - displayName (String)
  - attrCreatedAt (Attribute creation Datetime)
  - attrUpdatedAt (Attribute last update Datetime)
  - valueType (String)
  - value (String)
  - storedBy (String)
  - createdBy (Username of user)
  - updatedBy (Username of user)

See [Tracked Entities](#tracked-entities) and [Attributes](#attributes) for more field descriptions.

#### GZIP { #gzip } 

The response is file `trackedEntities.csv.gz` containing the `trackedEntities.csv` file.

#### ZIP { #zip } 

The response is file `trackedEntities.csv.zip` containing the `trackedEntities.csv` file.

#### Tracked Entities Collection endpoint `GET /api/tracker/trackedEntities` { #tracked-entities-collection-endpoint-get-apitrackertrackedentities } 

The purpose of this endpoint is to retrieve tracked entities matching client-provided criteria.

The endpoint returns a list of tracked entities that match the request parameters.

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`filter`|`String`|Comma-separated values of attribute filters.|Narrows response to tracked entities matching given filters. A filter is a colon separated property or attribute UID with optional operator and value pairs. Example: `filter=H9IlTX2X6SL:sw:A` with operator starts with `sw` followed by a value. Special characters like `+` need to be percent-encoded so `%2B` instead of `+`. Characters such as `:` (colon) or `,` (comma), as part of the filter value, need to be escaped by `/` (slash). Likewise, `/` needs to be escaped. Multiple operator/value pairs for the same property/attribute like `filter=AuPLng5hLbE:gt:438901703:lt:448901704` are allowed. Repeating the same attribute UID is not allowed. User needs access to the attribute to filter on it.|
|`orgUnits`|`String`|Comma-separated list of organisation unit `UID`s.|Only return tracked entities belonging to provided organisation units|
|`orgUnit` **deprecated for removal in version 42 use `orgUnits`**|`String`|Semicolon-separated list of organisation units `UID`s.|Only return tracked entities belonging to provided organisation units.|
|`orgUnitMode` see [orgUnitModes](#webapi_tracker_orgunit_scope)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`ouMode` **deprecated for removal in version 42 use `orgUnitMode`** see [orgUnitModes](#webapi_tracker_orgunit_scope)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`program`|`String`|Program `UID`|A program `UID` for which tracked entities in the response must be enrolled into.|
|`programStatus` **deprecated for removal in version 43 use `enrollmentStatus`**|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The status of the tracked entities enrollment in the given program.|
|`programStage`|`String`|`UID`|A program stage `UID` for which tracked entities in the response must have events for.|
|`followUp`|`Boolean`|`true`&#124;`false`|Indicates whether the tracked entity is marked for follow up for the specified program.|
|`updatedAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Start date and time for last updated|
|`updatedBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | End date and time for last updated|
|`updatedWithin`|`Duration`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) | Returns tracked entities not older than specified Duration|
|`enrollmentStatus`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The status of the tracked entities enrollment in the given program.|
|`enrollmentEnrolledAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date and time for enrollment in the given program|
|`enrollmentEnrolledBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date and time for enrollment in the given program|
|`enrollmentOccurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date and time and time and time for occurred in the given program|
|`enrollmentOccurredBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date and time and time for occurred in the given program|
|`trackedEntityType`|`String`|UID of tracked entity type|Only returns tracked entities of given type.|
|`trackedEntities`|`String`|Comma-separated list of tracked entity `UID`s.|Filter the result down to a limited set of tracked entities using explicit uids of the tracked entities by using `trackedEntity=id1,id2`. This parameter will, at the very least, create the outer boundary of the results, forming the list of all tracked entities using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary.|
|`trackedEntity` **deprecated for removal in version 42 use `trackedEntities`**|`String`|Semicolon-separated list of tracked entity `UID`s.|Filter the result down to a limited set of tracked entities using explicit uids of the tracked entities by using `trackedEntity=id1;id2`. This parameter will, at the very least, create the outer boundary of the results, forming the list of all tracked entities using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary.|
|`assignedUserMode`|`String`|`CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`|Restricts result to tracked entities with events assigned based on the assigned user selection mode. See table below "Assigned user modes" for explanations. |
|`assignedUsers`|`String`|Comma-separated list of user UIDs to filter based on events assigned to the users.|Filter the result down to a limited set of tracked entities with events that are assigned to the given user IDs by using `assignedUser=id1,id2`. This parameter will only be considered if `assignedUserMode` is either `PROVIDED` or `null`. The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`.|
|`assignedUser` **deprecated for removal in version 42 use `assignedUsers`**|`String`|Semicolon-separated list of user UIDs to filter based on events assigned to the users.|Filter the result down to a limited set of tracked entities with events that are assigned to the given user IDs by using `assignedUser=id1;id2`.This parameter will only be considered if assignedUserMode is either `PROVIDED` or `null`. The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`|
|`order`|`String`|Comma-separated list of property name or attribute or UID and sort direction pairs in format `propName:sortDirection`.|Supported values are `createdAt, createdAtClient, enrolledAt, inactive, trackedEntity, updatedAt, updatedAtClient`.|
|`eventStatus`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`VISITED`&#124;`SCHEDULE`&#124;`OVERDUE`&#124;`SKIPPED`|Status of any events in the specified program|
|`eventOccurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date and time for Event for the given Program|
|`eventOccurredBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date and time for Event for the given Program|
|`includeDeleted`|`Boolean`|`true`&#124;`false`|Indicates whether to include soft-deleted elements|
|`potentialDuplicate`|`Boolean`|`true`&#124;`false`| Filter the result based on the fact that a tracked entities is a Potential Duplicate. true: return tracked entities flagged as Potential Duplicates. false: return tracked entities NOT flagged as Potential Duplicates. If omitted, we don't check whether a tracked entities is a Potential Duplicate or not. |

The available assigned user modes are explained in the following table.

Table: Assigned user modes

| Mode | 描述 |
|---|---|
| CURRENT | Includes events assigned to the current logged in user. |
| PROVIDED | Includes events assigned to the user provided in the request. |
| NONE | Includes unassigned events only. |
| ANY | Includes all assigned events, doesn't matter who are they assigned to as long as they assigned to someone. |

查询不区分大小写。以下规则适用于查询
参数。

- At least one organisation unit must be specified using the `orgUnit`
  parameter (one or many), or `orgUnitMode=ALL` must be specified.

- Only one of the `program` and `trackedEntity` parameters can be
  指定（零或一）。

- If `programStatus` is specified, then `program` must also be specified.

- If `enrollmentStatus` is specified, then `program` must also be specified.

- If `followUp` is specified, then `program` must also be specified.

- If `enrollmentEnrolledAfter` or `enrollmentEnrolledBefore` is specified then
  `program` must also be specified.

- 过滤器项目只能指定一次。

##### Example requests { #example-requests } 

A query for all tracked entities associated with a specific organisation unit and program can look
like this:

    GET /api/tracker/trackedEntities?program=IpHINAT79UW&orgUnits=DiszpKrYNg8

To query for tracked entities using one attribute with a filter and one attribute without a filter,
with one organisation unit using the descendant organisation unit query mode:

    GET /api/tracker/trackedEntities?program=IpHINAT79UW&orgUnits=DiszpKrYNg8&filter=w75KJ2mc4zz:EQ:John

为过滤器指定了多个操作数和过滤器的查询
物品：

    GET /api/tracker/trackedEntities?orgUnits=DiszpKrYNg8&program=ur1Edk5Oe2n&filter=lw1SqmMlnfh:GT:150&filter=lw1SqmMlnfh:LT:190

A query filter with a value that needs escaping and will be interpreted as `:,/`:

    GET /api/tracker/trackedEntities?orgUnits=DiszpKrYNg8&program=ur1Edk5Oe2n&filter=lw1SqmMlnfh:EQ:/:/,//

要将程序注册日期指定为查询的一部分，请执行以下操作：

    GET /api/tracker/trackedEntities?orgUnits=DiszpKrYNg8&program=IpHINAT79UW&fields=trackedEntity,enrollments[enrolledAt]&enrollmentEnrolledAfter=2024-01-01

要在 *IN* 过滤器中使用多个值查询属性：

    GET /api/tracker/trackedEntities?trackedEntityType=nEenWmSyUEp&orgUnits=DiszpKrYNg8&filter=w75KJ2mc4zz:IN:Scott;Jimmy;Santiago

您可以使用一系列运算符进行过滤：

|Operator|  描述|
|---|---|
|`EQ`|Equal to|
|`GE`|Greater than or equal to|
|`GT`|Greater than|
|`IN`|Equal to one of the multiple values separated by ";"|
|`LE`|Less than or equal to|
|`LIKE`|Like (free text match)|
|`LT`|Less than|
|`NE`|Not equal to|

##### Tracked Entities response example { #tracked-entities-response-example } 

The API supports CSV and JSON response for `GET /api/tracker/trackedEntities`.

##### JSON { #json } 

Responses can be filtered on desired fields, see [Request parameter to filter
responses](#webapi_tracker_field_filter)

A JSON response can look like the following:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 1
  },
  "trackedEntities": [
    {
      "trackedEntity": "F8yKM85NbxW",
      "trackedEntityType": "Zy2SEgA61ys",
      "createdAt": "2019-08-21T13:25:38.022",
      "createdAtClient": "2019-03-19T01:12:16.624",
      "updatedAt": "2019-08-21T13:31:33.410",
      "updatedAtClient": "2019-03-19T01:12:16.624",
      "orgUnit": "DiszpKrYNg8",
      "inactive": false,
      "deleted": false,
      "potentialDuplicate": false,
      "geometry": {
        "type": "Point",
        "coordinates": [
          -11.7896,
          8.2593
        ]
      },
      "attributes": [
        {
          "attribute": "B6TnnFMgmCk",
          "displayName": "Age (years)",
          "createdAt": "2019-08-21T13:25:38.477",
          "updatedAt": "2019-08-21T13:25:38.477",
          "storedBy": "braimbault",
          "valueType": "INTEGER_ZERO_OR_POSITIVE",
          "value": "30"
        },
        {
          "attribute": "TfdH5KvFmMy",
          "displayName": "First Name",
          "createdAt": "2019-08-21T13:25:38.066",
          "updatedAt": "2019-08-21T13:25:38.067",
          "storedBy": "josemp10",
          "valueType": "TEXT",
          "value": "Sarah"
        },
        {
          "attribute": "aW66s2QSosT",
          "displayName": "Last Name",
          "createdAt": "2019-08-21T13:25:38.388",
          "updatedAt": "2019-08-21T13:25:38.388",
          "storedBy": "karoline",
          "valueType": "TEXT",
          "value": "Johnson"
        }
      ]
    }
  ]
}
```

##### CSV { #csv } 

A CSV response can look like the following:

```
trackedEntity,trackedEntityType,createdAt,createdAtClient,updatedAt,updatedAtClient,orgUnit,inactive,deleted,potentialDuplicate,geometry,latitude,longitude,storedBy,createdBy,updatedBy,attrCreatedAt,attrUpdatedAt,attribute,displayName,value,valueType
F8yKM85NbxW,Zy2SEgA61ys,2019-08-21T11:25:38.022Z,2019-03-19T00:12:16.624Z,2019-08-21T11:31:33.410Z,2019-03-19T00:12:16.624Z,DiszpKrYNg8,false,false,false,"POINT (-11.7896 8.2593)",8.2593,-11.7896,,,,2019-08-21T11:25:38.477Z,2019-08-21T11:25:38.477Z,B6TnnFMgmCk,"Age (years)",30,INTEGER_ZERO_OR_POSITIVE
F8yKM85NbxW,Zy2SEgA61ys,2019-08-21T11:25:38.022Z,2019-03-19T00:12:16.624Z,2019-08-21T11:31:33.410Z,2019-03-19T00:12:16.624Z,DiszpKrYNg8,false,false,false,"POINT (-11.7896 8.2593)",8.2593,-11.7896,,,,2019-08-21T11:25:38.066Z,2019-08-21T11:25:38.067Z,TfdH5KvFmMy,"First Name",Sarah,TEXT
F8yKM85NbxW,Zy2SEgA61ys,2019-08-21T11:25:38.022Z,2019-03-19T00:12:16.624Z,2019-08-21T11:31:33.410Z,2019-03-19T00:12:16.624Z,DiszpKrYNg8,false,false,false,"POINT (-11.7896 8.2593)",8.2593,-11.7896,,,,2019-08-21T11:25:38.388Z,2019-08-21T11:25:38.388Z,aW66s2QSosT,"Last Name",Johnson,TEXT
```

#### Tracked Entities single object endpoint `GET /api/tracker/trackedEntities/{uid}`

The purpose of this endpoint is to retrieve one tracked entity given its uid.

##### 请求语法 { #request-syntax } 

`GET /api/tracker/trackedEntities/{uid}?program={programUid}&fields={fields}`

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`uid`|`String`|`uid`|Return the tracked entity with specified `uid`|
|`program`|`String`|`uid`| Include program attributes in the response (only the ones user has access to) |
|`fields`|`String`| Any valid field filter (default `*,!relationships,!enrollments,!events,!programOwners`) |Include specified sub-objects in the response|

##### Example requests { #example-requests } 

A query for a tracked entity:

    GET /api/tracker/trackedEntities/PQfMcpmXeFE

##### Tracked Entity response example { #tracked-entity-response-example } 

The API supports CSV and JSON response for `GET /api/tracker/trackedEntities/{uid}`

###### JSON { #json } 

An example of a json response:

```json
{
  "trackedEntity": "PQfMcpmXeFE",
  "trackedEntityType": "nEenWmSyUEp",
  "createdAt": "2014-03-06T05:49:28.256",
  "createdAtClient": "2014-03-06T05:49:28.256",
  "updatedAt": "2016-08-03T23:49:43.309",
  "orgUnit": "DiszpKrYNg8",
  "inactive": false,
  "deleted": false,
  "potentialDuplicate": false,
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "code": "MMD_PER_NAM",
      "displayName": "First name",
      "createdAt": "2016-08-03T23:49:43.308",
      "updatedAt": "2016-08-03T23:49:43.308",
      "valueType": "TEXT",
      "value": "John"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "displayName": "Last name",
      "createdAt": "2016-08-03T23:49:43.309",
      "updatedAt": "2016-08-03T23:49:43.309",
      "valueType": "TEXT",
      "value": "Kelly"
    }
  ],
  "enrollments": [
    {
      "enrollment": "JMgRZyeLWOo",
      "createdAt": "2017-03-06T05:49:28.340",
      "createdAtClient": "2016-03-06T05:49:28.340",
      "updatedAt": "2017-03-06T05:49:28.357",
      "trackedEntity": "PQfMcpmXeFE",
      "program": "IpHINAT79UW",
      "status": "ACTIVE",
      "orgUnit": "DiszpKrYNg8",
      "enrolledAt": "2024-03-06T00:00:00.000",
      "occurredAt": "2024-03-04T00:00:00.000",
      "followUp": false,
      "deleted": false,
      "events": [
        {
          "event": "Zq2dg6pTNoj",
          "status": "ACTIVE",
          "program": "IpHINAT79UW",
          "programStage": "ZzYYXq4fJie",
          "enrollment": "JMgRZyeLWOo",
          "trackedEntity": "PQfMcpmXeFE",
          "relationships": [],
          "scheduledAt": "2023-03-10T00:00:00.000",
          "followUp": false,
          "deleted": false,
          "createdAt": "2017-03-06T05:49:28.353",
          "createdAtClient": "2016-03-06T05:49:28.353",
          "updatedAt": "2017-03-06T05:49:28.353",
          "attributeOptionCombo": "HllvX50cXC0",
          "attributeCategoryOptions": "xYerKDKCefk",
          "dataValues": [],
          "notes": [],
          "followup": false
        }
      ],
      "relationships": [],
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "code": "MMD_PER_NAM",
          "displayName": "First name",
          "createdAt": "2016-08-03T23:49:43.308",
          "updatedAt": "2016-08-03T23:49:43.308",
          "valueType": "TEXT",
          "value": "John"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "displayName": "Last name",
          "createdAt": "2016-08-03T23:49:43.309",
          "updatedAt": "2016-08-03T23:49:43.309",
          "valueType": "TEXT",
          "value": "Kelly"
        },
        {
          "attribute": "AuPLng5hLbE",
          "code": "National identifier",
          "displayName": "National identifier",
          "createdAt": "2016-08-03T23:49:43.301",
          "updatedAt": "2016-08-03T23:49:43.301",
          "valueType": "TEXT",
          "value": "245435245"
        },
        {
          "attribute": "ruQQnf6rswq",
          "displayName": "TB number",
          "createdAt": "2016-08-03T23:49:43.308",
          "updatedAt": "2016-08-03T23:49:43.308",
          "valueType": "TEXT",
          "value": "1Z 1F2 A84 59 4464 173 6"
        },
        {
          "attribute": "cejWyOfXge6",
          "displayName": "Gender",
          "createdAt": "2016-08-03T23:49:43.307",
          "updatedAt": "2016-08-03T23:49:43.307",
          "valueType": "TEXT",
          "value": "Male"
        },
        {
          "attribute": "VqEFza8wbwA",
          "code": "MMD_PER_ADR1",
          "displayName": "Address",
          "createdAt": "2016-08-03T23:49:43.307",
          "updatedAt": "2016-08-03T23:49:43.307",
          "valueType": "TEXT",
          "value": "Main street 2"
        }
      ],
      "notes": []
    }
  ],
  "programOwners": [
    {
      "orgUnit": "DiszpKrYNg8",
      "trackedEntity": "PQfMcpmXeFE",
      "program": "ur1Edk5Oe2n"
    },
    {
      "orgUnit": "DiszpKrYNg8",
      "trackedEntity": "PQfMcpmXeFE",
      "program": "IpHINAT79UW"
    }
  ]
}
```

###### CSV { #csv } 

The response will be the same as the collection endpoint but referring to a single tracked
entity, although it might have multiple rows for each attribute.

#### Tracked entity attribute value change logs { #webapi_tracker_attribute_change_logs }
`GET /api/tracker/trackedEntities/{uid}/changeLogs`

This endpoint retrieves change logs for the attributes of a specific tracked entity. It returns a list of all tracked entity attributes that have changed over time for that entity.

|Parameter|类型|Allowed values|
|---|---|---|
|path `/{uid}`|`String`|Tracked entity `UID`.|
|`program`|`String`|Program `UID` (optional).|

##### Tracked entity attribute value change logs response example { #tracked-entity-attribute-value-change-logs-response-example } 

An example of a json response:

```json
{
   "pager":{
      "page":1,
      "pageSize":10
   },
   "changeLogs":[
      {
         "createdBy":{
            "uid":"AIK2aQOJIbj",
            "username":"tracker",
            "firstName":"Tracker demo",
            "surname":"User"
         },
         "createdAt":"2024-06-20T14:51:16.433",
         "type":"UPDATE",
         "change":{
            "dataValue":{
               "dataElement":"bx6fsa0t90x",
               "previousValue":"true",
               "currentValue":"false"
            }
         }
      },
      {
         "createdBy":{
            "uid":"AIK2aQOJIbj",
            "username":"tracker",
            "firstName":"Tracker demo",
            "surname":"User"
         },
         "createdAt":"2024-06-20T14:50:32.966",
         "type":"CREATE",
         "change":{
            "dataValue":{
               "dataElement":"ebaJjqltK5N",
               "currentValue":"0"
            }
         }
      }
   ]
}
```

The change log type can be `CREATE`, `UPDATE`, or `DELETE`.
`CREATE` and `DELETE` will always hold a single value: the former shows the current value, and the latter shows the value that was deleted. UPDATE will hold two values: the previous and the current.

### Enrollments (`GET /api/tracker/enrollments`) { #enrollments-get-apitrackerenrollments } 

Two endpoints are dedicated to enrollments:

- `GET /api/tracker/enrollments`
    - retrieves enrollments matching given criteria
- `GET /api/tracker/enrollments/{id}`
    - retrieves an enrollment given the provided id

#### Enrollment Collection endpoint `GET /api/tracker/enrollments` { #enrollment-collection-endpoint-get-apitrackerenrollments } 

Returns a list of events based on filters.

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`orgUnits`|`String`|Comma-separated list of organisation unit `UID`s.|Only return enrollments belonging to provided organisation units.|
|`orgUnit` **deprecated for removal in version 42 use `orgUnits`**|`String`|Semicolon-separated list of organisation units `UID`s.|Only return enrollments belonging to provided organisation units.|
|`orgUnitMode` see [orgUnitModes](#webapi_tracker_orgunit_scope)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`ouMode` **deprecated for removal in version 42 use `orgUnitMode`** see [orgUnitModes](#webapi_tracker_orgunit_scope)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`program`|`String`|`uid`| Identifier of program|
|`programStatus` **deprecated for removal in version 43 use `status`**|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The status of the enrollment.|
|`status`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The status of the enrollment.|
|`followUp`|`boolean`| `true`&#124;`false` | Follow up status of the tracked entity for the given program. Can be `true`&#124;`false` or omitted.|
|`updatedAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Only enrollments updated after this date|
|`updatedWithin`|`Duration`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only enrollments updated since given duration |
|`enrolledAfter`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|  Only enrollments newer than this date|
|`enrolledBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only enrollments older than this date|
|`trackedEntityType`|`String`|`uid`| Identifier of tracked entity type|
|`trackedEntity`|`String`|`uid`| Identifier of tracked entity|
|`order`|`String`|Comma-separated list of property name or attribute or UID and sort direction pairs in format `propName:sortDirection`.|Supported fields: `completedAt, createdAt, createdAtClient, enrolledAt, updatedAt, updatedAtClient`.|
|`enrollments`|`String`|Comma-separated list of enrollment `UID`s.|Filter the result down to a limited set of IDs by using `enrollments=id1,id2`.|
|`enrollment` **deprecated for removal in version 42 use `enrollments`**|`String`|Semicolon-separated list of `uid`|Filter the result down to a limited set of IDs by using `enrollment=id1;id2`.|
|`includeDeleted`|`Boolean`| |When true, soft deleted events will be included in your query result.|

The query is case-insensitive. The following rules apply to the query parameters.

- At least one organisation unit must be specified using the `orgUnit` parameter (one or many), or
*orgUnitMode=ALL* must be specified.

- Only one of the *program* and *trackedEntity* parameters can be specified (zero or one).

- If *programStatus* is specified, then *program* must also be specified.
- If *enrollmentStatus* is specified, then *program* must also be specified.

- If *followUp* is specified, then *program* must also be specified.

- If *enrolledAfter* or *enrolledBefore* is specified, then *program* must also be specified.

##### Example requests { #example-requests } 

查询与特定组织单位关联的所有注册
看起来像这样：

    GET /api/tracker/enrollments?orgUnits=DiszpKrYNg8

To constrain the response to enrollments which are part of a specific program you can include a
program query parameter:

    GET /api/tracker/enrollments?orgUnits=O6uvpzGd5pu&orgUnitMode=DESCENDANTS&program=ur1Edk5Oe2n

要将程序注册日期指定为查询的一部分，请执行以下操作：

    GET /api/tracker/enrollments?orgUnits=DiszpKrYNg8&program=M3xtLkYBlKI&enrolledAfter=2023-11-14&enrolledBefore=2024-02-07

To constrain the response to enrollments of a specific tracked entity you can include a tracked
entity query parameter:

    GET /api/tracker/enrollments?trackedEntity=ClJ3fn47c4s

To constrain the response to enrollments of a specific tracked entity you can include a tracked
entity query parameter, in In this case, we have restricted it to available enrollments viewable for
current user:

    GET /api/tracker/enrollments?orgUnitMode=ACCESSIBLE&trackedEntity=tphfdyIiVL6

##### 回应格式 { #response-format } 

The `JSON` response can look like the following.

```json
{
  "pager": {
    "page": 1,
    "pageSize": 1
  },
  "enrollments": [
    {
      "enrollment": "TRE0GT7eh7Q",
      "createdAt": "2019-08-21T13:28:00.056",
      "createdAtClient": "2018-11-13T15:06:49.009",
      "updatedAt": "2019-08-21T13:29:44.942",
      "updatedAtClient": "2019-08-21T13:29:44.942",
      "trackedEntity": "s4NfKOuayqG",
      "program": "M3xtLkYBlKI",
      "status": "COMPLETED",
      "orgUnit": "DiszpKrYNg8",
      "enrolledAt": "2023-11-13T00:00:00.000",
      "occurredAt": "2023-11-13T00:00:00.000",
      "followUp": false,
      "deleted": false,
      "storedBy": "healthworker1",
      "notes": []
    }
  ]
}
```

#### Enrollments single object endpoint `GET /api/tracker/enrollments/{uid}`

The purpose of this endpoint is to retrieve one Enrollment given its uid.

##### 请求语法 { #request-syntax } 

`GET /api/tracker/enrollment/{uid}`

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`uid`|`String`|`uid`|Return the Enrollment with specified `uid`|
|`fields`|`String`| Any valid field filter (default `*,!relationships,!events,!attributes`) |Include
specified sub-objects in the response|

##### Example requests { #example-requests } 

A query for an enrollment:

    GET /api/tracker/enrollments/JMgRZyeLWOo

##### 回应格式 { #response-format } 

```json
{
  "enrollment": "JMgRZyeLWOo",
  "createdAt": "2017-03-06T05:49:28.340",
  "createdAtClient": "2016-03-06T05:49:28.340",
  "updatedAt": "2017-03-06T05:49:28.357",
  "trackedEntity": "PQfMcpmXeFE",
  "program": "IpHINAT79UW",
  "status": "ACTIVE",
  "orgUnit": "DiszpKrYNg8",
  "enrolledAt": "2024-03-06T00:00:00.000",
  "occurredAt": "2024-03-04T00:00:00.000",
  "followUp": false,
  "deleted": false,
  "notes": []
}
```

### Events (`GET /api/tracker/events`) { #events-get-apitrackerevents } 

Two endpoints are dedicated to events:

- `GET /api/tracker/events`
    - retrieves events matching given criteria
- `GET /api/tracker/events/{id}`
    - retrieves an event given the provided id

If not otherwise specified, JSON is the default response for the `GET` method.
The API also supports CSV export for single and collection endpoints. Furthermore, it supports
compressed JSON and CSV for the collection endpoint.

#### Events CSV { #events-csv } 

In the case of CSV, the `fields` request parameter has no effect, and the response will always
contain the following fields:

  - event (UID)
  - status (String)
  - program (UID)
  - programStage (UID)
  - enrollment (UID)
  - orgUnit (UID)
  - occurredAt (DateTime)
  - scheduledAt (DateTime)
  - geometry (WKT, https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry.
    You can omit it in case of a `Point` type and with `latitude` and `longitude` provided)
  - latitude (Latitude of a `Point` type of Geometry)
  - longitude (Longitude of a `Point` type of Geometry)
  - followUp (boolean)
  - deleted (boolean)
  - createdAt (DateTime)
  - createdAtClient (DateTime)
  - updatedAt (DateTime)
  - updatedAtClient (DateTime)
  - completedBy (String)
  - completedAt (DateTime)
  - updatedBy (UserName of user)
  - attributeOptionCombo (UID)
  - attributeCategoryOptions (UID)
  - assignedUser (UserName of user)
  - dataElement (UID)
  - value (String)
  - storedBy (String)
  - providedElsewhere (boolean)
  - storedByDataValue (String)
  - createAtDataValue (DateTime)
  - updatedAtDataValue (DateTime)

See [Events](#events) and [Data Values](#data-values) for more field descriptions.

#### Events GZIP { #events-gzip } 

The response is file `events.json.gz` or `events.csv.gzip` containing the `events.json`
or `events.csv` file.

#### Events ZIP { #events-zip } 

The response is file`events.json.gz` or `events.json.zip` containing the `events.json`
or `events.csv` file.

#### Events Collection endpoint `GET /api/tracker/events` { #events-collection-endpoint-get-apitrackerevents } 

Returns a list of events based on the provided filters.

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`program`|`String`|`uid`| Identifier of program|
|`programStage`|`String`|`uid`| Identifier of program stage|
|`programStatus` **deprecated for removal in version 43 use `enrollmentStatus`**|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The status of the events enrollment.|
|`filter`|`String`|Comma separated values of data element filters|Narrows response to events matching given filters. A filter is a colon separated property or data element UID with optional operator and value pairs. Example: `filter=fazCI2ygYkq:eq:PASSIVE` with operator starts with `eq` followed by a value. Characters such as `:` (colon) or `,` (comma), as part of the filter value, need to be escaped by `/` (slash). Likewise, `/` needs to be escaped. Multiple operator/value pairs for the same property/data element like `filter=qrur9Dvnyt5:gt:70:lt:80` are allowed. Repeating the same data element UID is not allowed. User needs access to the data element to filter on it.|
|`filterAttributes`|`String`|Comma separated values of attribute filters|Narrows response to tracked entities matching given filters. A filter is a colon separated property or attribute UID with optional operator and value pairs. Example: `filter=H9IlTX2X6SL:sw:A` with operator starts with `sw` followed by a value. Special characters like `+` need to be percent-encoded so `%2B` instead of `+`. Characters such as `:` (colon) or `,` (comma), as part of the filter value, need to be escaped by `/` (slash). Likewise, `/` needs to be escaped. Multiple operator/value pairs for the same property/attribute like `filter=AuPLng5hLbE:gt:438901703:lt:448901704` are allowed. Repeating the same attribute UID is not allowed. User needs access to the attribute to filter on it.|
|`followUp`|`boolean`| `true`&#124;`false` | Whether event is considered for follow up in program. Defaults to `true`|
|`trackedEntity`|`String`|`uid`|Identifier of tracked entity|
|`orgUnit`|`String`|`uid`|Identifier of organisation unit|
|`orgUnitMode` see [orgUnitModes](#webapi_tracker_orgunit_scope)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`ouMode` **deprecated for removal in version 42 use `orgUnitMode`** see [orgUnitModes](#webapi_tracker_orgunit_scope)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`status`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`VISITED`&#124;`SCHEDULE`&#124;`OVERDUE`&#124;`SKIPPED` | Status of event|
|`occurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which occurred after this date.|
|`occurredBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which occurred up until this date.|
|`scheduledAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were scheduled after this date.|
|`scheduledBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were scheduled before this date.|
|`updatedAfter`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were updated after this date. Cannot be used together with `updatedWithin`.|
|`updatedBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were updated up until this date. Cannot be used together with `updatedWithin`.|
|`updatedWithin`|`Duration`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations)| Include only items which are updated within the given duration.<br><br> The format is [ISO-8601#Duration](https://en.wikipedia.org/wiki/ISO_8601#Durations)|
|`enrollmentStatus`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The status of the events enrollment.|
|`enrollmentEnrolledAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date and time for enrollment in the given program|
|`enrollmentEnrolledBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date and time for enrollment in the given program|
|`enrollmentOccurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date and time for occurred in the given program|
|`enrollmentOccurredBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date and time for occurred in the given program|
|`dataElementIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Data element ID scheme to use for export.|
|`categoryOptionComboIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Category Option Combo ID scheme to use for export|
|`orgUnitIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Organisation Unit ID scheme to use for export|
|`programIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Program ID scheme to use for export|
|`programStageIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Program Stage ID scheme to use for export|
|`idScheme`|`string`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Allows to set id scheme for data element, category option combo, orgUnit, program and program stage at once.|
|`order`|`String`|Comma-separated list of property name, attribute or data element UID and sort direction pairs in format `propName:sortDirection`.|Supported fields: `assignedUser, assignedUserDisplayName, attributeOptionCombo, completedAt, completedBy, createdAt, createdAtClient, createdBy, deleted, enrolledAt, enrollment, enrollmentStatus, event, followUp, followup (deprecated), occurredAt, orgUnit, program, programStage, scheduledAt, status, storedBy, trackedEntity, updatedAt, updatedAtClient, updatedBy`.|
|`events`|`String`|Comma-separated list of event `UID`s.|Filter the result down to a limited set of IDs by using `event=id1,id2`.|
|`event` **deprecated for removal in version 42 use `events`**|`String`|Semicolon-separated list of `uid`| Filter the result down to a limited set of IDs by using `event=id1;id2`.|
|`attributeCategoryCombo` (see note)|`String`|Attribute category combo identifier. Must be combined with `attributeCategoryOptions`.|
|`attributeCc` **deprecated for removal in version 42 use `attributeCategoryCombo`**|`String`|Attribute category combo identifier (must be combined with attributeCos)|
|`attributeCategoryOptions` (see note)|`String`|Comma-separated attribute category option identifiers. Must be combined with `attributeCategoryCombo`.|
|`attributeCos` **deprecated for removal in version 42 use `attributeCategoryOptions`**|`String`|Semicolon-separated attribute category option identifiers. Must be combined with `attributeCc`.|
|`includeDeleted`|`Boolean`| |  When true, soft deleted events will be included in your query result.|
|`assignedUserMode`|`String`| `CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`| Assigned user selection mode|
|`assignedUsers`|`String`|Comma-separated list of user UIDs to filter based on events assigned to the users.|Filter the result down to a limited set of tracked entities with events that are assigned to the given user IDs by using `assignedUser=id1,id2`.This parameter will only be considered if `assignedUserMode` is either `PROVIDED` or `null`. The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`.|
|`assignedUser` **deprecated for removal in version 42 use `assignedUsers`**|`String`|Semicolon-separated list of user UIDs to filter based on events assigned to the users.|Filter the result down to a limited set of tracked entities with events that are assigned to the given user IDs by using `assignedUser=id1;id2`.This parameter will only be considered if assignedUserMode is either `PROVIDED` or `null`. The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`|

> **Note**
>
> If the query contains neither `attributeCategoryOptions` nor `attributeCategoryOptions`,
> the server returns events for all attribute option combos where the user has read access.

##### Example requests { #example-requests } 

The query for all events with children of a particular organisation unit:

    GET /api/tracker/events?orgUnit=YuQRtpLP10I&orgUnitMode=CHILDREN

The query for all events with all descendants of a particular organisation unit, implying all
organisation units in the sub-hierarchy:

    GET /api/tracker/events?orgUnit=O6uvpzGd5pu&orgUnitMode=DESCENDANTS

使用特定程序和组织单位查询所有事件：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

Query for all events with a certain program and organisation unit, sorting by scheduled date
ascending:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=scheduledAt

Query for the 10 events with the newest occurred date in a certain program and organisation unit -
by paging and ordering by occurred date descending:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=occurredAt:desc&pageSize=10&page=1

Query for all events with a certain program and organisation unit for a specific tracked entity:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=M3xtLkYBlKI&trackedEntity=dNpxRu1mWG5

Query for all events older or equal to 2024-02-03 and associated with a program and organisation
unit:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&occurredBefore=2024-02-03

A query where multiple operand and filters are specified for a data element UID:

    GET /api/tracker/events?orgUnit=g8upMTyEZGZ&program=M3xtLkYBlKI&filter=rFQNCGMYud2:GT:35&filter=rFQNCGMYud2:LT:50

A query filter with a value that needs escaping and will be interpreted as `:,/`:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&filter=DanTR5x0WDK:EQ:/:/,//

##### Events response example { #events-response-example } 

The API supports CSV and JSON response for `GET /api/tracker/events`.

###### JSON { #json } 

The JSON response can look like the following:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 1
  },
  "events": [
    {
      "event": "A7rzcnZTe2T",
      "status": "ACTIVE",
      "program": "eBAyeGv0exc",
      "programStage": "Zj7UnCAulEk",
      "enrollment": "RiLEKhWHlxZ",
      "orgUnit": "DwpbWkiqjMy",
      "occurredAt": "2023-02-13T00:00:00.000",
      "scheduledAt": "2023-02-13T00:00:00.000",
      "followUp": false,
      "deleted": false,
      "createdAt": "2017-09-08T21:40:22.000",
      "createdAtClient": "2016-09-08T21:40:22.000",
      "updatedAt": "2017-09-08T21:40:22.000",
      "attributeOptionCombo": "HllvX50cXC0",
      "attributeCategoryOptions": "xYerKDKCefk",
      "geometry": {
        "type": "Point",
        "coordinates": [
          -11.468912037323042,
          7.515913998868316
        ]
      },
      "dataValues": [
        {
          "createdAt": "2016-12-06T18:22:34.438",
          "updatedAt": "2016-12-06T18:22:34.438",
          "storedBy": "bjorn",
          "providedElsewhere": false,
          "dataElement": "F3ogKBuviRA",
          "value": "[-11.4880220438585,7.50978830548003]"
        },
        {
          "createdAt": "2013-12-30T14:23:57.423",
          "updatedAt": "2013-12-30T14:23:57.423",
          "storedBy": "lars",
          "providedElsewhere": false,
          "dataElement": "eMyVanycQSC",
          "value": "2018-02-07"
        },
        {
          "createdAt": "2013-12-30T14:23:57.382",
          "updatedAt": "2013-12-30T14:23:57.382",
          "storedBy": "lars",
          "providedElsewhere": false,
          "dataElement": "oZg33kd9taw",
          "value": "Male"
        }
      ],
      "notes": [],
      "followup": false
    }
  ]
}
```

###### CSV { #csv } 

The CSV response can look like the following:

```csv
event,status,program,programStage,enrollment,orgUnit,occurredAt,scheduledAt,geometry,latitude,longitude,followUp,deleted,createdAt,createdAtClient,updatedAt,updatedAtClient,completedBy,completedAt,updatedBy,attributeOptionCombo,attributeCategoryOptions,assignedUser,dataElement,value,storedBy,providedElsewhere,storedByDataValue,updatedAtDataValue,createdAtDataValue
A7rzcnZTe2T,ACTIVE,eBAyeGv0exc,Zj7UnCAulEk,RiLEKhWHlxZ,DwpbWkiqjMy,2023-02-12T23:00:00Z,2023-02-12T23:00:00Z,"POINT (-11.468912037323042 7.515913998868316)",7.515913998868316,-11.468912037323042,false,false,2017-09-08T19:40:22Z,,2017-09-08T19:40:22Z,,,,,HllvX50cXC0,xYerKDKCefk,,F3ogKBuviRA,"[-11.4880220438585,7.50978830548003]",admin,false,,2016-12-06T17:22:34.438Z,2016-12-06T17:22:34.438Z
A7rzcnZTe2T,ACTIVE,eBAyeGv0exc,Zj7UnCAulEk,RiLEKhWHlxZ,DwpbWkiqjMy,2023-02-12T23:00:00Z,2023-02-12T23:00:00Z,"POINT (-11.468912037323042 7.515913998868316)",7.515913998868316,-11.468912037323042,false,false,2017-09-08T19:40:22Z,,2017-09-08T19:40:22Z,,,,,HllvX50cXC0,xYerKDKCefk,,eMyVanycQSC,2018-02-07,admin,false,,2013-12-30T13:23:57.423Z,2013-12-30T13:23:57.423Z
A7rzcnZTe2T,ACTIVE,eBAyeGv0exc,Zj7UnCAulEk,RiLEKhWHlxZ,DwpbWkiqjMy,2023-02-12T23:00:00Z,2023-02-12T23:00:00Z,"POINT (-11.468912037323042 7.515913998868316)",7.515913998868316,-11.468912037323042,false,false,2017-09-08T19:40:22Z,,2017-09-08T19:40:22Z,,,,,HllvX50cXC0,xYerKDKCefk,,msodh3rEMJa,2018-02-13,admin,false,,2013-12-30T13:23:57.467Z,2013-12-30T13:23:57.467Z
```

#### Events single object endpoint `GET /api/tracker/events/{uid}`

The purpose of this endpoint is to retrieve one Event given its uid.

##### 请求语法 { #request-syntax } 

`GET /api/tracker/events/{uid}?fields={fields}`

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`uid`|`String`|`uid`|Return the Event with specified `uid`|
|`fields`|`String`| Any valid field filter (default `*,!relationships`) |Include specified sub-objects in the response|

##### Example requests { #example-requests } 

A query for an Event:

    GET /api/tracker/events/rgWr86qs0sI

##### Event response example { #event-response-example } 

The API supports CSV and JSON response for `GET /api/tracker/trackedEntities`

###### JSON { #json } 

```json
{
  "event": "rgWr86qs0sI",
  "status": "ACTIVE",
  "program": "kla3mAPgvCH",
  "programStage": "aNLq9ZYoy9W",
  "enrollment": "Lo3SHzCnMSm",
  "orgUnit": "DiszpKrYNg8",
  "occurredAt": "2024-10-12T00:00:00.000",
  "followUp": false,
  "deleted": false,
  "createdAt": "2018-10-20T12:09:19.492",
  "createdAtClient": "2017-10-20T12:09:19.492",
  "updatedAt": "2018-10-20T12:09:19.492",
  "attributeOptionCombo": "amw2rQP6r6M",
  "attributeCategoryOptions": "RkbOhHwiOgW",
  "dataValues": [
    {
      "createdAt": "2015-10-20T12:09:19.640",
      "updatedAt": "2015-10-20T12:09:19.640",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HyJL2Lt37jN",
      "value": "12"
    }
  ],
  "notes": [],
  "followup": false
}
```

###### CSV { #csv } 

The response will be the same as the collection endpoint but referring to a single event,
although it might have multiple rows for each data element value.

#### Event data value change logs { #webapi_event_data_value_change_logs }
`GET /api/tracker/events/{uid}/changeLogs`

This endpoint retrieves change logs for the data values of a specific event. It returns a list of all event data values that have changed over time for that particular event.

|Parameter|类型|Allowed values|
|---|---|---|
|path `/{uid}`|`String`|Event `UID`.|

##### Event data value change logs response example { #event-data-value-change-logs-response-example } 

An example of a json response:

```json
{
   "pager":{
      "page":1,
      "pageSize":10
   },
   "changeLogs":[
      {
         "createdBy":{
            "uid":"AIK2aQOJIbj",
            "username":"tracker",
            "firstName":"Tracker demo",
            "surname":"User"
         },
         "createdAt":"2024-06-20T15:43:36.342",
         "type":"DELETE",
         "change":{
            "dataValue":{
               "dataElement":"UXz7xuGCEhU",
               "previousValue":"12"
            }
         }
      },
      {
         "createdBy":{
            "uid":"AIK2aQOJIbj",
            "username":"tracker",
            "firstName":"Tracker demo",
            "surname":"User"
         },
         "createdAt":"2024-06-20T15:43:27.175",
         "type":"CREATE",
         "change":{
            "dataValue":{
               "dataElement":"UXz7xuGCEhU",
               "currentValue":"12"
            }
         }
      },
      {
         "createdBy":{
            "uid":"AIK2aQOJIbj",
            "username":"tracker",
            "firstName":"Tracker demo",
            "surname":"User"
         },
         "createdAt":"2024-06-20T14:51:16.433",
         "type":"UPDATE",
         "change":{
            "dataValue":{
               "dataElement":"bx6fsa0t90x",
               "previousValue":"true",
               "currentValue":"false"
            }
         }
      }
   ]
}
```

The change log type can be `CREATE`, `UPDATE`, or `DELETE`.
`CREATE` and `DELETE` will always hold a single value: the former shows the current value, and the latter shows the value that was deleted. UPDATE will hold two values: the previous and the current.


### Relationships (`GET /api/tracker/relationships`) { #relationships-get-apitrackerrelationships } 

Relationships are links between two entities in the Tracker. These entities can be tracked entities,
enrollments, and events.

The purpose of this endpoint is to retrieve relationships between objects.

Unlike other tracked objects endpoints, relationships only expose one endpoint:

- `GET /api/tracker/relationships?[trackedEntity={trackedEntityUid}|enrollment={enrollmentUid}|event={eventUid}]&fields=[fields]`

#### Request parameters { #request-parameters } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`trackedEntity`|`String`|`uid`|Identifier of a tracked entity|
|`enrollment`|`String`|`uid`|Identifier of an enrollment|
|`event`|`String`|`uid`|Identifier of an event|
|`fields`|`String`|Any valid field filter (default `relationship,relationshipType,createdAtClient,from[trackedEntity[trackedEntity],enrollment[enrollment],event[event]],to[trackedEntity[trackedEntity],enrollment[enrollment],event[event]]`) |Include specified sub-objects in the response|
|`order`|`String`|Comma-separated list of property name or attribute or UID and sort direction pairs in format `propName:sortDirection`.|Supported fields: `createdAt, createdAtClient`.|
|`includeDeleted`|`Boolean`|`true`&#124;`false`| whether to include soft-deleted elements in your query result|

The following rules apply to the query parameters.

- only one parameter among `trackedEntity`, `enrollment`, `event` can be passed

> **NOTE**
>
> Using tracked entity, enrollment or event params, will return any relationship where the
> trackedEntity, enrollment or event is part of the relationship (either from or to). As long as
> user has access, that is.

#### Example response { #example-response } 

```json
{
  "pager": {
    "page": 1,
    "pageSize": 2
  },
  "relationships": [
    {
      "relationship": "oGtgtJpp6fG",
      "relationshipType": "Mv8R4MPcNcX",
      "from": {
        "trackedEntity": {
          "trackedEntity": "neR4cmMY22o"
        }
      },
      "to": {
        "trackedEntity": {
          "trackedEntity": "DsSlC54GNXy"
        }
      }
    },
    {
      "relationship": "SSfIicJKbh5",
      "relationshipType": "Mv8R4MPcNcX",
      "from": {
        "trackedEntity": {
          "trackedEntity": "neR4cmMY22o"
        }
      },
      "to": {
        "trackedEntity": {
          "trackedEntity": "rEYUGH97Ssd"
        }
      }
    }
  ]
}
```

## Tracker Access Control { #webapi_tracker_access_control }

Tracker has a few different concepts in regards to access control, like sharing, organisation unit
scopes, ownership, and access levels. The following sections provide a short introduction to the
different topics.

### Metadata Sharing { #webapi_tracker_metadata_sharing }

Sharing setting is standard DHIS2 functionality that applies to both Tracker and Aggregate
metadata/data as well as dashboards and visualization items. At the core of sharing is the ability
to define who can see/do what. In general, there are five possible sharing configurations – no
access, metadata read, metadata write, data read, and data write. These access configurations can be
granted at user and/or user group level (for more flexibility). With a focus on Tracker, the
following metadata and their sharing setting is of particular importance: Data Element, Category
Option, Program, Program Stage, Tracked Entity Type, Tracked Entity Attribute as well as Tracker
related Dashboards and Dashboard Items.

How sharing setting works is straightforward – the settings are enforced during Tracker data
import/export processes. To read value, one needs to have data read access. If a user is expected to
modify data, he/she needs to have data write access. Similarly, if a user is expected to modify
metadata, it is essential to grant metadata write access.

One critical point with Tracker data is the need to have a holistic approach. For example, a user
won’t be able to see the Data Element value by having read access to just the Data Element. The user
needs to have data read to access the parent Program Stage and Program where this Data Element
belongs. It is the same with the category option combination. In Tracker, the Event is related to
AttributeOptionCombo, which is made up of a combination of Category Options. Therefore, for a user
to read data of an Event, he/she needs to have data read access to all Category Options and
corresponding Categories that constitute the AttributeOptionCombo of the Event in question. If a
user lacks access to just one Category Option or Category, then the user has no access to the entire
Event.

When it comes to accessing Enrollment data, it is essential to have access to the Tracked Entity
first. Access to a Tracked Entity is controlled through sharing setting of Program, Tracked Entity
Type, and Tracked Entity Attribute. Once Enrollment is accessed, it is possible to access Event
data, again depending on Program Stage and Data element sharing setting.

Another vital point to consider is how to map out access to different Program Stages of a Program.
Sometimes we could be in a situation where we need to grant access to a specific stage – for
example, “Lab Result” – to a specific group of users (Lab Technicians). In this situation, we can
provide data write access to "Lab Result" stage, probably data read to one or more stages just in
case we want Lab Technicians to read other medical results or no access if we think it not necessary
for the Lab Technicians to see data other than lab related.

In summary, DHIS2 has a fine-grained sharing setting that we can use to implement access control
mechanisms both at the data and metadata level. These sharing settings can be applied directly at
the user level or user group level. How exactly to apply a sharing setting depends on the use-case
at hand.

For more detailed information about data sharing, check out [Data
sharing](https://docs.dhis2.org/en/use/user-guides/dhis-core-version-master/configuring-the-system/about-sharing-of-objects.html#data-sharing-for-event-based-programs).

### Organisation Unit Scopes { #webapi_tracker_orgunit_scope }

Organisation units are one of the most fundamental objects in DHIS2. They define a universe under
which a user is allowed to record and/or read data. There are three types of organisation units that
can be assigned to a user. These are data capture, data view (not used in tracker), and tracker
search. As the name implies, these organisation units define a scope under which a user is allowed
to conduct the respective operations. A user can search for data in their search scope and capture
scope organisation units.

However, to further fine-tune the scope, DHIS2 Tracker introduces a concept that we call
**OrganisationUnitSelectionMode**. Such a mode is often used at the time exporting tracker objects.
For example, given that a user has a particular tracker search scope, does it mean that we have to
use this scope every time a user tries to search for a tracker, Enrollment, or Event object? Or is
the user interested in limiting the searching just to the selected org unit, or the entire capture
org unit scope, and so on.

Users can do the fine-tuning by passing a specific value of `orgUnitMode` in their API request:

*api/tracker/trackedEntities?orgUnit=UID&orgUnitMode=specific_organisation_unit_selection_mode*

Currently, there are six selection modes available: *SELECTED, CHILDREN, DESCENDANTS, CAPTURE,
ACCESSIBLE, and ALL*.

1. **SELECTED**: As the name implies, this mode narrows down all operations initiated by the
   requesting API to the specified organisation unit in the request.
2. **CHILDREN**: Under this mode, the organisation unit scope is constructed using the selected
   organisation unit and its immediate children, i.e., the organisation units at the level below.
3. **DESCENDANTS**: In this mode, the selected organisation unit and everything underneath it,
   encompassing not only the immediate children but all descendants, constitute the data operation
universe.
4. **CAPTURE**: This mode includes the data capture organization units associated with the current
   user and all descendants. It encompasses all organization units in the sub-hierarchy.
5. **ACCESSIBLE**: This mode is designed to retrieve data within the user's search scope
   organization units. This encompasses everything visible to the user, including open and audited
programs within its search scope, as well as data in protected and closed programs within the user's
capture scope. If a user lacks search organization units, the system defaults to capture scope,
ensuring that the user always has access to at least one universe. The capture scope, being
mandatory, serves as a foundational element in guaranteeing a data environment for the user.
6. **ALL**: This mode is reserved for authorized users, specifically those with the authority ALL
   (super users). Users with the authority F_TRACKED_ENTITY_INSTANCE_SEARCH_IN_ALL_ORGUNITS can also
search system-wide but need sharing access to the returned program, program stage, and/or tracked
entity type. For non-authorized users, an exception will be raised.

The first three modes, *SELECTED*, *CHILDREN* and *DESCENDANTS* expect an organisation unit to be
supplied in the request, while the last three, *CAPTURE*, *ACCESSIBLE* and *ALL* do not expect it
and in fact the request will fail if an organisation unit is provided.

The organisation unit mode will be one of the ones listed above when it's explicitly provided in the
API request. Since it's not a mandatory field, in case it's not specified, then the default value
will be *SELECTED* if an organisation unit is present, and *ACCESSIBLE* otherwise.

It makes little sense to pass these modes at the time of tracker import operations. Because when
writing tracker data, each of the objects needs to have a specific organisation unit attached to
them. The system will then ensure if each of the mentioned organisation units falls under the
CAPTURE scope. If not, the system will simply reject the write operation.

Note that there is 4 type of organisation unit associations relevant for Tracker objects. A
TrackedEntity has an organisation unit, commonly referred to as the Registration Organisation unit.
Enrollments have an organisation unit associated with them. Events also have an organisation unit
associated with them. There is also an Owner organisation unit for a TrackedEntity-Program
combination.

When fetching Tracker objects, depending on the context, the organisation unit scope is applied to
one of the above four organisation unit associations.

For example, when retrieving TrackedEntities without the context of a program, the organisation unit
scope is applied to the registration organisation unit of the TrackedEntity. Whereas, when
retrieving TrackedEntities, including specific program data, the organisation unit scope is applied
to the Owner organisation unit.

### Tracker Program Ownership { #webapi_tracker_ownership }

A new concept called Tracker Ownership is introduced from 2.30. This introduces a new organisation
unit association for a TrackedEntity - Program combination. We call this the Owner (or Owning)
Organisation unit of a TrackedEntity in the context of a Program. The Owner organisation unit is
used to decide access privileges when reading and writing tracker data related to a program. This,
along with the Program's [Access Level](#webapi_tracker_access_level) configuration, decides the access
behavior for Program-related data (Enrollments and Events). A user can access a TrackedEntity's
Program data if the corresponding Owner OrganisationUnit for that TrackedEntity-Program combination
falls under the user's organisation unit scope (Search/Capture). For Programs that are configured
with access level  *OPEN* or *AUDITED* , the Owner OrganisationUnit has to be in the user's search
scope. For Programs that are configured with access level  *PROTECTED* or *CLOSED* , the Owner
OrganisationUnit has to be in the user's capture scope to be able to access the corresponding
program data for the specific tracked entity. Irrespective of the program access level, to access
Tracker objects, the requested organisation unit must always be within either the user's search
scope or capture scope. A user cannot request objects outside these two scopes unless they are
using the organisation unit mode ALL and have sufficient privileges to use that mode.

When requesting tracked entities without specifying a program, the response will include only
tracked entities that satisfy [metadata sharing settings](#webapi_tracker_metadata_sharing) and
one of the following criteria:

* The tracked entity is enrolled in at least one program the user has data access to, and the user
 has access to the owner organisation unit.
* The tracked entity is not enrolled in any program the user has data access to, but the user has
 access to the tracked entity registering organisation unit.

#### Tracker Ownership Override: Break the Glass { #webapi_tracker_ownership_override }

It is possible to temporarily override this ownership privilege for a program that is configured
with an access level of *PROTECTED*. Any user will be able to temporarily gain access to the Program
related data if the user specifies a reason for accessing the TrackedEntity-Program data. This act
of temporarily gaining access is termed as *breaking the glass*. Currently, temporary access is
granted for 3 hours. DHIS2 audits breaking the glass along with the reason specified by the user. It
is not possible to gain temporary access to a program that has been configured with an access level
of *CLOSED*. To break the glass for a TrackedEntity-Program combination, the following POST request
can be used:

    /api/tracker/ownership/override?trackedEntity=DiszpKrYNg8&program=eBAyeGv0exc&reason=patient+showed+up+for+emergency+care

#### Tracker Ownership Transfer { #webapi_tracker_ownership_transfer }

It is possible to transfer the ownership of a TrackedEntity-Program from one organisation unit to
another. This will be useful in case of patient referrals or migrations. Only a user who has
Ownership access (or temporary access by breaking the glass) can transfer the ownership. To transfer
ownership of a TrackedEntity-Program to another organisation unit, the following PUT request can be
used:

    /api/tracker/ownership/transfer?trackedEntity=DiszpKrYNg8&program=eBAyeGv0exc&ou=EJNxP3WreNP

### Access Level { #webapi_tracker_access_level }

DHIS2 treats Tracker data with an extra level of protection. In addition to the standard feature of
metadata and data protection through sharing settings, Tracker data are shielded with additional
access level protection mechanisms.  Currently, there are four access levels that can be configured
for a Program: Open, Audited, Protected, and Closed.

These access levels are only triggered when users try to interact with program data, namely
Enrollments and Events data. The different Access Level configuration for Program is a degree of
openness (or closedness) of program data. Note that all other sharing settings are still respected,
and the access level is only an additional layer of access control. Here is a short description of
the four access levels that can be configured for a Program.

#### Open { #open } 

This access level is the least restricted among the access levels. Data inside an OPEN program can
be accessed and modified by users if the Owner organisation unit falls under the user's search
scope.  With this access level, accessing and modifying data outside the capture scope is possible
without any justification or consequence.

#### Audited { #audited } 

This is the same as the Open access level. The difference here is that the system will automatically
add an audit log entry on the data being accessed by the specific user.

#### Protected { #protected } 

This access level is slightly more restricted. Data inside a PROTECTED program can only be accessed
by users if the Owner organisation unit falls under the user's capture scope. However, a user who
only has the Owner organisation unit in the search scope can gain temporary ownership by [breaking
the glass](#webapi_tracker_ownership_override). The user has to provide a justification of why
they are accessing the data at hand. The system will then put a log of both the justification and
access audit and provide temporary access for 3 hours to the user. Note that when breaking the
glass, the Owner Organisation Unit remains unchanged, and only the user who has broken the glass
gains temporary access.

#### Closed { #closed } 

This is the most restricted access level. Data recorded under programs configured with access level
CLOSED will not be accessible if the Owner Organisation Unit does not fall within the user's capture
scope. It is also not possible to break the glass or gain temporary ownership in this configuration.
Note that it is still possible to transfer the ownership to another organisation unit. Only a user
who has access to the data can transfer the ownership of a TrackedEntity-Program combination to
another Organisation Unit. If ownership is transferred, the Owner Organisation Unit is updated.
trackedEntities

## Working Lists { #working-lists } 

Working lists allow users to efficiently organize their workflow by saving filters and sorting
preferences for tracked entities, enrollments, and events. Each type of working list—tracked
entities, enrollments, and events—has a dedicated API for management.

Working lists are [metadata](#webapi_metadata), making them shareable and subject to the same
[sharing](#webapi_sharing) patterns as other metadata. When using the
[`/api/sharing`](#webapi_sharing) endpoint, the type parameter should be set to the name of the
working list API. For example, use trackedEntityInstanceFilter for [tracked entity working
lists](#tracked-entity-instance-filters).

Since working lists are metadata refer to [metadata](#webapi_metadata) on how to create, update and
delete metadata. The following sections describe the payloads of each of the working lists
endpoints.

### Tracked entity working lists { #tracked-entity-working-lists } 

Create, update and delete tracked entity working lists using

    /api/trackedEntityInstanceFilters

#### Payload { #payload } 

Table: Payload

| Property | 描述 | 例 |
|---|---|---|
|名称|Name of the working list. Required.||
|描述|A description of the working list.||
|sortOrder|The sort order of the working list.||
|style|Object containing css style.|`{"color": "blue", "icon": "fa fa-calendar"}`|
|program|Object containing the id of the program. Required.|`{ "id" : "uy2gU8kTjF"}`|
|entityQueryCriteria|An object representing various possible filtering values. See *Entity Query Criteria* definition table below.
|eventFilters|A list of eventFilters. See *Event filters* definition table below.|`[{"programStage": "eaDH9089uMp", "eventStatus": "OVERDUE", "eventCreatedPeriod": {"periodFrom": -15, "periodTo": 15}}]`|

Table: Entity Query Criteria definition

| Property | 描述 | 例 |
|---|---|---|
|attributeValueFilters|A list of attributeValueFilters. This is used to specify filters for attribute values when listing tracked entity instances|`"attributeValueFilters"=[{"attribute": "abcAttributeUid","le": "20","ge": "10","lt": "20","gt": "10","in": ["India", "Norway"],"like": "abc","sw": "abc","ew": "abc","dateFilter": {"startDate": "2014-05-01","endDate": "2019-03-20","startBuffer": -5,"endBuffer": 5,"period": "LAST_WEEK","type": "RELATIVE"}}]`|
|enrollmentStatus|The tracked entities enrollment status. Can be none(any enrollmentstatus) or ACTIVE&#124;COMPLETED&#124;CANCELLED||
|跟进|When this parameter is true, the working list only returns tracked entities that have an enrollment with `folloWup=true`.||
|organisationUnit|To specify the uid of the organisation unit|`{"organisationUnit": "a3kGcGDCuk7"}`|
|ouMode|To specify the organisation unit selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL|`"ouMode": "SELECTED"`|
|assignedUserMode|To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered.|"assignedUserMode": "PROVIDED"|
|assignedUsers|To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above.|`"assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"]`|
|displayColumnOrder|To specify the output ordering of columns|`"displayOrderColumns": ["enrollmentDate", "program"]`|
|order|To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "orderDimension:direction". Note: Supported orderDimensions are trackedEntity, created, createdAt, createdAtClient, updatedAt, updatedAtClient, enrolledAt, inactive and the tracked entity attributes|`"order"="a3kGcGDCuk6:desc"`|
|programStage|To specify a programStage uid to filter on. tracked entities will be filtered based on presence of enrollment in the specified program stage.|`"programStage"="a3kGcGDCuk6"`|
|trackedEntityType|To specify a trackedEntityType filter tracked entities on.|`{"trackedEntityType"="a3kGcGDCuk6"}`|
|trackedEntities|To specify a list of trackedEntityInstances to use when querying tracked entities.|`"trackedEntityInstances"=["a3kGcGDCuk6","b4jGcGDCuk7"]`|
|enrollmentCreatedDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on enrollment created date.|`"enrollmentCreatedDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   }`|
|enrollmentIncidentDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on enrollment incident date.|`"enrollmentIncidentDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   }`|
|eventStatus|The event status. Possible values are ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED and VISITED|`"status":"VISITED"`|
|eventDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on event date.|`"eventDate": {"startBuffer": -5,"endBuffer": 5,     "type": "RELATIVE"   }`|
|lastUpdatedDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on last updated date.|`"lastUpdatedDate": {"startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   }`|

Table: Event filters definition

| Property | 描述 | 例 |
|---|---|---|
|programStage|Which programStage the tracked entity needs an event in to be returned.|`"eaDH9089uMp"`|
|eventStatus|The events status. Can be none(any event status) or ACTIVE&#124;COMPLETED&#124;SCHEDULE&#124;OVERDUE|`ACTIVE`|
|eventCreatedPeriod|FilterPeriod object containing a period in which the event must be created. See *Period* definition below.|`{ "periodFrom": -15, "periodTo": 15}`|
|assignedUserMode|To specify the assigned user selection mode for events. Possible values are CURRENT (events assigned to current user)&#124; PROVIDED (events assigned to users provided in "assignedUsers" list) &#124; NONE (events assigned to no one) &#124; ANY (events assigned to anyone). If PROVIDED (or null), non-empty assignedUsers in the payload will be considered.|`"assignedUserMode": "PROVIDED"`|
|assignedUsers|To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above.|`"assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"]`|

Table: FilterPeriod definition

| Property | 描述 | 例 |
|---|---|---|
|periodFrom|Number of days from current day. Can be positive or negative integer.|-15|
|periodTo|Number of days from current day. Must be bigger than periodFrom. Can be positive or negative integer.|15|

#### Query Request Parameters { #query-request-parameters } 

Table: Tracked entity instance filters query parameters

| 查询参数 | 描述 |
|---|---|
|program|Program identifier. Restricts filters to the given program.|

### Program stage working lists { #program-stage-working-lists } 

Create, update and delete program stage working lists using

    /api/programStageWorkingLists

#### Payload { #payload } 

Table: Payload

| Payload values | 描述 | 例 |
|---|---|---|
|名称|Name of the working list. Required.||
|描述|A description of the working list.||
|program|Object containing the id of the program. Required.|`{"id" : "uy2gU8kTjF"}`|
|programStage|Object containing the id of the program stage. Required.|`{"id" : "oRySG82BKE6"}`|
|programStageQueryCriteria|An object representing various possible filtering values. See *Program Stage Query Criteria* definition table below.

Table: Program Stage Query Criteria

| Criteria values | 描述 | 例 |
|---|---|---|
|eventStatus|The event status. Possible values are ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED and VISITED|`"status":"VISITED"`|
|eventCreatedAt|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object filtering based on the event creation date.|`{"type":"ABSOLUTE","startDate":"2020-03-01","endDate":"2022-12-30"}`|
|eventOccurredAt|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object filtering based on the event occurred date.|`{"type":"RELATIVE","period":"TODAY"}`|
|eventScheduledAt|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object filtering based on the event scheduled date.|`{"type":"RELATIVE","period":"TODAY"}`|
|enrollmentStatus|Any valid EnrollmentStatus. Possible values are ACTIVE, COMPLETED and CANCELLED.|`"enrollmentStatus": "COMPLETED"`|
|跟进|Indicates whether to filter enrollments marked for follow up or not|`"followUp":true`|
|enrolledAt|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object filtering based on the event enrollment date.|`"enrolledAt": {"type":"RELATIVE","period":"THIS_MONTH"}`|
|enrollmentOccurredAt|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object filtering based on the event occurred date.|`{"type":"RELATIVE","period":"THIS_MONTH"}`|
|orgUnit|A valid organisation unit UID|`"orgUnit": "Rp268JB6Ne4"`|
|ouMode|A valid OU selection mode|`"ouMode": "SELECTED"`|
|assignedUserMode|A valid user selection mode for events. Possible values are CURRENT, PROVIDED, NONE, ANY and ALL. If PROVIDED (or null), non-empty assignedUsers in the payload will be expected.|"assignedUserMode":"PROVIDED"|
|assignedUsers|A list of assigned users for events. To be used along with PROVIDED assignedUserMode above.|"assignedUsers":["DXyJmlo9rge"]|
|order|List of fields and its directions in comma separated values, the results will be sorted according to it. A single item in order is of the form "orderDimension:direction".|"order": "w75KJ2mc4zz:asc"|
|displayColumnOrder|Output ordering of columns|"displayColumnOrder":["w75KJ2mc4zz","zDhUuAYrxNC"]|
|dataFilters|A list of items that contains the filters to be used when querying events|"dataFilters":[{"dataItem": "GXNUsigphqK","ge": "10","le": "20"}]|
|attributeValueFilters|A list of attribute value filters. This is used to specify filters for attribute values when listing tracked entities|"attributeValueFilters":[{"attribute": "ruQQnf6rswq","eq": "15"}]|

See an example payload below:

```json
{
  "name": "Test WL",
  "description": "Test WL definition",
  "program": {
    "id": "uy2gU8kT1jF"
  },
  "programStage": {
    "id": "oRySG82BKE6"
  },
  "programStageQueryCriteria": {
    "eventStatus": "VISITED",
    "eventCreatedAt": {
      "type": "ABSOLUTE",
      "startDate": "2020-03-01",
      "endDate": "2022-12-30"
    },
    "eventScheduledAt": {
      "type": "RELATIVE",
      "period": "TODAY"
    },
    "enrollmentStatus": "COMPLETED",
    "followUp": true,
    "enrolledAt": {
      "type": "RELATIVE",
      "period": "THIS_MONTH"
    },
    "enrollmentOccurredAt": {
      "type": "RELATIVE",
      "period": "THIS_MONTH"
    },
    "orgUnit": "Rp268JB6Ne4",
    "ouMode": "SELECTED",
    "assignedUserMode": "PROVIDED",
    "assignedUsers": [
      "DXyJmlo9rge"
    ],
    "order": "w75KJ2mc4zz:asc",
    "displayColumnOrder": [
      "w75KJ2mc4zz",
      "zDhUuAYrxNC"
    ],
    "dataFilters": [
      {
        "dataItem": "GXNUsigphqK",
        "ge": "10",
        "le": "20"
      }
    ],
    "attributeValueFilters": [
      {
        "attribute": "ruQQnf6rswq",
        "eq": "15"
      }
    ]
  }
}
```

### Event working lists { #event-working-lists } 

Create, update and delete event working lists using

    /api/eventFilters

#### Payload { #payload } 

Table: Payload

| Property | 描述 | 例 |
|---|---|---|
|名称|Name of the working list.|"name":"My working list"|
|描述|A description of the working list.|"description":"for listing all events assigned to me".|
|program|The uid of the program.|"program" : "a3kGcGDCuk6"|
|programStage|The uid of the program stage.|"programStage" : "a3kGcGDCuk6"|
|eventQueryCriteria|Object containing parameters for querying, sorting and filtering events.|"eventQueryCriteria": {     "organisationUnit":"a3kGcGDCuk6",     "status": "COMPLETED",     "createdDate": {       "from": "2014-05-01",       "to": "2019-03-20"     },     "dataElements": ["a3kGcGDCuk6:EQ:1", "a3kGcGDCuk6"],     "filters": ["a3kGcGDCuk6:EQ:1"],     "programStatus": "ACTIVE",     "ouMode": "SELECTED",     "assignedUserMode": "PROVIDED",     "assignedUsers" : ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "followUp": false,     "trackedEntityInstance": "a3kGcGDCuk6",     "events": ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "fields": "eventDate,dueDate",     "order": "dueDate:asc,createdDate:desc"   }|

Table: Event Query Criteria definition

| Property | 描述 | 例 |
|---|---|---|
|跟进|Used to filter events based on enrollment followUp flag. Possible values are true&#124;false.|"followUp": true|
|organisationUnit|To specify the uid of the organisation unit|"organisationUnit": "a3kGcGDCuk7"|
|ouMode|To specify the OU selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL|"ouMode": "SELECTED"|
|assignedUserMode|To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered.|"assignedUserMode": "PROVIDED"|
|assignedUsers|To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above.|"assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"]|
|displayColumnOrder |To specify the output ordering of columns|"displayOrderColumns": ["eventDate", "dueDate", "program"]|
|order|To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "dataItem:direction".|"order"="a3kGcGDCuk6:desc,eventDate:asc"|
|dataFilters|To specify filters to be applied when listing events|"dataFilters"=[{       "dataItem": "abcDataElementUid",       "le": "20",       "ge": "10",       "lt": "20",       "gt": "10",       "in": ["India", "Norway"],       "like": "abc",       "dateFilter": {         "startDate": "2014-05-01",         "endDate": "2019-03-20",         "startBuffer": -5,         "endBuffer": 5,         "period": "LAST_WEEK",         "type": "RELATIVE"       }     }]|
|status|Any valid EventStatus|"eventStatus": "COMPLETED"|
|events|To specify list of events|"events"=["a3kGcGDCuk6"]|
|completedDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on completed date.|"completedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   }|
|eventDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on event date.|"eventDate": {     "startBuffer": -5,     "endBuffer": 5,     "type": "RELATIVE"   }|
|dueDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on due date.|"dueDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   }|
|lastUpdatedDate|[DateFilterPeriod](#webapi_tracker_workinglists_common_objects) object date filtering based on last updated date.|"lastUpdatedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   }|

See an example payload below:

```json
{
  "name": "event working list",
  "program": "VBqh0ynB2wv",
  "eventQueryCriteria": {
    "eventDate": {
      "period": "LAST_WEEK",
      "type": "RELATIVE"
    },
    "dataFilters": [
      {
        "ge": "35",
        "le": "70",
        "dataItem": "qrur9Dvnyt5"
      }
    ],
    "assignedUserMode": "PROVIDED",
    "assignedUsers": [
      "CotVI2NX0rI",
      "xE7jOejl9FI"
    ],
    "status": "ACTIVE",
    "order": "occurredAt:desc",
    "displayColumnOrder": [
      "occurredAt",
      "status",
      "assignedUser",
      "qrur9Dvnyt5",
      "oZg33kd9taw"
    ]
  }
}
```

### Common Objects { #webapi_tracker_workinglists_common_objects }

Table: DateFilterPeriod object definition

| Property | 描述 | 例 |
|---|---|---|
|type|Specify whether the date period type is ABSOLUTE &#124; RELATIVE|`"type" : "RELATIVE"`|
|period|Specify if a relative system defined period is to be used. Applicable only when `type` is RELATIVE. (see [Relative Periods](#webapi_date_relative_period_values) for supported relative periods)|`"period" : "THIS_WEEK"`|
|开始日期|Absolute start date. Applicable only when `type` is ABSOLUTE|`"startDate":"2014-05-01"`|
|结束日期|Absolute end date. Applicable only when `type` is ABSOLUTE|`"startDate":"2014-05-01"`|
|startBuffer|Relative custom start date. Applicable only when `type` is RELATIVE|`"startBuffer":-10`|
|endBuffer|Relative custom end date. Applicable only when `type` is RELATIVE|`"startDate":+10`|


## 潜在重复   { #potential-duplicates } 

Potential duplicates are records identified by the data deduplication feature as possibly being
duplicates. Due to the nature of this feature, the API endpoint has certain restrictions. A
potential duplicate represents a pair of records suspected to be duplicates.

To retrieve a list of potential duplicates, use the following endpoint:

    GET /api/potentialDuplicates

The response payload for a potential duplicate looks like this:

```json
{
  "created": "2024-06-04T10:11:29.110",
  "lastUpdated": "2024-06-04T10:11:29.110",
  "original": "<UID>",
  "duplicate": "<UID>",
  "status": "OPEN|INVALID|MERGED",
  "id": "<id>"
}
```

These are the parameters this endpoint accepts:

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| trackedEntities | List of tracked entities | List of string (separated by comma)| existing tracked entity UIDs |
| status | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED`, `ALL` |

To inspect individual potential duplicate records, use the following endpoint:

    GET /api/potentialDuplicates/<id>

To create a new potential duplicate, use this endpoint:

    POST / api / potentialDuplicates

The payload you provide must include the UIDs of the original and duplicate tracked entities. New
potential duplicates are open by default.

```json
{
  "original": "<UID>",
  "duplicate": "<UID>"
}
```

| Status code | 描述
|---|---|
| 400 | Input original or duplicate is null or has invalid uid
| 403 | User do not have access to read original or duplicate TEs
| 404 | TE not found
| 409 | Pair of original and duplicate TEs already existing

To update the status of a potential duplicate, use the following endpoint:

    PUT /api/potentialDuplicates/<id>

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| status | Potential duplicate status | string | `OPEN`, `INVALID` |

| Status code | 描述
|---|---|
| 400 | You can't update a potential duplicate to MERGED as this is possible only by a merging request
| 400 | You can't update a potential duplicate that is already in a MERGED status

### Merging Tracked Entities { #merging-tracked-entities } 

Tracked entities can be merged together if they are deemed viable. To initiate a merge, the first
step is to define two tracked entities as a Potential Duplicate. The merge endpoint moves data from
the duplicate tracked entity to the original tracked entity and deletes the remaining data of the
duplicate.

To merge a Potential Duplicate, i.e. the two tracked entities the Potential Duplicate represents,
use the following endpoint:

    POST /api/potentialDuplicates/<id>/merge

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| mergeStrategy | Strategy to use for merging the potentialDuplicate | string | AUTO(default) or MANUAL |

The endpoint accepts a single parameter, `mergeStrategy`, which determines the strategy used when merging. For the `AUTO` strategy, the server will attempt to merge the two tracked entities automatically without user input. This strategy only allows merging tracked entities without conflicting data (see examples below). The `MANUAL` strategy requires the user to send in a payload describing how the merge should be done. For examples and rules for each strategy, see their respective sections below.

#### Merge Strategy AUTO { #merge-strategy-auto } 

The automatic merge evaluates the mergability of the two tracked entities and merges them if they
are deemed mergeable. The mergability is based on whether the two tracked entities have any
conflicts. Conflicts refer to data that cannot be merged automatically. Examples of possible
conflicts include:

- The same attribute has different values in each tracked entity.
- Both tracked entities are enrolled in the same program.
- Tracked entities have different types.

If any conflict is encountered, an error message is returned to the user.

When no conflicts are found, all data in the duplicate that is not already in the original will be
moved to the original. This includes attribute values, enrollments (including events), and
relationships. After the merge completes, the duplicate is deleted and the Potential Duplicate is
marked as `MERGED`. When requesting an automatic merge, a payload is not required and will be
ignored.

#### Merge Strategy MANUAL { #merge-strategy-manual } 

The manual merge is suitable when there are resolvable conflicts or when not all the data needs to
be moved during the merge. For example, if an attribute has different values in both tracked entity
instances, the user can specify whether to keep the original value or move over the duplicate's
value. Since the manual merge involves the user explicitly requesting to move data, there are some
additional checks:

- Relationship cannot be between the original and the duplicate (This results in an invalid
self-referencing relationship)
- Relationship cannot be of the same type and to the same object in both tracked entities (IE.
between original and other, and duplicate and other; This would result in a duplicate relationship)

There are two ways to do a manual merge: With and without a payload.

When a manual merge is requested without a payload, we are telling the API to merge the two tracked
entities without moving any data. In other words, we are just removing the duplicate and marking the
potentialDuplicate MERGED. This might be valid in a lot of cases where the tracked entity was just
created, but not enrolled for example.

Otherwise, if a manual merge is requested with a payload, the payload refers to what data should be
moved from the duplicate to the original. The payload looks like this:

```json
{
  "trackedEntityAttributes": ["B58KFJ45L9D"],
  "enrollments": ["F61SJ2DhINO"],
  "relationships": ["ETkkZVSNSVw"]
}
```

This payload contains three lists, one for each of the types of data that can be moved.
`trackedEntityAttributes` is a list of uids for tracked entity attributes, `enrollments` is a list
of uids for enrollments and `relationships` a list of uids for relationships. The uids in this
payload have to refer to data that actually exists on the duplicate. There is no way to add new data
or change data using the merge endpoint - Only moving data.

#### Additional information about merging { #additional-information-about-merging } 

Currently it is not possible to merge tracked entities that are enrolled in the same program, due to
the added complexity. A workaround is to manually remove the enrollments from one of the tracked
entities before starting the merge.

All merging is based on data already persisted in the database, which means the current merging
service is not validating that data again. This means if data was already invalid, it will not be
reported during the merge. The only validation done in the service relates to relationships, as
mentioned in the previous section.


# 电子邮件 { #email } 

## 电子邮件 { #webapi_email } 

Web API 具有用于发送电子邮件的资源。对于电子邮件
发送 需要已正确设置 SMTP 配置
并且 DHIS2 实例的系统通知电子邮件地址具有
被定义。您可以从电子邮件设置屏幕设置 SMTP 设置
和来自常规设置屏幕的系统通知电子邮件地址
在 DHIS2 中。

    / api / 33 /电子邮件

### 系统通知 { #webapi_email_system_notification } 

*notification* 资源可让您发送系统电子邮件通知
使用 JSON 或 XML 格式的给定主题和文本。电子邮件将发送至
DHIS2 通用系统中定义的通知电子邮件地址
设置：

```json
{
  "subject": "Integrity check summary",
  "text": "All checks ran successfully"
}
```

您可以通过发布到通知来发送系统电子邮件通知
像这样的资源：

```bash
curl -d @email.json "localhost/api/33/email/notification" -X POST 
  -H "Content-Type:application/json" -u admin:district
```

### 出站电子邮件 { #outbound-emails } 

您还可以通过发布到
通知资源如下所述。 `F_SEND_EMAIL` 或 `ALL`
权限必须在系统中才能使用这个 api。主题
参数是可选的。 “DHIS 2”字符串将作为默认主题发送
如果 url 中没有提供。应该对 URL 进行编码才能使用它
应用程序接口。

```bash
curl "localhost/api/33/email/notification?recipients=xyz%40abc.com&message=sample%20email&subject=Test%20Email" 
  -X POST -u admin:district
```

### 测试讯息 { #webapi_email_test_message } 

通过发送测试电子邮件来测试 SMTP 设置是否正确
您可以自己与 *test* 资源进行交互。发送测试邮件
您的 DHIS2 用户帐户必须具有有效的电子邮件地址
与之相关。您可以像这样发送测试电子邮件：

```bash
curl "localhost/api/33/email/test" -X POST -H "Content-Type:application/json" -u admin:district
```






# 数据存储 { #data-store } 

## 数据存储 { #webapi_data_store } 

使用 *dataStore* 资源，开发人员可以存储任意数据
他们的应用程序。对数据存储密钥的访问基于其共享设置。
默认情况下，所有创建的密钥都可以公开访问（读取和写入）。
此外，对数据存储命名空间的访问仅限于用户的
访问相应的应用程序，如果应用程序保留了命名空间。
例如，有权访问“sampleApp”应用程序的用户也将
能够使用数据存储中的 sampleApp 命名空间。如果一个命名空间
没有保留，使用它不需要特定的访问权限。

    / api / 33 / dataStore

Note that there are reserved namespaces used by the system that require 
special authority to be able to read or write entries. 
For example the namespace for the android settings app `ANDROID_SETTINGS_APP`
will require the `M_androidsettingsapp` authority.

### 数据存储结构 { #webapi_data_store_structure } 

数据存储条目由命名空间、键和值组成。这
命名空间和键的组合是唯一的。值数据类型为 JSON。

Table: Data store structure

| 项目 | 描述 | 数据类型 |
|---|---|---|
| 命名空间 | Namespace for organization of entries. | 串 |
| 键 | Key for identification of values. | 串 |
| 值 | Value holding the information for the entry. | JSON格式 |
| Encrypted | Indicates whether the value of the given key should be encrypted | Boolean |

### 获取键和名称空间 { #webapi_data_store_get_keys_and_namespaces } 

有关所有现有名称空间的列表：

    GET /api/33/dataStore

清单示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore" -u admin:district
```

响应示例：

```json
[
  "foo",
  "bar"
]
```

有关命名空间中所有键的列表：

    GET /api/33/dataStore/<namespace>

清单示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -u admin:district
```

响应示例：

```json
[
  "key_1",
  "key_2"
]
```

要从名称空间检索现有键的值：

    GET /api/33/dataStore/<namespace>/<key>

卷曲请求检索示例：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1"-u admin:district
```

响应示例：

```json
{
  "foo":"bar"
}
```

要从名称空间检索现有键的元数据：

    GET /api/33/dataStore/<namespace>/<key>/metaData

卷曲请求检索示例：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1/metaData" -u admin:district
```

响应示例：

```json
{
  "id": "dsKeyUid001", 
  "created": "...",
  "user": {...},
  "namespace": "foo",
  "key": "key_1"
}
```

### Query API { #query-api } 
The query API is allows you to query and filter values over all keys in a namespace. The `fields` parameter is used to specify the query. This is useful for retrieving specific values of keys across a namespace in a single request. 

    GET /api/dataStore/<namespace>?fields=

The list of `fields` can be:

* empty: returns just the entry keys
* `.`: return the root value as stored
* comma separated list of paths: `<path>[,<path>]`; each `<path>` can be a simple property name (like `age`) or a nested path (like `person.age`) 

Furthermore, entries can be filtered using one or more `filter` parameters 
and sorted using the `order` parameter. 

Multiple filters can be combined using `rootJunction=OR` (default) or `rootJunction=AND`. 

All details on the `fields`, `filter` and `order` parameters are given in the following sections.

#### Paging { #paging } 
By default, results use paging. Use `pageSize` and `page` to adjust size and offset. 
The parameter `paging=false` can be used to opt-out and always return all matches. 
This should be used with caution as there could be many entries in a namespace. The default page size is 50.

    GET /api/dataStore/<namespace>?fields=.&page=2&pageSize=10

When paging is turned off, entries are returned as plain result array as the root JSON structure. The same effect can be achieved while having paged results by using `headless=true`.

```json
{
  "pager": { ... },
  "entries": [...]
}
```
vs.
```json
[...]
```

#### Value extraction { #value-extraction } 
The data store allows extracting entire simple or complex values 
as well as the extraction of parts of complex JSON values.

> **Note**
> 
> For clarity of the examples the responses shown mostly omit the outermost object with the `pager` information
> and the `entries` array that the examples show.

To filter a certain set of fields add a `fields` parameter to the namespace 
query:

    GET /api/dataStore/<namespace>?fields=name,description

This returns a list of all entries having a non-null `name` and/or a 
`description` field like in the following example:

```json
[
  {"key": "key1", "name": "name1", "description": "description1"},
  {"key": "key2", "name": "name2", "description": "description2"}
]
```

If for some reason we even want entries where none of the extracted fields 
is non-null contained in the result list the `includeAll` parameter can be 
added:

    GET /api/dataStore/<namespace>?fields=name,description&includeAll=true

The response now might look like this:

```json
[
  {"key": "key1", "name": "name1", "description": "description1"},
  {"key": "key2", "name": "name2", "description": "description2"},
  {"key": "key3", "name": null, "description": null},
  {"key": "key4", "name": null, "description": null}
]
```

The extraction is not limited to simple root level members but can pick 
nested members as well by using square or round brackets after a members name:

    GET /api/dataStore/<namespace>?fields=name,root[child1,child2]
    GET /api/dataStore/<namespace>?fields=name,root(child1,child2)

The example response could look like this:

```json
[
  { "key": "key1", "name": "name1", "root": {"child1": 1, "child2": []}},
  { "key": "key2", "name": "name2", "root": {"child1": 2, "child2": []}}
]
```

The same syntax works for nested members:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3]]]
    GET /api/dataStore/<namespace>?fields=root(level1(level2(level3)))

Example response here:

```json
[
  { "key": "key1", "root": {"level1": {"level2": {"level3": 42}}}},
  { "key": "key1", "root": {"level1": {"level2": {"level3": 13}}}}
]
```

When such deeply nested values are extracted we might not want to keep the 
structure but extract the leaf member to a top level member in the response.
Aliases can be used to make this happen. An alias can be placed anywhere 
after a member name using `~hoist` followed by the alias in round brackets like so:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3~hoist(my-prop)]]]

The response now would look like this:

```json
[
  { "key": "key1", "my-prop": 42},
  { "key": "key2", "my-prop": 13}
]
```

If the full path should be kept while giving an alias to a nested member the 
parent path needs to be repeated using dot-syntax to indicate the nesting.
This can also be used to restructure a response in a new different structure 
like so:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3~hoist(my-root.my-prop)]]]

The newly structured response now looks like this:

```json
[
  { "key": "key1", "my-root": {"my-prop": 42}},
  { "key": "key2", "my-root": {"my-prop": 13}}
]
```

OBS! An alias cannot be used to rename an intermediate level. However, an alias
could be used to resolve a name collision with the `key` member.

    GET /api/dataStore/<namespace>?fields=id,key~hoist(value-key)

```json
[
  { "key": "key1", "id": 1, "value-key": "my-key1"},
  { "key": "key2", "id": 2, "value-key": "my-key2"}
]
```

### Sorting results { #sorting-results } 
Results can be sored by a single property using the `order=<path>[:direction]` parameter.
This can be any valid value `<path>` or the entry key (use `_` as path).

By default, sorting is alphanumeric assuming the value at the path is a string of mixed type.

For example to extract the name property and also sort the result by it use:

    GET /api/dataStore/<namespace>?fields=name&order=name

To switch to descending order use `:desc`:

    GET /api/dataStore/<namespace>?fields=name&order=name:desc

Sometimes the property sorted by is numeric so alphanumeric interpretation would be confusing.
In such cases special ordering types `:nasc` and `:ndesc` can be used.

In summary, order can be one of the following:

* `asc`: alphanumeric ascending order
* `desc:`: alphanumeric descending order
* `nasc`: numeric ascending order
* `ndesc`: numeric descending order

> **OBS!**
> 
> When using numeric order all matches must have a numeric value for the property at the provided `<path>`.

### Filtering entries { #filtering-entries } 
To filter entries within the query API context add one or more `filter` parameters
while also using the `fields` parameter.

Each `filter` parameter has the following form:

* unary operators: `<path>:<operator>`
* binary operators: `<path>:<operator>:<value>`
* set operators: `<path>:<operator>:[<value>,<value>,...]`

Unary operators are:

| Operator | 描述 |
| -------- | ----------- |
| `null`   | value is JSON `null` |
| `!null`  | value is defined but different to JSON `null` |
| `empty`  | value is an empty object, empty array or JSON string of length zero |
| `!empty` | value is different to an empty object, empty array or zero length string |

Binary operators are:

| Operator | 描述 |
| -------- | ----------- |
| `eq`     | value is equal to the given boolean, number or string |
| `!eq`, `ne`, `neq` | value is not equal to the given boolean, number or string |
| `lt`     | value is numerically or alphabetically less than the given number or string |
| `le`     | value is numerically or alphabetically less than or equal to the given number or string |
| `gt`     | value is numerically or alphabetically greater than the given number or string |
| `ge`     | value is numerically or alphabetically greater than or equal to the given number or string |

Text pattern matching binary operators are:

| Operator | Case Insensitive |  描述 |
| -------- | ---------------- | ----------- |
| `like`   | `ilike`          | value matches the text pattern given |
| `!like`  | `!ilike`         | value does not match the text pattern given |
| `$like`  | `$ilike`, `startswith`   | value starts with the text pattern given |
| `!$like` | `!$ilike`, `!startswith` | value does not start with the text pattern given |
| `like$`  | `ilike$`, `endswith`     | value ends with the text pattern given |
| `!like$` | `!ilike$`, `!endswith`   | value does not end with the text pattern given |

For operators that work for multiple JSON node types the semantic is determined from the provided value.
If the value is `true` or `false` the filter matches boolean JSON values.
If the value is a number the filter matches number JSON values.
Otherwise, the value matches string JSON values or mixed types of values.

> **Tip**
>
> To force text comparison for a value that is numeric quote the value in single quotes.
> For example, the value `'13'` is the text 13 while `13` is the number 13.  

Set operators are:

| Operator | 描述 |
| -------- | ----------- |
| `in`     | entry value is textually equal to one of the given values (is in set) |
| `!in`    | entry value is not textually equal to any of the given values (is not in set) |

The `<path>` can be:

* `_`: the entry key is
* `.`: the entry root value is
* `<member>`: the member of the root value is
* `<member>.<member>`: the member at the path is (up to 5 levels deep)

A `<member>` path expression can be a member name or in case of arrays an array index.
In case of an array the index can also be given in the form: `[<index>]`.
For example, the path `addresses[0].street` would be identical to `addresses.0.street`.

Some example queries are found below.

Name (of root object) is "Luke":

    GET /api/dataStore/<namespace>?fields=.&filter=name:eq:Luke

Age (of root object) is greater than 42 (numeric):

    GET /api/dataStore/<namespace>?fields=.&filter=age:gt:42

Root value is a number greater than 42 (numeric matching inferred from the value):

    GET /api/dataStore/<namespace>?fields=.&filter=.:gt:42

Enabled (of root object) is true (boolean matching inferred from the value):

    GET /api/dataStore/<namespace>?fields=.&filter=enabled:eq:true

Root object has name containing "Pet" and has an age greater than 20:

    GET /api/dataStore/<namespace>?fields=.&filter=name:like:Pet&filter=age:gt:20

Root object is either flagged as minor or has an age less than 18:

    GET /api/dataStore/<namespace>?fields=.&filter=minor:eq:true&filter=age:lt:18&rootJunction=or

### 创造价值 { #webapi_data_store_create_values } 

为命名空间创建新的键和值：

    POST / api / 33 / dataStore / <namespace> / <key>

假设有效的JSON有效负载，创建示例的curl请求：

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X POST
  -H "Content-Type: application/json" -d "{\"foo\":\"bar\"}" -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'key_1' created."
}
```

如果您需要加密存储的数据（例如用户
凭据或类似的），您可以像这样将查询附加到 url：

    GET /api/33/dataStore/<namespace>/<key>?encrypt=true

### 更新值 { #webapi_data_store_update_values } 

更新命名空间中存在的密钥：

    PUT /api/33/dataStore/<namespace>/<key>

假设有效的JSON有效负载，示例curl请求更新：

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X PUT -d "[1, 2, 3]"
  -H "Content-Type: application/json" -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' updated."
}
```

### 删除键 { #webapi_data_store_delete_keys } 

要从名称空间中删除现有键：

    删除/ api / 33 / dataStore / <namespace> / <key>

删除示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X DELETE -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' deleted from namespace 'foo'."
}
```

要删除名称空间中的所有键：

    删除/ api / 33 / dataStore / <namespace>

删除示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -X DELETE -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Namespace 'foo' deleted."
}
```

### Sharing data store keys { #webapi_data_store_sharing } 

Sharing of data store keys follows the same principle as for other metadata sharing (see
[Sharing](#webapi_sharing)).

To get sharing settings for a specific data store key:

    GET /api/33/sharing?type=dataStore&id=<uid>

Where the id for the data store key comes from the `/metaData` endpoint for that key:

    GET /api/33/dataStore/<namespace>/<key>/metaData

As usual the `access` property in the response reflects the capabilities of the 
current user for the target entry.
Namespace wide protection might still apply and render a user incapable to
perform certain changes.

To modify sharing settings for a specific data store key:

    POST / api / 33 / sharing？type = dataStore＆id = <uid>

具有以下要求：

```json
{
  "object": {
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userAccesses": [],
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

## 用户数据存储 { #webapi_user_data_store } 

除了在所有用户之间共享的 *dataStore*
系统，还可以使用基于用户的数据存储。数据存储到
*userDataStore* 与单个用户相关联，以便每个用户
在相同的命名空间和组合键上可以有不同的数据。全部
对 *userDataStore* 的调用将与登录的
用户。这意味着只能查看、更改、删除和添加值
与当前登录的用户相关联。

    / api / 33 / userDataStore

### 用户数据存储结构 { #webapi_user_data_store_structure } 

*userDataStore* 由用户、命名空间、键和关联的
值。用户、命名空间和密钥的组合是唯一的。

Table: User data store structure

| 项目 | 描述 | Data Type |
|---|---|---|
| 用户 | The user this data is associated with | 串 |
| 命名空间 | The namespace the key belongs to | 串 |
| 键 | The key a value is stored on | 串 |
| 值 | The value stored | JSON格式 |
| Encrypted | Indicates whether the value should be encrypted | Boolean |

### 获取名称空间 { #webapi_user_data_store_get_namespaces } 

返回所有现有名称空间的数组

    GET /api/33/userDataStore

请求示例：

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore"
```

```json
[
  "foo",
  "bar"
]
```

### 取得金钥 { #webapi_user_data_store_get_keys } 

返回给定名称空间中所有现有键的数组

    GET /api/userDataStore/<namespace>

请求示例：

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
[
  "key_1",
  "key_2"
]
```

### 获取价值 { #webapi_user_data_store_get_values } 

返回给定名称空间和键的值

    GET /api/33/userDataStore/<namespace>/<key>

请求示例：

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "some": "value"
}
```

### 创造价值 { #webapi_user_data_store_create_values } 

向给定名称空间中的给定键添加新值。

    POST / api / 33 / userDataStore / <namespace> / <key>

请求示例：

```bash
curl -X POST -H "Content-Type: application/json" -u admin:district -d "['some value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'bar' in namespace 'foo' created."
}
```

如果您需要加密该值（例如用户凭据
等等）您可以像这样将查询附加到网址：

    GET /api/33/userDataStore/<namespace>/<key>?encrypt=true

### 更新值 { #webapi_user_data_store_update_values } 

更新现有值

    PUT /api/33/userDataStore/<namespace>/<key>

请求示例：

```bash
curl -X PUT -H "Content-Type: application/json" -u admin:district -d "['new value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"Created",
  "httpStatusCode":201,
  "status":"OK",
  "message":"Key 'bar' in namespace 'foo' updated."
}
```

### 删除键 { #webapi_user_data_store_delete_key } 

删除金钥

    删除/ api / 33 / userDataStore / <namespace> / <key>

请求示例：

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"Key 'bar' deleted from the namespace 'foo."
}
```

### 删除名称空间 { #webapi_user_data_store_delete_namespace } 

删除给定名称空间中的所有键

    删除/ api / 33 / userDataStore / <namespace>

请求示例：

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"All keys from namespace 'foo' deleted."
}
```

### Admin Access to another User's Datastore { #admin-access-to-another-users-datastore } 
Admins can manipulate another user's datastore by adding the `username`
parameter to any of the manipulations described above to not have them affect
the admins own datastore but the datastore of the user given by the `username`
parameter.

For example, to add a value to `Peter`'s datastore an admin uses:

    POST /api/userDataStore/<namespace>/<key>?username=Peter

## Partial Update (Experimental) { #partial-update-experimental } 
Both the datastore and user datastore allow partial updating of entry values.  

All the subsequent examples operate on the basis that the following JSON entry is in the namespace `pets` with key `whiskers`.  

```json
{
  "name": "wisker",
  "favFood": [
    "fish", "rabbit"
  ]
}
```

We can perform many update operations on this entry. The following examples use `{store}` in the API calls, please substitute with `dataStore` or `userDataStore` for your use case.

### Update root (entire entry) { #update-root-entire-entry } 
We can update the entry at the root by not supplying the `path` request param or leaving it empty `path=`.  

`PUT` `/api/{store}/pets/whiskers` with body `"whiskers"` updates the entry to be the supplied body. So a `GET` request to `/api/{store}/pets/whiskers` would now show:  
```json
"whiskers"
```

### Update at specific path { #update-at-specific-path } 
We can update the entry at a specific path by supplying the `path` request param and the property to update.

`PUT` `/api/{store}/pets/whiskers?path=name` with body `"whiskers"` updates the entry at the `name` property only. So a `GET` request to `/api/{store}/pets/whiskers` would now show the updated `name`:

```json
{
    "name": "whiskers",
    "favFood": [
        "fish",
        "rabbit"
    ]
}
```

We can update an array element at a specific path.

`PUT` `/api/{store}/pets/whiskers?path=favFood.[0]` with body `"carrot"` updates the first element in the `favFood` array only. So a `GET` request to `/api/{store}/pets/whiskers` would now show the updated `favFood`:

```json
{
    "name": "wisker",
    "favFood": [
        "carrot",
        "rabbit"
    ]
}
```

### Benefits { #benefits } 
- smaller payloads required for small changes
- less error-prone (no copy-pasting large entries to change 1 property)

## Roll (Experimental) { #roll-experimental } 
The `roll` request param enables the user to have a 'rolling' number of elements in an array. In our example we have the `favFood` array. If we wanted to update this array previously, we'd have to supply the whole payload like so:  
`PUT` `/api/{store}/pets/whiskers` with body

```json
{
    "name": "wisker",
    "favFood": [
        "fish",
        "rabbit",
        "carrot"
    ]
}
```

Now we can use the `roll` request param (with the `path` functionality) to state that we want the rolling functionality for _n_ number of elements.
In this example we state that we want the array to have a rolling value of 3, passing in an extra element in the call.  
`PUT` `/api/{store}/pets/whiskers?roll=3&path=favFood` with body `"carrot"` would result in the following state.

```json
{
    "name": "wisker",
    "favFood": [
        "fish",
        "rabbit",
        "carrot"
    ]
}
```

Since we passed the rolling value of `3`, this indicates that we only want the last 3 elements passed into the array. So if we now make another call and add a new element to the array, we would expect the first element (`fish`) to be dropped from the array.
`PUT` `/api/{store}/pets/whiskers?roll=3&path=favFood` with body `"bird"` would result in the following state:

```json
{
    "name": "wisker",
    "favFood": [
        "rabbit",
        "carrot",
        "bird"
    ]
}
```

> **Note**
>
> Once a rolling value has been set (e.g. `role=3`), it can only be increased (e.g. `roll=5`) and cannot be decreased (e.g. `roll=2`)

Dot notation does allow for nested calls. Let's say we have this current entry value:

```json
{
  "name": "wisker",
  "favFood": [
    "fish", "rabbit"
  ],
  "type": {
    "breed": ["shorthair"]
  }
}
```

If we wanted to add another breed using a rolling array we could make the call:
`PUT` `/api/{store}/pets/whiskers?roll=3&path=type.breed` with body `"small"` which would result in the following state:

```json
{
  "name": "wisker",
  "favFood": [
    "fish", "rabbit"
  ],
  "type": {
    "breed": ["shorthair, small"]
  }
}
```

### Benefits { #benefits } 
- Only interested in keeping track of _n_ values which may change over time


# Organisation unit profile { #org_unit_profile }

The organisation unit profile resource allows you to define and retrieve an information profile for organisation units in DHIS 2.

```
/api/organisationUnitProfile
```

A single organisation unit profile can be created and applies to all organisation units.

The information part of the organisation unit profile includes:

- Name, short name, description, parent organisation unit, level, opening date, closed date, URL.
- Contact person, address, email, phone number (if exists).
- Location (longitude/latitude).
- Metadata attributes (configurable).
- Organisation unit group sets and groups (configurable).
- Aggregate data for data elements, indicators, reporting rates, program indicators (configurable).

## Create organisation unit profile { #create-organisation-unit-profile } 

To define the organisation unit profile you can use a `POST` request:

```
POST /api/organisationUnitProfile
```

The payload in JSON format looks like this, where `attributes` refers to metadata attributes,  `groupSets` refer to organisation unit group sets and `dataItems` refers to data elements, indicators, data sets and program indicators:

```json
{
  "attributes": [
    "xqWyz9jNCA5",
    "n2xYlNbsfko"
  ],
  "groupSets": [
    "Bpx0589u8y0",
    "J5jldMd8OHv"
  ],
  "dataItems": [
    "WUg3MYWQ7pt",
    "vg6pdjObxsm",
    "DTVRnCGamkV",
    "Uvn6LCg7dVU",
    "eTDtyyaSA7f"
  ]
}
```

The `F_ORG_UNIT_PROFILE_ADD` authority is required to define the profile.

## Get organisation unit profile { #get-organisation-unit-profile } 

To retrieve the organisation unit profile definition you can use a `GET` request:

```
GET /api/organisationUnitProfile
```

The response will be in JSON format.

## Get organisation unit profile data { #get-organisation-unit-profile-data } 

To retrieve the organisation unit profile data you can use a `GET` request:

```
GET /api/organisationUnitProfile/{org-unit-id}/data?period={iso-period}
```

The organisation unit profile data endpoint will combine the profile definition with the associated information/data values. 

* The `org-unit-id` path variable is required and refers to the ID of the organisation unit to provide aggregated data for.
* The `iso-period` query parameter is optional and refers to the ISO period ID for the period to provide aggregated data for the data items. If none is specified, the _this year_ relative period will be used as fallback.

The response will include the following sections:

* `info`: Fixed information about the organisation unit.
* `attributes`: Metadata attributes with corresponding attribute values.
* `groupSets`: Organisation unit group sets with the corresponding organisation unit group which the organisation unit is a member of.
* `dataItems`: Data items with the corresponding aggregated data value.

Note that access control checks are performed and metadata items which are not accessible to the current user will be omitted.

请求示例如下所示：

```
GET /api/organisationUnitProfile/DiszpKrYNg8/data?period=2021
```

The profile data response payload in JSON format will look like this, where the `id` and `label` fields refer to the metadata item, and the `value` field refers to the associated value:

```json
{
  "info": {
    "id": "DiszpKrYNg8",
    "code": "OU_559",
    "name": "Ngelehun CHC",
    "shortName": "Ngelehun CHC",
    "parentName": "Badjia",
    "level": 4,
    "levelName": "Facility",
    "openingDate": "1970-01-01T00:00:00.000",
    "longitude": -11.4197,
    "latitude": 8.1039
  },
  "attributes": [
    {
      "id": "n2xYlNbsfko",
      "label": "NGO ID",
      "value": "GHE51"
    },
    {
      "id": "xqWyz9jNCA5",
      "label": "TZ code",
      "value": "NGE54"
    }
  ],
  "groupSets": [
    {
      "id": "Bpx0589u8y0",
      "label": "Facility Ownership",
      "value": "Public facilities"
    },
    {
      "id": "J5jldMd8OHv",
      "label": "Facility Type",
      "value": "CHC"
    }
  ],
  "dataItems": [
    {
      "id": "WUg3MYWQ7pt",
      "label": "Total Population",
      "value": 3503
    },
    {
      "id": "DTVRnCGamkV",
      "label": "Total population < 1 year",
      "value": 140
    },
    {
      "id": "vg6pdjObxsm",
      "label": "Population of women of child bearing age (WRA)",
      "value": 716
    },
    {
      "id": "Uvn6LCg7dVU",
      "label": "ANC 1 Coverage",
      "value": 368.2
    },
    {
      "id": "eTDtyyaSA7f",
      "label": "FIC <1y",
      "value": 291.4
    }
  ]
}
```

## Upload image for organisation unit { #upload-image-for-organisation-unit } 

To upload an image for an organisation unit you can use the `fileResources` endpoint.

```
/api/fileResources
```

The `fileResource` endpoint accepts a raw file as the request body. The `JPG`, `JPEG` and `PNG` formats are supported for organisation unit images. The domain for organisation unit images is `ORG_UNIT`.

Please consult *File resources* in the *Metadata* section for details about the `fileResources` endpoint. 

To upload an image you can send a `POST` request with `ORG_UNIT` as domain query parameter together with the image as the request payload. The `Content-Type` header should match the type of file being uploaded.

```
POST /api/fileResources?domain=ORG_UNIT
```

The `id ` property of the `response` > `fileResource` object in the JSON response will contain a reference to the identifier of the file resource.

The organisation unit entity has an `image` property which refers to the file resource image. To set the file resource reference on an organisation unit you can send a `PATCH` request to the organisation unit with a JSON payload:

```
PATCH /api/organisationUnits/{id}
```

```json
{ 
  "image": "{file-resource-id}" 
}
```

Alternatively, you can use a `PUT` request with the full organisation unit payload (fields omitted for brevity):

```
PUT /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-iid}"
  }
}
```

## Get image for organisation unit { #get-image-for-organisation-unit } 

The organisation unit entity has an `image` object which refers to a file resource by identifier. You can get the organisation unit information from the `organisationUnits` endpoint. If set, the JSON format looks like this:

```
GET /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-id}"
  }
}
```

The image file resource identifier can be used to make a request to the `fileResources` endpoint to retrieve the file content:

```
GET /api/fileResources/{id}/data
```

The `Content-Type` header will reflect the type of file being retrieved.



# 应用 { #apps } 

## 应用 { #webapi_apps } 

`/api/apps` 端点可用于安装、删除和
列出应用程序。应用程序密钥基于应用程序名称，但与所有
删除了非字母数字字符，并用破折号替换了空格。
*My app!* 将返回密钥 *My-app*。

> **注意**
>
> 在 2.28 之前，应用密钥是从 ZIP 的名称派生的
> 存档，不包括文件扩展名。使用旧格式的 URL
> 仍应在 api 中返回正确的应用程序。

    / api / 33 / apps

### 获取应用 { #webapi_get_apps } 

> **注意**
>
> 2.28之前的app属性folderName指的是实际
> 已安装应用程序的路径。能够在云上存储应用程序
> 服务，folderName 的用途已更改，现在将引用应用程序
> 键。

您可以通过列出应用程序中的所有应用程序来读取应用程序的密钥
资源并查找 *key* 属性。列出所有已安装的应用程序
JSON：

```bash
curl -u user:pass -H "Accept: application/json" "http://server.com/api/33/apps"
```

您也可以简单地将Web浏览器指向资源URL：

    http://server.com/api/33/apps

应用列表也可以按应用类型和名称过滤，通过附加
URL 的一个或多个 *filter* 参数：

    http://server.com/api/33/apps?filter=appType:eq:DASHBOARD_APP&filter=name:ilike:youtube

应用程序名称支持 *eq* 和 *ilike* 过滤器运算符，而 *appType*
仅支持 *eq*。

### 安装应用 { #webapi_install_app } 

要安装应用程序，可以发出以下命令：

```bash
curl -X POST -u user:pass -F file=@app.zip "http://server.com/api/33/apps"
```

### 删除应用 { #webapi_delete_app } 

要删除一个应用程序，您可以发出以下命令：

```bash
curl -X DELETE -u user:pass "http://server.com/api/33/apps/<app-key>"
```

### 重新加载应用 { #webapi_reload_apps } 

要强制重新加载当前安装的应用程序，您可以发出
以下命令。如果您直接手动添加文件，这很有用
到文件系统，而不是通过 DHIS2 用户上传
界面。

```bash
curl -X PUT -u user:pass "http://server.com/api/33/apps"
```

### 在实例之间共享应用 { #webapi_share_apps_between_instances } 

如果 DHIS2 实例已配置为使用云存储，应用程序
现在将安装并存储在云服务上。这将启用
多个实例在已安装的应用程序上共享相同的版本，而不是
在每个单独的实例上安装相同的应用程序。

> **注意**
>
> 在 2.28 之前，安装的应用程序只会存储在实例的
> 本地文件系统。 2.28 之前安装的应用程序仍可在
> 实例已安装，但不会与其他人共享
> 实例，因为它仍然位于实例本地文件系统上。

## 应用商店 { #webapi_app_store } 

The Web API exposes the content of the DHIS2 App Store as a JSON
representation which can found at the `/api/appHub` resource.

    /api/33/appHub

### 获取应用 { #webapi_get_app_store_apps } 

您可以使用GET请求检索应用程序：

    GET /api/33/appHub

JSON响应示例如下所述。

```json
{
  [
    {
      "name": "Tabular Tracker Capture",
      "description": "Tabular Tracker Capture is an app that makes you more effective.",
      "sourceUrl": "https://github.com/dhis2/App-repository",
      "appType": "DASHBOARD_WIDGET",
      "status": "PENDING",
      "id": "NSD06BVoV21",
      "developer": {
        "name": "DHIS",
        "organisation": "Uio",
        "address": "Oslo",
        "email": "dhis@abc.com",
      },
      "versions": [
        {
          "id": "upAPqrVgwK6",
          "version": "1.2",
          "minDhisVersion": "2.17",
          "maxDhisVersion": "2.20",
          "downloadUrl": "https://dhis2.org/download/appstore/tabular-capture-12.zip",
          "demoUrl": "http://play.dhis2.org/demo"
        }
      ],
      "images": [
        {
          "id": "upAPqrVgwK6",
          "logo": "true",
          "imageUrl": "https://dhis2.org/download/appstore/tabular-capture-12.png",
          "description": "added feature snapshot",
          "caption": "dialog",
        }
      ]
    }
  ]
}
```

### 安装应用 { #webapi_install_app_store_apps } 

您可以在 DHIS2 实例上安装应用程序，前提是您拥有
适当的权限。使用 `id` 属性引用应用程序
应用程序的相关版本。使用 POST 安装应用程序
使用版本 ID 请求以下资源：

    POST /api/33/appHub/{app-version-id}



# OpenAPI { #openapi } 

The DHIS2 server can provide an OpenAPI document for its API.
This document is created on the fly from analysis of the actual API.
It means the document is complete but details may be lost or misrepresented
due to limitations in the analysis.

Both JSON and YAML format are supported by all OpenAPI endpoints.
YAML should be requested with `Accept` header of `application/x-yaml`.

To fetch a single document containing all endpoints of the server use:

    GET /api/openapi.json
    GET /api/openapi.yaml

OBS! Be aware that this generates a document that is several MBs in size.

A document for a specific endpoint can be accessed by appending either 
`openapi.json` or `openapi.yaml` to an endpoint root path. 
For example, to generate a document for the `/users` endpoints use:

    GET /api/users/openapi.json
    GET /api/users/openapi.yaml

To generate a document with a specific selection of root paths and/or tags the
general `/openapi` endpoint can be used with one or more `tag` and `path`
selectors.

    GET /api/openapi/openapi.json?path=/users&path=/dataElements
    GET /api/openapi/openapi.yaml?tag=system&tag=metadata

Available tags are:

* `user`
* `data`
* `metadata`
* `ui`
* `analytics`
* `system`
* `messaging`
* `tracker`
* `integration`
* `login`
* `query`
* `management`

All endpoints that generate a OpenAPI document support the following optional 
request parameters:

### `failOnNameClash` { #failonnameclash } 
When set to `true`, two or more types of same simple (unqualified) name are considered clashing and the generation fails with an error. 

When set `false` (default), name clashes are resolved by adding numbers to the simple name to make each of them unique.
As a result the names are not predictable or stable. Merging simple names with their intended markdown documentation based on name will be broken. 
This option is meant as a preview feature which should only be used during development.

### `failOnInconsistency` { #failoninconsistency } 
When set to `true`, a semantic inconsistency in the declaration causes the generation to fail with an error.
Usually this indicates a programming mistake. For example, declaring a field both as required and having a default value.

When set to `false`, a semantic inconsistency is logged as warning but the generation proceeds.
This might produce a document that contradicts itself semantically but is valid formally.
