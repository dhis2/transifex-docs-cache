---
revision_date: '2024-02-12'
tags:
- Develop
- DHIS core version 2.40
template: single.html
---

# 总览 { #webapi } 

Web API 是一个组件，它使外部系统成为可能
访问和操作存储在 DHIS2 实例中的数据。更多的
准确地说，它为广泛的
为第三方等应用程序公开数据和服务方法
软件客户端、门户网站和内部 DHIS2 模块。

## 介绍 { #webapi_introduction } 

Web API 遵循 REST 背后的许多原则
建筑风格。提一些重要的：

1.  基本构建块称为*资源*。
    资源可以是任何暴露在 Web 上的东西，从文档到
    业务流程 - 客户可能想要与之交互的任何内容。
    可以检索或交换资源的信息方面
    通过资源*表示*。表示是一个视图
    任何给定时间的资源状态。例如，*可视化*
    DHIS2 中的资源表示聚合数据的可视化
    一组特定的参数。该资源可以在
    多种表示格式，包括 JSON 和 CSV。
2.  所有资源都可以由 *URI* 唯一标识（也称为
    作为 *URL*）。所有资源都有一个默认表示。你可以
    通过以下方式表明您对特定表示感兴趣
    提供 *Accept* HTTP 标头、文件扩展名或 *格式*
    查询参数。因此，为了检索 CSV 表示
    您可以提供的分析数据响应 *接受：application/csv*
    标头或将 *.csv* 或 *?format=csv* 附加到您的请求 URL。
3.  与 API 的交互需要正确使用 HTTP *方法* 或
    *动词*。这意味着对于资源，您必须发出 *GET*
    当你想要检索它时请求，当你想要时 *POST* 请求
    要创建一个，* PUT *（当您要更新时），* DELETE *（当您要删除时）
    你想删除它。

## 认证方式 { #webapi_authentication } 

DHIS2 Web API 支持三种身份验证协议：

- [基本身份验证](#webapi_basic_authentication)
- [个人访问令牌 (PAT)](#webapi_pat_authentication)
- [OAuth 2](#webapi_oauth2)

您可以验证并获取有关当前已验证的信息
用户通过向以下 URL 发出 GET 请求：

    / api / 33 / me

以及有关权限的更多信息（如果用户有特定的
权限）通过使用端点：

    / api / 33 / me / authorities
    / api / 33 / me / authorities / ALL

## 基本认证 { #webapi_basic_authentication } 

DHIS2 Web API 支持*基本身份验证*。基本认证
是一种客户端通过 HTTP 将登录凭据发送到 Web 的技术
服务器。从技术上讲，用户名后附有冒号和
密码，Base64 编码，前缀 Basic 并作为值提供
*Authorization* HTTP 标头。更正式的是：

    授权：基本base64encode（用户名：password）

大多数网络感知开发环境都支持 Basic
身份验证，例如 *Apache HttpClient* 和 *Spring RestTemplate*。
一个重要的注意事项是此身份验证方案不提供安全性
因为用户名和密码是以纯文本形式发送的，可以很容易地
被攻击者观察到。仅当服务器是
使用 SSL/TLS (HTTPS) 加密与客户端的通信。考虑这个
为了提供与 Web 的安全交互的硬性要求
应用程序接口。

## 两因素验证 { #webapi_2fa } 

DHIS2 支持两因素身份验证。这可以为每个用户启用。
启用后，用户将被要求在登录时输入 2FA 代码。您
可以阅读更多关于 2FA [这里](https://www.google.com/landing/2step/)。

## 个人访问令牌 { #webapi_pat_authentication }
个人访问令牌 (PAT) 是使用密码的替代方法
使用 API 时对 DHIS2 进行身份验证。

PAT 可以是 HTTP 基本身份验证的更安全的替代方案，
在创建新的应用程序/脚本等时应该是您的首选。

HTTP 基本身份验证被认为是不安全的，因为除其他外，
它以明文形式发送您的用户名和密码。它可能会被弃用
未来的 DHIS2 版本或选择加入，这意味着基本身份验证将
需要在配置中明确启用。

#### 重要的安全问题！ { #important-security-concerns }

您的 PAT 将自动继承您的所有权限和授权
用户有。因此，限制授予的访问权限非常重要
您的令牌取决于您打算如何使用它，请参阅**配置您的令牌**。

**如果您只希望令牌能够访问狭窄且特定的部分
服务器，建议创建一个您仅分配的新特殊用户
您希望它有权访问的角色/权限。**


### 创建令牌 { #creating-a-token }
要创建新的 PAT，您有两种选择：
* A. 在您帐户的个人资料页面的 UI 中创建令牌。
* B. 通过 API 创建令牌。

### A. 在账户页面创建令牌{ #a-creating-a-token-on-the-accounts-page }
使用您的用户名和密码登录，转到您的个人资料页面
（单击右上角，然后从下拉列表中选择“编辑个人资料”）。
在您的用户个人资料页面上，从“个人访问令牌”中选择“个人访问令牌”
左侧菜单。
您现在应该位于“管理个人访问令牌”页面并看到
文本：“您没有任何活动的个人访问令牌”。
点击“生成新令牌”来制作新令牌。
将显示“生成新令牌”弹出窗口，并向您提供两个选择：

#### 1. 服务器/脚本上下文：{ #1-serverscript-context }
_“此类型用于浏览器无法访问的集成和脚本”。_

如果您计划在应用程序、脚本或类似内容中使用令牌，则此
类型应该是你的选择。

#### 2. 浏览器上下文：{ #2-browser-context }
_“这种类型用于使用网络浏览器访问的应用程序，例如公共门户”。_

如果您需要在网页上链接到 DHIS2，或者例如嵌入 iframe 中，
这可能是您想要的令牌类型。


### 配置您的令牌 { #configuring-your-token }

选择所需的令牌类型后，您可以配置不同的访问限制
你的代币。约束是指如何限制和缩小代币的使用方式。
如果您计划在公共环境中使用令牌，这可能至关重要，
例如在另一个站点的公共仪表板上，嵌入在 iframe 中。
由于令牌始终具有与您的用户当前拥有的相同的访问/权限，因此需要特殊
如果您打算在任何您无法 100% 控制的环境中使用它，则需要小心。

**注意**：如果其他人拿到了您的代币，他们就可以做您的用户可以做的任何事情。
无法区分使用令牌执行的操作和其他操作
由您的用户执行。

**重要**：强烈建议您创建一个仅具有角色/权限的单独的唯一用户
如果您计划在不安全和/或公共环境中使用 PAT 令牌，您希望拥有该令牌，
例如在 PC 或服务器上，您无法 100% 控制或“嵌入”另一台服务器上的网页。

#### 不同的约束类型如下：{ #the-different-constraint-types-are-as-follows }
* 到期时间
* 允许的 UP 地址
* 允许的 HTTP 方法
* 允许的 HTTP 引荐来源网址

##### 过期时间{ #expiry-time }
过期时间只是设置您希望令牌可用的时间，默认为 30
天。过期时间后，令牌将仅返回 401（未经授权）消息。
您可以设置任何您想要的到期时间，但强烈建议您设置一个到期时间
这对于您的用例来说是合理的。

#### 允许的 IP 地址 { #allowed-ip-addresses }
这是一个以逗号分隔的 IP 地址列表，您要限制令牌请求的来源。

**重要**：IP 地址验证依赖于 X-Forwarded-For 标头，该标头可能会被欺骗。
为了安全起见，请确保负载均衡器或反向代理覆盖此标头。

#### 允许的 HTTP 方法 { #allowed-http-methods }
您希望令牌能够使用的 HTTP 方法的逗号分隔列表。
如果您只需要令牌来查看数据，而不需要修改或删除，则仅选择 GET HTTP 方法
说得通。

#### 允许的 HTTP 引荐来源网址 { #allowed-http-referrers }
HTTP Referer 是添加到请求中的标头，当您单击链接时，这表示哪个站点/页面
当您点击该链接时您正在上网。
在此处阅读有关 HTTP Referer 标头的更多信息：https://en.wikipedia.org/wiki/HTTP_referer

这可用于限制嵌入在另一个站点的另一个页面上的“公共”令牌的使用。
确保引用标头与应来自的站点主机名匹配，可以
帮助避免滥用令牌，例如如果有人将其发布在公共论坛上。

**Important**: this is not a security feature. The `referer` header can easily be spoofed.
This setting is intended to discourage unauthorized third-party developers from connecting
to public access instances.

#### 保存您的令牌：{ #saving-your-token }
完成令牌配置后，您可以通过单击“生成新令牌”来保存它
按钮，位于弹出窗口的右下角。
执行此操作时，将保存令牌并在服务器上生成秘密令牌密钥。
新的秘密令牌密钥将以绿色背景显示在 PAT 令牌列表的底部，
以及文本“新创建的令牌”。
秘密令牌密钥将类似于以下内容：
```
d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```
**重要**：这个生成的秘密令牌密钥只会显示一次，因此很重要
您现在复制令牌密钥并将其保存在安全的地方以供以后使用。
秘密令牌密钥将在服务器上安全地进行哈希处理，并且只有该秘密令牌的哈希值
密钥将被保存到数据库中。这样做是为了最大限度地减少安全影响，如果有人得到
未经授权访问数据库，类似于处理密码的方式。

### B. 通过 API 创建令牌 { #b-creating-a-token-via-the-api }

如何使用 API 创建新的个人访问令牌的示例：

```
POST https://play.dhis2.org/dev/api/apiToken
Content-Type: application/json
Authorization: Basic admin district

{}
```
**注意**：请记住有效负载中的空 JSON 正文 (`{}`)！

这将返回包含类似于以下内容的令牌的响应：
```json
{
  "httpStatus": "已创建",
  "httpStatusCode": 201,
  "status": "正常",
  "response": {
     "responseType": "ApiTokenCreationResponse",
     "key": "d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092",
     "uid": "jJYrtIVP7qU",
     "klass": "org.hisp.dhis.security.apikey.ApiToken",
     "errorReports": []
  }
}
```

**重要**：令牌密钥在此响应中仅显示一次。
您需要将其复制并保存在安全的地方以供以后使用！

令牌本身由三部分组成：
1. 前缀：(`d2pat_`) 表示这是什么类型的令牌。
2. 随机字节 Base64 编码：(`5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ`)
3. CRC32 校验和：(`1151814092`) 校验和部分用 0 填充，使其始终保持十个字符长。


#### 通过 API 配置您的令牌：{ #configure-your-token-via-the-api }
要更改令牌的任何限制，您可以发出以下 HTTP API 请求。

**注意**：创建令牌后只能修改约束！

```
PUT https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: Basic admin district
```

```json
{
  “版本”：1，
  “类型”：“PERSONAL_ACCESS_TOKEN”，
  “过期”：163465349603200，
  “属性”： [
      {
        "type": "IpAllowedList",
        “allowedIps”：[“192.168.0.1”]
      },
      {
        "type": "方法允许列表",
        “允许的方法”：[“GET”]
      }
  ]
}
```

### 使用您的个人访问令牌{ #using-your-personal-access-token }

要使用新创建的令牌发出请求，请使用授权标头
因此。
授权标头格式为：
```
Authorization: ApiToken [YOUR_SECRET_API_TOKEN_KEY]
```
**例子**：
```
GET https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


### 删除您的个人访问令牌{ #deleting-your-personal-access-token }
您可以在创建 PAT 的个人资料页面的 UI 中删除 PAT，
或者通过这样的 API：
```
DELETE https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


## OAuth2 { #webapi_oauth2 }

DHIS2支持* OAuth2 *身份验证协议。 OAuth2是开放的
授权标准，允许第三方客户代表DHIS2用户进行连接，并为对Web API的后续请求*bearer token* 。 DHIS2不支持细粒度
OAuth2角色，而是根据用户角色提供应用程序访问权限
DHIS2用户的身份。

您要允许其OAuth 2身份验证的每个客户端都必须
在DHIS2中注册。要添加新的OAuth2客户端，请转到`应用>设置> OAuth2客户端`。
在用户界面中，单击*添加新*，然后输入所需的客户端名称和授权类型。

#### 使用Web API添加客户端 { #adding-a-client-using-the-web-api } 

可以通过 Web API 添加 OAuth2 客户端。例如，我们可以
发送这样的有效载荷：

```json
{
  "name": "OAuth2 Demo Client",
  "cid": "demo",
  "secret": "1e6db50c-0fee-11e5-98d0-3c15c2c6caf6",
  "grantTypes": [
    "password",
    "refresh_token",
    "authorization_code"
  ],
  "redirectUris": [
    "http://www.example.org"
  ]
}
```

可用以下命令发送有效负载：

```bash
SERVER="https://play.dhis2.org/dev"
curl -X POST -H "Content-Type: application/json" -d @client.json
  -u admin:district "$SERVER/api/oAuth2Clients"
```

我们将使用此客户端作为下一个赠款类型示例的基础。

#### 授权类型密码 { #webapi_oauth2_password } 

所有授权类型中最简单的是 *password* 授权类型。这
授权类型类似于基本身份验证，因为它
要求客户端收集用户的用户名和密码。作为
例如，我们可以使用我们的演示服务器：

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d grant_type=password -d username=admin -d password=district
```

这将给您类似的响应：

```json
{
  "expires_in": 43175,
  "scope": "ALL",
  "access_token": "07fc551c-806c-41a4-9a8c-10658bd15435",
  "refresh_token": "a4e4de45-4743-481d-9345-2cfe34732fcc",
  "token_type": "bearer"
}
```

现在，我们将专注于 `access_token`，这就是我们
将用作我们的身份验证（承载）令牌。例如，我们将得到
使用我们的令牌的所有数据元素：

```bash
SERVER="https://play.dhis2.org/dev"
curl -H "Authorization: Bearer 07fc551c-806c-41a4-9a8c-10658bd15435" "$SERVER/api/33/dataElements.json"
```

#### 授予类型refresh \ _token { #webapi_refresh_token } 

通常，访问令牌的有效性有限。你可以看看
在上一个示例中响应的 `expires_in` 属性处
了解令牌何时到期。要获得新的`access_token`，您
可以再次往返服务器并使用`refresh_token`
这允许您获得更新的令牌而无需要求
再次使用用户凭据。

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"
REFRESH_TOKEN="a4e4de45-4743-481d-9345-2cfe34732fcc"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d "grant_type=refresh_token" -d "refresh_token=$REFRESH_TOKEN"
```

响应与获得令牌开始时的响应完全相同。

#### 授予类型authorization_code { #webapi_authorization_code } 

如果您不想的话，建议使用授权代码授予类型
在外部存储用户凭据。它允许DHIS2收集
用户名/密码直接来自用户而不是客户端
收集它们，然后代表用户进行身份验证。请成为
注意这种方法使用了客户端的` redirectUris`部分
有效载荷。

第 1 步：使用 Web 浏览器访问以下 URL。如果你有不止一个
重定向 URI，您可能需要添加 `&redirect_uri=http://www.example.org`
到网址：

```bash
SERVER="https://play.dhis2.org/dev"
$SERVER/uaa/oauth/authorize?client_id=demo&response_type=code
```

第 2 步：在用户成功登录并接受您的
客户端访问，它将重定向回您的重定向 uri，如下所示：

    http://www.example.org/?code=XYZ

第 3 步：这一步类似于我们在密码授予类型中所做的，
使用给定的代码，我们现在将要求访问令牌：

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -u demo:$SECRET -H "Accept: application/json" $SERVER/uaa/oauth/token
-d "grant_type=authorization_code" -d "code=XYZ"
```

## 错误和信息消息 { #webapi_error_info_messages } 

Web API 对所有错误/警告和
信息性消息：

```json
{
  "httpStatus": "Forbidden",
  "message": "You don't have the proper permissions to read objects of this type.",
  "httpStatusCode": 403,
  "status": "ERROR"
}
```

这里我们可以从消息中看到用户尝试访问
我无法访问的资源。它使用http状态代码403，
HTTP 状态消息*禁止*和描述性消息。

表：WebMessage 属性

| 名称 | 描述 |
|---|---|
| http状态 | 有关此响应的 HTTP 状态消息，请参阅 RFC 2616（第 10 节）了解更多信息。 |
| http状态码 | 此响应的 HTTP 状态代码，请参阅 RFC 2616（第 10 节）了解更多信息。 |
| 地位 | DHIS2状态，可能的值为*OK* | *WARNING* | *ERROR*，其中`OK`表示一切顺利，`ERROR`表示操作未完成，`WARNING`表示操作部分成功，如果消息包含`response`属性，请在那里查找更多信息。 |
| 信息 | 用户友好的消息，告知操作是否成功。 |
| 开发消息 | 更具技术性、对开发人员友好的消息（当前未使用）。 |
| 回复 | Extension point for future extensions of the `WebMessage` format. |

## 日期和期间格式 { #webapi_date_perid_format } 

在整个 Web API 中，我们指的是日期和期间。日期格式
是：

    年-月-日

例如，如果您想表达 2014 年 3 月 20 日，则必须使用
*2014-03-20*。

下表描述了期间格式（也可在
API 端点`/api/periodTypes`)

表：期间格式

| 间隔 | 格式 | 例 | 描述 |
|---|---|---|---|
| 天 | 年月日 | 20040315 | 2004 年 3 月 15 日 |
| 星期 | yyyyWn | 2004W10 | 2004 年第 10 周 |
| 周周三 | yyyy星期三 | 2015年星期三W5 | 第 5 周从周三开始 |
| 周周四 | yyyyThuWn | 2015年第6周星期四 | 第 6 周，周四开始 |
| 周周六 | yyyySatWn | 2015年星期六W7 | 第 7 周从周六开始 |
| 周周日 | yyyySunWn | 2015周日W8 | 第 8 周从周日开始 |
| 双周 | yyyyBiWn | 2015BiW1 | 20015 年第 1-2 周 |
| 月 | 年月日 | 200403 | 2004年3月 |
| 双月 | yyyyMMB | 200401B | 2004年1月-2月 |
| 四分之一 | yyyyQn | 2004年第一季度 | 2004年1月-3月 |
| 6个月 | yyyySn | 2004S1 | 2004年1月至6月 |
| 四月六个月 | yyyy四月Sn | 2004年4月S1 | 2004年4月-9月 |
| 年 | yyyy | 2004 | 2004 |
| 财政年度四月 | yyyy四月 | 2004年4月 | 2004年4月-2005年3月 |
| 财政年度七月 | yyyy七月 | 2004年7月 | 2004年7月-2005年6月 |
| 财政年度十月 | 十月 | 2004年10月 | 2004年10月-2005年9月 |


### 相对时期 { #webapi_date_relative_period_values } 


在 API 的某些部分，例如分析资源，您可以
除了固定期间（如上定义）之外，还使用相对期间。
相对期间是相对于当前日期并允许例如
用于创建动态报告。可用的相对期间值是：

    THIS_WEEK, LAST_WEEK, LAST_4_WEEKS, LAST_12_WEEKS, LAST_52_WEEKS,
    THIS_MONTH, LAST_MONTH, THIS_BIMONTH, LAST_BIMONTH, THIS_QUARTER, LAST_QUARTER,
    THIS_SIX_MONTH, LAST_SIX_MONTH, MONTHS_THIS_YEAR, QUARTERS_THIS_YEAR,
    THIS_YEAR, MONTHS_LAST_YEAR, QUARTERS_LAST_YEAR, LAST_YEAR, LAST_5_YEARS, LAST_10_YEARS, LAST_10_FINANCIAL_YEARS, LAST_12_MONTHS, 
    LAST_3_MONTHS, LAST_6_BIMONTHS, LAST_4_QUARTERS, LAST_2_SIXMONTHS, THIS_FINANCIAL_YEAR,
    LAST_FINANCIAL_YEAR, LAST_5_FINANCIAL_YEARS

### 自定义日期周期{ #webapi_date_custom_date_periods }

Analytics `query` resources support extra parameters to express periods.

Default `pe` dimension will fall back to:

- `eventDate` for `/analytics/events/query`
- `enrollmentDate` for `/analytics/enrollments/query`

允许在一个或多个日期字段上添加条件并将它们组合起来。

#### 自定义日期周期的使用{ #usage-of-custom-date-periods }

在支持自定义日期周期的资源中，存在额外的查询参数，这些参数将被组合起来表达时间维度上的条件。

| 自定义日期期间 | 事件查询资源  | 招生查询资源 |
|--------------------|------------------------|---------------------------|
| `事件日期`        | [X]                    | [ ]                       |
| `注册日期`   | [X]                    | [X]                       |
| `预定日期`    | [X]                    | [ ]                       |
| `事件日期`     | [X]                    | [X]                       |
| `lastUpdated`      | [X]                    | [X]                       |

条件可以用以下形式表示：

`分析/事件/查询/...？...&eventDate=2021&...`

可以在同一查询中组合更多时间字段：

`分析/事件/查询/...？...&eventDate=2021&incidentDate=202102&...`

All of these conditions can be combined with `pe` dimension:

`分析/事件/查询/...？...&dimension=pe:TODAY&enrollmentDate=2021&incidentDate=202102&...`

Supported formats are described in "date and period format" above. An extra format is provided to express a range of dates: `yyyyMMdd_yyyyMMdd` and `yyyy-MM-dd_yyyy-MM-dd`.

在下面的示例中，端点将返回计划在 20210101 到 20210104 之间发生的事件：

`分析/事件/查询/...？...&dimension=pe:TODAY&enrollmentDate=2021&incidentDate=202102&scheduledDate=20210101_20210104&...`


## 权威机构{ #authorities }
可以使用以下方式列出系统权限 ID 和名称：

    /api/权威机构

它返回以下格式：
```json
{
  "systemAuthorities": [
    {
      "id": "ALL",
      "name": "ALL"
    },
    {
      "id": "F_ACCEPT_DATA_LOWER_LEVELS",
      "name": "Accept data at lower levels"
    }
  ]
}
```

# 元数据 { #metadata } 

## 标识符方案 { #webapi_identifier_schemes } 

本节提供标识符方案概念的解释。
标识符方案用于将元数据对象映射到其他元数据
在导入期间，并将元数据呈现为导出的一部分。笔记
并非所有方案都适用于所有 API 调用，也并非所有方案都适用
方案可用于输入和输出。这在
解释各种 API 端点的部分。

列出了可用的全套标识符方案对象类型
下面，使用在查询中使用的属性名称：

  - 方案

  - 数据元素标识方案

  - 类别选项组合 ID 方案

  - 组织单位 ID 方案

  - 程序标识方案

  - 程序阶段标识方案

  - 跟踪实体 ID 方案

  - trackedEntityAttributeIdScheme

通用 idScheme 适用于所有类型的对象。有可能
被特定的对象类型覆盖。

所有参数的默认方案是 UID（稳定的 DHIS2
身份标识）。支持的标识符方案在
下表。

表：方案值

| 方案 | 描述 |
|---|---|
| ID, UID | 匹配 DHIS2 稳定标识符，这是默认的 ID 方案。 |
| 代码 | Match on DHIS2 Code，主要用于与外部系统交换数据。 |
| 名称 | 匹配 DHIS2 名称，请注意，这使用可用的 *object.name*，而不是翻译名称。另请注意，名称并不总是唯一的，在这种情况下，不能使用它们。 |
| ATTRIBUTE:ID | 匹配元数据属性，该属性需要分配给您要匹配的类型，并且唯一属性设置为 *true*。它的主要用途也是与外部系统交换数据，它比*CODE*有一些优势，因为可以添加多个属性，因此它可以用于与多个系统同步。 |

请注意，标识符方案不是一个独立的功能，但需要
与数据值导入、元数据导入等资源结合使用
GeoJson 导入。

例如，指定 CODE 作为通用 id 方案并覆盖
使用 UID 作为组织单位 ID 方案，您可以使用这些查询
参数：

    ？idScheme = CODE＆orgUnitIdScheme = UID

再举一个例子，为组织单位 id 指定一个属性
方案，数据元素 id 方案的代码并使用默认 UID id
您可以使用这些参数的所有其他对象的方案：

    ？orgUnitIdScheme =属性：j38fk2dKFsG＆dataElementIdScheme = CODE

## 浏览Web API { #webapi_browsing_the_web_api } 

浏览 Web API 的入口点是 `/api`。这个资源
提供所有可用资源的链接。四种资源表示
格式始终适用于所有资源：HTML、XML、JSON、
和 JSONP。某些资源将具有其他可用格式，例如 MS
Excel、PDF、CSV 和 PNG。要从 Web 浏览器探索 API，请导航
到 `/api` 入口点并按照链接到您想要的
资源，例如`/api/dataElements`。对于所有资源
返回元素列表，某些查询参数可用于修改
响应：

表：查询参数

| 范围 | 选项值 | 默认选项 | 描述 |
|---|---|---|---|
| 寻呼 | true &#124; false | 真正 | 指示是否返回页面中的元素列表。 |
| 页 | 数字 | 1 | 定义要返回的页码。 |
| 页面大小 | 数字 | 50 | 定义为每个页面返回的元素数量。 |
| 命令 | 属性：asc/iasc/desc/idesc || 使用指定的顺序对输出进行排序，仅支持持久且简单的属性（无集合、idObject 等）。 iasc 和 idesc 不区分大小写排序。 |

如何使用这些参数获取完整列表的示例
XML 响应格式的数据元素组是：

    /api/dataElementGroups.xml?links=false&paging=false

您可以在 name 属性上查询元素而不是返回
使用 *query* 查询变量的完整元素列表。在这个例子中
我们查询名称中带有“贫血”一词的所有数据元素：

    / api / dataElements？query =贫血

您可以像这样获取特定页面和对象的页面大小：

    /api/dataElements.json?page=2&pageSize=20

您可以像这样完全禁用分页：

    /api/indicatorGroups.json?paging=false

要基于特定属性对结果进行排序：

    /api/indicators.json?order=shortName:desc

您可以通过以下方式在所有对象类型中根据对象的 ID 查找对象
*identifiableObjects* 资源：

    / api / identifiableObjects / <id>

### 翻译 { #webapi_translation } 

DHIS2 支持数据库内容的翻译，例如数据元素、
指标和计划。 Web API 中的所有元数据对象都具有
用于显示/UI 目的的属性，其中包括
*显示名称*、*显示短名称*、*显示描述* 和
*displayFormName*（用于数据元素和跟踪的实体属性）。

表：翻译选项

| 范围 | 价值观 | 描述 |
|---|---|---|
| 翻译 | true &#124; false | 转换元数据输出中的 display\* 属性（数据元素和跟踪实体属性的 displayName、displayShortName、displayDescription 和 displayFormName）。默认值为 true。 |
| 语言环境 | 使用的区域设置 | 使用指定的区域设置翻译元数据输出（需要translate=true）。 |

### 翻译API { #webapi_translation_api } 

对象的翻译呈现为对象本身的一部分
在* translation *数组中。请注意，
JSON / XML有效负载的*翻译*数组通常为您预先过滤，这意味着它们不能直接用于导入/导出翻译（因为那样会
通常会覆盖当前用户以外的语言环境）。

在用户语言环境中过滤了转换数组的数据元素示例：

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute French",
  "translations": [
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    }
  ]
}
```

转换关闭的数据元素示例：

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute Flaccid Paralysis (Deaths < 5 yrs)",
  "translations": [
    {
      "property": "FORM_NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "Accute Flaccid Paral"
    },
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "DESCRIPTION",
      "locale": "en_FK",
      "value": "aa"
    }
  ]
}
```

请注意，即使您得到未过滤的结果，并且正在使用
适当的类型端点，即我们不允许的 `/api/dataElements` 
更新，因为这样做很容易犯错误并覆盖
其他可用的语言环境。

要阅读和更新翻译，您可以使用特殊翻译
每个对象资源的端点。可以通过*GET*或访问
在适当的`/ api / <object-type> / <object-id> / translations `端点上* PUT *。

As an example, for a data element with identifier `FTRrcoaog83`, you could use
`/api/dataElements/FTRrcoaog83/translations` to get and update
translations. The fields available are `property` with options *NAME*,
*SHORT_NAME*, *FORM_NAME*, *DESCRIPTION*, `locale` which supports any valid
locale ID and the translated property `value`.

法语语言环境的NAME属性示例：

```json
{
  "property": "NAME",
  "locale": "fr",
  "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
}
```

然后将此有效负载添加到翻译数组中，并发回
到适当的端点：

```json
{
  "translations": [
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
    }
  ]
}
```

对于ID为* FTRrcoaog83 *的数据元素，您可以* PUT *此代码为
`/ api / dataElements / FTRrcoaog83 / translations`。确保发送全部
特定对象的翻译，而不仅仅是单个语言环境的翻译
（否则，您可能会覆盖其他区域的现有语言环境
语言环境）。

如果数据值已成功保存或更新，则状态代码将为`204 No Content`，如果存在验证错误（例如，同一`语言环境`有多个`SHORT_NAME`），则状态代码将为`404 Not Found`。


### Web API版本 { #webapi_api_versions } 

Web API的版本从DHIS 2.25开始。 API版本
遵循DHIS2主版本号。例如，API
DHIS 2.33的版本是`33`。

您可以通过包含版本号来访问特定的 API 版本
在`/api` 组件之后，作为这样的例子：

    / api / 33 / dataElements

如果省略 URL 的 version 部分，系统将使用当前的
API 版本。例如，对于 DHIS 2.25，在省略 API 部分时，
系统将使用 API 版本 25。在开发 API 客户端时，它是
建议使用显式 API 版本（而不是省略 API
版本），因为这将保护客户端免受不可预见的 API 更改。

将支持最后三个 API 版本。例如，DHIS
2.27 版本将支持 API 版本 27、26 和 25。

请注意，元数据模型没有版本控制，您可能
体验变化，例如在对象之间的关联中。这些变化
将记录在 DHIS2 主要版本发行说明中。

## 元数据对象过滤器 { #webapi_metadata_object_filter } 

要过滤元数据，可以执行多种过滤操作
应用于返回的元数据列表。过滤器的格式
本身是直接的并且遵循模式
*property:operator:value*，其中 *property* 是
您要过滤的元数据，*operator* 是比较运算符
您想要执行的操作，*value* 是要检查的值（并非所有
运营商需要价值）。

请参阅*架构*部分以了解哪些属性可用。
除了列出的属性之外，过滤器还可以应用于自定义属性
通过使用属性的 ID 作为属性名称来获取值。

递归过滤，即。对关联对象或集合进行过滤
对象，也受支持。

表：可用的运算符

| 操作员 | 类型 | 所需值 | 描述 |
|---|---|---|---|
| 情商 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;枚举&#124;集合（检查大小）&#124;日期 | 真正 | 平等 |
| !eq | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;枚举&#124;集合（检查大小）&#124;日期 | 真正 | 不等式 |
| 讷 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;枚举&#124;集合（检查大小）&#124;日期 | 真正 | 不等式 |
| 喜欢 | 细绳 | 真正 | 区分大小写的字符串，在任何地方匹配 |
| ！喜欢 | 细绳 | 真正 | 区分大小写的字符串，不匹配任何地方 |
| $喜欢 | 细绳 | 真正 | 区分大小写的字符串，匹配开始 |
| ！$喜欢 | 细绳 | 真正 | 区分大小写的字符串，不匹配开头 |
| 喜欢$ | 细绳 | 真正 | 区分大小写的字符串，匹配结束 |
| ！喜欢$ | 细绳 | 真正 | 区分大小写的字符串，不匹配结尾 |
| 我喜欢 | 细绳 | 真正 | 不区分大小写的字符串，在任何地方匹配 |
| ！我喜欢 | 细绳 | 真正 | 不区分大小写的字符串，任何地方都不匹配 |
| $喜欢 | 细绳 | 真正 | 不区分大小写的字符串，匹配开始 |
| !$喜欢 | 细绳 | 真正 | 不区分大小写的字符串，不匹配开头 |
| 我喜欢$ | 细绳 | 真正 | 字符串不区分大小写，匹配结束 |
| !喜欢$ | 细绳 | 真正 | 不区分大小写的字符串，不匹配结尾 |
| GT | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;集合（检查大小）&#124;日期 | 真正 | 比...更棒 |
| 葛 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;集合（检查大小）&#124;日期 | 真正 | 大于或等于 |
| 其 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;集合（检查大小）&#124;日期 | 真正 | 少于 |
| 乐 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;集合（检查大小）&#124;日期 | 真正 | 小于或等于 |
| 无效的 | 全部 | 假 | 属性为空 |
| ！无效的 | 全部 | 假 | 属性不为空 |
| 空的 | 收藏 | 假 | 收藏品为空 |
| 代币 | 细绳 | 真正 | 匹配搜索属性中的多个标记 |
| !令牌 | 细绳 | 真正 | 搜索属性中的多个标记不匹配 |
| 在 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;日期 | 真正 | 查找与 1 个或多个值匹配的对象 |
| ！在 | 字符串 &#124;布尔值 &#124;整数 &#124;浮动&#124;日期 | 真正 | 查找与 1 个或多个值不匹配的对象 |

运算符将作为逻辑 *and* 查询应用。如果您需要*或*
查询，您可以查看 *in* 过滤器和下面的部分。
过滤机制允许递归。请参阅下面的一些示例。

获取ID属性为ID1或ID2的数据元素：

    / api / dataElements？filter = id：eq：ID1＆filter = id：eq：ID2

获取具有 id ID1 的数据集的所有数据元素：

    /api/dataElements?filter=dataSetElements.dataSet.id:eq:ID1

使用聚合运算符 *sum* 和值类型获取所有数据元素
*整数*：

    /api/dataElements.json?filter=aggregationOperator:eq:sum&filter=type:eq:int

您可以在集合中进行过滤，例如获取数据元素
是 *ANC* 数据元素组的成员，您可以使用以下内容
使用关联数据元素组的 id 属性进行查询：

    /api/dataElements.json?filter=dataElementGroups.id:eq:qfxEYY9xAl6

获取具有元数据特定属性值的数据元素
属性，属性 ID 和属性值的过滤器可以是
使用相同的集合查询语法指定：

    /api/dataElements.json?filter=attributeValues.attribute.id:eq:n2xYlNbsfko&filter=attributeValues.value:eq:AFP

获取具有任何选项集的数据元素：

    /api/dataElements?filter=optionSet:!null

由于默认情况下所有运算符都是 *and*，因此您无法找到数据
匹配多个 id 的元素，为此您可以使用 *in*
操作员。

    /api/dataElements.json?filter=id:in:[fbfJHSPpUQD,cYeuwXTCPkU]

### 逻辑运算符 { #webapi_metadata_logical_operator } 

如前一节所述，应用了默认逻辑运算符
过滤器是 *AND* 这意味着所有对象过滤器必须是
匹配。但是，在某些情况下，您希望匹配其中之一
几个过滤器（可能是 id 和 code 字段），在这些情况下，它是
可以将根逻辑运算符从 *AND* 切换为 *OR*
使用 *rootJunction* 参数。

示例：正常过滤，其中 id 和 code 必须匹配才能具有
结果返回

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1

示例：过滤逻辑运算符已切换为 OR 的位置
现在只有一个过滤器必须匹配才能产生结果
    回

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1&rootJunction=OR

### 可识别的令牌过滤器 { #identifiable-token-filter } 

除了上述基于特定属性的过滤之外，
我们还通过* token *基于* AND *过滤了一组
属性：ID，代码和名称（如果可用，还包括shortName）。这些
属性通常称为*可识别*。这个想法是为了
过滤ID，名称，代码或简称中包含某些内容的元数据。

示例：过滤所有包含 *2nd* 的数据元素
如下： id,name,code,shortName

    /api/dataElements.json?filter=identific:token:2nd

也可以指定多个过滤值。

示例：获取在任何 *identifiable* 属性中找到 *ANC visit* 的所有数据元素。系统返回所有数据元素，其中在可识别属性中的任何地方都可以找到令牌（ANC 和访问）。

    /api/dataElements.json?filter=identifiable:token:ANC访问

也可以将可识别过滤器与基于属性的过滤器结合起来，并期望应用 *rootJunction*。

    /api/dataElements.json?filter=identifiable:token:ANC visit＆filter = displayName：ilike：tt1

    /api/dataElements.json?filter=identifiable:token:ANC访问
      ＆filter = displayName：ilike：tt1＆rootJunction = OR

### 用于跟踪实体属性的仅可索引过滤器 { #indexable-only-filter-for-tracked-entity-attributes }

对于跟踪的实体属性，除了前面提到的过滤功能之外，还有一个特殊的过滤器。
一些跟踪的实体属性是创建三元组索引的候选属性，以获得更好的查找性能。
使用设置为 true 的 *indexableOnly* 参数，可以过滤结果以仅包含可索引的三元组属性。

示例：获取所有可索引的跟踪实体属性。

    /api/trackedEntityAttributtes.json?indexableOnly=true

Additional filters along with the `indexableOnly` parameter can be specified.

示例：获取在任何 *name* 属性中找到 *ANC* 的所有跟踪实体属性。系统返回跟踪的实体属性，其中名称与提供的关键字匹配以及该属性是否可索引。

    /api/trackedEntityAttributtes.json?filter=name:like:ANC&indexableOnly=true

## 元数据字段过滤器 { #webapi_metadata_field_filter } 

在许多情况下，元数据的默认视图可能太
冗长。客户端可能只需要每个对象中的几个字段并且想要
从响应中删除不必要的字段。发现哪些字段
适用于每个对象，请参阅 *schema* 部分。
除了列出的属性之外，还可以包括自定义属性
对于顶级对象，使用属性的 ID 作为属性名称。

The format for include/exclude allows for infinite recursion. To filter
at the "root" level you can just use the name of the field,
i.e. `?fields=id,name` which would only display the `id` and
`name` fields for every object. For objects that are either collections or
complex objects with properties on their own, you can use the format
`?fields=id,name,dataSets[id,name]` which would return `id`, `name` of
the root, and the `id` and `name` of every data set on that object.
Negation can be done with the exclamation operator, and we have a set of
presets of field select. Both XML and JSON formats are supported.

**示例**：在指标资源上获取`id`和`name`：

    / api / indicators？fields = id，名称

**示例**：从数据元素中获取`id`和`name`，以及`id`和`name`
从相关数据集：

    / api / dataElements？fields = id，name，dataSets [id，name]

**Example**: Get `id`, `name` and the value of a user defined attribute 
with ID `DnrLSdo4hMl` for organisation units:

    /api/organizationUnits?fields=id,名称,DnrLSdo4hMl

The attribute is then included as property `DnrLSdo4hMl` of each
matching object in the response. This can be renamed using the `rename` 
transformer as shown in the next section.

要从输出中排除字段，可以使用感叹号`!`。
操作符。这是在查询中的任何地方都允许的，而根本不会
包括该属性，因为它可能已经插入了某些
预设。

一些预设（选定的字段组）可用并且可以应用
使用`:` 运算符。

表：属性运算符

| 操作员 | 描述 |
|---|---|
|  <field-name\> | 包括具有名称的属性（如果存在）。 |
|  <object\> [ <field-name\> , ...] | 包含集合中的字段（将应用于该集合中的每个对象）或仅应用于单个对象。 |
| ！ <field-name\> , <object\> [! <field-name\> | 不要包含此字段名称，它也适用于对象/集合内部。当您使用预设来包含字段时很有用。 |
| \*, <object\> [\*] | 包含某个对象上的所有字段，如果应用于集合，它将包含该集合上所有对象上的所有字段。 |
| : <preset\> | 用于选择多个字段的别名。目前提供三种预设，请参阅下表了解说明。 |

表：字段预设

| 预设 | 描述 |
|---|---|
| 全部 | 对象的所有字段 |
| \* | 所有人的别名 |
| 可识别的 | 包括 id、名称、代码、已创建和最后更新字段 |
| 可命名的 | 包括 id、name、shortName、code、description、created 和 lastUpdated 字段 |
| 坚持 | 返回对象上的所有持久属性，不考虑该对象是否是关系的所有者。 |
| 所有者 | 返回对象上的所有持久属性，其中该对象是所有属性的所有者，此有效负载可用于通过 API 进行更新。 |

**示例**：包括数据集中除组织单位之外的所有字段：

    / api / dataSets？fields =：all，！organizationUnits

**示例**：仅包含ID，名称和数据集中的组织单位集合，但不包含组织单位中的ID：

    / api / dataSets / BfMAe6Itzgt？fields = id，name，organisationUnits [：all，！id]

**示例**：包括所有指标的可命名属性：

    /api/indicators.json?fields=:nameable

### 现场变压器 { #webapi_field_transformers } 

字段转换可用于转换属性。语法如下所述。

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

这会将 *id* 属性重命名为 *i*，将 *name* 属性重命名为 *n*。

通过重复变压器操作符，可以将多个变压器应用于单个属性：

    /api/dataElementGroups.json?fields=id,displayName,dataElements~isNotEmpty~rename(haveDataElements）

下表描述了支持的变压器运算符。

表：可用的变压器

| 名称 | 论据 | 描述 |
|---|---|---|
| 尺寸 || 给出字符串的大小（长度）和集合 |
| 是空的 || 字符串或集合是否为空 |
| 不为空 || 字符串或集合不为空 |
| 改名 | 参数1：名称 | 重命名属性名称 |
| 寻呼 | Arg1：页面，Arg2：页面大小 | 分页集合，默认 pageSize 为 50。 |
| 采摘 | 可选 Arg1：字段名称 | 将对象数组转换为该对象的选定字段的数组。默认情况下，使用集合返回的第一个字段（通常是 ID）。 |
| 密钥依据 | 可选 Arg1：字段名称 | 将对象数组转换为使用 fieldName（默认 id）作为键的对象。例如，这对于 JavaScript 中的快速查找很有用 |

#### 例子 { #webapi_field_transformers_examples } 

变压器使用示例如下。

获取集合的大小：

    /api/dataElements?fields=dataSets~size

测试集合是否为空：

    /api/dataElements?fields=dataSets~isEmpty

测试集合是否不为空：

    /api/dataElements?fields=dataSets~isNotEmpty

重命名属性：

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

对集合应用分页：

    /api/dataElementGroups?fields=id,displayName,dataElements~paging(1;20)

获取包含组织单位 ID 的数组：

    /api/categoryOptions.json?fields=id,organizationUnits~pluck

获取包含组织单位名称的数组：

    /api/categoryOptions.json?fields=id,organizationUnits~pluck[名称]

通过`d`字段键入 dataElements 数组：

    /api/dataElementGroups.json?fields=id,名称,dataElements~keyBy[id,名称,valueType]

通过`valueType`字段键入 dataElements 数组，因为多次点击这将生成（数据元素的）数组：

    /api/dataElementGroups.json?fields=id,名称,dataElements~keyBy(valueType)[id,名称,valueType]

## 元数据创建，读取，更新，删除，验证 { #webapi_metadata_crud } 

DHIS2 中的所有元数据实体都有自己的 API 端点，支持
*CRUD* 操作（创建、读取、更新和删除）。端点 URL
遵循以下格式：

    / api / <entityName>

_entityName_ 使用驼峰命名法。例如，端点
对于_数据元素_是：

    / api / dataElements

### 创建/更新参数 { #webapi_metadata_create_update } 

以下请求查询参数可用于所有元数据端点。

表：可用的查询过滤器

| 参数 | 类型 | 需要 | 选项（默认为默认） | 描述 |
|---|---|---|---|---|
| 预热缓存 | 布尔值 | 假 | true &#124; false | 打开/关闭缓存映射预热。默认情况下此功能处于打开状态，关闭此功能将使导入程序的初始加载时间大大缩短（但会使导入本身变慢）。这主要用于您想要导入一个小的 XML/JSON 文件，并且不想等待缓存映射预热的情况。 |
| 导入策略 | 枚举 | 假 | 创建_并_更新&#124;创建&#124;更新&#124;删除 | 要使用的导入策略，请参阅下文了解更多信息。 |
| 合并模式 | 枚举 | 假 | 替换、合并 | 进行更新时合并对象的策略。 REPLACE 只会用提供的新值覆盖属性，MERGE 仅当属性不为 null 时才设置该属性（仅当提供了该属性时）。 |

### 创建和更新对象 { #webapi_creating_updating_objects } 

要创建新对象，您需要知道端点、类型
格式，并确保您拥有所需的权限。作为
例如，我们将创建和更新一个*常量*。为了弄清楚
格式，我们可以使用新的 *schema* 端点来获取格式
描述。因此，我们将从获取该信息开始：

    http：// <server> /api/schemas/constant.json

从输出中，您可以看到创建所需的权限
是`F_CONSTANT_ADD`，重要的属性是：*name* 和
*价值*。由此，我们可以创建一个 JSON 负载并将其保存为文件
称为constant.json：

```json
{
  "name": "PI",
  "value": "3.14159265359"
}
```

与XML有效内容相同的内容：

```xml
<constant name="PI" xmlns="http://dhis2.org/schema/dxf/2.0">
  <value>3.14159265359</value>
</constant>
```

我们现在准备通过发送 POST 请求来创建新的*常量*
使用curl 的带有JSON 有效负载的`constants`端点：

```bash
curl -d @constant.json "http://server/api/constants" -X POST
  -H "Content-Type: application/json" -u user:password
```

将常量发布到演示中的具体示例
    服务器：

```bash
curl -d @constant.json "https://play.dhis2.org/api/constants" -X POST
  -H "Content-Type: application/json" -u admin:district
```

如果一切顺利，您应该看到类似以下的输出：

```json
{
  "status": "SUCCESS",
  "importCount": {
    "imported": 1,
    "updated": 0,
    "ignored": 0,
    "deleted": 0
  },
  "type": "Constant"
}
```

更新过程将完全相同，您进行更改
到 JSON/XML 负载，找出常量的 *ID*，然后
向端点发送包含 ID 的 PUT 请求：

```bash
curl -X PUT -d @pi.json -H "Content-Type: application/json"
  -u user:password "http://server/api/constants/ID"
```

### 删除物件 { #webapi_deleting_objects } 

删除对象非常简单，您需要知道
*ID* 和你要删除的类型的端点，让我们继续我们的
上一节中的示例并使用*常量*。让我们假设
id 是 *abc123*，那么你需要做的就是发送 DELETE
对端点的请求 + id：

```bash
curl -X DELETE -u user:password "http://server/api/constants/ID"
```

成功删除应返回HTTP状态204（无内容）。

### 在集合中添加和删除对象 { #webapi_adding_removing_objects_collections } 

集合资源允许您修改集合
对象。

#### 添加或删除单个对象 { #webapi_collections_adding_removing_single_objects } 

为了在对象集合中添加或删除对象，您
可以使用以下
    图案：

    / api / {collection-object} / {collection-object-id} / {collection-name} / {object-id}

应该使用POST方法添加，使用DELETE方法删除
一个东西。当对象之间存在多对多关系时，
您必须首先确定哪个对象拥有该关系。如果不是
清除这是哪个对象，尝试两种方式调用以查看哪个有效。

模式的组成部分是：

  - 集合对象：拥有您的集合的对象类型
    想修改。

  - 集合对象 id：拥有该对象的对象的标识符
    要修改的集合。

  - 集合名称：您要修改的集合的名称。

  - object id：要添加或删除的对象的标识符
    从集合。

例如，为了删除标识符为 IDB 的数据元素
从具有标识符 IDA 的数据元素组中，您可以执行 DELETE
要求：

    删除/ api / dataElementGroups / IDA / dataElements / IDB

将带有标识符 IDB 的类别选项添加到带有
标识符 IDA 你可以做一个 POST
要求：

    POST / api / categories / IDA / categoryOptions / IDB

#### 添加或删除多个对象 { #webapi_collections_adding_removing_multiple_objects } 

您可以在一个请求中从集合中添加或删除多个对象
具有这样的有效载荷：

```json
{
  "identifiableObjects": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ]
}
```

使用此有效负载，您可以添加，替换或删除项目：

*添加项目：*

    POST / api / categories / IDA / categoryOptions

*更换物品：*

    PUT /api/categories/IDA/categoryOptions

*删除
项目：*

    删除/ api / categories / IDA / categoryOptions

#### 在单个请求中添加和删除对象 { #webapi_collections_adding_removing_objects_single_request } 

您可以在单个 POST 中从集合中添加和删除对象
请求到以下 URL：

    POST / api / categories / IDA / categoryOptions

有效负载格式为：

```json
{
  "additions": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ],
  "deletions": [{
      "id": "IDD"
    }, {
      "id": "IDE"
    }, {
      "id": "IDF"
    }
  ]
}
```

### 验证有效载荷 { #webapi_validating_payloads } 

DHIS 2 支持元数据有效载荷的系统范围验证，这意味着
将检查 API 端点上的创建和更新操作
允许进行更改之前的有效负载。找出哪些验证
为特定端点准备好了，看看`/api/schemas`
端点，即要找出数据元素具有哪些约束，您
会去`/api/schemas/dataElement`。

您还可以手动验证您的有效负载，方法是将其发送到适当的
架构端点。如果您想从创建中验证常量
之前的部分，您可以这样发送：

    POST / api / schemas / constant

一个简单的（非验证）示例为：

```bash
curl -X POST -d "{\"name\": \"some name\"}" -H "Content-Type: application/json"
  -u admin:district "https://play.dhis2.org/dev/api/schemas/dataElement"
```

这将产生结果：

```json
[
   {
      "message" : "Required property missing.",
      "property" : "type"
   },
   {
      "property" : "aggregationOperator",
      "message" : "Required property missing."
   },
   {
      "property" : "domainType",
      "message" : "Required property missing."
   },
   {
      "property" : "shortName",
      "message" : "Required property missing."
   }
]
```

### 部分更新 { #webapi_partial_updates } 

对于处理元数据的 API 端点，我们支持使用 JSON 补丁 [标准](https://tools.ietf.org/html/rfc6902) 进行部分更新 (PATCH)。有效负载基本上概述了您想要应用于现有元数据对象的一组操作。有关 JSON 补丁的详细信息和示例，请参阅 [jsonpatch.com](http://jsonpatch.com/)。支持三个运算符：`添加`、`删除`和`替换`。

以下是与 DHIS2 相关的几个示例。请注意，对有效负载的任何更新都应被视为 HTTP PUT 操作，即任何突变都必须产生有效的 PUT 元数据有效负载。

The default `importReportMode` for JSON patch is `ERRORS_NOT_OWNER` which implies that when updating any property which is not owned by that particular object (for example trying to add a indicator group directly to an indicator) you will get an error.

根据 JSON 补丁规范，发送补丁时必须始终使用 mimetype `application/json-patch+json`。

#### 例子 { #examples } 

##### 更新数据元素的名称和值类型{ #update-name-and-value-type-of-data-element }

```
PATCH /api/dataElements/{id}
```

```json
[
  {"op": "add", "path": "/name", "value": "New Name"},
  {"op": "add", "path": "/valueType", "value": "INTEGER"}
] 
```

##### 将新数据元素添加到数据元素组 { #add-new-data-element-to-a-data-element-group }

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "add", "path": "/dataElements/-", "value": {"id": "data-element-id"}}
]
```

##### 从数据元素组中删除所有数据元素关联 { #remove-all-data-element-associations-from-a-data-element-group }

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "remove", "path": "/dataElements"}
]
```

##### 更改数据元素的域和值类型 { #change-domain-and-value-type-of-a-data-element }

```
PATCH /api/dataElements/{id}
```

```json
[
    {"op": "add", "path": "/domainType", "value": "TRACKER"},
    {"op": "add", "path": "/valueType", "value": "INTEGER"}
]
```

##### 从 orgUnit 组中删除特定 orgUnit { #remove-a-specific-orgunit-from-an-orgunit-group }

```
PATCH /api/organisationUnitGroups/{id}
```

```json
[
  {"op": "remove", "path": "/organisationUnits/1"}
]
```

#### 已阻止将 dataElementGroup 添加到 dataElement { #blocked-add-dataelementgroup-to-dataelement }

```
PATCH /api/dataElements/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "add", "path": "/dataElementGroups/-", "value": {"id": "data-element-group-id"}}
]
```

#### 阻止更新 dataElement 中 dataElementGroup 的名称 { #blocked-update-name-of-dataelementgroup-in-dataelement }

```
PATCH /api/dataElements/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "add", "path": "/dataElementGroups/0", "value": {"name": "new-name"}}
]
```
#### 按 ID 删除收藏项 { #remove-collection-item-by-id }

```
补丁 /api/dataSets/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "remove-by-id", "path": "/organisationUnits", "id": "u6CvKyF0Db5"}
]
```

#### 路径无效的补丁请求 { #patch-request-with-invalid-path }
如果`path`属性无效或不存在，则修补服务将返回如下错误。


```
补丁 /api/dataSets/{id}?importReportMode=ERRORS_NOT_OWNER
```

```json
[
    {"op": "remove-by-id", "path": "/test", "id": "u6CvKyF0Db5"}
]
```
回复
```json
{
    "httpStatus": "Bad Request",
    "httpStatusCode": 400,
    "status": "ERROR",
    "message": "Invalid path /test"
}
```

### 元数据 CSV 导出 { #webapi_metadata_csv_export }

CSV字段过滤与CSV（请注意，在`/api/metadata`端点上使用CSV不受支持）几乎相同，但字段转换尚不支持。

对于支持CSV的端点（如`/api/dataElements` `/api/organisationUnits`等我们的元数据端点），您可以使用`Accept`头部和值`text/csv`，或者您可以使用扩展名`.csv`。请注意，不支持复杂对象，我们仅支持id-object集合（因此将返回一个UID列表）。

| 名称 | 选项 | 描述 |
|---|---|---|
| 领域 | 与元数据字段过滤器相同（带有上面提到的注意事项） | 默认过滤器是`id，displayName` |
| 跳过标题 | 假/真 | 是否包含标题（带有列名）
| 分隔器 | 默认值：`.` | 柱隔板
| 数组分隔符 | 默认值：`;` | 如果其中一个字段是 id 对象的集合，则此分隔符将分隔所有 UID

#### 例子 { #examples } 

#### 获取所有数据元素，包括其组关联{ #get-all-data-elements-including-their-group-associations }

```
/api/dataElements.csv?fields=id,displayName,dataElementGroups
```

#### 获取所有组织部门，包括几何图形（将被忽略）{ #get-all-org-units-including-geometry-which-will-get-ignored }

```
/api/organisationUnits.csv?fields=id,displayName,organisationUnitGroups,geometry
```

## 元数据导出 { #webapi_metadata_export } 

本节介绍了可在以下位置获得的元数据 API
`/api/元数据`。支持 XML 和 JSON 资源表示。

    / api /元数据

最常用的参数在下面的“导出参数”中描述
桌子。您还可以使用以下方法将其应用于所有可用类型
`type:fields=<filter>` 和 `type:filter=<filter>`。你也可以
通过设置 `type=true|false` 启用/禁用某些类型的导出。

表：导出参数

| 名称 | 选项 | 描述 |
|---|---|---|
| 领域 | 与元数据字段过滤器相同 | 适用于所有类型的默认字段过滤器，默认为 `:owner`。 |
| 筛选 | 与元数据对象过滤器相同 | 适用于所有类型的默认对象过滤器，默认为`无`。 |
| 命令 | 与元数据顺序相同 | Default order to apply to all types, default is `name` if available, or `created` if not. |
| 翻译 | 假/真 | 启用翻译。请注意，默认情况下此功能处于关闭状态（在其他端点中，此功能默认处于打开状态）。 |
| 语言环境 |  <locale\> | 从用户区域设置更改为您自己的自定义区域设置。 |
| 默认值 | 包含/排除 | 自动生成的类别对象是否应该包含在有效负载中。如果您要在 2 个非同步实例之间移动元数据，则将其设置为 EXCLUDE 可能有意义，以简化对这些生成对象的处理。 |
| 跳过分享 | 假/真 | 启用此选项将从导出的对象中去除共享属性。这包括 *user*、*publicAccess*、*userGroupAccesses*、*userAccesses* 和 *externalAccess*。 |
| 下载 | 假/真 | 启用此选项将添加 HTTP 标头 Content-Disposition，指定数据应作为附件处理，并由 Web 浏览器作为下载提供。 |

### 元数据导出示例 { #webapi_metadata_export_examples } 

导出所有元数据。小心，因为响应可能非常大，具体取决于
关于您的元数据配置：

    / api /元数据

导出由lastUpdated降序排列的所有元数据：

    / api / metadata？defaultOrder = lastUpdated：desc

导出仅包括指标和指标组的元数据：

    / api / metadata？indicators = true＆indicatorGroups = true

导出所有数据元素的id和displayName，按displayName排序：

    / api / metadata？dataElements：fields = id，name＆dataElements：order = displayName：desc

导出名称以“ ANC”开头的数据元素和指示符：

    / api / metadata？filter = name：^ like：ANC＆dataElements = true＆indicators = true

### 具有依赖项的元数据导出 { #webapi_dataset_program_export_dependencies } 

当您想要交换数据集、程序、类别组合的元数据时，
仪表板、选项集或数据元素组
从一个 DHIS2 实例到另一实例，有六个可用的专用端点：

```
/api/dataSets/{id}/metadata.json

/api/programs/{id}/metadata.json

/api/categoryCombos/{id}/metadata.json

/api/dashboards/{id}/metadata.json

/api/optionSets/{id}/metadata.json

/api/dataElementGroups/{id}/metadata.json
```

然后可以使用`/ api / metadata`导入这些导出。

这些端点还支持以下参数：

表：导出参数

| 名称 | 选项 | 描述 |
|---|---|---|
| 跳过分享 | 假/真 | 启用此选项将从导出的对象中去除共享属性。这包括 *user*、*publicAccess*、*userGroupAccesses*、*userAccesses* 和 *externalAccess*。 |
| 下载 | 假/真 | 启用此选项将添加 HTTP 标头 Content-Disposition，指定数据应作为附件处理，并由 Web 浏览器作为下载提供。 |

## 元数据导入 { #webapi_metadata_import } 

本节介绍元数据导入 API。 XML 和 JSON 资源
支持表示。可以使用 *POST* 请求导入元数据。

    / api /元数据

导入器允许您导入元数据有效负载，其中可能包括许多
不同的实体和每个实体的任意数量的对象。元数据导出
元数据导出API生成的可以直接导入。

元数据导入端点支持多种参数，分别是
下面列出。

表：导入参数

| 名称 | 选项（第一个为默认） | 描述 |
|---|---|---|
| 导入模式 | 提交、验证 | 设置整体导入模式，决定是否仅 `VALIDATE` 或也 `COMMIT` 元数据，这与我们旧的 dryRun 标志具有相似的功能。 |
| 标识符 | UID、代码、自动 | Sets the identifier scheme to use for reference matching. `AUTO` means try `UID` first, then `CODE`. |
| 导入报告模式 | 错误，完整，调试 | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |
| 预热模式 | 参考、全部、无 | 设置预热器模式，用于指示是否应该对 `ALL` 进行预热（就像以前使用 *preheatCache=true* 一样）或对对象进行更智能的扫描以查看要预热的内容（现在是默认设置），将其设置为不推荐使用`无`。 |
| 导入策略 | CREATE_AND_UPDATE, CREATE, UPDATE, DELETE | 设置导入策略，`CREATE_AND_UPDATE`将尝试匹配标识符，如果不存在，则会创建对象。 |
| 原子模式 | 所有，无 | 设置原子模式，在旧的导入器中，我们总是进行*best effort*导入，这意味着即使某些引用不存在，我们仍然会导入（即数据元素组导入时缺少数据元素）。新进口商的默认设置是不允许这样做，并且类似地拒绝任何验证错误。设置 `NONE` 模式模拟了旧的行为. |
| ~~合并模式~~ | ~~替换，合并~~ | ~~设置合并模式，在进行更新时我们有两种方式将旧对象与新对象合并，`MERGE`模式只会在新对象不为空时覆盖旧属性，对于`REPLACE`模式则覆盖所有属性无论是否为 null 都会被覆盖。~~ (*) |
| 冲洗模式 | 自动、对象 | 设置刷新模式，控制何时刷新内部缓存。*强烈*建议将其保留为`AUTO`（这是默认设置）。仅将 `OBJECT` 用于调试目的，您会看到休眠异常并想查明堆栈发生的确切位置（休眠只会在刷新时抛出，因此很难知道哪个对象有问题）。 | 
| 跳过分享 | 假的，真的 | 跳过共享属性，更新时不合并共享，创建新对象时不添加用户组访问权限。 |
| 跳过验证 | 假的，真的 | 跳过导入的验证。`不推荐`。 |
| 异步 | 假的，真的 | 异步导入，立即返回，并带有指向 *importReport* 位置的 *Location* 标头。有效负载还包含所创建作业的 json 对象。 |
| 包容性策略 | NON_NULL, ALWAYS, NON_EMPTY | *NON_NULL* 包括不为空的属性，*ALWAYS* 包括所有属性，*NON_EMPTY* 包括非空属性（不包括长度为 0 的字符串、大小为 0 的集合等） |
| 用户覆盖模式 | 无、当前、已选择 | 允许您覆盖要导入的每个对象的用户属性，选项有 NONE（不执行任何操作）、CURRENT（使用导入用户）、SELECTED（使用 overrideUser=X 选择特定用户） |
| 覆盖用户 | 用户身份 | 如果 userOverrideMode 为 SELECTED，请使用此参数选择要覆盖的用户。 |

> (*) 目前导入服务的 `mergeMode=MERGE` 选项有限制并且不支持所有对象。它不适用于某些对象类型，例如嵌入式对象或在数据库中以 JSONB 格式保存的对象（共享、属性值等）。解决这些问题很复杂，而且只会引发新问题。因此，这个 `mergedMode=MERGE` 已被弃用，目前不建议使用。更新模式应始终为 mergedMode=REPLACE。我们开发了一个新的 [JSON Patch API](#webapi_partial_updates)，可以用作替代方法。该功能在 2.37 版本中引入。


要导入的元数据负载的示例如下所示。注意如何
每个实体类型都有自己的属性和一个对象数组：

```json
{
  "dataElements": [
    {
      "name": "EPI - IPV 3 doses given",
      "shortName": "EPI - IPV 3 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    },
    {
      "name": "EPI - IPV 4 doses given",
      "shortName": "EPI - IPV 4 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    }
  ],
  "indicators": [
    {
      "name": "EPI - ADS stock used",
      "shortName": "ADS stock used",
      "numerator": "#{LTb8XeeqeqI}+#{Fs28ZQJET6V}-#{A3mHIZd2tPg}",
      "numeratorDescription": "ADS 0.05 ml used",
      "denominator": "1",
      "denominatorDescription": "1",
      "annualized": false,
      "indicatorType": {
        "id": "kHy61PbChXr"
      }
    }
  ]
}
```

将此有效负载发布到元数据端点时，响应将包含
有关导入过程中使用的参数的信息和每个摘要
实体类型，包括创建、更新、删除和
忽略：

```json
{
  "importParams": {
    "userOverrideMode": "NONE",
    "importMode": "COMMIT",
    "identifier": "UID",
    "preheatMode": "REFERENCE",
    "importStrategy": "CREATE_AND_UPDATE",
    "atomicMode": "ALL",
    "mergeMode": "REPLACE",
    "flushMode": "AUTO",
    "skipSharing": false,
    "skipTranslation": false,
    "skipValidation": false,
    "metadataSyncImport": false,
    "firstRowIsHeader": true,
    "username": "UNICEF_admin"
  },
  "status": "OK",
  "typeReports": [
    {
      "klass": "org.hisp.dhis.dataelement.DataElement",
      "stats": {
        "created": 2,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 2
      }
    },
    {
      "klass": "org.hisp.dhis.indicator.Indicator",
      "stats": {
        "created": 1,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 1
      }
    }
  ],
  "stats": {
    "created": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0,
    "total": 3
  }
}
```

## GeoJSON 导入 <!-- DHIS2-EDIT:https://github.com/dhis2/dhis2-docs/edit/2.40/src/developer/web-api/geo-json.md --> { #geojson-import }

GeoJSON 导入用于将几何数据附加到组织单位。

对于批量导入，需要包含要素集合的 GeoJSON 文件。
集合中的每个功能都需要对其组织单位的引用
应该链接到。

默认情况下，文件中的几何图形存储为组织单位的`几何图形`属性。要存储额外的几何图形，可以创建`GEOJSON`类型的属性。当使用属性时，文件中的所有几何图形都存储为相同的属性，该属性提供了一个附加参数`attributeId`。

### GeoJSON 批量数据导入 { #webapi_geojson_bulk_import }

表：导入参数

| 名称              | 类型                           | 默认 | 描述                                                                                                                       |
|-------------------|--------------------------------|---|-----------------------------------------------------------------------------------------------------------------------------------|
| `geoJsonId`       | `boolean`                      | `真实` | 当`true`时，预期GeoJSON要素的`id`属性将保存组织单元标识符。                        |
| `geoJsonProperty` | `字符串`                       | _不明确的_ | If `geoJsonId` is `false` this parameter names the property in the GeoJSON feature's `properties` that holds the organisation unit identifier |
| `orgUnit 属性` | `enum`: [`id`, `code`, `name`] | `id` | GeoJSON 文件中使用的标识符引用的组织单位的属性                             |
| `属性ID`     | `字符串` | _不明确的_ | 设置后，几何图形将存储为 ID 引用的属性值                                                       |
| `干运行`          | `boolean` | `假` | When `true` the import is processed without actually updating the organisation units |
| `异步`           | `boolean` | `假` | When `true` the import is processed asnychronously |

用途：

    POST /api/organizationUnits/geometry

The post body is the GeoJSON file. Content type should be `application/json` or
`application/geo+json`. The file may be `.zip` or `.gzip` compressed.

For example, a default file where `id` is used to refer to an organisation unit 
id has this structure:

```json
{ 
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "id": "O6uvpzGd5pu",
      "geometry": { ... }
    },
    ...
  ]
}
```

一个文件，其中的功能属性用于引用组织单位代码
将具有以下结构：

```json
{ 
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": { "code": "OU1_CODE" },
      "geometry": { ... }
    },
    ...
  ]
}
```
The `coordinates` in a `geometry` may be pairs or triplets. 
If a third dimension is present it is stripped during the import.

A `geometry` may also be `null` to effectively clear or delete the geometry 
for specific organisation units. There is a special bulk deletion API that is
described in the next section.

When run synchronously an import report is returned directly.
The HTTP status code is always `OK`, the `status` in the message payload
indicates if all rows were imported successfully.
The import counts statistics contained in the report give further information:

* `imported`: number of organisation units that were successfully updated with a geometry that did not have one before for the updated property
* `updated`：已使用已具有更新属性值的几何图形成功更新的组织单位数
* `ignored`：更新失败的组织单位数量
* `deleted`：使用 _empty_ 几何图形成功更新的组织单位数量

When the import is run asynchronous the request returns immediately with status 
`OK` and job configuration response that contains a relative reference to 
the task endpoint that allows to track the status of the asynchronous import.
For example:

    /api/system/tasks/GEOJSON_IMPORT/{job-id}

直接返回同步执行的摘要可在以下位置找到：

    /api/system/taskSummaries/GEOJSON_IMPORT/{job-id}

导入完成后。

### GeoJSON 批量数据删除 { #webapi_geojson_bulk_deletion }
要清除或取消设置所有组织单位的`几何`数据，请使用：

    删除 /api/organizationUnits/geometry

To clear or unset the geometry data for a specific `GEOJSON` attribute for
all organisation units use:

    删除 /api/organizationUnits/geometry?attributeId={attr-id}

Clearing is always synchronous and returns a similar report as the bulk import.
It does not support any other parameters. No `dry-run` can be performed.
Bulk clearing requires the `F_PERFORM_MAINTENANCE` authority.

### GeoJSON 单一数据导入 { #webapi_geojson_single_import }
单个导入允许更新单个组织单元的几何结构。

    POST /api/organizationUnits/{id}/geometry

帖子正文仅包含 GeoJSON `geometry` 值，例如：
```json
{
  "type": "Polygon",
  "coordinates": [...]
}
```
单次导入仅支持`attributeId`和`dryRun`参数。

### GeoJSON 单一数据删除 { #webapi_geojson_single_deletion }
To clear the `geometry` GeoJSON data of an individual organisation unit use:

    删除 /api/organizationUnits/{id}/geometry

Similarly to clear a `GEOJSON` attribute value for an individual organisation 
unit use:

    删除 /api/organizationUnits/{id}/geometry?attributeId={attr-id}

Clearing is always synchronous returns a similar report as single import.
The `dry-run` parameter is supported as well. 
The performing user requires authority to modify the target organisation unit.



## 架构图 { #webapi_schema } 

可用于内省所有可用 DXF 2 对象的资源
可以在`/api/schemas` 上找到。对于特定资源，您可以拥有
查看`/api/schemas/<type>`。

要获取XML中所有可用的模式：

    获取/api/schemas.xml

要获取JSON中所有可用的模式，请执行以下操作：

    获取/api/schemas.json

要获取特定类的JSON模式：

    获取 /api/schemas/dataElement.json


## 图示 { #webapi_icons } 

DHIS2 包括一组可用于提供视觉效果的图标
元数据的上下文。这些图标可以通过图标访问
资源。

    获取/api/图标

此端点返回有关可用图标的信息列表。
每个条目都包含有关图标的信息，以及对图标的引用
实际图标。

```json
{
  key: "mosquito_outline",
  description: "Mosquito outline",
  keywords: [
    "malaria",
    "mosquito",
    "dengue"
  ],
  href: "<dhis server>/api/icons/mosquito_outline/icon.svg"
}
```

关键字可用于过滤要返回的图标。传递一个列表
带有请求的关键字将只返回与所有匹配的图标
关键词：

    GET /api/icons?keywords=shape,小

可以在关键字资源中找到所有唯一关键字的列表：

    获取/api/图标/关键字

## 渲染类型 { #webapi_render_type } 

某些元数据类型具有名为 *renderType* 的属性。渲染类型
属性是 *device* 和 *renderingType* 之间的映射。应用
可以使用此信息作为有关如何呈现对象的提示
在特定设备上。例如，移动设备可能想要渲染
与台式计算机不同的数据元素。

当前有两种不同的renderingTypes可用：

1.  值类型渲染

2.  程序阶段部分渲染

还提供2种设备类型：

1.  移动

2.  桌面

下表列出了可用的元数据和呈现类型。
值类型呈现具有基于元数据的附加约束
配置，这将显示在第二个表中。

表：元数据和 RenderingType 概述

| 元数据类型 | 可用的渲染类型 |
|---|---|
| 程序阶段部分 | * 列表（默认）<br> * 顺序 <br> * 矩阵 |
| 数据元素 | * DEFAULT<br> * DROPDOWN<br> * VERTICAL_RADIOBUTTONS<br> * HORIZONTAL_RADIOBUTTONS<br> * VERTICAL_CHECKBOXES<br> * HORIZONTAL_CHECKBOXES<br> * SHARED_HEADER_RADIOBUTTONS<br> * ICONS_AS_BUTTONS<br> * SPINNER<br> * ICON<br> * TOGGLE<br> * VALUE<br> * SLIDER<br> * LINEAR_SCALE<br> * AUTOCOMPLETE<br> * QR_CODE<br> * BAR_CODE<br> * GS1_DATAMATRIX |

由于处理数据元素和跟踪实体的默认呈现
属性取决于对象的值类型，还有
一个 DEFAULT 类型告诉客户端它应该被正常处理。
程序阶段部分默认为“列表”。

表：基于值类型允许的 RenderingType

| 值类型               | 对象是选项集吗？ | 允许的渲染类型 |
|--------------------------|---|---|
| TRUE_ONLY                | 不 | DEFAULT, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, TOGGLE |
| 布尔值                  | 不 ||
| --                        | 是的 | 默认、下拉、垂直_RADIOBUTTONS、水平_RADIOBUTTONS、垂直_CHECKBOXES、水平_CHECKBOXES、SHARED_HEADER_RADIOBUTTONS、图标_AS_按钮、微调器、图标 |
| 整数                  | 不 | DEFAULT, VALUE, SLIDER, LINEAR_SCALE, SPINNER |
| 文本                     | 不 | 默认、值、自动完成、QR_CODE、BAR_CODE、GS1_DATAMATRIX |
| INTEGER_POSITIVE         | 不 ||
| INTEGER_NEGATIVE         | 不 ||
| INTEGER_ZERO_OR_POSITIVE | 不 ||
| 数字                   | 不 ||
| UNIT_INTERVAL            | 不 ||
| 百分比               | 不 ||

上表的完整参考也可以使用
以下端点：

    GET /api/staticConfiguration/renderingOptions

值类型渲染也有一些额外的属性，可以
设置，通常在渲染某些特定类型时需要：

表：renderType 对象属性

| 财产 | 描述 | 类型 |
|---|---|---|
| 类型 | 对象的 RenderingType，如第一个表中所示。该属性对于值类型和程序阶段部分是相同的，但它是程序阶段部分唯一可用的属性。 | 枚举（请参阅元数据和渲染类型表中的列表） |
| 分钟 | 仅用于值类型渲染。表示该字段可以具有的最小值。 | 整数 |
| 最大限度 | 仅用于值类型渲染。表示该字段可以具有的最大值。 | 整数 |
| 步 | 仅用于值类型渲染。表示值应增加的步长大小，例如对于 SLIDER og LINEAR_SCALE | 整数 |
| 小数点 | 仅用于值类型渲染。表示值应使用的小数点位数。 | 整数 |

*renderingType* 可以在创建或更新第一个表中列出的元数据时设置。程序阶段部分的渲染类型的示例负载如下所示：

```json
{
  "renderingType": {
    "type": "MATRIX"
  }
}
```

对于数据元素和跟踪的实体属性：

```json
{
  "renderingType": {
    "type": "SLIDER",
    "min": 0,
    "max": 1000,
    "step": 50,
    "decimalPoints": 0
  }
}
```

## 对象样式 { #webapi_object_style } 

大多数元数据都有一个属性名称“样式”。可以使用此属性
由客户以某种方式表示对象。属性
目前支持的样式如下：

表：样式属性

| 财产 | 描述 | 类型 |
|---|---|---|
| 颜色 | 一种颜色，用十六进制表示。 | 字符串 (#000000) |
| 图标 | 一个图标，由图标名称表示。 | 串 |

目前，没有官方列表或对图标库的支持，所以
这目前由客户提供。下面的列表显示
所有支持样式的对象：

  - 数据元素

  - 数据元素类别选项

  - 资料集

  - 指示符

  - 选项

  - 程序

  - 计划指标

  - 计划科

  - 程序阶段

  - 程序阶段部分

  - 关系（跟踪器）

  - 跟踪实体属性

  - 追踪实体类型

在创建或更新任何这些对象时，您可以包括
以下有效负载更改样式：

```json
{
  "style": {
    "color": "#ffffff",
    "icon": "my-beautiful-icon"
  }
}
```

## 指标 { #webapi_indicators } 

本节介绍指标和指标表达式。

### 综合指标 { #webapi_aggregate_indicators } 

要检索指标，您可以向指标发出 GET 请求
像这样的资源：

    / api /指标

指标表示可以计算和呈现的表达式
因此。指标表达式分为分子和
分母。分子和分母是数学的
可以包含对数据元素、其他指标、常量和
组织单位组。变量将替换为数据
使用时的值，例如在报告中。允许的变量
表达式在下表中描述。

表：指示变量

| 变量 | 目的 | 描述 |
|---|---|---|
| #{ <data-element-id\> . <category-option-combo-id\> 。 <attribute-option-combo-id\> } | 数据元素操作数 | 指聚合数据元素和类别选项组合的组合。类别和属性选项组合 ID 都是可选的，并且可以使用通配符“\*”符号来指示任何值。 |
| #{ <dataelement-id\> . <category-option-group-id\> 。 <attribute-option-combo-id\> } | 类别选项组 | 指一个聚合数据元素和一个类别选项组，包含多个类别选项组合。 |
| #{ <data-element-id\> } | 汇总数据元素 | 指所有类别选项组合中的聚合数据元素的总值。 |
| D{ <program-id\> . <data-element-id\> } | 程序数据元素 | 引用程序中跟踪器数据元素的值。 |
| A{ <program-id\> . <attribute-id\> } | 程序跟踪的实体属性 | 指程序中被跟踪实体属性的值。 |
| 我{ <program-indicator-id\> } | 计划指标 | 指程序指示器的值。 |
| R{ <dataset-id\> . <metric\> } | 报告率 | 指报告率指标。指标可以是REPORTING_RATE，REPORTING_RATE_ON_TIME，ACTUAL_REPORTS，ACTUAL_REPORTS_ON_TIME，EXPECTED_REPORTS。 |
| C{ <constant-id\> } | 不变 | 指恒定值。 |
| N{ <indicator-id\> } | 指示符 | 指现有指标。 |
| OUG{ <orgunitgroup-id\> } | 组织单位组 | 指组织单位组内组织单位的数量。 |

在数据元素操作数或聚合数据元素内，可以进行以下替换：

| 项目 | 值 | 描述 |
|---|---|---|
| 数据元素 ID | 数据元素 ID | 聚合数据元素 |
| 数据元素 ID | deGroup:数据元素组 ID | 数据元素组中的所有聚合数据元素 |
| 类别选项组合 ID | 类别选项组合 ID | 类别选项组合 |
| 类别选项组合 ID | co:类别选项 ID | 类别选项中的所有类别选项组合 |
| 类别选项组合 ID | coGroup:类别选项组 ID | 类别选项组中的所有类别选项组合 |
| 类别选项组合 ID | coGroup:co-group-id1&co-group-id2... | 属于多个类别选项组成员的所有类别选项组合 |

语法看起来像
    这：

＃

相应的示例如下所示：

＃

请注意，对于数据元素变量，类别选项组合
标识符可以省略。该变量将代表总数
对于数据元素，例如在所有类别选项组合中。例子：

＃

数据元素操作数可以包括任何类别选项组合和
属性选项组合，并使用通配符表示任何
    价值：

＃

使用数据元素组的示例：

    #{deGroup:oDkJh5Ddh7d} + #{deGroup:GBHN1a1Jddh.j8vBiBqGf6O}

使用类别选项、数据元素组和类别选项组的示例：

    #{P3jJH5Tu5VC.co:FbLZS3ueWbQ} + #{deGroup:GBHN1a1Jddh.coGroup:OK2Nr4wdfrZ.j8vBiBqGf6O}

使用多个类别选项组的示例：

    #{P3jJH5Tu5VC.coGroup:OK2Nr4wdfrZ&j3C417uW6J7&ddAo6zmIHOk}

使用程序数据元素和程序属性的示例：

    （D {eBAyeGv0exc.vV9UWAZohSf} * A {IpHINAT79UW.cejWyOfXge6}）/ D {eBAyeGv0exc.GieVkTxp4HH}

结合计划指标和总体指标的示例：

    I {EMOt6Fwhs1n} * 1000 /＃{WUg3MYWQ7pt}

使用报告率的示例：

    R {BfMAe6Itzgt.REPORTING_RATE} *＃{P3jJH5Tu5VC.S34ULMcHMca}

使用实际数据集报告和预期报告的另一个报告率示例：

    R {BfMAe6Itzgt.ACTUAL_REPORTS} / R {BfMAe6Itzgt.EXPECTED_REPORTS}

使用现有指标的示例：

    N {Rigf2d2Zbjp} *＃{P3jJH5Tu5VC.S34ULMcHMca}

表达式可以是任何类型的有效数学表达式，作为
例子：

    （2 *＃{P3jJH5Tu5VC.S34ULMcHMca}）/（＃{FQ2o8UBlcrS.S34ULMcHMca}-200）* 25

### 计划指标 { #webapi_program_indicators } 

要检索程序指标，您可以向程序发出 GET 请求
像这样的指标资源：

    / api / programIndicators

程序指示器可以包含在程序中收集的信息。
指标有一个表达式，可以包含对数据的引用
元素、属性、常量和程序变量。变量
下表中描述了允许在表达式中使用。



表：程序指示变量

| 变量 | 描述 |
|---|---|
| #{ <programstage-id\> . <dataelement-id\> } | 指的是程序阶段和数据元素id的组合。 |
| A{ <attribute-id\> } | 指被跟踪的实体属性。 |
| V{ <variable-id\> } | 指的是程序变量。 |
| C{ <constant-id\> } | 指的是一个常数。 |

语法看起来像
    这：

＃

一个相应的例子看起来像
    这：

＃

### 表达方式 { #webapi_expressions } 

表达式是数学公式，可以包含对
数据元素、常量和组织单元组。验证和
获取表达式的文本描述，您可以发出 GET 请求
到表达式资源：

    / api / expressions / description？expression = <expression-string>

响应遵循标准的 JSON Web 消息格式。 *状态*
属性表示验证的结果，如果
成功和“错误”如果失败。 *message* 属性将为“有效”
如果成功并提供原因的文字描述
如果不是，则验证失败。 *描述*提供了文字说明
表达式的描述。

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Valid",
  "description": "Acute Flaccid Paralysis"
}
```

## 组织单位 { #webapi_organisation_units } 

*organisationUnits* 资源遵循标准约定，如
DHIS2 中的其他元数据资源。该资源支持一些
附加查询参数。

### 获取组织单位列表 { #webapi_list_of_organisation_units } 

要获取组织单位的列表，可以使用以下资源。

    / api / 33 / organisationUnits

表：组织单位查询参数

| 查询参数 | 选项 | 描述 |
|---|---|---|
| 仅限用户 | 假的&#124;真的 | 仅与当前用户关联的数据捕获组织单位。 |
| 仅用户数据查看 | 假的&#124;真的 | 仅与当前用户关联的数据视图组织单位。 |
| 用户数据视图回退 | 假的&#124;真的 | 仅与当前用户关联的数据视图组织单位，并回退到数据捕获组织单位。 |
| 询问 | 细绳 | 根据名称、代码和 ID 属性进行查询。 |
| 等级 | 整数 | 层次结构中给定级别的组织单位。 |
| 最大等级 | 整数 | 给定最高级别或层次结构中更高级别的组织单位。 |
| 在用户层次结构内 | 假的&#124;真的 | 将搜索和检索限制在用户数据捕获范围内的组织单位。 |
| 在用户搜索层次结构内 | 假的&#124;真的 | 将搜索和检索限制在当前用户搜索范围内的组织单位。注意：“withinUserHierarchy”如果为 true，则具有更高的优先级。 |
| 会员集合 | 细绳 | 要显示集合中的成员计数，请指与组织单位关联的集合的名称。 |
| 成员对象 | 用户标识 | 为了显示集合内的成员计数，指集合的对象成员的标识符。 |

### 获取具有子层次结构的组织部门 { #webapi_organisation_units_with_sub_hierarchy }

要获取在其子层次结构中包含组织单位的组织单位，您可以使用以下资源。

    / api / 33 / organisationUnits / {id}

表：组织单位参数

| 查询参数 | 选项 | 描述 |
|---|---|---|
| 包括儿童 | 假的&#124;真的 | 包括指定组织单位的直接子级，即子层次结构中直接以下级别的单位。 |
| 包括后代 | 假的&#124;真的 | 包括指定组织单位的所有子级，即子层次结构中的所有单位。 |
| 包括祖先 | 假的&#124;真的 | 包括指定组织单位的所有父级。 |
| 等级 | 整数 | 包括子层次结构给定级别的指定组织单位的子级。这与组织单位相关，对于紧邻组织单位的级别，从 1 开始。 |

### 按类别选项获取组织部门 { #webapi_organisation_units_by_category_options }

专门构建的端点，用于检索类别选项和组织单位之间的关联。此端点是检索程序组织单元关联的首选方式。

    /api/33/categoryOptions/orgUnits?categoryOptions={categoryOptionIdA},{categoryOptionIdB}

响应将采用以下格式：

```json
{
  "<categoryOptionIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdC>": []
}
```

所有组织单位均可访问的类别选项将返回组织单位的空数组 (`[]`)。

### 按计划获取组织单位 { #webapi_organisation_units_by_programs }

专门构建的端点，用于检索程序和组织单位之间的关联。此端点是检索程序组织单元关联的首选方式。

    /api/33/programs/orgUnits?programs={programIdA},{programIdB}

响应将采用以下格式：

```json
{
  "<programIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdC>": []
}
```

所有组织单位都可以访问的程序将返回组织单位的空数组（`[]`）。

### 拆分组织部门 { #webapi_organisation_unit_split }

组织单位拆分端点允许您将组织单位拆分为多个目标组织单位。

#### 请求{ #request }

使用 POST 请求拆分组织单位：

```
POST /api/organisationUnits/split
```

JSON 格式的有效负载如下所示：

```json
{
  "source": "rspjJHg4WY1",
  "targets": [
    "HT0w9YLMLyn",
    "rEpnzuNpRKM"
  ],
  "primaryTarget": "HT0w9YLMLyn",
  "deleteSource": true
}
```

下表描述了 JSON 属性。

表：拆分有效负载字段

| 领域         | 需要 | 值 |
| ------------- | -------- |------ |
| 来源        | 是的      | 要拆分的组织单位的标识符（源组织单位）。 |
| 目标       | 是的      | 要将源拆分为的组织单位（目标组织单位）的标识符数组。 |
| 主要目标 | 不       | 用于传输与源关联的聚合数据、事件和跟踪实体的组织单位的标识符。如果未指定，将使用第一个目标。 |
| 删除源  | 不       | 操作后是否删除源组织单位。默认为`真`。 |

拆分操作会将源组织单位拆分为目标组织单位。建议在执行拆分之前先创建新的目标组织部门，并至少确保目标组织部门不存在聚合数据。可以指定任意数量的目标组织单位。

拆分操作会将源组织单位的所有元数据关联转移到目标组织单位。这包括数据集、程序、组织单位组、类别选项、用户、可视化、地图和事件报告。

该操作会将源组织单位的所有数据记录传输到指定为主要目标的组织单位，或者如果未指定，则传输到第一个指定的目标组织单位。这包括聚合数据值、数据审批记录、事件、跟踪实体等。

#### 验证{ #validation }

以下限制和错误代码适用。

表：约束和错误代码

| 错误代码 | 描述                                     |
| ---------- | ----------------------------------------------- |
| E1510      | 必须指定来源组织单位               |
| E1511      | 必须至少指定两个目标组织单位 |
| E1512      | 源组织部门不能是目标组织部门     |
| E1513      | 必须指定主要目标                |
| E1514      | 主要目标必须是目标组织部门        |
| E1515      | 目标组织部门不存在                  |

### 合并组织单位 { #webapi_organization_unit_merge}

组织单位合并端点允许您将多个组织单位合并为一个目标组织单位。

#### 请求{ #request }

使用 POST 请求合并组织单位：

```
POST /api/organisationUnits/merge
```

JSON 格式的有效负载如下所示：

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "dataValueMergeStrategy": "LAST_UPDATED",
  "dataApprovalMergeStrategy": "LAST_UPDATED",
  "deleteSources": true
}
```

下表描述了 JSON 属性。

表：合并有效负载字段

| 领域                     | 需要 | 值 |
| ------------------------- | -------- | ----- |
| 来源                   | 是的      | 要合并的组织单位（源组织单位）的标识符数组。 |
| 目标                    | 是的      | 要合并源的组织单位的标识符（目标组织单位）。 |
| 数据值合并策略    | 不       | Strategy for merging data values. Options: `LAST_UPDATED` (default), `DISCARD`. |
| 数据审批合并策略 | 不       | Strategy for merging data approval records. Options: `LAST_UPDATED` (default), `DISCARD`. |
| 删除源             | 不       | 操作后是否删除源组织单元。默认为 true。 |

合并操作会将源组织单位合并到目标组织单位。建议在执行合并之前先创建新的目标组织部门，并至少确保目标组织部门不存在聚合数据。可以指定任意数量的源组织单位。

合并操作会将源组织单位的所有元数据关联传输到目标组织单位。这包括数据集、程序、组织单位组、类别选项、用户、可视化、地图和事件报告。该操作还将所有事件和跟踪器数据（例如事件、注册、所有权历史记录、计划所有权和跟踪实体）传输到目标组织部门。

指定的数据值合并策略定义了如何处理数据值。对于`LAST_UPDATED`策略，所有源组织单位的数据值都将转移到目标组织单位，并且在相同参数存在数据值的情况下，将使用最后更新或创建的数据值。这样做是为了避免数据重复。对于`DISCARD`策略，数据值不会转移到目标组织单位，而是简单地删除。指定的数据审批合并策略定义了数据审批记录的处理方式，并遵循与数据值相同的逻辑。

#### 验证{ #validation }

以下限制和错误代码适用。

表：约束和错误代码

| 错误代码 | 描述                                     |
| ---------- | ----------------------------------------------- |
| E1500      | 必须指定至少两个源组织单位 |
| E1501      | 必须指定目标组织单位               |
| E1502      | 目标组织部门不能是源组织部门     |
| E1503      | 源组织部门不存在                  |

## 数据集 { #webapi_data_sets } 

*dataSets* 资源遵循标准约定作为其他
DHIS2 中的元数据资源。此资源支持一些额外的
查询参数。

    / api / 33 / dataSets

要检索数据集的版本，您可以发出GET请求：

    GET /api/33/dataSets/ <uid> /版本

要提高（增加一个）数据集的版本，您可以发出 POST
要求：

    POST / api / 33 / dataSets / <uid> / version

### 数据集通知模板 { #webapi_dataset_notifications }

*数据集通知模板*资源遵循标准
DHIS2 中其他元数据资源的约定。

    获取 /api/33/dataSetNotificationTemplates

要检索数据集通知模板，您可以发出GET请求：

    GET /api/33/dataSetNotficationTemplates/ <uid>

要添加数据集通知模板，您可以发出POST请求：

    POST / api / 33 / dataSetNotficationTemplates

要删除数据集通知模板，您可以发出DELETE请求：

    删除/ api / 33 / dataSetNotficationTemplates / <uid>

JSON有效负载示例如下：

```json
{
  "name": "dataSetNotificationTemplate1",
  "dataSetNotificationTrigger": "DATA_SET_COMPLETION",
  "relativeScheduledDays": 0,
  "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
  "dataSets": [{
    "id": "eZDhcZi6FLP"
  }],
  "deliveryChannels": ["SMS","EMAIL"],
  "subjectTemplate": "V{data_set_name}",
  "messageTemplate": "V{data_set_name}V{registration_period}",
  "sendStrategy": "SINGLE_NOTIFICATION"
}

```

`notificationRecipient` 可以是以下之一：
- `USER_GROUP` for internal messages
- `ORGANISATION_UNIT_CONTACT` for external messages


## 填充的组织单位级别 { #webapi_filled_organisation_unit_levels } 

*fillOrganisationUnitLevels* 资源提供了一个有序的列表
组织单元级别，其中生成的级别被注入到
列表以填充不存在持久级别的位置。

    获取 /api/33/filledOrganizationUnitLevels

要设置组织单位级别，您可以使用以下命令发出 POST 请求：
JSON 负载和内容类型 `application/json` 如下所示：

```json
{
  "organisationUnitLevels": [{
    "name": "National",
    "level": 1,
    "offlineLevels": 3
  }, {
    "name": "District",
    "level": 2
  }, {
    "name": "Chiefdom",
    "level": 3
  }, {
    "name": "Facility",
    "level": 4
  }]
}
```

## 预测变量 { #webapi_predictors } 

预测器允许您根据表达式生成数据值。
这可以用于例如生成目标、阈值、
或估计值。

要检索预测器，您可以向预测器发出 GET 请求
像这样的资源：

    / api / predictors

### 创建预测变量 { #webapi_create_predictor } 

您可以使用对预测器的 POST 请求创建预测器
资源：

    POST / api / predictors

有效负载样本如下所示：

```json
{
  "id": "AG10KUJCrRk",
  "name": "Malaria Outbreak Threshold Predictor",
  "shortName": "Malaria Outbreak Predictor",
  "description": "Computes the threshold for potential malaria outbreaks based on the mean plus 1.5x the std dev",
  "output": {
    "id": "nXJJZNVAy0Y"
  },
  "generator": {
    "expression": "AVG(#{r6nrJANOqMw})+1.5*STDDEV(#{r6nrJANOqMw})",
    "description": "Maximum normal malaria case count",
    "missingValueStrategy": "NEVER_SKIP",
    "slidingWindow": false
  },
  "periodType": "Monthly",
  "sequentialSampleCount": 4,
  "sequentialSkipCount": 1,
  "annualSampleCount": 3,
  "organisationUnitLevels": [4]
}
```

输出元素是指数据元素的标识符
其中保存预测数据值。生成器元素是指
计算预测值时使用的表达式。

### 预测表达式 { #webapi_predictor_expressions } 

预测器总是有一个生成器表达式来描述
计算出预测值。预测器也可能有跳过测试
表达式返回一个布尔值。当跳过测试表达式为
目前，在每个采样周期中对其进行评估，以判断是否
应该跳过那个时期的值。

以下变量可用于生成器表达式
或跳过测试表达式：

| 变量    | 目的     | 描述 |
| ----------- | ---------- | ----------- |
| #{ <dataelement-id> } | 汇总数据元素 | 指所有类别选项组合中的聚合数据元素的总值。 |
| #{ <dataelement-id> . <categoryoptcombo-id> | 数据元素操作数 | 指聚合数据元素和类别选项组合的组合。 |
| D{ <program-id> . <dataelement-id> } | 程序数据元素 | 引用程序中跟踪器数据元素的值。 |
| A{ <program-id> . <attribute-id> } | 程序跟踪的实体属性 | 指程序中被跟踪实体属性的值。 |
| 我{ <program-indicator-id> } | 计划指标 | 指程序指示器的值。 |
| R{ <dataset-id> . <metric> } | 报告率 | 指报告率指标。指标可以是REPORTING_RATE，REPORTING_RATE_ON_TIME，ACTUAL_REPORTS，ACTUAL_REPORTS_ON_TIME，EXPECTED_REPORTS。 |
| C{ <constant-id> } | 不变 | 指恒定值。 |
| OUG{ <orgunitgroup-id> } | 组织单位组 | 指组织单位组内组织单位的数量。 |
| [天] | 天数 | 当前期间的天数。 |

### 生成预测值 { #webapi_generating_predicted_values } 

要运行所有预测器（生成预测值），您可以进行 POST
请求运行资源：

    POST / api / predictors / run

要运行单个预测器，您可以向运行发出 POST 请求
预测器的资源：

    POST / api / predictors / AG10KUJCrRk / run

## 计划规则 { #webapi_program_rules } 

本节是关于发送和读取程序规则，并解释
程序规则数据模型。程序规则赋予功能
在 DHIS2 程序中配置动态行为。

### 程序规则模型 { #webapi_program_rule_model } 

程序规则数据模型由 programRuleVariables、
程序规则和程序规则操作。 programRule 包含一个
表达式 - 当这个表达式为真时，子程序RuleActions
被触发。 programRuleVariables 用于寻址数据元素，
跟踪实体数据值和运行所需的其他数据值
表达式。一个程序中的所有程序规则共享同一个程序库
programRuleVariables，一个 programRuleVariable 可以用于多个
程序规则的表达式。

![](resources/images/program_rules/program-rule-model.jpg)

#### 程序规则模型详细信息 { #program-rule-model-details } 

下表给出了程序规则的详细概述
模型。

表：程序规则

| 名称 | 描述 | 强制性的 |
|---|---|---|
| 程序 | 执行programRule 的程序。 | 强制性的 |
| 名称 | 将向 dhis2 配置器显示程序规则的名称。对程序的最终用户不可见。 | 强制性的 |
| 描述 | 程序规则的描述，可以被配置者用来描述规则。对程序的最终用户不可见。 | 强制性的 |
| 节目阶段 | 如果为程序规则设置了programStage，则该规则将仅在指定的程序阶段内进行评估。 | 选修的 |
| 健康）状况 | 需要计算为 true 才能使程序规则触发其子操作的表达式。该表达式是使用运算符、函数调用、硬编码值、常量和程序规则变量编写的。 `d2:hasValue('血红蛋白') && #{hemoglobin} <= 7 `| 强制性的 |
| 优先事项 | 在规则顺序很重要的情况下运行规则的优先级。在大多数情况下，规则不依赖于在其他规则之前或之后运行，并且在这些情况下可以省略优先级。如果未设置优先级，则该规则将在定义了优先级的任何规则之后运行。如果设置了优先级（整数），则优先级最低的规则将在优先级较高的规则之前运行。 | 选修的 |

#### 计划规则操作模型详细信息 { #program-rule-action-model-details } 

下表给出了对 programRuleAction 的详细概述
模型。

表：programRuleAction

| 名称 | 描述 | 强制性的 |
|---|---|---|
| 程序规则 | 作为此操作的父级的programRule。 | 强制性的 |
| 程序规则-动作类型 | 要执行的操作类型。 <br> * `DISPLAYTEXT` - 在给定小部件中显示文本。 <br> * `DISPLAYKEYVALUEPAIR` - 在给定的小部件中显示键和值对（如程序指示器）。 <br> * `HIDEFIELD` - 隐藏指定的 dataElement 或 trackedEntityAttribute。 <br> - *content* - 如果定义，*content* 中的文本将在先前在字段中输入值（现在约为）的情况下向最终用户显示被隐藏（因此被清空）。如果未定义*content*，则在此实例中将向用户显示标准消息。 <br> - *dataElement* - 如果已定义，则当规则有效时，HIDEFIELD 操作将隐藏此 dataElement。 <br> - *trackedEntityDataValue* - 如果定义，则当规则有效时，HIDEFIELD 操作将隐藏此 trackedEntityDataValue。 <br> * `HIDESECTION` - 隐藏指定部分。 <br> - *programStageSection* - 必须定义。这是在父规则有效的情况下将隐藏的programStageSection。 <br> * `ASSIGN` - 为 dataElement 分配一个值（帮助用户计算某些内容或在某处填写明显的值）<br> - *content* - 如果定义，*data* 中的值将分配给该变量。如果定义了内容 ID，并因此分配了一个变量以在其他规则中使用，则还必须分配 *programRule.priority* 以确保具有 ASSIGN 操作的规则在依次评估分配的变量的规则之前运行。 <br> - *data* - 必须定义，数据形成一个表达式，该表达式被计算并分配给变量(#{myVariable} )、数据元素或两者。 <br> - *dataElement* - 如果定义，*data* 中的值将分配给此数据元素。 <br> 必须定义 content 或 dataElement 才能使 ASSIGN 操作生效。 <br> * `SHOWWARNING` - 向用户显示警告，不阻止用户完成活动或注册。 <br> - *content* - 如果定义，内容是显示在错误消息末尾的静态部分。 <br> - *data* - 如果定义，数据会形成一个表达式，该表达式将被计算并添加到警告消息的末尾。 <br> - *dataElement* - 如果已定义，警告消息将显示在此数据元素旁边。 <br> - *trackedEntityAttribute* - 如果定义，警告消息将显示在此跟踪实体属性旁边。 <br> 必须指定 dataElement 或 trackedEntityAttribute。 <br> * `SHOWERROR` - 向用户显示错误，阻止用户完成活动或注册。 <br> - *content* - 如果定义，内容是显示在错误消息开头的静态部分。 <br> - *data* - 如果定义，数据会形成一个表达式，该表达式将被计算并添加到错误消息的末尾。 <br> - *dataElement* - 如果定义，错误消息将链接到此数据元素。 <br> - *trackedEntityAttribute* - 如果定义，错误消息将链接到此跟踪的实体属性。 <br> 必须指定 dataElement 或 trackedEntityAttribute。 <br> * `WARNINGONCOMPLETE` - 在“完成表单”对话框中向用户显示警告，但允许用户完成事件。 <br> - *content* - 如果定义，内容是显示在错误消息末尾的静态部分。 <br> - *data* - 如果定义，数据会形成一个表达式，该表达式将被计算并添加到警告消息的末尾。 <br> - *dataElement* - 如果已定义，则警告消息以数据元素的名称/formName 为前缀。 <br> * `ERRORONCOMPLETE` - 当用户尝试完成事件时，在模式窗口中向用户显示错误。用户被阻止完成该事件。 <br> - *content* - 如果定义，内容是显示在错误消息开头的静态部分。 <br> - *data* - 如果定义，数据会形成一个表达式，该表达式将被计算并添加到错误消息的末尾。 <br> - *dataElement* - 如果定义，错误消息将链接到此数据元素。 <br> * `CREATEEVENT` - 在同一注册中创建事件。 <br> - *内容* <br> - *data* - 如果已定义，则包含用于分配创建的事件的数据值。格式为 <uid\> : <data value\> 。如果指定了多个值，则这些值用逗号分隔。 <br> AcMrnleqHqc:100,AqK1IHqCkEE:'PolyHydramnios' - *programStage* - 必须定义，并指定规则应在其中创建事件的程序阶段。 <br> * `SETMANDATORYFIELD` - 将字段设置为必填。 <br> - *dataElement* - 如果定义，此数据元素将在数据输入表单中设置为强制。 <br> - *trackedEntityAttribute* - 如果定义，此跟踪实体属性将在注册表单或个人资料中设置为强制属性。 <br> * `SENDMESSAGE` - 在活动/注册完成或数据值更新时发送消息。 <br> - *messageTemplate* - 如果定义，此模板将以 SMS 或 EMAIL 形式传送，具体取决于消息模板中的 DeliveryChannel 值。 <br> * `SCHEDULEMESSAGE` - 在事件/注册完成或数据值更新时安排消息。 <br> - *messageTemplate* - 如果定义，此模板将以 SMS 或 EMAIL 形式传送，具体取决于消息模板中的 DeliveryChannel 值。 <br> - *发送消息的日期* - 将用于评估预定日期的表达式。该表达式的结果应该是日期，任何其他结果都将被丢弃，并且不会安排通知。 | 强制性的 |
| 地点 | 用于actionType DISPLAYKEYVALUEPAIR 和DISPLAYTEXT 来指定在哪个小部件中显示文本或键值对。DISPLAYKEYVALUEPAIR 和DISPLAYTEXT 是必需的。 | 参见说明 |
| 内容 | 用于不同操作中的用户消息。有关如何在每种操作类型中使用它的详细说明，请参阅 actionType 概述。 SHOWWARNING、SHOWERROR、WARNINGONCOMPLETE、ERRORONCOMPLETE、DISPLAYTEXT 和 DISPLAYKEYVALUEPAIR 是必需的。 HIDEFIELD 和 ASSIGN 可选。 | 参见说明 |
| 数据 | 用于不同动作中的表达。有关如何在每种操作类型中使用它的详细说明，请参阅 actionType 概述。 ASSIGN 的强制要求。 SHOWWARNING、SHOWERROR、WARNINGONCOMPLETE、ERRORONCOMPLETE、DISPLAYTEXT、CREATEEVENT 和 DISPLAYKEYVALUEPAIR 可选 | 参见说明 |
| 数据元素 | 用于将规则操作链接到数据元素。有关如何在每种操作类型中使用它的详细说明，请参阅 actionType 概述。 SHOWWARNING、SHOWERROR、WARNINGONCOMPLETE、ERRORONCOMPLETE、ASSIGN 和 HIDEFIELD 可选 | 参见说明 |
| trackedEntity- 属性 | 用于将规则操作链接到 trackedEntityAttributes。有关如何在每种操作类型中使用它的详细说明，请参阅 actionType 概述。 SHOWWARNING、SHOWERROR 和 HIDEFIELD 是可选的。 | 参见说明 |
| 选项 | 用于将规则操作链接到选项。有关如何在每种操作类型中使用它的详细说明，请参阅 actionType 概述。 HIDEOPTION 可选 | 参见说明 |
| 选项组 | 用于将规则操作链接到选项组。有关如何在每种操作类型中使用它的详细说明，请参阅 actionType 概述。 SHOWOPTIONGROUP、HIDEOPTIONGROUP 是必需的。 | 参见说明 |
| 节目阶段 | 仅用于 CREATEEVENT 规则操作。 CREATEEVENT 必需的。 | 参见说明 |
| 程序阶段部分 | 仅用于 HIDESECTION 规则操作。 HIDESECTION 强制 | 参见说明 |

##### ProgramRuleAction 验证 { #programruleaction-validation }
2.37 中的 ProgramRuleAction 模型添加了某些验证。主要目的是防止用户创建错误的程序规则，以保持数据库的一致性。这些验证取决于程序规则操作类型。每个操作类型都有其各自的验证。

表：ProgramRuleAction 验证

| 名称 | 验证检查 id 是否存在 |
|---|---|
|发信息| 通知模板 ID |
|安排消息| 通知模板 ID |
|隐藏部分| ProgramStage 部分 id |
|隐藏程序阶段| 节目阶段 ID |
|隐藏字段| DataElement 或 TrackedEntityAttribute id |
|隐藏选项| 选项编号 |
|隐藏选项组| 选项组 ID |
|展会选择组| 选项组 ID |
|设置强制字段| DataElement 或 TrackedEntityAttribute id |
|淋浴错误| 始终有效 |
|显示警告| 始终有效 |
|显示文本| DataElement 或 TrackedEntityAttribute id |
|显示键值对||
|分配| DataElement 或 TrackedEntityAttribute id |
|警告完成| DataElement 或 TrackedEntityAttribute id |
|错误完成| DataElement 或 TrackedEntityAttribute id |

Apart from above validations, `data` field in program rule action which normally contains expression can also be evaluated using below api endpoint.

    POST /api/programRuleActions/data/expression/description?programId= <uid>


```json
{
  "condition": "1 + 1"
}
```

#### 程序规则变量模型的详细信息 { #program-rule-variable-model-details } 

下表详细概述了
程序规则变量模型。

表：programRuleVariable

| 名称 | 描述 | 强制性的 |
|---|---|---|
| 名称 | programRuleVariable 的名称 - 该名称在表达式中使用。 #{myVariable} \> 5 | 强制性的 |
| 源类型 | 定义如何使用来自注册和事件的数据填充此变量。 <br> * DATAELMENT_NEWEST_EVENT_PROGRAM_STAGE - 在跟踪器捕获中，获取当前注册中给定计划阶段的事件中数据元素存在的最新值。在事件捕获中，获取组织单元上最新的 10 个事件中的最新值。 <br> * DATAELMENT_NEWEST_EVENT_PROGRAM - 在跟踪器捕获中，获取整个注册过程中数据元素存在的最新值。在事件捕获中，获取组织单元上最新的 10 个事件中的最新值。 <br> * DATAELEMENT_CURRENT_EVENT - 仅获取当前事件中给定数据元素的值。 <br> * DATAELMENT_PREVIOUS_EVENT - 在跟踪器捕获中，获取当前事件之前的程序中的事件中存在的最新值。在事件捕获中，获取组织单位上注册的 10 个先前事件中的最新值。 <br> * CALCULATED_VALUE - 用于保留将由 ASSIGN 程序规则操作分配的变量名称 <br> * TEI_ATTRIBUTE - 获取给定跟踪实体属性的值 | 强制性的 |
| 值类型 | valueType 参数定义此 ProgramRuleVariable 可以包含的值的类型。其值取决于 sourceType 参数。如果源是 DataElement 或 TrackedEntityAttribute <br>，则 valueType 将从源的 valueType 派生。当 sourceType 为 CALCULATED_VALUE 时，valueType 应由用户提供，否则将默认 <br> 为 ValueType.TEXT| 强制性的
| 数据元素 | 用于将programRuleVariable链接到dataElement。对于以 DATAELEMENT_ 开头的所有源类型都是强制的。 | 参见说明 |
| trackedEntity- 属性 | 用于将programRuleVariable链接到trackedEntityAttribute。对于源类型 TEI_ATTRIBUTE 是必需的。 | 参见说明 |
| useCodeFor-OptionSet | 如果选中，该变量将使用任何链接选项集中的代码（而不是名称）填充。默认未选中，这意味着选项的名称已填充。 ||
| 节目阶段 | 用于指定从中检索programRuleVariable值的特定程序阶段。 DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE 必需。 | 参见说明 |

### 创建程序规则 { #webapi_creating_program_rules } 

- To perform crud operations, `programRules` resource is available in API.

要检索programRules的列表，您可以执行GET请求，如下所示：

    / api / programRules

要检索单个programRule，您可以执行GET请求，如下所示：

    / api / programRules / <program_rule_uid>

要保存/添加单个programRule，您可以执行POST请求，如下所示：

    / api / programRules / <program_rule_uid>

要更新单个programRule，您可以执行如下PUT请求：

    / api / programRules / <program_rule_uid>

要删除单个programRule，您可以执行以下DELETE请求：

    / api / programRules / <program_rule_uid>

要检索programRule条件的描述，可以使用POST并在POST正文中提供条件字符串。

    / api / programRules / condition / description？ <program_rule_uid>

## 形式 { #webapi_forms } 

To retrieve information about a form (which corresponds to a data set
and its sections) you can interact with the `form` resource. The form
response is accessible as XML and JSON and will provide information
about each section (group) in the form as well as each field in the
sections, including labels and identifiers. By supplying period and
organisation unit identifiers the form response will be populated with
data values.

表：表单查询参数

| 范围 | 选项 | 描述 |
|---|---|---|
| 聚乙烯 | ISO周期 | 填充表单数据值的时间段。 |
| 欧 | 用户标识 | 要为其填充表单数据值的组织单位。 |
| 元数据 | 假的&#124;真的 | 是否包含有关表单部分的每个数据元素的元数据。 |

要检索数据集的表单，您可以执行GET请求，如下所示：

    / api / dataSets / <dataset-id> /form.json

检索具有标识符“BfMAe6Itzgt”的数据集的表单
XML：

    / api / dataSets / BfMAe6Itzgt / form

要检索包含JSON中的元数据的表单，请执行以下操作：

    /api/dataSets/BfMAe6Itzgt/form.json?metaData=true

检索填充了特定时期数据值的表单，并
XML 中的组织单位：

    /api/dataSets/BfMAe6Itzgt/form.xml?ou=DiszpKrYNg8&pe=201401

当涉及自定义数据输入表单时，此资源还允许
直接为数据集创建此类表单。这可以通过一个
内容类型为 text/html 的 POST 或 PUT 请求，其中有效负载是
自定义表单标记，例如：

```bash
curl -d @form.html "localhost/api/dataSets/BfMAe6Itzgt/form"
  -H "Content-Type:text/html" -u admin:district -X PUT
```

## 文件资料 { #webapi_documents } 

对文件的引用可以与文档资源一起存储。



表：文档字段

| 字段名称 | 描述 |
|---|---|
| 名称 | 文档的唯一名称 |
| 外部的 | 标识文档位置的标志。 TRUE 表示外部文件，FALSE 表示内部文件 |
| 网址 | 文件的位置。外部文件的 URL。内部文件资源 ID（请参阅[文件资源](#webapi_file_resources)） |

对文档端点的GET请求将返回所有文档：

    / api / documents

对文档端点的POST请求将创建一个新文档：

```bash
curl -X POST -d @document.json -H "Content-type: application/json"
  "http://dhis.domain/api/documents"
```

```json
{
  "name": "dhis home",
  "external": true,
  "url": "https://www.dhis2.org"
}
```

带有附加文档 ID 的 GET 请求将返回信息
关于文件。对同一端点的 PUT 请求将更新
文档的字段：

    / api / documents / <documentId>

将 */data* 附加到 GET 请求将返回实际文件内容
文件的：

    / api / documents / <documentId> / data

## CSV元数据导入 { #webapi_csv_metadata_import } 

DHIS2支持以CSV格式导入元数据，例如数据元素，组织单位和验证规则。根据列顺序/列索引来标识各种元数据对象的属性（有关详细信息，请参见下文）。您可以省略不需要的对象属性/列，但是由于列顺序很重要，因此必须包括一个空列。换句话说，如果您要指定在列顺序中排在后面的属性/列，但不指定在列顺序中排在较早的位置的某些列，则可以为它们添加空白/空白列。

CSV文件的第一行被视为标题，在导入期间将被忽略。 _comma_字符应用作文本定界符。包含逗号的文本必须放在_双引号_中。

要上传CSV格式的元数据，您可以向元数据端点发出POST请求：

    POST / api / metadata？classKey = CLASS-KEY

支持以下对象类型。 `classKey` 查询参数是强制性的，可以在下表中的每个对象类型旁边找到。

表：对象类型和键

| 对象类型 | 类键 |
|---|---|
| 资料元素 | DATA_ELEMENT |
| 数据元素组 | DATA_ELEMENT_GROUP |
| 类别选项 | CATEGORY_OPTION |
| 类别选项组 | CATEGORY_OPTION_GROUP |
| 组织单位 | 组织_单位 |
| 组织单位组 | ORGANISATION_UNIT_GROUP |
| 验证规则 | VALIDATION_RULE |
| 选项集 | 选项_设置 |
| 翻译 | 翻译 |

> **提示**
>
> 如果使用 *curl*，应该使用 `--data-binary` 选项，因为它保留了换行符和换行符，这对于 CSV 数据是必不可少的。

例如，要使用`curl`上传CSV格式的数据元素文件，可以使用以下命令：

```bash
curl --data-binary @data_elements.csv "http://localhost/api/metadata?classKey=DATA_ELEMENT"
  -H "Content-Type:application/csv" -u admin:district
```

以下各节列出了CSV导入当前支持的对象类型的格式。

### 资料元素 { #webapi_csv_data_elements } 

表：数据元素 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || 姓名。最多 230 个字符。独特的。 |
| 2 | 用户标识 | 不 | 用户标识 | 稳定的标识符。正好 11 个字母数字字符，以字母开头。如果不指定则由系统生成。 |
| 3 | 码 | 不 || 稳定的代码。最多 50 个字符。 |
| 4 | 简称 | 不 | 50 名称的第一个字符 | 如果未指定，将回退到名称的前 50 个字符。最多 50 个字符。独特的。 |
| 5 | 描述 | 不 || 自由文字描述。 |
| 6 | 表格名称 | 不 || 最多 230 个字符。 |
| 7 | 域名类型 | 不 | 聚合&#124;追踪器 | 数据元素的域类型，可以是聚合或跟踪器。最多 16 个字符。 |
| 8 | 值类型 | 不 | INTEGER &#124; NUMBER &#124; UNIT_INTERVAL &#124; PERCENTAGE &#124; INTEGER_POSITIVE &#124; INTEGER_NEGATIVE &#124; INTEGER_ZERO_OR_POSITIVE &#124; FILE_RESOURCE &#124; COORDINATE &#124;TEXT &#124; LONG_TEXT &#124; LETTER &#124; PHONE_NUMBER &#124; EMAIL &#124; BOOLEAN &#124; TRUE_ONLY &#124; DATE &#124; DATETIME | 值类型。最多 16 个字符。 |
| 9 | 聚集类型 | 不 | 总和＆#124;平均水平AVERAGE_SUM_ORG_UNIT &#124;计数&#124;标准差值方差&#124;敏&#124;最大&#124;没有任何 | 聚合类型表示如何聚合各个维度的数据。最多 16 个字符。 |
| 10 | 品类组合 | 不 | 用户标识 | 类别组合的UID。如果未指定，将默认使用默认类别组合。 |
| 11 | 网址 | 不 || 数据元素资源的 URL。最多 255 个字符。 |
| 12 | 零很重要 | 不 | 假的&#124;真的 | 指示是否为此数据元素存储零值。 |
| 13 | 选项集 | 不 | 用户标识 | 用于数据的选项集的 UID。 |
| 14 | 评论选项集 | 不 | 用户标识 | 用于注释的选项集的 UID。 |

下面是数据元素的 CSV 文件示例。首先
行将始终被忽略。请注意如何跳过列并依赖
系统使用的默认值。您还可以跳过列
你不使用出现在右边的

```csv
名称，uid，代码，简称，描述
“妇女参加技能发展培训”，“ D0001”，“妇女参加培训”
“妇女参与社区组织”，“ D0002”，“妇女参与组织”
```

### 组织单位 { #webapi_csv_org_units } 

表：组织单位 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || 姓名。最多 230 个字符。独特的。 |
| 2 | 用户标识 | 不 | 用户标识 | 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。 |
| 3 | 码 | 不 || 稳定的代码。最多 50 个字符。 |
| 4 | 家长 | 不 | 用户标识 | 上级组织单位的 UID。 |
| 5 | 简称 | 不 | 50 名称的第一个字符 | 如果未指定，将回退到名称的前 50 个字符。最多 50 个字符。独特的。 |
| 6 | 描述 | 不 || 自由文字描述。 |
| 7 | 开业日期 | 不 | 1970年1月1日 | 组织单位的开业日期，格式为 YYYY-MM-DD。 |
| 8 | 截止日期 | 不 || 组织单位的关闭日期，格式为 YYYY-MM-DD，如果当前打开，则跳过。 |
| 9 | 评论 | 不 || 组织单位的自由文本评论。 |
| 10 | 特征类型 | 不 | NONE &#124; MULTI_POLYGON &#124; POLYGON &#124; POINT &#124; SYMBOL | 地理空间要素类型。 |
| 11 | 坐标 | 不 || 用于 Geo JSON 格式的地理空间分析的坐标。 |
| 12 | 网址 | 不 || 组织单位资源的 URL。最多 255 个字符。 |
| 13 | 联系人 | 不 || 组织单位联系人。最多 255 个字符。 |
| 14 | 地址 | 不 || 组织单位地址。最多 255 个字符。 |
| 15 | 电子邮件 | 不 || 组织单位的电子邮件。最多 150 个字符。 |
| 16 | 电话号码 | 不 || 组织单位的电话号码。最多 150 个字符。 |

使用父单位导入组织单位的最小示例
看起来像这样：

```csv
名称，uid，代码，父项
“西部省份”，“ WESTP”，“ ImspTQPwCqd”
“东部省”，“ EASTP”，“ ImspTQPwCqd”
```

### 验证规则 { #webapi_csv_validation_rules } 

表：验证规则 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || 姓名。最多 230 个字符。独特的。 |
| 2 | 用户标识 | 不 | 用户标识 | 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。 |
| 3 | 码 | 不 || 稳定的代码。最多 50 个 |
| 4 | 描述 | 不 || 自由文字描述。 |
| 5 | 操作说明 | 不 || 免费文字说明。 |
| 6 | 重要性 | 不 | 中号＆#124;高＆#124;低的 | 验证规则的重要性。 |
| 7 | 规则类型（忽略） | 不 | 验证&#124;监视 | 验证规则的类型。 |
| 8 | 操作员 | 不 | equal_to &#124; not_equal_to &#124; greater_than &#124; greater_than_or_equal_to &#124; less_than &#124; less_than_or_equal_to &#124; compulsory_pair &#124; exclusive_pair | 表达式运算符。 |
| 9 | 期间类型 | 不 | 每月&#124;每日&#124;每周&#124;季刊&#124;六月刊每年 | 时期类型。 |
| 10 | 左侧表达式 | 是的 || 基于数据元素和选项组合 UID 的数学公式。 |
| 11 | 左侧表达式说明 | 是的 || 自由文本。 |
| 12 | 左侧缺失值策略 | 不 | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124;从不_跳过 | 左侧表达式中缺少值时的行为。 |
| 13 | 右侧表达式 | 是的 || 基于数据元素和选项组合 UID 的数学公式。 |
| 14 | 右侧表达式说明 | 是的 || 自由文本。 |
| 15 | 右侧缺失值策略 | 不 | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124;从不_跳过 | 右侧表达式中缺少值时的行为。 |

### 选项集 { #webapi_csv_option_sets } 

表：选项集 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 选项集名称 | 是的 || 姓名。最多 230 个字符。独特的。每个选项都应该重复。 |
| 2 | 选项集UID | 不 | 用户标识 | 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。每个选项都应该重复。 |
| 3 | 选项集代码 | 不 || 稳定的代码。最多 50 个字符。每个选项都应该重复。 |
| 4 | 选项名称 | 是的 || 选项名称。最多 230 个字符。 |
| 5 | 选项UID | 不 | 用户标识 | 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。 |
| 6 | 选项代码 | 是的 || 稳定的代码。最多 50 个字符。 |

选项集的格式很特殊。前三个值代表
一个选项集。最后三个值代表一个选项。首先
代表选项集的三个值应该对每个值重复
选项。

```csv
optionsetname，optionsetuid，optionsetcode，optionname，optionuid，optioncode
“颜色”，“颜色”，“蓝色”，“蓝色”
“颜色”，“颜色”，“绿色”，“绿色”
“颜色”，“颜色”，“黄色”，“黄色”
“性别”，“男”，“男”
“性别”，“女性”，“女性”
“性别”，“未知”，“未知”
“结果”，“高”，“高”
“结果”，“中”，“中”
“结果”，“低”，“低”
“ Impact”，“ cJ82jd8sd32”，“ IMPACT”，“ Great”，“ GREAT”
“影响”，“ cJ82jd8sd32”，“影响”，“中等”，“中等”
“影响”，“ cJ82jd8sd32”，“影响”，“不良”，“不良”
```

### 选项组 { #option-group } 

表：选项组 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 选项组名称 | 是的 || 姓名。最多 230 个字符。独特的。每个选项都应该重复。 |
| 2 | 选项组Uid | 不 || 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。每个选项都应该重复。 |
| 3 | 选项组代码 | 不 || 稳定的代码。最多 50 个字符。每个选项都应该重复。 |
| 4 | 选项组简称 | 是的 || 简称。最多 50 个字符。独特的。每个选项都应该重复。 |
| 5 | 选项集Uid | 是的 || 稳定的标识符。最多 11 个字符。每个选项都应该重复。 |
| 6 | 选项ID | 不 || 稳定的标识符。最多 11 个字符。 |
| 7 | 选项代码 | 不 || 稳定的代码。最多 50 个字符。 |

OptionGroup CSV有效负载样本

```csv
optionGroupName，optionGroupUid，optionGroupCode，optionGroupShortName，optionSetUid，optionUid，optionCode
optionGroupA，groupA，xmRubJIhmaK，OptionA
optionGroupA，groupgroup，xmRubJIhmaK，OptionB
optionGroupB 、、 groupB，QYDAByFgTr1，OptionC
```
### 选项组集 { #option-group-set } 



表：选项组集 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 选项组集名称 | 是的 || 姓名。最多 230 个字符。独特的。每个选项都应该重复。 |
| 2 | 选项组集 Uid | 不 || 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。每个选项都应该重复。 |
| 3 | 选项组集代码 | 不 || 稳定的代码。最多 50 个字符。每个选项都应该重复。 |
| 4 | 选项组集描述 | 不 || 描述。每个选项都应该重复。 |
| 5 | 数据维度 | 不 || 真假 |
| 6 | 选项集Uid | 不 || 选项集 UID。稳定的标识符。最多 11 个字符。 |

OptionGroupSet CSV有效负载样本

```csv
名称，uid，代码，描述，数据维度，选项
optiongroupsetA，...，xmRubJIhmaK
optiongroupsetB 、、、、 false，QYDAByFgTr1
```
要将OptionGroups添加到导入的OptionGroupSet中，请按照导入集合成员身份的步骤进行操作

### 指标{ #webapi_csv_indicators }

表：指标 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || 姓名。最多 230 个字符。独特的。 |
| 2 | 用户标识 | 不 | 用户标识 | 稳定的标识符。正好 11 个字母数字字符，以字母开头。如果不指定则由系统生成。 |
| 3 | 码 | 不 || 稳定的代码。最多 50 个字符。 |
| 4 | 简称 | 是的 | 50 名称的第一个字符 | 如果未指定，将回退到名称的前 50 个字符。最多 50 个字符。独特的。 |
| 5 | 分母 | 是的 || 指标表达式。 |
| 6 | 分母描述 | 不 || 最多 230 个字符。 |
| 5 | 分子 | 是的 || 指标表达式。 |
| 6 | 分子描述 | 不 || 最多 230 个字符。 |
| 6 | 年化的 | 是的 ||  真假 |
| 6 | 小数点 | 不 || 用于指标值的小数位数，null 表示默认值。
| 6 | 指标类型 | 是的 || 用户标识 | 指标类型的 UID。

下面是指标 CSV 文件的示例。首先
行将始终被忽略。请注意如何跳过列并依赖
系统使用的默认值。您还可以跳过以下列
您不使用出现在右侧的哪个

```csv
Name,UID,Code,Description,shortName,denominator,denominatorDescription,numerator,numeratorDescription,annualized,decimals,indicatorType
Indicator A,yiAKjiZVoOU,CodeA,Indicator A description,Indicator A shortname,#{fbfJHSPpUQD},denominatorDescription,#{h0xKKjijTdI},numeratorDescription,false,2,sqGRzCziswD
Indicator B,Uvn6LCg7dVU,CodeB,Indicator B description,Indicator B shortname,#{fbfJHSPpUQD},denominatorDescription,#{h0xKKjijTdI},numeratorDescription,false,2,sqGRzCziswD
```

### 收藏会员 { #collection-membership } 

除了导入对象，您还可以选择只导入对象
对象和组之间的组成员关系。目前，该
支持以下组和对象对

  - 组织单位组-组织单位

  - 数据元素组-数据元素

  - 指标组-指标

  - 选项组集-选项组

这些导入的CSV格式相同



表：集合成员资格 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 用户标识 | 是的 | 用户标识 | 要添加对象的集合的 UID |
| 2 | 用户标识 | 是的 | 用户标识 | 要添加到集合中的对象的 UID |

### 其他物件 { #webapi_csv_other_objects } 



表：数据元素组、类别选项、类别选项组、组织单位组 CSV 格式

| 指数 | 柱 | 需要 | 值（默认优先） | 描述 |
|---|---|---|---|---|
| 1 | 名称 | 是的 || 姓名。最多 230 个字符。独特的。 |
| 2 | 用户标识 | 不 | 用户标识 | 稳定的标识符。最多 11 个字符。如果不指定则由系统生成。 |
| 3 | 码 | 不 || 稳定的代码。最多 50 个字符。 |
| 4 | 简称 | 不 || 简称。最多 50 个字符。 |

类别选项的示例如下所示：

```csv
名称，uid，代码，简称
“男”，“男”
“女性”，“女性”
```

## 删除的对象 { #webapi_deleted_objects } 

删除的对象资源提供了元数据对象的日志
删除。

    / api / deletedObjects

每当删除元数据类型的对象时，都会保留日志
uid、代码、类型和删除时间。这个 API 是
在`/api/deletedObjects` 字段过滤和对象过滤中可用
与其他元数据资源类似。

获取类型为数据元素的已删除对象：

    GET /api/deletedObjects.json?klass=DataElement

获取在 2015 年删除的指标类型的已删除对象和
向前：

    GET /api/deletedObjects.json?klass=指示器&deletedAt=2015-01-01

## 收藏夹 { #webapi_favorites } 

某些类型的元数据对象可以标记为收藏夹
当前登录的用户。这目前适用于仪表板。

    / api / dashboards / <uid> /收藏

要使仪表板成为收藏夹，您可以发出 *POST* 请求（无内容
type required) 到这样的 URL：

    / api /仪表板/ iMnYyBfSxmM /收藏

要将仪表板删除为收藏夹，您可以发出 *DELETE* 请求
使用与上面相同的 URL。

收藏夹状态将显示为布尔值 *收藏夹* 字段
元数据响应中的对象（例如仪表板）。

## 订阅内容 { #webapi_subscription } 

登录用户可以订阅某些类型的对象。现在
可订阅的对象是 EventChart、EventReport 类型的对象
地图、可视化和事件可视化。

> **注意**
>
> EventChart 和 EventReport 对象已弃用。请改用事件可视化。

要获取对象的订阅者（返回用户 ID 数组），您
可以发出 *GET* 请求：

    / api / <object-type> / <object-id> /订阅者

请参见以下示例：

    /api/可视化/DkPKc1EUmC2/订阅者

检查当前用户是否订阅了一个对象（返回一个
boolean) 您可以执行 *GET* 调用：

    / api / <object-type> / <object-id> /已订阅

请参见以下示例：

    /api/可视化/DkPKc1EUmC2/订阅

要订阅/取消订阅对象，请执行 *POST/DELETE*
请求（不需要内容类型）：

    / api / <object-type> / <object-id> / subscriber

## 文件资源 { #webapi_file_resources } 

*文件资源*是用于表示和存储二进制内容的对象。
*FileResource* 对象本身包含文件元数据（名称、
内容类型、大小等）以及允许检索
来自数据库外部文件存储的内容。 *FileResource* 对象
与其他数据库一样存储在数据库中，但内容（文件）是
存储在别处并可使用包含的引用检索
*（存储密钥）*。

    / api / fileResources

文件资源的内容不能直接访问，但可以
从其他对象（如数据值）引用来存储二进制
几乎无限大小的内容。

To create a file resource that does not require a corresponding data value,
POST to the endpoint `/api/fileResources` with a multipart upload:

```bash
curl "https://server/api/fileResources" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```
文件资源的` uid `可以在创建时提供，例如：
```bash
curl "https://server/api/fileResources?uid=0123456789x" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

To create both a file resource and a data value that references the file,
POST to the `/api/dataValues/file` endpoint in DHIS 2.36 or later:

```bash
curl "https://server/api/dataValues/file?de=xPTAT98T2Jd
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

For the `api/fileResources` endpoint, the only form parameter required is
*file*, which is the file to upload. For the `api/dataValues/file`
endpoint, the parameters required are the same as for a post to
`api/dataValues`, with the addition of *file*.

文件名和内容类型也应包含在请求中，但是
未提供时将替换为默认值。

成功创建文件资源后，返回的数据将包含
一个 `response` 字段，它又包含这样的 `fileResource`：

```json
{
  "httpStatus": "Accepted",
  "httpStatusCode": 202,
  "status": "OK",
  "response": {
    "responseType": "FileResource",
    "fileResource": {
      "name": "name-of-file.png",
      "created": "2015-10-16T16:34:20.654+0000",
      "lastUpdated": "2015-10-16T16:34:20.667+0000",
      "externalAccess": false,
      "publicAccess": "--------",
      "user": { ... },
      "displayName": "name-of-file.png",
      "contentType": "image/png",
      "contentLength": 512571,
      "contentMd5": "4e1fc1c3f999e5aa3228d531e4adde58",
      "storageStatus": "PENDING",
      "id": "xm4JwRwke0i"
    }
  }
}
```

注意响应是*202 Accepted*，表示返回的
资源已提交后台处理（持续到
在这种情况下是外部文件存储）。另外，请注意 `storageStatus` 字段
指示内容是否已存储。在这
点，到外部存储的持久化还没有完成（它是
可能会上传到某个地方的基于云的商店）
`PENDING` 状态。

即使内容尚未完全存储，文件资源
现在可以使用，例如作为数据值中的引用内容（参见
[使用文件数据值](#datavalue_file))。如果我们需要检查
更新的 *storageStatus* 或以其他方式检索
文件，可以查询`fileResources`端点。

```bash
curl "https://server/api/fileResources/xm4JwRwke0i" -H "Accept: application/json"
```

此请求将返回 `FileResource` 对象，如
上面例子的反应。

### 文件资源限制 { #webapi_file_resources_constraints } 

  - 文件资源*必须*从另一个对象引用（分配）
    以便长期坚持。一个文件资源是
    创建但未被其他对象（例如数据值）引用
    被认为处于*分期*。此中的任何文件资源
    状态并且超过*两个小时*将被标记为删除
    并将最终从系统中清除。

  - 文件资源初始创建返回的ID不是
    可从任何其他位置检索，除非文件资源具有
    已被引用（其中 ID 将被存储为引用），
    所以丢失它需要重复 POST 请求和一个新的
    要创建的对象。 *孤立*文件资源将被清理
    自动起来。

  - 文件资源对象是*不可变的*，意味着修改不是
    允许并需要创建一个全新的资源。

### 文件资源阻止列表 { #file-resource-blocklist } 

出于安全原因，某些类型的文件被阻止上传。

以下内容类型被阻止。

| 内容类型 | 内容类型 |
| ------------------------------------- | ---- |
| 文字/ HTML                             | 应用程序/ x-ms-dos-可执行 |
| 文字/ css                              | application / vnd.microsoft.portable-executable |
| 文字/ javascript                       | application / vnd.apple.installer + xml |
| 字体/ otf                              | application / vnd.mozilla.xul + xml |
| 应用程序/ x-shockwave-flash         | 应用程序/ x-httpd-php  |
| application / vnd.debian.binary-package | 应用程序/ x-sh |
| 应用/ x-rpm                     | 应用程序/ x-csh |
| 应用程序/ Java归档              |  |

以下文件扩展名被阻止。

| 文件扩展名 | 文件扩展名 | 文件扩展名 |
| ---- | ---- | ---- |
| html | 黛比  | ul  |
| 哈特姆  | 转数  | 的PHP  |
| 的CSS  | 罐  | 箱子  |
| js   | jsp  | SH   |
| 微信  | 可执行程序  | 西施  |
| OTF  | 微星  | 蝙蝠  |
| 瑞士法郎  | 每公斤 |      |

## 元数据版本控制 { #webapi_metadata_versioning } 

本节介绍元数据版本控制 API。

  - `/api/metadata/version`：这个端点将返回当前的元数据
    调用它的系统的版本。



表：查询参数

| 名称 | 需要 | 描述 |
|---|---|---|
| 版本名称 | 假 | 如果未指定此参数，它将返回系统的当前版本，否则将返回作为参数传递的 versionName 的详细信息。 （versionName 的语法为“Version_ <id\> ” |

### 获取元数据版本示例 { #webapi_metadata_versioning_examples } 

**示例：**获取此系统的当前元数据版本

请求：

```
/ api /元数据/版本
```

响应：

```json
{
  "name": "Version_4",
  "created": "2016-06-30T06:01:28.684+0000",
  "lastUpdated": "2016-06-30T06:01:28.685+0000",
  "externalAccess": false,
  "displayName": "Version_4",
  "type": "BEST_EFFORT",
  "hashCode": "848bf6edbaf4faeb7d1a1169445357b0",
  "id": "Ayz2AEMB6ry"
}
```

**示例：**获取名称为“ Version_2”的版本的详细信息

请求：

```
/ api / metadata / version？versionName = Version_2
```

响应：

```json
{
  "name": "Version_2",
  "created": "2016-06-30T05:59:33.238+0000",
  "lastUpdated": "2016-06-30T05:59:33.239+0000",
  "externalAccess": false,
  "displayName": "Version_2",
  "type": "BEST_EFFORT",
  "hashCode": "8050fb1a604e29d5566675c86d02d10b",
  "id": "SaNyhusVxBG"
}
```

  - `/api/metadata/version/history`：这个端点将返回所有
    调用它的系统的元数据版本。



表：查询参数

| 名称 | 需要 | 描述 |
|---|---|---|
| 基线 | 假 | 如果不指定该参数，则返回所有元数据版本的列表。否则，我们需要传递“Version_ <id\>”形式的 versionName 参数。然后，它将返回系统中存在的版本列表，这些版本是在作为查询参数提供的版本名称之后创建的。 |

### 获取所有元数据版本的列表 { #webapi_get_list_of_metadata_versions } 

**示例：**获取此系统中所有版本的列表

请求：

```
/ api /元数据/版本/历史记录
```

响应：

```json
{
  "metadataversions": [{
    "name": "Version_1",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:54:41.139+0000",
    "id": "SjnhUp6r4hG",
    "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798"
  }, {
    "name": "Version_2",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:59:33.238+0000",
    "id": "SaNyhusVxBG",
    "hashCode": "8050fb1a604e29d5566675c86d02d10b"
  }, {
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }]
}
```

**示例：**获取此系统在“ Version_2”之后创建的所有版本的列表

请求：

```
/ api / metadata / version / history？baseline = Version_2
```

响应：

```json
{
  "metadataversions": [{
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }, {
    "name": "Version_4",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:28.684+0000",
    "id": "Ayz2AEMB6ry",
    "hashCode": "848bf6edbaf4faeb7d1a1169445357b0"
  }]
 }
```

  - `/api/metadata/version/create`：这个端点将创建元数据
    version 参数中指定的版本类型。



表：查询参数

| 名称 | 需要 | 描述 |
|---|---|---|
| 类型 | 真正 | 需要创建的元数据版本的类型。 <br> * BEST_EFFORT <br> * ATOMIC |

用户可以选择需要创建的元数据类型。
元数据版本类型决定了进口商应该如何对待给定的
版本。导入元数据时将使用此类型。有
两种类型的元数据。

  - *BEST_EFFORT*：这种类型表明丢失的引用可以
    忽略，导入器可以继续导入元数据（例如
    数据元素组导入中缺少数据元素）。

  - *ATOMIC*：这种类型确保对元数据进行严格的类型检查
    如果有任何引用，则引用和元数据导入将失败
    不存在。

> **注意**
>
> 建议有一个 ATOMIC 类型的版本，以确保所有
> 系统（中央和本地）具有相同的元数据。任何遗漏
> 引用在验证阶段本身被捕获。请参阅
> 进口商详细信息的完整解释。

### 创建元数据版本 { #webapi_create_metadata_version } 

**示例：** 创建类型为 `BEST_EFFORT` 的元数据版本

请求：

```bash
curl -X POST -u admin:district "https://play.dhis2.org/dev/api/metadata/version/create?type=BEST_EFFORT"
```

响应：

```json
{
  "name": "Version_1",
  "created": "2016-06-30T05:54:41.139+0000",
  "lastUpdated": "2016-06-30T05:54:41.333+0000",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407+0000",
    "lastUpdated": "2016-04-06T00:06:06.571+0000",
    "externalAccess": false,
    "displayName": "John Traore",
    "id": "xE7jOejl9FI"
  },
  "displayName": "Version_1",
  "type": "BEST_EFFORT",
  "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798",
  "id": "SjnhUp6r4hG"
}
```

  - `/api/metadata/version/{versionName}/data`：这个端点将下载
    特定于作为路径传递的版本名称的实际元数据
    范围。

  - `/api/metadata/version/{versionName}/data.gz`：这个端点将下载
    特定于作为路径传递的版本名称的实际元数据
    压缩格式（gzipped）的参数。



表：路径参数

| 名称 | 需要 | 描述 |
|---|---|---|
| 版本名称 | 真正 | “Version_ <id\> ”形式的路径参数，以便 API 下载特定版本 |

### 下载版本元数据 { #webapi_download_version_metadata } 

**示例：**获取“版本5”的实际元数据

请求：

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/version/Version_5/data"
```

响应：

```json
{
  "date": "2016-06-30T06:10:23.120+0000",
  "dataElements": [
    {
      "code": "ANC 5th Visit",
      "created": "2016-06-30T06:10:09.870+0000",
      "lastUpdated": "2016-06-30T06:10:09.870+0000",
      "name": "ANC 5th Visit",
      "id": "sCuZKDsix7Y",
      "shortName": "ANC 5th Visit ",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "zeroIsSignificant": false,
      "valueType": "NUMBER",
      "categoryCombo": {
        "id": "p0KPaWEg3cf"
      },
      "user": {
        "id": "xE7jOejl9FI"
      }
    }
  ]
}
```

## 元数据同步{ #webapi_metadata_synchronization }

本节介绍了可用的元数据同步 API
2.24 开始

  - `/api/metadata/sync`：此端点执行元数据同步
    通过下载和在查询参数中传递的版本名称
    从远程服务器导入指定的版本，如定义
    设置应用程序。



表：查询参数

| 名称 | 需要 | 描述 |
|---|---|---|
| 版本名称 | 真正 | versionName 查询参数的形式为 "Version_ <id\> " 。 api从远程服务器下载此版本并将其导入到本地系统中。 |

  - 使用此 API 时应格外小心。请注意，有
    以完全自动化的方式实现同步的另一种方法
    利用“数据管理”中的元数据同步任务
    应用程序。详见用户手册第 22 章 22.17 节
    关于元数据同步任务。

  - 此同步 API 也可用于同步元数据
    从元数据同步调度程序失败的版本。由于
    它依赖于给定的元数据版本号，应该注意
    为调用 this 的顺序而采用。例如。如果这个api是
    用于从中央实例同步一些更高版本，然后
    同步可能会失败，因为元数据依赖项不存在于
    本地实例。

  - 假设本地实例在 `Version_12` 并且如果使用这个端点
    从中央同步`Version_15`（类型`BEST_EFFORT`）
    例如，调度程序将从以下位置开始同步元数据
    `版本_16`。所以本地实例不会有元数据
    `Version_12` 和 `Version_15` 之间的版本。你需要手动
    仅使用这些端点同步丢失的版本。

### 同步元数据版本 { #webapi_metadata_synchronization_version } 

**示例：**将Version_6从中央系统同步到该系统

请求：

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/sync?versionName=Version_6"
```

## 元数据存储库 { #webapi_metadata_repository } 

DHIS2 提供了一个包含元数据包的元数据存储库
各种内容。元数据包是符合 DHIS2 的 JSON 文档
它描述了一组元数据对象。

要检索可用元数据包的索引，您可以发出
对 *metadataRepo* 资源的 GET 请求：

    GET /api/synchronization/metadataRepo

元数据包条目包含有关包的信息和
相关包的 URL。索引可能如下所示：

```json
{
  "packages": [
    {
      "id": "sierre-leone-demo",
      "name": "Sierra Leone demo",
      "description": "Sierra Leone demo database",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/sierra-leone-demo/metadata.json"
    },
    {
      "id": "trainingland-org-units",
      "name": "Trainingland organisation units",
      "description": "Trainingland organisation units with four levels",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
    }
  ]
}
```

客户端可以通过 URL 安装元数据包
带有元数据包的内容类型 *text/plain* 的 POST 请求
URL 作为 *metadataPull* 资源的有效负载：

    POST / api / synchronization / metadataPull

curl命令示例如下所示：

```bash
curl "localhost:8080/api/synchronization/metadataPull" -X POST
  -d "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
  -H "Content-Type:text/plain" -u admin:district
```

## 对用户 { #reference-to-created-by-user } 创建的引用

Each object created in DHIS2 will have a property named `user` which is linked to `User` who created the object.

From version 2.36 we have changed the name of this property to `createdBy` to avoid confusion.

However, in order to keep the backwards compability, the legacy `user` property is still included in the payload and works normally as before.

```json
{
  "createdBy": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  },
  "user": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  }
}
```

## 元数据提案工作流程{ #webapi_metadata_proposal_workflow }

元数据提议工作流端点允许提议和接受元数据更改的工作流。

```
/api/metadata/proposals
```

### 提出元数据更改{ #webapi_metadata_proposal_propose }

提案始终使用以下方式针对单个元数据对象：

    POST /api/元数据/提案

根据有效负载，该提案可以：

* 添加新的元数据对象。
* 按 ID 更新现有元数据对象引用。
* 删除 ID 引用的现有元数据对象。

要建议添加新的元数据对象，请发送如下所示的 JSON 负载：

```json
{
  "type": "ADD",
  "target": "ORGANISATION_UNIT",
  "change": {"name":"My Unit", "shortName":"MyOU", "openingDate": "2020-01-01"}
}
```
The `change` property contains the same JSON object that could directly be posted to the corresponding endpoint to create the object.

要建议更新现有元数据对象，请发送 JSON 有效负载，如下例所示：

```json
{
  "type": "UPDATE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>",
  "change": [
    {"op": "replace", "path": "/name", "value": "New name"}
  ]
}
```
The `targetId` refers to the object by its ID which should be updated. The `change` property here contains a JSON patch payload. This is the same
patch payload that could be posted to the corresponding endpoint to directly apply the update.

要建议删除现有对象，请发送一个有效负载，如上一个示例所示：

```json
{
  "type": "REMOVE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>"
}
```
The `targetId` refers to the object  by its ID which should be removed. A free text `comment` can be added to any type of comment.

Only `target` type `ORGANISATION_UNIT` is supported currently.

### 接受元数据更改提案{ #webapi_metadata_proposal_accept }
要接受一个开放的提案，请在提案资源上使用`POST`

    POST /api/metadata/proposals/ <uid>

成功后，提案的状态变为`接受`状态。一旦被接受，提案就不能再被拒绝。

Should a proposal fail to apply it changes to status `NEEDS_UPDATE`. The `reason` field contains a summary of the failures when this information is 
available.

### 反对元数据更改提案{ #webapi_metadata_proposal_oppose }
如果提案不太正确并且需要调整，可以通过发送提案资源的`PATCH`来反对提案

    补丁 /api/metadata/proposals/ <uid>

可选地，可以在其中添加纯文本正文，以给出提案遭到反对的`原因`。

反对的提案必须处于`PROPOSED`状态，并将更改为`NEEDS_UPDATE`状态。

### 调整元数据更改提案{ #webapi_metadata_proposal_adjust }
A proposal in state `NEEDS_UPDATE` needs to be adjusted before it can be accepted. To adjust the proposal a `PUT` request is made for the proposal's 
resource

    PUT /api/metadata/proposals/ <uid>

Such an adjustment can either be made without a body or with a JSON body containing an object with the updated `change` and `targetId` for the 
adjustment:

```json
{
  "targetId": "<id>",
  "change": ...
}
```
The JSON type of the `change` value depends on the proposal `type` analogous to when a proposal is initially made.

### 拒绝元数据更改提案{ #webapi_metadata_proposal_reject }
要拒绝打开的提案，请在提案资源上使用`DELETE`

    删除 /api/metadata/proposals/ <uid>

这最终将提案的状态更改为`拒绝`。不能对此提案进行进一步的更改。它作为事件的文档保存。

### 列出元数据更改提案{ #webapi_metadata_proposal_list }
所有提案都可以列出：

    获取/api/元数据/提案/

The result list can be filtered using the `filter` parameter.
For example, to list only accepted proposals use:

    GET /api/metadata/proposals?filter=status:eq:ACCEPTED

与仅显示开放提案类似，使用：

    获取 /api/metadata/proposals?filter=status:eq:PROPOSED

Filters can also be applied to any field except `change`. Supported filter operators are those described in the Gist Metadata API. This also includes property transformers described for Gist API.

可用字段列表为：

| 领域       | 描述 |
| ----------- | -------------------------------------------------------------- |
| ID          | 提案的唯一标识符 |
| 类型        | `ADD` 一个新对象，`UPDATE` 现有对象，`REMOVE` 现有对象 |
| 地位      | `PROPOSED`（开放提案），`ACCEPTED`（成功），`NEEDS_UPDATE`（接受导致错误或反对），`REJECTED` |
| 目标      | type of metadata object to add/update/remove; currently only `ORGANISATION_UNIT` |
| 目标ID    | 更新或删除对象的 UID，未为`添加`定义 |
| 由...制作   | 创建提案的用户 |
| 已创建     | 创建提案的日期时间 |
| 最终确定者 | 接受或拒绝提案的用户 |
| 最终确定的   | 提案更改为接受或拒绝结论性状态的日期时间 |
| 评论     | 为初始提案提供可选的纯文本注释 |
| 原因      | 当提案被反对或接受提案失败时出现的错误时给出的可选纯文本 | 
| 改变      | JSON object for `ADD` proposal, JSON array for `UPDATE` proposal, nothing for `REMOVE` proposal |

### 查看元数据更改提案{ #webapi_metadata_proposal_show }
可以使用以下方式查看各个变更建议

    GET /api/metadata/proposals/ <uid>

The `fields` parameter can be used to narrow the fields included for the shown object. For example:

    GET /api/metadata/proposals/ <uid> ?fields=id,类型,状态,更改

## 元数据属性值类型和验证{ #metadata-attribute-value-type-and-validations }
| 类型 | 验证
|---| --- |
| 文本 | 没有
| LONG_TEXT | 没有
| 信 | 值长度 = 1 AND 是一个字母
| PHONE_NUMBER  | 验证基于此正则表达式 `^[0-9+\\(\\)#\\.\\s\\/ext-]{6,50}$`。最大长度为 50。 <br /> 示例：+4733987937、(+47) 3398 7937、(47) 3398 7937.123
| 电子邮件 | 一般电子邮件格式 abc@email.com
| 布尔值 | `true` or `false`
| TRUE_ONLY | Only accept `true`
| 日期 | Use format `yyyy-MM-dd`
| 约会时间 | 使用格式 `yyyy-MM-dd HH:mm:ssZ` 或 `yyyy-MM-dd'T'HH:mm:ss`
| 时间 | Use fornat `HH:mm`
| 数字 | 值必须是数字，最大长度 = 250
| UNIT_INTERVAL | 值是数字并且介于 0 和 1 之间
| 百分比 | 值是 0 到 100 范围内的数字
| 整数 | 值为整数
| INTEGER_POSITIVE | 值为正整数
| INTEGER_NEGATIVE | 值为负整数
| INTEGER_ZERO_OR_POSITIVE | 值为正整数或零整数
| TRACKER_ASSOCIATE | 没有
| 用户名 | Value is a username of an existing `User`
| 协调 | 没有
| 组织_单位 | Value is a valid UID of an existing `OrganisationUnit`
| 参考 | 没有
| 年龄 | 值为出生日期。使用 DATE 类型中的格式。
| 网址 | 值为有效的 URL
| FILE_RESOURCE | Value is a valid UID of existing `FileResource`
| 图像 | Value is a valid UID of existing `FileResource`
| 地理数据JSON |遵循[GeoJson规范](https://geojson.org)
| MULTI_TEXT | 没有


# 元数据要点 API { #gist_api }
 <!--DHIS2-SECTION-ID:gist_api-->

元数据 Gist API 是一个用于获取和浏览的 RESTful 只读 JSON API
元数据。此 API 中的项目包含元数据 API 中相同项目的要点。

该 API 专门设计用于避免：

* 由于包含部分嵌套对象，响应负载较大
  图表。
* 请求的内存处理需要大量资源
  （例如，在内存过滤或对象图遍历中）。
* _n + 1_ 次数据库查询是渲染时对象图遍历的结果
  响应。

## 与元数据 API 的比较 { #gist_vs_metadata_api }
 <!--DHIS2-SECTION-ID:gist_vs_metadata_api-->

标准元数据 API 是一个灵活而强大的 API，旨在为任何和
每个用例。
这样做的缺点是并非所有功能和组合都可以扩展
在存在大量项目的情况下保持良好的性能。
特别是包含项目的列表，其中每个项目本身都有一个属性，该属性是
大量复杂对象的集合已被证明是有问题的，因为它们很快
引用整个对象图的很大一部分。

添加 `/gist` API 是为了提供元数据 API，其中良好的扩展性是我们的目标
首要任务。这样做的缺点是有更多明显的限制
哪些功能在技术上是合理的，这意味着并非所有功能
Gist API 存在标准元数据 API。

The Gist API uses a divide and conquer strategy to avoid responses with large
partial object graphs. Instead of including nested objects or lists it provides
a `/gist` endpoint URI where this object or list can be viewed in isolation.

**The `/gist` API refers to nested data using URIs rather than including it.**
This means if a client is interested in this nested information more requests
are required but each of them is kept reasonable small and will scale
well in context of huge number of potential items.

已知差异：

* items 仅包含引用的可识别对象的字段（如果这些字段不包含）
  有自己的端点
* 它从不直接包含可识别的对象集合
* 默认情况下，项目不包括所有可用字段，而是取决于的子集
  关于上下文和参数
* lists cannot be used without pager (therefore there is no `pager` parameter)
* fields with collections are not paged using the `pager`-transformer but through
  特定集合属性的分页 API 端点
* 列表中的项目、集合属性大小或布尔转换器结果
  始终考虑对象共享（所考虑的项目的集合始终是集合
  用户可见）
* Gist 提供 `member( <id> )` 和 `not-member( <id> )` 集合字段转换器
* Gist offers `canRead` and `canWrite` access check filter instead of filtering
  on the `access` property
* Gist 提供使用属性 UID 作为字段和过滤器属性名称，以允许
  根据自定义属性值列出或过滤
* Gist 提供过滤器分组

已知限制：

* 默认情况下仅包含持久化的内容；少数特殊的
  可以显式添加非持久字段（合成字段）；其他
  non-persistent fields might be possible to extract using `from` transformation
* 过滤器只能应用于持久化字段
* 订单只能应用于持久化字段
* 令牌过滤器不可用
* 顺序始终区分大小写
* `pluck` 转换器仅限于文本属性
* 包含简单（不可识别）项目集合的字段并不总是
  是否包含在内取决于它们的存储方式

在可能的情况下，应考虑使用 `/gist` API 是更好的方式
获取元数据信息。


## 端点 { #gist_endpoints }
 <!--DHIS2-SECTION-ID:gist_endpoints-->

`/gist` API 有 3 种端点：

* <code>/api/&lt;object-type><b>/gist</b></code>: paged list of all known and visible objects of the type (implicit `auto=S`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;<b>/gist</b></code>: view single object by ID (implicit `auto=L`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;/&lt;field-name&gt;<b>/gist</b></code>: paged list of all known and visible items in the collection of owner object's field (implicit `auto=M`; in case this is a simple field just the field value)

这些端点对应于标准元数据 API 的端点，无需
`/gist` 后缀并与以下共享大多数参数及其选项
那个API。


## 浏览数据{ #gist_browse }
 <!--DHIS2-SECTION-ID:gist_browse-->

Since `/gist` API avoids deeply nested data structures in the response the
details of referenced complex objects or list of objects is instead provided
in form of a URI to the gist endpoint that only returns the complex object or
list of objects. These URIs are provided by the `apiEndpoints` field of an item
which is automatically added to an item when such references exist.
The item property itself might contain a transformation result on the object
or collection such as its size, emptiness, non-emptiness, id(s) or plucked 
property such as its name.

To manually browse data it can be handy to use the `absoluteUrls=true` parameter.
Linkage between parts of the gist can now be followed directly in browsers that
render JSON responses.


## 参数 { #gist_parameters }
 <!--DHIS2-SECTION-ID:gist_parameters-->

`/gist` API 的所有端点都接受相同的参数集。
在端点上下文中没有意义的参数及其选项是
被忽略。


### 总览 { #overview } 
参数按字母顺序排列：

| 范围      | 选项               |  默认     | 描述          |
| -------------- | --------------------- | ------------ | ---------------------|
| `绝对 URL` | `true` or `false`     | `假`      | `true` 在链接中使用相对路径，`false` 在链接中使用绝对 URL |
| `自动`         | `XS`, `S`, `M`, `L`, `XL` | （取决于上下文） | extent of fields selected by `*` field selector |
| `字段`       | （取决于端点） | `*`          | 要包含的字段或预设的逗号分隔列表 |
| `过滤器`       | ` <field> : <operator> ` 或 ` <field> : <operator> : <value> ` |   | 逗号分隔的查询字段过滤器列表（可以多次使用） |
| `headless`     | `true` or `false`     | `假`      | `true` skip wrapping result in a pager (ignores `total`), `false` use a pager wrapper object around the result list |
| `inverse`      | `true` or `false`     | `假`      | `true` 返回列表中**不**的项目，`false` 返回列表中的项目 |
| `语言环境`       |                       | （用户帐户配置的语言） | 翻译语言覆盖 |
| `订单`        | ` <field> ` 或 ` <field> :asc` 或 ` <field> :desc ` | `:asc` | 逗号分隔的查询顺序字段列表（可以多次使用） |
| `页面`         | 1-n                   | 1            | 页码 |
| `页面大小`     | 1-1000                | 50           | 页面上的项目数 |
| `根连接点` | `与`或`或`         | `AND`        | `filter` 的逻辑组合，`AND`= 全部匹配，`OR`= 至少一个匹配 |
| `总计`        | `true` or `false`     | `假`      | `true` 将匹配总数添加到寻呼机，`false` 跳过匹配总数的计数 |
| `翻译`    | `true` or `false`     | `真实`       | `true` translate all translatable properties, `false` skip translation of translatable properties (no effect on synthetic display names) |


### `absoluteUrls` 参数 { #gist_parameters_absoluteUrls }
 <!--DHIS2-SECTION-ID:gist_parameters_absoluteUrls-->

By default, URIs in `apiEndpoints`, `href` and the `pager` `prev` and `next` 
members are relative, starting with `/<object-type>/` path.

可以使用 `absoluteUrls` 参数将 URI 更改为绝对 URL。

For example, `/api/users/rWLrZL8rP3K/gist?fields=id,href` returns:

```json
{
  "id": "rWLrZL8rP3K",
  "href": "/users/rWLrZL8rP3K/gist"
}
```

而 `/api/users/rWLrZL8rP3K/gist?fields=id,href&absoluteUrls=true`
返回：

```json
{
  "id": "rWLrZL8rP3K",
  "href": "http://localhost:8080/api/users/rWLrZL8rP3K/gist?absoluteUrls=true"
}
```

As the example shows the `absoluteUrls` parameter is also forwarded or carried
over to the included URLs so allowing to browse the responses by following the 
provided URLs.


### `auto` 参数 { #the-auto-parameter }
每个端点隐式地设置与匹配的字段范围的默认值
`*` / `:all` 字段选择器：

* `/api/ <object-type> /gist`：暗示 `auto=S`
* `/api/ <object-type> / <object-id> /gist`：暗示 `auto=L`
* `/api/ <object-type> / <object-id> / <field-name> /gist`：暗示`自动=M`

`auto` 参数用于手动覆盖默认值以创建列表项
包括或多或少的字段。此设置再次充当默认值，可以
使用显式转换在每个字段的基础上进一步覆盖。

`auto` 的可能选项有（“T 恤尺寸”）：

* `XS`：仅包含 ID 和文本属性
* `S`：排除复杂（对象）属性，集合仅链接（不计数）
* `M`：复杂的包含作为参考 URL，引用和集合作为计数和参考 URL
* `L`: like `M` but references and collections included as IDs (OBS! unbound in size)
* `XL`：类似于 `L`，但引用和集合包含为 ID 对象：`{ "id": <id> }`

For example, `/api/users/gist` would list items with fields `id`, `surname`, 
`firstName`, `phoneNumber`, `email`, `lastUpdated` whereas 
`/api/users/gist?auto=XS` only lists `id`, `surname`,
`firstName`, `phoneNumber`, `email`. Using `/api/users/gist?auto=L` would also
include `organisationUnits`, `dataViewOrganisationUnits`, 
`teiSearchOrganisationUnits` and `userGroups` each with the list of IDs of the
members in the lists/sets.


### `fields` 参数 { #gist_parameters_fields }
 <!--DHIS2-SECTION-ID:gist_parameters_fields-->

指定每个列表项要包含的字段列表。

Fields are included in the result JSON objects for an item in the provided order.
A preset in the list of fields is expanded to the fields it contains at the 
position in the `fields` list it appears.
Fields within the preset are ordered from simple to complex.

If no `fields` parameter is provided `fields=*` is assumed.
Note that the fields of the `*` preset also depend on the `auto` parameter

要删除字段，请使用`!字段列表中的 <name> ` 或 `- <name> `。
例如，要从用户中删除用户组，请使用：

    /api/users/gist?fields=*,!userGroups

同样的原理也可以用于指定用于
场地。例如，要包含用户的用户组的 ID，请使用：

    /api/users/gist?fields=*,userGroups::ids

The `fields` parameter does allow listing fields of nested objects. 
For example to add `userCredentials` with `id` and `name` of a user use:

    /api/users/gist?fields=*,userCredentials[id,用户名]

这将创建以下形式的项目：

```json
{
  ...
  "userCredentials": {
    "id": "Z9oOHPi3FHB",
    "username": "guest"
  }
}
```

当包含集合的嵌套字段时，嵌套字段必须是文本
财产。

例如，通过以下方式包含用户的`userGroups`的所有`名称`：

    /api/users/gist?fields=*,userGroups[名称]

This lists the `userGroups` as:

```json
{
  "userGroups": {
    "name": [
      "_PROGRAM_Inpatient program",
      "_PROGRAM_TB program",
      "_DATASET_Superuser",
      "_PROGRAM_Superuser",
      "_DATASET_Data entry clerk",
      "_DATASET_M and E Officer"
    ]
  }
}
```
上面的功能与以下内容相同：

    /api/users/gist?fields=*,userGroups::pluck(name)~rename(userGroups.name)

When requesting a single field, like `/api/users/gist?fields=surname` the
response is a (still paged) list of simple values:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50
  },
  "users": [
    "Kamara",
    "Wakiki",
    "Nana",
    "Malai",
    ...
  ]
}
```

当请求具有简单的特定所有者对象的单个字段时
（非收藏）价值，例如
`/api/users/rWLrZL8rP3K/gist?fields=surname` 响应仅包含纯文本
JSON 值：

```json
"Wakiki"
```

有关字段预设的更多详细信息，请参阅[字段](#gist_fields) 部分。

### `filter` 参数 { #gist_parameters_filter }
 <!--DHIS2-SECTION-ID:gist_parameters_filter-->

要过滤返回的项目列表，请添加一个或多个`过滤器`参数。

Multiple filters can either be specified as comma-separated list of a single 
`filter` parameter or as multiple `filter` parameters each with a single filter.

有两种类型的过滤器：

* 一元：` <field> : <operator> `
* 二进制：` <field> : <operator> : <value> `

字段可以是：

* 列出的项目类型的持久字段
* 直接引用对象的持久字段（1:1 关系）
* 属性的 UID

可用的一元运算符有：

| 一元运算符 | 描述                                                 |
| -------- | ----------------------------------------------------------------- |
| `空`   | 字段为_null_（未定义）                                       |
| `!null`  | 字段_not null_（已定义）                                     |
| `empty`  | 字段是_空_集合或字符串                           |
| `！空` | 字段是_非空_集合或字符串                       |

可用的二元运算符有：

| 二元运算符   | 描述                                              |
| ----------------- | -------------------------------------------------------- |
| `eq`              | 字段_等于_值                                     |
| `ieq`             | 字段_等于_值（不区分大小写）                  |
| `!eq`、`neq`、`ne`| field is _not equal_ value                               |
| `lt`              | 字段_小于_值                               |
| `le`、`lte`       | 字段_小于或等于_值                   |
| `gt`              | 字段_大于_值                            |
| `ge`, `gte`       | 字段_大于或等于_值                |
| `在`              | field is a collection and value is an item _contained in_ the collection |
| `!in`             | 字段是一个集合，值是一个_不包含在_集合中的项目 |

如果 `in` 或 `!in` 过滤器的 ` <value> ` 是一个列表，则以以下形式给出
`[value1,value2,...]`，例如：`userGroups:in:[fbfJHSPpUQD,cYeuwXTCPkU]`。

应用于集合字段的任何 `>`、`>=`、`<`、`<=`、`==` 或 `!=` 比较
带有数值的会将集合的大小与该值进行比较，例如
例如：`userGroups:gt:0`。

应用于文本字段的任何 `>`、`>=`、`<`、`<=`、`==` 或 `!=` 比较
带有整数值会将文本长度与该值进行比较，例如
例如：`name:eq:4`（名称长度为 4）。


可用的二进制模式匹配运算符有：

| 二元运算符                   | 描述                              |
| --------------------------------- | ---------------------------------------- |
| `like`, `ilike`                   | 字段 _contains_ ` <value> ` 或字段 _matches_ 模式 ` <value> `（当值中包含通配符 `*` 或 `?` 时） |
| `！喜欢`，`！喜欢`                 | 字段_不包含_ ` <value> `或字段_不匹配_模式` <value> `（当通配符`*`或`?`值） |
| `$like`、`$ilike`、`startsWith`   | 字段 _starts with_ ` <value> `            |
| `!$like`、`!$ilike`、`!startsWith`| 字段_不以_开头` <value> `    |
| `like$`、`ilike$`、`endsWith`     | 字段_结尾为_ ` <value> `              |
| `!like$`、`!ilike$`、`!endsWith`  | 字段_不以_结尾` <value> `      |

The `like` and `!like` operators can be used by either providing a search term
in which case a match is any value where the term occurs anywhere, or they can
be used by providing the search pattern using `*` as _any number of characters_
and `?` as _any single character_.

All pattern matching operators named `like` are case-sensitive. All others 
are case-insensitive. 

请注意，属性值过滤器使用基于文本的比较，这意味着
支持所有文本过滤器。

例如，仅列出第二级组织使用

    /api/organizationUnits/gist?filter=level:eq:2

Similarly, when listing the `children` of a particular organisation unit the
collection can be filtered. To only list those children that are connected to
a program one would use:

    /api/organizationUnits/rZxk3S0qN63/children/gist?filter=程序:gt:0

用于基于访问（共享）的过滤的二元运算符：

| 二元运算符   | 描述                                              |
| ----------------- | -------------------------------------------------------- |
| `可以阅读`         | 拥有用户 ` <value> ` 对象的元数据读取权限 |
| `可以写`        | 拥有用户 ` <value> ` 元数据对对象的写入权限 |
| `可以读取数据`     | 拥有用户 ` <value> ` 对该对象的数据读取权限    |
| `可以数据写入`    | 拥有用户 ` <value> ` 对该对象的数据写入权限   |
| `可以访问`       | 拥有对象的用户 ` <value0> ` 权限 ` <value1> `  |

When the user ID `<value>` is omitted the check is performed for the currently
logged-in user. Similarly, if `<value0>` is ommitted for `canAccess` filter
the check is performed for the currently logged-in user.

When applied to a simple value property, here `code`, the filter restricts the response to
those data elements (owner object) the user can read/write:

    /api/dataElements/gist?filter=code:canWrite:OYLGMiazHtW

When applied to a reference property, here `categoryCombo`, the filter restricts the response 
to those data elements having a category combo that the user can read/write:

    /api/dataElements/gist?filter=categoryCombo:canWrite:OYLGMiazHtW

When applied to a reference collection property, here `dataElementGroups`, the
filter restricts the response to those data elements where a data element group exists in the
collection property and which the user can read/write:

    /api/dataElements/gist?filter=dataElementGroups:canWrite:OYLGMiazHtW

The `canAccess` expects two arguments, 1st is user ID, 2nd the access pattern,
for example to check metadata read and write access the pattern is `rw%`:

    /api/dataElements/gist?filter=code:canAccess:[OYLGMiazHtW,rw%]


此外，过滤器可以分组，以允许将选定的过滤器与
当通用过滤器组合器为逻辑 AND 时为逻辑 OR，反之亦然
当通用组合器为逻辑或时，为逻辑与。

对于组，过滤器模式扩展如下：

* 一元: ` <group> : <field> : <operator> `
* 二进制：` <group> : <field> : <operator> : <value> `

The group is an arbitrary number between `0` and `9` (when omitted `0` is 
assumed). 

The behaviour is best explained with a small example for an imaginary object
type with an `age` and `name` property.

    ?filter=1:age:eq:50&filter=2:name:eq:foo&filter=2:name:eq:bar

The above filter has two groups `1` and `2`, and the `2` group has 2 members.
This is equivalent to the SQL (note the `and` and `or` as well as the 
grouping braces):

    e.age = 50 和 (e.name = 'foo' 或 e.name = 'bar')

现在，如果将相同的`过滤器`与`rootJunction=OR`结合使用

    ?filter=1:age:eq:50&filter=2:name:eq:foo&filter=2:name:eq:bar&rootJunction=OR

其效果相当于以下 SQL：

    e.age = 50 或 (e.name = 'foo' 和 e.name = 'bar')


### `headless` 参数 { #gist_parameters_headless }
 <!--DHIS2-SECTION-ID:gist_parameters_headless-->

默认情况下返回列表的端点用包含以下内容的信封包装项目
`pager` 和列表，根据列出的对象类型命名。

例如 `/api/organizationUnits/gist` 返回：

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50,
    "nextPage": "/organisationUnits/gist?page=2"
  },
  "organisationUnits": [
    ...
  ]
}
```

With `headless=true` the response to `/api/organisationUnits/gist?headless=true` 
is just the `[...]` list part in above example.


### `inverse` 参数 { #the-inverse-parameter }
The `inverse` can be used in context of a collection field gist of the form 
`/api/<object-type>/<object-id>/<field-name>/gist` to not list all items that
are contained in the member collection but all items that are **not** contained
in the member collection.

例如，虽然

    /api/organizationUnits/rZxk3S0qN63/children/gist

将列出作为`rZxk3S0qN63`子级的所有组织单位

    /api/organizationUnits/rZxk3S0qN63/children/gist?inverse=true

would list all organisation units that are not children of `rZxk3S0qN63`. 
This would e.g. be used to compose a list of all units that can be made a child 
of a particular unit.

过滤器和订单通常适用，这意味着它们过滤或排序项目
不包含在成员集合中。


### `locale` 参数 { #gist_parameters_locale }
 <!--DHIS2-SECTION-ID:gist_parameters_locale-->
`locale` 参数通常用于测试临时切换
显示名称的翻译语言。

如果未指定，则翻译语言为用户中配置的语言
帐号设定。

例子：

    /api/organizationUnits/gist?locale=en
    /api/organizationUnits/gist?locale=en_GB

### `order` 参数 { #gist_parameters_order }
 <!--DHIS2-SECTION-ID:gist_parameters_order-->

为了对项目列表进行排序，可以给出一个或多个顺序表达式。

订单表达式要么只是持久化字段的字段名称，要么是一个字段
名称后跟 `:asc` （升序 - 默认）或 `:desc`
（降序排列）。

例如，要按名称字母顺序对组织单位进行排序，请使用：

    /api/organizationUnits/gist?order=名称

逆字母顺序将使用：

    /api/organizationUnits/gist?order=name:desc

要首先按级别排序组织单位，然后按名称排序，请使用：

    /api/organizationUnits/gist?order=级别,名称

这将从级别 1 的根开始。要从叶单元开始，请使用：

    /api/organizationUnits/gist?order=level:desc,名称

如果未指定顺序，结果列表将具有基于的稳定顺序
内部数据组织。


### `page` 参数 { #gist_parameters_page }
 <!--DHIS2-SECTION-ID:gist_parameters_page-->

指在分页列表中查看的页面，以`1`开头的第一页。

如果不存在`page`参数，则等于`page=1`。

The `page` is always in relation to the `pageSize`.
If a `page` is given beyond the number of existing matches an empty item list
is returned.


### `pageSize` 参数 { #gist_parameters_pageSize }
 <!--DHIS2-SECTION-ID:gist_parameters_pageSize-->

指的是`页面`上的项目数。最多 1000 个项目。

如果没有`pageSize`参数，则等于`pageSize=50`。


### `rootJunction` 参数 { #gist_parameters_rootJunction }
 <!--DHIS2-SECTION-ID:gist_parameters_rootJunction-->

`rootJunction` 参数可用于显式设置逻辑结点
在过滤器之间使用。可能的是：

* `AND`: all filters have to match an entry for it to be included in the results
* `OR`: any of the filters matches an entry for it to be included in the results

默认为`与`。


### `total` 参数 { #gist_parameters_total }
 <!--DHIS2-SECTION-ID:gist_parameters_total-->

By default, a gist query will **not** count the total number of matches should 
those exceed the `pageSize` limit. Instead, we opt-in to the additional costs
the total count implicates.

When not counting the total matches (`total=false`) the response `pager` will
assume that there is a `next` page in case `pageSize` items were found. This
could however turn out to be false when browsing to the page. Also, the `total`
field stating the number of total matches is not included in the `pager`.

For example, `/api/organisationUnits/gist` returns a `pager`:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50,
    "nextPage": "/organisationUnits/gist?page=2"
  }
}
```

When counting the total matches (`total=true`) the response `pager` will 
contain the `total` field with the actual number of total matches at the cost
of an additional database operation.

The response to `/api/organisationUnits/gist?total=true` now returns this `pager`:

```json
{
  "pager": {
    "page": 1,
    "pageSize": 50,
    "total": 1332,
    "nextPage": "/organisationUnits/gist?total=true&page=2",
    "pageCount": 27
  }
}
```


### `translate` 参数 { #gist_parameters_translate }
 <!--DHIS2-SECTION-ID:gist_parameters_translate-->

像`name`或`shortName`这样的字段可以被翻译（国际化）。

默认情况下，任何具有翻译的可翻译字段都会返回翻译后的结果
假设请求要点的用户配置了界面语言。

要返回普通的非翻译字段，请使用 `translate=false`。

For example, `/api/organisationUnits/gist` returns items like this:

```json
{
  "name": "A translated name",
  ...
}
```

而 `/api/organizationUnits/gist?translate=false` 将返回如下项目：

```json
{
  "name"
  "Plain field name",
  ...
}
```

Note that synthetic fields `displayName` and `displayShortName` are always
returning the translated value independent of the `translate` parameter.


## 字段{ #gist_fields }
 <!--DHIS2-SECTION-ID:gist_fields-->

The fields included by default (without `fields` parameter) correspond to 
`fields=*`. 
This means the list of fields shown depends on object type, endpoint context as 
well as the `auto` parameter.

Note that the `/gist` API always excludes certain fields that usually are of no 
interest to clients, like for example the `translations` or `sharing` fields. 
These can be added explicitly.

When not explicitly provided by name in the `fields` parameters the list of 
fields is computed from a preset.
A preset can be used in the list of fields like a field name. 
It expands to zero, one or many fields depending on the object type, used 
endpoint and selector.


### 字段预设 { #field-presets }

* `*` / `:all`：默认字段取决于上下文和 `auto` 参数
* `:identific`：`IdentifyingObject` 接口的所有持久化字段
* `:owner`：列出的类型是所有者的所有持久字段
* `:nameable`：`NameableObject` 接口的所有持久字段
* `:persisted`：字面上所有持久化字段


### 场变压器 { #field-transformers }
A transformer or transformation can be applied to a field by appending 
any of the indicators `::`, `~` or `@` followed by the transformer expression.

可用的变压器表达式有：

| 变压器        | JSON 结果类型    | 描述                       |
| ------------------ | ------------------- | --------------------------------- |
| `重命名( <name> )`   | --                   | 将响应中的字段重命名为 ` <name> ` |
| `尺寸`             | `数字`            | 集合字段中的项目数 |
| `是空的`          | `boolean`           | 集合字段为空   |
| `不为空`       | `boolean`           | 集合字段非空 |
| `id`              | `字符串` 或 `[字符串]` | 对象 ID 或集合项 ID |
| `id-对象`       | `[{ "id": <id> }]`  | 作为对象的集合项的 ID |
| `成员（ <id> ）`     | `boolean`           | 具有`<id>`的成员用于集合字段 |
| `非成员( <id> )` | `boolean`           | 集合字段中没有具有`<id>`的成员 |
| `pluck( <field> )`   | `字符串` 或 `[字符串]` | 提取对象或每个集合项的单个文本属性 |
| `来自( <field> ,...)`| 取决于咖啡豆类型 | 从一个或多个持久字段中提取非持久字段 |

A field can receive both the `rename` transformer and one of the other 
transformers, for example:

    /api/organizationUnits/gist?fields=*,children::size~rename(child-count)

The returned items now no longer have a `children` member but a `child-count`
member instead. Note that `rename` also affects the member name of the URI
reference given in `apiEndpoints`.

The `from` transformation can be used with one or more persistent fields as
parameter. These will be loaded from the database, set in an instance of the 
listed element object before the non-persistent property transformed with 
`from` is extracted from that instance by calling the getter. This allows to 
extract derived fields while using the same logic that is used in usual metadata API.

For example, a user's (non-persistent property) `name` is composed of the 
persistent property `firstName` and `surname`. It can be fetched like this:

    /api/users/gist?fields=id,name~from(名字,姓氏)

Since a user's name is such a common case an auto-detection was added so that in
this special case the `from` transformation is added automatically to `name`.
We are allowed to just use the following which internally adds the `from` 
transformation:

    /api/users/gist?fields=id,名称

While this makes non-persistent properties accessible in general these always 
have to be included in the `fields` explicitly. For a user this could be 
done using the following:

    /api/users/gist?fields=*,名称


## 合成字段{ #gist_syntheticFields }
 <!--DHIS2-SECTION-ID:gist_syntheticFields-->

The `/gist` API is tightly coupled to properties that exist the database.
This means properties that aren't stored in the database usually aren't 
available.
The exception to this are the "synthetic" properties which are dynamically 
computed on the basis of one or more database stored properties.

综合属性可用于持久化的所有端点
存在计算合成属性所需的属性。

Except for the `apiEndpoints` property which is automatically added when needed 
all other synthetic properties are not included by default and have to be 
requested explicitly in the list of `fields`.


### 总览 { #overview } 
按字母顺序排列的合成字段：

| 领域              | 描述                                             |
| ------------------ | ------------------------------------------------------- |
| `apiEndpoints`     | 包含浏览嵌套复杂对象或集合的链接 |
| `href`             | 链接到列表项本身（单个项目视图）         |
| `显示名称`      | 已翻译的`名称`（始终已翻译）                   |
| `显示短名称` | translated `shortName` (always translated)              |
| `访问`           | 当前用户读/写/修改条目的能力摘要 |


### `href` 字段 { #gist_syntheticFields_href }
 <!--DHIS2-SECTION-ID:gist_syntheticFields_href-->

`/gist` 响应中的每个项目都可以链接到自身。该链接在
`href` 属性。

要添加 `href` 字段，请使用（例如）：

    /api/ <object-type> /gist?fields=*,href

### `displayName` 和 `displayShortName` 字段 { #gist_syntheticFields_displayName }
 <!--DHIS2-SECTION-ID:gist_syntheticFields_displayName-->

By definition the `displayName` is the translated `name` and the 
`displayShortName` is the translated `shortName`. 

要添加 `displayName` 或 `displayShortName` 将其添加到列表中（例如）：

    /api/ <object-type> /gist?fields=*,displayName
    /api/ <object-type> /gist?fields=*,displayShortName

Note that by default all translatable properties like `name` and `shortName` 
would also be translated. When `translate=false` is used to disable this 
`displayName` and `displayShortName` stay translated.


### `apiEndpoints` 字段 { #gist_syntheticFields_apiEndpoints }
 <!--DHIS2-SECTION-ID:gist_syntheticFields_apiEndpoints-->

This property provides the links to further browse complex objects or list of 
items that are included in the `/gist` response in form of a transformed simple 
value like an item count.

The `apiEndpoints` object will have a member of the same name for every member 
in the item that was transformed to a simple value.

例如，

    /api/users/gist?fields=id,userGroups::size,organizationUnits::size

返回以下形式的项目：

```json
{
  "id": "rWLrZL8rP3K",
  "userGroups": 0,
  "organisationUnits": 1,
  "apiEndpoints": {
    "organisationUnits": "/users/rWLrZL8rP3K/organisationUnits/gist",
    "userGroups": "/users/rWLrZL8rP3K/userGroups/gist"
  }
}
```

The list of `userGroups` and `organisationUnits` are included as their `size`. 
Each has a corresponding member in `apiEndpoints` with the path to browse the 
list.

The paths can be changed to URLs by using the `absoluteUrls` parameter. 

    /api/users/gist?fields=id,userGroups::size,organizationUnits::size&absoluteUrls=true

返回以下形式的项目：

```json
{
  "id": "rWLrZL8rP3K",
  "userGroups": 0,
  "organisationUnits": 1,
  "apiEndpoints": {
    "organisationUnits": "http://{host}/api/users/rWLrZL8rP3K/organisationUnits/gist?absoluteUrls=true",
    "userGroups": "http://{host}/api/users/rWLrZL8rP3K/userGroups/gist?absoluteUrls=true"
  }
}
```

### `access` 字段 { #the-access-field }
The `access` summary is based on the `sharing` and the current user.
This means it is only applicable for objects that have a `sharing` property.

For example, when listing data elements with `access` field

    /api/dataElements/gist?fields=*,访问

返回的数据元素项包含一个`访问`成员，如下所示：

```json
"access": {
  "manage": false,
  "externalize": false,
  "write": false,
  "read": true,
  "update": false,
  "delete": false
}
```

### 属性作为字段 { #gist_attributeFields }
DHIS2 allows creating and adding custom attributes to metadata objects.
Their values are contained in the `attributeValues` property of a metadata 
object in form of a map with the attribute UID as the map's key.

直接列出此映射中的一个或多个特定属性值，就好像它们一样
属性 UID 是元数据对象的常用字段，可以像它一样使用
是一个常见领域的名称。

For example, to include the value of the attribute with UID `Y1LUDU8sWBR` as 
the property `unit-of-measure` in the list use:

    /api/dataElements/gist?fields=id,名称,Y1LUDU8sWBR::重命名（测量单位）

这会产生以下形式的列表项：
```json
{
  "id": "qrur9Dvnyt5",
  "name": "Age in years",
  "unit-of-measure": "years"
}
```

By default, the values are fetched as JSON and extracted from the map of 
attribute values. This means the listing will contain the proper JSON type for
the type of attribute value. This comes at the overhead of fetching all 
attribute values. To single out the value within the database the `PLUCK` 
transformation can be used.

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(测量单位)~pluck

结果看起来是一样的，但现在该值被提取为文本
数据库将任何 JSON 值转换为属性输出中的字符串。

## 例子 { #gist_examples } 
 <!--DHIS2-SECTION-ID:gist_examples-->
一些示例从简单的列表开始，一直到非常具体的用例。

It is preferable to always supply an explicit list of `fields` so this section 
will do so. 

列出具有 ID 和名称的组织单位：

    /api/organizationUnits/gist?fields=id,名称

列出组织单位及其 ID、名称和总数：

    /api/organizationUnits/gist?fields=id,name&total=true

列出用户的 id 和用户名：

    /api/users/gist?fields=id,userCredentials.用户名

列出用户的 ID、用户名和上次登录日期：

    /api/users/gist?fields=id,userCredentials[用户名,lastLogin]

仅列出第二级组织单位及其 ID、名称和级别：

    /api/organizationUnits/gist?fields=id,名称,level&filter=level:eq:2

仅列出拥有 1 个以上子级（其 ID、姓名和名称）的组织单位
儿童人数：

    /api/organizationUnits/gist?fields=id,名称,children::size&filter=children:gt:1

仅列出还不是其他单位子级的组织单位
`zFDYIgyGmXG`:

    /api/organizationUnits/zFDYIgyGmXG/children/gist?fields=id,name&inverse=true

列出用户并标记他们是否是特定用户组的成员
`NTC8GjJ7p8P` 并在响应中将该字段命名为 `is-member`：

    /api/users/gist?fields=id,userCredentials.username,userGroups::member(NTC8GjJ7p8P)~rename(is-member)

在 10 个项目的页面中列出所有用户的链接：

    /api/users/gist?fields=href&absoluteUrls&pageSize=10




# 数据 { #data } 

## 数据值 { #webapi_data_values } 

本节关于发送和读取数据值。

    /api/dataValueSets

### 发送数据值 { #webapi_sending_data_values } 

要发送数据值，您可以向以下资源发出 POST 请求。

```
POST /api/dataValueSets
```

A common use-case for system integration is the need to send a set of
data values from a third-party system into DHIS. In this example, we will
use the DHIS2 demo on `http://play.dhis2.org/demo` as basis. We assume
that we have collected case-based data using a simple software client
running on mobile phones for the *Mortality <5 years* data set in the
community of *Ngelehun CHC* (in *Badjia* chiefdom, *Bo* district) for
the month of January 2014. We have now aggregated our data into a
statistical report and want to send that data to the DHIS2 instance. The
base URL to the demo API is `http://play.dhis2.org/demo/api`. The following
links are relative to the base URL.


最适合我们发送数据的资源
values 是 `/api/dataValueSets` 资源。一个数据值集代表一个
一组具有关系的数据值，通常来自
从相同的数据输入表单中捕获。格式看起来像
这：

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="dataSetID"
  completeDate="date" period="period" orgUnit="orgUnitID" attributeOptionCombo="aocID">
  <dataValue dataElement="dataElementID" 
    categoryOptionCombo="cocID" value="1" comment="comment1"/>
  <dataValue dataElement="dataElementID" 
    categoryOptionCombo="cocID" value="2" comment="comment2"/>
  <dataValue dataElement="dataElementID" 
    categoryOptionCombo="cocID" value="3" comment="comment3"/>
</dataValueSet>
```

JSON支持以下格式：

```json
{
  "dataSet": "dataSetID",
  "completeDate": "date",
  "period": "period",
  "orgUnit": "orgUnitID",
  "attributeOptionCombo": "aocID",
  "dataValues": [
    {
      "dataElement": "dataElementID", 
      "categoryOptionCombo": "cocID", 
      "value": "1", 
      "comment": "comment1"
    },
    {
      "dataElement": "dataElementID", 
      "categoryOptionCombo": "cocID", 
      "value": "2", 
      "comment": "comment2"
    },
    {
      "dataElement": "dataElementID", 
      "categoryOptionCombo": "cocID", 
      "value": "3", 
      "comment": "comment3"
    }
  ]
}
```

CSV支持以下格式：

```csv
“ dataelement”，“ period”，“ orgunit”，“ catoptcombo”，“ attroptcombo”，“ value”，“ strby”，“ lstupd”，“ cmt”
“ dataElementID”，“ period”，“ orgUnitID”，“ cocID”，“ aocID”，“ 1”，“用户名”，“ 2015-04-01”，“ comment1”
“ dataElementID”，“ period”，“ orgUnitID”，“ cocID”，“ aocID”，“ 2”，“用户名”，“ 2015-04-01”，“ comment2”
“ dataElementID”，“ period”，“ orgUnitID”，“ cocID”，“ aocID”，“ 3”，“用户名”，“ 2015-04-01”，“ comment3”
```

> **注意**
>
>有关时间格式，请参阅上面的日期和期间部分。

从这个例子中，我们可以看出我们需要识别周期，
数据集、组织单位（设施）和数据元素
报告。

To obtain the identifier for the data set we make a request to the
`/api/dataSets` resource. From there we find and follow the link to 
the *Mortality < 5 years* data set which leads us to `/api/dataSets/pBOMPrpg1QX`. 
The resource representation for the *Mortality < 5 years* data set conveniently
advertises links to the data elements which are members of it. From here
we can follow these links and obtain the identifiers of the data
elements. For brevity we will only report on three data elements:
*Measles* with id `f7n9E0hX8qk`, *Dysentery* with id `Ix2HsbDMLea` and
*Cholera* with id `eY5ehpbEsB7`.

剩下的就是掌握组织的标识符
单元。 *dataSet* 表示方便地提供了到组织的链接
报告它的单位，所以我们搜索 *Ngelehun CHC* 并按照
链接到 `/api/organisationUnits/DiszpKrYNg8` 中的 HTML 表示，其中
告诉我们这个组织单位的标识符是`DiszpKrYNg8`。

根据我们基于病例的数据，我们假设我们有 12 例麻疹病例，14
痢疾16例，霍乱16例。我们现在已经聚集了足够的
能够将 XML 数据值集放在一起的信息
信息：

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-02-03" period="201401" orgUnit="DiszpKrYNg8">
  <dataValue dataElement="f7n9E0hX8qk" value="12"/>
  <dataValue dataElement="Ix2HsbDMLea" value="14"/>
  <dataValue dataElement="eY5ehpbEsB7" value="16"/>
</dataValueSet>
```

JSON格式：

```json
{
  "dataSet": "pBOMPrpg1QX",
  "completeDate": "2014-02-03",
  "period": "201401",
  "orgUnit": "DiszpKrYNg8",
  "dataValues": [
    {
      "dataElement": "f7n9E0hX8qk", 
      "value": "1"
    },
    {
      "dataElement": "Ix2HsbDMLea", 
      "value": "2"
    },
    {
      "dataElement": "eY5ehpbEsB7", 
      "value": "3"
    }
  ]
}
```

To perform functional testing we will use the _curl_ tool which provides
an easy way of transferring data using HTTP. First, we save the data
value set XML content in a file called `datavalueset.xml`. From the
directory where this file resides we invoke the following from the
command line:

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

要发送 JSON 内容，您必须设置 content-type 标头
因此：

```bash
curl -d @datavalueset.json "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/json" -u admin:district
```

该命令将向演示 Web API 发送请求，设置
`application/xml` 作为内容类型并使用
`admin`/`district` 作为用户名/密码。如果一切顺利，这将返回一个
`200 OK` HTTP 状态代码。您可以验证数据是否已
通过在 DHIS2 中打开数据输入模块并选择组织来接收
本例中使用的单位、数据集和期间。

The API follows normal semantics for error handling and HTTP status
codes. If you supply an invalid username or password, `401 Unauthorized`
is returned. If you supply a content-type other than `application/xml`,
`415 Unsupported Media Type` is returned. If the XML content is invalid
according to the DXF namespace, `400 Bad Request` is returned. If you
provide an invalid identifier in the XML content, `409 Conflict` is
returned together with a descriptive message.

### 发送大量数据值 { #webapi_sending_bulks_data_values } 

前面的例子向我们展示了如何发送一组相关的数据值
共享同一时期和组织单位。这个例子将向我们展示
如何发送大量不一定是的数据值
逻辑相关。

我们将再次与`/api/dataValueSets` 资源交互。这次我们
不会指定 `dataSet` 和 `completeDate` 属性。此外，我们将
在单个数据值上指定 `period` 和 `orgUnit` 属性
元素而不是外部数据值集元素。这会
使我们能够发送不同时期和组织单位的数据值：

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0">
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201401" orgUnit="DiszpKrYNg8" value="12"/>
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201401" orgUnit="FNnj3jKGS7i" value="14"/>
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201402" orgUnit="DiszpKrYNg8" value="16"/>
  <dataValue dataElement="f7n9E0hX8qk" 
    period="201402" orgUnit="Jkhdsf8sdf4" value="18"/>
</dataValueSet>
```

JSON格式：

```json
{
  "dataValues": [
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201401", 
      "orgUnit": "DiszpKrYNg8", 
      "value": "12"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201401", 
      "orgUnit": "FNnj3jKGS7i", 
      "value": "14"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201402", 
      "orgUnit": "DiszpKrYNg8", 
      "value": "16"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "period": "201402", 
      "orgUnit": "Jkhdsf8sdf4", 
      "value": "18"
    }
  ]
}
```

CSV格式：

```csv
“ dataelement”，“ period”，“ orgunit”，“ categoryoptioncombo”，“ attributeoptioncombo”，“ value”
“ f7n9E0hX8qk”，“ 201401”，“ DiszpKrYNg8”，“ bRowv6yZOF2”，“ bRowv6yZOF2”，“ 1”
“ Ix2HsbDMLea”，“ 201401”，“ DiszpKrYNg8”，“ bRowv6yZOF2”，“ bRowv6yZOF2”，“ 2”
“ eY5ehpbEsB7”，“ 201401”，“ DiszpKrYNg8”，“ bRowv6yZOF2”，“ bRowv6yZOF2”，“ 3”
```

我们通过使用curl以XML格式发送数据值进行测试：

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

请注意，使用 CSV 格式时，您必须使用二进制数据选项
保留 CSV 文件中的换行符：

```bash
curl --data-binary @datavalueset.csv "https://play.dhis2.org/demo/24/api/dataValueSets"
  -H "Content-Type:application/csv" -u admin:district
```

数据值集资源提供有用的 XML 响应
当您想验证您的请求所产生的影响时。我们第一次
发送上面的数据值设置请求，服务器将响应
以下导入摘要：

```xml
<importSummary>
  <dataValueCount imported="2" updated="1" ignored="1"/>
  <dataSetComplete>false</dataSetComplete>
</importSummary>
```

此消息告诉我们导入了 3 个数据值，1 个数据值是
在忽略零数据值时更新。单一更新来自
我们在上一个示例中发送该数据值的结果。一个数据
如果引用不存在的数据元素，值将被忽略，
期间、组织单位或数据集。在我们的例子中，这个被忽略的值是
由对组织单位的无效引用的最后一个数据值引起。
数据集完整元素将显示数据的日期
值集已完成，如果没有数据元素属性，则为 false
提供。

### 导入参数 { #webapi_data_values_import_parameters } 

可以使用一组导入参数来自定义导入过程：

表：导入参数

| 范围 | 值（默认优先） | 描述 |
|---|---|---|
| 数据元素标识方案 | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的数据元素对象的属性。 |
| 组织单位 ID 方案 | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的组织单位对象的属性。 |
| attributeOptionComboIdScheme | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的属性选项组合对象的属性。 |
| 类别选项组合 ID 方案 | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的类别选项组合对象的属性。 |
| 数据集IdScheme | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的数据集对象的属性。 |
| 类别IdScheme | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的类别对象的属性（仅限 ADX）。 |
| 类别选项Id方案 | uid &#124;名字&#124;代码&#124;属性：ID | 用于映射数据值的类别选项对象的属性（仅限 ADX）。 |
| 方案 | uid &#124;名字&#124;代码&#124;属性：ID | 上述任何对象的属性（如果未指定）用于映射数据值。 |
| 预热缓存 | 假的&#124;真的 | 指示是否在开始导入数据值之前预加载元数据缓存，将加速具有高元数据基数的大型导入有效负载。 |
| 干运行 | 假的&#124;真的 | 是否在服务器上保存更改或仅返回导入摘要。 |
| 导入策略 | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | 在服务器上保存所有对象、新对象或更新导入状态。 |
| 跳过现有检查 | 假的&#124;真的 | 跳过对现有数据值的检查。提高性能。仅用于空数据库或要导入的数据值尚不存在时。 |
| 跳过审计 | 假的&#124;真的 | 跳过审核，意味着不会生成审核值。以审计变更的能力为代价来提高性能。需要权限“F_SKIP_DATA_IMPORT_AUDIT”。 |
| 异步 | 假的&#124;真的 | 指示导入应该异步还是同步完成。前者适用于非常大的导入，因为它确保请求不会超时，尽管它具有显着的性能开销。后者速度更快，但需要持续连接直到该过程完成。 |
| 力量 | 假的&#124;真的 | 指示是否应强制导入。数据导入可能会因数据集锁定的各种原因而被拒绝，例如由于批准、数据输入期限、到期日等。为了覆盖此类锁定并强制数据输入，可以使用force=true 的数据导入。然而，必须是\*超级用户\*才能使该参数起作用。 |
| 数据集 | uid | 提供用于 CSV 导入的数据集 ID（文件本身无法提供 ID） |

所有参数都是可选的，可以作为查询参数提供
请求 URL 是这样的：

    /api/dataValueSets?dataElementIdScheme=代码&orgUnitIdScheme=名称
      &dryRun=true&importStrategy=创建

它们也可以作为数据值集上的 XML 属性提供
元素如下。 XML 属性将覆盖查询字符串
参数。

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataElementIdScheme="code"
  orgUnitIdScheme="name" dryRun="true" importStrategy="CREATE">
</dataValueSet>
```

请注意，`preheatCache` 参数会对
表现。对于小的导入文件，将其设置为 false 会很快。
对于包含大量不同数据的大型导入文件
元素和组织单位，将其设置为 true 将是
幅度更快。

#### 数据值要求 { #webapi_data_values_import_requirement } 

数据值导入支持一组值类型。对于每个值类型，
有一个特殊要求。下表列出了边缘情况
对于值类型。



表：值类型要求

| 值类型 | 要求 | 评论 |
|---|---|---|
| 布尔值 | 真实的&#124;真实的&#124;真实&#124;假的&#124;假的&#124;假的&#124; 1 &#124; 0 &#124; t &#124; f&#124; | 当值为布尔值、true 或 false 值时使用。导入服务不关心输入是否以大写字母或小写字母开头，或者是否全部大写。 |

#### 标识符方案 { #webapi_data_values_identifier_schemes } 

Regarding the id schemes, by default the identifiers used in the XML
messages use the DHIS2 stable object identifiers referred to as `UID`.
In certain interoperability situations we might experience that an external
system decides the identifiers of the objects. In that case we can use
the `code` property of the organisation units and other objects to set
fixed identifiers. When importing data values we hence need to reference
the code property instead of the identifier property of these metadata
objects. Identifier schemes can be specified in the XML message as well
as in the request as query parameters. To specify it in the XML payload
you can do this:

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0"
  dataElementIdScheme="CODE" orgUnitIdScheme="UID" idScheme="CODE">
</dataValueSet>
```

上面的参数表解释了如何指定 id 方案
作为查询参数。以下规则适用于
优先级：

  - XML 或 JSON 负载中定义的 ID 方案优先于
    id 方案定义为 URL 查询参数。

  - 特定的 id 方案，例如 dataElementIdScheme 或
    orgUnitIdScheme 优先于一般 idScheme。

  - If no explicit id scheme is defined, the default id scheme is `code`
    for ADX format, and `uid` for all other formats.

以下标识符方案可用。

  - uid

  - 码

  - 名称

  - 属性（后跟属性的UID）

属性选项是特殊的，指的是元数据属性
已被标记为*独特*。使用此选项时，`attribute` 必须
紧随其后的是属性的标识符，例如
“属性：DnrLSdo4hMl”。

#### 异步数据值导入 { #webapi_data_values_async_import } 

可以通过以下方式以异步方式发送和导入数据值
提供设置为 *true* 的 `async` 查询参数：

    /api/dataValueSets?async=true

这将启动一个异步导入作业，您可以对其进行监控
任务摘要 API 中的状态。 API 响应表明
作业的唯一标识符、作业类型和可用于的 URL
监控导入作业状态。响应将类似于以下内容：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Initiated dataValueImport",
  "response": {
    "name": "dataValueImport",
    "id": "YR1UxOUXmzT",
    "created": "2018-08-20T14:17:28.429",
    "jobType": "DATAVALUE_IMPORT",
    "relativeNotifierEndpoint": "/api/system/tasks/DATAVALUE_IMPORT/YR1UxOUXmzT"
  }
}
```

请阅读有关*异步任务状态*的部分了解更多信息
信息。

### CSV数据值格式 { #webapi_data_values_csv } 

以下部分描述了 DHIS2 中使用的 CSV 格式。首先
行被假定为标题行，在导入期间将被忽略。



表：DHIS2 的 CSV 格式

||||
|---|---|---|
| 柱 | 需要 | 描述 |
| 数据元素 | 是的 | 默认为ID，也可以根据选择的ID方案为名称和代码 |
| 期 | 是的 | ISO 格式 |
| 组织单位 | 是的 | 默认为ID，也可以根据选择的ID方案为名称和代码 |
| 类别选项组合 | 不 | 参考身份证号 |
| 属性选项组合 | 不 | 指ID（从2.16版本开始） |
| 值 | 不 | 资料值 |
| 存储者 | 不 | 指输入该值的用户的用户名 |
| 最近更新时间 | 不 | ISO 格式的日期 |
| 评论 | 不 | 自由文字评论 |
| 跟进 | 不 | 对或错 |

可以导入DHIS2的CSV文件示例如下所示。

```csv
“ dataelement”，“ period”，“ orgunit”，“ catoptcombo”，“ attroptcombo”，“ value”，“ storedby”，“ timestamp”
“ DUSpd8Jq3M7”，“ 201202”，“ gP6hn503KUX”，“ Prlt0C1RF0s”，“ 7”，“ bombali”，“ 2010-04-17”
“ DUSpd8Jq3M7”，“ 201202”，“ gP6hn503KUX”，“ V6L425pT3A0”，“ 10”，“ bombali”，“ 2010-04-17”
“ DUSpd8Jq3M7”，“ 201202”，“ OjTS752GbZE”，“ V6L425pT3A0”，“ 9”，“孟买”，“ 2010-04-06”
```

### 生成数据值集模板 { #webapi_data_values_template } 

要为特定数据集生成数据值集模板，您可以使用
`/api/dataSets/ <id> /dataValueSet` 资源。 XML 和 JSON 响应
支持格式。例子：

    /api/dataSets/BfMAe6Itzgt/dataValueSet

描述了可用于进一步调整输出的参数
以下：



表：数据值查询参数

| 查询参数 | 需要 | 描述 |
|---|---|---|
| 时期 | 不 | 使用期限，将被包括在内，无需任何检查。 |
| orgUnit | 不 | 使用的组织单元，支持多个orgUnit，id和code都可以使用。 |
| 评论 | 不 | 如果包含注释，默认：是。 |
| 组织单位 ID 方案 | 不 | 使用的组织单位方案，支持 id &#124;代码。 |
| 数据元素标识方案 | 不 | 使用的数据元素方案，支持 id &#124;代码。 |

### 读取数据值 { #webapi_reading_data_values } 

要读取数据值，您可以向以下资源发出 GET 请求。

```
GET /api/dataValueSets
```

Data values can be retrieved in *XML*, *JSON*, *CSV*, and *ADX* format. Since we want to read data we will use the *GET* HTTP verb. We will also specify that we are
interested in the XML resource representation by including an `Accept` HTTP header with our request. The following query parameters are
accepted:


表：数据值设置查询参数

| 范围 | 描述 |
|---|---|
| 数据集 | 数据集标识符。可以重复任意次数。 |
| 数据元素组 | 数据元素组标识符。可以重复任意次数（ADX 不支持）。 |
| 数据元素 | 数据元素标识符。可以重复任意次数。 |
| 时期 | ISO 格式的周期标识符。可以重复任意次数。 |
| 开始日期 | 要导出的值的时间跨度的开始日期。 |
| 结束日期 | 要导出的值的时间跨度的结束日期。 |
| orgUnit | 组织单位标识符。可以重复任意次数。 |
| 孩子们 | 是否将子级包含在组织单位的层次结构中。 |
| 组织单位组 | 组织单位组标识符。可以重复任意次数。 |
| 属性选项组合 | 属性选项组合标识符。可以重复任意次数。 |
| 包含已删除 | 是否包含已删除的数据值。 |
| 最近更新时间 | 仅包括自给定时间戳以来更新的数据值。 |
| 最后更新持续时间 | 仅包括在给定持续时间内更新的数据值。格式为 <value\> <time-unit\> ，其中支持的时间单位为“d”（天）、“h”（小时）、 “m”（分钟）和“s”（秒）。 |
| 限制 | 响应中的最大结果数。 |
| 数据元素标识方案 | 用于响应数据值的数据元素对象的属性。 |
| 组织单位 ID 方案 | 用于响应数据值的组织单位对象的属性。 |
| 类别选项组合 ID 方案 | 用于响应数据值的类别选项组合的属性。 |
| attributeOptionComboIdScheme | 用于响应数据值的属性选项组合对象的属性。 |
| 数据集IdScheme | 要在响应中使用的数据集对象的属性。 |
| 类别IdScheme | 要在响应中使用的类别对象的属性（仅限 ADX）。 |
| 类别选项Id方案 | 要在响应中使用的类别选项对象的属性（仅限 ADX）。 |
| 方案 | 上述任何对象的属性（如果未指定）将在响应中使用。如果未指定，则 ADX 的默认 idScheme 是 code，所有其他格式的默认 idScheme 是 uid。 |
| 输入组织单位 ID 方案 | 用于提供的`orgUnit`参数值的标识属性； `id` 或 `code` |
| 输入数据集Id方案 | 用于提供的`dataSet`参数值的标识属性； `id` 或 `code` |
| 输入数据元素组Id方案 | 用于提供的`dataElementGroup`参数值的标识属性； `id` 或 `code` |
| 输入数据元素Id方案 | 用于提供的`dataElement`参数值的标识属性； `id` 或 `code` |
| 输入IdScheme | Identification property used for any of the provided `dataSet`, `dataElementGroup`, `orgUnit`, `orgUnitGroup`, `attributeOptionCombo`  parameter values unless any of the three schemes above explicitly overrides this input default; `id` or `code` |

需要上面列表中的以下参数：
- dataSet 或 dataElementGroup（对于 ADX，这必须是 dataSet）
- 任一时间段、startDate 和 endDate、lastUpdated 或 lastUpdatedDuration
- orgUnit 或 orgUnitGroup

支持以下响应格式：

  - xml（应用程序/ xml）

  - json（应用程序/ json）

  - csv（应用程序/ csv）

  - adx（应用程序/ adx + xml）

假设我们已经根据
上一节称为 *发送数据值* 我们现在可以放在一起
我们对单个数据值集的请求并使用 cURL 请求它：

```bash
curl "https://play.dhis2.org/demo/api/dataValueSets?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8"
  -H "Accept:application/xml" -u admin:district
```

我们还可以使用开始和结束日期查询参数来请求一个
大量的数据值。 IE。您还可以请求数据值
多个数据集和组织单位以及一个时间跨度以便导出
更大的数据块。请注意，期间查询参数采用
优先于开始和结束日期参数。一个例子看起来像
这：

```bash
curl "https://play.dhis2.org/demo/api/dataValueSets?dataSet=pBOMPrpg1QX&dataSet=BfMAe6Itzgt
  &startDate=2013-01-01&endDate=2013-01-31&orgUnit=YuQRtpLP10I&orgUnit=vWbkYPRmKyS&children=true"
  -H "Accept:application/xml" -u admin:district
```

检索已创建或更新的数据值
过去 10 天，您可以提出这样的请求：

    / api / dataValueSets？dataSet = pBOMPrpg1QX＆orgUnit = DiszpKrYNg8＆lastUpdatedDuration = 10d

响应将如下所示：

```xml
<?xml version='1.0' encoding='UTF-8'?>
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-01-02" period="201401" orgUnit="DiszpKrYNg8">
<dataValue dataElement="eY5ehpbEsB7" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10003"/>
<dataValue dataElement="Ix2HsbDMLea" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10002"/>
<dataValue dataElement="f7n9E0hX8qk" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10001"/>
</dataValueSet>
```

您可以使用JSON格式请求数据，如下所示：

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8

响应如下所示：

```json
{
  "dataSet": "pBOMPrpg1QX",
  "completeDate": "2014-02-03",
  "period": "201401",
  "orgUnit": "DiszpKrYNg8",
  "dataValues": [
    {
      "dataElement": "eY5ehpbEsB7", 
      "categoryOptionCombo": "bRowv6yZOF2", 
      "period": "201401",
      "orgUnit": "DiszpKrYNg8", 
      "value": "10003"
    }, 
    {
      "dataElement": "Ix2HsbDMLea", 
      "categoryOptionCombo": "bRowv6yZOF2", 
      "period": "201401",
      "orgUnit": "DiszpKrYNg8", 
      "value": "10002"
    }, 
    {
      "dataElement": "f7n9E0hX8qk", 
      "categoryOptionCombo": "bRowv6yZOF2", 
      "period": "201401",
      "orgUnit": "DiszpKrYNg8", 
      "value": "10001"
    }
  ]
}
```

请注意，数据值是软删除的，即删除的值具有
`deleted` 属性设置为 true 而不是被永久删除。
这在集成多个系统以进行通信时很有用
删除。您可以在响应中包含已删除的值，如下所示：

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8&includeDeleted=true

您还可以请求CSV格式的数据，如下所示：

    /api/dataValueSets.csv?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8

响应将如下所示：

```csv
数据元素，期限，组织单位，catoptcombo，attroptcombo，值，存储于，最后更新，注释，开始
f7n9E0hX8qk，201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,12，system，2015-04-05T19：58：12.000，comment1，false
Ix2HsbDMLea，201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,14，system，2015-04-05T19：58：12.000，comment2，false
eY5ehpbEsB7,201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,16，系统，2015-04-05T19：58：12.000，comment3，false
FTRrcoaog83,201401，DiszpKrYNg8，bRowv6yZOF2，bRowv6yZOF2,12，系统，2014-03-02T21：45：05.519，comment4，false
```

以下约束适用于数据值集资源：

  - 必须至少指定一个数据集。

  - 必须是至少一个期间或开始日期和结束日期
    指定的。

  - 必须至少指定一个组织单位。

  - 组织单位必须在组织的层次结构内
    认证用户的单位。

  - 限制不能小于零。

### 发送，读取和删除单个数据值 { #webapi_sending_individual_data_values } 

此示例将显示如何发送要保存的单个数据值
一个要求。这可以通过发送一个 *POST* 请求到
`dataValues` 资源：

    POST /api/dataValues

此资源支持以下查询参数：

表：数据值查询参数

| 查询参数 | 需要 | 描述 |
|---|---|---|
| 德 | 是的 | 数据元素标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | 组织单位标识符 |
| 共 | 不 | 类别选项组合标识符，如果省略则使用默认值 |
| 抄送 | 否（必须与 cp 结合使用） | 属性类别组合标识符 |
| CP | 否（必须与 cc 结合使用） | 属性类别选项标识符，用 ; 分隔对于多个值 |
| ds | 不 | 数据集，检查期间和组织单位是否允许 POST 或 DELETE。如果指定，则必须将数据元素分配给该数据集。如果没有指定，将选择包含该数据元素的数据集来检查该操作是否被允许。 |
| 价值 | 不 | 数据价值。对于布尔值，将接受以下内容： true &#124;真实的&#124;真实&#124;假的&#124;假的&#124;假的&#124; 1 &#124; 0 &#124; t &#124; f&#124; |
| 评论 | 不 | 数据评论 |
| 跟进 | 不 | 跟踪数据值，将切换当前布尔值 |

如果给定的任何标识符无效，如果数据值或
评论无效或如果数据被锁定，响应将包含
*409 Conflict* 状态代码和描述性文本消息。如果
操作导致保存或更新的值，*200 OK* 将被返回。
请求的示例如下所示：

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s&value=12"
  -X POST -u admin:district
```

此资源还允许使用特殊语法将值关联到
一个属性选项组合。这可以通过发送
属性类别组合的标识符，连同标识符
值代表的属性类别选项
组合。类别组合由 `cc` 参数指定，而
类别选项被指定为分号分隔的字符串，带有`cp`
范围。有必要确保类别选项都是部分
的类别组合。一个示例如下所示：

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu&ou=DiszpKrYNg8
  &pe=201308&cc=dzjKKQq0cSO&cp=wbrDrL2aYEc;btOyqprQ9e8&value=26"
  -X POST -u admin:district
```

您可以使用 *GET* 方法通过请求检索数据值。这
value、comment 和 followUp 参数在这方面不适用：

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s"
  -u admin:district
```

您可以使用 *DELETE* 方法通过请求删除数据值。

### 将单个数据值作为负载发送 { #webapi_sending_individual_data_values_as_payload }

You can send individual data values as a JSON payload using the following resource using `Content-Type: application/json`.

```
POST /api/dataValues
```

资源将创建新的数据值或更新数据值（如果已存在）。 JSON 负载格式定义如下。

```json
{
  "dataElement": "fbfJHSPpUQD",
  "categoryOptionCombo": "PT59n8BQbqM",
  "period": "202201",
  "orgUnit": "DiszpKrYNg8",
  "value": "10",
  "comment": "OK"
}
```

端点支持在嵌套结构中指定属性选项组合。

```json
{
  "dataElement": "BOSZApCrBni",
  "categoryOptionCombo": "TkDhg29x18A",
  "attribute": {
    "combo": "O4VaNks6tta",
    "options": [
      "C6nZpLKjEJr", "i4Nbp8S2G6A"
    ]
  },
  "dataSet": "lyLU2wR22tC",
  "period": "202201",
  "orgUnit": "DiszpKrYNg8",
  "value": "15",
  "comment": "Good"
}
```

如果数据值已成功保存或更新，则状态代码将为`201 Created`，如果存在验证错误，则状态代码将为`409 Conflict`。

### 处理文件数据值 { #datavalue_file } 

处理具有 *file* 类型数据元素的数据值时
与上述方法存在一些偏差。这些数据
值的特殊之处在于值的内容是一个 UID 引用
到 *FileResource* 对象而不是自包含常量。这些
数据值的行为就像其他存储文本的数据值一样
内容，但应以不同方式处理以产生
有意义的输入和输出。

有两种存储文件资源数据值的方法。

* 将文件上传到 `/api/dataValues/file` 端点，如下所示
  文件资源部分中描述。这适用于 2.36 及更高版本。

* 如果您正在编写需要兼容的代码
  对于 2.36 之前的 DHIS2 版本，则流程为：

1.  如所述将文件上传到 `/api/fileResources` 端点
    在文件资源部分。

2.  Retrieve the `id` property of the returned file resource.

3.  Store the retrieved identifier using the `value` property of the data value using any
    上面描述的方法。

数据值和文件资源之间只有一对一的关系
允许。这是在内部强制执行的，以便保存文件资源 ID
在多个数据值中是不允许的，并且会返回错误。删除
数据值将删除引用的文件资源。直接删除
的文件资源是不可能的。

数据值现在可以作为除返回数据以外的任何其他值进行检索
将是文件资源的 UID。为了检索实际
内容（意味着存储在映射的文件资源中的文件
到数据值）必须向 `/api/dataValues/files` 发出 GET 请求
镜像查询参数，因为它们将用于数据值
本身。 `/api/dataValues/files` 端点仅支持 GET 请求。

值得注意的是，由于底层存储机制工作
异步文件内容可能不会立即准备好
从`/api/dataValues/files` 端点下载。这是特别真实的
对于可能需要耗时上传的大文件
外部文件存储的背景（取决于系统
配置）。从文件资源元数据中检索
`/api/fileResources/ <id> ` 端点允许检查 `storageStatus`
在尝试下载内容之前。

## ADX数据格式 { #webapi_adx_data_format } 

从 2.20 版本开始，我们加入了对国际标准的支持
用于称为 ADX 的聚合数据交换。 ADX 的开发和维护
由 IHE 质量研究和公共卫生委员会
（整合医疗保健企业）。详细介绍 QRPH 的 wiki 页面
活动可以在以下位置找到
[wiki.ihe.net](http://wiki.ihe.net/index.php?title=Quality,_Research_and_Public_Health#Current_Domain_Activities)。
ADX 仍在积极开发中，现已发布
试行实施。请注意 DHIS2 当前实施的内容
是读取和写入 ADX 格式数据的功能，即什么是
在 ADX 中被描述为内容消费者和内容生产者参与者
轮廓。

ADX 数据消息的结构与您可能的结构非常相似
从前面描述的 DXF 2 数据中已经熟悉了。有一个
几个重要的区别。我们将描述这些差异
参考一个小例子：

```xml
<adx xmlns="urn:ihe:qrph:adx:2015" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="urn:ihe:qrph:adx:2015 ../schema/adx_loose.xsd" 
  exported="2015-02-08T19:30:00Z">
  <group orgUnit="OU_559" period="2015-06-01/P1M" 
    completeDate="2015-07-01" dataSet="(TB/HIV)VCCT">
    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
  </group>
</adx>
```

### ADX 根元素 { #the-adx-root-element }

ADX 根元素只有一个强制属性，即
*导出*时间戳。与其他 ADX 元素一样，该架构是
可扩展，因为它不限制其他特定于应用程序的
属性。

### ADX 组元素 { #the-adx-group-element }

与 dxf2 不同，ADX 要求数据值根据以下条件进行分组
orgUnit、期间和数据集。上面的例子显示了一个数据报告
来自在线演示数据库的“(TB/HIV) VCCT”数据集。这个例子
使用代码作为标识符而不是 dhis2 uids。代码是
使用 ADX 时的首选标识符形式。

orgUnit、period 和 dataSet 属性在 ADX 中是必需的。这
group 元素可以包含附加属性。在我们的 DHIS2 中
实现任何附加属性都简单地传递给
底层进口商。这意味着当前的所有属性
在dxf2中有意义（如上例中的completeDate）可以
继续在 ADX 中使用，它们将以相同的方式进行处理。

ADX 和 dxf2 之间的显着差异在于周期的方式
被编码。 ADX严格使用ISO8601并对报告进行编码
周期为（日期|日期时间）/（持续时间）。所以上面例子中的句点
是从 2015 年 6 月 1 日开始的 1 个月 (P1M) 期间。所以就是数据
2015 年 6 月。符号有点冗长，但它非常
灵活，使我们能够支持 DHIS2 中所有现有的期间类型

### ADX期间定义 { #adx-period-definitions } 

期间从持续时间开始的日期开始，然后是
“/”，然后是表中注明的持续时间符号。这
下表详细介绍了所有 DHIS2 周期类型及其含义
以 ADX 形式表示，并附有示例。

表：ADX 周期

| 期间类型 | 持续时间符号 | 例子） | 持续时间 |
|---|---|---|---|
| 日常 | P1D | 2017-10-01/P1M | 2017 年 10 月 1 日 |
| 每周 | P7D | 2017-10-02/P7D | 2017年10月2日-2017年10月8日 |
| 每周周三 | P7D | 2017-10-04/P7D | 2017年10月4日-2017年10月10日 |
| 每周周四 | P7D | 2017-10-05/P7D | 2017年10月5日-2017年10月11日 |
| 每周周六 | P7D | 2017-10-07/P7D | 2017年10月7日-2017年10月13日 |
| 每周日 | P7D | 2017-10-01/P7D | 2017年10月1日-2017年10月7日 |
| 每两周一次 | P14D | 2017-10-02/P14D | 2017年10月2日-2017年10月15日 |
| 每月 | P1M | 2017-10-01/P1M | 2017年10月1日-2017年10月31日 |
| 双月刊 | 点对点 | 2017-11-01/P2M | 2017年11月1日-2017年12月31日 |
| 季刊 | P3M | 2017-09-01/P3M | 2017年9月1日-2017年12月31日 |
| 六个月一期 | P6M | 2017-01-01/P6M <br> 2017-07-01/P6M | 2017年1月1日-2017年6月30日 <br> 2017年7月1日-2017年12月31日 |
| 四月六个月 | P6M | 2017-04-01/P6M <br> 2017-10-01/P6M | 2017年4月1日-2017年9月30日 <br> 2017年10月1日-2018年3月31日 |
| 11月每六个月一次 | P6M | 2017-10-01/P6M <br> 2018-05-01/P6M | 2017年11月1日-2018年4月30日 <br> 2018年5月1日-2018年10月31日 |
| 每年 | P1Y | 2017-01-01/P1Y | 2017年1月1日-2017年12月31日 |
| 财经四月 | P1Y | 2017-04-01/P1Y | 2017年4月1日-2018年3月31日 |
| 七月财经 | P1Y | 2017-07-01/P1Y | 2017年7月1日-2018年6月30日 |
| 财经十月 | P1Y | 2017-10-01/P1Y | 2017年10月1日-2018年9月30日 |
| 十一月财务 | P1Y | 2017-11-01/P1Y | 2017年11月1日-2018年10月31日 |

### ADX 数据值 { #adx-data-values }

ADX 中的 dataValue 元素与其在 DXF 中的等效元素非常相似。
强制属性是*dataElement* 和*value*。 *orgUnit* 和
*period* 属性不会出现在 dataValue 中，因为它们是必需的
在*组*级别。

The most significant difference is the way that disaggregation is
represented. DXF uses the categoryOptionCombo to indicate the disaggregation
of data. In ADX the disaggregations (e.g. AGE_GROUP and SEX) are
expressed explicitly as attributes. If you use `code` as the id scheme for
`category`, not that you must assign a code to all the categories used for
dataElements in the dataSet, and further, that code must be of a form
which is suitable for use as an XML attribute. The exact constraint on
an XML attribute name is described in the W3C XML standard - in practice,
this means no spaces, no non-alphanumeric characters other than '_' and
it may not start with a letter. The example above shows examples of
'good' category codes ('GENDER' and 'HIV_AGE'). The same restrictions
apply if you use `name` or `attribute` as id schemes.

在ADX中，仅使用类别标识符作为XML属性；身份标识
对于其他元数据类型，不必用作 XML 属性。
请注意，当您分配时，DHIS2 不强制执行此语法
名称、代码或 DHIS2 属性，但您会收到信息性错误
如果您尝试导入 ADX 数据且类别标识符为
要么没有分配，要么不适合。

使用分解数据的显式维度的主要好处是
那

  - 生成数据的系统不必与
    DHIS2 中的 categoryOptionCombo。

  - 生产者和消费者可以将他们的代码与第三方进行匹配
    权威来源，例如 vterminology 服务。请注意，在
    上面的性别和年龄组代码示例使用的是代码列表
    来自[世卫组织全球卫生观察站](http://apps.who.int/gho/data/node.resources.api)。

请注意，此功能可能非常有用，例如当
从 EMR 系统生成分类数据，但可能存在以下情况
其中 *categoryOptionCombo* 映射更容易或更理想。这
ADX 的 DHIS2 实现将检查是否存在
*categoryOptionCombo* 属性，如果存在，它将在
优先选择分解维度属性。同样，一个
*group* 元素上的 *attributeOptionCombo* 属性将是
以传统方式处理。否则，attributeOptionCombo 可以是
正如 *dataValue* 上一样，被视为分解类别。

在上面的简单示例中，数据集中的每个数据元素
具有相同的维度（类别组合），因此数据整齐
矩形的。情况不一定如此。数据集可能包含
具有不同类别组合的数据元素，导致
*ragged-right* ADX 数据消息（即不同数据元素的值
可能有不同数量的类别。）

### 导入 ADX 数据{ #importing-adx-data }

DHIS2 exposes an endpoint for POST ADX data at `/api/dataValueSets`
using *application/xml+adx* as content type. So, for example, the
following curl command can be used to POST the example data above to the
DHIS2 demo server:

```bash
curl -u admin:district -X POST -H "Content-Type: application/adx+xml"
  -d @data.xml "https://play.dhis2.org/demo/api/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=code"
```

请注意，查询参数与 DXF 数据使用的参数相同。这
ADX 端点应使用以下命令解释所有现有 DXF 参数
与 DXF 的语义相同。

### 导出 ADX 数据{ #exporting-adx-data }

DHIS2 exposes an endpoint to GET ADX data sets at `/api/dataValueSets`
using *application/xml+adx* as the accepted content type. So, for
example, the following curl command can be used to retrieve the ADX
data:

```bash
curl -u admin:district -H "Accept: application/adx+xml"
 "https://play.dhis2.org/demo/api/dataValueSets?dataValueSets?orgUnit=M_CLINIC&dataSet=MALARIA&period=201501"
```

请注意，查询参数与 DXF 数据使用的参数相同。一个
重要的区别是 dataSet 和 orgUnit 的标识符可以
可以是 uid 或代码。

## 后续行动 { #webapi_follow_up } 

本节介绍了后续的标记数据。

### 数据值跟踪 { #data-value-follow-up } 

数据值跟踪端点允许标记数据值以进行跟踪。

```
PUT / api / 36 / dataValues /跟进
```

The payload in `JSON` format looks like this:

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "categoryOptionCombo": "psbwp3CQEhs",
  "attributeOptionCombo": "HllvX50cXC0",
  "followup": true
}
```

The `categoryOptionCombo` and `attributeOptionCombo` fields are optional. A minimal `JSON` payload looks like this:

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "followup": false
}
```

The `followup` field should be set to `true` to mark a data value for follow-up, and `false` to remove the mark.

如果操作成功，响应状态代码将为`200 OK`，如果请求出错，则响应状态代码为`409 Conflict`。

批量更新数据值以供后续使用：

    PUT /api/dataValues/followups

with `JSON` payload:

```json
{
  "values": [
    {
      "dataElement": "s46m5MS0hxu",
      "period": "202005",
      "orgUnit": "DiszpKrYNg8",
      "categoryOptionCombo": "psbwp3CQEhs",
      "attributeOptionCombo": "HllvX50cXC0",
      "followup": true
    }
  ]
}
```

批量更新的每个项目与单个项目具有相同的字段和要求
更新端点。

Bulk update equally confirms with a `200 OK` on success or returns a 
`409 Conflict` in case of input errors.



# 数据验证 { #data-validation } 

## 验证方式 { #webapi_validation } 

要生成数据验证摘要，您可以与
验证资源。数据集资源针对数据输入进行了优化
用于验证数据集/表单的客户端，可以像这样访问：

    获取 /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

除了基于数据集验证规则外，还有两种
执行验证的其他方法：自定义验证和
预定验证。

第一个路径变量是引用数据集的标识符
证实。支持 XML 和 JSON 资源表示。这
响应包含违反验证规则。这将延长
在即将到来的版本中有更多的验证类型。

要检索与特定数据集相关的验证规则，
意思是所有数据元素都是一部分的带有公式的验证规则
的特定数据集，您可以向
`validationRules` 资源如下：

    GET /api/validationRules?dataSet= <dataset-id>

验证规则有左边和右边，也就是
根据运营商比较有效性。有效的运算符
值见下表。



表：运算符

| 值 | 描述 |
|---|---|
| equal_to | 等于 |
| not_equal_to | 不等于 |
| greater_than | 比...更棒 |
| greater_than_or_equal_to | 大于或等于 |
| less_than | 少于 |
| less_than_or_equal_to | 小于或等于 |
| compulsory_pair | 如果任何一方在场，另一方也必须在场 |
| exclusive_pair | 如果任何一方在场，则另一方不得在场 |

左边和右边的表达式是数学表达式
其中可以包含对数据元素和类别选项的引用
以下格式的组合：

    $ {<dataelement-id>。 <catoptcombo-id>}

左侧和右侧表达式有一个 *missing 值
战略*。这是指系统应该如何处理数据值
缺少数据元素/类别选项组合引用
在公式中是否应该检查验证规则
为有效性或跳过。有效的缺失值策略见于
下表。



表：缺失值策略

| 值 | 描述 |
|---|---|
| SKIP_IF_ANY_VALUE_MISSING | 如果缺少任何数据值，则跳过验证规则 |
| SKIP_IF_ALL_VALUES_MISSING | 如果所有数据值均缺失，则跳过验证规则 |
| 从不_跳过 | 无论缺少数据值，都不要跳过验证规则 |

## 验证结果{ #webapi_validation_results }

验证结果是在执行期间发现的违规的持久结果
验证分析。如果您在开始时选择“持久结果”或
安排验证分析，发现的任何违规将存储在
数据库。当结果存储在数据库中时，它将被使用
对于 3 件事：

1.  根据存储的结果生成分析。

2.  未生成通知的持久结果将这样做，
    一次。

3.  跟踪结果是否产生了
    通知。

4.  跳过运行时已经检查过的规则
    验证分析。

这意味着如果你不坚持你的结果，你将无法
为验证结果生成分析，如果选中，结果将
每次找到并运行验证时生成通知
分析可能会更慢。

### 查询验证结果{ #query-validation-results }

持久化的验证结果可以在下面查看
端点：

    获取 /api/33/validationResults

您还可以使用验证结果 ID 检查单个结果
在这个端点：

    GET /api/33/validationResults/ <id>

验证结果也可以通过以下属性过滤：

* 组织单位：`ou = <UID>`
* 验证规则：`vr = <UID>`
* 期间：`pe = <ISO-expression>`

上面的每个过滤器属性可以多次出现，例如：

    获取 /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

同一过滤器的多个值与OR组合，结果必须匹配给定值之一。

如果使用了一个以上的过滤器属性，则将它们与AND组合在一起，结果必须与每个属性的值之一匹配。

对于时段过滤器，匹配结果必须与任何指定的时段重叠。

此外，验证结果还可以按其创建日期进行过滤：

    GET /api/36/validationResults?createdDate= <date>

该过滤器可以与其他任何过滤器结合使用。

### 触发验证结果通知{ #trigger-validation-result-notifications }

验证结果每天发送给适当的用户一次，
但也可以使用以下命令手动触发以按需运行
API端点：

    POST / api / 33 / validation / sendNotifications

使用此端点仅发送未发送的结果。

### 删除验证结果{ #delete-validation-results }

验证结果可以通过ID手动删除，

    删除/ api / 36 / validationResults / <id>

或使用过滤器

    删除/ api / 36 / validationResults？ <filters>

支持的过滤器参数包括：

* `ou = <UID>`以匹配组织单位的所有验证结果；提供多个参数时，多个单元组合或
* `vr = <UID>`以匹配验证规则的所有验证结果；提供多个参数时，多个规则组合或
* `pe = <ISO-expression>`以匹配与与指定时期重叠的时期相关的所有验证结果
* `created = <ISO-expression>`以匹配在规定时间内创建的所有验证结果
* `notificationSent= <boolean> ` 仅匹配已发送或未发送通知的验证结果

如果组合了过滤器，则所有条件都必须为真（AND逻辑）。

一些例子：

要删除 2020 年第一季度与 UID 为`NqwvaQC1ni4`的组织单位相关的所有验证结果，请使用：

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

要删除在2019年第1周创建的且已发送通知的所有验证结果，请使用：

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

任何删除操作都需要_执行维护任务_权限。


## 离群值检测 { #outlier-detection } 

异常值检测端点允许检测聚合数据值中的异常值。

```
GET / api / 36 / outlierDetection
```

该端点支持两种用于检测离群值的算法：

* ** Z分数：** Z分数定义为分数与平均值之间的绝对偏差除以标准偏差。必须使用z分数算法指定一个阈值参数，该阈值参数表示与平均值之间的标准偏差，以定义异常值的上限和下限。
* **修改后的 Z 分数：** 与 z 分数相同，只是它使用中位数而不是均值作为集中趋势的度量。参数与 Z 分数相同。
* ** Min-max：** Min-max数据元素值是指可以根据数据元素，组织单位和类别选项组合插入DHIS 2的自定义边界。

离群值将*根据显着性*排序，默认情况下是与均值的绝对偏差，最高有效值在前。这有助于快速识别对数据质量和数据分析影响最大的离群值。

### 请求查询参数 { #request-query-parameters } 

支持以下查询参数。

| 查询参数 | 描述                                                  | 强制的 | 选项（默认为默认）                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | 数据集，可以多次指定。                   | 不 [*]    | 数据集标识符。                      |
| 德              | 数据元素，可以多次指定。               | 不 [*]    | 数据元素标识符。                  |
| 开始日期       | 间隔的开始日期，以检查异常值。               | 是的       | 日期（yyyy-MM-dd）。                        |
| 结束日期         | 检查异常值的时间间隔的结束日期。                 | 是的       | 日期（yyyy-MM-dd）。                        |
| 欧              | 组织单位，可以多次指定。          | 是的       | 组织单位标识符。             |
| 算法       | 用于离群值检测的算法。                      | 不        | `Z_SCORE`、`MIN_MAX`、`MOD_Z_SCORE`       |
| 临界点       | Threshold for outlier values. `Z_SCORE` and `MOD_Z_SCORE` algorithm only. | 不        | 数值，大于零。默认值：3.0。 |
| 数据开始日期   | Start date for interval for mean and std dev calculation. `Z_SCORE` and `MOD_Z_SCORE` algorithm only. | 不        | 日期（yyyy-MM-dd）。 |
| 数据结束日期     | End date for interval for mean and std dev calculation. `Z_SCORE` and `MOD_Z_SCORE` algorithm only. | 不        | 日期（yyyy-MM-dd）。   |
| 订购         | Field to order by. `Z_SCORE` and `MOD_Z_SCORE`algorithm only.| 不        | `MEAN_ABS_DEV`，`Z_SCORE`                 |
| 最大结果      | 输出的最大限制。                                    | 不        | 整数，大于零。默认值：500。 |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.

必须定义至少一个数据集或数据元素，开始日期和结束日期以及至少一个组织单位。

The `startDate` and `endDate` parameters are mandatory and refer to the time interval for which you want to detect outliers. The `dataStartDate` and `dataEndDate` parameters are optional and refer to the time interval for the data to use when calculating the mean and std dev, which are used to eventually calculate the z-score.

### 用法和示例 { #usage-and-examples }

使用默认的z分数算法获取异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆ou = fdc6uOvgoji＆startDate = 2020-01-01＆endDate = 2020-12-31
```

使用特定算法和特定阈值获取异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆algorithm = Z_SCORE＆threshold = 2.5
```

获取按z分数排序的异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆orderBy = Z_SCORE
```

获取前10个离群值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆maxResults = 10
```

获取具有定义间隔的离群值，以供在计算均值和标准差开发数据时使用的数据：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆dataStartDate = 2018-01-01＆dataEndDate = 2020-12-31
```

使用最小-最大算法获取离群值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆ou = fdc6uOvgoji＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆algorithm = MIN_MAX
```

### 回应格式 { #response-format } 

支持以下响应格式。

| 格式 | API格式                                                   |
| ------ | ------------------------------------------------------------ |
| JSON格式   | `/ api / 36 / outlierDetection.json`或`Accept：application / json`（默认格式） |
| CSV    | `/ api / 36 / outlierDetection.csv`或`接受：application / csv`  |

响应包含以下字段：

| 领域      | 描述                                                  |
| ---------- | ------------------------------------------------------------ |
| 德         | 数据元素标识符。                                     |
| 取消命名     | 数据元素名称。                                           |
| 聚乙烯         | 期间ISO标识符。                                       |
| 欧         | 组织单位标识符。                                |
| 组织名称     | 组织单位名称。                                      |
| 可可        | 类别选项组合标识符。                      |
| coc名称    | 类别选项组合名称。                            |
| 冠捷        | 属性选项组合标识符。                     |
| aoc名称    | 属性选项组合名称。                           |
| 价值      | 数据值。                                                  |
| 意思是       | 时间维度中数据值的平均值。                   |
| 标准差     | 标准偏差。                                          |
| 绝对值     | 对于z得分，与均值的绝对偏差。对于最小-最大，与最小或最大边界的绝对偏差。 |
| 分数     | Z分数。仅Z分数算法。                         |
| 下界 | 下边界。                                          |
| 上限 | 上限。                                          |
| 跟进   | 数据值是否标记为后续。                  |

The `mean`, `stdDev` and `zScore` fields are only present when `algorithm` is `Z_SCORE`.

响应将与此类似。 `元数据`部分包含请求和响应的元数据。 `outlierValues` 部分包含异常值。

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### 约束与验证 { #constraints-and-validation } 

在查询验证期间，以下约束适用。每个验证错误都有一个对应的错误代码。

| 错误代码 | 信息                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | 必须至少指定一个数据元素                  |
| E2201      | 必须指定开始日期和结束日期                    |
| E2202      | 开始日期必须早于结束日期                           |
| E2203      | 必须至少指定一个组织单位             |
| E2204      | 阈值必须为正数                          |
| E2205      | 最高结果必须为正数                        |
| E2206      | 最大结果超出了允许的最大限制：{d}               |
| E2207      | 数据开始日期必须早于数据结束日期                 |
| E2208      | 离群值检测期间遇到的非数字数据值 |

## 数据分析 { #webapi_data_analysis } 

用于执行数据分析和查找数据质量的多种资源
并提供验证问题。

**注意：**不建议使用此端点，该端点将在2.38中删除。请改用`outlierAnalysis`端点。

### 验证规则分析 { #webapi_data_analysis_validation_rules } 

要运行验证规则并检索违规：

    GET /api/dataAnalysis/validationRules

支持以下查询参数：



表：验证规则分析查询参数

| 查询参数 | 描述 | 选项 |
|---|---|---|
| 弗格 | 验证规则组 | ID |
| 欧 | 组织单位 | ID |
| 开始日期 | 时间跨度的开始日期 | 日期 |
| 结束日期 | 时间跨度的结束日期 | 日期 |
| 坚持 | 是否将违规行为保留在系统中 | 假的&#124;真的 |
| 通知 | 是否发送违规通知 | 假的&#124;真的 |

样本输出：
```json
    [{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### 基于标准差的离群分析 { #webapi_data_analysis_std_dev_outlier } 

根据平均值的标准偏差识别数据异常值
价值：

    GET /api/dataAnalysis/stdDevOutlier

支持以下查询参数：



表：标准差异常值分析查询参数

| 查询参数 | 描述 | 选项 |
|---|---|---|
| 欧 | 组织单位 | ID |
| 开始日期 | 时间跨度的开始日期 | 日期 |
| 结束日期 | 时间跨度的结束日期 | 日期 |
| ds | 数据组、参数可重复 | ID |
| 标准差 | 与平均值的标准差数 | 数值 |

### 基于最小值/最大值的离群值分析 { #webapi_data_analysis_min_max_outlier } 

要基于最小/最大值来识别数据离群值：

    GET /api/dataAnalysis/minMaxOutlier

支持的查询参数等于基于 *std dev 的异常值
上面描述的分析*资源。

### 后续数据分析 { #follow-up-data-analysis } 

要识别标记为后续的数据：

    GET /api/dataAnalysis/followup

必须定义至少一个数据集或数据元素、开始日期和结束日期或期间，以及至少一个组织单位。

支持以下查询参数。

| 范围  | 描述                                                  | 强制的 | 选项（默认为默认）                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| 欧         | 组织单位，可以多次指定。          | 是的       | 组织单位标识符。             |
| ds         | 数据集，可以多次指定。                   | 不 [*]    | 数据集标识符。                      |
| 德         | 数据元素，可以多次指定。               | 不 [*]    | 数据元素标识符。                  |
| 开始日期  | 间隔的开始日期，以检查异常值。               | 不 [*]    | 日期（yyyy-MM-dd）。                        |
| 结束日期    | 检查异常值的时间间隔的结束日期。                 | 不 [*]    | 日期（yyyy-MM-dd）。                        |
| 聚乙烯         | ISO 周期 ID。                                               | 不 [*]    | 周期 ISO ID。                        |
| pe类型     | ISO 时期。                                                  | 不 [*]    | 句点 ISO 字符串。                        |
| 可可        | 类别选项组合，可以指定多次。     | 不        | 类别选项组合标识符。         |
| 最大结果 | 输出的最大限制。                                    | 不        | 整数，大于零。默认值：50。  |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.
     Equally, either `startDate` and `endDate` _or_ `period` must be specified.

The `startDate` and `endDate` parameters refer to the time interval for which you want to detect outliers.
If a period `pe` is provided instead the interval start and end is that of the period.

如果未提供选项组合`coc`，则考虑所有数值类型的数据元素。


## 数据的完整性 { #webapi_data_integrity } 

数据管理模块的数据完整性功能是
可通过 Web API 获取。本节介绍如何运行
数据完整性处理并检索结果。具体的
用户手册中描述了有关每项检查的详细信息。

### 列出可用的数据完整性检查{ #webapi_data_integrity_list }
可用检查的描述由以下请求返回：

    获取 /api/dataIntegrity

```
[
    {
        "name": "data_elements_without_groups",
        "displayName": "Data elements lacking groups",
        "section": "Data Elements",
        "severity": "WARNING",
        "description": "Lists all data elements that have no data element groups",
        "issuesIdType": "dataElements",
        "isSlow": false
    }
]
```

The `name` member of the returned check elements is the identifier used for the
`checks` parameter to declare the set of checks to run.

> **Note**
> 
> Each check will indicate whether it may require significant time and resources to complete with the `isSlow` field. 
> Users should be cautious about running these
> checks on production systems as they could lead to decreased performance. 
> These checks can be run individually, but will 
> not be run unless specifically requested.

Checks are grouped semantically by the `section` member and categorised in 
one of four `severity` levels:

| 严重性 | 描述                                                                                                                   |
| -------- |-------------------------------------------------------------------------------------------------------------------------------|
| 信息     | 表明这仅供参考。                                                                                  |
| 警告  | 警告表明这可能是一个问题，但不一定是错误。不过，建议对这些问题进行分类。 |
| 严重   | 应该修复但不一定会导致系统无法运行的错误。                               |
| 批判的 | 必须修复的错误，该错误可能会导致最终用户错误或系统崩溃。                                           |

The available checks can be filtered using the `checks` parameter.

    GET /api/dataIntegrity?checks= <pattern1> , <pattern2>

One or more exact names or patterns using `*` as a wildcard can be provided.

Additional results can be filtered using a `section` parameter.

    GET /api/dataIntegrity?section=类别

The `section` filter will return all exact matches which have the specified section. 

### 运行数据完整性摘要{ #webapi_data_integrity_run_summary }

从版本 2.38 开始，数据完整性检查有两个级别的特异性：
- a `summary` level that provides an overview of the number of issues
- a `details` level that provides a list of issues pointing to individual data integrity violations.

要触发一组检查运行的摘要分析：

    POST /api/dataIntegrity/summary?checks= <name1> , <name2>

这会触发异步运行检查的作业。个别检查结果
检查完成后将立即返回到应用程序缓存。

或者，检查列表也可以作为 POST 请求的正文给出。
如果列表变得太长而无法在 URL 中使用，这会很有用。

要获取触发检查的数据完整性摘要，请使用：

    GET /api/dataIntegrity/summary?checks= <name1> , <name2>

When the `checks` parameter is omitted, all checks are fetched from the server cache.

响应是检查结果的“地图”，每一项都对应已完成的检查。
此信息将缓存一小时或直到重新运行检查为止。

To wait for the summary to be available in the cache a `timeout` in milliseconds can be added:

    GET /api/dataIntegrity/summary?checks= <name1> , <name2> &timeout=500

摘要响应的示例可能如下所示：
```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 12,
    "percentage": 2.3
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 4,
    "percentage": 5.1
  }
}
```

Each summary response will contain the `name`, `section`, `severity`, 
`description` and optionally  an `introduction` and `recommendation`.  
Each summary contains the number of issues found in the `count` field. When possible,
an optional `percentage` field will provide the percentage of objects with data
integrity issues when compared to all objects of the same type.
The `startTime` field indicates when the check was initiated. Using the `finishedTime`
the duration which was required to execute the check can be calculated.

Should a check analysis fail due to programming error or unforeseen data inconsistencies
both the summary and the details will have an `error` field describing the error that occurred.
The `count` of any checks which failed will be set to -1. 
No `percentage` will be returned in such cases.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "error": "what has happened",
    "issues": []
  }
}
```

> **注意**
>
> 每个元数据检查都在服务器上异步运行。结果
> 每次检查完成后将立即返回。最安全的方式来保证
> 您已检索到最新一组结果
> requests 是比较发出请求时的时间戳
> 响应中包含 `finishedTime`。

获取当前正在执行的检查的名称列表
服务器使用：

    获取 /api/dataIntegrity/summary/running

要获取已提供结果的检查名称列表，请使用：

    获取 /api/dataIntegrity/summary/completed


### 运行数据完整性详细信息 { #webapi_data_integrity_run_details }

To run a selection of details checks first trigger them using a  `POST` request:

    POST /api/dataIntegrity/details?checks= <name1> , <name2>

与摘要类似，检查列表也可以作为 POST 正文给出。

然后使用以下命令从缓存中获取结果：

    GET /api/dataIntegrity/details?checks= <name1> , <name2> &timeout=500

When the `checks` parameter is not provided,  all checks which 
have not been marked as `isSlow` will be scheduled to be run on the server.

Omitting the `timeout` will not wait for results to be found in the cache, 
but instead not have a result for the requested check.

The `/details` response returns a map similar to the `summary`, but does not contain
a `count` or `percentage`. Instead, a list of `issues` is returned.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": [{
      "id": "<id-or-other-identifier>",
      "name": "<name-of-the-id-obj>",
      "comment": "optional plain text description or hint of the issue",
      "refs": ["<id1>", "<id2>"]
    }]
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": []
  }
}
```
Each issue will always have `id` and `name` members.  Often the `issuesIdType`
is available to indicate the type of objects the `id` refers to. If the 
`issuesIdType` is not available, the `id` often is not available either and the
`name` is used for an aggregate key of an issue that has no object equivalent.

The `comment` and `refs` fields are optional for each issue.
A `comment` may provide more context or
insight into why this particular issue is regarded to be a data integrity problem. 
The `refs` list may also give the identifiers of other objects that contributed to the violation.
The `finishedTime` field shows when the particular check finished processing on the server.
The cache will store the result of each completed check for one hour.

> **Tip**
>
> A set of checks can also be specified using wild-cards. To include all 
> checks with _element_ in the name use `checks=*element*`. Like full names 
> such patterns can be used in a comma-separated list and be mixed with full 
> names as well. Duplicates will be eliminated. 
> Also a check can be given by its code. A code consists of the first letters
> of each word in the name as upper case letter. 
> For example, `orgunits_invalid_geometry` has the code `OIG`.

与摘要类似，一组当前执行的名称和
可以使用以下方式获取已完成的详细信息检查：

    GET /api/dataIntegrity/详细信息/正在运行
    GET /api/dataIntegrity/详细信息/已完成


## 完整的数据集注册 { #webapi_complete_data_set_registrations } 

本节是关于数据集的完整数据集注册。一种
注册标记作为完全捕获的数据集。

### 完成数据集 { #webapi_completing_data_sets } 

本节说明如何将数据集注册为完整。这是
通过与 *completeDataSetRegistrations* 交互实现
资源：

    获取 /api/33/completeDataSetRegistrations

端点支持*POST*方法注册数据集
完成。端点在功能上非常类似于
*dataValueSets* 端点，支持批量导入完整
注册。

支持导入 *XML* 和 *JSON* 格式的有效负载。这
这个有效负载的基本格式，在这个例子中以 *XML* 给出，就像
所以：

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP" 
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP" 
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

*storedBy* 属性是可选的（因为它是
完整的注册对象）。您还可以选择设置
*date* 属性（注册时间）作为属性。是时候了
未设置，将使用当前时间。

导入过程支持以下查询参数：



表：完整数据集注册查询参数

| 范围 | 价值观 | 描述 |
|---|---|---|
| 数据集IdScheme | 身份证号名字&#124;代码&#124;属性：ID | 用于映射完整注册的数据集的属性。 |
| 组织单位 ID 方案 | 身份证号名字&#124;代码&#124;属性：ID | 用于映射完整注册的组织单位的属性。 |
| attributeOptionComboIdScheme | 身份证号名字&#124;代码&#124;属性：ID | 用于映射完整注册的属性选项组合的属性。 |
| 方案 | 身份证号名字&#124;代码&#124;属性：ID | 所有对象的属性，包括数据集、组织单位和属性选项组合，用于映射完整的注册。 |
| 预热缓存 | 假的&#124;真的 | 是否在服务器上保存更改或仅返回导入摘要。 |
| 干运行 | 假的&#124;真的 | 子单位是否适用登记 |
| 导入策略 | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | 在服务器上保存所有对象、新对象或更新导入状态。 |
| 跳过现有检查 | 假的&#124;真的 | 跳过对现有完整注册的检查。提高性能。仅用于空数据库或要导入的注册尚不存在时使用。 |
| 异步 | 假的&#124;真的 | 指示导入应该异步还是同步完成。前者适用于非常大的导入，因为它确保请求不会超时，尽管它具有显着的性能开销。后者速度更快，但需要持续连接直到该过程完成。 |

`idScheme`、`dataSetIdScheme`、`orgUnitIdScheme`、`attributeOptionComboIdScheme`、
`dryRun` 和 `strategy` （注意参数 `importStrategy` 的不同命名）
也可以设置为有效负载的一部分。
对于 XML，这些是属性，对于 JSON，这些是成员
`completeDataSetRegistrations` 节点。

例如：
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

如果 URL 参数和有效负载都设置了方案，则有效负载优先。

### 读取完整的数据集注册 { #webapi_reading_complete_data_sets } 

本节说明如何检索数据集完整性
注册。我们将使用 *completeDataSetRegistrations*
资源。要使用的查询参数如下：



表：数据值设置查询参数

| 范围 | 描述 |
|---|---|
| 数据集 | 数据集标识符，允许多个数据集 |
| 时期 | ISO 格式的周期标识符。允许多个句点。 |
| 开始日期 | 要导出的值的时间跨度的开始日期 |
| 结束日期 | 要导出的值的时间跨度的结束日期 |
| 已创建 | 仅包含自给定时间戳以来创建的注册 |
| 创建持续时间 | 仅包括在给定持续时间内创建的注册。格式为 <value\> <time-unit\> ，其中支持的时间单位为 "d", "h", "m", "s " *(天、小时、分钟、秒)。*时间单位是相对于当前时间的。 |
| orgUnit | 组织单位标识符，可以指定多次。如果给出 orgUnitGroup，则不适用。 |
| 组织单位组 | 组织单位组标识符，可以指定多次。如果给出 orgUnit，则不适用。 |
| 孩子们 | 是否将子级包含在组织单位的层次结构中 |
| 限制 | 响应中包含的最大注册数。 |
| 方案 | 用于响应中元数据对象的标识符属性。 |
| 数据集IdScheme | 用于响应中数据集的标识符属性。覆盖 idScheme。 |
| 组织单位 ID 方案 | 用于响应中组织单位的标识符属性。覆盖 idScheme。 |
| attributeOptionComboIdScheme | 用于响应中属性选项组合的标识符属性。覆盖 idScheme。 |
The `dataSet` and `orgUnit` parameters can be repeated in order to include multiple data sets and organisation units.

`period`、`startDate`、`endDate`、`created` 和 `createdDuration` 参数提供了多种方式来设置请求的时间维度，因此只需
可以使用一个。例如，同时设置开始/结束日期和时间段是没有意义的。

请求示例如下所示：

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX&dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

您可以获得 *xml* 和 *json* 格式的响应。你可以指出
通过 *Accept* HTTP 标头，您更喜欢哪种响应格式
在上面的例子中。对于 xml，您使用 *application/xml*；对于 json 你
使用*应用程序/json*。

### 未完成的数据集 { #webapi_uncompleting_data_sets } 

本节说明如何取消注册数据的完整性
放。要取消完成数据集，您将与
completeDataSetRegistrations 资源：

    获取 /api/33/completeDataSetRegistrations

此资源支持*DELETE* 取消注册。以下查询
支持参数：



表：完整数据集注册查询参数

| 查询参数 | 需要 | 描述 |
|---|---|---|
| ds | 是的 | 数据集标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | 组织单位标识符 |
| 抄送 | 否（必须与 cp 结合） | 属性组合标识符（用于锁定检查） |
| CP | 否（必须与 cp 结合） | 属性选项标识符，用 ; 分隔对于多个值（用于锁定检查） |
| 多欧 | 否（默认 false） | 子单位是否适用登记 |



# 数据审批 { #data-approval } 

## 数据审批 { #webapi_data_approval } 

本节说明如何批准、取消批准和检查批准
使用 *dataApprovals* 资源的状态。批准是按数据完成的
审批工作流、期间、组织单位和属性选项组合。

    /api/33/dataApprovals

数据批准工作流与多个实体相关联：

* 定义批准频率的期间类型
* 可选类别组合
* 工作流程中的一个或多个数据批准级别
* 一个或多个用于数据收集的数据集

### 获取批准状态 { #webapi_data_approval_get_status } 

要获取数据集的批准信息，您可以发出GET请求：

    / api / dataApprovals？wf = rIUL3hYOjJc＆pe = 201801＆ou = YuQRtpLP10I



表：数据审批查询参数

| 查询参数 | 需要 | 描述 |
|---|---|---|
| 工作组 | 是的 | 数据批准工作流标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | 组织单位标识符 |
| 冠捷 | 不 | 属性选项组合标识符 |

> **注意**
>
> 为了向后兼容，在此和其他数据批准请求中，可能会为数据集提供参数`ds`而不是`wf`，如下所述。如果给出了数据集，则将使用与该数据集关联的工作流。

这将产生类似于以下的响应：

```json
{
  "mayApprove": false,
  "mayUnapprove": false,
  "mayAccept": false,
  "mayUnaccept": false,
  "state": "APPROVED_HERE",
  "approvedBy": "User A",
  "approvedAt": "2022-01-13T12:56:07.005",
  "acceptedBy": "User A",
  "acceptedAt": "2022-01-13T12:56:07.005"
}
```

返回的参数是：

表：数据审批返回参数

| 返回参数 | 描述 |
|---|---|
| 可能批准        | 当前用户是否可以批准此数据选择。 |
| 可能不批准      | 当前用户是否可以不批准此数据选择。 |
| 可以接受         | 当前用户是否可以接受该数据选择。 |
| 可能不接受       | 当前用户是否可以不接受该数据选择。 |
| 州             | 其中一项数据批准情况如下表所示。 |
| 由...批准        | 如果选择被批准，并且如果存在（并不总是需要），则为进行此批准的用户的名称。 |
| 批准时间        | 如果选择获得批准，并且如果存在（并不总是需要），则创建最高级别批准的日期和时间。 |
| 被接受        | 如果选择被批准，并且如果存在（并不总是需要），则为上次更新的用户名。 |
| 接受于        | 如果选择获得批准，并且如果存在（并不总是需要），则上次更新最高级别批准的日期和时间。 |


表：数据批准状态

| 状态 | 描述 |
|---|---|
| 不可批准 | 数据批准不适用于此选择。 （数据既未获得批准，也未获得批准。） |
| 未批准_等待 | 此选择的数据可以得到批准，但在准备批准之前正在等待一些较低级别的批准。 |
| 未批准_其他地方 | 数据未批准，正在其他地方等待批准（此处未批准。） |
| 未批准_准备就绪 | 数据尚未批准，并准备好批准此选择。 |
| 已批准_此处 | 数据已获得批准，并且已在此处获得批准（因此可能在此未获得批准。） |
| APPROVED_ELSEWHERE | 数据已获得批准，但未在此处获得批准（因此无法在此处取消批准。）这包括以下情况：<br> * 数据在更高级别获得批准。 <br> * 数据已批准用于更广泛的类别选项。 <br> * 所选期间内所有子期间的数据均已批准。 <br> 在前两种情况下，有一个涵盖选择的数据审批对象。第三种情况则没有。 |
| 已接受_此处 | 数据已在此处获得批准和接受（因此可能在此未获得批准。） |
| 已接受_其他地方 | 数据已被批准和接受，但在其他地方。 |

注意查询数据审批状态时，可以指定
查询参数的任意组合。您指定的组合
不需要描述数据被批准的地方
审批级别。例如：

  - 组织单位可能不在审批级别。这
    批准状态取决于数据是否在某个时间被批准
    组织单位上级的批准级别。

  - 您可以指定单个属性类别选项。批准
    状态取决于数据是否被批准用于属性
    包含其中一项或多项的类别选项组合
    选项。

  - 您可以指定一个时间段，该时间段长于
    数据输入和批准的数据集。批准
    状态取决于数据是否被批准用于所有
    指定期间内的数据集期间。

对于与您可能需要的类别组合关联的数据集
获取单个属性选项组合的数据批准记录
从具有 GET 请求的以下资源：

    /api/dataApprovals/categoryOptionCombos?wf=rIUL3hYOjJc&pe=201801&ou=YuQRtpLP10I

### 批量获取批准状态 { #bulk-get-approval-status } 

要获取多个批准状态的列表，可以发出类似于以下内容的GET请求：

    /api/dataApprovals/approvals?wf=rIUL3hYOjJc&pe=201801,201802&ou=YuQRtpLP10I

参数 `wf`、`pe`、`ou` 和 `aoc` 与获取单个批准状态的参数相同，但您可以为每个参数提供一个以逗号分隔的一个或多个值的列表。

这将为您提供一个包含批准参数和状态列表的响应，如下所示：

```json
[
  {
    "aoc": "HllvX50cXC0",
    "pe": "201801",
    "level": "KaTJLhGmU95",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "mayApprove": false,
      "mayUnapprove": true,
      "mayAccept": true,
      "mayUnaccept": false,
      "mayReadData": true,
      "approvedBy": "User A",
      "approvedAt": "2022-01-13T12:56:07.005",
      "acceptedBy": "User A",
      "acceptedAt": "2022-01-13T12:56:07.005"      
    },
    "state": "APPROVED_HERE",
    "wf": "rIUL3hYOjJc"
  },
  {
    "aoc": "HllvX50cXC0",
    "pe": "201802",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "mayApprove": true,
      "mayUnapprove": false,
      "mayAccept": false,
      "mayUnaccept": false,
      "mayReadData": true
    },
    "state": "UNAPPROVED_READY",
    "wf": "rIUL3hYOjJc"
  }
]
```

下表描述了返回的字段。

| 领域       | 描述 |
| ----------- | ----------- |
| 冠捷         | 属性选项组合标识符 |
| 聚乙烯          | 期间标识符 |
| 欧          | 组织单位标识符 |
| 权限 | 权限：与获取单次审批状态定义相同（参见表_数据审批返回参数_）。 |
| 州       | 数据批准状态之一（与获取单个批准状态相同）。 |
| 工作组          | 数据批准工作流标识符 |

### 批准数据 { #webapi_data_approval_approve_data } 

要批准数据，您可以向 *dataApprovals* 发出 *POST* 请求
资源。要取消批准数据，您可以发送*DELETE*请求到数据批准资源。

    POST DELETE /api/33/dataApprovals

要接受已经批准的数据，您可以发出 *POST* 请求
到 *dataAcceptances* 资源。要取消接受数据，您可以发出
*DELETE* 对 *dataAcceptances* 资源的请求。

    POST DELETE /api/33/dataAcceptances

这些请求包含以下参数：



表：数据审批操作参数

| 动作参数 | 需要 | 描述 |
|---|---|---|
| 工作组 | 是的 | 数据批准工作流标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | 组织单位标识符 |
| 冠捷 | 不 | 属性选项组合标识符 |

注意，与查询数据审批状态不同，必须指定
对应于可以选择的数据的参数
得到正式认可的。特别是，以下两项都必须为真：

  - 组织单位的级别必须由审批级别指定
    在工作流程中。

  - 指定的时间段必须与
    工作流程。

### 批量批准数据 { #webapi_data_approval_bulk_approve_data } 

您可以通过发布到批准大量数据记录
`/api/dataApprovals/approvals` 资源。

    POST /api/33/dataApprovals/approvals

您可以通过发布到
`/api/dataApprovals/unapprovals` 资源。

    POST /api/33/dataApprovals/unapprovals

您可以通过发布到
`/api/dataAcceptances/acceptances` 资源。

    POST /api/33/dataAcceptances/acceptances

您可以通过发布到
`/api/dataAcceptances/unacceptances` 资源。

    POST /api/33/dataAcceptances/unacceptances

批准有效负载受JSON支持，如下所示：

```json
{
  "wf": [
    "pBOMPrpg1QX", "lyLU2wR22tC"
  ],
  "pe": [
    "201601", "201602"
  ],
  "approvals": [
    {
      "ou": "cDw53Ej8rju",
      "aoc": "ranftQIH5M9"
    }, 
    {
      "ou": "cDw53Ej8rju",
      "aoc": "fC3z1lcAW5x"
    }
  ]
}
```

### 获取数据批准级别 { #get-data-approval-levels } 

要检索数据审批工作流及其数据审批级别，您
可以发出类似这样的 GET 请求：

    /api/dataApprovalWorkflows?
      fields=id,name,periodType,dataApprovalLevels[id,name,level,orgUnitLevel]


### 数据审批机构{ #authorities-for-data-approval }

- `F_DATA_APPROVAL_WORKFLOW` ：允许用户添加/更新数据审批工作流程
- `F_DATA_APPROVAL_LEVEL` ：允许用户添加/更新数据批准级别


# 分享中 { #sharing } 

## 分享中 { #webapi_sharing } 

共享解决方案允许您共享系统中的大多数对象
特定的用户组并定义对象是否应该公开
可访问或私有。要获取和设置对象的共享状态，您可以
与*共享*资源互动。

    /api/33/sharing

### 获取共享状态 { #webapi_get_sharing_status } 

要请求对象的共享状态，请使用GET请求执行以下操作：

    / api / 33 / sharing？type = dataElement＆id = fbfJHSPpUQD

响应如下所示。

```json
{
  "meta": {
    "allowPublicAccess": true,
    "allowExternalAccess": false
  },
  "object": {
    "id": "fbfJHSPpUQD",
    "name": "ANC 1st visit",
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

### 设定分享状态 { #webapi_set_sharing_status } 

您可以使用相同的 URL 定义对象的共享状态
一个 POST 请求，其中 JSON 格式的有效负载如下所示：

```json
{
  "object": {
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

在此示例中，有效负载定义了具有读写权限的对象
公共访问，无外部访问（无需登录），读写访问
一个用户组和另一个用户组的只读访问权限。你可以
使用 curl 将其提交到共享资源：

```bash
curl -d @sharing.json "localhost/api/33/sharing?type=dataElement&id=fbfJHSPpUQD"
  -H "Content-Type:application/json" -u admin:district
```
**笔记**
> It is possible to create surprising sharing combinations. For
> instance, if `externalAccess` is set to `true` but `publicAccess` is
> set to `--------`, then users will have access to the object 
> only when they are logged out.




## 新共享对象 { #new-sharing-object }
From 2.36 a new `sharing` property has been introduced in order to replace the old sharing properties `userAccesses`, `userGroupAccesses`, `publicAccess`, `externalAccess` in all metadata classes that have sharing enabled. This `Sharing` object is saved as a JSONB column in database. 
However, in order make it backward compatible the old sharing objects still work normally as before, for both import and export. In backend sharing data will be saved to new  JSONb `sharing` column instead of the old `*accesses` tables.

格式如下：
```json
{
  "name": "ANC 1st visit",
  "publicAccess": "rw------",
  "externalAccess": false,
  "userGroupAccesses": [
      {
          "access": "r-r-----",
          "userGroupUid": "Rg8wusV7QYi",
          "displayName": "HIV Program Coordinators",
          "id": "Rg8wusV7QYi"
      }
  ],
  "userAccesses": [],
  "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
  },
  "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {
          "Rg8wusV7QYi": {
              "access": "r-r-----",
              "id": "Rg8wusV7QYi"
          }
      },
      "public": "rw------"
  }
}
```

### 使用新的 JSON Patch Api 设置共享状态 { #webapi_set_sharing_status_using_json_patch_api }
You can use [JSON Patch API](#webapi_partial_updates) to update sharing for an object by sending a `PATCH` request to this endpoint with header `Content-Type: application/json-patch+json`
```
api/dataElements/fbfJHSPpUQD
```
Please note that this function ***only supports*** new `sharing` format. The payload in JSON format looks like this:
```json
[
  {
    "op": "replace",
    "path": "/sharing/users",
    "value": {
      "NOOF56dveaZ": {
        "access": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "access": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
You can add users to `sharing` property of an object like this
```json
[
  {
    "op": "add",
    "path": "/sharing/users",
    "value": {
      "NOOF56dveaZ": {
        "access": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "access": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
You can add one user to `sharing` like this
```json
[
  {
    "op": "add",
    "path": "/sharing/users/NOOF56dveaZ",
    "value": {
      "access": "rw------",
      "id": "NOOF56dveaZ"
    }
  }
]
```
You can remove one user from `sharing` like this
```json
[
  { 
    "op": "remove", 
    "path": "/sharing/users/N3PZBUlN8vq"
  }
]
```

## 仪表板级联共享 { #cascade-sharing-for-dashboard }

### 总览 { #overview } 

- `cascadeSharing` is available for Dashboards. This function copies the `userAccesses` and `userGroupAccesses` of a Dashboard to all of the objects in its `DashboardItems`, including `Map`, `EventReport`, `EventChart`, `Visualization`. 
- This function will not copy `METADATA_WRITE` access. The copied `UserAccess` and `UserGroupAccess` will **only** receive the `METADATA_READ` permission. 
- The `publicAccess` setting of the Dashboard is not copied.
- If any target object has `publicAccess` enabled, then it will be skipped and will not receive the `UserAccesses` or `UserGroupAccesses` from the Dashboard.
- The current user must have `METADATA_READ` sharing permission to all target objects. If the user does not, error `E5001` is thrown.
- The current user must have `METADATA_WRITE` sharing permission to update any target objects. If a target object should be updated and the user does not have this permission, error `E3001` is thrown.

### 示例用例 { #sample-use-case }

- DashboardA is shared to userA with `METADATA_READ_WRITE` permission. 
- DashboardA 有 VisualizationA，其中有 DataElementA。
- VisualizationA, DataElementA have `publicAccess` *disabled* and are *not shared* to userA.
- After executing cascade sharing for DashboardA, userA will have `METADATA_READ` access to VisualizationA and DataElementA.

### API 端点 { #api-endpoint }

- Send `POST` request to endpoint 
```
api/dashboards/cascadeSharing/{dashboardUID}
```


### API 参数 { #api-parameters }

| 名称 | 默认 | 描述 |
| --- | --- | -- |
| 干运行 | 假 | If this is set to `true`, then cascade sharing function will proceed without updating any objects. </br> The response will includes errors if any and all objects which will be updated. </br>This helps user to know the result before actually executing the cascade sharing function.
| 原子 | 假 | If this is set to `true`, then the cascade sharing function will stop and not updating any objects if there is an error. </br>Otherwise, if this is `false` then the function will try to proceed with best effort mode.

响应示例：

```json
{
  "errorReports": [
    {
      "message": "No matching object for reference. Identifier was s46m5MS0hxu, and object was DataElement.",
      "mainKlass": "org.hisp.dhis.dataelement.DataElement",
      "errorCode": "E5001",
      "errorProperties": [
        "s46m5MS0hxu",
        "DataElement"
      ]
    }
  ],
  "countUpdatedDashBoardItems": 1,
  "updateObjects": {
    "dataElements": [
      {
        "id": "YtbsuPPo010",
        "name": "Measles doses given"
      },
      {
        "id": "l6byfWFUGaP",
        "name": "Yellow Fever doses given"
      }
    ]
  }
}
```

### 响应属性：{ #response-properties }

- `errorReports`：包含级联共享过程中的所有错误。
- `countUpdatedDashBoardItems`：将要或已经更新的 `DashboardItem` 数量取决于 `dryRun` 模式。
- `updateObjects`：将要或已经更新的所有对象的列表取决于`dryRun`模式。

## 批量共享补丁 API { #webapi_bulk_sharing }
- 批量共享 API 允许您将共享设置应用于多个元数据对象。这意味着能够在一个 API 操作中向多个对象添加或删除多个用户和用户组。
- 此 API 不应支持随时间推移保持元数据对象同步，而应将其视为一次性操作。
- API 需要尊重共享访问控制，因为当前用户必须有权编辑正在更新的对象的共享。
- 从 2.38 开始引入了两个新的 api 端点，允许批量共享补丁更新，如下所述。
- Please note that those `PATCH` request must use header `Content-type:application/json-patch+json`

### Using `/api/{object-type}/sharing` with `PATCH` request
- This endpoint allows user to apply one set of Sharing settings for multiple metadata objects of *one object-type*.
- Note that we still support JsonPatch request for one object with endpoint `api/{object-type}/{uid}`. For instance, you can still update sharing of a DataElement by sending PATCH request to `api/dataElements/cYeuwXTCPkU/sharing`

例子：
```
curl -X PATCH -d @payload.json -H "Content-Type: application/json-patch+json" "https://play.dhis2.org/dev/api/dataElements/sharing"
```

### Using `/api/metadata/sharing` with `PATCH` request { #using-apimetadatasharing-with-patch-request } 
- This endpoint allows user to apply Sharing settings for *multiple object-types* in one payload.

例：
```
curl -X PATCH -d @payload.json -H "Content-Type: application/json-patch+json" "https://play.dhis2.org/dev/api/metadata/sharing"
```

## 参数 { #parameters }
- 两个补丁 api 端点具有相同的参数：

| 名称  |  默认  |  描述  |
| ---- | ---- | -------------------- |
| 原子 | 假 | 如果将此设置为 true，则如果出现错误，批处理函数将停止并且不更新任何对象 <br> 否则，如果此为 false，则该函数将尝试继续尽力而为模式。 |


## 验证{ #validation }
- 所有对象 ID 都将被验证是否存在。
- 当前用户需要拥有更新对象的元数据读/写权限。
- 元数据导入服务的所有现有验证也将应用。

## 响应 { #response }
- Response format should be same as from `/api/metadata` api.

## 负载格式{ #payload-formats }
- Payload for single object type using `/api/{object-type}/sharing` looks like this
```json
{
  "dataSets":[
    "cYeuwXTCPkU",
    "aYeuwXTCPkU"
  ],
  "patch":[
    {
      "op":"add",
      "path":"/sharing/users/DXyJmlo9rge",
      "value":{
        "access":"rw------",
        "id":"DXyJmlo9rge"
      }
    },
    {
      "op":"remove",
      "path":"/sharing/users/N3PZBUlN8vq"
    }
  ]
}
```

- Payload for multiple object types in one payload using `api/metadata/sharing`
```json
{
  "dataElements": {
    "fbfJHSPpUQD": [
      {
        "op": "replace",
        "path": "/sharing/users",
        "value": {
          "NOOF56dveaZ": {
            "access": "rw------",
            "id": "CotVI2NX0rI"
          },
          "Kh68cDMwZsg": {
            "access": "rw------",
            "id": "DLjZWMsVsq2"
          }
        }
      }
    ]
  },
  "dataSets": {
    "cYeuwXTCPkA": [
      {
        "op": "remove",
        "path": "/sharing/users/N3PZBUlN8vq"
      }
    ],
    "cYeuwXTCPkU": [
      {
        "op": "add",
        "path": "/sharing/users/DXyJmlo9rge",
        "value": {
          "access": "rw------",
          "id": "DXyJmlo9rge"
        }
      }
    ]
  },
  "programs": {
    "GOLswS44mh8": [
      {
        "op": "add",
        "path": "/sharing/userGroups",
        "value": {
          "NOOF56dveaZ": {
            "access": "rw------",
            "id": "NOOF56dveaZ"
          },
          "Kh68cDMwZsg": {
            "access": "rw------",
            "id": "Kh68cDMwZsg"
          }
        }
      }
    ]
  }
}
```


# 排程 { #webapi_scheduling }

## 获取可用的职位类型{ #types }

要获取所有可用作业类型的列表，可以使用以下端点：

    获取 /api/jobConfigurations/jobTypes

响应包含有关每个作业类型的信息，包括名称、作业类型、键、调度类型和可用参数。调度类型可以是 `CRON`，这意味着可以使用带有 `cronExpression` 字段的 cron 表达式来调度作业，或者是`FIXED_DELAY`，意味着可以使用 `delay` 字段将作业调度为以固定延迟运行.场延迟以秒为单位。

响应将类似于以下内容：

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

## 作业配置{ #job-configurations }
DHIS2允许安排各种类型的作业。每种类型的作业都有不同的配置属性，可让您更好地控制作业的运行方式。此外，如果需要，您可以将同一作业配置为以不同的配置和不同的时间间隔运行。

表：主要特性

| 财产 | 描述 | 类型 |
|---|---|---|
| 名称 | 职位名称。 | 串 |
| cron表达式 | cron 表达式定义作业运行的时间间隔。 | 字符串（Cron 表达式） |
| 工作类型 | 作业类型表示运行哪个任务。在下表中，您可以了解现有作业类型的概述。每种作业类型都可以有一组特定的作业配置参数。 | 字符串（枚举） |
| 工作参数 | 作业参数（如果适用于作业类型）。 | （参见职位类型列表） |
| 已启用 | A job can be added to the system without it being scheduled by setting `enabled` to false in the JSON payload. Use this if you want to temporarily stop scheduling for a job, or if a job configuration is not complete yet. | Boolean |



### 作业参数 { #job-parameters }

Table: `DATA_INTEGRITY` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `检查` | 字符串数组 | `[]` = 全部 | 按执行顺序运行的检查的名称 |
| `类型`   | 枚举            | `报告`   | 报告、摘要或详细信息                       |

Table: `ANALYTICS_TABLE` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `去年` | 整数  | 0       | 包含的回溯年数 |
| `skipTableTypes` | 枚举数组  | `[]`    | 跳过表的生成；可能的值：`DATA_VALUE`、`COMPLETENESS`、`COMPLETENESS_TARGET`、`ORG_UNIT_TARGET`、`EVENT`、`ENROLLMENT`、`VALIDATION_RESULT` |
| `跳过资源表` | 布尔值 | `假`   | 跳过资源表的生成 |
| `跳过程序` | 字符串数组 | `[]`    | 应跳过的可选程序 (ID) 列表 |

Table: `CONTINUOUS_ANALYTICS_TABLE` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `去年` | 整数           | `0`     | 包含的回溯年数 |
| `skipTableTypes` | 枚举数组 | `[]`    | 跳过表的生成；可能的值：`DATA_VALUE`、`COMPLETENESS`、`COMPLETENESS_TARGET`、`ORG_UNIT_TARGET`、`EVENT`、`ENROLLMENT`、`VALIDATION_RESULT` |
| `完整更新时间` | 整数           | `0`     | 一天中完整更新分析表的时间 (0-23) |

Table: `DATA_SYNC` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `页面大小` | 整数 | `10000` | 作为一个单元处理的数据值的数量 |

Table: `META_DATA_SYNC` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `trackerProgramPageSize` | 整数 | `20` | 作为一个单元处理的跟踪实体的数量 |
| `事件程序页面大小` | 整数 | `60` | 作为一个单元处理的事件数           |
| `数据值页面大小` | 整数 | `10000` | 作为一个单元处理的数据值的数量  |

Table: `MONITORING` (Validation rule analysis) job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `相对开始` | 整数 | `0` | 与执行日期相关的数字，类似于要监控的期间的开始时间 |
| `相对结束` | 整数 | `0` | 与执行日期相关的数字，类似于要监控的期间结束时间 |
| `验证规则组` | 字符串数组 | `[]` | 要包含在作业中的验证规则组 (UID) |
| `发送通知` | 布尔值 | `假` | Set `true` if job should send notifications based on validation rule groups |
| `持续结果` | 布尔值 | `假` | Set `true` if job should persist validation results |

Table: `PUSH_ANALYSIS` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `推分析` | 字符串数组 | `[]` |  您要运行的推送分析的 UID |

Table: `PREDICTOR` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `相对开始` | 整数 | `0` | 与执行日期相关的数字，类似于要监控的期间的开始时间 |
| `相对结束` | 整数 | `0` | 与执行日期相关的数字，类似于要监控的期间的开始时间 |
| `predictors` | 字符串数组 | `[]` | 要包含在作业中的预测器 (UID)                                                      |
| `预测器组` | 字符串数组 | `[]` | 要包含在作业中的预测器组 (UID)                                                |

Table: `MATERIALIZED_SQL_VIEW_UPDATE` job parameters

| 名称          | 类型          | 默认 | 描述                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `sqlViews`    | 字符串数组 | `[]` | 由作业更新的 SQL 视图的 UID |


### 创建作业配置{ #create-a-job-configuration }

要配置作业，您可以对以下资源发出POST请求：

    /api/jobConfigurations

不含JSON格式参数的作业如下所示：

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

参数为JSON格式的分析表作业的示例：

```json
{
  "name": "Analytics tables last two years",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * * ? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

作为带有JSON格式参数的推送分析作业的示例：

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

An example of a job with scheduling type `FIXED_DELAY` and 120 seconds delay:

```json
{
  "name": "Continuous analytics table",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "delay": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
```

### 获取作业配置{ #get-job-configurations }

列出所有作业配置：

    GET /api/jobConfigurations

检索作业：

    GET /api/jobConfigurations/{id}

响应有效负载如下所示：

```json
{
  "lastUpdated": "2018-02-22T15:15:34.067",
  "id": "KBcP6Qw37gT",
  "href": "http://localhost:8080/api/jobConfigurations/KBcP6Qw37gT",
  "created": "2018-02-22T15:15:34.067",
  "name": "analytics last two years",
  "jobStatus": "SCHEDULED",
  "displayName": "analytics last two years",
  "enabled": true,
  "externalAccess": false,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "2018-02-26T03:00:00.000",
  "cronExpression": "0 0 3 ? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorite": false,
  "configurable": true,
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "manage": true
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favorites": [],
  "translations": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
```

### 更新作业配置{ #update-a-job-configuration }

使用以下端点和JSON有效负载格式，通过参数更新作业：

    PUT /api/jobConfiguration/{id}

```json
{
  "name": "analytics last two years",
  "enabled": true,
  "cronExpression": "0 0 3 ? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

### 删除作业配置{ #delete-a-job-configuration }

使用以下方法删除作业：

    删除/ api / jobConfiguration / {id}

请注意，某些具有自定义配置参数的作业可能不会被添加，如果
未配置所需的系统设置。一个例子是数据
同步，这需要远程服务器配置。

### 手动运行作业{ #execute }

可以使用以下命令手动运行作业：

    POST /api/jobConfiguration/{id}/execute



## 调度程序 API { #scheduler-api }
While `/api/jobConfigurations` is centered around the job configuration objects
the `/api/scheduler` API reflects the state of the scheduler 
and the `/api/scheduling` API provides job progress tracking information.  

### 观察正在运行的作业 { #running}
作业运行时可以观察执行步骤和状态。
当前正在运行的所有类型作业的列表由以下各项提供：

    GET /api/scheduling/running/types 获取 /api/scheduling/running/types

要按作业类型获取所有正在运行的作业的概述，请使用：

    GET /api/调度/运行

由于每种类型一次只能运行一个作业，因此
可以使用以下命令详细查看正在运行的作业：

    GET /api/scheduling/running/{type}

For example, to see status of a running `ANALYTICS_TABLE` job use

    获取 /api/scheduling/running/ANALYTICS_TABLE

A job is a sequence of processes. Each process has a sequence of `stages`.
Within each stage there might be zero, one or many `items`. Items could be
processed strictly sequential or parallel, n items at a time. Often the
number of `totalItems` is known up-front.

一般来说，流程中的阶段和阶段中的项目是“发现”的
作为处理数据的“副作用”。虽然大多数进程都有固定的
一些处理的阶段顺序可能有不同的阶段，具体取决于
数据处理。项目通常依赖于数据。大多数工作只包括
单一进程。

过程阶段项树中的每个节点都有一个状态，可以是
* `RUNNING`：当前正在处理（尚未完成）
* `SUCCESS`：成功完成时
* `ERROR`：完成时有错误或发生异常时
* `CANCELLED`：当请求取消且项目无法完成时

### 查看已完成的作业运行{ #completed }
一旦一项工作成功完成或由于某种原因而失败
异常或取消状态从运行状态集移动到
已完成的工作状态。该集合仅保留最近的执行
每种工作类型的状态。概述可在以下位置找到：

    GET /api/调度/已完成

有关特定工作类型的详细信息相应地提供于：

    GET /api/scheduling/completed/{type}

In case of the `ANALYTICS_TABLE` job this would be:

    获取 /api/scheduling/completed/ANALYTICS_TABLE

### 请求取消正在运行的作业{ #cancel }
作业一旦开始，就会通过一系列步骤进行工作。每一步都可能
依次具有已处理的项目的集合。虽然工作通常
无法在任何时间点停止，我们可以请求取消，并且
一旦完成一个项目或步骤，流程就会合作放弃，并且
承认已请求取消。这意味着工作不会停止
立即并在某个未知点离开
加工。相反，当有机会跳到
结束。这仍然意味着整个过程尚未完成，并且还没有完成。
回滚。它可能只执行了一些步骤并跳过了其他步骤
结束。

要取消正在运行的作业，请使用：

    POST /api/scheduling/cancel/{type}

For example, to cancel the `ANALYTICS_TABLE` job run:

    POST /api/scheduling/cancel/ANALYTICS_TABLE

Depending on the current step and item performed this can take from
milliseconds to minutes before the cancellation becomes effective.
However, the status of the overall process will be shown as `CANCELLED`
immediately when check using

    获取 /api/scheduling/running/ANALYTICS_TABLE

仅可拆分为流程、阶段和项目的作业
有效取消。并非所有工作都已被拆分。这些将运行直到
即使已请求取消，也要完成。


## 作业队列 { #queues }
可以使用作业队列创建作业序列（配置）。
队列始终使用唯一的名称和 CRON 表达式触发器。
队列启动后，它将按给定顺序运行队列中的所有作业。
当第一个完成时，第二个按顺序开始，依此类推。

### 列出作业队列名称{ #queues-list }
要列出现有队列的唯一名称，请使用：

    获取/api/调度程序/队列

响应是一个名称数组：
```json
["queue_a", "queue_b"]
```

### 获取作业队列{ #queues-info }
要获取特定队列的所有详细信息，请使用：

    GET /api/scheduler/queues/{name}

详细信息包括其名称、CRON 表达式和作业序列：

```json
{
  "name": "myQ",
  "cronExpression": "0 0 1 ? * *",
  "sequence": ["FgAxa6eRSzQ", "BeclVERfWbg" ]
}
```

### 创建新的作业队列 { #queues-add }
要创建新队列，请发送带有名称的有效负载对象的 POST 请求，
CRON 表达式和作业顺序：

    POST /api/scheduler/queues/{name}

To create a queue with name `myQ` use a POST to `/api/scheduler/queues/myQ`:

```json
{
  "cronExpression": "0 0 1 ? * *",
  "sequence": ["FgAxa6eRSzQ", "BeclVERfWbg" ]
}
```
A `name` can be present in the payload as well but name specified in the URL
path takes precedence. 

> **注意**
>
> 除队列中第一个作业配置外的所有作业配置的 cron 表达式为
> 清除，因为它们不再有自己的触发器。它需要
> 一旦作业从队列中删除，就会手动恢复。

### 更新作业队列 { #queues-update }
要更新现有队列 CRON 表达式或序列，请使用 PUT 请求

    PUT /api/scheduler/queues/{name}

有效负载必须声明新的 CRON 表达式和作业序列，如
上面的例子创建了一个新队列。

### 删除作业队列 { #queues-delete }
要删除作业队列，请向其资源 URL 发送 DELETE 请求：

    删除 /api/scheduler/queues/{name}

> **注意**
>
> 删除队列不会删除任何引用的作业配置。任何工作
> 通过更改顺序或从队列中删除的配置
> 删除队列被禁用。要单独使用它，请提供一个 CRON
> 表达式并再次启用配置。


## 作业调度程序 { #scheduler }
调度程序中的调度是基于作业配置的列表
和作业队列。计划中的条目要么是简单的作业配置，
或者它是一个作业队列。两者都使用相同的条目格式表示。

要获取调度程序列表，请使用：

    获取/api/调度程序

此列表中的作业配置如下所示：

```json
  {
    "name": "User account expiry alert",
    "type": "ACCOUNT_EXPIRY_ALERT",
    "cronExpression": "0 0 2 ? * *",
    "nextExecutionTime": "2023-03-15T02:00:00.000",
    "status": "SCHEDULED",
    "enabled": true,
    "configurable": false,
    "sequence": [
      {
        "id": "fUWM1At1TUx",
        "name": "User account expiry alert",
        "type": "ACCOUNT_EXPIRY_ALERT",
        "cronExpression": "0 0 2 ? * *",
        "nextExecutionTime": "2023-03-15T02:00:00.000",
        "status": "SCHEDULED"
      }
    ]
  }
```
Most notably the `sequence` has only a single item. Information on top level
object and the object in the `sequence` both originate from the job configuration.

列表中的作业队列如下所示：

```json
  {
    "name": "myQ",
    "type": "Sequence",
    "cronExpression": "0 0 1 ? * *",
    "nextExecutionTime": "2023-03-15T01:00:00.000",
    "status": "SCHEDULED",
    "enabled": true,
    "configurable": true,
    "sequence": [
      {
        "id": "FgAxa6eRSzQ",
        "name": "test Q1",
        "type": "ANALYTICS_TABLE",
        "cronExpression": "0 0 1 ? * *",
        "nextExecutionTime": "2023-03-15T01:00:00.000",
        "status": "SCHEDULED"
      },
      {
        "id": "BeclVERfWbg",
        "name": "est Q2",
        "type": "DATA_INTEGRITY",
        "status": "SCHEDULED"
      }
    ]
  }
```
顶级对象源自队列和聚合信息。
序列中的对象源自作业配置
序列的一部分。

### 列出可添加到作业队列的作业条目{ #queueable }
并非所有 jon 配置都可以添加到队列中。
系统作业和已经属于队列的作业不能在另一个队列中使用
队列。要列出可以作为任何队列一部分的作业配置，请使用：

    获取 /api/scheduler/queueable

要列出可以作为特定队列一部分的作业配置，请使用：

    GET /api/scheduler/queueable?name={queue}

这还将排除已属于指定队列的所有作业。


# 同步化 { #webapi_synchronization }

本节介绍数据和元数据的提取和推送。

## 数据值推送 { #webapi_sync_data_push }

要将数据值推送到远程服务器，必须首先配置
系统设置 > 中相关服务器的 URL 和凭据
同步，然后向以下资源发出 POST 请求：

    / api / 33 / synchronization / dataPush

## 元数据拉取 { #webapi_sync_metadata_pull }

要从远程 JSON 文档中启动元数据拉取，您可以创建一个
使用 *url* 作为请求负载的 POST 请求到以下资源：

    / api / 33 / synchronization / metadataPull

## 可用性检查 { #webapi_sync_availability_check } 

检查远程数据服务器的可用性并验证用户
您可以向以下资源发出 GET 请求：

    / api / 33 /同步/可用性



# 审核 { #audit } 

## 稽核 { #webapi_auditing } 

DHIS2 将审核聚合数据值、跟踪实体数据值、跟踪实体属性值和数据审批记录的更新和删除。本节介绍如何检索上述实体的审核记录。请注意，多个查询参数可以重复任意次。

### 汇总数据价值审核 { #webapi_auditing_aggregate_audits } 

聚合数据值审核的端点位于：

```
/api/audits/dataValue
```

表：聚合数据值查询参数

| 范围 | 选项 | 描述 |
|---|---|---|
| ds | 数据集ID | 用于从中获取数据元素的一个或多个数据集标识符 |
| 德 | 数据元素ID | 一个或多个数据元素标识符 |
| 聚乙烯 | ISO周期 | 一个或多个句点 ISO 标识符 |
| 欧 | 组织单位ID | 一个或多个组织部门标识符 |
| 审计类型 | 更新&#124;删除 | 按一种或多种审核类型过滤 |
| 跳过分页 | 假的&#124;真的 | 打开/关闭分页 |
| 寻呼 | 错误的 \| 真正 | 启用或禁用分页 |
| 页 | 数 | 页码（默认1） |
| 页面大小 | 数 | 页面大小（默认 50） |

Example: Get audits for a data set `lyLU2wR22tC` and audit type `CREATE` or `UPDATE`:

    /api/33/audits/dataValue?ds=lyLU2wR22tC&auditType=创建、更新

Example: Get audits for data element `BOSZApCrBni`, org unit `DiszpKrYNg8` and category option combination `TkDhg29x18A`:

    /api/33/audits/dataValue?de=BOSZApCrBni&ou=DiszpKrYNg8&co=TkDhg29x18A

### 跟踪实体数据价值审核 { #webapi_tracked_entity_data_value_audits } 

跟踪实体数据值审核的端点位于：

```
/api/audits/trackedEntityDataValue
```

表：跟踪实体数据值查询参数

| 范围 | 选项 | 描述 |
|---|---|---|
| 德 | 数据元素ID | 一个或多个数据元素标识符 |
| 欧 | 组织单位ID | 已审核事件的一个或多个组织单位标识符 |
| 磅/平方英寸 | 程序阶段实例ID | 被审计事件的一个或多个程序阶段实例标识符 |
| 附注 | 节目阶段 ID | 审核事件程序的一位或多位程序圣人 |
| 开始日期 | 开始日期 | 仅返回该日期之后创建的审核记录 |
| 结束日期 | 结束日期 | 仅返回日期之前创建的审核记录 |
| 模式 | 组织单位选择方式 | 已选\| 后人 |
| 审核类型 | 更新&#124;删除 | 按一种或多种审核类型过滤 |
| 跳过分页 | 假的&#124;真的 | 打开/关闭分页 |
| 寻呼 | 错误的 \| 真正 | 是否启用或禁用分页 |
| 页 | 数 | 页码（默认1） |
| 页面大小 | 数 | 页面大小（默认 50） |

Example: Get audits for data elements `eMyVanycQSC` and `qrur9Dvnyt5`:

    / api / 33 / audits / trackedEntityDataValue？de = eMyVanycQSC＆de = qrur9Dvnyt5

Example: Get audits for org unit `O6uvpzGd5pu` including descendant org units in the org unit hierarchy:

    /api/audits/trackedEntityDataValue?ou=O6uvpzGd5pu&ouMode=DESCENDANTS

### 跟踪实体属性值审核 { #webapi_tracked_entity_attribute_value_audits } 

跟踪实体属性值审核的端点位于：

```
/api/audits/trackedEntityAttributeValue
```

表：跟踪实体属性值查询参数

| 范围 | 选项 | 描述 |
|---|---|---|
| 茶 | 跟踪的实体属性 ID | 一个或多个被跟踪实体属性标识符 |
| 亭 | 跟踪的实体实例 ID | 一个或多个被跟踪实体实例标识符 |
| 审核类型 | 更新&#124;删除 | 按一种或多种审核类型过滤 |
| 跳过分页 | 假的&#124;真的 | 打开/关闭分页 |
| 寻呼 | 错误的 \| 真正 | 是否启用或禁用分页 |
| 页 | 数 | 页码（默认1） |
| 页面大小 | 数 | 页面大小（默认 50） |

Example: Get audits for tracked entity attribute `VqEFza8wbwA`:

    / api / 33 / audits / trackedEntityAttributeValue？tea = VqEFza8wbwA

Example: Get audits for tracked entity instance `wNiQ2coVZ39` and audit type `DELETE`:

    /api/33/audits/trackedEntityAttributeValue?tei=wNiQ2coVZ39&auditType=DELETE

### 跟踪实体实例审核 { #webapi_tracked_entity_instance_audits } 

Once auditing is enabled for tracked entity instances (by setting `allowAuditLog` of tracked entity types to `true`), all read and search operations are logged. The endpoint for accessing audit logs is located at:

```
/api/audits/trackedEntityInstance
```

表：跟踪的实体实例审核查询参数

| 范围 | 选项 | 描述 |
|---|---|---|
| 亭 | 跟踪实体实例 | 一个或多个被跟踪实体实例标识符 |
| 用户 | 用户 | 一个或多个用户标识符 |
| 审计类型 | 搜索&#124;读 | 按一种或多种审核类型过滤 |
| 开始日期 | 开始日期 | Start date for audits in `yyyy-mm-dd` format |
| 结束日期 | 结束日期 | End date for audits in `yyyy-mm-dd` format |
| 跳过分页 | 假的&#124;真的 | 打开/关闭寻呼。 |
| 寻呼 | 错误的 \| 真正 | 是否启用或禁用分页 |
| 页 | 数 | 页码（默认1） |
| 页面大小 | 数 | 页面大小（默认 50） |

Example: Get audits of audit type `READ` with `startDate` 2018-03-01 and `endDate` 2018-04-24 with a page size of 5:

    /api/33/audits/trackedEntityInstance.json?startDate=2021-03-01&endDate=2022-04-24&auditType=READ&pageSize=5

Example: Get audits for tracked entity instance `wNiQ2coVZ39`:

    /api/33/audits/trackedEntityInstance.json?tei=wNiQ2coVZ39

### 数据审批审核 { #data-approval-audits } 

数据审批审核的端点位于：

```
/api/audits/dataApproval
```

表：数据审批查询参数

| 范围 | 选项 | 描述 |
|---|---|---|
| 达尔 | 数据审批级别ID | 一个或多个数据批准级别标识符 |
| 工作组 | 数据审批工作流程ID | 一个或多个数据审批工作流标识符 |
| 欧 | 组织单位ID | 一个或多个组织单位标识符 |
| 冠捷 | 属性选项组合 ID | 一个或多个属性选项组合标识符 |
| 开始日期 | 开始日期 | Start date for approvals in `yyyy-mm-dd` format |
| 结束日期 | 结束日期 | End date for approvals in `yyyy-mm-dd` format |
| 跳过分页 | 假的&#124;真的 | 打开/关闭分页 |
| 页 | 数 | 页码（默认1） |
| 页面大小 | 数 | 页面大小（默认 50） |

Example: Get audits for data approval workflow `i5m0JPw4DQi`:

    /api/33/audits/dataApproval?wf=i5m0JPw4DQi

Exaple: Get audits between `2021-01-01` and `2022-01-01` for org unit `DiszpKrYNg8`:

    /api/33/audits/dataApproval?ou=DiszpKrYNg8&startDate=2021-01-01&endDate=2022-01-01



# 讯息传递 { #messaging } 

## 讯息对话 { #webapi_message_conversations } 

DHIS2 具有发送消息的机制，例如
用户反馈、通知和给用户的一般信息。留言
被分组到对话中。与消息对话交互
您可以向 *messageConversations* 发送 POST 和 GET 请求
资源。

    / api / 33 / messageConversations

消息会传送到 DHIS2 消息收件箱，但也可以发送
以短信形式发送到用户的电子邮件地址和手机。在这个例子中，
我们将看到如何利用 Web API 来发送、读取和管理
消息。我们将伪装成*DHIS2管理员*用户并发送
给*移动*用户的消息。然后我们会假装是手机
用户并阅读我们的新消息。在此之后，我们将管理管理员
用户收件箱通过标记和删除邮件。

### 撰写和阅读邮件 { #webapi_writing_messages } 

我们在发送和阅读消息时需要交互的资源
是 *messageConversations* 资源。我们首先访问 Web API
在 <http://play.dhis2.org/demo/api> 的入口点我们找到并跟随
*messageConversations* 资源的链接位于
 <http://play.dhis2.org/demo/api/messageConversations> 。说明
告诉我们可以使用 POST 请求来创建新消息
发送给多个用户的以下 XML 格式：

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <users>
    <user id="user1ID" />
    <user id="user2ID" />
    <user id="user3ID" />
  </users>
</message>
```

为了发送给一个或多个用户组中的所有用户，我们可以
用：

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <userGroups>
    <userGroup id="userGroup1ID" />
    <userGroup id="userGroup2ID" />
    <userGroup id="userGroup3ID" />
  </userGroups>
</message>
```

为了发送给连接到一个或多个组织单位的所有用户，我们
可以使用：

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <organisationUnits>
    <organisationUnit id="ou1ID" />
    <organisationUnit id="ou2ID" />
    <organisationUnit id="ou3ID" />
  </organisationUnits>
</message>
```

Since we want to send a message to our friend the mobile user we need to
look up her identifier. We do so by going to the Web API entry point and
follow the link to the *users* resource at `/api/users`. We continue by 
following link to the mobile user at `/api/users/PhzytPW3g2J` where we learn
that her identifier is *PhzytPW3g2J*. We are now ready to put our XML
message together to form a message where we want to ask the mobile user
whether she has reported data for January 2014:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>Mortality data reporting</subject>
  <text>Have you reported data for the Mortality data set for January 2014?</text>
  <users>
    <user id="PhzytPW3g2J" />
  </users>
</message>
```

为了测试这一点，我们将 XML 内容保存到一个名为 *message.xml* 的文件中。
我们使用 cURL 将消息发送到 DHIS2 演示实例
指示内容类型是 XML 并以 *admin* 身份进行身份验证
用户：

```bash
curl -d @message.xml "https://play.dhis2.org/demo/api/messageConversations"
  -H "Content-Type:application/xml" -u admin:district -X POST
```

JSON和POST命令中的相应有效负载如下所示：

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}
```

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Content-Type:application/json" -u admin:district -X POST
```

如果一切顺利，我们会收到一个 *201 Created* HTTP 状态代码。另外，请注意
我们收到一个 *Location* HTTP 标头，该标头的值通知我们
新创建的消息对话资源的 URL - 这可以是
消费者使用它来执行进一步的操作。

我们现在将假装是移动用户并阅读消息
刚刚通过向 *messageConversations* 发送 GET 请求发送
资源。我们提供一个带有 *application/xml* 的 *Accept* 标头作为
表示我们对 XML 资源感兴趣的值
表示，我们以*移动*用户身份进行身份验证：

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Accept:application/xml" -u mobile:district
```

作为响应，我们得到以下XML：

```xml
<messageConversations xmlns="http://dhis2.org/schema/dxf/2.0"
  link="https://play.dhis2.org/demo/api/messageConversations">
  <messageConversation name="Mortality data reporting" id="ZjHHSjyyeJ2"
    link="https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"/>
  <messageConversation name="DHIS2 version 2.7 is deployed" id="GDBqVfkmnp2"
    link="https://play.dhis2.org/demo/api/messageConversations/GDBqVfkmnp2"/>
</messageConversations>
```

从响应中，我们能够读取新发送的标识符
消息是 *ZjHHSjyyeJ2*。注意具体链接
资源已嵌入，可以关注以阅读完整内容
信息。一旦我们知道，我们可以直接回复现有的消息对话
通过包含消息文本作为请求负载来获取 URL。我们
现在可以构造一个 URL 来发送我们的回复：

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

如果一切按计划进行，您将收到 *200 OK* 状态代码。

在2.30中，我们添加了URL搜索参数：

    queryString =？＆queryOperator =？

过滤器在主题、文本和发件人中搜索消息的匹配项
对话。默认查询运算符是 *token*，但是其他运算符
可以在查询中定义。

### 管理讯息 { #webapi_managing_messages } 

随着用户接收和发送消息，对话将开始堆积
在他们的收件箱中，最终变得难以跟踪。我们现在将
看看通过删除和标记来管理用户的消息收件箱
通过 Web-API 进行对话。我们将通过执行一些
在“DHIS 管理员”用户的收件箱中维护。

首先，让我们看看从收件箱中删除一些邮件。是
一定要注意这里描述的所有删除操作只删除
用户和消息对话之间的关系。实际上
这意味着我们不会删除消息本身（或任何
内容），但只是从
用户使其不再列在
`/api/messageConversations` 资源。

To remove a message conversation from a users inbox we need to issue a
*DELETE* request to the resource identified by the id of the message
conversation and the participating user. For example, to remove the user
with id `xE7jOejl9FI` from the conversation with id `jMe43trzrdi`:

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations/jMe43trzrdi
```

如果请求成功，服务器将回复 *200 OK*。这
响应正文包含一个 XML 或 JSON 对象（根据接受
请求的标头）包含已删除用户的 ID。

```json
{
  "removed" : ["xE7jOejl9FI"]
}
```

失败时，返回的对象将包含一个消息有效负载
描述错误。

```json
{
  "message" : "No user with uid: dMV6G0tPAEa"
}
```

细心的读者已经注意到对象返回了
在我们的例子中，成功实际上是一个 id 列表（包含一个
入口）。这是因为端点也支持批量删除。这
对相同的 *messageConversations* 资源发出请求，但遵循
语义略有不同。对于批处理操作，会话 ID
作为查询字符串参数给出。以下示例删除了两个
当前用户的单独消息对话：

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm"
  -X DELETE -u admin:district
```

如果您有足够的权限，可以删除对话
通过提供可选的用户 ID 参数代表另一个用户。

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm&user=PhzytPW3g2J"
  -X DELETE -u admin:district
```

如上所述，批量删除将返回与
单一操作。删除的对象列表将反映成功
执行的移除。部分错误的请求（即不存在的 ID）
因此不会取消整个批处理操作。

消息带有布尔 *read* 属性。这允许跟踪是否
用户是否看到（打开）了一条消息。在典型应用中
场景（例如 DHIS2 网络门户），消息将被标记为已读
用户第一次打开它。然而，用户可能想要
管理他们的消息的已读或未读状态，以保持
跟踪某些对话。

标记消息已读或未读遵循与批处理类似的语义
移除，并且还支持批量操作。将消息标记为已读
我们向 `messageConversations/read` 资源发出一个 *POST*
包含一个或多个消息 ID 的请求正文。将消息标记为
未读我们向 `messageConversations/unread` 发出相同的请求
资源。与删除的情况一样，可选的 *user* 请求参数
可以给。

让我们将几条消息标记为当前用户已读：

```bash
curl "https://play.dhis2.org/dev/api/messageConversations/read"
  -d '["ZrKML5WiyFm","Gc03smoTm6q"]' -X POST
  -H "Content-Type: application/json" -u admin:district
```

响应是带有以下 JSON 正文的 *200 OK*：

```json
{
  "markedRead": ["ZrKML5WiyFm", "Gc03smoTm6q"]
}
```

您可以将收件人添加到现有的消息对话中。该资源位于：

    / api / 33 / messageConversations / id /收件人

此资源的选项是用户、用户组和
组织单位。请求应如下所示：

```json
{
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}

```

### 邮件附件 { #webapi_message_attachments } 

创建带附件的消息分两步完成：上传
文件添加到 *attachments* 资源，然后包括一个或几个
创建新邮件时的附件 ID。

对 *attachments* 资源的 POST 请求会将文件上传到
服务器。

```
curl -F file=@attachment.png“ https://play.dhis2.org/demo/api/messageConversations/attachments”
  -u管理员：区
```

该请求返回一个表示附件的对象。的标识
创建消息时必须使用此对象以链接
邮件附件。

```json
{
  "created": "2018-07-20T16:54:18.210",
  "lastUpdated": "2018-07-20T16:54:18.212",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407",
    "lastUpdated": "2018-03-09T23:06:54.512",
    "externalAccess": false,
    "displayName": "John Traore",
    "favorite": false,
    "id": "xE7jOejl9FI"
  },
  "lastUpdatedBy": {
    "id": "xE7jOejl9FI",
    "name": "John Traore"
  },
  "favorite": false,
  "id": "fTpI4GOmujz"
}
```

创建新消息时，可以在请求正文中传递 id
将上传的文件链接到正在创建的消息。

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "attachments": [
    "fTpI4GOmujz",
    "h2ZsOxMFMfq"
  ]
}
```

回复消息时，可以将 id 作为请求传递
范围。

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?attachments=fTpI4GOmujz,h2ZsOxMFMfq"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

创建带有附件的邮件后，附加文件
可以通过对以下 URL 的 GET 请求访问：

    / api / messageConversations / <mcv-id> / <msg-id> / attachments / <attachment-id>

其中 <mcv-id> 是*消息对话* ID，<msg-id> 是
包含附件和 <attachment-id> 的 *message* 是
特定*消息附件*的 ID。

### 票证和验证结果通知 { #webapi_messaging_tickets } 

您可以使用“写反馈”工具来创建工单和消息。
一张票和一条消息的唯一区别是你可以给
票证的状态和优先级。设置状态：

    POST / api / messageConversations / <uid> / status

设置优先级：

    POST / api / messageConversations / <uid> / priority

在 2.29 中，验证分析生成的消息现在也用于
状态和优先级属性。默认情况下，消息由
验证分析将继承验证规则的优先级
问题，或者如果消息包含多个最重要的
规则。

在 2.30 中，可以将验证规则分配给任何用户，同时工单
仍然需要分配给系统反馈接收者中的一个用户
团体。



表：有效状态和优先级值的列表

| 状态 | 优先事项 |
|---|---|
| 打开 | 低的 |
| 待办的 | 中等的 |
| 无效的 | 高的 |
| 解决了 ||

也可以给工单添加内部消息，只能看到
拥有“管理票证”权限的用户。创建一个内部
回复，包括“内部”参数，并将其设置为

```bash
curl -d "This is an internal message"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?internal=true"
  -H "Content-Type:text/plain" -u admin:district -X POST
```




# 可视化 { #visualizations } 
## 仪表板 { #webapi_dashboard } 

仪表板旨在为您提供多个分析的概览
地图、图表、数据透视表和报告等项目，它们一起可以
提供您数据的全面概览。仪表板可用
通过 *dashboards* 资源在 Web API 中。仪表板包含一个
仪表板*项目*列表。一个项目可以代表一个单一的资源，比如
图表、地图或报告表，或表示指向分析的链接列表
资源，如报告、资源、表格报告和用户。一种
仪表板项目最多可以包含八个链接。通常，仪表板
客户可以选择直接在一个
用户界面，同时将多对象项目渲染为可点击
链接。

    / api /仪表板

### 浏览仪表板 { #webapi_browsing_dashboards } 

获取包含基本信息的仪表板列表，包括
JSON 格式的标识符、名称和链接，您可以向其发出 *GET* 请求
以下网址：

    /api/dashboards.json

仪表板资源将提供仪表板列表。请记住
仪表板对象是共享的，因此列表将受
当前已验证的用户。您可以检索有关一个的更多信息
特定的仪表板，请点击其链接，类似于：

    /api/dashboards/vQFhmLJU5sK.json

仪表板包含名称和创建日期等信息以及
仪表板项目数组。 JSON 格式的响应看起来类似
对此回复（某些信息已被删除，以便
简洁）。

```json
{
  "lastUpdated" : "2013-10-15T18:17:34.084+0000",
  "id": "vQFhmLJU5sK",
  "created": "2013-09-08T20:55:58.060+0000",
  "name": "Mother and Child Health",
  "href": "https://play.dhis2.org/demo/api/dashboards/vQFhmLJU5sK",
  "publicAccess": "--------",
  "restrictFilters": false,
  "externalAccess": false,
  "itemCount": 17,
  "displayName": "Mother and Child Health",
  "access": {
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "read": true,
    "manage": true
  },
  "user": {
    "id": "xE7jOejl9FI",
    "name": "John Traore",
    "created": "2013-04-18T15:15:08.407+0000",
    "lastUpdated": "2014-12-05T03:50:04.148+0000",
    "href": "https://play.dhis2.org/demo/api/users/xE7jOejl9FI"
  },
  "dashboardItems": [{
    "id": "bu1IAnPFa9H",
    "created": "2013-09-09T12:12:58.095+0000",
    "lastUpdated": "2013-09-09T12:12:58.095+0000"
    }, {
    "id": "ppFEJmWWDa1",
    "created": "2013-09-10T13:57:02.480+0000",
    "lastUpdated": "2013-09-10T13:57:02.480+0000"
  }],
  "layout": {
    "spacing": {
      "column": 5,
      "row": 5
    },
    "columns": [{
      "index": 0,
      "span": 2
    }, {
      "index": 1,
      "span": 1
    }]
  },
  "userGroupAccesses": []
}
```

通过指定特定字段可以获得更定制的响应
在请求中。下面提供了一个示例，它将返回更多
有关用户仪表板上每个对象的详细信息。

    / api / dashboards / vQFhmLJU5sK /？fields =：all，dashboardItems [：all]

### 搜索仪表板 { #webapi_searching_dasboards } 

当用户构建仪表板时很方便
能够使用搜索各种分析资源
*/dashboards/q* 或 */dashboards/search* 资源。
这些资源可让您搜索匹配项
以下对象的 name 属性：可视化、eventVisualizations 映射、
用户、报告和资源。您可以通过 *GET* 进行搜索
对以下资源 URL 模式的请求，其中 my-query 应该是
替换为首选搜索查询：

    /api/dashboards/q/my-query.json
    /api/dashboards/search?q=my-query

例如，此查询：

    /api/dashboards/q/ma?count=6&maxCount=20&max=REPORT&max=MAP
    /api/dashboards/search?q=ma?count=6&maxCount=20&max=REPORT&max=MAP

将搜索以下内容：

* 分析对象名称包含字符串“ ma”
* 每种类型最多返回6
* 对于 REPORT 和 MAP 类型，最多返回 20 个项目



表：dashboards/q 和dashboards/search 查询参数

| 查询参数 | 描述 | 类型 | 默认 |
|---|---|---|---|
| 计数 | 每种类型要返回的项目数 | 正整数 | 6 |
| 最大计数 | 要返回的最大类型的项目数 | 正整数 | 25 |
| 最大限度 | 返回 maxCount 的类型 | 字符串 [地图&#124;用户&#124;报告&#124;资源&#124;VISUALIZATION#124;EVENT_VISUALIZATION,EVENT_CHART,EVENT_REPORT] | 不适用 |

支持 JSON 和 XML 响应格式。 JSON 格式的响应
将包含对匹配资源的引用和数量
总共找到匹配项，并为每种类型的资源找到匹配项。它会看起来
类似于：

```json
{
  "visualizations": [{
    "name": "ANC: ANC 3 Visits Cumulative Numbers",
    "id": "arf9OiyV7df",
    "type": "LINE"
  }, {
    "name": "ANC: 1st and 2rd trends Monthly",
    "id": "jkf6OiyV7el",
    "type": "PIVOT_TABLE"
  }],
  "eventVisualizations": [{
    "name": "Inpatient: Cases 5 to 15 years this year (case)",
    "id": "TIuOzZ0ID0V",
    "type": "LINE_LIST"
  }, {
    "name": "Inpatient: Cases last quarter (case)",
    "id": "R4wAb2yMLik",
    "type": "LINE_LIST"
  }],
  "maps": [{
    "name": "ANC: 1st visit at facility (fixed) 2013",
    "id": "YOEGBvxjAY0"
  }, {
    "name": "ANC: 3rd visit coverage 2014 by district",
    "id": "ytkZY3ChM6J"
  }],
  "reports": [{
    "name": "ANC: 1st Visit Cumulative Chart",
    "id": "Kvg1AhYHM8Q"
  }, {
    "name": "ANC: Coverages This Year",
    "id": "qYVNH1wkZR0"
  }],
  "searchCount": 8,
  "visualizationCount": 2,
  "eventVisualizationCount": 2,
  "mapCount": 2,
  "reportCount": 2,
  "userCount": 0,
  "eventReports": 0,
  "eventCharts" :0,
  "resourceCount": 0
}
```

### 创建，更新和删除仪表板 { #webapi_creating_updating_removing_dashboards } 

创建、更新和删除仪表板遵循标准 REST
语义。为了创建一个新的仪表板，您可以创建一个 *POST*
请求`/api/dashboards` 资源。从消费者的角度
首先创建仪表板然后添加项目可能会很方便
到它。请求有效负载支持 JSON 和 XML 格式。至
创建一个名为“我的仪表板”的仪表板，您可以在其中使用有效负载
像这样的 JSON：

    {
      “名称”：“我的仪表板”
    }

更新，例如重命名，仪表板，您可以使用 *PUT* 请求
类似的请求负载相同的 api/dashboards 资源。

要删除仪表板，您可以向特定的人发出 *DELETE* 请求
与此类似的仪表板资源：

    / api /仪表板/ vQFhmLJU5sK

### 添加，移动和删除仪表板项目和内容 { #webapi_adding_moving_removing_dashboard_items } 

为了添加仪表板项目，消费者可以使用
`/api/dashboards/ <dashboard-id> /items/content` 资源，其中
 <dashboard-id\> 应替换为相关仪表板
标识符。该请求必须使用 *POST* 方法。 URL 语法和
参数详细说明如下表。



表：项目内容参数

| 查询参数 | 描述 | 选项 |
|---|---|---|
| 类型 | 仪表板项目所代表的资源类型 | 可视化&#124;地图&#124;事件可视化&#124;用户&#124;报告&#124;资源&#124;应用程序 |
| ID | 仪表板项目所代表的资源的标识符 | 资源标识符 |

用于将可视化添加到特定仪表板的 *POST* 请求 URL 可能如下所示，其中最后一个 id 查询参数值是图表资源标识符：

    /api/仪表板/vQFhmLJU5sK/items/content?type=可视化&id=LW0O27b7TdD

添加地图、可视化、APP类型资源时，API
将创建一个新项目并将其添加到仪表板。添加资源时
用户、报告和资源类型，API 将尝试
将资源添加到相同类型的现有仪表板项目。如果不
相同类型的项目或没有相同类型的项目且资源少于八个
与其关联的存在，API 将创建一个新的仪表板项目并
将资源添加到其中。

In order to move a dashboard item to a new position within the list of
items in a dashboard, a consumer can make a *POST* request to the
following resource URL, where `<dashboard-id>` should be replaced by the
identifier of the dashboard, `<item-id>` should be replaced by the
identifier of the dashboard item and `<index>` should be replaced by the
new position of the item in the dashboard, where the index is
zero-based:

    / api /仪表板/ <dashboard-id> / items / <item-id> / position / <index>

要从特定仪表板中完全删除仪表板项目
消费者可以向以下资源 URL 发出 *DELETE* 请求，其中
` <dashboard-id> ` 应替换为仪表板的标识符
和 `<item-id>` 应替换为仪表板的标识符
物品。可以通过 GET 检索仪表板项目标识符
对仪表板资源 URL 的请求。

    / api /仪表板/ <dashboard-id> / items / <item-id>

要删除仪表板项目中的特定内容资源，消费者
可以向以下资源 URL 发出 *DELETE* 请求，其中
` <content-resource-id> ` 应替换为
与仪表板项目关联的资源；例如a 的标识符
报告或用户。例如，这可用于删除单个
报告类型的仪表板项目中的报告，而不是删除
仪表板项目完全：

    / api /仪表板/ <dashboard-id> / items / <item-id> / content / <content-resource-id>

### 定义仪表板布局 { #webapi_dasboard_layout }

您可以定义并保存每个仪表板的布局。以下对象负责保存此设置。

    {
      “布局”： {
        “间距”：{
          “列”：5，
          “行”：5
        },
        “列”： [{
          “索引”：0，
          “跨度”：2
        }, {
          “索引”：1，
          “跨度”：1
        }]
      }
    }

布局定义将应用于与给定仪表板相关的所有仪表板项目，并考虑间距、列、跨度等布局属性。请参阅下面每个属性的简要说明。

表：布局属性

| 属性 | 描述 | 类型 |
|---|---|---|
| 布局 | 这是根对象 | 目的 |
| 间距 | 定义特定布局组件的间距。目前，它支持列和行。 | 目的 |
| 列 | 存储与列相关的特定参数（目前为索引和跨度） | 对象数组 |

## 可视化 { #webapi_visualization } 

Visualization API旨在帮助客户与图表和数据透视表/报表交互。数据可视化应用程序使用此API的端点，该应用程序允许基于客户端的定义创建，配置和管理图表和数据透视表。主要思想是使客户和用户拥有一个独特的集中式API，该API提供所有类型的图表和数据透视表以及每种可视化类型的特定参数和配置。

This API was introduced to unify both `charts` and `reportTables` APIs and entirely replace them by the `visualizations` API.

一个可视化对象由很多属性组成（有些与图表相关，有些与数据透视表相关），但负责反映对象核心信息的最重要的属性是：*"id"、"name"、"type" ”、“dataDimensionItems”、“列”、“行”和“过滤器”。*

API的根端点是`/ api / visualizations`，下表中描述了当前属性和元素的列表。



表：可视化属性

| 领域 | 描述 |
|---|---|
| ID | 唯一标识符。 |
| 码 | 用于识别可视化的自定义代码。 |
| 名称 | 可视化的名称 |
| 类型 | 可视化的类型。有效类型包括：COLUMN、STACKED_COLUMN、BAR、STACKED_BAR、LINE、AREA、PIE、RADAR、GAUGE、YEAR_OVER_YEAR_LINE YEAR_OVER_YEAR_COLUMN、SINGLE_VALUE、PIVOT_TABLE。 |
| 标题 | 自定义标题。 |
| 字幕 | 自定义字幕。 |
| 描述 | 定义可视化的自定义描述。 |
| 已创建 | 可视化创建的日期/时间。 |
| 开始日期 | 过滤期间使用的开始日期。 |
| 结束日期 | 过滤期间使用的结束日期。 |
| 排序 | 此可视化的排序顺序。整数值。 |
| 用户 | 代表可视化创建者的对象。 |
| 公共访问 | 设置公共访问的权限。 |
| 显示密度 | 文本的显示密度。 |
| 字体大小 | 文本的字体大小。 |
| 字体样式 | 自定义字体样式：visualizationTitle、visualizationSubtitle、horizontalAxisTitle、verticalAxisTitle、targetLineLabel、baseLineLabel、seriesAxisLabel、categoryAxisLabel、legend。 |
| 相对时期 | 表示分析查询中使用的相对周期的对象。 |
| legend集 | 代表图例定义的对象。 |
| 图例显示样式 | 图例的显示风格。它可以是：填充或文本。 |
| 图例显示策略 | 图例的显示风格。它可以是：FIXED 或 BY_DATA_ITEM。 |
| 聚合类型 | 确定如何聚合数据透视表中的值。有效选项：SUM、AVERAGE、AVERAGE_SUM_ORG_UNIT、LAST、LAST_AVERAGE_ORG_UNIT、FIRST、FIRST_AVERAGE_ORG_UNIT、COUNT、STDDEV、VARIANCE、MIN、MAX、NONE、CUSTOM 或 DEFAULT。 |
| 回归类型 | 有效的回归类型：NONE、LINEAR、POLYNOMIAL 或 LOESS。 |
| 目标线值 | 图表目标线。接受 Double 类型。 |
| 目标线标签 | 图表目标线标签。 |
| 范围轴标签 | 图表垂直轴 (y) 标签/标题。 |
| 域轴标签 | 图表水平轴 (x) 标签/标题。 |
| 范围轴最大值 | 图表轴最大值。超出范围的值将不会显示。 |
| 范围轴最小值 | 图表轴最小值。超出范围的值将不会显示。 |
| 范围轴步数 | 最小值和最大值之间的轴步数。 |
| 范围轴小数 | 轴值的小数位数。 |
| 基线值 | 图表基线值。 |
| 基线标签 | 图表基线标签。 |
| 数字组分隔符 | 数字组分隔符。有效值：逗号、空格或无。 |
| 上限 | 为数据透视表设置的上限。 |
| 衡量标准 | 描述应用于此测量的标准。 |
| 堆叠值百分比 | 是否使用堆叠值。更有可能应用于图形/图表。布尔值。 |
| 列之间没有空格 | 显示/隐藏列之间的空间。布尔值。 |
| 回归 | 指示可视化是否包含回归列。更有可能适用于数据透视表/报表。布尔值。 |
| 外部访问 | 指示可视化是否可用作外部只读。仅在没有用户登录时适用。布尔值。 |
| 用户组织单位 | 指示用户是否有组织部门。布尔值。 |
| 用户组织单位子级 | 指示用户是否有子组织部门。布尔值。 |
| 用户组织单位孙子 | 指示用户是否有孙组织单位。布尔值。 |
| 报告参数 | 用于定义与报告相关的布尔属性的对象。 |
| 行总计 | 显示（或不显示）行总计。布尔值。 |
| 总计 | 显示（或不显示）列总计。布尔值。 |
| 行小计 | 显示（或不显示）行小计。布尔值。 |
| 列小计 | 显示（或不显示）列小计。布尔值。 |
| 累计值 | 指示可视化是否使用累积值。布尔值。 |
| 隐藏空列 | 指示是否隐藏没有数据值的列。布尔值。 |
| 隐藏空行 | 指示是否隐藏没有数据值的行。布尔值。 |
| 修复列标题 | 使数据透视表中的列标题保持固定（或不固定）。布尔值。 |
| 修复行标题 | 使数据透视表中的行标题保持固定（或不固定）。布尔值。 |
| 仅已完成 | 分析请求中使用的标志。如果为真，则仅考虑已完成的活动/注册。布尔值。 |
| 跳过舍入 | 应用或不应用舍入。布尔值。 |
| 显示维度标签 | 是否显示尺寸标签。布尔值。 |
| 隐藏标题 | 隐藏或不隐藏标题。布尔值。 |
| 隐藏字幕 | 是否隐藏字幕。布尔值。 |
| 隐藏图例 | 显示/隐藏图例。很有可能被图表使用。布尔值。 |
| 显示层次结构 | 显示（或不显示）组织单位层次结构名称。布尔值。 |
| 显示数据 | 图表使用它来隐藏或不隐藏渲染模型中的数据/值。布尔值。 |
| 最后更新者 | 代表对可视化应用最后更改的用户的对象。 |
| 最近更新时间 | 上次更改可视化的日期/时间。 |
| 收藏夹 | 已将此对象标记为收藏夹的用户 ID 列表。 |
| 订户 | 已订阅此可视化的用户 ID 列表。 |
| 翻译 | 可用对象翻译集，通常按区域设置过滤。 |
| 异常值分析 | 负责保留与异常值分析相关的设置的对象。内部属性“outlierMethod”支持：IQR、STANDARD_Z_SCORE、MODIFIED_Z_SCORE。 “normalizationMethod”目前仅接受 Y_RESIDUALS_LINEAR。 |
| 系列键 | 样式选项以及是否显示系列键。 |
| 传说 | 选项以及是否将图例颜色应用于图表系列。 |

### 检索可视化 { #webapi_visualization_retrieving_visualizations } 

To retrieve a list of all existing visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared visualizations plus your private ones.

    获取/api/visualizations.json

如果要检索特定可视化的JSON定义，可以将其各自的标识符添加到URL：

    获取 /api/visualizations/hQxZGXqnLS9.json

以下表示是JSON格式的响应示例（为简便起见，某些信息已被删除）。对于完整的模式，请使用`GET / api / schemas / visualization`。

```json
{
  "lastUpdated": "2020-02-06T11:57:09.678",
  "href": "http://my-domain/dhis/api/visualizations/hQxZGXqnLS9",
  "id": "hQxZGXqnLS9",
  "created": "2017-05-19T17:22:00.785",
  "name": "ANC: ANC 1st visits last 12 months cumulative values",
  "publicAccess": "rw------",
  "userOrganisationUnitChildren": false,
  "type": "LINE",
  "access": {},
  "reportingParams": {
    "parentOrganisationUnit": false,
    "reportingPeriod": false,
    "organisationUnit": false,
    "grandParentOrganisationUnit": false
  },
  "dataElementGroupSetDimensions": [],
  "attributeDimensions": [],
  "yearlySeries": [],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "title": {
        "textMode": "CUSTOM",
        "text": "Any Title"
      }
    }
  ],
  "filterDimensions": [
    "dx"
  ],
  "columns": [
    {
      "id": "ou"
    }
  ],
  "dataElementDimensions": [],
  "categoryDimensions": [],
  "rowDimensions": [
    "pe"
  ],
  "columnDimensions": [
    "ou"
  ],
  "dataDimensionItems": [
    {
      "dataDimensionItemType": "DATA_ELEMENT",
      "dataElement": {
        "id": "fbfJHSPpUQD"
      }
    }
  ],
  "filters": [
    {
      "id": "dx"
    }
  ],
  "rows": [
    {
      "id": "pe"
    }
  ]
}
```
通过在URL中指定要提取的字段，可以获得更定制的响应。即：

    GET /api/visualizations/hQxZGXqnLS9.json?fields=interpretations

将返回

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### 创建，更新和删除可视化 { #webapi_visualization_add_update_remove_visualizations } 

These operations follow the standard *REST* semantics. A new Visualization can be created through a `POST` request to the `/api/visualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
  "columns": [
    {
      "dimension": "J5jldMd8OHv",
      "items": [
        {
          "name": "CHP",
          "id": "uYxK4wmcPqA",
          "displayName": "CHP",
          "displayShortName": "CHP",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        },
        {
          "name": "Hospital",
          "id": "tDZVQ1WtwpA",
          "displayName": "Hospital",
          "displayShortName": "Hospital",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        }
      ]
    }
  ],
  "rows": [
    {
      "dimension": "SooXFOUnciJ",
      "items": [
        {
          "name": "DOD",
          "id": "B0bjKC0szQX",
          "displayName": "DOD",
          "displayShortName": "DOD",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        },
        {
          "name": "CDC",
          "id": "OK2Nr4wdfrZ",
          "displayName": "CDC",
          "displayShortName": "CDC",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        }
      ]
    }
  ],
  "filters": [
    {
      "dimension": "ou",
      "items": [
        {
          "name": "Sierra Leone",
          "id": "ImspTQPwCqd",
          "displayName": "Sierra Leone",
          "displayShortName": "Sierra Leone",
          "dimensionItemType": "ORGANISATION_UNIT"
        },
        {
          "name": "LEVEL-1",
          "id": "LEVEL-H1KlN4QIauv",
          "displayName": "LEVEL-1"
        }
      ]
    }
  ],
  "name": "HIV Cases Monthly",
  "description": "Cases of HIV across the months",
  "category": "XY1vwCQskjX",
  "showDimensionLabels": true,
  "hideEmptyRows": true,
  "hideEmptyColumns": true,
  "skipRounding": true,
  "aggregationType": "SUM",
  "regressionType": "LINEAR",
  "type": "PIVOT_TABLE",
  "numberType": "VALUE",
  "measureCriteria": "Some criteria",
  "showHierarchy": true,
  "completedOnly": true,
  "displayDensity": "NORMAL",
  "fontSize": "NORMAL",
  "digitGroupSeparator": "SPACE",
  "legendDisplayStyle": "FILL",
  "legendDisplayStrategy": "FIXED",
  "hideEmptyRowItems": "BEFORE_FIRST_AFTER_LAST",
  "fixColumnHeaders": true,
  "fixRowHeaders": false,
  "regression": false,
  "cumulative": true,
  "sortOrder": 1,
  "topLimit": 2,
  "rowTotals": true,
  "colTotals": true,
  "hideTitle": true,
  "hideSubtitle": true,
  "hideLegend": true,
  "showData": true,
  "percentStackedValues": true,
  "noSpaceBetweenColumns": true,
  "rowSubTotals": true,
  "colSubTotals": true,
  "userOrgUnitType": "TEI_SEARCH",
  "externalAccess": false,
  "publicAccess": "--------",
  "reportingParams": {
    "reportingPeriod": true,
    "organisationUnit": true,
    "parentOrganisationUnit": true,
    "grandParentOrganisationUnit": true
  },
  "parentGraphMap": {
    "ImspTQPwCqd": ""
  },
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": false,
    "write": true,
    "manage": false
  },
  "optionalAxes": [
    {
      "dimensionalItem": "fbfJHSPpUQD",
      "axis": 1
    },
    {
      "dimensionalItem": "cYeuwXTCPkU",
      "axis": 2
    }
  ],
  "relativePeriods": {
    "thisYear": false,
    "quartersLastYear": true,
    "last52Weeks": false,
    "thisWeek": false,
    "lastMonth": false,
    "last14Days": false,
    "biMonthsThisYear": false,
    "monthsThisYear": false,
    "last2SixMonths": false,
    "yesterday": false,
    "thisQuarter": false,
    "last12Months": false,
    "last5FinancialYears": false,
    "thisSixMonth": false,
    "lastQuarter": false,
    "thisFinancialYear": false,
    "last4Weeks": false,
    "last3Months": false,
    "thisDay": false,
    "thisMonth": false,
    "last5Years": false,
    "last6BiMonths": false,
    "last4BiWeeks": false,
    "lastFinancialYear": false,
    "lastBiWeek": false,
    "weeksThisYear": false,
    "last6Months": false,
    "last3Days": false,
    "quartersThisYear": false,
    "monthsLastYear": false,
    "lastWeek": false,
    "last7Days": false,
    "thisBimonth": false,
    "lastBimonth": false,
    "lastSixMonth": false,
    "thisBiWeek": false,
    "lastYear": false,
    "last12Weeks": false,
    "last4Quarters": false
  },
  "user": {},
  "yearlySeries": [
    "THIS_YEAR"
  ],
  "userGroupAccesses": [
    {
      "access": "rwx-----",
      "userGroupUid": "ZoHNWQajIoe",
      "displayName": "Bo District M&E officers",
      "id": "ZoHNWQajIoe"
    }
  ],
  "userAccesses": [
    {
      "access": "--------",
      "displayName": "John Barnes",
      "id": "DXyJmlo9rge",
      "userUid": "DXyJmlo9rge"
    }
  ],
  "legendSet": {
    "name": "Death rate up",
    "id": "ham2eIDJ9k6",
    "legends": [
      {
        "startValue": 1,
        "endValue": 2,
        "color": "red",
        "image": "some-image"
      },
      {
        "startValue": 2,
        "endValue": 3,
        "color": "blue",
        "image": "other-image"
      }
    ]
  },
  "outlierAnalysis": {
    "enabled": true,
    "outlierMethod": "IQR",
    "thresholdFactor": 1.5,
    "normalizationMethod": "Y_RESIDUALS_LINEAR",
    "extremeLines": {
      "enabled": true,
      "value": 3.5
    }
  },
  "legend": {
    "strategy": "FIXED",
    "style": "FILL",
    "set": {
      "id": "fqs276KXCXi",
      "displayName": "ANC Coverage"
    },
    "showKey": false
  },
  "seriesKey": {
    "hidden": true,
    "label": {
      "fontStyle": {
        "textColor": "#cccddd"
      }
    }
  },
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ]
}
```

要更新特定的可视化，您可以向相同的 `/api/visualizations` 资源发送一个 `PUT` 请求，该资源具有类似的负载 `PLUS` 以及相应的可视化的标识符，即：

    PUT /api/可视化/hQxZGXqnLS9

最后，要删除现有的可视化，您可以发出一个 `DELETE` 请求，指定要删除的可视化的标识符，如下所示：

    删除/ api / visualizations / hQxZGXqnLS9

## 事件可视化 { #webapi_event_visualization }
<!--DHIS2-SECTION-ID:webapi_event_visualization-->
The EventVisualization API is designed to help clients to interact with event charts and reports. The endpoints of this API are used by the Event Visualization application which allows the creation, configuration and management of charts and reports based on the client's definitions. The main idea is to enable clients and users to have a unique and centralized API providing all types of event charts and reports as well as specific parameters and configuration for each type of event visualization.
This API was introduced with the expectation to unify both `eventCharts` and `eventReports` APIs and entirely replace them in favour of the `eventVisualizations` API (which means that the usage of `eventCharts` and `eventReports` APIs should be avoided). In summary, the following resources/APIs:
    /api/eventCharts, /api/eventReports
*are being replaced by*
    /api/eventVisualizations

> **Note**
>
> New applications and clients should avoid using the `eventCharts` and `eventReports` APIs because they are deprecated. Use the `eventVisualizations` API instead.

An EventVisualization object is composed of many attributes (some of them related to charting and others related to reporting), but the most important ones responsible to reflect the core information of the object are: *"id", "name", "type", "dataDimensionItems", "columns", "rows" and "filters".*
The root endpoint of the API is `/api/eventVisualizations`, and the list of current attributes and elements are described in the table below.



表：EventVisualization 属性

| 领域 | 描述 |
|---|---|
| ID | 唯一标识符。 |
| 码 | 用于识别 EventVisualiation 的自定义代码。 |
| 名称 | 事件可视化的名称 |
| 类型 | EventVisualiation 的类型。有效类型包括：COLUMN、STACKED_COLUMN、BAR、STACKED_BAR、LINE、LINE_LIST、AREA、STACKED_AREA、PIE、RADAR、GAUGE、YEAR_OVER_YEAR_LINE、YEAR_OVER_YEAR_COLUMN、SINGLE_VALUE、PIVOT_TABLE、SCATTER、BUBBLE。 |
| 标题 | 自定义标题。 |
| 字幕 | 自定义字幕。 |
| 描述 | 定义 EventVisualiation 的自定义描述。 |
| 已创建 | EventVisualiation 创建的日期/时间。 |
| 开始日期 | 过滤期间使用的开始日期。 |
| 结束日期 | 过滤期间使用的结束日期。 |
| 排序 | 此 EventVisualiation 的排序顺序。整数值。 |
| 用户 | 代表可视化创建者的对象。 |
| 公共访问 | 设置公共访问的权限。 |
| 显示密度 | 文本的显示密度。 |
| 字体大小 | 文本的字体大小。 |
| 相对时期 | 表示分析查询中使用的相对周期的对象。 |
| 传说 | 表示图例和图例集、显示样式（FILL 或 TEXT）和显示策略（FIXED 或 BY_DATA_ITEM）定义的对象。 |
| 聚合类型 | 确定如何聚合值（如果适用）。有效选项：SUM、AVERAGE、AVERAGE_SUM_ORG_UNIT、LAST、LAST_AVERAGE_ORG_UNIT、FIRST、FIRST_AVERAGE_ORG_UNIT、COUNT、STDDEV、VARIANCE、MIN、MAX、NONE、CUSTOM 或 DEFAULT。 |
| 回归类型 | 有效的回归类型：NONE、LINEAR、POLYNOMIAL 或 LOESS。 |
| 目标线值 | 图表目标线。接受 Double 类型。 |
| 目标线标签 | 图表目标线标签。 |
| 范围轴标签 | 图表垂直轴 (y) 标签/标题。 |
| 域轴标签 | 图表水平轴 (x) 标签/标题。 |
| 范围轴最大值 | 图表轴最大值。超出范围的值将不会显示。 |
| 范围轴最小值 | 图表轴最小值。超出范围的值将不会显示。 |
| 范围轴步数 | 最小值和最大值之间的轴步数。 |
| 范围轴小数 | 轴值的小数位数。 |
| 基线值 | 图表基线值。 |
| 基线标签 | 图表基线标签。 |
| 数字组分隔符 | 数字组分隔符。有效值：逗号、空格或无。 |
| 上限 | 为数据透视表设置的上限。 |
| 衡量标准 | 描述应用于此测量的标准。 |
| 堆叠值百分比 | 是否使用堆叠值。更有可能应用于图形/图表。布尔值。 |
| 列之间没有空格 | 显示/隐藏列之间的空间。布尔值。 |
| 外部访问 | 指示 EventVisualization 是否可用作外部只读。布尔值。 |
| 用户组织单位 | 指示用户是否有组织部门。布尔值。 |
| 用户组织单位子级 | 指示用户是否有子组织部门。布尔值。 |
| 用户组织单位孙子 | 指示用户是否有孙组织单位。布尔值。 |
| 行总计 | 显示（或不显示）行总计。布尔值。 |
| 总计 | 显示（或不显示）列总计。布尔值。 |
| 行小计 | 显示（或不显示）行小计。布尔值。 |
| 列小计 | 显示（或不显示）列小计。布尔值。 |
| 累计值 | 指示 EventVisualization 是否使用累积值。布尔值。 |
| 隐藏空行 | 指示是否隐藏没有数据值的行。布尔值。 |
| 仅已完成 | 分析请求中使用的标志。如果为真，则仅考虑已完成的活动/注册。布尔值。 |
| 显示维度标签 | 是否显示尺寸标签。布尔值。 |
| 隐藏标题 | 隐藏或不隐藏标题。布尔值。 |
| 隐藏字幕 | 是否隐藏字幕。布尔值。 |
| 显示层次结构 | 显示（或不显示）组织单位层次结构名称。布尔值。 |
| 显示数据 | 图表使用它来隐藏或不隐藏渲染模型中的数据/值。布尔值。 |
| 最后更新者 | 代表对 EventVisualization 应用最后一次更改的用户的对象。 |
| 最近更新时间 | 上次更改 EventVisualization 的日期/时间。 |
| 收藏夹 | 已将此对象标记为收藏夹的用户 ID 列表。 |
| 订户 | 已订阅此 EventVisualization 的用户 ID 列表。 |
| 翻译 | 可用对象翻译集，通常按区域设置过滤。 |
| 程序 | 相关程序。 |
| 节目阶段 | 相关的程序阶段。 |
| 程序状态 | 程序状态。它可以是活动的、已完成的、已取消的。 |
| 事件状态 | 事件状态。它可以是活动的、已完成的、已访问的、已安排的、逾期的、已跳过的。 |
| 数据类型 | 事件数据类型。它可以是 AGGREGATED_VALUES 或 EVENTS。 |
| 柱尺寸 | 为列定义的尺寸。 |
| 行尺寸 | 为行定义的维度。 |
| 过滤器尺寸 | 为过滤器定义的尺寸。 |
| 输出类型 | 指示EventVisualization 的输出类型。它可以是 EVENT、ENROLLMENT 或 TRACKED_ENTITY_INSTANCE。 |
| 折叠数据维度 | 指示是否将所有数据维度折叠为单个维度。布尔值。 |
| 隐藏NaData | 是否隐藏N/A数据。布尔值。 |

### 检索事件可视化 { #webapi_event_visualization_retrieving_event_visualizations }
<!--DHIS2-SECTION-ID:webapi_event_visualization_retrieving_event_visualizations-->
To retrieve a list of all existing event visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared event visualizations plus your private ones.
    GET /api/eventVisualizations.json
If you want to retrieve the JSON definition of a specific EventVisualization you can add its respective identifier to the URL:
    GET /api/eventVisualizations/hQxZGXqnLS9.json
The following representation is an example of a response in JSON format (for brevity, certain information has been removed). For the complete schema, please use `GET /api/schemas/eventVisualization`.

```json
{
    "lastUpdated": "2021-11-25T17:18:03.834",
    "href": "http://localhost:8080/dhis/api/eventVisualizations/EZ5jbRTxRGh",
    "id": "EZ5jbRTxRGh",
    "created": "2021-11-25T17:18:03.834",
    "name": "Inpatient: Mode of discharge by facility type this year",
    "publicAccess": "rw------",
    "userOrganisationUnitChildren": false,
    "type": "STACKED_COLUMN",
    "subscribed": false,
    "userOrganisationUnit": false,
    "rowSubTotals": false,
    "cumulativeValues": false,
    "showDimensionLabels": false,
    "sortOrder": 0,
    "favorite": false,
    "topLimit": 0,
    "collapseDataDimensions": false,
    "userOrganisationUnitGrandChildren": false,
    "displayName": "Inpatient: Mode of discharge by facility type this year",
    "percentStackedValues": false,
    "noSpaceBetweenColumns": false,
    "showHierarchy": false,
    "hideTitle": false,
    "showData": true,
    "hideEmptyRows": false,
    "hideNaData": false,
    "regressionType": "NONE",
    "completedOnly": false,
    "colTotals": false,
    "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {},
      "public": "rw------"
    },
    "programStatus": "CANCELLED",
    "hideEmptyRowItems": "NONE",
    "hideSubtitle": false,
    "outputType": "EVENT",
    "hideLegend": false,
    "externalAccess": false,
    "colSubTotals": false,
    "rowTotals": false,
    "digitGroupSeparator": "SPACE",
    "program": {
      "id": "IpHINAT79UW"
    },
    "access": {
      "read": true,
      "update": true,
      "externalize": true,
      "delete": true,
      "write": true,
      "manage": true
    },
    "lastUpdatedBy": {
      "displayName": "John Traore",
      "name": "John Traore",
      "id": "xE7jOejl9FI",
      "username": "admin"
    },
    "relativePeriods": {
      "thisYear": false,
      ...
    },
    "programStage": {
      "id": "A03MvHHogjR"
    },
    "createdBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "attributeDimensions": [],
    "translations": [],
    "legend": {
      "set": {
        "id": "gFJUXah1uRH"
      },
      "showKey": false,
      "style": "FILL",
      "strategy": "FIXED"
    },
    "filterDimensions": [
      "ou",
      "H6uSAMO5WLD"
    ],
    "interpretations": [],
    "userGroupAccesses": [],
    "subscribers": [],
    "columns": [
      {
        "id": "X8zyunlgUfM"
      }
    ]
    "periods": [],
    "categoryDimensions": [],
    "rowDimensions": [
      "pe"
    ],
    "itemOrganisationUnitGroups": [],
    "programIndicatorDimensions": [],
    "attributeValues": [],
    "columnDimensions": [
      "X8zyunlgUfM"
    ],
    "userAccesses": [],
    "favorites": [],
    "dataDimensionItems": [],
    "categoryOptionGroupSetDimensions": [],
    "organisationUnitGroupSetDimensions": [],
    "organisationUnitLevels": [],
    "organisationUnits": [
      {
        "id": "ImspTQPwCqd"
      }
    ],
    "filters": [
      {
        "id": "ou"
      },
      {
        "id": "H6uSAMO5WLD"
      }
    ],
    "rows": [
      {
        "id": "pe"
      }
    ]
}
```

通过在 URL 中指定要提取的字段，可以获得更定制的响应。 IE。：
    GET /api/eventVisualizations/hQxZGXqnLS9.json?fields=interpretations
将返回

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### 创建、更新和删除事件可视化 { #webapi_event_visualization_add_update_remove_event_visualizations }
<!--DHIS2-SECTION-ID:webapi_event_visualization_add_update_remove_event_visualizations-->
These operations follow the standard *REST* semantics. A new EventVisualization can be created through a `POST` request to the `/api/eventVisualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
    "name": "Inpatient: Cases under 10 years last 4 quarters",
    "publicAccess": "rw------",
    "userOrganisationUnitChildren": false,
    "type": "STACKED_COLUMN",
    "subscribed": false,
    "userOrganisationUnit": false,
    "rowSubTotals": false,
    "cumulativeValues": false,
    "showDimensionLabels": false,
    "sortOrder": 0,
    "favorite": false,
    "topLimit": 0,
    "collapseDataDimensions": false,
    "userOrganisationUnitGrandChildren": false,
    "displayName": "Inpatient: Cases under 10 years last 4 quarters",
    "percentStackedValues": false,
    "noSpaceBetweenColumns": false,
    "showHierarchy": false,
    "hideTitle": false,
    "showData": true,
    "hideEmptyRows": false,
    "userAccesses": [],
    "userGroupAccesses": [],
    "hideNaData": false,
    "regressionType": "NONE",
    "completedOnly": false,
    "colTotals": false,
    "programStatus": "CANCELLED",
    "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {},
      "public": "rw------"
    },
    "displayFormName": "Inpatient: Cases under 10 years last 4 quarters",
    "hideEmptyRowItems": "NONE",
    "hideSubtitle": false,
    "outputType": "EVENT",
    "hideLegend": false,
    "externalAccess": false,
    "colSubTotals": false,
    "rowTotals": false,
    "digitGroupSeparator": "SPACE",
    "access": {
      "read": true,
      "update": true,
      "externalize": false,
      "delete": true,
      "write": true,
      "manage": true
    },
    "lastUpdatedBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "legend": {
      "set": {
        "id": "gFJUXah1uRH"
      },
      "showKey": false,
      "style": "FILL",
      "strategy": "FIXED"
    },
    "relativePeriods": {
      "thisYear": false,
    ...
    },
    "program": {
      "id": "IpHINAT79UW",
      "enrollmentDateLabel": "Date of enrollment",
      "incidentDateLabel": "Date of birth",
      "name": "Child Programme"
    },
    "programStage": {
      "id": "A03MvHHogjR",
      "executionDateLabel": "Report date",
      "name": "Birth"
    },
    "createdBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "translations": [],
    "filterDimensions": [
      "ou"
    ],
    "interpretations": [],
    "dataElementDimensions": [
      {
        "filter": "LE:10",
        "dataElement": {
          "id": "qrur9Dvnyt5"
        }
      }
    ],
    "periods": [],
    "categoryDimensions": [],
    "rowDimensions": [
      "pe"
    ],
    "columnDimensions": [
      "qrur9Dvnyt5"
    ],
    "organisationUnits": [
      {
        "id": "ImspTQPwCqd"
      }
    ],
    "filters": [
      {
        "dimension": "ou",
        "items": [
          {
            "id": "ImspTQPwCqd"
          }
        ]
      },
      {
        "dimension": "H6uSAMO5WLD",
        "items": []
      }
    ],
    "columns": [
      {
        "dimension": "X8zyunlgUfM",
        "items": [],
        "repetition": {
          "indexes": [1, 2, 3, -2, -1, 0]
        }
      },
      {
        "dimension": "eventDate",
        "items": [
          {
            "id": "2021-07-21_2021-08-01"
          },
          {
            "id": "2021-01-21_2021-02-01"
          }
        ]
      },
      {
        "dimension": "incidentDate",
        "items": [
          {
            "id": "2021-10-01_2021-10-30"
          }
        ]
      },
      {
        "dimension": "eventStatus",
        "items": [
          {
            "id": "ACTIVE"
          },
          {
            "id": "COMPLETED"
          }
        ]
      },
      {
        "dimension": "createdBy",
        "items": [
          {
            "id": "userA"
          }
        ]
      },
      {
        "dimension": "lastUpdatedBy",
        "items": [
          {
            "id": "userB"
          }
        ]
      }
    ],
    "rows": [
      {
        "dimension": "pe",
        "items": [
          {
              "id": "LAST_12_MONTHS"
          }
        ]
      }
    ]
}
```

> **Note**
>
> The `repetition` attribute (in `rows`, `columns` or `filters`) indicates the events indexes to be retrieved. Taking the example above (in the previous `json` payload), it can be read as follows:
> 
    1 = First event
    2 = Second event
    3 = Third event
    ...
    -2 = Third latest event
    -1 = Second latest event
    0 = Latest event (default)

To update a specific EventVisualization, you can send a `PUT` request to the same `/api/eventVisualizations` resource with a similar payload `PLUS` the respective EventVisualization's identifier, ie.:
    PUT /api/eventVisualizations/hQxZGXqnLS9
Finally, to delete an existing EventVisualization, you can make a `DELETE` request specifying the identifier of the EventVisualization to be removed, as shown:
    DELETE /api/eventVisualizations/hQxZGXqnLS9

## 释义 { #webapi_interpretations } 

对于 DHIS2 中与数据分析相关的资源，例如可视化、地图、事件报告、事件图表甚至可视化，您可以编写和共享数据解释。解释可以是对数据报告或可视化的评论、问题、观察或解释。

    / api /解释

### 阅读口译 { #webapi_reading_interpretations } 

为了阅读解释，我们将与
`/api/interpretations` 资源。使用字段的典型 GET 请求
过滤可以是这样的：

    GET /api/interpretations?fields=*,comments[id,text,user,mentions]

JSON 响应格式的输出可能如下所示（附加
为简洁起见省略了字段）：

```json
{
  "interpretations": [
    {
      "id": "XSHiFlHAhhh",
      "created": "2013-05-30T10:24:06.181+0000",
      "text": "Data looks suspicious, could be a data entry mistake.",
      "type": "MAP",
      "likes": 2,
      "user": {
        "id": "uk7diLujYif"
      },
      "reportTable": {
        "id": "LcSxnfeBxyi"
      },
      "visualization": {
        "id": "LcSxnfeBxyi"
      }
    }, {
      "id": "kr4AnZmYL43",
      "created": "2013-05-29T14:47:13.081+0000",
      "text": "Delivery rates in Bo looks high.",
      "type": "VISUALIZATION",
      "likes": 3,
      "user": {
        "id": "uk7diLujYif"
      },
      "visualization": {
        "id": "HDEDqV3yv3H"
      },
      "mentions": [
        {
          "created": "2018-06-25T10:25:54.498",
          "username": "boateng"
        }
      ],
      "comments": [
        {
          "id": "iB4Etq8yTE6",
          "text": "This report indicates a surge.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "iB4Etq8yTE6",
          "text": "Likely caused by heavy rainfall.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "SIjkdENan8p",
          "text": "Have a look at this @boateng.",
          "user": {
            "id": "xE7jOejl9FI"
          },
          "mentions": [
            {
              "created": "2018-06-25T10:03:52.316",
              "username": "boateng"
            }
          ]
        }
      ]
    }
  ]
}
```



表：解释字段

| 领域 | 描述 |
|---|---|
| ID | 解释标识符。 |
| 已创建 | 创建解释的时间。 |
| 类型 | The type of analytical object being interpreted. Valid options: VISUALIZATION, MAP, EVENT_REPORT, EVENT_CHART, EVENT_VISUALIZATION, DATASET_REPORT. |
| 用户 | 与创建解释的用户的关联。 |
| 可视化 | 如果类型为 VISUALIZATION，则与可视化关联 |
| 事件可视化 | 如果类型为 EVENT_VISUALIZATION，则与事件可视化关联 |
| 地图 | 如果类型是 MAP，则与地图关联。 |
| 事件报告 | 与事件报告关联的类型是 EVENT_REPORT。 |
| 事件图 | 如果类型为 EVENT_CHART，则与事件图表关联。 |
| 数据集 | 如果类型为 DATASET_REPORT，则与数据集关联。 |
| 评论 | 用于解释的注释数组。文本字段包含实际的评论。 |
| 提及 | 解释的一系列提及。用户标识符列表。 |

对于所有分析对象，您可以将 */data* 附加到 URL 以检索
与资源关联的数据（相对于元数据）。作为
一个例子，通过跟随地图链接并附加 /data 可以
通过检索主题地图的 PNG（图像）表示
以下网址：

    https://play.dhis2.org/demo/api/maps/bhmHJ4ZCdCd/data

对于所有分析对象，您可以通过*提及*进行过滤。检索所有
您提到的用户的解释/评论
三个选项。您可以通过解释提及（提及
在解释中
    描述）：

    GET /api/interpretations?fields=*,comments[*]&filter=mentions.username:in:[boateng]

您可以通过解释评论提及（在任何
评论）：

    GET / api / interpretations？fields = *，评论[*]
      ＆filter = comments.mentions.username：in：[boateng]

您可以按包含提及的解释进行过滤
在解释或任何评论中（或结点）：

    GET /api/interpretations?fields=*,comments[*]&filter=mentions:in:[boateng]

### 写作解释 { #webapi_writing_interpretations } 

在编写解释时，您将提供解释文本作为
使用内容类型为“text/plain”的 POST 请求的请求正文。
URL 模式如下所示，其中 {object-type} 指的是
被解释的对象的类型，{object-id} 指的是
被解释对象的标识符。

    / api / interpretations / {object-type} / {object-id}

对象类型的有效选项为*可视化*、*地图*、
*eventReport*、*eventChart*、*eventVisualization* 和 *dataSetReport*。

下面列出了一些有效的解释示例。

> **Note**
>
> The `eventCharts` and `eventReports` APIs are deprecated. We recommend using the `eventVisualizations` API instead.

    /api/解释/可视化/hQxZGXqnLS9
    /api/interpretations/map/FwLHSMCejFu
    /api/interpretations/eventReport/xJmPLGP3Cde
    /api/interpretations/eventChart/nEzXB2M9YBz
    /api/interpretations/eventVisualization/nEzXB2M9YBz
    /api/interpretations/dataSetReport/tL7eCjmDIgM

As an example, we will start by writing an interpretation for the visualization with identifier *EbRN2VIbPdV*. To write visualization interpretations we will interact with the `/api/interpretations/visualization/{visualizationId}` resource.
The interpretation will be the request body. Based on this we can put
together the following request using cURL:

```bash
curl -d "This visualization shows a significant ANC 1-3 dropout" -X POST
  "https://play.dhis2.org/demo/api/interpretations/visualization/EbRN2VIbPdV" -H "Content-Type:text/plain" -u admin:district
```

请注意，响应提供了一个带有值的 Location 标头
指示创建的解释的位置。这很有用
从客户的角度来看，当您想向
解释。

### 更新和删除解释 { #webapi_updating_removing_interpretations } 

要更新现有解释，您可以使用 PUT 请求，其中
解释文本是使用以下 URL 模式的请求正文，
其中 {id} 指的是解释标识符：

    / api / interpretations / {id}

基于此，我们可以使用curl来更新解释：

```bash
curl -d "This visualization shows a high dropout" -X PUT
  "https://play.dhis2.org/demo/api/interpretations/visualization/EV08iI1cJRA" -H "Content-Type:text/plain" -u admin:district
```

您可以使用与上面相同的 URL 模式使用 DELETE 请求来
删除解释。

### 创建解释注释 { #webapi_creating_interpretation_comments } 

在为解释撰写评论时，您将提供评论
text 作为使用内容类型的 POST 请求的请求正文
“文本/纯文本”。 URL 模式如下所示，其中
{interpretation-id} 指的是解释标识符。

    / api / interpretations / {interpretation-id} /评论

其次，我们将对我们在
上面的例子。通过查看解释响应，您将看到
返回一个 *Location* 标头。这个标题告诉我们的 URL
新创建的解释，从中我们可以阅读它的
标识符。此标识符是随机生成的，因此您必须
用您自己的命令替换下面命令中的那个。写评论
我们可以与`/api/interpretations/{id}/comments`进行交互
像这样的资源：

```bash
curl -d "An intervention is needed" -X POST
  "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments"
  -H "Content-Type:text/plain" -u admin:district
```

### 更新和删除解释注释 { #webapi_updating_removing_interpretation_comments } 

要更新解释注释，您可以使用 PUT 请求，其中
评论文本是使用以下 URL 模式的请求正文：

    / api / interpretations / {interpretation-id} / comments / {comment-id}

基于此，我们可以使用curl来更新注释：

```bash
curl "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments/idAzzhVWvh2"
  -d "I agree with that." -X PUT -H "Content-Type:text/plain" -u admin:district
```

您可以使用与上面相同的 URL 模式，使用 DELETE 请求到
删除解释注释。

### 喜欢的解释 { #webapi_liking_interpretations } 

要喜欢一个解释，你可以使用一个空的 POST 请求到
*喜欢*资源：

    POST / api / interpretations / {id} / like

将为当前经过身份验证的用户添加一个赞。一个用户可以
只喜欢解释一次。

要删除解释的赞，您可以使用 DELETE 请求
与类似操作相同的资源。

可以通过查看解释的类似状态来查看
常规 Web API 表示：

    GET /api/interpretations/{id}

在 *likes* 字段中可以找到喜欢的信息，它代表
喜欢的数量，以及 *likedBy* 数组，它枚举了喜欢的用户
喜欢这个解释。

```json
{
  "id": "XSHiFlHAhhh",
  "text": "Data looks suspicious, could be a data entry mistake.",
  "type": "VISUALIZATION",
  "likes": 2,
  "likedBy": [
    {
      "id": "k7Hg12fJ2f1"
    },
    {
      "id": "gYhf26fFkjFS"
    }
  ]
}
```
## SQL视图 { #webapi_sql_views } 

SQL 视图资源允许您创建和检索结果集
SQL 视图。 SQL 视图可以直接针对
数据库并通过 Web API 资源呈现结果集。

    / api / sqlViews

SQL 视图对于创建可能更容易的数据视图很有用
用SQL构造比较结合Web的多个对象
应用程序接口。举个例子，假设我们被要求提供一个视图
所有组织单位及其名称、父名称、组织单位
级别和名称，以及数据库中列出的坐标。风景
可能看起来像这样：

``sql
选择 ou.name 作为 orgunit，par.name 作为父级，ou.coordinates，ous.level，oul.name
来自组织单位 ou
ou.organizationunitid = ous.organizationunitid 上的内连接 _orgunitstruct ous
内连接 ou.parentid = par.organizationunitid 上的organizationunit par
内连接 orgunitlevel oul on ous.level = oul.level
其中 ou.coordinates 不为空
按 oul.level、par.name、ou.name 排序；
````

我们将使用 *curl* 首先在 DHIS2 服务器上执行视图。这
本质上是一个物化过程，并确保我们拥有
检索时可通过 SQL 视图获得的最新数据
从服务器。您可以先从 SQL 视图中查找
api/sqlViews 资源，然后使用以下命令进行 POST：

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/execute" -X POST -u admin:district
```

该过程的下一步是检索数据。端点位于：

    /api/sqlViews/{id}/data(.csv)

The `id` path represents the SQL view identifier. The path extensions refers to the format of the data download. Append either `data` for JSON data or `data.csv` for comma separated  values. Support response formats are json, xml, csv, xls, html and html+css. 

例如，以下命令将为上面定义的 SQL 视图检索 CSV 数据。

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv" -u admin:district
```

SQL视图有三种类型：

  - *SQL 视图：* 标准 SQL 视图。

  - *物化的SQL视图：*物化的SQL视图，意思是
    写入磁盘。需要更新以反映变化
    底层表。支持过滤结果集的标准。

  - *SQL 查询：* 普通 SQL 查询。支持内联变量
    自定义查询。

### 标准 { #webapi_sql_view_criteria } 

您可以通过以下方式对结果集中的列进行简单过滤
使用列名将 *criteria* 查询参数附加到 URL
并过滤由列分隔的值作为参数值，在
以下格式：

    / api / sqlViews / {id} / data？criteria = col1：value1＆criteria = col2：value2

举个例子，要过滤上面的SQL视图结果集，只返回
在级别 4 的组织单位中，您可以使用以下 URL：

    https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv?criteria=level:4

### 变数 { #webapi_sql_view_variables } 

SQL 视图支持变量替换。变量替换只是
可用于 *query* 类型的 SQL 视图，这意味着 SQL 视图不是
在数据库中创建，但只是作为常规 SQL 查询执行。
变量可以直接插入到 SQL 查询中，并且必须在
这种格式：

    $ {variable-key}

例如，检索给定的所有数据元素的 SQL 查询
通过变量定义值类型的值类型可以看
像这样：

    从dataelement中选择*，其中valuetype ='$ {valueType}';

然后可以在请求时将这些变量作为 URL 的一部分提供
通过 *sqlViews* Web API 资源。可以提供变量
以下格式：

    / api / sqlViews / {id} / data？var = key1：value1＆var = key2：value2

与上面的示例相对应的示例查询如下所示：

    /api/sqlViews/dI68mLkP1wN/data.json?var=valueType:int

*valueType* 变量将替换为 *int* 值，并且
查询将返回具有 int 值类型的数据元素。

变量参数必须仅包含字母数字字符。这
变量必须包含字母数字、破折号、下划线和空格
仅字符。

*query* 类型的 SQL 视图还支持两个系统定义的变量，这些变量允许查询访问有关执行视图的用户的信息：

| 变量 | 手段 |
| -------- | ----- |
| ${_current_user_id} | 用户的数据库ID |
| ${_current_username} | 用户的用户名 |

这些变量的值不能作为URL的一部分提供。它们始终充满有关用户的信息。

例如，以下 *query* 类型的 SQL 视图显示分配给用户的所有组织单位：

``sql
选择ou.路径，ou.名称
来自组织单位 ou_user
在 ou.path 上加入组织单位 ou，如 ou_user.path || '%'
在 um.organizationunitid = ou_user.organizationunitid 上加入用户会员 um
其中 um.userinfoid = ${_current_user_id}
按 ou.path 排序；
````

### 筛选 { #webapi_sql_view_filtering } 

SQL视图API支持数据过滤，相当于[元数据object_filter](#webapi_metadata_object_filter)。有关过滤器运算符的完整列表，您可以查看 [metadata object_filter](#webapi_metadata_object_filter) 的文档。

要使用过滤器，只需将它们作为参数添加到 SQL 视图的请求 URL 末尾，如下所示。此请求将返回一个结果，其中包括组织单位层次结构第 2 级名称中带有“bo”的组织单位：

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:eq:2&filter=orgunit_name:ilike:bo

以下示例将返回所有带有 `orgunit_level` 2 或
4：

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:in:[2,4]

最后，返回所有不以“Bo”开头的组织单位的示例：

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_name:!like:Bo


## 数据项 { #webapi_data_items } 

This endpoint allows the user to query data related to a few different dimensional items. These items are: `INDICATOR`, `DATA_ELEMENT`, `DATA_SET`, `PROGRAM_INDICATOR`, `PROGRAM_DATA_ELEMENT`, `PROGRAM_ATTRIBUTE`. The endpoint supports only `GET` requests and, as other endpoints, can return responses in JSON or XML format.

该URL是`/ api / dataItems`，并且可以想象，它能够在同一`GET`请求中通过同一端点检索不同的对象。因此，某些可用的可查询属性将根据要查询的维项目而有所不同。

为了理解上面的陈述，让我们看一下以下请求示例：

1)`GET /api/dataItems?filter=dimensionItemType:eq:DATA_ELEMENT&filter=valueType:eq:TEXT`
在这个例子中，项目类型`DATA_ELEMENT` 有一个`valueType` 属性，可以在查询中使用。

2) `GET /api/dataItems?pageSize=50&order=displayName:asc&filter=dimensionItemType:eq:PROGRAM_INDICATOR&filter=displayName:ilike:someName&filter=programId:eq:WSGAb5XwJ3Y`

Here, the `PROGRAM_INDICATOR` allows filtering by `programId`.

So, based on the examples `1)` and `2)` if you try filtering a `DATA_ELEMENT` by `programId` or filter a `PROGRAM_INDICATOR` by `valueType`, you should get no results.
In other words, the filter will be applied only when the attribute actually exists for the respective data item.

需要强调的另一个重要方面是，此端点不遵循与其他现有端点相同的查询标准，例如[元数据对象过滤器](#webapi_metadata_object_filter)。因此，它支持较小的功能和查询集。
其主要原因是需要查询具有不同关系的多个不同项目，这是使用现有的过滤组件（由其他端点使用）不可能实现的。

### 端点响应 { #webapi_data_items_possible_responses }

基于`GET`请求/查询，可以返回以下状态代码和响应。

#### 找到结果（状态代码 200）{ #results-found-status-code-200 }

```json
{
  "pager": {
    "page": 1,
    "pageCount": 27,
    "total": 1339,
    "pageSize": 50
  },
  "dataItems": [
    {
      "simplifiedValueType": "TEXT",
      "displayName": "TB program Gender",
      "displayShortName": "TB prog. Gen.",
      "valueType": "TEXT",
      "name": "TB program Gender",
      "shortName": "TB prog Gen",
      "id": "ur1Edk5Oe2n.cejWyOfXge6",
      "programId": "ur1Edk5Oe2n",
      "dimensionItemType": "PROGRAM_ATTRIBUTE"
    }
  ]
}
```

#### 未找到结果（状态代码 200）{ #results-not-found-status-code-200 }

```json
{
  "pager": {
    "page": 1,
    "pageCount": 1,
    "total": 0,
    "pageSize": 50
  },
  "dataItems": [
  ]
}
```

#### 无效查询（状态代码 409）{ #invalid-query-status-code-409 }

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Unable to parse element `INVALID_TYPE` on filter dimensionItemType`. The values available are: [INDICATOR, DATA_ELEMENT, DATA_ELEMENT_OPERAND, DATA_SET, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE]",
  "errorCode": "E2016"
}
```

### 分页 { #webapi_data_items_pagination } 

This endpoint also supports pagination as a default option. If needed, you can disable pagination by adding `paging=false` to the `GET` request, i.e.: `/api/dataItems?filter=dimensionItemType:in:[INDICATOR]&paging=false`.

这是启用分页时的有效负载示例。请记住，分页是默认选项，不需要显式设置。

```json
{
  "pager": {
    "page": 1,
    "pageCount": 20,
    "total": 969,
    "pageSize": 50
  },
  "dataItems": [...]
}
```

> **Note**
>
> For elements where there is an associated Program, the program name should also be returned as part of the element name (as a prefix). The only exception is `Program Indicators`. We will not prefix the element name in this case, in order to keep the same behavior as existing endpoints.
>
> The /dataItems endpoint will bring only data items that are defined as aggregatable type. The current list of valid aggregatable types is:
`TEXT, LONG_TEXT`, `LETTER`, `BOOLEAN`, `TRUE_ONLY`, `NUMBER`, `UNIT_INTERVAL`, `PERCENTAGE`, `INTEGER`, `INTEGER_POSITIVE`, `INTEGER_NEGATIVE`, `INTEGER_ZERO_OR_POSITIVE`, `COORDINATE`.
>
> Even though the response returns several different attributes, the filtering can only be applied to specific ones: `displayName`, `name`, `valueType`, `id`, `dimensionItemType`, `programId`.
>
> The `order` will be considered invalid if it is set on top of `name` (ie.: order=*name:asc*) and a `filter` is set to `displayName` (ie.: filter=*displayName:ilike:aName*), and vice-versa.

### 响应属性 { #webapi_data_items_response_attributes } 

现在，我们已经了解了此端点的主要功能和用法，让我们看一下响应中返回的属性列表。

表：数据项属性

| 领域 | 描述 |
|---|---|
| ID | 唯一标识符。 |
| 码 | 用于识别维度项目的自定义代码。 |
| 名称 | 为该项目指定的名称。 |
| 显示名称 | 定义的显示名称。 |
| 简称 | 为该项目指定的简称。 |
| 显示简称 | 定义的显示短名称。 |
| 维度项目类型 | 尺寸类型。可能的类型：INDICATOR、DATA_ELEMENT、REPORTING_RATE、PROGRAM_INDICATOR、PROGRAM_DATA_ELEMENT、PROGRAM_ATTRIBUTE。 |
| 值类型 | 项目值类型（更具体的定义）。可能的类型：TEXT、LONG_TEXT、LETTER、BOOLEAN、TRUE_ONLY、UNIT_INTERVAL、PERCENTAGE、INTEGER、INTEGER_POSITIVE、INTEGER_NEGATIVE、INTEGER_ZERO_OR_POSITIVE、COORDINATE |
| 简化值类型 | The genereal representation of a value type. Valid values: NUMBER, BOOLEAN, DATE, FILE_RESOURCE, COORDINATE, TEXT |
| 节目编号 | 关联的programId。 |

## 查看分析性资源表示 { #webapi_viewing_analytical_resource_representations } 

DHIS2 has several resources for data analysis. These resources include
*maps*, *visualizations*, *eventVisualizations*, *reports* and *documents*. By visiting these resources you will retrieve information about the resource. For instance, by navigating to `/api/visualizations/R0DVGvXDUNP` the response will contain the name, last date of modification and so on for the chart. To retrieve the analytical representation, for instance, a PNG representation of the visualization, you can append */data* to all these resources. For instance, by visiting `/api/visualizations/R0DVGvXDUNP/data` the system will return a PNG image of the visualization.

表：分析资源

| 资源 | 描述 | 数据网址 | 资源表示 |
|---|---|---|---|
| 事件图表 | 活动图 | /api/eventCharts/ <identifier\> /data | PNG |
| 地图 | 地图 | /api/maps/ <identifier\> /data | PNG |
| 可视化 | 数据透视表和图表 | /api/可视化/ <identifier\> /data | json &#124; jsonp &#124; html &#124; xml &#124; pdf &#124; xls &#124;数据集
| 事件可视化 | 活动图 | /api/eventVisualizations/ <identifier\> /data | PNG
| PNG |
| 报告 | 标准报告 | /api/reports/ <identifier\> /data | pdf &#124; xls &#124; html |
| 文件 | 资源资源 | /api/documents/ <identifier\> /data |  <follows document\> |

解析表示的数据内容可以通过以下方式修改
提供 *date* 查询参数。这就要求分析
为期间维度的相对期间设置资源。

表：数据查询参数

| 查询参数 | 值 | 描述 |
|---|---|---|
| 日期 | yyyy-MM-dd 格式的日期 | 报告中相对期间的基础（需要相对期间） |

表：png/图像类型的查询参数（可视化、地图）

| 查询参数 | 描述 |
|---|---|
| 宽度 | 图像的宽度（以像素为单位） |
| 高度 | 图像的高度（以像素为单位） |

用于检索各种分析的有效 URL 的一些示例
代表如下。

    /api/可视化/R0DVGvXDUNP/数据
    /api/可视化/R0DVGvXDUNP/data?date=2013-06-01

    /api/visualizations/jIISuEWxmoI/data.html
    /api/visualizations/jIISuEWxmoI/data.html?date=2013-01-01
    /api/可视化/FPmvWs7bn2P/data.xls
    /api/visualizations/FPmvWs7bn2P/data.pdf

    /api/eventVisualizations/x5FVFVt5CDI/data
    /api/eventVisualizations/x5FVFVt5CDI/data.png

    /api/maps/DHE98Gsynpr/数据
    /api/maps/DHE98Gsynpr/data?date=2013-07-01

    /api/reports/OeJsA6K1Otx/data.pdf
    /api/reports/OeJsA6K1Otx/data.pdf?date=2014-01-01



# 分析工具 { #analytics } 

## 分析工具 { #webapi_analytics } 

要访问 DHIS2 中的分析汇总数据，您可以使用
*分析*资源。分析资源非常强大，因为它可以让您
查询和检索沿所有可用数据维度聚合的数据。
例如，您可以要求分析资源提供
一组数据元素、时间段和
组织单位。此外，您可以检索聚合数据
基于数据元素的任意数量维度的组合和
组织单位组集。

    /api/分析

### 请求查询参数 { #webapi_analytics_query_parameters } 

分析资源可让您指定一系列查询参数：



表：查询参数

| 查询参数 | 需要 | 描述 | 选项（默认为默认） |
|---|---|---|---|
| 方面 | 是的 | 要检索的维度和维度项目，每个维度都重复。 | 任何维度 |
| 筛选 | 不 | 应用于查询的过滤器和过滤项，对每个过滤器和过滤项重复。 | 任何维度 |
| 聚合类型 | 不 | 聚合过程中使用的聚合类型。 | 总和＆#124;平均水平AVERAGE_SUM_ORG_UNIT &#124;最后&#124; LAST_AVERAGE_ORG_UNIT &#124;计数&#124;标准差值方差&#124;敏&#124;最大限度 |
| 衡量标准 | 不 | 过滤数据/度量。 | 情商&#124; GT&#124;通用电气LT&#124; LE |
| 预聚合测量标准 | 不 | 数据/度量的过滤器，在执行聚合之前应用。 | 情商&#124; GT&#124;通用电气LT&#124; LE |
| 开始日期 | 不 | 日期范围的开始日期。将用作过滤器。不能与周期维度或过滤器一起使用。 | 日期 |
| 结束日期 | 不 | 日期范围的结束日期。将用作过滤器。不能与周期维度或过滤器一起使用。 | 日期 |
| 跳过元数据 | 不 | 排除响应的元数据部分（提高性能）。 | 假的&#124;真的 |
| 跳过数据 | 不 | 排除响应的数据部分。 | 假的&#124;真的 |
| 跳过舍入 | 不 | 跳过数据值的舍入，即提供完整的精度。 | 假的&#124;真的 |
| 层级元 | 不 | 在元数据中包括组织单位祖先的名称和组织单位的层次结构路径。 | 假的&#124;真的 |
| 忽略限制 | 不 | 忽略响应中最多 50 000 条记录的限制 - 谨慎使用。 | 假的&#124;真的 |
| 表格布局 | 不 | 使用纯数据源或表布局进行响应。 | 假的&#124;真的 |
| 隐藏空行 | 不 | 隐藏响应中的空行，适用于表布局为 true 的情况。 | 假的&#124;真的 |
| 隐藏空列 | 不 | 隐藏响应中的空列，适用于表布局为 true 的情况。 | 假的&#124;真的 |
| 显示层次结构 | 不 | 显示完整的组织单位层次结构路径以及组织单位名称。 | 假的&#124;真的 |
| 包含编号 | 不 | 包括用于计算响应中的值的分子和分母。 | 假的&#124;真的 |
| 包含元数据详细信息 | 不 | 将元数据详细信息包含到原始数据响应中。 | 假的&#124;真的 |
| 显示属性 | 不 | 要显示元数据的属性。 | 姓名 &#124;简称 |
| 输出IdScheme | 不 | 用于查询响应中元数据项的标识符方案。它接受标识符、代码或属性。 | UID &#124; UUID &#124;代码&#124;姓名 &#124;属性：<ID\> |
| 输出组织单位 ID 方案 | 不 | 用于查询响应中元数据项的标识符方案。此参数会覆盖专门用于组织单位的“outputIdScheme”。它接受标识符、代码或属性。 | UUID &#124;代码&#124;姓名 &#124;属性：<ID\> |
| 输出数据元素Id方案 | 不 | 用于查询响应中元数据项的标识符方案。此参数会覆盖专门针对数据元素的“outputIdScheme”。它接受标识符、代码或属性。 | UUID &#124;代码&#124;姓名 &#124;属性：<ID\> |
| 输入IdScheme | 不 | 用于查询请求中的元数据项的标识符方案可以是标识符、代码或属性。 | UID &#124;代码&#124;属性：<ID\> |
| 审批级别 | 不 | 包括至少已被批准达到给定批准级别的数据，指批准级别的标识符。 | 批准级别标识符 |
| 相对期间日期 | 不 | 用作相对期间基础的日期。 | 日期。 |
| 用户组织单位 | 不 | 显式定义要使用的用户组织单位，覆盖与当前用户关联的组织单位，多个标识符可以用分号分隔。 | 组织单位标识符。 |
| 列 | 不 | 用作表布局的列的维度。 | 任意维度（必须是查询维度） |
| 行 | 不 | 用作表布局的行的维度。 | 任意维度（必须是查询维度） |
| 命令 | 不 | 根据值指定行的顺序。 | ASC &#124; DESC |
| 时间字段 | 不 | 事件聚合所依据的时间字段。仅适用于事件数据项。可以是预定义选项或具有基于时间的值类型的属性或数据元素的 ID。 | EVENT_DATE &#124; ENROLLMENT_DATE &#124; INCIDENT_DATE &#124; DUE_DATE &#124; COMPLETED_DATE &#124; CREATED &#124; LAST_UPDATED &#124; <Attribute ID\> &#124; <Data element ID\> |
| 组织单位字段 | 不 | 事件聚合所依据的组织单位字段。仅适用于事件数据项。可以是具有组织单位值类型的属性或数据元素的 ID。默认选项指定为省略查询参数。 |  <Attribute ID\> &#124; <Data element ID\> &#124;注册&#124;注册&#124; OWNER_AT_START &#124; OWNER_AT_END |
| 增强条件           | 不       | 启用维度/过滤器的增强条件 | 假的&#124;真的 |

*dimension* 查询参数定义了哪些维度应该是
包含在分析查询中。可以是任意数量的维度
指定的。每个维度都应该重复维度参数
包含在查询响应中。查询响应可能
包含指定的所有组合的聚合值
维度项。

*filter* 参数定义应将哪些维度用作
在分析查询中检索到的数据的过滤器。任意数量
可以指定过滤器。过滤器参数应该重复
要在查询中使用的每个过滤器。过滤器与维度的不同之处在于
过滤器维度不会成为查询响应的一部分
内容，并且响应中的聚合值将是
在过滤器尺寸上折叠。换句话说，数据在
响应将在过滤器维度上聚合，但过滤器
不会作为维度包含在实际响应中。作为
例如，查询按句点过滤的某些数据元素和
您可以使用以下 URL 的组织单位：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&filter=pe:2014Q1;2014Q2
      &filter=ou:O6uvpzGd5pu;lc3eMKXaEfw

*aggregationType* 查询参数允许您定义哪个聚合
运算符应该用于查询。默认情况下，聚合
将使用为查询中包含的数据元素定义的运算符。
如果您的查询不包含任何数据元素但包含数据
元素组，第一个数据元素的聚合运算符
将使用第一组。组和数据元素的顺序是
不明确的。此查询参数允许您覆盖默认值和
指定特定的聚合运算符。例如，您可以设置
使用以下 URL 进行“计数”的聚合运算符：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2014Q1&dimension=ou:O6uvpzGd5pu
      &聚合类型=COUNT

*measureCriteria* 查询参数可让您过滤掉数据范围
要返回的记录。您可以指示系统仅返回记录
其中聚合数据值等于、大于、大于或
等于、小于或小于或等于某些值。您可以指定任何
以下格式的标准数量，其中 *criteria* 和
*value* 应替换为实际值：

    /api/analytics?measureCriteria=标准：值；标准：值

例如，以下查询将仅返回以下记录
数据值大于或等于 6500 且小于 33000：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&measureCriteria=GE:6500;LT:33000

类似于 *measureCriteria*，*preAggregationMeasureCriteria* 查询
参数让你过滤掉数据，只有在聚合之前
执行。例如，以下查询仅聚合数据，其中
原始值在定义的标准内：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&preAggregationMeasureCriteria=GE:10;LT:100

*startDate* 和 *endDate* 参数可用于指定自定义
要汇总的日期范围。指定日期范围时，您不能
将相对或固定期间指定为维度或过滤器。日期范围
将过滤分析响应。你可以这样使用它：

    /api/analytics.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=ou:ImspTQPwCqd&startDate=2018-01-01&endDate=2018-06-01

为了让分析资源生成形状中的数据
一个现成的表格，你可以提供 *tableLayout* 参数
true 作为值。而不是生成一个普通的、规范化的数据源，
分析资源现在将生成表格布局中的数据。你
可以将 *columns* 和 *rows* 参数与维度标识符一起使用
用分号分隔作为值以指示使用哪些值
表格列和行。列和行维度必须存在
作为查询中的数据维度（不是过滤器）。这样的请求可以看
像这样：

    /api/analytics.html?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014Q1;2014Q2
      &dimension=ou:O6uvpzGd5pu&tableLayout=true&columns=dx;ou&rows=pe

*order* 参数可用于分析资源生成
有序数据。数据将按升序（或降序）排序
值。以降序对值进行排序的示例请求
顺序是：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:LAST_12_MONTHS
      &dimension=ou:O6uvpzGd5pu&order=DESC

### 尺寸和项目 { #webapi_analytics_dimensions_and_items } 

DHIS2 具有多维数据模型，具有多个固定和
动态数据维度。固定维度是数据元素，
期间（时间）和组织单位维度。您可以动态添加
通过类别、数据元素组集和组织的维度
单元组集。下表显示了可用的数据维度
在 DHIS2 中。每个数据维度都有一个对应的*维度
标识符*，每个维度可以有一组*维度项*：



表：尺寸和尺寸项目

| 尺寸 | 维度 ID | 维度项目 |
|---|---|---|
| 数据元素、指标、数据集报告率度量、数据元素操作数、程序指标、程序数据元素、程序属性、验证规则 | dx | 数据元素、指示器、数据集报告率度量、数据元素操作数、程序指示器、程序属性标识符、关键字 DE_GROUP- <group-id\> 、 IN_GROUP- <group-id\>  ，使用 <dataelement-id\> 。 <optioncombo-id\> 用于数据元素操作数， <program-id\> 。 <dataelement-id\> 用于程序数据元素，<program-id\> 。 <attribute-id\> 用于程序属性，<validationrule-id\> 用于验证结果。 |
| 期间（时间） | 聚乙烯 | ISO 周期和相对周期，请参阅“日期和周期格式” |
| 组织单位层次结构 | 欧 | 组织部门标识符和关键字 USER_ORGUNIT、USER_ORGUNIT_CHILDREN、USER_ORGUNIT_GRANDCHILDREN、LEVEL- <level\> 和 OU_GROUP- <group-id\> |
| 类别选项组合 | 共 | 类别选项组合标识符（省略以获取所有项目） |
| 属性选项组合 | 敖 | 类别选项组合标识符（省略以获取所有项目） |
| 分类目录 |  <category id\> | 类别选项标识符（省略以获取所有项目） |
| 数据元素组集 |  <group set id\> | 数据元素组标识符（省略以获取所有项目） |
| 组织单位组集 |  <group set id\> | 组织单位组标识符（省略以获取所有项目） |
| 类别选项组集 |  <group set id\> | 类别选项组标识符（省略以获取所有项目） |

没有必要知道哪些对象用于
设计分析查询时的各种动态维度。你可以得到
通过访问 Web API 中的此 URL 获得动态维度的完整列表：

    /api/尺寸

If you want to retrieve only the dimensional items for a given dynamic dimension you can
use the example below. Pagination is disabled by default. It can be enabled by adding
the pagination parameter `paging=true` to the URL.

    /api/dimensions/J5jldMd8OHv/items?paging=true

The `/dimensions` API also provides an endpoint where the clients can get the *recomendations* for a given set of *dimensions*. For example:

    /api/33/dimensions/recommendations?fields=id&dimension=dx:fbfJHSPpUQD

In the example above, the client will receive back all the *Categories* that are configured as `Data dimension`s and associated (through data sets and category combos) with the data element `fbfJHSPpUQD`.
In addition, all *Organization Unit Group Set*s that are configured as `Data dimension`s will also (and always) be returned as part of the response.


The endpoint supports multiple data elements. If one wishes to send multiple data elements, they should be separated by `;`. For example:

    /api/33/dimensions/recommendations?fields=id&dimension=dx:fbfJHSPpUQD;JuTpJ2Ywq5b

> 注意事项
>
> 此端点仅返回当前登录用户可以读取的维度。它将检查当前用户是否可以读取相应推荐维度的数据或元数据。列表中省略了非授权尺寸。


分析资源的基本 URL 是`/api/analytics`。请求
您可以在其上使用查询字符串的特定维度和维度项目
以下格式，其中 `dim-id` 和 `dim-item` 应替换为实际值：

    /api/analytics?dimension=dim-id:dim-item;dim-item&dimension=dim-id:dim-item;dim-item

如上所示，维度标识符后跟一个冒号
而维度项之间用分号分隔。例如，一个
查询两个数据元素，两个期间和两个组织单位可以
使用以下 URL 完成：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &维度=pe:2016Q1;2016Q2&维度=ou:O6uvpzGd5pu;lc3eMKXaEfw

查询按类别选项组合细分的数据，而不是
您可以在查询中包含类别维度的数据元素总计
字符串，例如像这样：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &尺寸=co&尺寸=pe:201601&尺寸=ou:O6uvpzGd5pu;lc3eMKXaEfw

选择数据元素时，您还可以选择一个中的所有数据元素
使用 `DE_GROUP- <id> ` 语法将其分组为项目：

    /api/analytics?dimension=dx:DE_GROUP-h9cuJOkOwY2
      &维度=pe:201601&维度=ou:O6uvpzGd5pu

选择数据集报告率时，语法包含数据
设置标识符后跟报告率指标：

    /api/analytics?dimension=dx:BfMAe6Itzgt.REPORTING_RATE;BfMAe6Itzgt.ACTUAL_REPORTS
      &维度=pe:201601&维度=ou:O6uvpzGd5pu

要查询程序数据元素（跟踪器域类型），您可以获得
通过使用以下命令为每个数据元素指定程序
` <program-id> 。 <dataelement-id> ` 语法：

    /api/analytics.json?dimension=dx:eBAyeGv0exc.qrur9Dvnyt5;eBAyeGv0exc.GieVkTxp4HH
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

要查询程序属性（跟踪实体属性），您可以获得
通过使用以下命令为每个属性指定程序
` <program.id> 。 <attribute-id> ` 语法：

    /api/analytics.json?dimension=dx:IpHINAT79UW.a3kGcGDCuk6;IpHINAT79UW.UXz7xuGCEhU
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:ImspTQPwCqd

要查询可以使用的组织单位组集和数据元素
以下网址。请注意如何将组集标识符用作
维度标识符和作为维度项的组：

    /api/analytics?dimension=Bpx0589u8y0:oRVt7g429ZO;MAs88nJc9nL
      &维度=pe:2016&维度=ou:ImspTQPwCqd

要查询数据元素和类别，您可以使用此 URL。使用
类别标识符作为维度标识符，类别选项作为
维度项目：

    /api/analytics?dimension=dx:s46m5MS0hxu;fClA2Erf6IO&dimension=pe:2016
      &dimension=YNZyaJHiHYq:btOyqprQ9e8;GEqzEKCHoGA&filter=ou:ImspTQPwCqd

使用相关期间和组织单位进行查询
当前用户可以使用这样的 URL：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:LAST_12_MONTHS&dimension=ou:USER_ORGUNIT

When selecting organisation units for a dimension you can select an
entire level optionally constrained by any number of boundary
organisation units with the `LEVEL-<level>` syntax. Boundary refers to a
top node in a sub-hierarchy, meaning that all organisation units at the
given level below the given boundary organisation unit in the hierarchy
will be included in the response, and is provided as regular organisation unit 
dimension items. The level value can either be a numerical level or refer to the identifier
of the organisation unit level entity. A simple query for all org units at level three:

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016&dimension=ou:LEVEL-3

具有两个边界组织单位的三级和四级查询可以是
指定如下：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:LEVEL-3;LEVEL-4;O6uvpzGd5pu;lc3eMKXaEf

选择组织单位时，您还可以选择所有组织
组织单位组中的单位将作为维度项目包含在内
使用 `OU_GROUP- <id> ` 语法。团体内的组织单位
可以选择受到任意数量的边界组织的约束
单位。级别和组项目都可以重复任意次数
次数：

    /api/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:OU_GROUP-w0gFTTmsUcF;OU_GROUP-EYbopBOJWSW;O6uvpzGd5pu;lc3eMKXaEf

您可以将标识符方案用于元数据部分
具有 outputIdScheme 属性的分析响应，如下所示。你可以
使用 ID、代码和属性作为标识符方案：

    /api/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2017Q1;2017Q2&dimension=ou:O6uvpzGd5pu&outputIdScheme=CODE

列出了使用分析资源时需要注意的一些事项
以下。

  - 数据元素、指标、数据集报告率、计划数据
    要素和计划指标是共同数据维度的一部分，
    标识为“dx”。这意味着您可以使用任何数据
    元素、指标和数据集标识符以及“dx”
    查询中的维度标识符。

  - 对于类别、数据元素组集和组织单元组
    设置维度，如果没有，将在查询中使用所有维度项
    维度项目被指定。

  - 对于期间维度，维度项为 ISO 期间
    标识符和/或相对周期。请参阅部分
    上面称为“日期和期间格式”的期间格式和
    可用的相对时期。

  - 对于组织单位维度，您可以指定要处理的项目
    组织单位或组织单位的子单位
    与当前针对请求进行身份验证的用户相关联
    使用键 `USER_ORGUNIT` 或 `USER_ORGUNIT_CHILDREN` 作为项目，
    分别。您还可以指定组织单位标识符
    直接，或两者结合。

  - 对于组织单位维度，您可以指定组织
    层次结构级别和用于请求的边界单元
    格式`LEVEL-<level>-<boundary-id>`;举个例子
    `LEVEL-3-ImspTQPwCqd`意味着低于给定的所有组织单位
    层次结构中第 3 级的边界单元。

  - 对于组织单位维度，维度项是
    组织单位及其子层次结构 - 数据将被聚合
    对于指定组织单位下的所有组织单位
    等级制度。

  - 您不能为类别选项指定维度项目
    组合维度。相反，响应将包含项目
    链接到数据值。

### dx尺寸 { #webapi_analytics_dx_dimension } 

`dx` 维度是一个特殊的维度，它可以包含所有的
以下数据类型。



表：数据 dx 维度类型

| 类型 | 句法 | 描述 | 数据源 |
|---|---|---|---|
| 指示符 |  <indicator-id\> | 指标标识符。 | 汇总数据 |
| 指标组 | IN_GROUP- <indicatorgroup-id\> | 关键字后跟指标组标识符。将在响应中包含该组中的所有指标。 | 汇总数据 |
| 数据元素 |  <dataelement-id\> | 数据元素标识符。 | 汇总数据 |
| 数据元素组 | DE_GROUP- <dataelementgroup-id\> | 关键字后跟数据元素组标识符。将在响应中包含组中的所有数据元素。 | 汇总数据 |
| 数据元素操作数 |  <dataelement-id\> 。 <categoryoptcombo-id\> 。 <attributeoptcombo-id\> | 数据元素标识符后跟类别选项组合和属性选项组合标识符之一或两者。通配符“\*”符号可用于指示任意选项组合值。属性选项组合标识符可以完全省略。 | 汇总数据 |
| 资料集 |  <dataset-id\> 。 <reporting-rate-metric\> | Data set identifier followed by reporting rate metric. Can be REPORTING_RATE &#124; REPORTING_RATE_ON_TIME &#124; ACTUAL_REPORTS &#124; ACTUAL_REPORTS_ON_TIME &#124; EXPECTED_REPORTS. | 数据集完整性注册 |
| 程序数据元素 |  <program-id\> 。 <dataelement-id\> | 程序标识符后跟数据元素标识符。从指定程序内的事件中读取。 | 给定程序中的事件 |
| 计划指标 |  <programindicator-id\> | 程序指示器标识符。从与程序标识符关联的程序内的事件中读取。 | 来自程序指示器的程序的事件 |
| 验证结果 |  <validationrule-id\> | 验证规则标识符。将包括验证规则的验证规则违规，要求生成并保留验证结果。 | 验证结果 |

Items from all of the various `dx` types can be combined in an analytics
request. An example looks like this:

    /api/analytics.json
      ?维度=dx:Uvn6LCg7dVU;BfMAe6Itzgt.REPORTING_RATE;IpHINAT79UW.a3kGcGDCuk6
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

组语法也可以与任何其他项目一起使用。一个
示例如下所示：

    /api/analytics.json
      ?dimension=dx:DE_GROUP-qfxEYY9xAl6;IN_GROUP-oehv9EO3vP7;BfMAe6Itzgt.REPORTING_RATE
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

数据元素操作数可以选择性地指定属性选项
组合并使用通配符，例如指定所有类别选项
组合值：

    /api/analytics.json
      ?维度=dx:Uvn6LCg7dVU.*.j8vBiBqGf6O;Uvn6LCg7dVU.Z4oQs46iTeR
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

> **提示**
>
> 学习如何使用分析 API 的一个好方法是使用 DHIS2
> 数据可视化器 Web 应用程序并创建数据透视表。你可以去玩玩
> 使用各种维度和项目的数据透视表，然后单击
> **下载** > **普通数据源** > **JSON** 查看分析结果
> Web 浏览器地址栏中的 API 调用。

### 回应格式 { #webapi_analytics_response_formats } 

包含聚合数据的分析响应可以在
各种表现形式。像往常一样，您可以表示对某个项目感兴趣
通过将文件扩展名附加到 URL，通过
`Accept` HTTP 标头或通过 `format` 查询参数。这
默认格式为 JSON。可用的格式和内容类型是
下面列出。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xml（应用程序/ xml）

  - csv（应用程序/ csv）

  - html（text / html）

  - html + css（text / html）

  - xls（application / vnd.ms-excel）

例如，要请求 XML 格式的分析响应，您可以
使用以下网址：

    /api/analytics.xml?dimension=dx:fbfJHSPpUQD
      &维度=pe:2016&维度=ou:O6uvpzGd5pu;lc3eMKXaEfw

JSON响应如下所示：

```json
{
  "headers": [
    {
      "name": "dx",
      "column": "Data",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "pe",
      "column": "Period",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "value",
      "column": "Value",
      "meta": false,
      "type": "java.lang.Double"
    }
  ],
  "height": 4,
  "metaData": {
    "pe": [
      "2016Q1",
      "2016Q2"
    ],
    "ou": [
      "ImspTQPwCqd"
    ],
    "names": {
      "2016Q1": "Jan to Mar 2016",
      "2016Q2": "Apr to Jun 2016",
      "FbKK4ofIv5R": "Measles Coverage <1 y",
      "ImspTQPwCqd": "Sierra Leone",
      "eTDtyyaSA7f": "Fully Immunized Coverage"
    }
  },
  "rows": [
    [
      "eTDtyyaSA7f",
      "2016Q2",
      "81.1"
    ],
    [
      "eTDtyyaSA7f",
      "2016Q1",
      "74.7"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q2",
      "88.9"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q1",
      "84.0"
    ]
  ],
  "width": 3
}
```

响应表示维度数据表。 *headers* 数组
概述了表中包含哪些列以及哪些列
列包含。 *column* 属性显示列维度
标识符，或者如果列包含度量，则为“值”一词。这
*meta* 属性为 *true* 如果列包含维度项或
*false* 如果列包含度量（聚合数据值）。这
*name* 属性类似于 column 属性，不同之处在于它显示
如果列包含度量，则为“值”。 *type* 属性
表示列值的 Java 类类型。

*height* 和 *width* 属性表示有多少数据列和
行分别包含在响应中。

*metaData period* 属性包含一个唯一的有序数组
响应中包含的时间段。 *metaData ou* 属性包含一个
响应中包含的组织单位标识符数组。
*metaData names* 属性包含标识符之间的映射
用于数据响应和它们代表的对象的名称。
客户端可以使用它来替换数据中的标识符
响应名称以提供更有意义的数据视图
桌子。

*rows* 数组包含维度数据表。它包含
具有维度项（对象或期间标识符）和一列的列
具有聚合数据值。上面的示例响应有一个
数据/指标列、期间列和值列。首先
列包含指标标识符，第二列包含 ISO 句点
标识符，第三个包含聚合数据值。

### 约束与验证 { #webapi_analytics_constraints } 

您可以提供给
分析资源。如果违反任何约束，API 将
返回一个 *409 Conflict* 响应和一个类似于下面的响应消息：

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Only a single indicator can be specified as filter",
  "errorCode": "E7108"
}
```

`httpStatus` 和 `httpStatusCode` 字段表示 HTTP 状态和
根据 HTTP 规范的状态代码。 `message` 字段提供了一个
验证错误的人类可读描述。 `errorCode` 字段
提供一个机器可读的代码，客户端可以使用它来处理
验证错误。聚合分析的可能验证错误
API 如下表所述。

| 错误代码 | 信息 |
| ---------- | ------- |
| E7100      | 查询参数不能为空 |
| E7101      | 必须至少指定一个尺寸 |
| E7102      | 必须至少指定一个数据维项目或数据元素组集合维项目 |
| E7103      | 尺寸不能同时指定为尺寸和过滤器 |
| E7104      | 必须至少指定一个期间作为维度或过滤器，或者开始和日期 |
| E7105      | 不能同时指定期间，开始日期和结束日期 |
| E7106      | 开始日期不能晚于结束日期 |
| E7107      | 无法为报告费率指定开始日期和结束日期 |
| E7108      | 只能将一个指标指定为过滤器 |
| E7109      | 只能将单个报告率指定为过滤器 |
| E7110      | 类别选项组合不能指定为过滤器 |
| E7111      | 尺寸不能多次指定 |
| E7112      | 只能与类型的尺寸一起指定报告率 |
| E7113      | 未指定数据元素时无法指定分配的类别 |
| E7114      | 指定的类别只能与数据元素一起指定，不能与指标或报告率一起指定 |
| E7115      | 数据元素必须具有允许聚合的值和聚合类型 |
| E7116      | 指标表达式不能包含循环引用 |
| E7117      | 当输出格式为DATA_VALUE_SET时，必须指定数据尺寸“ dx” |
| E7118      | 当输出格式为DATA_VALUE_SET时，必须指定期间尺寸“ pe” |
| E7119      | 当输出格式为DATA_VALUE_SET时，必须指定组织单位维度“ ou” |
| E7120      | 不允许用户查看组织单位 |
| E7121      | 不允许用户读取对象的数据 |
| E7122      | 数据批准级别不存在 |
| E7123      | 当前用户受维度限制，但无权访问任何维度项目 |
| E7124      | 维度存在于查询中，没有任何有效的维度选项 |
| E7125      | 维度标识符未引用任何维度 |
| E7126      | 列必须作为查询中的维存在 |
| E7127      | 行必须作为查询中的维存在 |
| E7128      | 查询结果集超出最大限制 |
| E7129      | 程序已指定但不存在 |
| E7130      | 已指定程序阶段，但不存在 |
| E7131      | 查询失败，可能是因为查询超时 |

### 数据值设定格式 { #webapi_analytics_data_value_set_format } 

分析 *dataValueSet* 资源允许返回聚合
数据值集格式的数据。这种格式代表原始数据
值，而不是按照各种方式汇总的数据
方面。将聚合数据导出为常规数据值很有用
当目标系统包含数据时，用于系统之间的数据交换
与目标系统存储的内容相比具有更精细的粒度。

例如，可以在目标系统中指定一个指标来
汇总多个数据元素的数据并将此数据导入
目标系统中的单个数据元素。再举一个例子，一个
可以汇总在目标的组织单位级别 4 收集的数据
系统级别 2 并将该数据导入目标系统。

您可以从原始数据值集格式中检索数据
数据值集资源：

    /api/analytics/dataValueSet

支持以下资源表示形式：

  - json（应用程序/ json）

  - xml（应用程序/ xml）

使用数据值集格式时，必须正好三个维度
指定为分析维度，每个维度至少有一个维度项目：

  - 资料（dx）

  - 周期（pe）

  - 组织单位（ou）

任何其他维度都将被忽略。过滤器将被应用
定期分析请求。请注意，任何数据维度类型都可以
指定，包括指示符、数据元素、数据元素操作数、
数据集和计划指标。

汇总特定指标数据的示例请求，
期间和组织单位并将其作为常规数据值返回
XML 看起来像这样：

    api / analytics / dataValueSet.xml？dimension = dx：Uvn6LCg7dVU; OdiHJayrsKo
      ＆dimension = pe：LAST_4_QUARTERS＆dimension = ou：lc3eMKXaEfw; PMa2VCrupOd

聚合数据元素操作数的数据并使用 CODE 的请求
因为输出标识符方案如下所示。当定义
输出标识符方案，响应的所有元数据对象部分都是
做作的：

    api / analytics / dataValueSet.json？dimension = dx：fbfJHSPpUQD.pq2XI5kz2BY; fbfJHSPpUQD.PT59n8BQbqM
      ＆dimension = pe：LAST_12_MONTHS＆dimension = ou：ImspTQPwCqd＆outputIdScheme = CODE

使用基于属性的标识符方案进行导出时存在风险
产生重复的数据值。布尔查询参数
duplicatesOnly 可用于调试目的仅返回
重复数据值。此响应可用于清理
重复：

    api / analytics / dataValueSet.xml？dimension = dx：Uvn6LCg7dVU; OdiHJayrsKo
      ＆dimension = pe：LAST_4_QUARTERS＆dimension = ou：lc3eMKXaEfw＆duplicatesOnly = true

### 原始数据格式 { #webapi_analytics_raw_data } 

分析 *rawData* 资源允许返回存储在
未执行任何聚合的分析数据表。这
对于想要执行聚合和的客户很有用
自行过滤，而无需对数据进行非规范化
可用的数据维度本身。

    / api / analytics / rawData

支持以下资源表示形式：

  - json（应用程序/ json）

  - csv（应用程序/ csv）

此资源遵循常规分析资源的语法。仅有的
支持查询参数的子集。此外，一个
*startDate* 和 *endDate* 参数可用。支持的
参数如下表所示。



表：查询参数

| 查询参数 | 必填/备注 |
|---|---|
| 方面 | 是的 |
| 开始日期 | 否 / 年-月-日 |
| 结束日期 | 否 / 年-月-日 |
| 跳过元数据 | 不 |
| 跳过数据 | 不 |
| 层级元 | 不 |
| 显示层次结构 | 不 |
| 显示属性 | 不 |
| 输出IdScheme | 不 |
| 输出组织单位 ID 方案 | 不 |
| 输出数据元素Id方案 | 不 |
| 输入IdScheme | 不 |
| 用户组织单位 | 不 |

*dimension* 查询参数定义了哪些维度（表列）
应包含在响应中。它可以选择性地受到约束
与项目。 *filter* 查询参数定义了哪些项目和
维度（表格列）应用作响应的过滤器。

对于组织单位维度，响应将包含数据
与组织单位和该组织中的所有组织单位相关联
子层次结构（树中的孩子）。这与
常规分析资源，其中只有明确选择的
包括组织单位。

要检索具有特定数据元素、特定时间段的响应，
两个自定义维度的特定组织单位和所有数据
可以发出这样的请求：

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      ＆dimension = J5jldMd8OHv＆dimension = Bpx0589u8y0
      ＆dimension = pe：LAST_12_MONTHS
      ＆dimension = ou：O6uvpzGd5pu; fdc6uOvgoji

*startDate* 和 *endDate* 参数允许获取链接的数据
到这些日期之间的任何时间段。这避免了定义所有
期间明确在
    要求：

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      ＆dimension = J5jldMd8OHv＆dimension = Bpx0589u8y0
      ＆startDate = 2015-01-01＆endDate = 2015-12-31
      ＆dimension = ou：O6uvpzGd5pu; fdc6uOvgoji

*filter* 参数可用于过滤响应，而无需
包括该维度作为响应的一部分，这次是在 CSV 中
格式：

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      ＆filter = J5jldMd8OHv：uYxK4wmcPqA; tDZVQ1WtwpA
      ＆startDate = 2015-01-01＆endDate = 2015-12-31
      ＆dimension = ou：O6uvpzGd5pu

如果您想要人类可读的数据，*outputIdScheme* 参数很有用
响应，因为它可以像这样设置为 *NAME*：

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      ＆filter = J5jldMd8OHv：uYxK4wmcPqA; tDZVQ1WtwpA
      ＆startDate = 2017-01-01＆endDate = 2017-12-31
      ＆dimension = ou：O6uvpzGd5pu
      ＆outputIdScheme = NAME

来自 *rawData* 资源的响应看起来与
定期分析资源；不同之处在于响应包含
原始的、非聚合的数据，适合进一步聚合
第三方系统。

### 调试 { #webapi_analytics_debugging } 

在调试分析请求时，检查数据会很有用
聚合分析响应的价值来源。这
*analytics/debug/sql* 资源将提供一个 SQL 语句
返回数据值表的相关内容。你可以生产
通过执行内容类型为“text/html”的 GET 请求或
如下所示的“文本/纯文本”。维度和过滤器语法与
常规分析查询：

    / api / analytics / debug / sql？dimension = dx：fbfJHSPpUQD; cYeuwXTCPkU
      ＆filter = pe：2016Q1; 2016Q2＆filter = ou：O6uvpzGd5pu

## 事件分析 { #webapi_event_analytics } 

事件分析 API 允许您访问聚合的事件数据和查询
*事件*在 DHIS2 中捕获。此资源可让您检索基于事件的
在程序和可选的程序阶段，并让您检索和
在任何事件维度上过滤事件。

    /api/分析/事件

### 尺寸和项目 { #webapi_event_analytics_dimensions_items } 

事件维度包括数据元素、属性、组织单位
和时期。聚合的事件分析资源将返回
聚合信息，例如计数或平均值。查询分析
资源将简单地返回匹配一组条件的事件，并且不会
不执行任何聚合。您可以在表单中指定维度项
来自选项集的选项和来自数据图例集的图例
与此相关的元素和属性。事件
尺寸如下表所示。



表：活动维度

| 尺寸 | 维度 ID | 描述 |
|---|---|---|
| 资料元素 |  <id\> | 数据元素标识符 |
| 属性 |  <id\> | 属性标识符 |
| 句号 | 聚乙烯 | ISO 周期和相对周期，请参阅“日期和周期格式” |
| 组织单位 | 欧 | 组织部门标识符和关键字 USER_ORGUNIT、USER_ORGUNIT_CHILDREN、USER_ORGUNIT_GRANDCHILDREN、LEVEL- <level\> 和 OU_GROUP- <group-id\> |
| 组织单位组集 |  <org unit group set id\> | 组织单位组集标识符 |
| 分类目录 |  <category id\> | 类别标识符（仅限节目属性类别） |

### 请求查询参数 { #webapi_event_analytics_request_query_parameters } 

Analytics事件API可让您指定一系列查询参数。



表：事件查询和聚合分析的查询参数

| 查询参数 | 需要 | 描述 | 选项（默认为默认） |
|---|---|---|---|
| 程序 | 是的 | 程序标识符。 | 任何程序标识符 |
| 阶段 | 不 | 程序阶段标识符。 | 任何程序阶段标识符 |
| 开始日期 | 是的 | 活动的开始日期。 | yyyy-MM-dd 格式的日期 |
| 结束日期 | 是的 | 活动的结束日期。 | yyyy-MM-dd 格式的日期 |
| 方面 | 是的 | 维度标识符包括数据元素、属性、程序指标、期间、组织单元和组织单元组集。参数可以重复任意次数。项目过滤器可以应用于维度的格式<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 | 运营商可以EQ&#124; GT&#124;通用电气LT&#124;勒&#124; NE＆#124;喜欢&#124;在 |
| 筛选 | 不 | 维度标识符包括数据元素、属性、期间、组织单位和组织单位组集。参数可以重复任意次数。项目过滤器可以应用于维度，格式为<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 ||
| 层级元 | 不 | 在元数据中包括组织单位祖先的名称和组织单位的层次结构路径。 | 假的&#124;真的 |
| 事件状态 | 不 | 指定要包含的事件的状态。 | 活跃&#124;已完成&#124;时间表&#124;逾期&#124;已跳过。可以用逗号分隔（*仅用于查询*）。 |
| 程序状态 | 不 | 指定要包含的事件的注册状态。 | 活跃&#124;已完成&#124;取消。可以用逗号分隔（*仅用于查询*）。 |
| 相对期间日期 | 细绳 | 不 | 日期标识符，例如：“2016-01-01”。覆盖相对期间的开始日期 |
| 列 | 不 | 用作表布局的列的维度。 | 任意维度（必须是查询维度） |
| 行 | 不 | 用作表布局的行的维度。 | 任意维度（必须是查询维度） |
| 时间字段 | 不 | 用于事件聚合/查询的时间字段。仅适用于事件数据项。可以是预定义选项或具有基于时间的值类型的属性或数据元素的 ID。对于“/analytics/events/”端点，默认“timeField”为 EVENT_DATE。 | EVENT_DATE &#124; SCHEDULED_DATE &#124; <Attribute ID\> &#124; <Data element ID\> |



表：仅用于事件查询分析的查询参数

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 模式 | 不 | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. More details [here].(https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html#webapi_nti_ou_scope) | 后裔、子女、精选 |
| 升序 | 不 | 维度按升序排序，可以引用事件日期、组织单位名称和代码以及任何项目标识符。 | `ouname` &#124; `程序状态` &#124; `事件状态` &#124; `由显示名称创建` &#124; `lastupdatedbydisplayname` &#124; `事件日期` &#124; `注册日期` &#124; `事件日期` &#124; `最后更新` &#124;项目标识符 |
| 描述 | 不 | 维度按降序排序，可以引用事件日期、组织单位名称和代码以及任何项目标识符。 | `ouname` &#124; `程序状态` &#124; `事件状态` &#124; `由显示名称创建` &#124; `lastupdatedbydisplayname` &#124; `事件日期` &#124; `注册日期` &#124; `事件日期` &#124; `最后更新` &#124;项目标识符 |
| 仅坐标 | 不 | 是否只返回具有坐标的事件。 | 假的&#124;真的 |
| 坐标Ou后备 | 不 | 只要组织单位几何图形丢失，就会应用程序实例几何图形。 | 假的&#124;真的 |
| 数据ID方案 | 不 | 用于数据的 ID 方案，更具体地说是具有选项集或图例集的数据元素和属性，例如在数据响应中返回选项名称而不是代码，或者返回图例名称而不是图例 ID。 | 姓名 &#124;代码&#124;用户识别码 |
| 标头 | 不 | 作为响应的一部分返回的标头的名称。 | 一个或多个标头名称，以逗号分隔 |
| 页 | 不 | 页码。默认页数为 1。 | 数值正值 |
| 页面大小 | 不 | 页面大小。默认大小为每页 50 项。 | 数字零或正值 |
| 活动日期 | 不 | (`events` resource only) Custom period on `eventDate` (see "custom date periods" section) | 请参阅“日期和周期格式”部分 |
| 开学报道日 | 不 | `enrollmentDate` 的自定义期间（请参阅“自定义日期期间”部分） | 请参阅“日期和周期格式”部分 |
| 约定的日期 | 不 | (`events` resource only) Custom period on `scheduledDate` (see "custom date periods" section) | 请参阅“日期和周期格式”部分 |
| 事件日期 | 不 | `incidentDate` 的自定义期间（请参阅“自定义日期期间”部分） | 请参阅“日期和周期格式”部分 |
| 最近更新时间 | 不 | `lastUpdated` 的自定义周期（请参阅“自定义日期周期”部分） | 请参阅“日期和周期格式”部分 |



表：仅用于聚合事件分析的查询参数

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 价值 | 不 | 值维度标识符。可以是数据元素或属性，必须是数值类型。 | 数据元素或属性标识符 |
| 聚合类型 | 不 | 值维度的聚合类型。默认为平均。 | 总和＆#124;平均水平AVERAGE_SUM_ORG_UNIT &#124;最后&#124; LAST_AVERAGE_ORG_UNIT &#124;计数&#124;标准差值方差&#124;敏&#124;最大限度 |
| 显示层次结构 | 不 | 显示完整的组织单位层次结构路径以及组织单位名称。 | 假的&#124;真的 |
| 显示属性 | 不 | 要显示元数据的属性。 | 姓名 &#124;简称 |
| 排序 | 不 | 按升序或降序对值列上的记录进行排序。 | ASC &#124; DESC |
| 限制 | 不 | 要返回的最大记录数。不能大于 10 000。 | 数值正值 |
| 输出类型 | 不 | 指定分析数据的输出类型，可以是事件、注册或跟踪的实体实例。最后两个选项仅适用于注册程序。 | 活动＆#124;注册&#124; TRACKED_ENTITY_INSTANCE |
| 折叠数据维度 | 不 | 将响应中的所有数据维度（数据元素和属性）折叠为单个维度。 | 假的&#124;真的 |
| 跳过元数据 | 不 | 排除响应的元数据部分（提高性能）。 | 假的&#124;真的 |
| 跳过数据 | 不 | 排除响应的数据部分。 | 假的&#124;真的 |
| 跳过舍入 | 不 | 跳过聚合数据值的舍入。 | 假的&#124;真的 |
| 聚合数据 | 不 | 生成数据维度的聚合值（而不是维度项）。 | 假的&#124;真的 |
| 组织单位字段 | 不 | 事件聚合所依据的组织单位字段。仅适用于事件数据项。可以是具有组织单位值类型的属性或数据元素的 ID。默认选项指定为省略查询参数。 |  <Attribute ID\> &#124; <Data element ID\> &#124;注册&#124;注册&#124; OWNER_AT_START &#124; OWNER_AT_END |




表：仅用于集群事件分析的查询参数

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 簇的大小 | 是的 | 簇的大小（以米为单位）。 | 数值正值 |
| 坐标场 | 不 | 地理空间事件分析的基础字段。默认为事件。可以设置为值类型坐标的属性和数据元素的标识符。 | 活动＆#124; <attribute-id\> &#124; <dataelement-id\> |
| 盒子 | 是的 | 要包含在响应中的事件边界框/区域，格式为“最小经度、最小纬度、最大经度、最大纬度”。 | 串 |
| 包含簇点 | 不 | 包括有关每个簇的基础点的信息，如果簇代表大量点，请小心。 | 假的&#124;真的 |

### 事件查询分析 { #webapi_event_query_analytics } 

*analytics/events/query* 资源可让您查询捕获的
事件。此资源不执行任何聚合，而是让
您查询和过滤有关事件的信息。

    /api/analytics/events/query

您可以指定任意数量的维度和任意数量的过滤器
询问。维度项标识符可以引用任何数据元素，
人员属性、人员标识符、固定和相对时间段以及
组织单位。维度可以选择有一个查询运算符和
一个过滤器。事件查询应采用所描述的格式
    以下。

    /api/analytics/events/query/ <program-id> ?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou: <ou-id> ; <ou-id> &dimension= <item-id> &dimension= <item-id> : <operator> : <filter>

例如，要从“住院发病率和
2016 年 1 月至 10 月期间的死亡率”计划，其中“性别”
和“年龄”数据元素被包括在内并且“年龄”维度被过滤
在“18”上，您可以使用以下内容
    询问：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &尺寸=ou:O6uvpzGd5pu;fdc6uOvgoji&尺寸=oZg33kd9taw&尺寸=qrur9Dvnyt5:EQ:18

检索“Child”的“Birth”程序阶段的事件
2016 年 3 月至 12 月期间的“计划”计划，其中“重量”
数据元素，过滤大于
    2000年：

    /api/analytics/events/query/IpHINAT79UW?stage=A03MvHHogjR&startDate=2016-03-01
      &endDate=2016-12-31&dimension=ou:O6uvpzGd5pu&dimension=UXz7xuGCEhU:GT:2000

排序可以应用于查询事件的事件日期和
任何尺寸。按事件日期降序和升序排序
您可以使用的“年龄”数据元素维度
    用：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&desc=EVENTDATE&asc=qrur9Dvnyt5

分页可以通过指定页码和
页面大小参数。如果指定了页码但未指定页面大小，
将使用 50 的页面大小。如果指定了页面大小但页面
number 不是，将使用页码 1。获取第三页
页面大小为 20 的响应，您可以使用类似的查询
    这：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&page=3&pageSize=20

#### 筛选 { #filtering } 

过滤器可以应用于数据元素，人员属性和人员标识符。过滤是通过以下格式的查询参数值完成的：

    ＆dimension = <item-id>：<operator>：<filter-value>

例如，您可以过滤“ Weight”数据元素以获取大于2000且小于4000的值，如下所示：

    ＆dimension = UXz7xuGCEhU：GT：2000＆dimension = UXz7xuGCEhU：LT：4000

您可以使用以下方法过滤多个特定年龄的“年龄”数据元素
像这样的 IN 运算符：

    ＆dimension = qrur9Dvnyt5：IN：18; 19; 20

您可以通过重复运算符和过滤器组件为给定项目指定多个过滤器，所有组件均用分号分隔：

    ＆dimension = qrur9Dvnyt5：GT：5：LT：15

下面列出了可用的运算符。



表：过滤器运算符

| 操作员 | 描述 |
|---|---|
| 情商 | 等于 |
| ！情商 | 不等于 |
| 室内环境质量 | 等于，忽略大小写 |
| !IEQ | 不等于，忽略大小写 |
| GT | 比...更棒 |
| 通用电气 | 大于或等于 |
| LT | 少于 |
| LE | 小于或等于 |
| 东北 | 不等于 |
| 喜欢 | 喜欢（自由文本匹配） |
| ！喜欢 | 不喜欢（自由文本匹配） |
| 我喜欢 | 就像，忽略大小写（自由文本匹配） |
| ！我喜欢 | 不喜欢，忽略大小写（自由文本匹配） |
| 在 | 等于由“;”分隔的多个值之一 |

#### 时间字段过滤{ #time-field-filtering }

By default, the `query` endpoints filter periods based on `eventDate`.
However, it is possible to filter entries based on `lastUpdated` or `schedule` instead, by using the `timeField` query parameter.
For example:

    &timeField=LAST_UPDATED
    &timeField=SCHEDULED_DATE

#### 增强条件{ #enhanced-conditions }

By default `enhancedConditions` flag is set to `false`. This means all conditions expressed in `dimension` and `filter` are meant as `AND` conditions.
For example:

    尺寸=a:GT:20:LT:40&尺寸=b:GT:1:LT:5

转化为以下逻辑条件：

    a>20 和 <40 and b> 1 和 b<5

However, there are cases in which more control on conditions might be needed and can be enabled by setting `enhancedConditions` query parameter to `true`.
By doing so, a client can use a special `_OR_` separator to join conditions using `OR` logical operator.

例：

    尺寸=a:GT:20:LT:40_OR_b:GT:1:LT:5&尺寸=c:EQ:测试

转化为以下逻辑条件：

    ((a>20 和 <40) or (b> 1 和 b<5)) 和 c =“测试”

#### 回应格式 { #response-formats } 

默认的响应表示格式是 JSON。请求必须使用 HTTP *GET* 方法。支持以下响应格式。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xls（application / vnd.ms-excel）

例如，要获得Excel格式的响应，可以在请求URL中使用文件扩展名，如下所示：

    /api/analytics/events/query/eBAyeGv0exc.xls?startDate=2016-01-01&endDate=2016-10-31
      &尺寸=ou:O6uvpzGd5pu&尺寸=oZg33kd9taw&尺寸=qrur9Dvnyt5

您可以将hierarchyMeta 查询参数设置为true，以便
在元部分中包括所有祖先组织单位的名称
响应：

    /api/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:YuQRtpLP10I&dimension=qrur9Dvnyt5:EQ:50&hierarchyMeta=true

默认响应JSON格式将类似于以下内容：

```json
{
  "headers": [
    {
      "name": "psi",
      "column": "Event",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ps",
      "column": "Program stage",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "eventdate",
      "column": "Event date",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdated",
      "column": "Last Updated",
      "valueType": "DATE",
      "type": "java.time.LocalDate",
      "hidden": false,
      "meta": true
    },
    {
      "name": "createdbydisplayname",
      "column": "Created by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdatedbydisplayname",
      "column": "Last updated by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "coordinates",
      "column": "Coordinates",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "qrur9Dvnyt5": "Age",
      "eBAyeGv0exc": "Inpatient morbidity and mortality",
      "ImspTQPwCqd": "Sierra Leone",
      "O6uvpzGd5pu": "Bo",
      "YuQRtpLP10I": "Badjia",
      "oZg33kd9taw": "Gender"
    },
    "ouHierarchy": {
      "YuQRtpLP10I": "/ImspTQPwCqd/O6uvpzGd5pu"
    }
  },
  "width": 8,
  "height": 4,
  "rows": [
    [
      "yx9IDINf82o",
      "Zj7UnCAulEk",
      "2016-08-05",
      "system",
      "2018-08-07",
      "[5.12, 1.23]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "IPNa7AsCyFt",
      "Zj7UnCAulEk",
      "2016-06-12",
      "system",
      "2018-08-07",
      "[5.22, 1.43]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "ZY9JL9dkhD2",
      "Zj7UnCAulEk",
      "2016-06-15",
      "system",
      "2018-08-07",
      "[5.42, 1.33]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "MYvh4WAUdWt",
      "Zj7UnCAulEk",
      "2016-06-16",
      "system",
      "2018-08-07",
      "[5.32, 1.53]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ]
  ]
}
```

响应的 *headers* 部分描述了查询的内容
结果。事件唯一标识符、节目阶段标识符、
事件日期、组织单位名称、组织单位代码和
组织单位标识符显示为前六个维度
响应并将始终存在。接下来是数据元素，
指定为的人员属性和人员标识符
请求中的维度，在本例中为“性别”和“年龄”数据
元素尺寸。标题部分包含的标识符
“名称”属性中的维度项和可读维度
“列”属性中的描述。

*metaData* 部分，*ou* 对象包含映射到表示层次结构的字符串的响应中存在的所有组织单位的标识符。此层次结构字符串从根开始列出组织单位的祖先（父）的标识符。 *names* 对象包含响应中映射到其名称的所有项目的标识符。

*rows* 部分包含查询产生的事件。每一行
正好代表一个事件。

为了让事件分析资源在
一个现成的表格的形状，你可以提供*行*和*列*
具有请求的维度标识符的参数以分号分隔
作为值来指示哪些用作表列和行。
事件不是生成一个普通的、规范化的数据源
分析资源现在将生成表格布局中的数据。这
列和行维度必须作为数据维度出现在
查询（不是过滤器）。这样的请求可能如下所示：

    /api/analytics.html+css?dimension=dx:cYeuwXTCPkU;fbfJHSPpUQD&dimension=pe:WEEKS_THIS_YEAR
      &filter=ou:ImspTQPwCqd&displayProperty=SHORTNAME&columns=dx&rows=pe

### 事件汇总分析 { #webapi_event_aggregate_analytics } 

`/analytics/events/aggregate` 资源可让您检索 *aggregated
DHIS2 中捕获的事件数量*。此资源可让您检索
基于程序和可选的程序阶段聚合数据，以及
允许您过滤任何事件维度。

    /api/analytics/events/aggregate

事件聚合资源不返回事件信息
本身，而不是与请求匹配的事件总数
询问。事件维度包括数据元素、人员属性、人员
标识符、期间和组织单位。聚合事件查询
应该是下面描述的格式。

    /api/analytics/events/aggregate/ <program-id> ?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou: <ou-id> ; <ou-id> &dimension= <item-id> &dimension= <item-id> : <operator> : <filter>

例如，要从
1 月至 10 月期间的“住院发病率和死亡率”计划
2016 年，其中包含“性别”和“年龄”数据元素，“年龄”
维度项目在“18”上过滤，“性别”项目在过滤上
“女性”，您可以使用以下查询：

    /api/analytics/events/aggregate/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &尺寸=ou:O6uvpzGd5pu&尺寸=oZg33kd9taw:EQ:女&尺寸=qrur9Dvnyt5:GT:50

检索固定和相对时期的数据，而不是开始和结束
日期，在本例中为 2016 年 5 月和过去 12 个月，以及组织
与当前用户关联的单位，可以使用以下查询：

    /api/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:201605;LAST_12_MONTHS
      &dimension=ou:USER_ORGUNIT;fdc6uOvgo7ji&dimension=oZg33kd9taw

为了将“女性”指定为数据的“性别”过滤器
响应，意思是“性别”不会是响应的一部分，但会
过滤其中的聚合数字，您可以使用以下语法：

    /api/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:2016;
      &dimension=ou:O6uvpzGd5pu&filter=oZg33kd9taw:EQ:女

要将“Bo”组织单位和期间“2016”指定为过滤器，
和“放电方式”和“性别”作为维度，其中“性别”是
在“男性”项目上过滤，您可以使用这样的查询：

    /api/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&dimension=oZg33kd9taw:EQ:男

要为_出院模式_创建“前 3 名报告”，您可以使用限制
和 sortOrder 查询参数类似：

    /api/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&limit=3&sortOrder=DESC

要指定具有相应聚合类型的值维度，您
可以使用 value 和aggregationType 查询参数。指定一个
值维度将使分析引擎返回聚合值
对于响应中该维度的值，而不是计数
事件。

    /api/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &维度=ou:ImspTQPwCqd&维度=pe:LAST_12_MONTHS&维度=fWIAEtYVEGk
      &value=qrur9Dvnyt5&aggregationType=AVERAGE

基于特定数据元素或属性的事件分析聚合
对于值类型日期或日期时间，您可以使用 `timeField` 参数：

    /api/analytics/events/aggregate/IpHINAT79UW.json?dimension=ou:ImspTQPwCqd
      &维度=pe:LAST_12_MONTHS&维度=cejWyOfXge6&阶段=A03MvHHogjR
      &timeField=ENROLLMENT_DATE

基于特定数据元素或属性的事件分析聚合
对于值类型的组织单元，您可以使用 `orgUnitField` 参数：

    /api/analytics/events/aggregate/eBAyeGv0exc.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:THIS_YEAR&dimension=oZg33kd9taw&stage=Zj7UnCAulEk
      &orgUnitField=S33cRBsnXPo

`orgUnitField` 参数值可以是以下之一：

| 组织单位字段 | 描述 |
| --- | --- |
|  <Attribute ID\> | 具有组织单位值类型的属性的 ID |
|  <Data element ID\> | 具有组织单位值类型的数据元素的 ID |
| 登记 | 注册（创建）跟踪实体实例的组织单位 |
| 注册 | 跟踪的实体实例在计划中注册的组织部门 |
| OWNER_AT_START | 报告期开始时跟踪的实体实例的所属组织单位 |
| OWNER_AT_END | 报告期末被跟踪实体实例所属组织单位 |

#### 范围/图例集 { #ranges-legend-sets } 

对于聚合查询，您可以为数值指定范围/图例集
数据元素和属性维度。目的是将
数值范围内。举个例子，而不是生成数据
对于不同年份的“年龄”数据元素，您可以将
年龄组的信息。为了实现这一点，数据元素或
属性必须与图例集相关联。格式是
如下面所描述的：

    ？dimension = <item-id>-<legend-set-id>

一个示例如下所示：

    /api/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &维度=qrur9Dvnyt5-Yf6UHoPkdS6&维度=ou:ImspTQPwCqd&维度=pe:LAST_MONTH

#### 回应格式 { #response-formats } 

默认的响应表示格式是 JSON。请求必须是
使用 HTTP *GET* 方法。响应将类似于以下内容：

```json
{
  "headers": [
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "pe",
      "column": "Period",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "value",
      "column": "Value",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "eBAyeGv0exc": "Inpatient morbidity and mortality"
    }
  },
  "width": 5,
  "height": 39,
  "rows": [
    [
      "Female",
      "95",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "63",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "67",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "71",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "75",
      "201605",
      "O6uvpzGd5pu",
      "14"
    ],
    [
      "Female",
      "73",
      "201605",
      "O6uvpzGd5pu",
      "5"
    ]
  ]
}
```

请注意，单个响应中返回的行的最大限制为 10 000。
如果查询产生超过最大限制，*409 Conflict* 状态代码
将被退回。

### 事件聚类分析 { #webapi_event_clustering_analytics } 

*analytics/events/cluster* 资源提供集群地理空间
事件数据。请求如下所示：

    /api/analytics/events/cluster/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:LEVEL-2&clusterSize=100000
      &bbox=-13.2682125,7.3721619,-10.4261178,9.904012&includeClusterPoints=false

集群响应提供基础点的计数，中心
每个集群的点和范围。如果 `includeClusterPoints` 查询
参数设置为 true，以逗号分隔的字符串与标识符
包括基础事件。示例响应如下所示：

```json
{
  "headers": [
    {
      "name": "count",
      "column": "Count",
      "type": "java.lang.Long",
      "meta": false
    },
    {
      "name": "center",
      "column": "Center",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "extent",
      "column": "Extent",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "points",
      "column": "Points",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "width": 3,
  "height": 4,
  "rows": [
    [
      "3",
      "POINT(-13.15818 8.47567)",
      "BOX(-13.26821 8.4St7215,-13.08711 8.47807)",
      ""
    ],
    [
      "9",
      "POINT(-13.11184 8.66424)",
      "BOX(-13.24982 8.51961,-13.05816 8.87696)",
      ""
    ],
    [
      "1",
      "POINT(-12.46144 7.50597)",
      "BOX(-12.46144 7.50597,-12.46144 7.50597)",
      ""
    ],
    [
      "7",
      "POINT(-12.47964 8.21533)",
      "BOX(-12.91769 7.66775,-12.21011 8.49713)",
      ""
    ]
  ]
}
```

### 事件计数和范围分析 { #webapi_event_count_extent_analytics } 

*analytics/events/count* 资源适合与几何相关的
检索事件的计数和范围（边界框）的请求
对于特定查询。查询语法等于*events/query*
资源。请求如下所示：

    /api/analytics/events/count/eBAyeGv0exc?startDate=2016-01-01
      &endDate=2016-10-31&dimension=ou:O6uvpzGd5pu

响应将以JSON格式提供计数和范围：

```json
{
  extent: "BOX(-13.2682125910096 7.38679562779441,-10.4261178860988 9.90401290212795)",
  count: 59
}
```

### 约束与验证 { #webapi_event_analytics_constraints } 

您可以提供给
事件分析资源。如果违反任何约束，API 将
返回一个 *409 Conflict* 响应和一个类似于下面的响应消息：

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "At least one organisation unit must be specified",
  "errorCode": "E7200"
}
```

描述了事件分析 API 的可能验证错误
在下表中。

| 错误代码 | 信息 |
| ---------- | ------- |
| E7200      | 必须至少指定一个组织单位 |
| E7201      | 尺寸不能多次指定 |
| E7202      | 不能多次指定查询项 |
| E7203      | 值维也不能指定为项目或项目过滤器 |
| E7204      | 指定聚合类型时，必须指定值维或聚合数据 |
| E7205      | 必须指定开始和结束日期或至少一个期间 |
| E7206      | 开始日期晚于结束日期 |
| E7207      | 页码必须为正数 |
| E7208      | 页面大小必须为零或正数 |
| E7209      | 限制大于最大限制 |
| E7210      | 时间字段无效 |
| E7211      | 组织单位字段无效 |
| E7212      | 群集大小必须为正数 |
| E7213      | Bbox无效，必须采用以下格式：'min-lng，min-lat，max-lng，max-lat' |
| E7214      | 当指定bbox或集群大小时，必须指定集群字段 |
| E7215      | 查询项目不能同时指定图例集和选项集 |
| E7216      | 在汇总查询中使用时，查询项必须是可汇总的 |
| E7217      | 不允许用户查看事件分析数据 |
| E7218      | 未启用空间数据库支持 |
| E7219      | 数据元素必须是值类型坐标才能用作坐标字段 |
| E7220      | 属性必须是坐标值类型，才能用作坐标域 |
| E7221      | 座标栏位无效 |
| E7222      | 查询项目或过滤器无效 |
| E7223      | 值不引用数字元素或程序一部分的数据元素或属性 |
| E7224      | 项目标识符未引用程序的任何数据元素，属性或指标部分 |
| E7225      | 计划阶段对于注册分析查询中的数据元素维度是必需的 |
| E7226      | 维度不是有效的查询项目 |
| E7227      | 不支持关系实体类型 |
| E7228      | 后备坐标字段无效 |
| E7229      | 运算符不允许缺失值 |

## 入学分析 { #webapi_enrollment_analytics } 

注册分析 API 允许您访问聚合事件数据并查询*注册及其在 DHIS2 中捕获的事件数据*。除了跟踪的实体属性之外，此资源还允许您根据程序阶段和数据元素检索程序的数据。在每个注册中查询特定程序阶段的事件数据时，每个程序阶段的数据元素值将作为来自 api 的响应中的一行返回。如果在可重复的程序阶段查询数据元素，则最新的数据元素值将用于 api 响应中的该数据元素。

### 尺寸和项目 { #webapi_enrollment_analytics_dimensions } 

注册维度包括数据元素，属性，组织单位和期间。查询分析资源将仅返回符合一组条件的注册，并且不执行任何汇总。



表：招生规模

| 尺寸 | 维度 ID | 描述 |
|---|---|---|
| 程序阶段的数据元素 |  <program stage id\> 。 <data element id\> | 查询注册数据时，数据元素标识符必须包括节目阶段。维度=edqlbukwRfQ.vANAXwtLwcT |
| 属性 |  <id\> | 属性标识符 |
| 句号 | 聚乙烯 | ISO 周期和相对周期，请参阅“日期和周期格式” |
| 组织单位 | 欧 | 组织部门标识符和关键字 USER_ORGUNIT、USER_ORGUNIT_CHILDREN、USER_ORGUNIT_GRANDCHILDREN、LEVEL- <level\> 和 OU_GROUP- <group-id\> |

#### 可重复阶段{ #repeatable-stages }

数据元素标识符必须包括程序阶段。程序阶段可以重复。例如，维度 edqlbukwRfQ.vANAXwtLwcT 可以指代可重复的程序阶段。此阶段的数据元素可通过索引参数（用 [ ] 括起来）访问。

表：可重复阶段的可能索引

| 尺寸                                  | 指标参数             | DataElement值指的是                                                                |
|--------------------------------------------|------------------------------|--------------------------------------------------------------------------------------------|
| edqlbukwRfQ.vANAXwtLwcT                    | 不适用                          | 最后执行日期                                                                        |
| edqlbukwRfQ[0].vANAXwtLwcT                 | 0                            | 最后执行日期                                                                        |
| dqlbukwRfQ[-2].vANAXwtLwcT                 | -2                           | 上次执行日期倒数第二个                                                            |
| dqlbukwRfQ[1].vANAXwtLwcT                  | 1                            | 首次执行日期                                                                       |
| dqlbukwRfQ[3].vANAXwtLwcT                  | 3                            | 第三次执行日期                                                                       |
| edqlbukwRfQ[*].vANAXwtLwcT                 | *                            | 所有重复                                                                            |
| edqlbukwRfQ[-1~3].vANAXwtLwcT              | -1, 3                        | 以 -1 开始的 3 次重复（上次执行日期后的第一次）                           |
| edqlbukwRfQ[0~5~LAST_3_MONTHS].vANAXwtLwcT | 0、5、LAST_3_MONTHS          | 从最后一次执行日期开始到最近 3 个月内的第五次重复 5 次 |
| edqlbukwRfQ[-1~3~2021-01-01~2022-05-31].vANAXwtLwcT            | -1, 3, 2021-01-01,2022-05-31 | 在指定日期内以 -1 开头（上次执行日期后的第一次）重复 3 次                                     |

警告：不可重复程序阶段的索引会导致参数验证错误。

### 注册查询分析 { #webapi_enrollment_query_analytics } 

The `analytics/enrollments/query` resource lets you query for captured enrollments. This resource does not perform any aggregation, rather it lets you query and filter for information about enrollments.

    /api/analytics/enrollments/query

您可以在查询中指定任意数量的维度和任意数量的过滤器。维项目标识符可以引用程序阶段，已跟踪实体属性，固定和相对期间以及组织单位中的任何数据元素。维度可以选择具有查询运算符和过滤器。注册查询应采用以下所述的格式。

    /api/analytics/enrollments/query/ <program-id> ?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou: <ou-id> ; <ou-id> &dimension= <item-id> &dimension= <item-id> : <operator> : <filter>

例如，要从2019年1月起从“产前护理”计划中检索入学申请，该计划从属性中提取“名字”，则在第一个计划阶段包括“慢性病”和“吸烟”数据元素，并且来自以下程序阶段的“血红蛋白值”，并且仅包括具有“疯子病”的女性，您可以使用以下查询：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &尺寸=w75KJ2mc4zz&尺寸=WZbXY0S00lP.de0FEHSIoxh:eq:1&尺寸=w75KJ2mc4zz
      &尺寸=WZbXY0S00lP.sWoqcoByYmD&尺寸=edqlbukwRfQ.vANAXwtLwcT
      &开始日期=2019-01-01&结束日期=2019-01-31

要从上个月（相对于执行查询的时间点）的“产前护理”程序中检索入学登记，其中“慢性病”和“吸烟”数据元素包含在第一程序阶段，而“后续计划阶段的“血红蛋白价值”，仅包括吸烟的血红蛋白少于20岁的女性：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &尺寸=WZbXY0S00lP.de0FEHSIoxh&尺寸=w75KJ2mc4zz
      &尺寸=WZbXY0S00lP.sWoqcoByYmD:eq:1&尺寸=edqlbukwRfQ.vANAXwtLwcT:lt:20
      &dimension=pe:LAST_MONTH

可以将排序应用于注册的查询和注册的事件日期：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &列=w75KJ2mc4zz&维度=WZbXY0S00lP.sWoqcoByYmD&维度=pe:LAST_MONTH
      &stage=WZbXY0S00lP&pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

通过指定页码和页面大小参数，可以将分页应用于查询。如果指定了页码，但未指定页码，则将使用50页码。如果指定了页面大小，但未指定页面号，则将使用页面号1。要获得页面大小为10的响应的第二页，可以使用如下查询：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &尺寸=WZbXY0S00lP.de0FEHSIoxh&尺寸=w75KJ2mc4zz&尺寸=pe:LAST_MONTH
      &dimension=WZbXY0S00lP.sWoqcoByYmD&pageSize=10&page=2

#### 筛选 { #filtering } 

过滤器可以应用于数据元素，人员属性和人员标识符。过滤是通过以下格式的查询参数值完成的：

    ＆dimension = <item-id>：<operator>：<filter-value>

例如，您可以过滤“ Weight”数据元素以获取大于2000且小于4000的值，如下所示：

    ＆dimension = WZbXY0S00lP.UXz7xuGCEhU：GT：2000＆dimension = WZbXY0S00lP.UXz7xuGCEhU：LT：4000

您可以使用IN运算符过滤多个特定年龄的“年龄”属性，如下所示：

    ＆dimension = qrur9Dvnyt5：IN：18; 19; 20

您可以通过重复运算符和过滤器组件为给定项目指定多个过滤器，所有组件均用分号分隔：

    ＆dimension = qrur9Dvnyt5：GT：5：LT：15

#### 时间字段过滤{ #time-field-filtering }

By default, the `query` endpoints filter periods based on `enrollmentDate`.
However, it is possible to filter entries based on `lastUpdated` instead, by using the `timeField` query parameter.

    &timeField=LAST_UPDATED

##### NV 关键字 { #nv-keyword }
A special keyword `NV` can be used to filter by `null` values

按 AGE 筛选为空

    &dimension=qrur9Dvnyt5:EQ:NV

按 AGE 过滤不为空

    &dimension=qrur9Dvnyt5:NE:NV

按 AGE 筛选为 18、19 或为空

    &dimension=qrur9Dvnyt5:IN:18;19;NV

`NV` 可以与 `EQ`、`NE` 和 `IN` 运算符一起使用

##### 运算符 { #operators }

下面列出了可用的运算符。

表：过滤器运算符

| 操作员 | 描述 |
|---|---|
| 情商 | 等于 |
| GT | 比...更棒 |
| 通用电气 | 大于或等于 |
| LT | 少于 |
| LE | 小于或等于 |
| 东北 | 不等于 |
| 喜欢 | 喜欢（自由文本匹配） |
| 在 | 等于由“;”分隔的多个值之一 |

### 请求查询参数 { #webapi_enrollment_analytics_query_parameters } 

借助Analytics（分析）注册查询API，您可以指定一系列查询参数。



表：注册查询端点的查询参数

| 查询参数 | 需要 | 描述 | 选项（默认为默认） |
|---|---|---|---|
| 程序 | 是的 | 程序标识符。 | 任何程序标识符 |
| 开始日期 | 不 | 报名开始日期。 | yyyy-MM-dd 格式的日期 |
| 结束日期 | 不 | 报名结束日期。 | yyyy-MM-dd 格式的日期 |
| 方面 | 是的 | 维度标识符包括数据元素、属性、程序指标、期间、组织单元和组织单元组集。参数可以重复任意次数。项目过滤器可以应用于维度的格式<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 | 运营商可以EQ&#124; GT&#124;通用电气LT&#124;勒&#124; NE＆#124;喜欢&#124;在 |
| 筛选 | 不 | 维度标识符包括数据元素、属性、期间、组织单位和组织单位组集。参数可以重复任意次数。项目过滤器可以应用于维度，格式为<item-id\>:<operator\>:<filter\>。过滤器值不区分大小写。 ||
| 程序状态 | 不 | 指定要包括的注册的注册状态。 | 活跃&#124;已完成&#124;取消 |
| 相对期间日期 | 细绳 | 不 | 日期标识符，例如：“2016-01-01”。覆盖相对期间的开始日期 |
| 模式 | 不 | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. More details [here].(https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html#webapi_nti_ou_scope) | 后裔、子女、精选 |
| 升序 | 不 | 维度按升序排序，可以参考注册日期、事件日期、组织单位名称和代码。 | `ouname` &#124; `程序状态` &#124; `由显示名称创建` &#124; `lastupdatedbydisplayname` &#124; `注册日期` &#124; `事件日期` &#124; `最后更新` &#124;项目标识符 |
| 描述 | 不 | 维度按降序排序，可以引用注册日期、事件日期、组织单位名称和代码。 | `ouname` &#124; `程序状态` &#124; `由显示名称创建` &#124; `lastupdatedbydisplayname` &#124; `注册日期` &#124; `事件日期` &#124; `最后更新` &#124;项目标识符 |
| 仅坐标 | 不 | 是否仅返回具有坐标的注册。 | 假的&#124;真的 |
| 标头 | 不 | 作为响应的一部分返回的标头的名称。 | 一个或多个标头名称，以逗号分隔 |
| 页 | 不 | 页码。默认页数为 1。 | 数值正值 |
| 页面大小 | 不 | 页面大小。默认大小为每页 50 项。 | 数字零或正值 |
| 时间字段 | 不 | 用于注册聚合/查询的时间字段。仅适用于注册数据项。可以是预定义选项或具有基于时间的值类型的属性或数据元素的 ID。对于“/analytics/enrollments/”端点，默认“timeField”为 ENROLLMENT_DATE。 | ENROLLMENT_DATE &#124; LAST_UPDATED &#124; <Attribute ID\> &#124; <Data element ID\> |

#### 回应格式 { #response-formats } 

默认的响应表示格式是 JSON。请求必须使用 HTTP *GET* 方法。支持以下响应格式。

  - json（应用程序/ json）
  - xml（应用程序/ xml）
  - xls（application / vnd.ms-excel）
  - csv（应用程序/ csv）
  - html（text / html）
  - html + css（text / html）

例如，要获得Excel格式的响应，可以在请求URL中使用文件扩展名，如下所示：

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &维度=WZbXY0S00lP.de0FEHSIoxh&列=w75KJ2mc4zz
      &维度=WZbXY0S00lP.sWoqcoByYmD&维度=pe:LAST_MONTH&阶段=WZbXY0S00lP
      &pageSize=10&page=1&asc=注册日期&ouMode=后代

默认响应JSON格式将类似于以下内容：

```json
{
  "headers": [
    {
      "name": "pi",
      "column": "Enrollment",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "tei",
      "column": "Tracked entity instance",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "enrollmentdate",
      "column": "Enrollment date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "incidentdate",
      "column": "Incident date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdated",
      "column": "Last Updated",
      "valueType": "DATE",
      "type": "java.time.LocalDate",
      "hidden": false,
      "meta": true
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "createdbydisplayname",
      "column": "Created by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdatedbydisplayname",
      "column": "Last updated by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "geometry",
      "column": "Geometry",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "longitude",
      "column": "Longitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "latitude",
      "column": "Latitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "de0FEHSIoxh",
      "column": "WHOMCH Chronic conditions",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    },
    {
      "name": "sWoqcoByYmD",
      "column": "WHOMCH Smoking",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    }
  ],
  "metaData": {
    "pager": {
      "page": 2,
      "total": 163,
      "pageSize": 4,
      "pageCount": 41
    },
    "items": {
      "ImspTQPwCqd": {
        "name": "Sierra Leone"
      },
      "PFDfvmGpsR3": {
        "name": "Care at birth"
      },
      "bbKtnxRZKEP": {
        "name": "Postpartum care visit"
      },
      "ou": {
        "name": "Organisation unit"
      },
      "PUZaKR0Jh2k": {
        "name": "Previous deliveries"
      },
      "edqlbukwRfQ": {
        "name": "Antenatal care visit"
      },
      "WZbXY0S00lP": {
        "name": "First antenatal care visit"
      },
      "sWoqcoByYmD": {
        "name": "WHOMCH Smoking"
      },
      "WSGAb5XwJ3Y": {
        "name": "WHO RMNCH Tracker"
      },
      "de0FEHSIoxh": {
        "name": "WHOMCH Chronic conditions"
      }
    },
    "dimensions": {
      "pe": [],
      "ou": [
        "ImspTQPwCqd"
      ],
      "sWoqcoByYmD": [],
      "de0FEHSIoxh": []
    }
  },
  "width": 12,
  "rows": [
    [
      "A0cP533hIQv",
      "to8G9jAprnx",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Tonkomba MCHP",
      "OU_193264",
      "xIMxph4NMP1",
      "0",
      "1"
    ],
    [
      "ZqiUn2uXmBi",
      "SJtv0WzoYki",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Mawoma MCHP",
      "OU_254973",
      "Srnpwq8jKbp",
      "0",
      "0"
    ],
    [
      "lE747mUAtbz",
      "PGzTv2A1xzn",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Kunsho CHP",
      "OU_193254",
      "tdhB1JXYBx2",
      "",
      "0"
    ],
    [
      "nmcqu9QF8ow",
      "pav3tGLjYuq",
      "2019-02-03 12:05:00.0",
      "2019-02-03 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Korbu MCHP",
      "OU_678893",
      "m73lWmo5BDG",
      "",
      "1"
    ]
  ],
  "height": 4
}
```

响应的 *headers* 部分描述了查询结果的内容。注册唯一标识符、被跟踪实体实例标识符、注册日期、事件日期、几何形状、纬度、经度、组织单位名称和组织单位代码作为响应中的第一个维度出现并且将始终存在。接下来是数据元素和在请求中指定为维度的跟踪实体属性，在本例中为“WHOMCH 慢性条件”和“WHOMCH 吸烟”数据元素维度。标题部分在“名称”属性中包含维度项的标识符，在“列”属性中包含可读的维度描述。

*metaData* 部分，*ou* 对象包含映射到表示层次结构的字符串的响应中存在的所有组织单位的标识符。此层次结构字符串从根开始列出组织单位的祖先（父）的标识符。 *names* 对象包含响应中映射到其名称的所有项目的标识符。

*rows* 部分包含查询生成的注册。每一行正好代表一个注册。

### 使用计划指标{ #analytics-across-tei-relationships-with-program-indicators }进行TEI关系分析 { #analytics-across-tei-relationships-with-program-indicators } 

非汇总注册分析API还支持将程序指示器链接到关系类型，以显示应用于所列出的跟踪实体实例的相关实体的特定程序指示器的计算结果。

![](resources/images/enrollments/enrollments-pi-relationship.jpg)

For the Program Indicator/Relationship Type link to work, the `/api/analytics/enrollments/query` API requires an additional dimension which must include the chosen Relationship Type UID and the chosen Program Indicator UID:

    /api/analytics/enrollments/query/ <program-id>
      ?dimension= <relationshiptype-id> 。 <programindicator-id>

例如，要从“ WHO RMNCH Tracker”程序中检索2019年1月的注册列表，并按“与人相关的疟疾病例”类型的关系显示与该注册相关的疟疾病例数，则可以使用以下查询

    /api/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=mxZDvSZYxlw.nFICjJluo74
      &开始日期=2019-01-01&结束日期=2019-01-31

API 支持使用与“主”程序（即在`/query/` 之后指定的程序 ID）无关的程序指示符。

## 尺寸{ #webapi_dimensions }

五种资源可以轻松检索数据维度：

- [事件查询数据维度](#webapi_event_query_analytics_dimension)`/analytics/events/query/dimensions`
- [事件聚合数据维度](#webapi_event_aggregate_analytics_dimension) `/analytics/events/aggregate/dimensions`
- [注册查询数据维度](#webapi_enrollment_query_analytics_dimension) `/analytics/enrollments/query/dimensions`
- [注册聚合数据维度](#webapi_enrollment_aggregate_analytics_dimension) `/analytics/enrollments/aggregate/dimensions`
- [跟踪实体查询数据维度](#webapi_teis_query_analytics_dimensions)) `/analytics/teis/query/dimensions`

上述资源共享以下请求参数：

| 查询参数 | 必需的                                         | 描述                                                                                       | 选项                                                                                                                                              |
|-----------------|--------------------------------------------------|---------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| 筛选          | 不                                               | 允许按以下格式过滤字段值：<br/> `filter=field:OP:value&filter=field:OP:value&...` | 请参阅[维度过滤器部分]。(#webapi_analytics_dimension_filters)                                                                                |
| 领域          | 不                                               | 允许字段过滤                                                  |
| 页            | 不 | 页码                                                                                       | 默认为 1（第一页）                                                                                                                           |
| 页面大小        | 不 | 页面大小                                                                                         | 默认为每页 50 个元素                                                                                                                     |
| 寻呼          | 不 | Disables pagination when `false`                                                                  | `true` 或 `false`，默认为 `true`                                                                                                                |
| 命令           | 不 | Allows sorting on the format: `order=field:direction`                                                                   | Sortable fields: `created` (default), `lastUpdated`, `code`, `uid`, `id`, `name`, `displayName`, `dimensionType`<br/><br/> Direction can be `ASC` (default) or `DESC` |

#### 维度过滤器 { #webapi_analytics_dimension_filters }

Dimensions endpoints support filtering the output to narrow down the response to desired elements.
Filters are in the format `filter=field:op:value&filter=field:op:value&...&filter=field:op:value`.

Supported `field` values are:

- **id**/**uid** - 维度 ID
- **代码** - 尺寸代码
- **valueType** - 维度值类型
- **名称** - 维度的名称
- **dimensionType** - 维度的类型
    - `DATA_ELEMENT`
    - `PROGRAM_INDICATOR`
    - `PROGRAM_ATTRIBUTE`
    - `类别`
    - `CATEGORY_OPTION_GROUP_SET`
- **显示名称** - 维度的显示名称
- **displayShortName** - 维度的显示短名称

Supported `op`values are:

- `startsWith` - 字段开头为
- `!startsWith` - 字段不以以下内容开头
- `endsWith` - 字段以以下结尾
- `!endsWith` - 字段不以 - 结尾
- `eq` - 等于
- `ieq` - 等于忽略大小写
- `ne` - 不等于
- `like` - 包含
- `!like` - 不包含
- `ilike` - 包含忽略大小写
- `!ilike` - 不包含忽略大小写

### 事件分析维度{ #event-analytics-dimensions }
#### 事件查询分析维度{ #webapi_event_query_analytics_dimension }

`/analytics/events/query/dimensions?programStageId=...` 资源接受强制跟踪器程序阶段并返回以下数据维度：

- **与节目相关的节目指示器**（源自programStageId）
- 程序阶段*支持类型*的**数据元素**
- 与程序关联的*支持类型*的**跟踪实体属性**（源自programStageId）
- 与节目关联的类别组合中的 **类别**（源自programStageId）
- **Category option group sets** of type `ATTRIBUTE`

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

#### 事件聚合维度{ #webapi_event_aggregate_analytics_dimension }

`/analytics/events/aggregate/dimensions?programStageId=...` 资源接受强制 `programStageId` 参数并返回以下数据维度：

- 程序阶段*支持类型*的**数据元素**
- 与程序关联的*支持类型*的**跟踪实体属性**（源自programStageId）
- 与节目关联的类别组合中的 **类别**（源自programStageId）
- **Category option group sets** of type `ATTRIBUTE` associated with program (derived from programStageId)

Data elements and tracked entity attributes are considered *supported types* if their value type is one of the following:

- `数字`
- `UNIT_INTERVAL`
- `百分比`
- `整数`
- `INTEGER_POSITIVE`
- `INTEGER_NEGATIVE`
- `INTEGER_ZERO_OR_POSITIVE`
- `布尔值`
- `仅 TRUE_ONLY`

### 注册分析维度 { #enrollment-analytics-dimensions }

#### 注册查询分析维度 { #webapi_enrollment_query_analytics_dimension }

`/analytics/enrollments/query/dimensions?programId=...` 资源接受跟踪器程序的强制 ID 并返回以下数据维度：

- **程序指示器**连接到程序
- 程序中*支持类型*的**数据元素**，以及每个数据元素的程序阶段
- **与非机密程序关联的*支持类型*的跟踪实体属性**

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

#### 注册聚合维度{ #webapi_enrollment_aggregate_analytics_dimension }

`/analytics/enrollments/aggregate/dimensions?programId=...` 资源接受跟踪器程序的强制 ID，引用已注册的程序，并返回以下数据维度：

- 程序中*支持类型*的**数据元素**，以及每个数据元素的程序阶段
- **与非机密程序关联的*支持类型*的跟踪实体属性**

Data elements and tracked entity attributes are considered *supported types* if their value type is one of the following:

- `数字`
- `UNIT_INTERVAL`
- `百分比`
- `整数`
- `INTEGER_POSITIVE`
- `INTEGER_NEGATIVE`
- `INTEGER_ZERO_OR_POSITIVE`
- `布尔值`
- `仅 TRUE_ONLY`

### 跟踪实体分析维度{ #tracked-entities-analytics-dimensions }

#### 跟踪实体查询分析维度{ #webapi_teis_query_analytics_dimensions }

`/analytics/teis/query/dimensions?trackedEntityType=TET` 资源接受跟踪实体类型 `TET` 的强制 ID 并返回以下数据维度：

for each program `P` associated with a tracked entity instance of type `TET`:
- **Program indicators** associated to `P`
- **Data elements** of *supported types* in `P`, with program stage for each data element
- **与非机密程序关联的*支持类型*的跟踪实体属性**
- **Program attributes** of `P`

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

### 请求和响应示例 { #sample-request-and-response }

    GET /api/analytics/events/query/dimensions?programStageId=A03MvHHogjR&order=code&filter=名称:ilike:权重

```json
{
   "page":1,
   "total":5,
   "pageSize":50,
   "dimensions":[
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-08-06T22:49:20.128",
         "lastUpdated":"2015-08-06T22:51:19.787",
         "name":"Measles + Yellow fever doses low infant weight",
         "displayName":"Measles + Yellow fever doses low infant weight",
         "id":"tt54DiKuQ9c",
         "uid":"tt54DiKuQ9c",
         "displayShortName":"Measles + Yellow fever doses low infant weight"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2017-01-20T10:32:26.388",
         "lastUpdated":"2017-01-20T10:32:26.388",
         "name":"Weight gain(in g) between birth and last postnatal",
         "displayName":"Weight gain(in g) between birth and last postnatal",
         "id":"qhTkqwAJLMv",
         "uid":"qhTkqwAJLMv",
         "displayShortName":"Weight gain(g)"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-09-14T20:25:55.543",
         "lastUpdated":"2018-08-28T12:22:47.857",
         "name":"Average weight (g)",
         "displayName":"Average weight (g)",
         "id":"GxdhnY5wmHq",
         "uid":"GxdhnY5wmHq",
         "displayShortName":"Average weight (g)"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-08-06T22:35:40.391",
         "lastUpdated":"2015-08-06T22:35:40.391",
         "name":"BCG doses low birth weight",
         "displayName":"BCG doses low birth weight",
         "id":"hCYU0G5Ti2T",
         "uid":"hCYU0G5Ti2T",
         "displayShortName":"BCG doses low birth weight"
      },
      {
         "valueType":"NUMBER",
         "dimensionType":"DATA_ELEMENT",
         "created":"2012-09-20T17:37:45.474",
         "lastUpdated":"2014-11-11T21:56:05.418",
         "name":"MCH Weight (g)",
         "displayName":"MCH Weight (g)",
         "id":"A03MvHHogjR.UXz7xuGCEhU",
         "uid":"UXz7xuGCEhU",
         "code":"DE_2005736",
         "displayShortName":"Weight (g)"
      }
   ]
}
```

## 组织单位分析 { #webapi_org_unit_analytics } 

组织单位分析API提供有关按组织单位组集分类的组织单位的统计信息，即组织单位组集中每个组织单位组的组织单位计数。

    GET /api/orgUnitAnalytics?ou= <org-unit-id> &ougs= <org-unit-group-set-id>

该API需要至少一个组织单位和至少一个组织单位组集。可以提供多个组织单位和组集，以分号分隔。

### 请求查询参数 { #request-query-parameters } 

组织单位分析资源使您可以指定一系列查询参数：



表：组织单位分析查询参数

| 财产 | 描述 | 需要 |
|---|---|---|
| 欧 | 组织单位标识符，可能用分号分隔。 | 是的 |
| 乌格斯 | 组织单位组设置标识符，可能用分号分隔。 | 是的 |
| 列 | 组织单位组设置标识符，可能用分号分隔。定义哪些组集在表布局中呈现为列。 | 不 |

响应将包含用于父组织单位的列，用于请求的每个组织单位组集部分的列以及用于计数的列。统计信息包括组织单位的数量，该组织单位是请求中指定的组织单位的子层次结构的一部分。该响应包含一个元数据部分，该元数据部分指定由其标识符引用的响应的每个组织单位和组织单位组部分的名称。

默认响应使用单个 `count` 列进行标准化。通过使用 `columns` 查询参数指定至少一个组织单位组集，可以在表格布局中呈现响应。

### 回应格式 { #response-formats } 

组织单位分析端点支持以下表示格式：

- json（应用程序/ json）
- csv（应用程序/ csv）
- xls（application / vnd.ms-excel）
- pdf（应用程序/ pdf）

### 例子 { #examples } 

要获取组织单位和组织单位组集的组织单位分析，请执行以下操作：

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw&ougs=J5jldMd8OHv

要获取两个组织单位和两个组织单位组集合的组织单位分析数据：

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw;PMa2VCrupOd&ougs=J5jldMd8OHv;Bpx0589u8y0

要以表格模式获取组织单位分析数据，并将一组设置为列：

    GET / api / orgUnitAnalytics？ou = fdc6uOvgoji; jUb8gELQApl; lc3eMKXaEfw; PMa2VCrupOd
      ＆ougs = J5jldMd8OHv＆列= J5jldMd8OHv

### 约束与验证 { #constraints-and-validation } 

下表描述了专门针对组织单位分析API的可能的验证错误。为汇总分析API指定的某些错误也相关。

| 错误代码 | 信息 |
| ---------- | ------- |
| E7300      | 必须至少指定一个组织单位 |
| E7301      | 必须至少指定一个组织单位组集 |

## 数据集报告 { #webapi_data_set_report } 

可以使用 web api 生成数据集报告
`/dataSetReport` 资源。此资源生成有关数据集的报告
并以 HTML 表格的形式返回结果。

    /api/dataSetReport

### 请求查询参数 { #request-query-parameters } 

该请求支持以下参数：



表：数据集报告查询参数

| 范围 | 描述 | 类型 | 需要 |
|---|---|---|---|
| ds | 用于创建报告的数据集。 | 数据集UID | 是的 |
| 聚乙烯 | 创建报告的时期。可能是逗号分隔的列表。 | ISO 字符串 | 是的 |
| 欧 | 创建报告的组织单位。 | 组织单位UID | 是的 |
| 筛选 | 用作报告过滤器的过滤器。可以重复任意次数。遵循分析 API 语法。 | 一个或多个UID | 不 |
| 仅选定单位 | 是仅使用捕获的数据还是聚合的数据。 | Boolean | 不 |

The data set report resource accepts `GET` requests only. The response content type is `application/json` and returns data in a grid. This endpoint works for all types of data sets, including default, section and custom forms.

检索 2018 年 10 月月度数据集和组织单位的报告的示例请求如下所示：

    GET /api/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd&selectedUnitOnly=false

检索 2018 年 10 月、11 月和 12 月每月数据集和组织单位的报告的示例请求如下所示：

    GET /api/dataSetReport?ds=BfMAe6Itzgt&pe=201810,201811,201812&ou=ImspTQPwCqd&selectedUnitOnly=false

要获得带有过滤器的数据集报告，可以使用`filter`参数。在这种情况下，过滤器基于一个组织单位组集和两个组织单位组：

    GET /api/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd
      &filter=J5jldMd8OHv:RXL3lPSK8oG;tDZVQ1WtwpA

### 回应格式 { #response-formats } 

数据集报告端点支持以下格式的输出。您可以使用文件扩展名或 `Accept` HTTP 标头检索特定端点。

- json（应用程序/ json）
- pdf（应用程序/ pdf）
- xls（application / vnd.ms-excel）

### 自订表格 { #custom-forms } 

A dedicated endpoint is available for data sets with custom HTML forms. This endpoint returns the HTML form content with content type `text/html` with data inserted into it. Note that you can use the general data set report endpoint also for data sets with custom forms; however, that will return the report in JSON format as a grid. This endpoint only works for data sets with custom HTML forms.

    获取 /api/dataSetReport/custom

否则，此端点的语法等于常规数据集报告端点。要检索自定义HTML数据集报告，您可以发出如下请求：

    GET /api/dataSetReport/custom?ds=lyLU2wR22tC&pe=201810&ou=ImspTQPwCqd


## 推送分析 { #webapi_push_analysis } 

推送分析 API 包括用于预览推送分析的端点
报告登录用户并手动触发系统
生成和发送推送分析报告，除了正常的 CRUD
操作。使用创建和更新端点进行推送时
分析，推送分析将根据
推分析的性质。删除或更新一个
禁用推送分析，作业也将停止运行
将来。

要获得现有推送分析的 HTML 预览，您可以执行 GET
请求到以下端点：

    /api/pushAnalysis/ <id> /render

要手动触发推送分析作业，您可以执行 POST 请求以
这个端点：

    /api/pushAnalysis/ <id> /run

推送分析包含以下属性，其中一些是
自动运行推送分析作业所需：



表：推送分析属性

| 财产 | 描述 | 类型 | 需要 |
|---|---|---|---|
| 仪表板 | 报告所基于的仪表板 | 仪表板 UID | 是的 |
| 信息 | 显示在报告标题之后 | 串 | 不 |
| 收件人用户组 | 应接收报告的一组用户组 | 一个或多个用户组 UID | 不会。没有任何收件人的预定作业将被跳过。 |
| 已启用 | 指示是否应安排此推送分析。默认为假。 | Boolean | 是的。必须真实才能安排。 |
| 调度频率 | 应安排报告的频率。 | “每日”、“每周”、“每月” | 否。没有频率的推送分析将不会被安排 |
| 调度日频率 | 应安排作业的频率的日期。 | 整数。频率为“DAILY”时的任何值。当频率为“每周”时为 0-7。频率为“每月”时为 1-31 | 不会。如果没有频率集的有效频率日，则不会安排推送分析。 |

## 数据使用情况分析 { #webapi_usage_analytics } 

使用情况分析 API 可让您访问有关人们使用情况的信息
使用基于数据分析的 DHIS2。当用户访问收藏夹时，
事件被记录。事件由用户名、UID 组成
最喜欢的、事件发生的时间以及事件的类型。这
表中列出了不同类型的事件。

    /api/dataStatistics

使用情况分析 API 可让您检索使用情况的汇总快照
基于时间间隔的分析。 API 捕获用户视图（对于
例如，图表或数据透视表被用户查看的次数
用户）和保存的分析收藏夹（例如收藏夹图表和
数据透视表）。 DHIS2 将捕获夜间快照，然后
应要求汇总。

### 请求查询参数 { #webapi_usage_analytics_request_query_parameters } 

使用情况分析（数据统计）API支持两种操作：

  - *POST:* 创建一个视图事件

  - *GET:* 检索汇总统计信息

### 创建视图事件（POST） { #webapi_usage_analytics_create_view_events } 

使用情况分析 API 可让您创建事件视图。这
dataStatisticsEventType 参数描述了项目的类型
看过。最喜欢的参数表示相关的标识符
最喜欢的。

创建新事件视图的 URL
    图表：

    POST /api/dataStatistics?eventType=CHART_VIEW&favorite=LW0O27b7TdD

成功的保存操作会返回 HTTP 状态代码 201。表
下面显示了支持的事件类型。



表：支持的事件类型

| 键 | 描述 |
|---|---|
| 可视化_VIEW | 可视化视图 |
| MAP_VIEW | 地图视图 (GIS) |
| EVENT_REPORT_VIEW | 事件报告视图 |
| EVENT_CHART_VIEW | 事件图表视图 |
| EVENT_VISUALIZATION_VIEW | 事件可视化视图 |
| DASHBOARD_VIEW | 仪表板视图 |
| PASSIVE_DASHBOARD_VIEW | 仪表板视图（未明确选择仪表板时） |
| DATA_SET_REPORT_VIEW | 数据集报告视图 |

### 检索汇总的使用情况分析报告（GET） { #webapi_aggregated_usage_analytics } 

使用情况分析（数据统计）API 允许您指定特定查询
请求汇总报告时的参数。



表：聚合使用分析的查询参数（数据统计）

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 开始日期 | 是的 | 期间的开始日期 | yyyy-MM-dd 格式的日期 |
| 结束日期 | 是的 | 期间的结束日期 | yyyy-MM-dd 格式的日期 |
| 间隔 | 是的 | 要聚合的区间类型 | 日、周、月、年 |

startDate 和 endDate 参数指定期间
将在聚合中使用快照。您必须格式化日期
如上图所示。如果在指定时间段内没有保存快照，则
空列表被送回。称为间隔的参数指定了什么
将进行聚合类型。

用于创建每月查询的 API 查询
    聚合：

    GET /api/dataStatistics?startDate=2014-01-02&endDate=2016-01-01&interval=MONTH

### 检索热门收藏夹 { #webapi_usage_analytics_top_favorites } 

使用情况分析 API 可让您检索最常用的
DHIS2，并由用户。



表：最喜欢的查询参数

| 查询参数 | 需要 | 描述 | 选项 |
|---|---|---|---|
| 事件类型 | 是的 | 数据统计事件类型 | 见上表 |
| 页面大小 | 不 | 返回列表的大小 | 例如 5、10、25。默认值为 25 |
| 排序 | 不 | 下降或上升 | ASC 或 DESC。默认为 DESC。 |
| 用户名 | 不 | 如果指定，响应将仅包含该用户的收藏夹。 | 例如“管理员” |

API 查询可以不用用户名，然后会找到顶部
系统的最爱。

    /api/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25&sortOrder=ASC

如果指定了用户名，则响应将仅包含该用户的最爱。

    /api/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25
      &sortOrder=ASC&用户名=admin

### 回应格式 { #webapi_usage_analytics_response_format } 

您可以在使用情况分析响应中返回聚合数据
几种表示格式。默认格式为 JSON。这
可用的格式和内容类型有：

  - json（应用程序/ json）

  - xml（应用程序/ xml）

  - html（text / html）

请求 XML 格式的使用情况分析响应的 API 查询
    格式：

    /api/dataStatistics.xml?startDate=2014-01-01&endDate=2016-01-01&interval=WEEK

要以 JSON 格式获取使用情况分析响应：

    /api/dataStatistics?startDate=2016-02-01&endDate=2016-02-14&interval=WEEK

JSON响应如下所示：

```json
[
  {
    "year": 2016,
    "week": 5,
    "mapViews": 2181,
    "chartViews": 2227,
    "reportTableViews": 5633,
    "eventReportViews": 6757,
    "eventChartViews": 9860,
    "eventVisualizationViews": 2387,
    "dashboardViews": 10082,
    "passiveDashboardViews": 0,
    "totalViews": 46346,
    "averageViews": 468,
    "averageMapViews": 22,
    "averageChartViews": 22,
    "averageReportTableViews": 56,
    "averageEventReportViews": 68,
    "averageEventChartViews": 99,
    "averageEventVisualizationViews": 10,
    "averageDashboardViews": 101,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1805,
    "savedCharts": 2205,
    "savedReportTables": 1995,
    "savedEventReports": 1679,
    "savedEventCharts": 1613,
    "savedEventVisualizations": 1231,
    "savedDashboards": 0,
    "savedIndicators": 1831,
    "activeUsers": 99,
    "users": 969
  },
  {
    "year": 2016,
    "week": 6,
    "mapViews": 2018,
    "chartViews": 2267,
    "reportTableViews": 4714,
    "eventReportViews": 6697,
    "eventChartViews": 9511,
    "dashboardViews": 12181,
    "passiveDashboardViews": 0,
    "totalViews": 47746,
    "averageViews": 497,
    "averageMapViews": 21,
    "averageChartViews": 23,
    "averageReportTableViews": 49,
    "averageEventReportViews": 69,
    "averageEventChartViews": 99,
    "averageDashboardViews": 126,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1643,
    "savedCharts": 1935,
    "savedReportTables": 1867,
    "savedEventReports": 1977,
    "savedEventCharts": 1714,
    "savedDashboards": 0,
    "savedIndicators": 1646,
    "activeUsers": 96,
    "users": 953
  }
]
```

### 检索收藏的统计信息 { #webapi_usage_analytics_retrieve_favorite_statistics } 

您可以使用
*收藏夹* 资源，其中 *{favorite-id}* 应替换为
感兴趣的收藏夹的标识符：

    /api/dataStatistics/favorites/{favorite-id}.json

响应将包含给定收藏的观看次数和
看起来像这样：

```json
{
  "views": 3
}
```

## 地理空间特征 { #webapi_geospatial_features } 

*geoFeatures* 资源可让您从中检索地理空间信息
DHIS2。地理空间特征与组织单位一起存储。
检索特征的语法与用于检索特征的语法相同
分析资源的组织单位维度。这是
建议在继续之前阅读分析 api 资源
阅读本节。您必须使用 GET 请求类型，并且只能使用 JSON
支持响应格式。

例如，在以下位置检索所有组织单位的地理特征
组织单位层次结构中的第 3 级，您可以使用 GET 请求
使用以下网址：

    /api/geoFeatures.json?ou=ou:LEVEL-3

检索组织单位内某个级别的地理特征
组织单位的边界（例如在第 2 级），您可以使用以下 URL：

    /api/geoFeatures.json?ou=ou:LEVEL-4;O6uvpzGd5pu

The response coordinates value can be read from two properties which is decided by the parameter `coordinateField`.
  - OrganizationUnit 的 `geometry` 属性：这是未提供参数 `coordinateField` 时应用的默认行为。
  - The OrgansationUnit attribute of value type GeoJSON: the api will use the provided `coordinateField={attributeId}` to get the GeoJSON coordinates from this attribute value.

For example, to retrieve geo features for all organisation units at level 3 as above but get the coordinates from OrganisationUnit attribute `tJqtSV4quLb`

    /api/geoFeatures.json?ou=ou:LEVEL-3&coordinateField=tJqtSV4quLb

响应属性的语义描述如下
桌子。

表：地理特征响应

| 财产 | 描述 |
|---|---|
| ID | 组织单位/地理特征标识符 |
| 娜 | 组织单位/地理要素名称 |
| 六氯乙烯 | 坐标向下，指示是否存在一个或多个带有坐标的子组织单位（位于层次结构的下方） |
| hcu | 坐标向上，指示上级组织单位是否具有坐标（层次结构中的上方） |
| 乐 | 此组织单位/地理特征的级别。 |
| PG | 父图，父组织单位标识符直至层次结构中的根的图 |
| 圆周率 | 父级标识符，该组织单元的父级标识符 |
| PN | 父级名称，该组织部门的父级名称 |
| 蒂 | 地理要素类型，1 = 点，2 = 多边形或多多边形 |
| 共 | 该地理要素的坐标 |


### GeoJSON { #geojson }

要导出 GeoJSON，您只需添加 *.geosjon* 作为扩展名
端点 */api/organisationUnits*，或者您可以使用 *Accept* 标头
*应用程序/json+geojson*。

支持两个参数：`level`（默认为 1）和 `parent`（默认为根组织单位）。两者都可以多次包含。一些例子：

获得第2级和第4级的所有功能：

    /api/organizationUnits.geojson?level=2&level=4

使用边界组织单位获取级别3的所有功能：

    /api/organizationUnits.geojson?parent=fdc6uOvgoji&level=3

## 分析表挂钩 { #webapi_analytics_table_hooks } 

Analytics 表挂钩提供了一种调用 SQL 脚本的机制
在分析表生成过程的不同阶段。这
对于自定义资源和分析表中的数据很有用，例如在
以实现计算和聚合的特定逻辑。
可以在以下 API 端点操作分析表挂钩：

    / api / analyticsTableHooks

分析表钩子 API 支持标准的 HTTP CRUD 操作
用于创建（POST）、更新（PUT）、检索（GET）和删除
（删除）实体。

### 钩场 { #webapi_analytics_table_hook_fields } 

Analytics表挂钩具有以下字段：



表：分析表挂钩字段

| 领域 | 选项 | 描述 |
|---|---|---|
| 名称 | 文本 | 钩子的名称。 |
| 阶段 | RESOURCE_TABLE_POPULATED、ANALYTICS_TABLE_POPULATED | 应调用 SQL 脚本的阶段。 |
| 资源表类型 | 请参阅下面的“阶段、表类型和临时表”表中的“表类型”列 | 要为其调用 SQL 脚本的资源表的类型。仅适用于使用 RESOURCE_TABLE_POPULATED 阶段定义的挂钩。 |
| 分析表类型 | 请参阅下面的表“阶段、表类型和临时表”中的“表类型”列 | 要为其调用 SQL 脚本的分析表的类型。仅适用于使用 ANALYTICS_TABLE_POPULATED 阶段定义的挂钩。 |
| sql | 文本 | 要调用的 SQL 脚本。 |

*ANALYTICS_TABLE_POPULATED* 阶段发生在分析之后
表已填充，但在创建索引之前
临时表已与主表交换。结果，SQL
脚本应引用分析临时表，例如*分析_温度*，
*analytics_completeness_temp*、*analytics_event_temp_ebayegv0exc*。

这也适用于 *RESOURCE_TABLE_POPULATED* 阶段，它需要
放置在资源表被填充之后，索引之前
已创建并且临时表已与主表交换
桌子。因此，SQL 脚本应参考资源临时
表，例如*_orgunitstructure_temp*，*_categorystructure_temp*。

您应该只定义 *resourceTableType* 和
*analyticsTableType* 字段，取决于定义的 *phase*。

可以参考匹配的临时数据库表
仅指定挂钩表类型（其他临时表不会
可用的）。例如，如果您指定 *ORG_UNIT_STRUCTURE* 作为
资源表类型，可以参考*_orgunitstructure_temp*
仅临时数据库表。

下表显示了阶段、表格类型的有效组合
和临时表。



表：阶段、表类型和临时表

| 相 | 桌子类型 | 临时表 |
|---|---|---|
| RESOURCE_TABLE_POPULATED 资源表 | ORG_UNIT_STRUCTURE | \_组织结构\_temp |
|| DATA_SET_ORG_UNIT_CATEGORY |\_datasetorgunitcategory\_temp |
|| CATEGORY_OPTION_COMBO_NAME | \_categoryoptioncomboname\_temp |
|| DATA_ELEMENT_GROUP_SET_STRUCTURE | \_dataelementgroupsetstruct\_temp |
|| INDICATOR_GROUP_SET_STRUCTURE |\_indicatorgroupsetstructor\_temp |
|| ORG_UNIT_GROUP_SET_STRUCTURE | \_organizationunitgroupsetstructural\_temp |
|| CATEGORY_STRUCTURE | \_categorystruct\_temp |
|| DATA_ELEMENT_STRUCTURE | \_dataelementstruct\_temp |
|| PERIOD_STRUCTURE | \_periodstruct\_temp |
|| DATE_PERIOD_STRUCTURE | \_dateperiod结构\_temp |
|| DATA_ELEMENT_CATEGORY_OPTION_COMBO | \_dataelementcategoryoptioncombo\_temp |
|| DATA_APPROVAL_MIN_LEVEL | \_dataapprovalminlevel\_temp |
| ANALYTICS_TABLE_POPULATED | DATA_VALUE | 分析\_temp |
|| 完整性 | 分析\_完整性\_temp |
|| 完整性_目标 | 分析\_完整性目标\_temp |
|| ORG_UNIT_TARGET | 分析\_orgunittarget\_temp |
|| 事件 | 分析\_事件\_temp\_{程序-uid} |
|| 注册 | 分析\_注册\_temp\_{program-uid} |
|| VALIDATION_RESULT | 分析\_validationresult\_temp |

### 创建钩子 { #webapi_create_analytics_table_hook } 

要创建一个在填充资源表后运行的挂钩，您可以使用 *JSON* 作为内容类型执行 *POST* 请求：

```
POST /api/analyticsTableHooks
```

```json
{
  "name": "Update 'Area' in org unit group set resource table",
  "phase": "RESOURCE_TABLE_POPULATED",
  "resourceTableType": "ORG_UNIT_GROUP_SET_STRUCTURE",
  "sql": "update _organisationunitgroupsetstructure_temp set \"uIuxlbV1vRT\" = 'b0EsAxm8Nge'"
}
```

要创建一个在填充数据值分析表后运行的挂钩，您可以使用 *JSON* 格式执行 *POST* 请求，如下所示：

```json
{
  "name": "Update 'Currently on treatment' data in analytics table",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "DATA_VALUE",
  "sql": "update analytics_temp set monthly = '200212' where monthly in ('200210', '200211')"
}
```

要创建在填充事件分析表后运行的挂钩，您可以使用 *JSON* 格式执行 *POST* 请求，如下所示：

```json
{
  "name": "Delete data for a data element",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "EVENT",
  "sql": "delete from analytics_event_temp_lxaq7zs9vyr where dx = 'uDX9LKGRwaH'"
}
```



## SVG转换 { #webapi_svg_conversion } 

Web API 提供了可用于转换 SVG 内容的资源
转换为更广泛使用的格式，例如 PNG 和 PDF。理想情况下这个
转换应该发生在客户端，但不是所有的客户端
技术能够完成这项任务。目前为 PNG 和 PDF
支持输出格式。 SVG 内容本身应该通过
一个 *svg* 查询参数和一个可选的查询参数 *filename* 可以
用于指定响应附件文件的文件名。笔记
应该省略文件扩展名。对于 PNG，您可以发送 *POST*
使用 Content-type 请求以下 URL
`application/x-www-form-urlencoded`，与常规 HTML 表单相同
提交。

    api / svg.png

对于 PDF，您可以将 *POST* 请求发送到以下 URL
内容类型`application/x-www-form-urlencoded`。

    api / svg.pdf

表：查询参数

| 查询参数 | 需要 | 描述 |
|---|---|---|
| svg | 是的 | SVG 内容 |
| 文件名 | 不 | 返回的附件的文件名，不带文件扩展名 |

## 分析查询执行计划和成本，包括执行时间估计{ #analytics-query-execution-plan-and-costs-including-execution-time-estimation }

分析 API 提供用于调查查询性能问题的端点。它作为所有分析端点的一部分实现：

- 分析/解释
- 分析/事件/解释
- 分析/注册/解释

**例**

    GET /api/analytics/explain?displayProperty=NAME
      &dimension=dx:Uvn6LCg7dVU;sB79w2hiLp8,ou:USER_ORGUNIT
      &filter=pe:THIS_YEAR&includeNumDen=false&skipMeta=false
      &skipData=true&includeMetadataDetails=true

响应看起来像这样。

```json
{
    "headers": [
        {
            "name": "dx",
            "column": "Data",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": true
        },
        {
            "name": "ou",
            "column": "Organisation unit",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": true
        },
        {
            "name": "value",
            "column": "Value",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        }
    ],
    "metaData": {
        "items": {
            "ImspTQPwCqd": {
                "uid": "ImspTQPwCqd",
                "code": "OU_525",
                "name": "Sierra Leone",
                "dimensionItemType": "ORGANISATION_UNIT",
                "valueType": "NUMBER",
                "totalAggregationType": "SUM"
            },
            "sB79w2hiLp8": {
                "uid": "sB79w2hiLp8",
                "name": "ANC 3 Coverage",
                "description": "Total 3rd ANC visits (Fixed and outreach) by expected number of pregnant women.",
                "legendSet": "fqs276KXCXi",
                "dimensionItemType": "INDICATOR",
                "valueType": "NUMBER",
                "totalAggregationType": "AVERAGE",
                "indicatorType": {
                    "name": "Per cent",
                    "displayName": "Per cent",
                    "factor": 100,
                    "number": false
                }
            },
            "dx": {
                "uid": "dx",
                "name": "Data",
                "dimensionType": "DATA_X"
            },
            "pe": {
                "uid": "pe",
                "name": "Period",
                "dimensionType": "PERIOD"
            },
            "ou": {
                "uid": "ou",
                "name": "Organisation unit",
                "dimensionType": "ORGANISATION_UNIT"
            },
            "Uvn6LCg7dVU": {
                "uid": "Uvn6LCg7dVU",
                "code": "IN_52486",
                "name": "ANC 1 Coverage",
                "description": "Total 1st ANC visits (Fixed and outreach) by expected number of pregnant women.",
                "legendSet": "fqs276KXCXi",
                "dimensionItemType": "INDICATOR",
                "valueType": "NUMBER",
                "totalAggregationType": "AVERAGE",
                "indicatorType": {
                    "name": "Per cent",
                    "displayName": "Per cent",
                    "factor": 100,
                    "number": false
                }
            },
            "THIS_YEAR": {
                "name": "This year"
            },
            "2022": {
                "uid": "2022",
                "code": "2022",
                "name": "2022",
                "dimensionItemType": "PERIOD",
                "valueType": "NUMBER",
                "totalAggregationType": "SUM",
                "startDate": "2022-01-01T00:00:00.000",
                "endDate": "2022-12-31T00:00:00.000"
            }
        },
        "dimensions": {
            "dx": [
                "Uvn6LCg7dVU",
                "sB79w2hiLp8"
            ],
            "pe": [
                "2022"
            ],
            "ou": [
                "ImspTQPwCqd"
            ],
            "co": []
        }
    },
    "performanceMetrics": {
        "totalTimeInMillis": 90.894,
        "executionPlans": [
            {
                "timeInMillis": 12.314,
                "planningTime": 6.801,
                "executionTime": 5.513,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(daysxvalue) / 365 as value from analytics_2022 as ax where ax.\"dx\" in ('h0xKKjijTdI') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 20.21,
                    "Total Cost": 5602.98,
                    "Plan Rows": 260,
                    "Plan Width": 32,
                    "Actual Startup Time": 5.448,
                    "Actual Total Time": 5.449,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 20.21,
                            "Total Cost": 5588.33,
                            "Plan Rows": 1520,
                            "Plan Width": 32,
                            "Actual Startup Time": 0.446,
                            "Actual Total Time": 5.003,
                            "Actual Rows": 1032,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'h0xKKjijTdI'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 46,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ao_ax_2022_MClNI",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 19.83,
                                    "Plan Rows": 1520,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 0.406,
                                    "Actual Total Time": 0.407,
                                    "Actual Rows": 1032,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'h0xKKjijTdI'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            },
            {
                "timeInMillis": 38.35,
                "planningTime": 0.627,
                "executionTime": 37.723,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(value) as value from analytics_2022 as ax where ax.\"dx\" in ('Jtf34kNZhzP') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 193.57,
                    "Total Cost": 47322.83,
                    "Plan Rows": 261,
                    "Plan Width": 32,
                    "Actual Startup Time": 37.685,
                    "Actual Total Time": 37.685,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 193.57,
                            "Total Cost": 47191.38,
                            "Plan Rows": 17179,
                            "Plan Width": 32,
                            "Actual Startup Time": 1.981,
                            "Actual Total Time": 32.332,
                            "Actual Rows": 17462,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'Jtf34kNZhzP'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 1165,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ax_2022_Eb64F",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 189.27,
                                    "Plan Rows": 17179,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 1.765,
                                    "Actual Total Time": 1.765,
                                    "Actual Rows": 17462,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'Jtf34kNZhzP'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            }
        ]
    },
    "width": 0,
    "rows": [],
    "height": 0,
    "headerWidth": 2
}
```

此响应显示 PostgreSQL 规划器为所提供的语句生成的执行计划。

执行计划显示了如何扫描语句引用的表：通过普通顺序扫描、索引扫描，如果引用多个表，将使用什么连接来将每个输入表中所需的行组合在一起。

显示中最关键的部分是估计的语句执行成本，这是查询规划器对运行该语句所需时间的估计。

All entry points are secured by authorization. The `F_PERFORM_ANALYTICS_EXPLAIN` role is required.

## 分析说明 { #webapi_analytics_explain }

    /api/分析/解释

## 事件分析解释{ #webapi_event_analytics_explain }

    /api/analytics/event/aggregate/{program}/explain

    /api/analytics/event/query/{program}/explain

## 注册分析说明{ #webapi_enrollment_analytics_explain }

    /api/analytics/enrollment/query/{program}/explain


# 保养 { #maintenance } 

## 资源和分析表{ #webapi_generating_resource_analytics_tables }

DHIS2 具有一组生成的数据库表，用作
各种系统功能的基础。这些表可以执行
立即或计划通过定期执行
用户界面。它们也可以通过 Web API 生成为
本节说明。此任务通常是针对系统的一项任务
管理员而不使用客户端。

资源表由 DHIS2 应用程序内部使用
各种分析功能。这些表对用户也很有价值
编写高级 SQL 报告。它们可以通过 POST 或 PUT 生成
请求到以下 URL：

    / api / 33 / resourceTables

分析表针对数据聚合进行了优化并使用
目前在 DHIS2 中用于数据透视表模块。分析表可以
使用 POST 或 PUT 请求生成：

    / api / 33 / resourceTables / analytics



表：分析表可选查询参数

| 查询参数 | 选项 | 描述 |
|---|---|---|
| 跳过资源表 | 假的&#124;真的 | 跳过资源表的生成 |
| 跳过聚合 | 假的&#124;真的 | 跳过聚合数据和完整性数据的生成 |
| 跳过事件 | 假的&#124;真的 | 跳过事件数据的生成 |
| 跳过注册 | 假的&#124;真的 | 跳过注册数据的生成 |
| 跳过组织单位所有权 | 假的&#124;真的 | 跳过组织单位所有权数据的生成 |
| 去年 | 整数 | 要包含的最近几年数据的数量 |

“数据质量”和“数据监控”可通过监控运行
任务，由以下端点触发：

    / api / 33 / resourceTables / monitoring

此任务将分析您的验证规则，查找任何违规并
将它们保存为验证结果。

这些请求将立即返回并启动服务器端
过程。

## 保养 { #webapi_maintenance } 

要执行维护，您可以与 *maintenance* 资源进行交互。您应该使用 *POST* 或 *PUT* 作为请求方法。可以使用以下方法。

清除分析表将删除所有分析表。

    开机自检/ api / maintenance / analyticsTablesClear

分析表分析将收集有关数据库中分析表内容的统计信息。

    开机自检/ api / maintenance / analyticsTablesAnalyze

清除过期邀请将删除所有用户帐户邀请
已过期。

    开机自检/ api / maintenance / expiredInvitationsClear

期间修剪将删除未链接到任何数据的期间
值。

    开机自检/ api / maintenance / periodPruning

零数据值删除将删除链接到数据的零数据值
零数据被定义为不重要的元素：

    开机自检/ api / maintenance / zeroDataValueRemoval

软删除的数据值删除将永久删除软删除的数据值。

    开机自检/ api / maintenance / softDeletedDataValueRemoval

软删除的程序阶段实例删除将永久删除软删除的事件。

    开机自检/ api / maintenance / softDeletedProgramStageInstanceRemoval

软删除程序实例的删除将永久删除软删除的注册。

    开机自检/ api / maintenance / softDeletedProgramInstanceRemoval

软删除的跟踪实体实例的删除将永久删除软删除的跟踪实体实例。

    开机自检/ api / maintenance / softDeletedTrackedEntityInstanceRemoval

删除SQL视图将删除数据库中的所有SQL视图。请注意，它不会删除DHIS2 SQL视图实体。

    开机自检/ api / maintenance / sqlViewsDrop

创建SQL视图将重新创建数据库中的所有SQL视图。

    开机自检/ api / maintenance / sqlViewsCreate

类别选项组合更新将删除过时并为所有类别组合生成缺少的类别选项组合。

    开机自检/ api / maintenance / categoryOptionComboUpdate

也可以使用以下端点为单个类别组合更新类别选项组合。

    开机自检/ api / maintenance / categoryOptionComboUpdate / categoryCombo / <category-combo-uid>

缓存清除将清除应用程序Hibernate缓存和分析分区缓存。

    开机自检/ api / maintenance / cacheClear

组织单位路径更新将重新生成组织单位路径属性。这可能是有用的，例如如果您使用SQL导入组织单位。

    开机自检/ api / maintenance / ouPathsUpdate

数据修剪将删除完整的数据集注册，数据批准，数据价值审核和数据价值，在这种情况下是组织单位。

    开机自检/ api / maintenance / dataPruning / organisationUnits / <org-unit-id>

数据元素的数据修剪，这将删除数据值审核和数据值。

    开机自检/ api / maintenance / dataPruning / dataElement / <data-element-uid>

元数据验证将应用所有元数据验证规则，并返回操作结果。

    开机自检/ api / metadataValidation

应用程序重新加载将通过从文件系统读取来刷新已安装应用程序的DHIS2托管缓存。

    开机自检/ api / appReload

通过对api / maintenance资源的POST请求以批处理方式支持维护操作，在api / maintenance资源中，该操作作为查询参数提供：

    开机自检/ api / maintenance？analyticsTablesClear = true＆expiredInvitationsClear = true
      ＆periodPruning = true＆zeroDataValueRemoval = true＆sqlViewsDrop = true＆sqlViewsCreate = true
      ＆categoryOptionComboUpdate = true＆cacheClear = true＆ouPathsUpdate = true

## 系统信息 { #webapi_system_resource } 

系统资源为您提供方便的信息和
职能。系统资源可以在 */api/system* 中找到。

### 产生识别码 { #webapi_system_resource_generate_identifiers } 

要生成有效的随机 DHIS2 标识符，您可以执行 GET 请求
此资源：

    / api / 33 / system / id？limit = 3

*limit* 查询参数是可选的，表示有多少
您希望与响应一起返回的标识符。默认为
返回一个标识符。响应将包含一个带有
数组命名代码，类似于：

```json
{
  "codes": [
    "Y0moqFplrX4",
    "WI0VHXuWQuV",
    "BRJNBBpu4ki"
  ]
}
```

DHIS2 UID格式具有以下要求：

  - 长11个字符。

  - 仅字母数字字符，即。字母或数字字符
    (A-Za-z0-9)。

  - 以字母字符（A-Za-z）开头。

### 查看系统信息 { #webapi_system_resource_view_system_information } 

要获取有关当前系统的信息，您可以执行 GET 请求
这个网址：

    / api / 33 / system / info

支持 JSON 和 JSONP 响应格式。系统信息响应
目前包括以下属性。

```json
{
  "contextPath": "http://yourdomain.com",
  "userAgent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/29.0.1547.62",
  "calendar": "iso8601",
  "dateFormat": "yyyy-mm-dd",
  "serverDate": "2021-01-05T09:16:03.548",
  "serverTimeZoneId": "Etc/UTC",
  "serverTimeZoneDisplayName": "Coordinated Universal Time",
  "version": "2.13-SNAPSHOT",
  "revision": "11852",
  "buildTime": "2013-09-01T21:36:21.000+0000",
  "serverDate": "2013-09-02T12:35:54.311+0000",
  "environmentVariable": "DHIS2_HOME",
  "javaVersion": "1.7.0_06",
  "javaVendor": "Oracle Corporation",
  "javaIoTmpDir": "/tmp",
  "javaOpts": "-Xms600m -Xmx1500m -XX:PermSize=400m -XX:MaxPermSize=500m",
  "osName": "Linux",
  "osArchitecture": "amd64",
  "osVersion": "3.2.0-52-generic",
  "externalDirectory": "/home/dhis/config/dhis2",
  "databaseInfo": {
    "type": "PostgreSQL",
    "name": "dhis2",
    "user": "dhis",
    "spatialSupport": false
  },
  "memoryInfo": "Mem Total in JVM: 848 Free in JVM: 581 Max Limit: 1333",
  "cpuCores": 8
}
```

> **注意**
>
>如果请求此资源的用户不具有完全权限，则仅包括不被视为敏感的属性。

仅获取有关系统上下文的信息，即`contextPath` 和
`userAgent`，您可以向以下 URL 发出 GET 请求。 JSON 和
支持 JSONP 响应格式：

    / api / 33 / system / context

### 检查用户名和密码组合是否正确 { #webapi_system_resource_check_username_password } 

检查某些用户凭据（用户名和密码组合）
是正确的，您可以使用以下资源向以下资源发出 *GET* 请求
*基本认证*：

    / api / 33 / system / ping

您可以通过检查 *HTTP 来检测身份验证的结果
响应头的状态码*。可能状态的含义
代码如下。请注意，这适用于 Web API 请求
一般的。



表：HTTP 状态代码

| HTTP 状态代码 | 描述 | 结果 |
|---|---|---|
| 200 | 好的 | 认证成功 |
| 302 | 成立 | 请求中未提供任何凭据 - 未进行身份验证 |
| 401 | 未经授权 | 用户名和密码组合不正确 - 身份验证失败 |

### 查看异步任务状态 { #webapi_system_resource_view_async_task_status } 

Tasks which often take a long time to complete can be performed
asynchronously. After initiating an async task you can poll the status
through the `system/tasks` resource by supplying the task category and
the task identifier of interest.

轮询任务状态时，您需要进行身份验证
启动任务的用户。以下任务类别是
支持的：



表：任务类别

| 识别码 | 描述 |
|---|---|
| ANALYTICS_TABLE | 分析表的生成。 |
| RESOURCE_TABLE | 资源表的生成。 |
| 监控 | 数据监视/监视验证规则的处理。 |
| 数据值_导入 | 导入数据值。 |
| EVENT_IMPORT | 导入事件。 |
| ENROLLMENT_导入 | 导入注册。 |
| TEI_导入 | 导入跟踪的实体实例。 |
| METADATA_IMPORT | 导入元数据。 |
| DATA_INTEGRITY | 处理数据完整性检查。 |

每个异步任务都会自动分配一个标识符，该标识符可以
用于监视任务的状态。这个任务标识符是
当您通过各种方式启动异步任务时由 API 返回
启用异步的端点。

#### 监控任务 { #monitoring-a-task } 

您可以通过对系统任务的 GET 请求轮询任务状态
像这样的资源：

    / api / 33 / system / tasks / {task-category-id} / {task-id}

一个示例请求可能看起来像这样：

    / api / 33 / system / tasks / DATAVALUE_IMPORT / j8Ki6TgreFw

响应将提供有关状态的信息，例如
通知级别、类别、时间和状态。 *已完成的*属性
指示该过程是否被认为是完整的。

```json
[{
  "uid": "hpiaeMy7wFX",
  "level": "INFO",
  "category": "DATAVALUE_IMPORT",
  "time": "2015-09-02T07:43:14.595+0000",
  "message": "Import done",
  "completed": true
}]
```

#### 监视类别的所有任务 { #monitoring-all-tasks-for-a-category } 

您可以通过 GET 请求轮询特定类别的所有任务
系统任务资源：

    / api / 33 / system / tasks / {task-category-id}

轮询数据值导入任务状态的示例请求
看起来像这样：

    / api / 33 / system / tasks / DATAVALUE_IMPORT

#### 监控所有任务 { #monitor-all-tasks } 

您可以使用以下命令请求系统中所有当前正在运行的任务的列表
对系统任务资源的 GET 请求：

    / api / 33 / system / tasks

响应将类似于以下内容：

```json
[{
  "EVENT_IMPORT": {},
  "DATA_STATISTICS": {},
  "RESOURCE_TABLE": {},
  "FILE_RESOURCE_CLEANUP": {},
  "METADATA_IMPORT": {},
  "CREDENTIALS_EXPIRY_ALERT": {},
  "SMS_SEND": {},
  "MOCK": {},
  "ANALYTICSTABLE_UPDATE": {},
  "COMPLETE_DATA_SET_REGISTRATION_IMPORT": {},
  "DATAVALUE_IMPORT": {},
  "DATA_SET_NOTIFICATION": {},
  "DATA_INTEGRITY": {
    "OB1qGRlCzap": [{
      "uid": "LdHQK0PXZyF",
      "level": "INFO",
      "category": "DATA_INTEGRITY",
      "time": "2018-03-26T15:02:32.171",
      "message": "Data integrity checks completed in 38.31 seconds.",
      "completed": true
    }]
  },
  "PUSH_ANALYSIS": {},
  "MONITORING": {},
  "VALIDATION_RESULTS_NOTIFICATION": {},
  "REMOVE_EXPIRED_RESERVED_VALUES": {},
  "DATA_SYNC": {},
  "SEND_SCHEDULED_MESSAGE": {},
  "DATAVALUE_IMPORT_INTERNAL": {},
  "PROGRAM_NOTIFICATIONS": {},
  "META_DATA_SYNC": {},
  "ANALYTICS_TABLE": {},
  "PREDICTOR": {}
}]
```

### 查看异步任务摘要 { #view-asynchronous-task-summaries } 

任务摘要资源允许您检索任务摘要
异步任务调用。您需要指定类别和
可选的任务标识符。任务标识符可以是
从发起请求的 API 请求的响应中检索
异步任务。

要检索特定任务的摘要，您可以发出以下请求：

    / api / 33 / system / taskSummaries / {task-category-id} / {task-id}

一个示例请求可能看起来像这样：

    / api / 33 / system / taskSummaries / DATAVALUE_IMPORT / k72jHfF13J1

响应将类似于以下内容：

```json
{
  "responseType": "ImportSummary",
  "status": "SUCCESS",
  "importOptions": {
    "idSchemes": {},
    "dryRun": false,
    "async": true,
    "importStrategy": "CREATE_AND_UPDATE",
    "mergeMode": "REPLACE",
    "reportMode": "FULL",
    "skipExistingCheck": false,
    "sharing": false,
    "skipNotifications": false,
    "datasetAllowsPeriods": false,
    "strictPeriods": false,
    "strictCategoryOptionCombos": false,
    "strictAttributeOptionCombos": false,
    "strictOrganisationUnits": false,
    "requireCategoryOptionCombo": false,
    "requireAttributeOptionCombo": false,
    "skipPatternValidation": false
  },
  "description": "Import process completed successfully",
  "importCount": {
    "imported": 0,
    "updated": 431,
    "ignored": 0,
    "deleted": 0
  },
  "dataSetComplete": "false"
}
```

您还可以检索多个任务的导入摘要
具有类似请求的特定类别
这：

    / api / 33 / system / taskSummaries / {task-category-id}

### 获取外观信息 { #webapi_system_resource_get_appearance_information } 

您可以使用 GET 以 JSON 格式检索可用的标志图标
要求：

    / api / 33 / system / flags

您可以使用 GET 以 JSON 格式检索可用的 UI 样式
要求：

    / api / 33 / system / styles


## 三元组索引摘要{ #trigram-index-summary }

可以使用跟踪器搜索优化作业创建三元组索引。了解哪些跟踪实体属性已建立索引、哪些未建立索引非常有用。以下 API 可用于获取三元组索引状态的摘要。 API 支持使用字段查询参数进行字段选择和过滤。

与属性“indexedAttributes”相对应的属性当前已在系统中建立索引。与属性“indexableAttributes”相对应的属性当前未编入索引，但如果需要，可以作为创建索引的候选属性。与属性“obsoleteIndexedAttributes”相对应的属性在系统中建立了索引，但由于属性配置的更改不再使它们符合可索引的条件，这些索引已过时。

```
GET /api/39/trigramSummary
```

JSON 响应示例如下所示：

```json
{
    "indexedAttributes": [{
        "displayName": "First name",
        "id": "w75KJ2mc4zz"
    }, {
        "displayName": "Last name",
        "id": "zDhUuAYrxNC"
    }],
    "indexableAttributes": [{
        "displayName": "Phone number",
        "id": "P2cwLGskgxn"
    }],
    "obsoleteIndexedAttributes": [{
        "displayName": "TB identifier",
        "id": "xs8A6tQJY0s"
    }, {
        "displayName": "Provider ID",
        "id": "DODgdr5Oo2v"
    }]
}
```

## 集群信息 { #cluster-info }

当在集群配置中设置 DHIS 2 时，了解集群中的哪个节点充当集群的领导者非常有用。以下API可用于获取领导节点实例的详细信息。该 API 支持 JSON 和 XML 格式。

```
GET /api/36/cluster/leader
```

JSON 响应示例如下所示：

```json
{
  "leaderNodeId": "play-dhis2-org-dev",
  "leaderNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "currentNodeId": "play-dhis2-org-dev",
  "currentNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "leader": true
}
```

## 最小-最大数据元素 { #webapi_min_max_data_elements } 

min-max 数据元素资源允许您设置最小值和最大值
数据元素的值范围。它是独一无二的
组织单位、数据元素和类别选项组合。

    / api / minMaxDataElements



表：最小-最大数据元素数据结构

| 项目 | 描述 | 数据类型 |
|---|---|---|
| 来源 | 组织单位标识符 | 串 |
| 数据元素 | 数据元素标识符 | 串 |
| 选项组合 | 数据元素类别选项组合标识符 | 串 |
| 分钟 | 最小值 | 整数 |
| 最大限度 | 最大值 | 整数 |
| 生成的 | 指示该对象是否由系统生成（而不是手动设置）。 | Boolean |

您可以从以下位置检索所有最小-最大数据元素的列表
资源：

    获取 /api/minMaxDataElements.json

您可以像这样过滤响应：

    GET /api/minMaxDataElements.json?filter=dataElement.id:eq:UOlfIjgN8X6

    GET /api/minMaxDataElements.json?filter=dataElement.id:in:[UOlfIjgN8X6,xc8gmAKfO95]

min-max 数据元素的过滤器参数支持两种运算符：
eq 和 in。您还可以使用 `fields` 查询参数。

    GET /api/minMaxDataElements.json?fields=:all,dataElement[id,name]

### 添加/更新最小-最大数据元素 { #webapi_add_update_min_max_data_element } 

要添加新的最小-最大数据元素，请使用POST请求执行以下操作：

    POST /api/minMaxDataElements.json

JSON内容格式如下所示：

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

如果数据元素、组织单位和类别的组合
选项组合存在，最小值-最大值将被更新。

### 删除最小-最大数据元素 { #webapi_delete_min_max_data_element } 

要删除最小-最大数据元素，请使用DELETE方法发送请求：

    删除/api/minMaxDataElements.json

JSON内容的格式与上述类似：

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

## 锁定异常 { #webapi_lock_exceptions } 

锁定异常资源允许您打开其他锁定的数据
用于特定数据集、时期和组织的数据输入集
单元。您可以从以下资源中读取锁定异常：

    / api / lockExceptions

要创建新的锁定异常，您可以使用 POST 请求并指定
数据集、期间和组织单位：

    POST / api / lockExceptions？ds = BfMAe6Itzgt＆pe = 201709＆ou = DiszpKrYNg8

要删除锁定异常，您可以使用类似的请求语法
删除请求：

    删除/ api / lockExceptions？ds = BfMAe6Itzgt＆pe = 201709＆ou = DiszpKrYNg8




# 数据交换{ #data-exchange }

## 聚合数据交换{ #aggregate-data-exchange }

本节介绍聚合数据交换服务和API。

### 介绍 { #introduction } 

聚合数据交换服务提供了在 DHIS 2 实例和可能支持 DHIS 2 数据值集 JSON 格式的其他软件之间交换数据的能力。它还允许在 DHIS 2 的单个实例内进行数据交换，例如聚合跟踪器数据并将结果保存为聚合数据。

聚合数据交换服务适用于以下用例：

* HMIS 实例与 DHIS 2 的数据门户或数据仓库实例之间的数据交换。
* 具有单独数据的 DHIS 2 跟踪器实例与聚合 HMIS 实例之间的数据交换。
* 预先计算跟踪器数据，并将程序指标保存为聚合数据值。
* 从国家 HMIS 向全球捐助者报告数据。

### 总览 { #overview } 

The aggregate data exchange service allows for data exchange between a *source* instance of DHIS 2 and a *target* instance of DHIS 2. A data exchange can be *external*, for which the target instance is different/external to the source instance. A data exchange can also be *internal*, for which the target instance is the same as the source instance. The aggregate data exchange source can contain multiple source requests, where a source request roughly corresponds to an analytics API request.

The data value will be retrieved and transformed into the *data value set* format, and then pushed to the target instance of DHIS 2. The aggregate data exchange service supports *identifier schemes* to allow for flexibility in mapping metadata between instances.

将使用分析引擎从源实例检索和聚合数据。这意味着可以在对源实例的请求中引用数据元素、聚合指标、数据集报告率和计划指标。源请求还包含期间（支持固定期间和相对期间）以及组织单位。任意数量的*过滤器*可以应用于源请求。

数据交换可以作为计划作业运行，其中数据交换可以设置为以特定间隔运行。数据交换也可以通过 API 按需运行。

要创建和操作聚合数据交换，需要`F_AGGREGATE_DATA_EXCHANGE_PUBLIC_ADD` / `F_AGGREGATE_DATA_EXCHANGE_PRIVATE_ADD` and `F_AGGREGATE_DATA_EXCHANGE_DELETE`权限。

聚合数据交换定义是 DHIS 2 中的常规元数据，这意味着可以在 DHIS 2 的实例之间导入和导出定义。凭证（用户名和访问令牌）除外，它不会在元数据导出中公开。凭证在存储中进行加密，以提供额外的安全层。

The aggregate data exchange service was introduced in version 2.39, which means that the source instance of DHIS 2 must be version 2.39 or later. The target instance of DHIS 2 must be version 2.38 or later.

### 身份验证 { #authentication }

对于外部类型的数据交换，必须指定目标 DHIS 2 实例的基本 URL 和身份验证凭据。对于身份验证，支持基本身份验证和个人访问令牌 (PAT)。

建议指定基本身份验证或 PAT 身份验证。如果两者都指定，则 PAT 身份验证优先。

请注意，PAT 支持是在版本 2.38.1 中引入的，这意味着为了使用 PAT 身份验证，目标 DHIS 2 实例必须是版本 2.38.1 或更高版本。

### API { #api } 

聚合数据交换 API 将在以下部分中介绍。

#### 创建聚合数据交换{ #create-aggregate-data-exchange }

```
POST /api/aggregateDataExchanges
```

```
Content-Type: application/json
```

内部数据交换有效负载示例，其中事件数据使用程序指示器计算并保存为聚合数据值：

```json
{
  "name": "Internal data exchange",
  "source": {
    "params": {
      "periodTypes": [
        "MONTHLY",
        "QUARTERLY"
      ]
    },
    "requests": [
      {
        "name": "ANC",
        "visualization": null,
        "dx": [
          "fbfJHSPpUQD",
          "cYeuwXTCPkU",
          "Jtf34kNZhzP"
        ],
        "pe": [
          "LAST_12_MONTHS",
          "202201"
        ],
        "ou": [
          "ImspTQPwCqd"
        ],
        "filters": [
          {
            "dimension": "Bpx0589u8y0",
            "items": [
              "oRVt7g429ZO", 
              "MAs88nJc9nL"
            ]
          }
        ],
        "inputIdScheme": "UID",
        "outputDataElementIdScheme": "UID",
        "outputOrgUnitIdScheme": "UID",
        "outputIdScheme": "UID"
      }
    ]
  },
  "target": {
    "type": "INTERNAL",
    "request": {
      "dataElementIdScheme": "UID",
      "orgUnitIdScheme": "UID",
      "categoryOptionComboIdScheme": "UID",
      "idScheme": "UID"
    }
  }
}
```

具有基本身份验证和 ID 方案*代码*的外部数据交换负载示例，其中数据被推送到外部 DHIS 2 实例：

```json
{
  "name": "External data exchange with basic authentication",
  "source": {
    "requests": [
      {
        "name": "ANC",
        "visualization": null,
        "dx": [
          "fbfJHSPpUQD",
          "cYeuwXTCPkU",
          "Jtf34kNZhzP"
        ],
        "pe": [
          "LAST_12_MONTHS",
          "202201"
        ],
        "ou": [
          "ImspTQPwCqd"
        ],
        "inputIdScheme": "UID",
        "outputIdScheme": "CODE"
      }
    ]
  },
  "target": {
    "type": "EXTERNAL",
    "api": {
        "url": "https://play.dhis2.org/2.38.2.1",
        "username": "admin",
        "password": "district"
    },
    "request": {
      "idScheme": "CODE"
    }
  }
}
```

具有 PAT 身份验证和 ID 方案*代码*的外部数据交换负载示例，其中数据被推送到外部 DHIS 2 实例：

```json
{
  "name": "External data exchange with PAT authentication",
  "source": {
    "requests": [
      {
        "name": "ANC",
        "dx": [
          "fbfJHSPpUQD",
          "cYeuwXTCPkU",
          "Jtf34kNZhzP"
        ],
        "pe": [
          "LAST_12_MONTHS",
          "202201"
        ],
        "ou": [
          "ImspTQPwCqd"
        ],
        "inputIdScheme": "UID",
        "outputIdScheme": "CODE"
      }
    ]
  },
  "target": {
    "type": "EXTERNAL",
    "api": {
        "url": "https://play.dhis2.org/2.38.2.1",
        "accessToken": "d2pat_XIrqgAGjW935LLPuSP2hXSZwpTxTW2pg3580716988"
    },
    "request": {
      "idScheme": "CODE"
    }
  }
}
```

The syntax for the source requests follow the analytics endpoint API syntax. This means that for the `dx` part, data elements, indicators, data set reporting rates, program data elements and program indicators are supported. Note that for program data elements, the data element must be prefixed with the program identifier. For the `pe` part, relative periods as well as fixed periods are supported. For the `ou` part, user org units, org unit levels and org unit groups as well as individual org units are supported. Consult the *Analytics* chapter > the *Dimensions and items* and *The dx dimension* sections for a full explanation.

##### 响应 { #response }

```
201 Created
```

```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "response": {
    "responseType": "ObjectReport",
    "uid": "pG4bBTMiCqO",
    "klass": "org.hisp.dhis.dataexchange.aggregate.AggregateDataExchange",
    "errorReports": []
  }
}
```

#### 更新聚合数据交换{ #update-aggregate-data-exchange }

```
PUT /api/aggregateDataExchanges/{id}
```

```
Content-Type: application/json
```

请求负载与创建操作相同。

##### 响应 { #response }

```
200 OK
```

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "response": {
    "responseType": "ObjectReport",
    "uid": "pG4bBTMiCqO",
    "klass": "org.hisp.dhis.dataexchange.aggregate.AggregateDataExchange",
    "errorReports": []
  }
}
```

#### 获取聚合数据交换{ #get-aggregate-data-exchange }

```
GET /api/aggregateDataExchanges/{id}
```

``` 
Accept: application/json
```

检索端点遵循常规元数据端点字段过滤和对象过滤语义。 JSON 是唯一支持的响应格式。

##### 响应 { #response }

```
200 OK
```

#### 删除聚合数据交换{ #delete-aggregate-data-exchange }

```
DELETE /api/aggregateDataExchanges/{id}
```

##### 响应 { #response }

```
204 No Content
```

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "response": {
    "responseType": "ObjectReport",
    "uid": "pG4bBTMiCqO",
    "klass": "org.hisp.dhis.dataexchange.aggregate.AggregateDataExchange",
    "errorReports": []
  }
}
```

#### 运行聚合数据交换{ #run-aggregate-data-exchange }

聚合数据交换可以直接通过向以下端点发出 POST 请求来运行：

```
POST /api/aggregateDataExchanges/{id}/exchange
```

##### 响应 { #response }

```
200 OK
```

```json
{
  "responseType": "ImportSummaries",
  "status": "SUCCESS",
  "imported": 36,
  "updated": 0,
  "deleted": 0,
  "ignored": 0,
  "importSummaries": ["<import summaries here>"]
}
```

将返回描述数据交换结果的导入摘要，包括导入、更新、删除和忽略的数据值的数量。

#### 获取源数据{ #get-source-data }

可以通过向以下端点发出 GET 请求以分析数据格式检索聚合数据交换的源请求的聚合数据：

```
GET /api/aggregateDataExchanges/{id}/sourceData
```

```
Accept: application/json
```

##### 响应 { #response }

```
200 OK
```

##### 查询参数{ #query-parameters }

| 查询参数 | 需要 | 描述                                                  | 选项                       |
| --------------- | -------- | ------------------------------------------------------------ | ----------------------------- |
| 输出IdScheme  | 不       | 覆盖数据响应的输出标识符方案。 | 用户识别码\| 代码 \| 属性：{ID} |

响应负载格式与分析 API 端点相同。此端点对于调试目的很有用。有关更多详细信息，请参阅分析 API 指南。

#### 获取源数据值集{ #get-source-data-value-sets }

可以通过向以下端点发出 GET 请求以数据值集格式检索聚合数据交换的源请求的聚合数据：

```
GET /api/aggregateDataExchanges/{id}/sourceDataValueSets
```

```
Accept: application/json
```

##### 响应 { #response }

```
200 OK
```

##### 查询参数{ #query-parameters }

| 查询参数 | 需要 | 描述                                                  | 选项                       |
| --------------- | -------- | ------------------------------------------------------------ | ----------------------------- |
| 输出IdScheme  | 不       | 覆盖数据响应的输出标识符方案。 | 用户识别码\| 代码 \| 属性：{ID} |

响应负载格式与数据值集 API 端点相同。此端点对于调试目的很有用。有关更多详细信息，请参阅数据值集 API 指南。

### 数据模型 { #data-model } 

聚合数据交换数据模型/有效负载在以下部分中描述。

| 领域                                             | 数据类型      | 强制的   | 描述                                                  |
| ------------------------------------------------- | -------------- | ----------- | ------------------------------------------------------------ |
| 名称                                              | 串         | 是的         | 聚合数据交换的名称。独特的。                     |
| 来源                                            | 目的         | 是的         | 聚合数据交换的来源。                          |
| 源参数                                     | 目的         | 不          | 源请求的参数。                               |
| source.params.periodTypes                         | 数组/字符串   | 不          | 源请求中允许覆盖期间的期间类型。 |
| 源.请求                                   | 数组/对象   | 是的         | 来源请求。                                             |
| 源.请求.名称                              | 串         | 是的         | 源请求的名称。                                      |
| 源.请求.可视化                     | 串         | 不          | 关联可视化对象的标识符。               |
| 源.requests.dx                                | 数组/字符串   | 是的         | 源请求的数据元素、指标、数据集和程序指标的标识符。 |
| 源.requests.pe                                | 数组/字符串   | 是的         | 源请求的固定和相对周期的标识符。 |
| 来源.requests.ou                                | 数组/字符串   | 是的         | 源请求的组织单位标识符。    |
| 源.请求.过滤器                           | 数组（对象） | 不          | 过滤源请求。                              |
| 源.请求.过滤器.维度                 | 串         | 不          | 过滤器的维度标识符。                         |
| 源.请求.过滤器.项目                     | 数组/字符串   | 不          | 过滤器的项目标识符。                             |
| 源.requests.inputIdScheme                     | 串         | 不          | 输入 ID 方案，可以是 `UID`、`CODE`、`ATTRIBUTE:{ID}`。     |
| source.requests.outputDataElementIdScheme         | 串         | 不          | 输出数据元素 ID 方案，可以是 `UID`、`CODE`、`ATTRIBUTE:{ID}`。 |
| source.requests.outputOrgUnitIdScheme             | 串         | 不          | 输出组织单位 ID 方案，可以是 `UID`、`CODE`、`ATTRIBUTE:{ID}`。 |
| 源.请求.outputIdScheme                    | 串         | 不          | 输出通用ID方案，可以是`UID`，`CODE`，`ATTRIBUTE:{ID}`。 |
| 源.目标                                     | 目的         | 是的         | 聚合数据交换的目标。                         |
| 源.目标.类型                                | 串         | 是的         | Type of target, can be `EXTERNAL`, `INTERNAL`.               |
| 源.目标.api                                 | 目的         | 有条件的 | 目标 API 信息，仅对`EXTERNAL`类型是必需的。  |
| 源.目标.api.url                             | 串         | 有条件的 | Base URL of target DHIS 2 instance, do not include the `/api` part. |
| source.target.api.accessToken                     | 串         | 有条件的 | 目标 DHIS 2 实例的访问令牌 (PAT)，用于 PAT 身份验证。 |
| 源.目标.api.用户名                        | 串         | 有条件的 | 目标 DHIS 2 实例的用户名，用于基本身份验证。 |
| 源.目标.api.密码                        | 串         | 有条件的 | 目标 DHIS 2 实例的密码，用于基本身份验证。 |
| 源.目标.请求                             | 目的         | 不          | 目标请求信息。                                  |
| 源.目标.请求.dataElementIdScheme         | 串         | 不          | 输入数据元素 ID 方案，可以是 `UID`、`CODE`、`ATTRIBUTE:{ID}`。 |
| source.target.request.orgUnitIdScheme             | 串         | 不          | 输入组织部门 ID 方案，可以是 `UID`、`CODE`、`ATTRIBUTE:{ID}`。 |
| source.target.request.categoryOptionComboIdScheme | 串         | 不          | 输入类别选项组合 ID 方案，可以是 `UID`、`CODE`、`ATTRIBUTE:{ID}`。 |
| 源.目标.请求.idScheme                    | 串         | 不          | 输入通用ID方案，可以是`UID`，`CODE`，`ATTRIBUTE:{ID}`。 |

### 错误处理{ #error-handling }

当按标识符运行数据交换时，有关操作结果的信息将在响应负载中提供。响应将包含导入摘要列表，即每个源请求一个导入摘要。导入摘要将指示由于从源实例检索数据和在目标实例中导入数据而导致的任何潜在冲突。

### 例子 { #examples } 

#### 与标识符方案代码 { #external-data-exchange-with-identifier-scheme-code } 进行外部数据交换

This example will demonstrate how to exchange data based on program indicators in the source DHIS 2 instance and data elements in the target instance. The `code` identifier scheme, which means the data exchange will use the `code` property on the metadata to reference the data. Using codes is useful when the ID properties don't match across DHIS 2 instances. The example will demonstrate how data can be aggregated in the source instance, including aggregation in time and the unit hierarchy, before being exchanged with the target instance.

The example will exchange data using the DHIS 2 play environment, and refer to the 2.39 version at `https://play.dhis2.org/2.39` as the *source instance*, and the 2.38 version at `https://play.dhis2.org/2.38.2.1` as the *target instance*. Note that the URLs will change over time as new patch versions are released, so make sure to update the target URLs.

* 登录到 **source** 实例，导航到维护应用程序并观察存在三个程序指示器。

  * _BCG doses_ with code `BCG_DOSE`
  * _Measles doses_ with code `MEASLES_DOSE` 
  * _Yellow fever doses_ with code `YELLOW_FEVER_DOSE`

* 请注意，根组织单位是`塞拉利昂`，代码为`OU_525`。

* 登录到 **目标** 实例并导航到 *维护* 应用程序。创建三个数据元素，其中代码与前面提到的程序指示符相匹配：

  * Name _BCG doses_ and code `BCG_DOSE`
  * Name _Measles doses_ and code `MEASLES_DOSE`
  * 用代码`YELLOW_FEVER_DOSE`命名_黄热病剂量_

* 在 **target** 实例中，创建一个具有任意名称的新数据集，例如_数据交换_，选择树中新创建的数据元素，并将数据集分配给根组织单位_塞拉利昂_。

* Observe that the root org unit `Sierra Leone` has the code `OU_525`, which is equal to the source instance.

* 打开 HTTP 工具（例如 _Postman_）并将以下聚合数据交换有效负载放在 JSON 中。
  ```
  POST /api/aggregateDataExchanges
  ```

  ```
  Content-Type: application/json
  ```

  ```json
  {
    "name": "Immunization doses program indicators to data elements",
    "source": {
      "requests": [
        {
          "name": "Immunization doses",
          "dx": [
            "BCG_DOSE",
            "MEASLES_DOSE",
            "YELLOW_FEVER_DOSE"
          ],
          "pe": [
            "202201"
          ],
          "ou": [
            "OU_525"
          ],
          "inputIdScheme": "code",
          "outputIdScheme": "code"
        }
      ]
    },
    "target": {
      "type": "EXTERNAL",
      "api": {
        "url": "https://play.dhis2.org/2.38.2.1",
        "username": "admin",
        "password": "district"
      },
      "request": {
        "idScheme": "code"
      }
    }
  }
  ```

* In this payload, observe that for the source request, program indicators are referred to using codes. The `inputIdScheme` is set to `code`, which means that the DHIS 2 analytics engine will use the `code` property to reference metadata, such as program indicators. The `outputIdScheme` is set to `code`, which means that the `code` property will be used to reference metadata in the output. For the target request, the `idScheme` is also set to `code`, which means that the `code` property will be used to reference metadata during the data value import. Note that ID schemes can be specified per entity type, such as `dataElementIdScheme` and `orgUnitIdScheme`. 

* 请注意，期间为`202201`或_2022 年1 月_。请注意，时间段可能需要随着时间的推移而更新。

* Run the POST request to create the aggregate data exchange definition. Confirm that the API response status code is 201. Note that the name of the data exchange is unique. Take a note of the ID of the newly created object by looking at `response` > `uid` in the response body.

* 使用 POST 请求运行新创建的数据交换（将 `{id}` 替换为数据交换的 ID）：
  ```
  POST /api/aggregateDataExchanges/{id}/exchange
  ```

* 确认 API 响应指示已成功导入三个数据值。
  ```json
  {
    "responseType": "ImportSummaries",
    "status": "SUCCESS",
    "imported": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0
  }
  ```

* 在 **目标** 实例中，导航到*数据输入* 应用，选择组织单位_塞拉利昂_、数据集_数据交换_和期间_2022 年 1 月_。请注意，交换的数据值在表单中可见。

总而言之，在此示例中，事件数据记录在组织单位层次结构中从设施级别汇总到国家级别，并使用计划指标从事件数据汇总到每月数据值。通过使用`代码`属性引用元数据，数据值与目标 DHIS 2 实例交换。



# 国际化 { #i18n }

## 语言环境 { #webapi_locales } 

DHIS2 支持用户界面和数据库的翻译
内容。

### UI语言环境 { #ui-locales } 

您可以通过以下方式检索用户界面的可用区域设置
以下资源带有 GET 请求。 XML 和 JSON 资源
支持表示。

    / api / 33 / locales / ui

### 数据库内容语言环境 { #database-content-locales } 

You can retrieve and create locales for the database content with GET and POST requests through the `dbLocales` resource. XML and JSON resource representations are supported. To POST data, there are two required parameters: `country` and `language`. 

    /api/locales/dbLocales?country=US&language=en

## 翻译 { #webapi_translations } 

DHIS2 allows for translations of database content. 
If a metadata is translatable, then it will have a `translations` property.

That means you can retrieve and update translations using metadata class resources such as `api/dataElements`, `api/organisationUnits`, `api/dataSets`, etc.

### 获取翻译 { #get-translations } 

You can get translations for a metadata object such as DataElement by sending a GET request to `api/dataElements/{dataElementUID}`

The response contains full details of the DataElement which also includes the `translations` property as below

```json
{
  "id": "fbfJHSPpUQD",
  "href": "https://play.dhis2.org/dev/api/29/dataElements/fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```
You can also get only the `translations` property of an object by sending a GET request to 
`api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

### 创建/更新翻译 { #createupdate-translations }

您可以通过将具有相同 JSON 格式的 PUT 请求发送到 `api/dataElements/{dataElementUID}/translations` 来创建翻译

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "DESCRIPTION",
      "locale": "fr",
      "value": "description in french"
    },
    {
      "property": "FORM_NAME",
      "locale": "fr",
      "value": "name in french"
    }
  ]
}
```

Alternatively, you can also just update the object with payload including the `translations` property.

将 PUT 请求发送到 `api/dataElements/{dataElementUID}` 并包含完整对象负载，如下所示：

```json
{
  "id": "fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

The status code will be `204 No Content` if the data value was successfully saved or updated, or `409 Conflict` if there was a validation error (e.g. more than one `SHORT_NAME` for the same `locale`).

下表列出了支持翻译的常见属性。

表：属性名称

| 物业名称 | 描述 |
|---|---|
| 名称 | 对象名称 |
| 简称 | 对象短名称 |
| 描述 | 对象描述 |

下表列出了支持翻译的类。

表：类名称

| 班级名称 | 描述 | 其他可翻译的属性 |
|---|---|---|
| 数据元素类别选项 | 类别选项 | |
| 数据元素类别 | 类别 | |
| 数据元素类别组合 | 品类组合 | |
| 数据元素 | 数据元素 | |
| 数据元素组 | 数据元素组 | |
| 数据元素组集 | 数据元素组集 | |
| 指示符 | 指示符 | 分子描述，分母描述 |
| 指标类型 | 指示器类型 | |
| 指标组 | 指标组 | |
| 指标组集 | 指标组设置 | |
| 组织单位 | 组织单位 | |
| 组织单位组 | 组织单位组 | |
| 组织单位组集 | 组织单位组集 | |
| 数据集 | 资料集 | |
| 部分 | 数据集部分 | |
| 验证规则 | 验证规则 | 操作说明 |
| 验证规则组 | 验证规则组 | |
| 程序 | 程序 | 注册日期标签、事件日期标签 |
| 程序阶段 | 程序阶段 | 执行日期标签、到期日期标签 |
| 跟踪实体属性 | 跟踪实体属性 | |
| 被跟踪实体 | 被跟踪的实体 | |
| 关系类型 | 跟踪实体实例的关系类型 | 从到名称, 到从名称 |
| 选项集 | 选项集 | |
| 属性 | 元数据的属性 | |
| 节目通知模板 | 计划通知模板 | 主题模板、消息模板 |
| 验证通知模板 | 验证通知模板 | 主题模板、消息模板 |
| 数据集通知模板 | 数据集通知模板 | 主题模板、消息模板 |
| 可视化 | 可视化 | 标题、副标题、rangeAxisLabel、baseLineLabel、targetLineLabel、domainAxisLabel |
| 程序规则动作 | 程序规则操作 | 内容 |
| 预测变量 | 预测变量 | 名称、简称、描述、生成器描述  |
| 验证规则 | 验证规则 | 名称、描述、指令、左侧表达式、右侧表达式 |

## 国际化 { #webapi_i18n } 

为了检索翻译字符串的键值对，您可以使用
*i18n* 资源。

    / api / 33 / i18n

端点位于 */api/i18n* 并且请求格式是一个简单的
键值对数组：

```json
[
  "access_denied",
  "uploading_data_notification"
]
```

请求必须是 *POST* 类型并使用 *application/json* 作为
内容类型。使用 curl 的示例，假设请求数据已保存
作为文件`keys.json`：

```bash
curl -d @keys.json "play.dhis2.org/demo/api/33/i18n" -X POST
  -H "Content-Type: application/json" -u admin:district
```

结果将如下所示：

```json
{
  "access_denied":"Access denied",
  "uploading_data_notification":"Uploading locally stored data to the server"
}
```





# 短信 { #sms } 

## 短消息服务（SMS） { #webapi_sms } 

本节介绍用于发送和接收短文本的 SMS Web API
消息。

### 出站短信服务 { #outbound-sms-service } 

Web API 支持使用 POST 方法发送外发 SMS。短信可以
发送到单个或多个目的地。一个或多个网关需要
在使用服务之前进行配置。如果出现以下情况，将不会发送短信
没有配置网关。它需要一组接收者和
JSON 格式的消息文本，如下所示。

    / api / sms / outbound

```json
{
  "message":"Sms Text",
  "recipients": [
    "004712341234",
    "004712341235"
  ]
}
```

> **Note**
>
> Recipients list will be partitioned if the size exceeds `MAX_ALLOWED_RECIPIENTS` limit of 200.

Web API 也支持查询参数版本，但
参数化 API 只能用于发送短信到单个
目的地。

    / api / sms / outbound？message = text＆recipient = 004712341234

可以使用GET资源提取出站邮件。

    GET / api / sms / outbound
    GET / api / sms / outbound？filter = status：eq：SENT
    GET / api / sms / outbound？filter = status：eq：SENT＆fields = *

可以使用DELETE资源删除出站邮件。

    删除/ api / sms / outbound / {uid}
    删除/ api / sms / outbound？ids = uid1，uid2

#### 网关响应码 { #gateway-response-codes } 

网关可以使用以下响应代码进行响应。



表：网关响应代码

| 响应码 | 回复信息 | 详细说明 |
|---|---|---|
| RESULT_CODE_0 | 成功 | 消息已发送成功 |
| RESULT_CODE_1 | 预定的 | 消息已安排成功 |
| RESULT_CODE_22 | 内部致命错误 | 内部致命错误 |
| RESULT_CODE_23 | 验证失败 | 身份验证凭据不正确 |
| RESULT_CODE_24 | 数据验证失败 | 请求中提供的参数不正确 |
| RESULT_CODE_25 | 学分不足 | 信用额度不足，无法发送消息 |
| RESULT_CODE_26 | 上游积分不可用 | 上游积分不可用 |
| RESULT_CODE_27 | 超出了您的每日配额 | 您已超出每日配额 |
| RESULT_CODE_40 | 暂时不可用 | 服务暂时中断 |
| RESULT_CODE_201 | 超出最大批量大小 | 超出最大批量大小 |
| RESULT_CODE_200 | 成功 | 请求已成功完成 |
| RESULT_CODE_202 | 公认 | 消息将被处理 |
| RESULT_CODE_207 | 多状态 | 向 API 提交了多条消息；但是，并非所有消息都具有相同的状态 |
| RESULT_CODE_400 | 错误的请求 | 验证失败（例如参数或标头丢失/无效） |
| RESULT_CODE_401 | 未经授权的 | 验证失败。这也可能是由 IP 锁定设置引起的 |
| RESULT_CODE_402 | 需要付款 | 信用额度不足，无法发送消息 |
| RESULT_CODE_404 | 未找到 | 资源不存在 |
| RESULT_CODE_405 | 方法不允许 | 该资源不支持 Http 方法 |
| RESULT_CODE_410 | 消失了 | 手机号码被屏蔽 |
| RESULT_CODE_429 | 请求太多 | 通用速率限制错误 |
| RESULT_CODE_503 | 暂停服务 | 我们的平台发生临时错误 - 请重试 |

### 入站短信服务 { #inbound-sms-service } 

Web API 支持使用 POST 收集传入的 SMS 消息
方法。路由到 DHIS2 Web API 的传入消息可以是
使用此 API 接收。 API 收集入站 SMS 消息和
根据短信内容（SMS
命令）。下面给出了 JSON 格式的示例负载。文本，
发起者、接收日期和发送日期是强制性参数。这
其余是可选的，但系统将使用这些默认值
参数。

    / api / sms / inbound

```json
{
  "text": "sample text",
  "originator": "004712341234",
  "gatewayid": "unknown",
  "receiveddate": "2016-05-01",
  "sentdate":"2016-05-01",
  "smsencoding": "1",
  "smsstatus":"1"
}
```

可以使用GET resourcef获取入站消息

    GET / api / sms / inbound
    GET / api / sms / inbound？fields = *＆filter = smsstatus = INCOMING

可以使用DELETE资源删除入站邮件

    删除/ api / sms / inbound / {uid}
    删除/ api / sms / inbound？ids = uid1，uid2

导入所有未解析的消息

    POST /api/sms/入站/导入



表：用户查询参数

| 范围 | 类型 | 描述 |
|---|---|---|
| 信息 | 串 | 这是携带实际文本消息的强制参数。 |
| 鼻祖 | 串 | 这是强制性参数，显示该消息实际上是由谁发送的。 |
| 网关 | 串 | 这是一个可选参数，提供网关 ID。如果不存在，将存储默认文本“UNKNOWN” |
| 接收时间 | 日期 | 这是一个可选参数。它是网关接收消息的时间戳。 |

### 网关服务管理 { #gateway-service-administration } 

Web API 公开资源，这些资源提供了一种配置和
更新短信网关配置。

可以使用 GET 检索配置的不同网关的列表
方法。

    获取/api/33/网关

还可以使用特定网关类型检索配置
获取方法。

    GET /api/33/gateways/{uid}

可以使用 POST 添加新的网关配置。 POST api 需要类型请求参数，目前它的值可以有一个 *http,bulksms,clickatell,smpp*。第一个添加的网关将设置为默认值。一次只能默认一个网关。默认网关只能通过其 api 更改。如果删除了默认网关，则列表中的下一个网关将自动变为默认网关。

    POST / api / 33 / gateways

可以通过提供如下所述的uid和网关配置来更新配置

    PUT /api/33/gateways/{uids}

可以使用 DELETE 删除特定网关类型的配置
方法。

    删除/ api / 33 / gateways / {uid}

可以检索和更新默认网关。

    获取 /api/33/gateways/default

可以使用PUT方法设置默认网关。

    PUT /api/33/gateways/default/{uid}

### 网关配置 { #gateway-configuration } 

Web API 允许您创建和更新网关配置。对于每个
网关类型 JSON 有效负载中有不同的参数。
下面给出了每个网关的示例 JSON 有效负载。 POST 用于
create 和 PUT 以更新配置。标头参数可用于
GenericHttpGateway 将一个或多个参数作为 http 标头发送的情况。

#### Clickatell { #clickatell }

```json
{
  "type" : "clickatell",
  "name" : "clickatell",
  "username": "clickatelluser",
  "authToken": "XXXXXXXXXXXXXXXXXXXX",
  "urlTemplate": "https://platform.clickatell.com/messages"
}
```

#### 散装 { #bulksms } 

```json
{
  "type": "bulksms",
  "name": "bulkSMS",
  "username": "bulkuser",
  "password": "abc123"
}
```

#### SMPP网关 { #smpp-gateway } 

```json
{
  "type": "smpp",
  "name": "smpp gateway2",
  "systemId": "smppclient1",
  "host": "localhost",
  "systemType": "cp",
  "numberPlanIndicator": "UNKNOWN",
  "typeOfNumber": "UNKNOWN",
  "bindType": "BIND_TX",
  "port": 2775,
  "password":"password",
  "compressed": false
}
```

#### 通用HTTP { #generic-http } 

```json
{
  "type": "http",
  "name": "Generic",
  "configurationTemplate": "username=${username}&password=${password}&to=${recipients}&countrycode=880&message=${text$}&messageid=0",
  "useGet": false,
  "sendUrlParameters":false,
  "contentType": "APPLICATION_JSON",
  "urlTemplate":"https://samplegateway.com/messages",
  "parameters": [
    {
      "header": true,
      "encode": false,
      "key": "username",
      "value": "user_uio",
      "confidential": true
    },
    {
      "header": true,
      "encode": false,
      "key": "password",
      "value": "123abcxyz",
      "confidential": true
    },
    {
      "header": false,
      "encode": false,
      "key": "deliveryReport",
      "value": "yes",
      "confidential": false
    }
  ],
  "isDefault": false
}
```

在通用的http网关中，可以添加任意数量的参数。



表：通用 SMS 网关参数

| 范围 | 类型 | 描述 |
|---|---|---|
| 名称 | 串 | 网关名称 |
| 配置模板 | 串 | 使用参数值填充的配置模板。例如上面给出的配置模板将像这样填充 { "to": "+27001234567", "body": "Hello World!"} |
| 使用获取 | Boolean | 默认情况下将使用 Http POST 方法。为了更改它和 Http GET，用户可以将 useGet 标志设置为 true。 |
| 内容类型 | 串 | 内容类型指定正在发送的数据类型。支持的类型有 APPLICATION_JSON、APPLICATION_XML、FORM_URL_ENCODED、TEXT_PLAIN |
| url模板 | 串 | 网址模板 |
| 标头 | Boolean | 如果参数需要在Http headers中发送 |
| 编码 | Boolean | 如果参数需要编码 |
| 钥匙 | 串 | 参数键 |
| 价值 | 串 | 参数值 |
| 机密的 | Boolean | 如果参数是保密的。该参数不会通过API公开 |
| 发送Url参数 | Boolean | 如果选中此标志，则 urlTemplate 可以附加查询参数。如果网关 API 仅支持 HTTP GET，这非常有用。示例 urlTemplate 如下所示 `"urlTemplate":"https://samplegateway.com/messages?apiKey={apiKey}&to={recipients},content={text},deliveryreport=<span class='notranslate'>{dp}< /跨度>“` |

如果配置保存成功则返回 HTTP.OK 否则 *Error*

## 短信命令 { #webapi_sms_commands } 

SMS 命令用于通过 SMS 收集数据。这些命令
属于特定的解析器类型。每个解析器都有不同的功能。

可以使用GET检索命令列表。

    GET /api/sms命令

可以使用GET检索一个特定的命令。

    GET /api/smsCommands/uid

可以使用PUT更新一个特定的命令。

    PUT /api/smsCommands/uid

可以使用POST创建命令。

    POST / api / smsCommands

可以使用DELETE删除一个特定命令。

    删除/ api / smsCommands / uid

#### 短信命令类型 { #sms-command-types } 

| 类型 | 用法 |
|---|---|
|KEY_VALUE_PARSER | 用于汇总数据收集。|
|ALERT_PARSER | 发送警报消息。|
|未注册_解析器 | 用于疾病监测病例报告。|
|TRACKED_ENTITY_REGISTRATION_PARSER | 用于跟踪器实体注册。|
|PROGRAM_STAGE_DATAENTRY_PARSER | 程序阶段的数据收集。 （根据phoneNumner确定TEI）|
|EVENT_REGISTRATION_PARSER | 单个事件的注册。这用于事件程序。|

#### Android的SMS命令类型 { #sms-command-types-for-android } 

当互联网不可用时，Android应用程序可以使用这些命令类型通过SMS提交数据。 SMS由Android应用程序组成。

| 类型 | 用法 |
|---|---|
|AGGREGATE_DATASET | 用于汇总数据收集。|
|注册 | 用于跟踪器实体注册。|
|TRACKER_EVENT | 跟踪器程序的事件注册。|
|SIMPLE_EVENT | 活动节目的活动注册。|
|关系 | 建立关系。|
|删除 | 删除事件。|



# 用户数 { #users } 

## 用户数 { #webapi_users } 

本节介绍用户资源方法。

    /api/用户

### 用户查询 { #webapi_users_query } 

*users* 资源提供了额外的查询参数
标准参数（例如分页）。在用户处查询用户
资源可以使用以下参数。

表：用户查询参数

| 范围 | 类型 | 描述 |
|---|---|---|
| 询问 | 文本 | 名字、姓氏、用户名和电子邮件的查询值，不区分大小写。 |
| 电话号码 | 文本 | 查询电话号码。 |
| 可以管理 | 假的&#124;真的 | 通过管理的用户组关系过滤当前用户是否可以管理返回的用户。 |
| 授权子集 | 假的&#124;真的 | 过滤返回的用户是否具有当前用户权限的子集。 |
| 上次登录 | 日期 | 过滤晚于给定日期登录的用户。 |
| 不活跃月数 | 数 | 筛选在给定月份内未登录的用户。 |
| 自不活动以来 | 日期 | 过滤在给定日期之后未登录的用户。 |
| 自行注册 | 假的&#124;真的 | 过滤已自行注册用户帐户的用户。 |
| 邀请状态 | 没有&#124;全部&#124;已到期 | 过滤用户邀请，包括所有或过期的邀请。 |
| 欧 | 识别码 | 筛选与具有给定标识符的组织部门关联的用户。 |
| 用户组织单位 | 假的&#124;真的 | 筛选与当前登录用户链接的组织部门关联的用户。 |
| 包括儿童 | 假的&#124;真的 | 包括来自 ou 参数的所有子组织单位的用户。 |
| 页 | 数 | 页码。 |
| 页面大小 | 数 | 页面大小。 |
| 组织单位边界 | data_capture &#124; data_output &#124; tei_search | 将搜索限制为与给定边界的当前用户具有共同组织单位的用户        |

以“konan”作为名字或姓氏的最多 10 个用户的查询（案例
不敏感）与当前相比拥有部分权限的人
用户：

    /api/users?query=konan&authSubset=true&pageSize=10

要检索最初自行注册的所有用户帐户：

```
/api/users?selfRegistered=true
```

#### 用户按标识符查询 { #user-query-by-identifier }

您可以使用以下语法检索具有特定标识符的用户的完整信息。

```
/api/users/{id}
```

特定标识符的示例如下所示：

```
/api/users/OYLGMiazHtW
```

### 用户查找 { #user-lookup } 

用户查找 API 提供了一个端点来检索用户
响应包含最少的信息集。它不需要一个
特定权限，适合客户端查询信息
例如用户名和姓氏，不会暴露潜在的敏感信息
用户信息。

```
/ api / userLookup
```

用户查找端点有两种方法。

#### 通过标识符查找用户 { #user-lookup-by-identifier } 

您可以使用以下API请求按标识符进行用户查找。

```
GET / api / userLookup / {id}
```

用户 `id` 将与以下用户属性匹配
按照指定的顺序：

- 用户标识
- 用户名
- 用户名

请求示例如下所示：

```
/ api / userLookup / QqvaU7JjkUV
```

该响应将包含有关用户的最少信息。

```json
{
  "id": "QqvaU7JjkUV",
  "username": "nkono",
  "firstName": "Thomas",
  "surname": "Nkono",
  "displayName": "Thomas Nkono"
}
```

#### 用户查询 { #user-lookup-query } 

您可以使用以下API请求向用户查询。

```
GET / api / userLookup？query = {string}
```

`query` 请求参数是强制性的。查询`string`将被匹配
针对以下用户属性：

- 名字
- 姓
- 电子邮件
- 用户名

In addition to the `query` parameter the search can be restricted by the
`orgUnitBoundary` parameter as described in table of parameters for users above.

请求示例如下所示：

```
/ api / userLookup？query = John
```

响应将包含有关与请求匹配的用户的信息。

```json
{
  "users": [
    {
      "id": "DXyJmlo9rge",
      "username": "jbarnes",
      "firstName": "John",
      "surname": "Barnes",
      "displayName": "John Barnes"
    },
    {
      "id": "N3PZBUlN8vq",
      "username": "jkamara",
      "firstName": "John",
      "surname": "Kamara",
      "displayName": "John Kamara"
    }
  ]
}
```

### 用户帐户创建和更新 { #webapi_users_create_update } 

通过 API 支持创建和更新用户。一个基本的
创建用户的有效负载类似于以下示例。注意密码
将以纯文本形式发送，因此请记住为网络传输启用 SSL/HTTPS。

```json
{
  "id": "Mj8balLULKp",
  "firstName": "John",
  "surname": "Doe",
  "email": "johndoe@mail.com",
  "userCredentials": {
    "id": "lWCkJ4etppc",
    "userInfo": {
    "id": "Mj8balLULKp"
  },
  "username": "johndoe123",
  "password": "Your-password-123",
  "skype": "john.doe",
  "telegram": "joh.doe",
  "whatsApp": "+1-541-754-3010",
  "facebookMessenger": "john.doe",
  "avatar": {
    "id": "<fileResource id>"
  },
  "userRoles": [
    {
      "id": "Ufph3mGRmMo"
    }
  ]
  },
  "organisationUnits": [
    {
      "id": "Rp268JB6Ne4"
    }
  ],
  "userGroups": [
    {
      "id": "wl5cDMuUhmF"
    }
  ]
}
```

```bash
curl -X POST -d @u.json "http://server/api/33/users" -u user:pass 
  -H "Content-Type: application/json" 
```

在用户创建负载中，仅在导入时支持用户组
或一次*发布*一个用户。如果您尝试创建多个
user 在指定用户组时，您将不会收到错误，并且
将创建用户，但不会分配用户组。这是设计使然
并且由于用户和用户之间的多对多关系而受到限制
用户组，其中用户组是关系的所有者。更新
或者创建多个用户和他们的用户组，考虑一个程序来*POST*
一次一个，或 *POST* 所有用户，然后执行另一个操作
在指定新用户的标识符的同时更新他们的用户组。

When creating a user the payload may also contain user settings.
These are added as `settings` object to the root object.
Each key-value pair becomes a member in the `settings` object, for example:
```json
{
    "id": "Mj8balLULKp",
    "firstName": "John",
    "surname": "Doe",
    "settings": {
        "keyUiLocale": "de"
    },
    //...
}
```

创建用户后，*Location* 标头与
新生成的 ID（你也可以使用 `/api/system/id` 提供你自己的
端点）。然后可以使用相同的有效负载进行更新，但请记住
然后使用 *PUT* 而不是 *POST* 并且端点现在是`/api/users/ID`。

```bash
curl -X PUT -d @u.json "http://server/api/33/users/ID" -u user:pass 
  -H "Content-Type: application/json" 
```

有关可用的全部有效负载的更多信息，请参见`/ api / schemas / user`。

有关上传和检索用户头像的更多信息，请参阅
`/fileResources` 端点。

### 用户帐户邀请 { #webapi_user_invitations } 

The Web API supports inviting people to create user accounts through the
`invite` resource. To create an invitation you should POST a user in XML
or JSON format to the invite resource. A specific username can be forced
by defining the username in the posted entity. By omitting the username,
the person will be able to specify it herself. The system will send out
an invitation through email. This requires that email settings have been
properly configured.

邀请资源可用于安全地
允许人们在其他人不知道密码的情况下创建帐户
或通过以纯文本形式传输密码。用于的有效载荷
邀请与创建用户相同。 JSON 格式的示例负载
看起来像这样：

```json
{
  "firstName": "John",
  "surname": "Doe",
  "email": "johndoe@mail.com",
  "userCredentials": {
    "username": "johndoe",
    "userRoles": [{
      "id": "Euq3XfEIEbx"
    }]
  },
  "organisationUnits": [ {
    "id": "ImspTQPwCqd"
  } ],
  "userGroups": [ {
    "id": "vAvEltyXGbD"
  }]
}
```

用户邀请实体可以这样发布：

```bash
curl -d @invite.json "localhost/api/33/users/invite" -u admin:district
  -H "Content-Type:application/json" 
```

要同时向多个用户发送邀请，您必须使用
格式略有不同。对于 JSON：

```json
{
  "users": [ {
    "firstName": "John",
    "surname": "Doe",
    "email": "johndoe@mail.com",
    "userCredentials": {
      "username": "johndoe",
      "userRoles": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "organisationUnits": [ {
      "id": "ImspTQPwCqd"
      } ]
    }, {
    "firstName": "Tom",
    "surname": "Johnson",
    "email": "tomj@mail.com",
    "userCredentials": {
      "userRoles": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "organisationUnits": [ {
      "id": "ImspTQPwCqd"
      } ]
    }
  ]
}
```

要创建多个邀请，您可以将有效负载发布到
api/users/invites 资源如下：

```bash
curl -d @invites.json "localhost/api/33/users/invites" -u admin:district
  -H "Content-Type:application/json"
```

发送用户账号邀请有一定的要求
出去：

  - 电子邮件SMTP服务器必须在服务器上正确配置。

  - 被邀请的用户必须指定了有效的电子邮件。

  - 如果指定了用户名，则它不得已被其他人使用
    现有用户。

如果不满足这些要求中的任何一个，邀请资源将返回
带有 *409 Conflict* 状态代码和描述性消息。

### 用户复制 { #webapi_user_replication } 

要复制用户，您可以使用 *replica* 资源。复制一个
用户在调试或重现报告的问题时很有用
特定用户。您需要提供新的用户名和密码
您稍后将用于验证的复制用户。请注意，您
需要 ALL 权限才能执行此操作。要复制用户，您
可以发布如下所示的 JSON 有效负载：

```json
{
  "username": "user_replica",
  "password": "SecretPassword"
}
```

此有效负载可以发布到您提供的副本资源
要在 URL 中复制的用户标识符：

    / api / 33 / users / <uid> /副本

使用curl复制用户的示例如下所示：

```bash
curl -d @replica.json "localhost/api/33/users/N3PZBUlN8vq/replica"
  -H "Content-Type:application/json" -u admin:district
```

### 重置用户密码{ #webapi_user_reset }

用户管理员（具有适当的权限）可以重置其他用户的帐户
通过触发密码恢复。一旦触发，就会向用户发送一封电子邮件
包含恢复链接。点击链接的用户将获得一个表格，该表格允许
设置新密码。

To trigger this workflow for user `tH7WIiIJ0O3` use:

    POST /api/37/users/tH7WIiIJ0O3/reset

### 禁用和启用用户帐户 { #webapi_user_disable } 

可以将用户帐户标记为禁用。
禁用的用户无法再登录。

要将具有UID`tH7WIiIJ0O3`的用户标记为已禁用（需要具有适当权限的用户）：

    POST / api / 36 / users / tH7WIiIJ0O3 / disabled

要再次启用禁用的用户，请相应地使用（要求具有适当权限的用户）：

    POST / api / 36 / users / tH7WIiIJ0O3 / enabled

### 用户有效期 { #webapi_user_expiration } 

可以为用户帐户设置到期日期。
它标记了用户帐户已过期的时间点
并且无法再使用。过期的用户无法再登录。

To update the expiration date of user with UID `tH7WIiIJ0O3` 
and set it to the date `2021-01-01` use (requires user with appropriate rights):

    POST / api / 36 / users / tH7WIiIJ0O3 / expired？date = 2021-01-01

取消设置到期日期，以使帐户永不过期
相应地使用（需要具有适当权限的用户）：

    POST / api / 36 / users / tH7WIiIJ0O3 /未过期

### 用户数据批准工作流程 { #user-data-approval-workflows } 

要查看用户可以访问哪些数据批准工作流和级别，
您可以按以下方式使用* dataApprovalWorkflows *资源：

```
GET / api / users / {id} / dataApprovalWorkflows
```

## 当前用户信息 { #webapi_current_user_information } 

为了获取有关当前已验证用户的信息和
它与其他资源的关联，您可以使用 *me* 资源
（您也可以通过其旧名称 *currentUser* 来引用它）。目前
用户相关资源为您提供有用的信息
构建客户端，例如用于数据输入和用户管理。这
下面描述了这些资源及其用途。

提供有关您当前登录的用户的基本信息
in as，包括用户名、用户凭据、分配的组织
单位：

    / api / me

提供有关当前未读消息和解释的信息：

    / api / me / dashboard

为了更改密码，此端点可用于验证
新输入的密码。密码验证将基于
系统中配置的 PasswordValidationRules。这个端点支持
POST 和密码字符串应在 POST 正文中发送。

    / api / me / validatePassword

更改密码时，此端点（支持 POST）可用于
验证旧密码。密码字符串应在 POST 正文中发送。

    / api / me / verifyPassword

返回授予当前用户的权限集：

    / api / me / authorization

返回 true 或 false，表示当前用户是否已被
授予给定的`<auth>`授权：

    / api / me / authorization / <auth>

给出与当前用户相关的数据批准级别：

    / api / me / dataApprovalLevels

提供当前用户可以访问的数据批准工作流。
对于每个工作流程，显示用户可能看到的数据批准级别，以及
他们在每个级别上具有什么权限：

    / api / me / dataApprovalWorkflows



# 设置和配置 { #settings-and-configuration } 

## 系统设置 { #webapi_system_settings } 

您可以通过与
*系统设置*资源。系统设置是一个简单的键值对，
其中键和值都是纯文本字符串。保存或
更新系统设置，您可以向以下 URL 发出 *POST* 请求：

    / api / 33 / systemSettings / my-key？value = my-val

或者，您可以将设置值作为请求正文提交，
其中内容类型设置为“文本/纯文本”。例如，您可以使用
像这样卷曲：

```bash
curl "play.dhis2.org/demo/api/33/systemSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

要批量设置系统设置，您可以发送带有
使用 POST 请求的每个系统设置键值对的属性和值：

```json
{
  "keyApplicationNotification": "Welcome",
  "keyApplicationIntro": "DHIS2",
  "keyApplicationFooter": "Read more at dhis2.org"
}
```

可以通过指定语言环境来设置可翻译设置键的翻译
可以指定的查询参数和翻译值
作为查询参数或与正文有效负载一起使用。查看示例网址：

    / api / 33 / systemSettings / <my-key>？locale = <my-locale>＆value = <my-translated-value>

您应该将 my-key 替换为您的真实密钥，并将 my-val 替换为您的真实密钥
价值。检索给定键的值（以 JSON 或纯文本形式）
您可以向以下 URL 发出 *GET* 请求：

    / api / 33 / systemSettings / my-key

或者，您可以将键指定为查询参数：

    / api / 33 / systemSettings？key =我的密钥

您可以通过重复键以 JSON 形式检索特定的系统设置
查询参数：

```bash
curl "play.dhis2.org/demo/api/33/systemSettings?key=keyApplicationNotification&key=keyApplicationIntro"
  -u admin:district
```

您可以使用GET请求检索所有系统设置：

    / api / 33 / systemSettings

要检索给定可翻译键的特定翻译，您可以指定
作为查询参数的语言环境：

    / api / 33 / systemSettings / <my-key>？locale = <my-locale>

如果存在，则返回给定语言环境的翻译。否则默认
值被返回。如果没有为可翻译键指定语言环境，则用户默认
UI 语言环境用于获取正确的翻译。如果给定的翻译不是
现在，再次返回默认值。

可翻译键的优先级如下：

    指定的区域设置>用户的默认UI区域设置> defaut值

要删除系统设置，您可以向 URL 发出 *DELETE* 请求
类似于上面用于检索的那个。如果一个可翻译的键是
使用，所有现有的翻译也将被删除。

仅删除可翻译键的特定翻译，相同的 URL
至于添加翻译应该使用，空值应该是
假如：

    / api / 33 / systemSettings / <my-key>？locale = <my-locale>＆value =

可用的系统设置在下面列出。

表：系统设置

| 键 | 描述 | 可翻译 |
|---|---|---|
| keyUiLocale | 用户界面的区域设置 | 不 |
| 密钥数据库区域设置 | 数据库的区域设置 | 不 |
| 关键分析显示属性 | 要在分析中显示的属性。默认值：“名称” | 不 |
| 键分析数字组分隔符 | 用于分隔数字组的分隔符 | 不 |
| keyCurrentDomainType | 尚未使用 | 不 |
| keyTracker仪表板布局 | 由跟踪器捕获使用 | 不 |
| 申请标题 | 应用程序标题。默认值：“DHIS2” | 是的 |
| 关键应用介绍 | 应用介绍 | 是的 |
| 关键应用通知 | 申请通知 | 是的 |
| 关键应用程序页脚 | 应用程序左页脚 | 是的 |
| 关键应用程序右页脚 | 应用程序右页脚 | 是的 |
| 键标志 | 应用标志 | 不 |
| 关键标志图像 | 仪表板菜单中使用的标志 | 不 |
| 启动模块 | 应用程序的起始页。默认值：“dhis-web-dashboard-integration” | 不 |
| 启动模块启用轻量级 | 用于渲染轻量级登陆页面的起始页面应用程序。默认值：“假” | 不 |
| 因子偏差 | 数据分析标准偏差因子。默认值：“2d” | 不 |
| 密钥电子邮件主机名 | 电子邮件服务器主机名 | 不 |
| 关键电子邮件端口 | 电子邮件服务器端口 | 不 |
| 关键电子邮件Tls | 使用 TLS。默认值：“真” | 不 |
| 关键电子邮件发送者 | 电子邮件发件人 | 不 |
| key电子邮件用户名 | 电子邮件服务器用户名 | 不 |
| 密钥电子邮件密码 | 电子邮件服务器密码 | 不 |
| 最小密码长度 | 密码最小长度 | 不 |
| 最大密码长度 | 密码最大长度 | 不 |
| 按键短信设置 | 短信配置 | 不 |
| keyCache策略 | 缓存策略。默认值：“CACHE_6AM_TOMORROW” | 不 |
| 密钥可缓存性 | 公共或私人。确定是否允许代理服务器缓存数据。 | 不 |
| 电话号码区号 | 电话号码 区号 | 不 |
| 多组织单位表格 | 启用多组织单位形式。默认值：“假” | 不 |
| 密钥配置 || 不 |
| 关键账户恢复 | 启用用户帐户恢复。默认值：“假” | 不 |
| keyLock多次登录失败 | 多次登录失败后启用锁定访问 | 不 |
| 谷歌分析UA | 用于跟踪网站使用情况的 Google Analytic UA 密钥 | 不 |
| 凭证过期 | 需要更改用户帐户密码。默认值：“0”（从不） | 不 |
| 凭证过期警报 | 当凭证接近到期日期时启用警报 | 不 |
| 凭证过期提醒天数 | 应在实际到期之前发送凭证到期警报的天数。默认值：28 | 不 |
| 账户到期提醒 | 向帐户因设置的到期日期而即将到期的用户发送警报电子邮件。默认值：“假” | 不 |
| 帐户过期天数 | 应在实际到期之前发送帐户到期警报的天数。默认值：7 | 不 |
| 密钥自助注册无验证码 | 自我注册不需要重新验证。默认值：“假” | 不 |
| 验证码秘密 | Google API 验证码秘密。默认值：dhis2 play 实例 API 密钥，但这仅适用于您的本地实例，不适用于生产环境。 | 不 |
| 验证码网站 | Google API 验证码网站。默认值：dhis2 play 实例 API 站点，但这仅适用于您的本地实例，不适用于生产环境。 | 不 |
| keyCanGrantOwnUserAuthorityGroups | 允许用户授予自己的用户角色。默认值：“假” | 不 |
| keySqlViewMaxLimit | SQL 视图的最大限制 | 不 |
| keyRespectMetaDataStartEndDatesInAnalyticsTableExport | 当“true”时，分析将跳过不在类别选项的开始和结束日期内的数据。默认值：“假” | 不 |
| keySkipDataTypeValidationInAnalyticsTableExport | 在分析表导出中跳过数据类型验证 | 不 |
| 键自定义登录页面徽标 | 自定义登录页面的徽标 | 不 |
| 键自定义顶部菜单徽标 | 自定义顶部菜单的徽标 | 不 |
| keyCacheAnalyticsDataYearThreshold | 早于该值（以年为单位）的分析数据将始终被缓存。 “0”禁用此设置。默认值：0 | 不 |
| analyticsFinancialYearStart | Set financial year start. Default: October | 不 |
| keyIgnoreAnalyticsApprovalYearThreshold | "0" check approval for all data. "-1" disable approval checking. "1" or higher checks approval for all data that is newer than "1" year. | 不 |
| keyAnalyticsMaxLimit | Maximum number of analytics records. Default: "50000" | 不 |
| keyAnalyticsPeriodYearsOffset | Defines the years' offset to be used in the analytics export process. If the year of a respective date is out of the offset the system sends back a warning message during the process. At this point, the period generation step is skipped. ie.: suppose the system user sets the offset value to `5`, and we are in the year 2023. It means that analytics will accept exporting dates from 2018 (inclusive) to 2028 (inclusive). Which translates to: [2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028]. NOTE: The offset will have a significant influence on resource usage. Higher values will trigger higher usage of memory RAM/HEAP and CPU. Setting negative numbers to this key will disable any kind of validation (which means no warnings) and the internal range of years will be used (1970 to current year plus 10) Default: 22 | 不 |
| keyDatabaseServerCpus | Number of database server CPUs. Default: "0" (Automatic) | 不 |
| keyLastSuccessfulAnalyticsTablesRuntime | Keeps timestamp of last successful analytics tables run | 不 |
| keyLastSuccessfulLatestAnalyticsPartitionRuntime | Keeps timestamp of last successful latest analytics partition run | 不 |
| keyLastMonitoringRun | Keeps timestamp of last monitoring run | 不 |
| keyLastSuccessfulDataSynch | Keeps timestamp of last successful data values synchronization | 不 |
| keyLastSuccessfulEventsDataSynch | Keeps timestamp of last successful Event programs data synchronization | 不 |
| keyLastCompleteDataSetRegistrationSyncSuccess | Keeps timestamp of last successful completeness synchronization | 不 |
| syncSkipSyncForDataChangedBefore | Specifies timestamp used to skip synchronization of all the data changed before this point in time | 不 |
| keyLastSuccessfulAnalyticsTablesUpdate | Keeps timestamp of last successful analytics tables update | 不 |
| keyLastSuccessfulLatestAnalyticsPartitionUpdate | Keeps timestamp of last successful latest analytics partition update | 不 |
| keyLastSuccessfulResourceTablesUpdate | Keeps timestamp of last successful resource tables update | 不 |
| keyLastSuccessfulSystemMonitoringPush | Keeps timestamp of last successful system monitoring push | 不 |
| keyLastSuccessfulMonitoring | Keeps timestamp of last successful monitoring | 不 |
| keyNextAnalyticsTableUpdate | Keeps timestamp of next analytics table update | 不 |
| helpPageLink | Link to help page. Default: "[https://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html](http://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html) | 不 |
| keyAcceptanceRequiredForApproval | Acceptance required before approval. Default: "false" | 不 |
| keySystemNotificationsEmail | Where to email system notifications | 不 |
| keyAnalysisRelativePeriod | Default relative period for analysis. Default: "LAST_12_MONTHS" | 不 |
| keyRequireAddToView | Require authority to add to view object lists. Default: "false" | 不 |
| keyAllowObjectAssignment | Allow assigning object to related objects during add or update. Default: "false" | 不 |
| keyUseCustomLogoFront | Enables the usage of a custom logo on the front page. Default: "false" | 不 |
| keyUseCustomLogoBanner | Enables the usage of a custom banner on the website. Default: "false" | 不 |
| keyDataImportStrictPeriods || 不 |
| keyDataImportStrictPeriods | Require periods to match period type of data set. Default: "false" | 不 |
| keyDataImportStrictDataElements | Require data elements to be part of data set. Default: "false" | 不 |
| keyDataImportStrictCategoryOptionCombos | Require category option combos to match category combo of data element. Default: "false" | 不 |
| keyDataImportStrictOrganisationUnits | Require organisation units to match assignment of data set. Default: "false" | 不 |
| keyDataImportStrictAttributeOptionsCombos | Require attribute option combis to match category combo of data set. Default: "false" | 不 |
| keyDataImportStrictDataSetApproval | true: If an already approved dataset exists for a given data value entry is not permitted; false: If a not yet approved dataset exists for a given data value entry is permitted. Default: "true" | 不 |
| keyDataImportStrictDataSetLocking | true: If a dataset exists for which entry expired without lock exception for a given data value entry is not permitted; false: If a dataset exists for which entry is not expired or a lock exception applies for a given data value entry is permitted. Default: "true" | 不 |
| keyDataImportStrictDataSetInputPeriods | true: If a dataset exists for which the input period is closed for a given data value entry is not permitted; false: If a dataset exists for which data the input period is open for a given data value entry is permitted. Default: "true" | 不 |
| keyDataImportRequireCategoryOptionCombo | Require category option combo to be specified. Default: "false" | 不 |
| keyDataImportRequireAttributeOptionCombo | Require attribute option combo to be specified. Default: "false" | 不 |
| keyCustomJs | Custom JavaScript to be used on the website | 不 |
| keyCustomCss | Custom CSS to be used on the website | 不 |
| keyCalendar | The calendar type. Default: "iso8601". | 不 |
| keyDateFormat | The format in which dates should be displayed. Default: "yyyy-MM-dd". | 不 |
| keyStyle | The style used on the DHIS2 webpages. Default: "light_blue/light_blue.css". | 不 |
| keyRemoteInstanceUrl | Url used to connect to remote instance | 不 |
| keyRemoteInstanceUsername | Username used to connect to remote DHIS2 instance | 不 |
| keyRemoteInstancePassword | Password used to connect to remote DHIS2 instance | 不 |
| keyGoogleMapsApiKey | Google Maps API key | 不 |
| keyGoogleCloudApiKey | Google Cloud API key | 不 |
| keyLastMetaDataSyncSuccess | Keeps timestamp of last successful metadata synchronization | 不 |
| keyVersionEnabled | Enables metadata versioning | 不 |
| keyMetadataFailedVersion | Keeps details about failed metadata version sync | 不 |
| keyMetadataLastFailedTime | Keeps timestamp of last metadata synchronization failure | 不 |
| keyLastSuccessfulScheduledProgramNotifications || 不 |
| keyLastSuccessfulScheduledDataSetNotifications || 不 |
| keyRemoteMetadataVersion | Details about metadata version of remote instance | 不 |
| keySystemMetadataVersion | Details about metadata version of the system | 不 |
| keyStopMetadataSync | Flag to stop metadata synchronization | 不 |
| keyFileResourceRetentionStrategy | 确定与已删除或更新的值相关联的文件资源保留的时间长度。NONE，THREE_MONTHS，ONE_YEAR或FOREVER。 | 不 |
| syncMaxRemoteServerAvailabilityCheckAttempts | Specifies how many times the availability of remote server will be checked before synchronization jobs fail. | 不 |
| syncMaxAttempts | Specifies max attempts for synchronization jobs | 不 |
| syncDelayBetweenRemoteServerAvailabilityCheckAttempts | Delay between remote server availability checks | 不 |
| lastSuccessfulDataStatistics | Keeps timestamp of last successful data analytics | 不 |
| keyHideDailyPeriods | Not in use | 不 |
| keyHideWeeklyPeriods || 不 |
| keyHideBiWeeklyPeriods | Boolean flag used to hide/show bi-weekly periods | 不 |
| keyHideMonthlyPeriods || 不 |
| keyHideBiMonthlyPeriods || 不 |
| keyGatherAnalyticalObjectStatisticsInDashboardViews | Whether to gather analytical statistics on objects when they are viewed within a dashboard | 不 |
| keyCountPassiveDashboardViewsInUsageAnalytics | Counts "passive" dashboard views (not selecting a particular dashboard) in usage analytics | 不 |
| keyDashboardContextMenuItemSwitchViewType | Allow users to switch dashboard favorites' view type | 是的 |
| keyDashboardContextMenuItemOpenInRelevantApp | Allow users to open dashboard favorites in relevant apps | 是的 |
| keyDashboardContextMenuItemShowInterpretationsAndDetails | Allow users to show dashboard favorites' interpretations and details | 是的 |
| keyDashboardContextMenuItemViewFullscreen | Allow users to view dashboard favorites in fullscreen | 是的 |
| keyParallelJobsInAnalyticsTableExport | Returns the number of parallel jobs to use for processing analytics tables. It takes priority over "keyDatabaseServerCpus". Default: -1 | 不 |

## 用户设置 { #webapi_user_settings } 

您可以通过与 *userSettings* 交互来操作用户设置
资源。用户设置是一个简单的键值对，其中键
并且值是纯文本字符串。用户设置将链接到
已针对 Web API 请求进行身份验证的用户。返回列表
在所有用户设置中，您可以向以下 URL 发送 *GET* 请求：

    / api / 33 / userSettings

用户未设置的用户设置，将回退到等效的
系统设置。只返回用户明确设置的值，
您可以将 ?useFallback=false 附加到上述 URL，如下所示：

    / api / 33 / userSettings？useFallback = false

要为当前经过身份验证的用户保存或更新设置，您可以
向以下 URL 发出 *POST* 请求：

    / api / 33 / userSettings / my-key？value = my-val

您可以指定要为其显式保存设置的用户
这个语法：

    / api / 33 / userSettings / my-key？user = username＆value = my-val

或者，您可以将设置值作为请求正文提交，
其中内容类型设置为“文本/纯文本”。例如，您可以使用
像这样卷曲：

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

例如，要将当前用户的 UI 语言环境设置为法语，您
可以使用以下命令。

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/keyUiLocale?value=fr" 
  -X POST -u admin:district
```

您应该将 my-key 替换为您的真实密钥，并将 my-val 替换为您的真实密钥
价值。要以纯文本形式检索给定键的值，您可以
对以下 URL 的 *GET* 请求：

    / api / 33 / userSettings / my-key

要删除用户设置，您可以向 URL 发出 *DELETE* 请求
类似于上面用于检索的那个。

可用的系统设置在下面列出。



Table: User settings

| 键 | 选项 | 描述 |
|---|---|---|
| keyStyle | light_blue/light_blue.css &#124; green/green.css &#124; vietnam/vietnam.css | User interface stylesheet. |
| keyMessageEmailNotification | false &#124; true | Whether to send email notifications. |
| keyMessageSmsNotification | 假的&#124;真的 | Whether to send SMS notifications. |
| keyUiLocale | Locale value | User interface locale. |
| keyDbLocale | 区域设置值 | Database content locale. |
| keyAnalysisDisplayProperty | name &#124; shortName | Property to display for metadata in analysis apps. |
| keyCurrentDomainType | all &#124; aggregate &#124; tracker | Data element domain type to display in lists. |
| keyAutoSaveCaseEntryForm | false &#124; true | Save case entry forms periodically. |
| keyAutoSaveTrackedEntityForm | 假的&#124;真的 | Save person registration forms periodically. |
| keyAutoSaveDataEntryForm | 假的&#124;真的 | Save aggregate data entry forms periodically. |
| keyTrackerDashboardLayout | 假的&#124;真的 | Tracker dasboard layout. |

## 组态 { #webapi_configuration } 

要访问配置，您可以与 *configuration* 交互
资源。您可以通过 *Accept* 标头获取 XML 和 JSON 响应
或使用 .json 或 .xml 扩展名。你可以*GET*所有属性
配置来自：

    / api / 33 /配置

您可以将 *GET* 和 *POST* 请求发送到以下特定
资源：

    GET /api/33/configuration/systemId

    GET POST DELETE /api/configuration/feedbackRecipients

    GET POST DELETE /api/configuration/offlineOrganisationUnitLevel

    GET POST /api/configuration/infrastructuralDataElements

    GET POST /api/configuration/infrastructuralIndicators

    GET POST /api/configuration/infrastructuralPeriodType

    GET POST DELETE /api/configuration/selfRegistrationRole

    GET POST DELETE /api/configuration/selfRegistrationOrgUnit

    GET POST /api/facilityOrgUnitGroupSet

    GET POST /api/facilityOrgUnitLevel

对于 CORS 白名单配置，您可以使用
使用“application/json”作为有效负载的 URL 数组
内容类型，例如：

```json
["www.google.com", "www.dhis2.org", "www.who.int"]
```

    GET POST / api / 33 / configuration / corsWhitelist

对于 POST 请求，配置值应作为请求发送
有效载荷为文本。下表显示了适当的配置
每个属性的值。



Table: Configuration values

| Configuration property | 值 |
|---|---|
| feedbackRecipients | User group ID |
| offlineOrganisationUnitLevel | Organisation unit level ID |
| infrastructuralDataElements | Data element group ID |
| infrastructuralIndicators | Indicator group ID |
| infrastructuralPeriodType | Period type name (e.g. "Monthly") |
| selfRegistrationRole | User role ID |
| selfRegistrationOrgUnit | Organisation unit ID |
| smtpPassword | SMTP email server password |
| remoteServerUrl | URL to remote server |
| remoteServerUsername | Username for remote server authentication |
| remoteServerPassword | Password for remote server authentication |
| corsWhitelist | JSON list of URLs |

例如，要设置反馈接收者用户组，您可以调用
以下 curl 命令：

```bash
curl "localhost/api/33/configuration/feedbackRecipients" -d "wl5cDMuUhmF"
  -H "Content-Type:text/plain"-u admin:district
```

## 只读配置 { #webapi_readonly_configuration_interface } 

要访问所有配置设置和属性，您可以使用只读配置端点。这将提供对 *UserSettings、SystemSettings 和 DHIS2 服务器配置*的只读访问权限。您可以通过 *Accept* 标头获得 XML 和 JSON 响应。您可以*获取*所有设置：

    / api / 33 / configuration / settings

您可以根据设置类型获得过滤设置：

    GET / api / 33 / configuration / settings / filter？type = USER_SETTING

    GET / api / 33 / configuration / settings / filter？type = CONFIGURATION

可以提供一种以上的类型：

    GET /api/33/configuration/settings/filter?type=USER_SETTING&type=SYSTEM_SETTING



Table: SettingType values

| 值 | 描述 |
|---|---|
| 用户_设置 | To get user settings |
| SYSTEM_SETTING | To get system settings |
| CONFIGURATION | To get DHIS server settings |

> **注意**
>
>将在输出中提供机密字段，但没有值。

## 代币 { #webapi_tokens } 

*tokens* 资源提供对各种服务的访问令牌。

### Google服务帐号 { #webapi_tokens_google_service_account } 

您可以使用以下命令检索 Google 服务帐户 OAuth 2.0 访问令牌
对以下资源的 GET 请求。

    GET /api/tokens/google

令牌将在一定时间内有效，之后
必须从此资源请求另一个令牌。响应
包含匹配令牌到期的缓存控制标头。这
响应将包含以下 JSON 格式的属性。



Table: Token response

| Property | 描述 |
|---|---|
| access_token | The OAuth 2.0 access token to be used when authentication against Google services. |
| expires_in | The number of seconds until the access token expires, typically 3600 seconds (1 hour). |
| client_id | The Google service account client id. |

假定已为DHIS2设置并配置了Google服务帐户。请查阅安装指南以获取更多信息。

## 静态内容 { #webapi_static_content } 

*staticContent* 资源允许您上传和检索自定义
DHIS2 中使用的徽标。该资源允许用户上传带有
关联的密钥，稍后可以使用密钥检索。只有 PNG
文件受支持，只能上传到`logo_banner` 和
`logo_front` 键。

    / api / 33 / staticContent



Table: Static content keys

| 键 | 描述 |
|---|---|
| logo_banner | Logo in the application top menu on the left side. |
| logo_front | Logo on the login-page above the login form. |

要上传文件，请将带有 *POST* 请求的文件发送至：

    POST / api / 33 / staticContent / <key>

请求将logo.png上传到`logo_front`键的示例：

```bash
curl -F "file=@logo.png;type=image/png" "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -X POST -H "Content-Type: multipart/form-data" -u admin:district
```

使用相同的密钥上传多个文件将覆盖现有的
文件。这样，检索任何给定键的文件只会返回
最新上传的文件。

要检索徽标，您可以*获取*以下内容：

    GET /api/33/staticContent/<key>

Example of requests to retrieve the file stored for `logo_front`:

* 将“Accept: text/html”添加到 HTTP 标头。*__ 在这种情况下，如果未定义任何内容，端点将返回默认图像。找到自定义或默认图像时将返回图像流。

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front" 
  -H "Accept: text/html" -L -u admin:district
```

* 将“Accept: application/json”添加到 HTTP 标头。*__ 设置此参数后，如果未找到自定义徽标，端点将永远不会返回默认图像。相反，将返回一条错误消息。找到自定义图像后，此端点将返回一个 JSON 响应，其中包含相应图像的路径/URL。

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front" 
  -H "Accept: application/json" -L -u admin:district
```

成功和错误消息将如下所示：

```json
{
  "images": {
    "png": "http://localhost:8080/dhis/api/staticContent/logo_front"
  }
}
```

```json
{
  "httpStatus": "Not Found",
  "httpStatusCode": 404,
  "status": "ERROR",
  "message": "No custom file found."
}
```

要使用自定义标志，您需要启用相应的系统
通过将其设置为 *true* 来设置。如果相应的设置为false，
将提供默认徽标。

## 用户界面定制 { #webapi_ui_customization } 

要自定义 DHIS2 应用程序的 UI，您可以插入自定义
JavaScript 和 CSS 样式通过 *files* 资源。

```
POST删除后/ api / 33 / files / script
POST GET DELETE / api / 33 / files / style
```

通过此资源插入的 JavaScript 和 CSS 内容将由
DHIS2 网络应用程序。这在某些情况下特别有用：

  - 覆盖 DHIS2 应用程序的 CSS 样式，例如
    登录页面或主页。

  - 定义几个自定义的通用 JavaScript 函数
    数据输入表单和基于 HTML 的报告。

  - 包括用于自定义数据输入表单的 CSS 样式和
    基于 HTML 的报告。

### Java脚本 { #webapi_customization_javascript } 

要从名为 *script.js* 的文件中插入 Javascript，您可以进行交互
使用带有 POST 请求的 *files/script* 资源：

```bash
curl --data-binary @script.js "localhost/api/33/files/script"
  -H "Content-Type:application/javascript" -u admin:district
```

请注意，我们使用 `--data-binary` 选项来保留格式
文件内容。您可以使用 GET 请求获取 JavaScript 内容：

    / api / 33 / files / script

要删除JavaScript内容，可以使用DELETE请求。

### 的CSS { #webapi_customization_css } 

要从名为 *style.css* 的文件插入 CSS，您可以与
带有 POST 请求的 *files/style* 资源：

```bash
curl --data-binary @style.css "localhost/api/33/files/style"
  -H "Content-Type:text/css" -u admin:district
```

您可以通过GET请求获取CSS内容：

    / api / 33 / files / style

要删除JavaScript内容，可以使用DELETE请求。


# 追踪器 { #tracker } 

> **Note**
>Tracker has been re-implemented in DHIS2 2.36. This document describes the new tracker endpoints
>
> * `POST /api/tracker`
> * `GET  /api/tracker/enrollments`
> * `GET  /api/tracker/events`
> * `GET  /api/tracker/trackedEntities`
> * `GET  /api/tracker/relationships`
>
>[Tracker
>(deprecated)](https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker-deprecated.html)
>describes the deprecated endpoints
>
> * `GET/POST/PUT/DELETE /api/trackedEntityInstance`
> * `GET/POST/PUT/DELETE /api/enrollments`
> * `GET/POST/PUT/DELETE /api/events`
> * `GET/POST/PUT/DELETE /api/relationships`
>
>* If your are still using the deprecated tracker endpoints in production, please plan to migrate
>  over to the new endpoints. [Migrating to new tracker
>  endpoints](https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker-deprecated.html#webapi_tracker_migration)
>  should help you get started. Reach out on the [community of
>  practice](https://community.dhis2.org) if you need further assistance. NOTE: The feature for data
>  sync(importMode=SYNC) is not implemented in the new tracker endpoints, and if you are using this
>  feature you will have to postpone the migration until a new SYNC feature is in place.

## Tracker Objects { #webapi_nti_tracker_objects }

Tracker consists of a few different types of objects that are nested together to represent the data. In this section, we will show and describe each of the objects used in the Tracker API.

### Tracked Entity { #tracked-entity } 

`跟踪实体`是跟踪器模型的根对象。

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| trackedEntity | The identifier of the tracked entity. Generated if not supplied | 不 | 是的 | String:Uid | ABCDEF12345 |
| trackedEntityType | The type of tracked entity. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| createdAt | Timestamp when the user created the tracked entity. Set on the server. | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the tracked entity on the client. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the object was last updated. Set on the server. | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAtClient | Timestamp when the object was last updated on the client. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| orgUnit | The organisation unit where the user created the tracked entity. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| inactive | Indicates whether the tracked entity is inactive or not. | 不 | 是的 | Boolean | Default: False, True |
| deleted | Indicates whether the tracked entity has been deleted. It can only change when deleting. | 不 | 不 | Boolean | False until deleted |
| geometry | A  geographical representation of the tracked entity. Based on the "featureType" of the TrackedEntityType. | 不 | 是的 | GeoJson | {<br>"type": "POINT",<br>"coordinates": [123.0, 123.0]<br>} |
| storedBy | Client reference for who stored/created the tracked entity. | 不 | 是的 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| 属性 | A list of tracked entity attribute values owned by the tracked entity. | 不 | 是的 | List of TrackedEntityAttributeValue | See Attribute |
| enrollments | A list of enrollments owned by the tracked entity. | 不 | 是的 | List of Enrollment | See Enrollment |
| relationships | A list of relationships connected to the tracked entity. | 不 | 是的 | List of Relationship | See Relationship |
| programOwners | A list of organisation units that have access through specific programs to this tracked entity. See "Program Ownership" for more. | 不 | 是的 | List of ProgramOwner | See section "Program Ownership" |

> **注意**
>
> `被跟踪实体`"拥有"所有`被跟踪实体属性值`（或上表中所述的"属性"）。然而，`被跟踪实体属性`要么通过`被跟踪实体类型`或`程序`连接到`被跟踪实体`。我们经常将这种分离称为`跟踪实体类型属性`和`跟踪实体程序属性`。这种分离的重要性与访问控制和限制用户可以看到的信息有关。
>
> `被跟踪实体`中提到的"属性"是`被跟踪实体类型属性`。


### 注册 { #enrollment } 
`被跟踪实体`可以注册其符合资格的`项目`。只要程序配置了与被跟踪实体相同的`被跟踪实体类型`，被跟踪实体就符合资格。我们用`Enrollment`对象来表示注册，我们将在本节中对此进行描述。


| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| enrollment | The identifier of the enrollment. Generated if not supplied | 不 | 是的 | String:Uid | ABCDEF12345 |
| program | The program the enrollment represents. | 是的 | 不 | String:Uid | ABCDEF12345 |
| trackedEntity | A reference to the tracked entity enrolled. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| trackedEntityType | Only for reading data. The type of tracked entity enrolled | 不 | 是的 | String:Uid | ABCDEF12345 |
| status | Status of the enrollment. ACTIVE if not supplied. | 不 | 不 | Enum | ACTIVE, COMPLETED, CANCELLED |
| orgUnit | The organisation unit where the user enrolled the tracked entity. | 是的 | 不 | String:Uid | ABCDEF12345 |
| orgUnitName | Only for reading data. The name of the organisation unit where the enrollment took place. | 不 | 不 | String:Any | Sierra Leone |
| createdAt | Timestamp when the user created the object. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the object on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the object was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAtClient | Timestamp when the object was last updated on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| enrolledAt | Timestamp when the user enrolled the tracked entity. | 是的 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| occurredAt | Timestamp when enrollment occurred. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedAt | Timestamp when the user completed the enrollment. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedBy | Reference to who completed the enrollment | 不 | 不 | String:any | John Doe |
| 跟进 | Indicates whether the enrollment requires follow-up. False if not supplied | 不 | 不 | Booelan | Default: False, True |
| deleted | Indicates whether the enrollment has been deleted. It can only change when deleting. | 不 | 是的 | Boolean | False until deleted |
| geometry | A  geographical representation of the enrollment. Based on the "featureType" of the Program | 不 | 不 | GeoJson | {<br>"type": "POINT",<br>"coordinates": [123.0, 123.0]<br>} |
| storedBy | Client reference for who stored/created the enrollment. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| 属性 | A list of tracked entity attribute values connected to the enrollment. | 不 | 不 | List of TrackedEntityAttributeValue | See Attribute |
| events | A list of events owned by the enrollment. | 不 | 不 | List of Event | See Event |
| relationships | A list of relationships connected to the enrollment. | 不 | 不 | List of Relationship | See Relationship |
| notes | Notes connected to the enrollment. It can only be created. | 不 | 是的 | List of Note | See Note |

> **Note**
>
> `Tracked Entities` "owns" all `Tracked Entity Attribute Values` (Or "attributes" as described in the previous table). However, `Tracked Entity Attributes` are either connected to a `Tracked Entity` through its `Tracked Entity Type` or a `Program`. We often refer to this separation as `Tracked Entity Type Attributes` and `Tracked Entity Program Attributes`. The importance of this separation is related to access control and limiting what information the user can see.
>
> The "attributes" referred to in the `Enrollment` are `Tracked Entity Program Attributes`.


### 大事记 { #events } 
`Events` are either part of an `EVENT PROGRAM` or `TRACKER PROGRAM`. For `TRACKER PROGRAM`, events belong to an `Enrollment`, which again belongs to a `Tracked Entity`. On the other hand, `EVENT PROGRAM` is `Events` not connected to a specific `Enrollment` or `Tracked Entity`. The difference is related to whether we track a specific `Tracked Entity` or not. We sometimes refer to `EVENT PROGRAM` events as "anonymous events" or "single events" since they only represent themselves and not another `Tracked Entity`.

In the API, the significant difference is that all events are either connected to the same enrollment (`EVENT PROGRAM`) or different enrollments (`TRACKER PROGRAM`). The table below will point out any exceptional cases between these two.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| event | The identifier of the event. Generated if not supplied | 不 | 是的 | String:Uid | ABCDEF12345 |
| programStage | The program stage the event represents. | 是的 | 不 | String:Uid | ABCDEF12345 |
| enrollment | A reference to the enrollment which owns the event. ***Not applicable for `EVENT PROGRAM`*** | 是的 | 是的 | String:Uid | ABCDEF12345 |
| program | Only for reading data. The type of program the enrollment which owns the event has. | 不 | 是的 | String:Uid | ABCDEF12345 |
| trackedEntity | Only for reading data. The tracked entity which owns the event. ***Not applicable for `EVENT PROGRAM`*** | 不 | 不 | String:Uid | ABCDEF12345 |
| status | Status of the event. ACTIVE if not supplied. | 不 | 不 | Enum | ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED |
| enrollmentStatus | Only for reading data. The status of the enrollment which owns the event. ***Not applicable for `EVENT PROGRAM`*** | 不 | 不 | Enum | ACTIVE, COMPLETED, CANCELLED |
| orgUnit | The organisation unit where the user registered the event. | 是的 | 不 | String:Uid | ABCDEF12345 |
| orgUnitName | Only for reading data. The name of the organisation unit where the user registered the event. | 不 | 不 | String:Any | Sierra Leone |
| createdAt | Timestamp when the user created the event. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| createdAtClient | Timestamp when the user created the event on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the event was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAtClient | Timestamp when the event was last updated on client | 不 | 不 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| scheduledAt | Timestamp when the event was scheduled for. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| occurredAt | Timestamp when something occurred. | 是的 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedAt | Timestamp when the user completed the event. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| completedBy | Reference to who completed the event | 不 | 不 | String:Any | John Doe |
| 跟进 | Indicates whether the event has been flagged for follow-up. False if not supplied | 不 | 不 | Booelan | Default: False, True |
| deleted | Indicates whether the event has been deleted. It can only change when deleting. | 不 | 是的 | Boolean | False until deleted |
| geometry | A  geographical representation of the event. Based on the "featureType" of the Program Stage | 不 | 不 | GeoJson | {<br>"type": "POINT",<br>"coordinates": [123.0, 123.0]<br>} |
| storedBy | Client reference for who stored/created the event. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| attributeOptionCombo | Attribute option combo for the event. Default if not supplied or configured. | 不 | 不 | String:Uid | ABCDEF12345
| attributeCategoryOptions | Attribute category option for the event. Default if not supplied or configured. | 不 | 不 | String:Uid | ABCDEF12345
| assignedUser | A reference to a user who has been assigned to the event. | 不 | 不 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| dataValues | A list of data values connected to the event. | 不 | 不 | List of TrackedEntityAttributeValue | See Attribute |
| relationships | A list of relationships connected to the event. | 不 | 不 | List of Relationship | See Relationship |
| notes | Notes connected to the event. It can only be created. | 不 | 是的 | List of Note | See Note |

### Relationship { #relationship } 

`Relationships` are objects that link together two other tracker objects. The constraints each side of the relationship must conform to are based on the `Relationship Type` of the `Relationship`.


| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| relationship | The identifier of the relationship. Generated if not supplied. | 不 | 是的 | String:Uid | ABCDEF12345 |
| relationshipType | The type of the relationship. Decides what objects can be linked in a relationship. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| relationshipName | Only for reading data. The name of the relationship type of this relationship | 不 | 不 | String:Any | Sibling |
| createdAt | Timestamp when the user created the relationship. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the relationship was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| bidirectional | Only for reading data. Indicated whether the relationship type is bidirectional or not. | 不 | 不 | Boolean | True or False |
| from, to | A reference to each side of the relationship. Must conform to the constraints set in the relationship type | 是的 | 是的 | RelationshipItem | {"trackedEntity": {"trackedEntity": "ABCEF12345"}}, {"enrollment": {"enrollment": "ABCDEF12345"}} or {"event": {"event": "ABCDEF12345" }} |

> **Note**
>
>`Relationship item` represents a link to an object. Since a `relationship` can be between any tracker object like `tracked entity`, `enrollment`, and `event`, the value depends on the `relationship type`. For example, if the `relationship type` connects from an `event` to a `tracked entity`, the format is strict:
>```json
>{
>   "from": {
>     "event": { "event": "ABCDEF12345" }
>   },
>   "to": {
>     "trackedEntity": { "trackedEntity": "FEDCBA12345" }
>   }
>}
>```

### 属性 { #attribute } 
`Attributes` are the actual values describing the `tracked entities`. They can either be connected through a `tracked entity type` or a `program`. Implicitly this means `attributes` can be part of both a `tracked entity` and an `enrollment`.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| attribute | A reference to the tracked entity attribute represented. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| 码 | Only for reading data. The code of the tracked entity attribute. | 不 | 不 | String:Any | ABC |
| displayName | Only for reading data. The displayName of the tracked entity attribute. | 不 | 不 | String:Any | 名称 |
| createdAt | Timestamp when the value was added. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the value was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| storedBy | Client reference for who stored/created the value. | 不 | 不 | String:Any | John Doe |
| valueType | Only for reading data. The type of value the attribute represents. | 不 | 不 | Enum | TEXT, INTEGER, and more |
| 价值 | The value of the tracked entity attribute. | 不 | 不 | String:Any | John Doe |

> **Note**
>
> For `attributes` only the "attribute" and "value" properties are required when adding data. "value" can be null, which implies the user should remove the value.
>
> In the context of tracker objects, we refer to `Tracked Entity Attributes` and `Tracked Entity Attribute Values` as "attributes". However, attributes are also their own thing, related to metadata. Therefore it's vital to separate Tracker attributes and metadata attributes. In the tracker API, it is possible to reference the metadata attributes when specifying `idScheme` (See request parameters for more information).

### Data Values { #data-values } 
While `Attributes` describes a `tracked entity` or an `enrollment`, `data values` describes an `event`. The major difference is that `attributes` can only have a single value for a given `tracked entity`. In contrast, `data values` can have many different values across different `events` - even if the `events` all belong to the same `enrollment` or `tracked entity`.

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| dataElement | The data element this value represents. | 是的 | 是的 | String:Uid | ABCDEF12345 |
| 价值 | The value of the data value. | 不 | 不 | String:Any | 123 |
| providedElsewhere | Indicates whether the user provided the value elsewhere or not. False if not supplied. | 不 | 不 | Boolean | False or True |
| createdAt | Timestamp when the user added the value. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| updatedAt | Timestamp when the value was last updated. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| storedBy | Client reference for who stored/created the value. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |
| updatedBy | Only for reading data. User that last updated the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |


> **Note**
>
> For `data elements` only the "dataElement" and "value" properties are required when adding data. "value" can be null, which implies the user should remove the value.

### Tracker Notes { #tracker-notes } 

DHIS2 tracker allows for capturing of data using data elements and tracked entity attributes. However, sometimes there could be a situation where it is necessary to record additional information or comment about the issue at hand. Such additional information can be captured using tracker notes. Tracker notes are equivalent to data value comments from the Aggregate DHIS2 side.

There are two types of tracker notes - notes recorded at the event level and those recorded at the enrollment level. An enrollment can have one or more events. Comments about each of the events - for example, why an event was missed, rescheduled, or why only a few data elements were filled and the like - can be documented using event notes. Each of the events within an enrollment can have its own story/notes. One can then record, for example, an overall observation of these events using the parent enrollment note. Enrollment notes are also helpful to document, for example, why an enrollment is canceled. It is the user's imagination and use-case when and how to use notes.

Both enrollment and event can have as many notes as needed - there is no limit. However, it is not possible to delete or update neither of these notes. They are like a logbook. If one wants to amend a note, one can do so by creating another note. The only way to delete a note is by deleting the parent object - either event or enrollment. 

Tracker notes do not have their dedicated endpoint; they are exchanged as part of the parent event and/or enrollment payload. Below is a sample payload.

```json
{
  "trackedEntityInstance": "oi3PMIGYJH8",
  <entity_details>,
  ],
  "enrollments": [
    {
      "enrollment": "EbRsJr8LSSO",
      <enrollment_details>
      "notes": [
        {
          "note": "vxmCvYcPdaW",
          "value": "Enrollment note 2.",
        },
        {
          "value": "Enrollment note 1",
        }
      ],

      "events": [
        {
          "event": "zfzS9WeO0uM",
          <event_details>,
          "notes": [
            {
              "note": "MAQFb7fAggS",
              "value": "Event Note 1.",
            },
            {
              "value": "Event Note 2.",
            }
          ],
        },
        {
          ...
        }
      ]
    }
  ]
}
```


| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| note | The reference of the note. Generated if empty | 不 | 是的 | String:Uid | ABCDEF12345 |
| 价值 | The content of the note. | 是的 | 是的 | String:Any | This is a note |
| storedAt | Timestamp when the user added the note. Set on the server. | 不 | 是的 | Date:ISO 8601 | YYYY-MM-DDThh:mm:ss |
| storedBy | Client reference for who stored/created the note. | 不 | 不 | String:Any | John Doe |
| createdBy | Only for reading data. User that created the object. Set on the server | 不 | 是的 | 用户 | {<br>"uid": "ABCDEF12345",<br>"username": "username",<br>"firstName": "John",<br>"surname": "Doe"<br>} |

### 用户 { #user } 

| Property | 描述 | 需要 | Immutable | 类型 | 例 |
|---|---|---|---|---|---|
| uid | The identifier of the user. | Yes* | 是的 | String:Uid | ABCDEF12345 |
| 用户名 | Username used by the user. | Yes* | 是的 | String:Any | 123 |
| firstName | Only for reading data. First name of the user. | 不 | 是的 | String:Any | John |
| surname | Only for reading data. Last name of the user. | 不 | 是的 | String:Any | Doe |

> One between `uid` or `username` field must be provided. If both are provided, only username is considered.

### Program stage working lists { #webapi_working_list_filters } 

The program stage working lists feature within the Capture app is designed to display pre-established working lists relevant to a particular program stage. This functionality enables users to save filters and sorting preferences that are related to program stages, facilitating the organization and management of their workflow. To interact with them, you'll need to use the */api/programStageWorkingLists* resource. These lists can be shared and follow the same sharing pattern as any other metadata. When using the */api/sharing* the type parameter will be *programStageWorkingLists*.

    /api/40/programStageWorkingLists

##### Payload on CRUD operations to program stage working lists { #payload-on-crud-operations-to-program-stage-working-lists } 

The endpoint above can be used to get all program stage working lists. 
To get a single one, just add at the end the id of the one you are interested in. This is the same in case you want to delete it.
On the other hand, if you are looking to create or update a program stage working list, besides the endpoint mentioned above, you'll need to provide a payload in the following format: 

Table: Payload

| Payload values | 描述 | 例 |
|---|---|---|
| 名称 | Name of the working list. Required. ||
| 描述 | A description of the working list. ||
| program | Object containing the id of the program. Required. | {"id" : "uy2gU8kTjF"} |
| programStage | Object containing the id of the program stage. Required. | {"id" : "oRySG82BKE6"} |
| programStageQueryCriteria | An object representing various possible filtering values. See *Program Stage Query Criteria* definition table below.

Table: Program Stage Query Criteria

| Criteria values | 描述 | 例 |
|---|---|---|
| status | The event status. Possible values are ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED and VISITED | "status":"VISITED" |
| eventCreatedAt | DateFilterPeriod object filtering based on the event creation date. | {"type":"ABSOLUTE","startDate":"2020-03-01","endDate":"2022-12-30"} |
| scheduledAt | DateFilterPeriod object filtering based on the event scheduled date. | {"type":"RELATIVE","period":"TODAY"} |
| enrollmentStatus | Any valid ProgramStatus. Possible values are ACTIVE, COMPLETED and CANCELLED. | "enrollmentStatus": "COMPLETED" |
| enrolledAt | DateFilterPeriod object filtering based on the event enrollment date. | "enrolledAt": {"type":"RELATIVE","period":"THIS_MONTH"} |
| enrollmentOccurredAt | DateFilterPeriod object filtering based on the event incident date. | {"type":"RELATIVE","period":"THIS_MONTH"} |
| orgUnit | A valid organisation unit UID | "orgUnit": "Rp268JB6Ne4" |
| ouMode | A valid OU selection mode | "ouMode": "SELECTED" |
| assignedUserMode | A valid user selection mode for events. Possible values are CURRENT, PROVIDED, NONE, ANY and ALL. If PROVIDED (or null), non-empty assignedUsers in the payload will be expected. | "assignedUserMode":"PROVIDED" |
| assignedUsers | A list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers":["DXyJmlo9rge"] |
| order | List of fields and its directions in comma separated values, the results will be sorted according to it. A single item in order is of the form "orderDimension:direction". | "order": "w75KJ2mc4zz:asc" |
| displayColumnOrder | Output ordering of columns | "displayColumnOrder":["w75KJ2mc4zz","zDhUuAYrxNC"] |
| dataFilters | A list of items that contains the filters to be used when querying events | "dataFilters":[{"dataItem": "GXNUsigphqK","ge": "10","le": "20"}] |
| attributeValueFilters | A list of attribute value filters. This is used to specify filters for attribute values when listing tracked entity instances | "attributeValueFilters":[{"attribute": "ruQQnf6rswq","eq": "15"}] |

See an example payload below:

```json
{   
    "name":"Test WL",
    "program":{"id":"uy2gU8kT1jF"},
    "programStage":{"id":"oRySG82BKE6"},
    "description": "Test WL definition",
    "programStageQueryCriteria":
        {
            "status":"VISITED",
            "eventCreatedAt":{"type":"ABSOLUTE","startDate":"2020-03-01","endDate":"2022-12-30"},
            "scheduledAt": {"type":"RELATIVE","period":"TODAY"},
            "enrollmentStatus": "COMPLETED",
            "enrolledAt": {"type":"RELATIVE","period":"THIS_MONTH"},
            "enrollmentOccurredAt": {"type":"RELATIVE","period":"THIS_MONTH"},
            "orgUnit": "Rp268JB6Ne4",
            "ouMode": "SELECTED",
            "assignedUserMode":"PROVIDED",
            "assignedUsers":["DXyJmlo9rge"],
            "order": "w75KJ2mc4zz:asc",
            "displayColumnOrder":["w75KJ2mc4zz","zDhUuAYrxNC"],
            "dataFilters":[{
                "dataItem": "GXNUsigphqK",
                "ge": "10",
                "le": "20"
            }],
            "attributeValueFilters":[{
                "attribute": "ruQQnf6rswq",
                "eq": "15"
            }]
        }
}
```
## Tracker Import (`POST /api/tracker`) { #webapi_nti_import }

The `POST /api/tracker` endpoint allows clients to import the following tracker objects into DHIS2:

* **Tracked entities**
* **Enrollments**
* **Events**
* **Relationships**
* Data embedded in other [tracker objects](#webapi_nti_tracker_objects)

Main changes compared to the other endpoints for tracker import are:

1. Import payload can be ***nested*** or ***flat***
2. Invocation can be ***synchronous*** or ***asynchronous***
3. Import ***CSV*** events payload

### Request parameters { #request-parameters } 

Currently, the tracker import endpoint supports the following parameters:

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| async | Indicates whether the import should happen asynchronously or synchronously. | Boolean | `TRUE`, `FALSE` |
| reportMode | Only when performing synchronous import. See importSummary for more info. | Enum | `FULL`, `ERRORS`, `WARNINGS` |
| importMode | Indicates the mode of import. Can either be validate only (dry run) or commit (Default) | Enum | `VALIDATE`, `COMMIT` |
| 方案 | Indicates the overall idScheme to use for metadata references when importing. Default is UID. Can be overridden for specific metadata (Listed below) | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| 数据元素标识方案 | Indicates the idScheme to use for data elements when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| orgUnitIdScheme | Indicates the idScheme to use for organisation units when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| 程序标识方案 | Indicates the idScheme to use for programs when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| 程序阶段标识方案 | Indicates the idScheme to use for program stages when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| categoryOptionComboIdScheme | Indicates the idScheme to use for category option combos when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| categoryOptionIdScheme | Indicates the idScheme to use for category options when importing. | Enum | `UID`, `CODE`, `NAME`, `ATTRIBUTE` |
| importStrategy | Indicates the effect the import should have. Can either be `CREATE`, `UPDATE`, `CREATE_AND_UPDATE` and `DELETE`, which respectively only allows importing new data, importing changes to existing data, importing any new or updates to existing data, and finally deleting data. | Enum | `CREATE`, `UPDATE`, `CREATE_AND_UPDATE`, `DELETE` |
| atomicMode | Indicates how the import responds to validation errors. If `ALL`, all data imported must be valid for any data to be committed. For `OBJECT`, only the data committed needs to be valid, while other data can be invalid. | Enum | `ALL`, `OBJECT` |
| flushMode | Indicates the frequency of flushing. This is related to how often data is pushed into the database during the import. Primarily used for debugging reasons, and should not be changed in a production setting | Enum | `AUTO`, `OBJECT` |
| validationMode | Indicates the completeness of the validation step. It can be skipped, set to fail fast (Return on the first error), or full(Default), which will return any errors found | Enum | `FULL`, `FAIL_FAST`, `SKIP` |
| skipPatternValidation | If true, it will skip validating the pattern of generated attributes. | Boolean | `TRUE`, `FALSE` |
| skipSideEffects | If true, it will skip running any side effects for the import | Boolean | `TRUE`, `FALSE` |
| skipRuleEngine | If true, it will skip running any program rules for the import | Boolean | `TRUE`, `FALSE` |

**NOTE**: idScheme and its metadata specific idScheme parameters like
orgUnitIdScheme, programIdScheme, ... used to allow and use the default `AUTO`.
`AUTO` has been removed. The default idScheme has already been `UID`. Any
requests sent with idScheme `AUTO` will see the same behavior as before, namely
matching done using `UID`.

### Flat and nested payloads { #flat-and-nested-payloads } 

The importer support both flat and nested payloads. The main difference is how the client requires their data to be structured.

**Flat**
:   The flat-structured payload is straightforward. It can contain collections for each of the core tracker objects we have. This works seamlessly with existing data, which already have UIDs assigned. However, for new data, the client will have to provide new UIDs for any references between objects. For example, if you import a new tracked entity with a new enrollment, the tracked entity requires the client to provide a UID so that the enrollment can be linked to that UID.

**Nested**
:   Nested payloads are the most commonly used structure. Here, tracker objects are embedded within their parent object; For example, an enrollment within a tracked entity. The advantage of this structure is that the client does not need to provide UIDs for these connections since they will be given this connection during the import process since they are nested together.

> **NOTE**
>
> While nested payloads might prove simpler for clients to deal with, the payload will always be flattened before the import. This means that for large imports, providing a flat structured payload will provide both more control and lower overhead for the import process itself.

Examples for the **FLAT** and the **NESTED** versions of the payload are listed below. Both cases use the same data.

#### ***FLAT*** payload { #flat-payload } 

```json
{
  "trackedEntities": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "Q9GufDoplCL"
    }
  ],
  "enrollments": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "program": "f1AyMswryyQ",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "trackedEntityType": "Q9GufDoplCL",
      "enrolledAt": "2019-08-19T00:00:00.000",
      "deleted": false,
      "occurredAt": "2019-08-19T00:00:00.000",
      "status": "ACTIVE",
      "notes": [],
      "attributes": [],
    }
  ],
  "events": [
    {
      "scheduledAt": "2019-08-19T13:59:13.688",
      "program": "f1AyMswryyQ",
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "status": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "attributeCategoryOptions": "xYerKDKCefk",
      "deleted": false,
      "attributeOptionCombo": "HllvX50cXC0",
      "dataValues": [
        {
          "updatedAt": "2019-08-19T13:58:37.477",
          "storedBy": "admin",
          "dataElement": "BuZ5LGNfGEU",
          "value": "20",
          "providedElsewhere": false
        },
        {
          "updatedAt": "2019-08-19T13:58:40.031",
          "storedBy": "admin",
          "dataElement": "ZrqtjjveTFc",
          "value": "Male",
          "providedElsewhere": false
        },
        {
          "updatedAt": "2019-08-19T13:59:13.691",
          "storedBy": "admin",
          "dataElement": "mB2QHw1tU96",
          "value": "[-11.566044,9.477801]",
          "providedElsewhere": false
        }
      ],
      "notes": []
    },
    {
      "scheduledAt": "2019-08-19T13:59:13.688",
      "program": "f1AyMswryyQ",
      "event": "XwwuwNp6gVE",
      "programStage": "PaOOjwLVW23",
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "status": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "attributeCategoryOptions": "xYerKDKCefk",
      "deleted": false,
      "attributeOptionCombo": "HllvX50cXC0",
      "notes": []
    }
  ],
  "relationships": [
    {
      "relationshipType": "Udhj3bsdHeT",
      "from": {
        "trackedEntity": { "trackedEntity": "Kj6vYde4LHh" }
      },
      "to": {
        "trackedEntity": { "trackedEntity": "Gjaiu3ea38E" }
      }
    }
  ]
}
```

#### ***NESTED*** payload { #nested-payload } 

```json
{
  "trackedEntities": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "Q9GufDoplCL",
      "relationships": [
        {
          "relationshipType": "Udhj3bsdHeT",
          "from": {
            "trackedEntity": { "trackedEntity": "Kj6vYde4LHh" }
          },
          "to": {
            "trackedEntity": { "trackedEntity": "Gjaiu3ea38E" }
          }
        }
      ],
      "enrollments": [
        {
          "orgUnit": "O6uvpzGd5pu",
          "program": "f1AyMswryyQ",
          "trackedEntity": "Kj6vYde4LHh",
          "enrollment": "MNWZ6hnuhSw",
          "trackedEntityType": "Q9GufDoplCL",
          "enrolledAt": "2019-08-19T00:00:00.000",
          "deleted": false,
          "occurredAt": "2019-08-19T00:00:00.000",
          "status": "ACTIVE",
          "notes": [],
          "relationships": [],
          "attributes": [],
          "events": [
            {
              "scheduledAt": "2019-08-19T13:59:13.688",
              "program": "f1AyMswryyQ",
              "event": "ZwwuwNp6gVd",
              "programStage": "nlXNK4b7LVr",
              "orgUnit": "O6uvpzGd5pu",
              "trackedEntity": "Kj6vYde4LHh",
              "enrollment": "MNWZ6hnuhSw",
              "enrollmentStatus": "ACTIVE",
              "status": "ACTIVE",
              "occurredAt": "2019-08-01T00:00:00.000",
              "attributeCategoryOptions": "xYerKDKCefk",
              "deleted": false,
              "attributeOptionCombo": "HllvX50cXC0",
              "dataValues": [
                {
                  "updatedAt": "2019-08-19T13:58:37.477",
                  "storedBy": "admin",
                  "dataElement": "BuZ5LGNfGEU",
                  "value": "20",
                  "providedElsewhere": false
                },
                {
                  "updatedAt": "2019-08-19T13:58:40.031",
                  "storedBy": "admin",
                  "dataElement": "ZrqtjjveTFc",
                  "value": "Male",
                  "providedElsewhere": false
                },
                {
                  "updatedAt": "2019-08-19T13:59:13.691",
                  "storedBy": "admin",
                  "dataElement": "mB2QHw1tU96",
                  "value": "[-11.566044,9.477801]",
                  "providedElsewhere": false
                }
              ],
              "notes": [],
              "relationships": []
            },
            {
              "scheduledAt": "2019-08-19T13:59:13.688",
              "program": "f1AyMswryyQ",
              "event": "XwwuwNp6gVE",
              "programStage": "PaOOjwLVW23",
              "orgUnit": "O6uvpzGd5pu",
              "trackedEntity": "Kj6vYde4LHh",
              "enrollment": "MNWZ6hnuhSw",
              "enrollmentStatus": "ACTIVE",
              "status": "ACTIVE",
              "occurredAt": "2019-08-01T00:00:00.000",
              "attributeCategoryOptions": "xYerKDKCefk",
              "deleted": false,
              "attributeOptionCombo": "HllvX50cXC0",
              "notes": [],
              "relationships": []
            }
          ]
        }
      ]
    }
  ]
}
```

### SYNC and ASYNC { #sync-and-async } 
For the user, the main difference between importing synchronously rather than asynchronously is the immediate response from the API. For the synchronous import, the response will be returned as soon as the import finishes with the importSummary. However, for asynchronous imports, the response will be immediate and contain a reference where the client can poll for updates to the import.

For significant imports, it might be beneficial for the client to use the asynchronous import to avoid waiting too long for a response.


Examples of the **ASYNC** response is shown below. For **SYNC** response, look at the [importSummary section](#webapi_nti_import_summary).

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "message": "Tracker job added",
    "response": {
        "responseType": "TrackerJob",
        "id": "LkXBUdIgbe3",
        "location": "https://play.dhis2.org/dev/api/tracker/jobs/LkXBUdIgbe3"
    }
}
```

### CSV Events payload { #csv-events-payload } 

In order to maintain compatibility with older versions of tracker, the API allows to import events using the CSV format.
As this format does not allow list as field, every row of the CSV payload represents an event and a data value.
So for events with multiple data values, the CSV file will have `x` rows per event where `x` is the number of data values in that event.
Other fields that are lists as ***relationships*** and ***notes*** are not supported.
To import a CSV payload, the content type of the request must be set to ***application/csv*** or ***text/csv***.

#### ***CSV PAYLOAD*** example { #csv-payload-example } 

|event|status|program|programStage|enrollment|orgUnit|occurredAt|scheduledAt|dataElement|价值|storedBy|providedElsewhere
|---|---|---|---|---|---|---|---|---|---|---|---|
|V1CerIi3sdL|COMPLETED|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|a3kGcGDCuk6|11|admin|假
|V1CerIi3sdL|COMPLETED|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|mB2QHw1tU96|[-11.566044,9.477801]|admin|假

### Import Summary { #webapi_nti_import_summary }

The Tracker API has two primary endpoints for consumers to acquire feedback from their imports. These endpoints are most relevant for async import jobs but are available for sync jobs as well. These endpoints will return either the log related to the import or the import summary itself.

> **Note**
>
> These endpoints rely on information stored in the application memory. This means the information will be unavailable after certain cases, as an application restart or after a large number of import requests have started after this one.

After submitting a tracker import request, we can access the following endpoints in order to monitor the job progress based on logs:

`GET /tracker/jobs/{uid}`

| Parameter|描述|例
|---|---|---|
|`{uid}`| The UID of an existing tracker import job | ABCDEF12345

#### ***REQUEST*** example { #request-example } 

`GET /tracker/jobs/mEfEaFSCKCC`

#### ***RESPONSE*** example { #response-example } 

```json
[
  {
    "uid": "mEfEaFSCKCC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:06.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) finished in 6.00000 sec. Import:Done",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:05.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) commit completed in 1.00000 sec. Import:commit",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:04.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) programruleValidation completed in 1.00000 sec. Import:programruleValidation",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:03.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) programrule completed in 1.00000 sec. Import:programrule",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:02.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) validation completed in 1.00000 sec. Import:validation",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:01.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) preheat completed in 1.00000 sec. Import:preheat",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:00.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) started by admin ( xE7jOejl9FI ) Import:Start",
    "completed": true,
    "id": "mEfEaFSCKCC"
  }
]
```

Additionally, the following endpoint will return the import summary of the import job. This import summary will only be available after the import has completed:

`GET /tracker/jobs/{uid}/report`

| Parameter|描述|例
|---|---|---|
|path `/{uid}`| The UID of an existing tracker import job | ABCDEF12345
|`reportMode`| The level of the report to return | `FULL`&#124;`ERRORS`&#124;`WARNINGS`|

#### ***REQUEST*** example { #request-example } 

`GET /tracker/jobs/mEfEaFSCKCC/report`

#### ***RESPONSE*** example { #response-example } 

The [response payload](#sample-responses) is the same as the one returned after a sync import request.

> **Note**
>
> Both endpoints are used primarily for async import; however, `GET /tracker/jobs/{uid}` would also work for sync requests as it eventually uses the same import process and logging as async requests.

### Import Summary Structure { #import-summary-structure } 

Import summaries have the following overall structure, depending on the requested `reportMode`:
```json
{
  "status": "...",
  "validationReport": { },
  "stats": { },
  "timingsStats": { },
  "bundleReport": { },
  "message" : { }
}
```

***status***

The property, `status`, of the import summary indicates the overall status of the import. If no errors or warnings were raised during the import, the `status` is reported as `OK`. The presence of any error or warnings in the import will result in a status of type `ERROR` or `WARNING`.

`status` is based on the presence of the most significant `validationReport`. `ERROR` has the highest significance, followed by `WARNING` and finally `OK`. This implies that `ERROR` is reported as long as a single error was found during the import, regardless of how many warnings occurred.

> **Note**
>
> If the import is performed using the AtomicMode "OBJECT", where the import will import any data without validation errors, the overall status will still be `ERROR` if any errors were found.

***validationReport***

The `validationReport` might include `errorReports` and `warningReports` if any errors or warnings were present during the import. When present, they provide a detailed list of any errors or warnings encountered.

For example, a validation error while importing a `TRACKED_ENTITY`:
```json
{
  "validationReport": {
    "errorReports": [
      {
        "message": "Could not find TrackedEntityType: `Q9GufDoplCL`.",
        "errorCode": "E1005",
        "trackerType": "TRACKED_ENTITY",
        "uid": "Kj6vYde4LHh"
      },
      ...
    ],
    "warningReports" : [ ... ]
  }
}
```

The report contains a message and a code describing the actual error (See the [error codes](#error-codes) section for more information about errors). Additionally, the report includes the `trackerType` and `uid`, which aims to describe where in the data the error was found. In this case, there was a `TRACKED_ENTITY` with the uid `Kj6vYde4LHh`, which had a reference to a tracked entity type that was not found.

> **Note**
>
> When referring to the `uid` of tracker objects, they are labeled as their object names in the payload. For example, the `uid` of a tracked entity would in the payload have the name "trackedEntity". The same goes for "enrollment", "event" and "relationship" for enrollments, events, and relationships, respectively.
>
> If no uid is provided in the payload, the import process will generate new uids. This means the error report might refer to a uid that does not exist in your payload.
>
> Errors represent issues with the payload which the importer can not circumvent. Any errors will block that data from being imported. Warnings, on the other hand, are issues where it's safe to circumvent them, but the user should be made aware that it happened. Warnings will not block data from being imported.

***stats***

The stats provide a quick overview of the import. After an import is completed, these will be the actual counts representing how much data was created, updated, deleted, or ignored.

例：
```json
{
  "stats": {
    "created": 2,
    "updated": 2,
    "deleted": 1,
    "ignored": 5,
    "total": 10
  }
}
```
`created` refers to how many new objects were created. In general, objects without an existing uid in the payload will be treated as new objects.

`updated` refers to the number of objects updated. If an object has a uid set in the payload, it will be treated as an update as long as that same uid exists in the database.

`deleted` refers to the number of objects deleted during the import. Deletion only happens when the import is configured to delete data and only then when the objects in the payload have existing uids set.

`ignored` refers to objects that were not persisted. Objects can be ignored for several reasons, for example trying to create something that already exists. Ignores should always be safe, so if something was ignored, it was not necessary, or it was due to the configuration of the import.

***timingsStats***

`timingStats` represents the time elapsed in different steps of the import. These stats do not provide an accurate overall time for the import but rather the time spent in the code for different steps.

The `timingStats` are primarily helpful in debugging imports that are causing issues to see which part of the import is having issues.
```json
{
  "timingsStats": {
    "timers": {
      "preheat": "0.234086 sec.",
      "preprocess": "0.000058 sec.",
      ...
      "totalImport": "0.236810 sec.",
      "validation": "0.001533 sec."
    }
  }
}
```

***bundleReport***

When the import is completed, the `bundleReport` contains all the [tracker objects](#tracker-objects) imported.

For example, `TRACKED_ENTITY`:
```json
{
  "bundleReport": {
    "typeReportMap": {
      "TRACKED_ENTITY": {
        "trackerType": "TRACKED_ENTITY",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "TRACKED_ENTITY",
            "uid": "FkxTQC4EAKK",
            "index": 0,
            "errorReports": []
          }
        ]
      },
      ...
    }
  }
}
```
As seen, each type of tracker object will be reported, and each has its own stats and `objectReports`. These `objectReports` will provide details about each imported object, like their type, their uid, and any error or warning reports is applicable.

***message***

If the import ended abruptly, the `message` would contain further information in relation to what happened.

### Import Summary Report Level { #import-summary-report-level } 

As previously stated, `GET /tracker/jobs/{uid}/report` can be retrieved using a specific `reportMode` parameter. By default the endpoint will return an `importSummary` with `reportMode` `ERROR`.

| Parameter | 描述 |
|---|---|
| `FULL` | Returns everything from `WARNINGS`, plus `timingsStats` |
| `WARNINGS` | Returns everything from `ERRORS`, plus `warningReports` in `validationReports` |
| `ERRORS` (default) | Returns only `errorReports` in `validationReports` |

In addition, all `reportModes` will return `status`, `stats`, `bundleReport` and `message` when applicable.

### Error Codes { #webapi_nti_error_codes }

There are various error codes for different error scenarios. The following table has the list of error codes thrown from the new Tracker API, along with the error messages and some additional descriptions. The placeholders in the error messages (`{0}`,`{1}`,`{2}`..) are usually uids unless otherwise specified.

| Error Code | Error Message | 描述 |
|:--|:----|:----|
| E1000 | User: `{0}`, has no write access to OrganisationUnit: `{1}`. | This typically means that the OrganisationUnit `{1}` is not in the capture scope of the user `{0}` for the write operation to be authorized. |
| E1001 | User: `{0}`, has no data write access to TrackedEntityType: `{1}`. | The error occurs when the user is not authorized to create or modify data of the TrackedEntityType `{1}`  
| E1002 | TrackedEntityInstance: `{0}`, already exists. | This error is thrown when trying to create a new TrackedEntity with an already existing uid. Make sure a new uid is used when adding a new TrackedEntity. |
| E1005 | Could not find TrackedEntityType: `{0}`. | Error thrown when trying to fetch a non existing TrackedEntityType with uid `{0}` . This might also mean that the user does not have read access to the TrackedEntityType. |
| E1006 | Attribute: `{0}`, does not exist. | Error thrown when the system was not able to find a matching TrackedEntityAttribute with uid `{0}`. This might also mean that the user does not have access to the TrackedEntityAttribute. |
| E1007 | Error validating attribute value type: `{0}`; Error: `{1}`. | Mismatch between value type of a TrackedEntityAttribute and its provided attribute value. The actual validation error will be displayed in `{1}`. |
| E1009 | File resource: `{0}`, has already been assigned to a different object. | The File resource uid `{0}` is already assigned to another object in the system. |
| E1010 | Could not find Program: `{0}`, linked to Event. | The system was unable to find a Program with the uid `{0}` specified inside the Event payload. This might also mean that the specific Program is not accessible by the logged in user. |
| E1011 | Could not find OrganisationUnit: `{0}`, linked to Event. | The system was unable to find a OrganisationUnit with uid `{0}` specified inside the Event payload.  |
| E1012 | Geometry does not conform to FeatureType: `{0}`. | FeatureType provided is either NONE or an incompatible one for the provided geometry value. |
| E1013 | Could not find ProgramStage: `{0}`, linked to Event. | The system was unable to find a ProgramStage with uid `{0}` specified inside the Event payload. This might also mean that the ProgramStage is not accessible to the logged in user.  |
| E1014 | Provided Program: `{0}`, is a Program without registration. An Enrollment cannot be created into Program without registration. | Enrollments can only be created for Programs with registration. |
| E1015 | TrackedEntityInstance: `{0}`, already has an active Enrollment in Program `{1}`. | Cannot enroll into a Program if another active enrollment already exists for the Program. The active enrollment will have to be completed first atleast. |
| E1016 | TrackedEntityInstance: `{0}`, already has an active enrollment in Program: `{1}`, and this program only allows enrolling one time. | As per the Program `{1}` configuration, a TrackedEntity can only be enrolled into that Program once. It looks like the TrackedEntity `{0}` already has either an ACTIVE or COMPLETED enrollment in that Program. Hence another enrollment cannot be added. |
| E1018 | Attribute: `{0}`, is mandatory in program `{1}` but not declared in enrollment `{2}`. | Attribute value is missing in payload, for an attribute that is defined as mandatory for a Program. Make sure that attribute values for mandatory attributes are provided in the payload.  |
| E1019 | Only Program attributes is allowed for enrollment; Non valid attribute: `{0}`. | Attribute uid `{0}` specified in the enrollment payload is not associated with the Program.  |
| E1020 | Enrollment date: `{0}`, can`t be future date. | Cannot enroll into a future date unless the Program allows for it in its configuration. |
| E1021 | Incident date: `{0}`, can`t be future date. | Incident date cannot be a future date unless the Program allows for it in its configuration. |
| E1022 | TrackedEntityInstance: `{0}`, must have same TrackedEntityType as Program `{1}`. | The Program is configured to accept TrackedEntityType uid that is different from what is provided in the enrollment payload. |
| E1023 | DisplayIncidentDate is true but property occurredAt is null or has an invalid format: `{0}`. | Program is configured with DisplayIncidentDate but its either null or an invalid date in the payload. |
| E1025 | Property enrolledAt is null or has an invalid format: `{0}`. | EnrolledAt Date is mandatory for an Enrollment. Make sure it is not null and has a valid date format. |
| E1029 | Event OrganisationUnit: `{0}`, and Program: `{1}`, don't match. | The Event payload uses a Program `{1}` which is not configured to be accessible by OrganisationUnit `{0}`. |
| E1030 | Event: `{0}`, already exists. | This error is thrown when trying to add a new Event with an already existing uid. Make sure a new uid is used when adding a new Event. |
| E1031 | Event OccurredAt date is missing. | OccuredAt property is either null or has an invalidate date format in the payload. |
| E1032 | Event: `{0}`, do not exist. | |
| E1033 | Event: `{0}`, Enrollment value is NULL. | |
| E1035 | Event: `{0}`, ProgramStage value is NULL. | |
| E1036 | Event: `{0}`, TrackedEntityInstance does not point to a existing object. | The system was unable to find a TrackedEntity with the uid specified inside the event payload. This might also mean that the user does not have read access to the TrackedEntity. |
| E1039 | ProgramStage: `{0}`, is not repeatable and an event already exists. | An Event already exists for the ProgramStage for the specific Enrollment. Since the ProgramStage is configured to be non-repeatable, another Event for the same ProgramStage cannot be added.  |
| E1041 | Enrollment OrganisationUnit: `{0}`, and Program: `{1}`, don't match. | The Enrollment payload contains a Program `{1}` which is not configured to be accessible by the OrganisationUnit  `{0}`. |
| E1042 | Event: `{0}`, needs to have completed date. | If the program is configured to have completeExpiryDays, then CompletedDate is mandatory for a COMPLETED event payload. An Event with status as COMPLETED should have completedDate property as non-null and a valid date format. |
| E1048 | Object: `{0}`, uid: `{1}`, has an invalid uid format. | 有效的 uid 有 11 个字符。第一个字符必须是字母（a-z 或 A-Z），其余 10 个字符可以是字母数字（a-z 或 A-Z 或 0-9）。 |
| E1049 | Could not find OrganisationUnit: `{0}`, linked to Tracked Entity. | The system could not find an OrganisationUnit with uid `{0}`. |
| E1050 | Event ScheduledAt date is missing. | ScheduledAt property in the Event payload is either missing or an invalid date format. |
| E1055 | Default AttributeOptionCombo is not allowed since program has non-default CategoryCombo. | The Program is configured to contain non-default CategoryCombo but the request uses the Default AttributeOptionCombo. |
| E1056 | Event date: `{0}`, is before start date: `{1}`, for AttributeOption: `{2}`. | The CategoryOption has a start date configured , the Event date in the payload cannot be earlier than this start date. |
| E1057 | Event date: `{0}`, is after end date: `{1}`, for AttributeOption; `{2}`. | The CategoryOption has an end date configured, the Event date in the payload cannot be later than this end date.  |
| E1063 | TrackedEntityInstance: `{0}`, does not exist. | Error thrown when trying to fetch a non existing TrackedEntity with uid `{0}` . This might also mean that the user does not have read access to the TrackedEntity. |
| E1064 | Non-unique attribute value `{0}` for attribute `{1}` | The attribute value has to be unique within the defined scope. The error indicates that the attribute value already exists for another TrackedEntity. |
| E1068 | Could not find TrackedEntityInstance: `{0}`, linked to Enrollment. | The system could not find the TrackedEntity specified in the Enrollment payload. This might also mean that the user does not have read access to the TrackedEntity. |
| E1069 | Could not find Program: `{0}`, linked to Enrollment. | The system could not find the Program specified in the Enrollment payload. This might also mean that the user does not have read access to the Program. |
| E1070 | Could not find OrganisationUnit: `{0}`, linked to Enrollment. | The system could not find the OrganisationUnit specified in the Enrollment payload. |
| E1074 | FeatureType is missing. | |
| E1075 | Attribute: `{0}`, is missing uid. | |
| E1076 | `{0}` `{1}` is mandatory and can't be null | |
| E1077 | Attribute: `{0}`, text value exceed the maximum allowed length: `{0}`. | |
| E1080 | Enrollment: `{0}`, already exists. | This error is thrown when trying to create a new Enrollmentt with an already existing uid. Make sure a new uid is used when adding a new Enrollment. |
| E1081 | Enrollment: `{0}`, do not exist. | Error thrown when trying to fetch a non existing Enrollment with uid `{0}` . This might also mean that the user does not have read access to the Enrollment. |
| E1082 | Event: `{0}`, is already deleted and can't be modified. | If the event is soft deleted, no modifications on it are allowed. |
| E1083 | User: `{0}`, is not authorized to modify completed events. | Only a super user or a user with the authority "F_UNCOMPLETE_EVENT" can modify completed events. Completed Events are those Events with status as COMPLETED. |
| E1084 | File resource: `{0}`, reference could not be found. | |
| E1085 | Attribute: `{0}`, value does not match value type: `{1}`. | Mismatch between value type of an attribute and its provided attribute value. |
| E1089 | Event: `{0}`, references a Program Stage `{1}` that does not belong to Program `{2}`. | The ProgramStage uid and Program uid in the Event payload is incompatible. |
| E1090 | Attribute: `{0}`, is mandatory in tracked entity type `{1}` but not declared in tracked entity `{2}`. | The payload has missing values for mandatory TrackedEntityTypeAttributes. |
| E1091 | User: `{0}`, has no data write access to Program: `{1}`. | The Program sharing configuration is such that, the user does not have write access for this Program. |
| E1095 | User: `{0}`, has no data write access to ProgramStage: `{1}`. | The ProgramStage sharing configuration is such that, the user does not have write access for this ProgramStage.  |
| E1096 | User: `{0}`, has no data read access to Program: `{1}`. | The Program sharing configuration is such that, the user does not have read access for this Program. |
| E1099 | User: `{0}`, has no write access to CategoryOption: `{1}`. | The CategoryOption sharing configuration is such that, the user does not have write access for this CategoryOption |
| E1100 | User: `{0}`, is lacking 'F_TEI_CASCADE_DELETE' authority to delete TrackedEntityInstance: `{1}`. | There exists undeleted Enrollments for this TrackedEntity. If the user does not have 'F_TEI_CASCADE_DELETE' authority, then these Enrollments has to be deleted first explicitly to be able to delete the TrackedEntity. |
| E1102 | User: `{0}`, does not have access to the tracked entity: `{1}`, Program: `{2}`, combination. | This error is thrown when the user's OrganisationUnit does not have the ownership of this TrackedEntity for this specific Program. The owning OrganisationUnit of the TrackedEntity-Program combination should fall into the capture scope (in some cases the search scope) of the user. |
| E1103 | User: `{0}`, is lacking 'F_ENROLLMENT_CASCADE_DELETE' authority to delete Enrollment : `{1}`. | There exists undeleted Events for this Enrollment. If the user does not have 'F_ENROLLMENT_CASCADE_DELETE' authority, then these Events has to be deleted first explicitly to be able to delete the Enrollment. |
| E1104 | User: `{0}`, has no data read access to program: `{1}`, TrackedEntityType: `{2}`. | The sharing configuration of the TrackedEntityType associated with the Program is such that, the user does not have data read access to it. |
| E1112 | Attribute value: `{0}`, is set to confidential but system is not properly configured to encrypt data. | Either JCE files is missing or the configuration property `encryption.password` might be missing in `dhis.conf`. |
| E1113 | Enrollment: `{0}`, is already deleted and can't be modified. | If the Enrollment is soft deleted, no modifications on it are allowed. |
| E1114 | TrackedEntity: `{0}`, is already deleted and can't be modified. | If the TrackedEntity is soft deleted, no modifications on it are allowed. |
| E1115 | Could not find CategoryOptionCombo: `{0}`. | |
| E1116 | Could not find CategoryOption: `{0}`. | This might also mean the CategoryOption is not accessible to the user.|
| E1117 | CategoryOptionCombo does not exist for given category combo and category options: `{0}`. | |
| E1118 | Assigned user `{0}` is not a valid uid. | |
| E1119 | A Tracker Note with uid `{0}` already exists. | |
| E1120 | ProgramStage `{0}` does not allow user assignment | Event payload has assignedUserId but the ProgramStage is not configured to allow user assignment. |
| E1121 | Missing required tracked entity property: `{0}`. | |
| E1122 | Missing required enrollment property: `{0}`. | |
| E1123 | Missing required event property: `{0}`. | |
| E1124 | Missing required relationship property: `{0}`. | |
| E1125 | Value `{0}` is not a valid option for `{1}` `{2}` in option set `{3}` | |
| E1017 | Attribute: `{0}`, does not exist. | |
| E1093 | User: `{0}`, has no search access to OrganisationUnit: `{1}`. | |
| E1094 | Not allowed to update Enrollment: `{0}`, existing Program `{1}`. | The Enrollment payload for an existing Enrollment has a different Program uid than the one it was originally enrolled with. |
| E1110 | Not allowed to update Event: `{0}`, existing Program `{1}`. | The Event payload for an existing Event has a different Program uid than the one it was originally created with.  |
| E1111 | We have a generated attribute: `{0}`, but no pattern. | |
| E1043 | Event: `{0}`, completeness date has expired. Not possible to make changes to this event. | A user without 'F_EDIT_EXPIRED' authority cannot update an Event that has passed its expiry days as configured in its Program. |
| E1046 | Event: `{0}`, needs to have at least one (event or schedule) date. | Either of occuredAt or scheduledAt property should be present in the Event payload. |
| E1047 | Event: `{0}`, date belongs to an expired period. It is not possible to create such event. | Event occuredAt or scheduledAt has a value that is earlier than the PeriodType start date.  |
| E1300 | Generated by program rule (`{0}`) - `{1}` | |
| E1302 | Generated by program rule (`{0}`) - DataElement `{1}` is not valid: `{2}` | |
| E1303 | Generated by program rule (`{0}`) - Mandatory DataElement `{1}` is not present | |
| E1304 | Generated by program rule (`{0}`) - DataElement `{1}` is not a valid data element | |
| E1305 | Generated by program rule (`{0}`) - DataElement `{1}` is not part of `{2}` program stage | |
| E1306 | Generated by program rule (`{0}`) - Mandatory Attribute `{1}` is not present | |
| E1307 | Generated by program rule (`{0}`) - Unable to assign value to data element `{1}`. The provided value must be empty or match the calculated value `{2}` | |
| E1308 | Generated by program rule (`{0}`) - DataElement `{1}` is being replaced in event `{2}` | |
| E1309 | Generated by program rule (`{0}`) - Unable to assign value to attribute `{1}`. The provided value must be empty or match the calculated value `{2}` | |
| E1310 | Generated by program rule (`{0}`) - Attribute `{1}` is being replaced in tei `{2}` | |
| E4000 | Relationship: `{0}` cannot link to itself | |
| E4001 | Relationship Item `{0}` for Relationship `{1}` is invalid: an Item can link only one Tracker entity. | |
| E4006 | Could not find relationship Type: `{0}`. | |
| E4009 | Relationship Type `{0}` is not valid. | |
| E4010 | Relationship Type `{0}` constraint requires a {1} but a {2} was found. | |
| E4011 | Relationship: `{0}` cannot be persisted because {1} {2} referenced by this relationship is not valid. | |
| E4012 | Could not find `{0}`: `{1}`, linked to Relationship. | |
| E4013 | Relationship Type `{0}` constraint is missing {1}. | |
| E4014 | Relationship Type `{0}` constraint requires a Tracked Entity having type `{1}` but `{2}` was found. | |
| E4062 | Start date or end date not specified with ABSOLUTE date period type for item `{0}` | |
| E4063 | Assigned users cannot be empty when assigned user mode is set to PROVIDED | |
| E4064 | Organisation unit cannot be empty with `{0}` org unit mode | |
| E4065 | Data item UID is missing in filter | |
| E4066 | No data element found for item: `{0}` | |
| E4067 | Attribute UID is missing in filter | |
| E4068 | No tracked entity attribute found for attribute: `{0}` | |
| E9999 | 不适用 | Undefined error message. |

### 验证方式 { #webapi_nti_validation }

While importing data using the tracker importer, a series of validations are performed to ensure the validity of the data. This section will describe some of the different types of validation performed to provide a better understanding if validation fails for your import.

#### Required properties { #required-properties } 

Each of the tracker objects has a few required properties that need to be present when importing data. For an exhaustive list of required properties, have a look at the [Tracker Object section](#webapi_nti_tracker_objects).

When validating required properties, we are usually talking about references to other data or metadata. In these cases, there are three main criteria:

1. The reference is present and not null in the payload.
2. The reference points to the correct type of data and exists in the database
3. The user has access to see the reference

If the first condition fails, the import will fail with a message about a missing reference. However, suppose the reference points to something that doesn't exist or which the user cannot access. In that case, both cases will result in a message about the reference not being found.

#### Formats { #formats } 

Some of the properties of tracker objects require a specific format. When importing data, each of these properties is validated against the expected format and will return different errors depending on which property has a wrong format. Some examples of properties that are validated this way:

- UIDs (These cover all references to other data or metadata in DHIS2.)
- Dates
- Geometry (The coordinates must match the format as specified by its type)

#### User access { #user-access } 
All data imported will be validated based on the metadata  ([Sharing](#webapi_nti_metadata_sharing)) and the organisation units ([Organisation Unit Scopes](#webapi_nti_ou_scope)) referenced in the data. You can find more information about sharing and organisation unit scopes in the following sections.

Sharing is validated at the same time as references are looked up in the database. Metadata outside of the user's access will be treated as if it doesn't exist. The import will validate any metadata referenced in the data.

Organisation units, on the other hand, serve a dual purpose. It will primarily make sure that data can only be imported when imported for an organisation unit the user has within their "capture scope". Secondly, organisation units are also used to restrict what programs are available. That means if you are trying to import data for an organisation unit that does not have access to the Program you are importing, the import will be invalid.

Users with the `ALL` authority will ignore the limits of sharing and organisation unit scopes when they import data. However, they can not import enrollments in organisation units that do not have access to the enrollment program.

#### Attribute and Data values { #attribute-and-data-values } 

Attributes and data values are part of a tracked entity and an event, respectively. However, attributes can be linked to a tracked entity either through its type (TrackedEntityType) or its Program (Program). Additionally, attributes can also be unique.

The initial validation done in the import is to make sure the value provided for an attribute or data element conforms to the type of value expected. For example, suppose you import a value for a data element with a numeric type. In that case, the value is expected to be numeric. Any errors related to a mismatch between a type and a value will result in the same error code but with a specific message related to the type of violation.

Mandatory attributes and data values are also checked. Currently, removing mandatory attributes is not allowed. Some use-cases require values to be sent separately, while others require all values to be sent as one. Programs can be configured to either validate mandatory attributes `ON_COMPLETE` or `ON_UPDATE_AND_INSERT` to accommodate these use-cases.

The import will validate unique attributes at the time of import. That means as long as the provided value is unique for the attribute in the whole system, it will pass. However, if the unique value is found used by any other tracked entity other than the one being imported, it will fail.

#### 组态 { #configuration } 

The last part of validations in the importer are validations based on the user's configuration of relevant metadata. For more information about each configuration, check out the relevant sections. Some examples of configurable validations:
- Feature type (For geometry)
- User-assignable events
- Allow future dates
- Enroll once
- And more.

These configurations will further change how validation is performed during import.

### Program Rules { #webapi_nti_program_rules }

Users can configure [Program Rules](#webapi_program_rules), which adds conditional behavior to tracker forms. In addition to running these rules in the tracker apps, the tracker importer will also run a selection of these rules. Since the importer is also running these rules, we can ensure an additional level of validation.

Not all program rule actions are supported since they are only suitable for a frontend presentation. A complete list of the supported program rule actions is presented below.

  |Program Rule Action|支持的|
  |---|:---:|
  |**DISPLAYTEXT**| |
  |**DISPLAYKEYVALUEPAIR**| |
  |**HIDEFIELD**||
  |**HIDESECTION**||
  |**ASSIGN**|**X**|
  |**SHOWWARNING**|**X**|
  |**SHOWERROR**|**X**|
  |**WARNINGONCOMPLETION**|**X**|
  |**ERRORONCOMPLETION**|**X**|
  |**CREATEEVENT**||
  |**SETMANDATORYFIELD**|**X**|
  |**SENDMESSAGE**|**X**|
  |**SCHEDULEMESSAGE**|**X**|

Program rules are evaluated in the importer in the same way they are evaluated in the Tracker apps. To summarize, the following conditions are considered when enforcing the program rules:

* The program rule must be linked to the data being imported. For example, a program stage or a data element.
* The Program rule's condition must be evaluated to true

The results of the program rules depend on the actions defined in those rules:

* Program rule actions may end in 2 different results: Warnings or Errors.
  * Errors will make the validation fail, while the warnings will be reported as a message in the import summary.
    * SHOWWARNING and WARNINGONCOMPLETION actions can generate only Warnings.
    * SHOWERROR, ERRORONCOMPLETION, and SETMANDATORYFIELD actions can generate only Errors.
    * ASSIGN action can generate both Warnings and Errors.
      * When the action is assigning a value to an empty attribute/data element, a warning is generated.
      * When the action is assigning a value to an attribute/data element that already has the same value to be assigned, a warning is generated.
      * When the action is assigning a value to an attribute/data element that already has a value and the value to be assigned is different, an error is generated unless the `RULE_ENGINE_ASSIGN_OVERWRITE` system setting is set to true.

Additionally, program rules can also result in side-effects, like send and schedule messages. More information about side effects can be found in the following section.

> **NOTE**
>
> Program rules can be skipped during import using the `skipProgramRules` parameter.

### Side Effects { #webapi_nti_side_effects }

After an import has been completed, specific tasks might be triggered as a result of the import. These tasks are what we refer to as "Side effects". These tasks perform operations that do not affect the import itself.

Side effects are tasks running detached from the import but are always triggered by an import. Since side effects are detached from the import, they can fail even when the import is successful. Additionally, side effects are only run when the import is successful, so they cannot fail the other way around.

The following side effects are currently supported:

  |Side Effects|支持的|描述|
  |---|:---:|---|
  |**Tracker Notification**|**X**| Updates can trigger notifications. Updates which trigger notifications are **enrollment**, **event update**, **event or enrollment completion**. |
  |**ProgramRule Notification**|**X**| Program rules can trigger notifications. Note that these notifications are part of program rule effects which are generated through the DHIS2 rule engine.|

  > **NOTE**
  >
  > Certain configurations can control the execution of side effects. `skipSideEffects` flag can be set during the import to skip side effects entirely. This parameter can be useful if you import something you don't want to trigger notifications for, as an example.

### Assign user to events { #webapi_nti_user_event_assignment }

Specific workflows benefit from treating events like tasks, and for this reason, you can assign a user to an event.

Assigning a user to an event will not change the access or permissions for users but will create a link between the Event and the user.
When an event has a user assigned, you can query events from the API using the `assignedUser` field as a parameter.

When you want to assign a user to an event, you simply provide the UID of the user you want to assign in the `assignedUser` field. See the following example:

```json
{
  ...
  "events": [
    {
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "enrollment": "MNWZ6hnuhSw",
      "assignedUser" : "M0fCOxtkURr"
    }
  ],
  ...
}
```

In this example, the user with uid `M0fCOxtkURr` will be assigned to the Event with uid `ZwwuwNp6gVd`. Only one user can be assigned to a single event.

To use this feature, the relevant program stage needs to have user assignment enabled, and the uid provided for the user must refer to a valid, existing user.

## Tracker Export { #webapi_nti_export }

Tracker export endpoints allow you to retrieve the previously imported objects which are:

- **tracked entities**
- **events**
- **enrollments**
- **relationships**

> **NOTE**
>
> - All these endpoints currently support `JSON`. `CSV` is only supported by tracked entities and events.

### Common request parameters { #common-request-parameters } 

The following endpoint supports standard parameters for pagination.

- **Tracked Entities** `GET /api/tracker/trackedEntities`
- **Events** `GET /api/tracker/events`
- **Enrollments** `GET /api/tracker/enrollments`
- **Relationships** `GET /api/tracker/relationships`

#### Request parameters for pagination { #request-parameters-for-pagination } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`page`|`Integer`| Any positive integer |Page number to return. Defaults to 1 if missing|
|`pageSize`|`Integer`| Any positive integer |Page size. Defaults to 50. |
|`totalPages`|`Boolean`| `true`&#124;`false` |Indicates whether to return the total number of pages in the response |
|`skipPaging`|`Boolean`| `true`&#124;`false` |Indicates whether paging should be ignored and all rows should be returned. Defaults to `false`, meaning that by default all requests are paginated, unless `skipPaging=true`|

> **Caution**
>
> Be aware that the performance is directly related to the amount of data requested. Larger pages will take more time to return.

#### Request parameters for Organisational Unit selection mode { #request-parameters-for-organisational-unit-selection-mode } 

可用的组织单元选择模式在
下表。

|Mode|描述|
|---|---|
|`SELECTED`|  Organisation units defined in the request.|
|`CHILDREN`|  The selected organisation units and the immediate children, i.e., the organisation units at the level below.|
|`DESCENDANTS`| The selected organisation units and all children, i.e., all organisation units in the sub-hierarchy.|
|`ACCESSIBLE`|  The data view organisation units associated with the current user and all children, i.e., all organisation units in the sub-hierarchy. Will fall back to data capture organisation units associated with the current user if the former is not defined.|
|`CAPTURE`| The data capture organisation units associated with the current user and all children, i.e., all organisation units in the sub-hierarchy.|
|`ALL`| All organisation units in the system. Requires the ALL authority.|

#### Request parameter to filter responses { #webapi_nti_field_filter }

All export endpoints accept a `fields` parameter which controls which fields will be returned in the
JSON response. `fields` parameter accepts a comma separated list of field names or patterns. A few
possible `fields` filters are shown below. Refer to [Metadata field
filter](#webapi_metadata_field_filter) for a more complete guide on how to use `fields`.

##### 例子 { #examples } 

|Parameter example|Meaning|
|:---|:---|
|`fields=*`|returns all fields|
|`fields=createdAt,uid`|only returns fields `createdAt` and `uid`|
|`fields=enrollments[*,!uid]`|returns all fields of `enrollments` except `uid`|
|`fields=enrollments[uid]`|only returns `enrollments` field `uid`|
|`fields=enrollments[uid,enrolledAt]`|only returns `enrollments` fields `uid` and `enrolledAt`|

### Tracked Entities (`GET /api/tracker/trackedEntities`) { #tracked-entities-get-apitrackertrackedentities } 

Two endpoints are dedicated to tracked entities:

- `GET /api/tracker/trackedEntities`
  - retrieves tracked entities matching given criteria
- `GET /api/tracker/trackedEntities/{id}`
  - retrieves a tracked entity given the provided id

#### Tracked Entities Collection endpoint `GET /api/tracker/trackedEntities` { #tracked-entities-collection-endpoint-get-apitrackertrackedentities } 

The purpose of this endpoint is to retrieve tracked entities matching client-provided criteria.

The endpoint returns a list of tracked entities that match the request parameters.

##### 请求语法 { #request-syntax } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`query`|`String`|`{operator}:{filter-value}`|Creates a filter over tracked entity attributes. Only the filter value is mandatory. The `EQ` operator is used if `operator` is not specified.|
|`attribute`|`String`|Comma separated values of attribute `UID`s |For each tracked entity in the response, only returns specified attributes |
|`filter`|`String`|Comma separated values of attribute filters|Narrows response to TEIs matching given filters. A filter is a colon separated property or attribute UID with optional operator and value pairs. Example: `filter=H9IlTX2X6SL:sw:A` with operator starts with `sw` followed by a value. Special characters like `+` need to be percent-encoded so `%2B` instead of `+`. Characters such as `:` (colon) or `,` (comma), as part of the filter value, need to be escaped by `/` (slash). Likewise, `/` needs to be escaped. Multiple operator/value pairs for the same property/attribute like `filter=AuPLng5hLbE:gt:438901703:lt:448901704` are allowed. Repeating the same attribute UID is not allowed. User needs access to the attribute to filter on it.|
|`orgUnit`|`String`|semicolon-delimited list of organisational unit `UID`|Only return tracked entity instances belonging to provided organisational units|
|`ouMode` see [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`String`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|The mode of selecting organisation units, can be. Default is `SELECTED`, which refers to the selected organisation units only.|
|`program`|`String`|Program `UID`| a Program `UID` for which instances in the response must be enrolled into|
|`programStatus`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|The ProgramStatus of the Tracked Entity Instance in the given program|
|`programStage`|`String`|`UID`|a Program Stage `UID` for which instances in the response must have events for|
|`followUp`|`Boolean`|`true`&#124;`false`|Indicates whether the Tracked Entity Instance is marked for follow up for the specified Program|
|`updatedAfter`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Start date for last updated|
|`updatedBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | End date for last updated|
|`updatedWithin`|`Duration`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) | Returns TEIs not older than specified Duration|
|`enrollmentEnrolledAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date for enrollment in the given program|
|`enrollmentEnrolledBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date for enrollment in the given program|
|`enrollmentOccurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date for incident in the given program|
|`enrollmentOccurredBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date for incident in the given program|
|`trackedEntityType`|`String`|UID of tracked entity type|Only returns Tracked Entity Instances of given type|
|`trackedEntity`|`String`|semicolon-delimited list of tracked entity instance `UID`|Filter the result down to a limited set of tracked entities using explicit uids of the tracked entity instances by using `trackedEntity=id1;id2`. This parameter will, at the very least, create the outer boundary of the results, forming the list of all tracked entities using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary.|
|`assignedUserMode`|`String`|`CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`|Restricts result to tracked entities with events assigned based on the assigned user selection mode. See table below "Assigned user modes" for explanations. |
|`assignedUser`|`String`|Semicolon-delimited list of user UIDs to filter based on events assigned to the users.|Filter the result down to a limited set of tracked entities with events that are assigned to the given user IDs by using `assignedUser=id1;id2`.This parameter will only be considered if assignedUserMode is either `PROVIDED` or `null`. The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`|
|`eventStatus`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`VISITED`&#124;`SCHEDULE`&#124;`OVERDUE`&#124;`SKIPPED`|Status of any events in the specified program|
|`eventOccurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date for Event for the given Program|
|`eventOccurredBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date for Event for the given Program|
|`skipMeta`|`Boolean`|`true`&#124;`false`|Indicates whether not to include metadata in the response.|
|`includeDeleted`|`Boolean`|`true`&#124;`false`|Indicates whether to include soft-deleted elements|
|`includeAllAttributes`|`Boolean`|`true`&#124;`false`|Indicates whether to include all TEI attributes|
|`attachment`|`String`| |The file name in case of exporting as a file|
|`potentialDuplicate`|`Boolean`|`true`&#124;`false`| Filter the result based on the fact that a TEI is a Potential Duplicate. true: return TEIs flagged as Potential Duplicates. false: return TEIs NOT flagged as Potential Duplicates. If omitted, we don't check whether a TEI is a Potential Duplicate or not. |
|`order`|`String`|comma-delimited list of property name or attribute UID and sort direction pairs in format `propName:sortDirection`.|Supported fields: `createdAtClient`, `createdAt`, `enrolledAt`, `inactive`, `trackedEntity`, `updatedAtClient`, `updatedAt`.|

The available assigned user modes are explained in the following table.


Table: Assigned user modes

| Mode | 描述 |
|---|---|
| CURRENT | Includes events assigned to the current logged in user. |
| PROVIDED | Includes events assigned to the user provided in the request. |
| NONE | Includes unassigned events only. |
| ANY | Includes all assigned events, doesn't matter who are they assigned to as long as they assigned to someone. |

查询不区分大小写。以下规则适用于查询
参数。

- At least one organisation unit must be specified using the `orgUnit`
  parameter (one or many), or `ouMode=ALL` must be specified.

- Only one of the `program` and `trackedEntity` parameters can be
  指定（零或一）。

- If `programStatus` is specified, then `program` must also be
  指定的。

- If `followUp` is specified, then `program` must also be specified.

- If `enrollmentEnrolledAfter` or `enrollmentEnrolledBefore` is specified then
  `program` must also be specified.

- 过滤器项目只能指定一次。

##### Example requests { #example-requests } 

查询与特定组织单位关联的所有实例
看起来像这样：

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8

使用一个带有过滤器的属性和一个属性来查询实例
没有过滤器的属性，一个组织单位使用
后代组织单位查询方式：

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &attribure=AMpUYgxuCaE&orgUnit=DiszpKrYNg8;yMCshbaVExv

A query for instances where attributes are included in the response
and one attribute is used as a filter:

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &filter=AMpUYgxuCaE:LIKE:Road
        &orgUnit=DiszpKrYNg8

为过滤器指定了多个操作数和过滤器的查询
物品：

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &program=ur1Edk5Oe2n
        &filter=lw1SqmMlnfh:GT:150
        &filter=lw1SqmMlnfh:LT:190

A query filter with a value that needs escaping and will be interpreted as `:,/`:

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &program=ur1Edk5Oe2n
        &filter=lw1SqmMlnfh:EQ:/:/,//

要在 *IN* 过滤器中使用多个值查询属性：

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &filter=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

限制对属于特定事件一部分的实例的响应
program 你可以包含一个 program 查询参数：

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS
        &program=ur1Edk5Oe2n

要将程序注册日期指定为查询的一部分，请执行以下操作：

    GET /api/tracker/trackedEntities?
        &orgUnit=O6uvpzGd5pu&program=ur1Edk5Oe2n
        &enrollmentEnrolledAfter=2013-01-01
        &enrollmentEnrolledBefore=2013-09-01

要限制对特定跟踪实体实例的响应，您
可以包含跟踪实体查询参数：

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu
        &ouMode=DESCENDANTS
        &trackedEntity=cyl5vuJ5ETQ

默认情况下，实例以大小为 50 的页面返回，以更改
您可以使用 page 和 pageSize 查询参数：

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu
        &ouMode=DESCENDANTS
        &page=2&pageSize=3

您可以使用一系列运算符进行过滤：

|Operator|  描述|
|---|---|
|`EQ`|  Equal to|
|`GT`|  Greater than|
|`GE`|  Greater than or equal to|
|`LT`|  Less than|
|`LE`|  Less than or equal to|
|`NE`|  Not equal to|
|`LIKE`|  Like (free text match)|
|`IN`|  Equal to one of the multiple values separated by ";"|

##### 回应格式 { #response-format } 

The `JSON` response can look like the following.

Responses can be filtered on desired fields, see [Request parameter to filter responses](#webapi_nti_field_filter)

```json
{
  "instances": [
    {
      "trackedEntity": "IzHblRD2sDH",
      "trackedEntityType": "nEenWmSyUEp",
      "createdAt": "2014-03-26T15:40:36.669",
      "createdAtClient": "2014-03-26T15:40:36.669",
      "updatedAt": "2014-03-28T12:28:17.544",
      "orgUnit": "g8upMTyEZGZ",
      "inactive": false,
      "deleted": false,
      "relationships": [],
      "attributes": [
        {
          "attribute": "VqEFza8wbwA",
          "code": "MMD_PER_ADR1",
          "displayName": "Address",
          "createdAt": "2016-01-12T00:00:00.000",
          "updatedAt": "2016-01-12T00:00:00.000",
          "valueType": "TEXT",
          "value": "1061 Marconi St"
        },
        {
          "attribute": "RG7uGl4w5Jq",
          "code": "Longitude",
          "displayName": "Longitude",
          "createdAt": "2016-01-12T00:00:00.000",
          "updatedAt": "2016-01-12T00:00:00.000",
          "valueType": "TEXT",
          "value": "27.866613"
        },
        ...,
        ...,
      ],
      "enrollments": [],
      "programOwners": []
    }
  ],
  "page": 1,
  "total": 39,
  "pageSize": 1
}
```

#### Tracked Entities single object endpoint `GET /api/tracker/trackedEntities/{uid}`

The purpose of this endpoint is to retrieve one tracked entity given its uid.

##### 请求语法 { #request-syntax } 

`GET /api/tracker/trackedEntities/{uid}?program={programUid}&fields={fields}`

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`uid`|`String`|`uid`|Return the Tracked Entity Instance with specified `uid`|
|`program`|`String`|`uid`| Include program attributes in the response (only the ones user has access to) |
|`fields`|`String`| Any valid field filter (default `*,!relationships,!enrollments,!events,!programOwners`) |Include specified sub-objects in the response| 

##### Example requests { #example-requests } 

A query for a Tracked Entity Instance:

    GET /api/tracker/trackedEntities/IzHblRD2sDH?program=ur1Edk5Oe2n&fields=*

##### 回应格式 { #response-format } 

This endpoint supports returning sub-objects when the `fields` request parameter is passed when json format is requested. In case of csv the `fields` request parameter has no effect and the response will always contain the same fields, which are:
  - trackedEntity (Identifier)
  - trackedEntityType (Identifier)
  - createdAt (Datetime)
  - createdAtClient (Datetime)
  - updatedAt (Datetime)
  - updatedAtClient (Datetime)
  - orgUnit (Identifier)
  - inactive (boolean)
  - deleted (boolean)
  - potentialDuplicate (boolean)
  - geometry (WKT, https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry)
  - storedBy (String)
  - createdBy (Username of user)
  - updatedBy (Username of user)
  - attributes (each valid attribute listed as another column)

An example of a json response:
```json
{
    "trackedEntity": "IzHblRD2sDH",
    "trackedEntityType": "nEenWmSyUEp",
    "createdAt": "2014-03-26T15:40:36.669",
    "updatedAt": "2014-03-28T12:28:17.544",
    "orgUnit": "g8upMTyEZGZ",
    "inactive": false,
    "deleted": false,
    "relationships": [],
    "attributes": [
        {
            "attribute": "w75KJ2mc4zz",
            "code": "MMD_PER_NAM",
            "displayName": "First name",
            "createdAt": "2016-01-12T09:10:26.986",
            "updatedAt": "2016-01-12T09:10:35.884",
            "valueType": "TEXT",
            "value": "Wegahta"
        },
        {
            "attribute": "zDhUuAYrxNC",
            "displayName": "Last name",
            "createdAt": "2016-01-12T09:10:26.986",
            "updatedAt": "2016-01-12T09:10:35.884",
            "valueType": "TEXT",
            "value": "Goytiom"
        }
    ],
    "enrollments": [
        {
            "enrollment": "uT5ZysTES7j",
            "createdAt": "2017-03-28T12:28:17.539",
            "createdAtClient": "2016-03-28T12:28:17.539",
            "updatedAt": "2017-03-28T12:28:17.544",
            "trackedEntity": "IzHblRD2sDH",
            "trackedEntityType": "nEenWmSyUEp",
            "program": "ur1Edk5Oe2n",
            "status": "ACTIVE",
            "orgUnit": "g8upMTyEZGZ",
            "orgUnitName": "Njandama MCHP",
            "enrolledAt": "2020-11-10T12:28:17.532",
            "occurredAt": "2020-10-12T12:28:17.532",
            "followUp": false,
            "deleted": false,
            "events": [
                {
                    "event": "ixDYEGrNQeH",
                    "status": "ACTIVE",
                    "program": "ur1Edk5Oe2n",
                    "programStage": "ZkbAXlQUYJG",
                    "enrollment": "uT5ZysTES7j",
                    "enrollmentStatus": "ACTIVE",
                    "trackedEntity": "IzHblRD2sDH",
                    "relationships": [],
                    "scheduledAt": "2019-10-12T12:28:17.532",
                    "followup": false,
                    "deleted": false,
                    "createdAt": "2017-03-28T12:28:17.542",
                    "createdAtClient": "2016-03-28T12:28:17.542",
                    "updatedAt": "2017-03-28T12:28:17.542",
                    "attributeOptionCombo": "HllvX50cXC0",
                    "attributeCategoryOptions": "xYerKDKCefk",
                    "dataValues": [],
                    "notes": []
                }
            ],
            "relationships": [],
            "attributes": [],
            "notes": []
        }
    ],
    "programOwners": [
        {
            "orgUnit": "g8upMTyEZGZ",
            "trackedEntity": "IzHblRD2sDH",
            "program": "ur1Edk5Oe2n"
        }
    ]
}
```

### Events (`GET /api/tracker/events`) { #events-get-apitrackerevents } 

Two endpoints are dedicated to events:

- `GET /api/tracker/events`
    - retrieves events matching given criteria
- `GET /api/tracker/events/{id}`
    - retrieves an event given the provided id

#### Events Collection endpoint `GET /api/tracker/events` { #events-collection-endpoint-get-apitrackerevents } 

Returns a list of events based on the provided filters.

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`program`|`String`|`uid`| Identifier of program|
|`programStage`|`String`|`uid`| Identifier of program stage|
|`programStatus`|`enum`| `ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`| Status of event in program | 
|`filter`|`String`|Comma separated values of data element filters|Narrows response to events matching given filters. A filter is a colon separated property or data element UID with optional operator and value pairs. Example: `filter=fazCI2ygYkq:eq:PASSIVE` with operator starts with `eq` followed by a value. Characters such as `:` (colon) or `,` (comma), as part of the filter value, need to be escaped by `/` (slash). Likewise, `/` needs to be escaped. Multiple operator/value pairs for the same property/data element like `filter=qrur9Dvnyt5:gt:70:lt:80` are allowed. Repeating the same data element UID is not allowed. User needs access to the data element to filter on it.|
|`filterAttributes`|`String`|Comma separated values of attribute filters|Narrows response to TEIs matching given filters. A filter is a colon separated property or attribute UID with optional operator and value pairs. Example: `filter=H9IlTX2X6SL:sw:A` with operator starts with `sw` followed by a value. Special characters like `+` need to be percent-encoded so `%2B` instead of `+`. Characters such as `:` (colon) or `,` (comma), as part of the filter value, need to be escaped by `/` (slash). Likewise, `/` needs to be escaped. Multiple operator/value pairs for the same property/attribute like `filter=AuPLng5hLbE:gt:438901703:lt:448901704` are allowed. Repeating the same attribute UID is not allowed. User needs access to the attribute to filter on it.|
|`followUp`|`boolean`| `true`&#124;`false` | Whether event is considered for follow up in program. Defaults to `true`|
|`trackedEntityInstance`|`String`|`uid`| Identifier of tracked entity instance|
|`orgUnit`|`String`|`uid`| Identifier of organisation unit|
|`ouMode` see [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`String`| `SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`|  Org unit selection mode| 
|`status`|`String`|`ACTIVE`&#124;`COMPLETED`&#124;`VISITED`&#124;`SCHEDULE`&#124;`OVERDUE`&#124;`SKIPPED` | Status of event|
|`occurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which occurred after this date.|
|`occurredBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which occurred up until this date.|
|`scheduledAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were scheduled after this date.|
|`scheduledBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were scheduled before this date.|
|`updatedAfter`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were updated after this date. Cannot be used together with `updatedWithin`.|
|`updatedBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were updated up until this date. Cannot be used together with `updatedWithin`.|
|`updatedWithin`|`Duration`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations)| Include only items which are updated within the given duration.<br><br> The format is [ISO-8601#Duration](https://en.wikipedia.org/wiki/ISO_8601#Durations)|
|`enrollmentEnrolledAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date for enrollment in the given program|
|`enrollmentEnrolledBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date for enrollment in the given program|
|`enrollmentOccurredAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Start date for incident in the given program|
|`enrollmentOccurredBefore`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|End date for incident in the given program|
|`skipMeta`|`Boolean`| `true`&#124;`false` | Exclude the meta data part of response (improves performance)|
|`dataElementIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Data element ID scheme to use for export.|
|`categoryOptionComboIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Category Option Combo ID scheme to use for export|
|`orgUnitIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Organisation Unit ID scheme to use for export|
|`programIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Program ID scheme to use for export|
|`programStageIdScheme`|`String`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Program Stage ID scheme to use for export|
|`idScheme`|`string`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Allows to set id scheme for data element, category option combo, orgUnit, program and program stage at once.|
|`order`|`String`|Supported fields are: `assignedUser, assignedUserDisplayName, attributeOptionCombo, completedAt, completedBy, createdAt, createdBy, deleted, enrolledAt, enrollment, enrollmentStatus, event, followup, occurredAt, orgUnit, orgUnitName, program, programStage, scheduleAt, status, storedBy, trackedEntity, updatedAt, updatedBy`.|Comma-delimited list of property name, attribute or data element UID and sort direction pairs in format `propName:sortDirection`.<br><br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive. |
|`event`|`String`|comma-delimited list of `uid`| Filter the result down to a limited set of IDs by using event=id1;id2.|
|`skipEventId`|`Boolean`| | Skips event identifiers in the response|
|`attributeCc` (see note)|`String`| Attribute category combo identifier (must be combined with attributeCos)|
|`attributeCos` (see note)|`String`| Attribute category option identifiers, separated with ; (must be combined with attributeCc)|
|`includeDeleted`|`Boolean`| |  When true, soft deleted events will be included in your query result.|
|`assignedUserMode`|`String`| `CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`| Assigned user selection mode|
|`assignedUser`|`String`|comma-delimited list od `uid`| Filter the result down to a limited set of events that are assigned to the given user IDs by using `assignedUser=id1;id2`.<br><br>This parameter will be considered only if assignedUserMode is either `PROVIDED` or `null`.<br><br>The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`|

> **Note**
>
> If the query contains neither `attributeCC` nor `attributeCos`, 
> the server returns events for all attribute option combos where the user has read access.

##### Example requests { #example-requests } 

The query for all events with children of a particular organisation unit:

    GET /api/tracker/events?orgUnit=YuQRtpLP10I&ouMode=CHILDREN

The query for all events with all descendants of a particular organisation
unit, implying all organisation units in the sub-hierarchy:

    GET /api/tracker/events?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS

使用特定程序和组织单位查询所有事件：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

查询具有一定节目和组织单位的所有事件，
按截止日期排序
    上升：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=dueDate

查询某节目中活动日期最新的10个活动
和组织单位 - 按到期日降序分页和排序：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &order=eventDate:desc&pageSize=10&page=1

查询具有特定节目和组织单位的所有事件
特定的跟踪实体实例：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8
      &program=eBAyeGv0exc&trackedEntityInstance=gfVxE3ALA9m

查询某个程序和组织单位较旧的所有事件
或等于
    2014-02-03：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&endDate=2014-02-03

查询具有一定节目阶段、组织单位和
2014年被跟踪实体实例：

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &trackedEntityInstance=gfVxE3ALA9m&occurredAfter=2014-01-01&occurredBefore=2014-12-31

Retrieve events with specified Organisation unit and Program, and use `Attribute:Gq0oWTf2DtN` as
identifier scheme

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN

Retrieve events with specified Organisation unit and Program, and use UID as identifier scheme for
organisation units, Code as identifier scheme for Program stages, and _Attribute:Gq0oWTf2DtN_ as the identifier
scheme for the rest of the metadata with assigned attributes.

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN
      &orgUnitIdScheme=UID&programStageIdScheme=Code

A query where multiple operand and filters are specified for a data element UID:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8
        &program=lxAQ7Zs9VYR
        &filter=lw1SqmMlnfh:GT:150
        &filter=lw1SqmMlnfh:LT:190

A query filter with a value that needs escaping and will be interpreted as `:,/`:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8
        &program=lxAQ7Zs9VYR
        &filter=lw1SqmMlnfh:EQ:/:/,//

##### 回应格式 { #response-format } 

The `JSON` response can look like the following.

```json
{
    "instances": [
        {
            "event": "rgWr86qs0sI",
            "status": "ACTIVE",
            "program": "kla3mAPgvCH",
            "programStage": "aNLq9ZYoy9W",
            "orgUnit": "DiszpKrYNg8",
            "orgUnitName": "Ngelehun CHC",
            "relationships": [],
            "occurredAt": "2021-10-12T00:00:00.000",
            "followup": false,
            "deleted": false,
            "createdAt": "2018-10-20T12:09:19.492",
            "updatedAt": "2018-10-20T12:09:19.492",
            "attributeOptionCombo": "amw2rQP6r6M",
            "attributeCategoryOptions": "RkbOhHwiOgW",
            "dataValues": [
                {
                    "createdAt": "2015-10-20T12:09:19.640",
                    "updatedAt": "2015-10-20T12:09:19.640",
                    "storedBy": "system",
                    "providedElsewhere": false,
                    "dataElement": "HyJL2Lt37jN",
                    "value": "12"
                },
              ...
            ],
            "notes": []
        }
    ],
    "page": 1,
    "pageSize": 1
}
```

The `CSV` response can look like the following.

```
|event|status|program|programStage|enrollment|orgUnit|occurredAt|scheduledAt|dataElement|value|storedBy|providedElsewhere
|---|---|---|---|---|---|---|---|---|---|---|---|
|V1CerIi3sdL|COMPLETED|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|a3kGcGDCuk6|11|admin|false
|V1CerIi3sdL|COMPLETED|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|mB2QHw1tU96|[-11.566044,9.477801]|admin|false
```

#### Events single object endpoint `GET /api/tracker/events/{uid}`

The purpose of this endpoint is to retrieve one Event given its uid.

##### 请求语法 { #request-syntax } 

`GET /api/tracker/events/{uid}?fields={fields}`

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`uid`|`String`|`uid`|Return the Event with specified `uid`|
|`fields`|`String`| Any valid field filter (default `*,!relationships`) |Include specified sub-objects in the response| 

##### Example requests { #example-requests } 

A query for an Event:

    GET /api/tracker/events/rgWr86qs0sI

##### 回应格式 { #response-format } 

```json
{
  "event": "rgWr86qs0sI",
  "status": "ACTIVE",
  "program": "kla3mAPgvCH",
  "programStage": "aNLq9ZYoy9W",
  "enrollment": "Lo3SHzCnMSm",
  "enrollmentStatus": "ACTIVE",
  "orgUnit": "DiszpKrYNg8",
  "orgUnitName": "Ngelehun CHC",
  "relationships": [],
  "occurredAt": "2021-10-12T00:00:00.000",
  "followup": false,
  "deleted": false,
  "createdAt": "2018-10-20T12:09:19.492",
  "createdAtClient": "2017-10-20T12:09:19.492",
  "updatedAt": "2018-10-20T12:09:19.492",
  "attributeOptionCombo": "amw2rQP6r6M",
  "attributeCategoryOptions": "RkbOhHwiOgW",
  "dataValues": [
    {
      "createdAt": "2015-10-20T12:09:19.640",
      "updatedAt": "2015-10-20T12:09:19.640",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HyJL2Lt37jN",
      "value": "12"
    },
    {
      "createdAt": "2015-10-20T12:09:19.514",
      "updatedAt": "2015-10-20T12:09:19.514",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "b6dOUjAarHD",
      "value": "213"
    },
    {
      "createdAt": "2015-10-20T12:09:19.626",
      "updatedAt": "2015-10-20T12:09:19.626",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "UwCXONyUtGs",
      "value": "3"
    },
    {
      "createdAt": "2015-10-20T12:09:19.542",
      "updatedAt": "2015-10-20T12:09:19.542",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "fqnXmRYo5Cz",
      "value": "123"
    },
    {
      "createdAt": "2015-10-20T12:09:19.614",
      "updatedAt": "2015-10-20T12:09:19.614",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "Qz3kfeKgLgL",
      "value": "23"
    },
    {
      "createdAt": "2015-10-20T12:09:19.528",
      "updatedAt": "2015-10-20T12:09:19.528",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "W7aC8jLASW8",
      "value": "12"
    },
    {
      "createdAt": "2015-10-20T12:09:19.599",
      "updatedAt": "2015-10-20T12:09:19.599",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HrJmqlBqTFG",
      "value": "3"
    }
  ],
  "notes": []
}
```

### Enrollments (`GET /api/tracker/enrollments`) { #enrollments-get-apitrackerenrollments } 

Two endpoints are dedicated to enrollments:

- `GET /api/tracker/enrollments`
    - retrieves enrollments matching given criteria
- `GET /api/tracker/enrollments/{id}`
    - retrieves an enrollment given the provided id

#### Enrollment Collection endpoint `GET /api/tracker/enrollments` { #enrollment-collection-endpoint-get-apitrackerenrollments } 

Returns a list of events based on filters.

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`orgUnit`|`String`|`uid`| Identifier of organisation unit|
|`ouMode` see [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`String`| `SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL| Org unit selection mode| 
|`program`|`String`|`uid`| Identifier of program|
|`programStatus`|`enum`| `ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`| Program Status |
|`followUp`|`boolean`| `true`&#124;`false` | 跟踪给定程序的实例状态。可以是 `true`&#124;`false` 或省略。|
|`updatedAfter`|`DateTime`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Only enrollments updated after this date|
|`updatedWithin`|`Duration`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only enrollments updated since given duration |
|`enrolledAfter`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|  Only enrollments newer than this date|
|`enrolledBefore`|`DateTime`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only enrollments older than this date|
|`trackedEntityType`|`String`|`uid`| Identifier of tracked entity type|
|`trackedEntity`|`String`|`uid`| Identifier of tracked entity instance|
|`enrollment`|`String`|Comma-delimited list of `uid`| Filter the result down to a limited set of IDs by using enrollment=id1;id2.|
|`includeDeleted`|`Boolean`| |  When true, soft deleted events will be included in your query result.|
|`order`|`String`|Supported fields: `assignedUser, assignedUserDisplayName, attributeOptionCombo, completedAt, completedBy, createdAt, createdAtClient, createdBy, deleted, enrolledAt, enrollment, enrollmentStatus, event, followUp, occurredAt, orgUnit, program, programStage, scheduledAt, status, storedBy, trackedEntity, updatedAt, updatedAtClient, updatedBy`.|Comma-delimited list of property name, attribute or data element UID and sort direction pairs in format `propName:sortDirection`.|

The query is case-insensitive. The following rules apply to the query parameters.

- At least one organisation unit must be specified using the `orgUnit`
  参数（一个或多个）或 *ouMode=ALL* 必须指定。

- 只能使用 *program* 和 *trackedEntity* 参数之一
  指定（零或一）。

- If *programStatus* is specified, then *program* must also be
  指定的。

- If *followUp* is specified, then *program* must also be specified.

- If *enrolledAfter* or *enrolledBefore* is specified, then *program* must also be specified.

##### Example requests { #example-requests } 

查询与特定组织单位关联的所有注册
看起来像这样：

    GET /api/tracker/enrollments?orgUnit=DiszpKrYNg8

限制对作为特定活动一部分的注册的响应
程序，您可以包含程序查询
    范围：

    GET /api/tracker/enrollments?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

要将程序注册日期指定为查询的一部分，请执行以下操作：

    GET /api/tracker/enrollments?&orgUnit=O6uvpzGd5pu&program=ur1Edk5Oe2n
      &enrolledAfter=2013-01-01&enrolledBefore=2013-09-01

限制对特定被跟踪实体的注册的响应
您可以包含跟踪实体查询
    范围：

    GET /api/tracker/enrollments?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

To constrain the response to enrollments of a specific tracked entity
you can include a tracked entity instance query parameter, in
In this case, we have restricted it to available enrollments viewable for
current
user:

    GET /api/tracker/enrollments?ouMode=ACCESSIBLE&trackedEntity=tphfdyIiVL6

##### 回应格式 { #response-format } 

The `JSON` response can look like the following.

```json
{
  "instances": [
    {
      "enrollment": "iKaBMOyq7QQ",
      "createdAt": "2017-03-28T12:28:19.812",
      "createdAtClient": "2016-03-28T12:28:19.812",
      "updatedAt": "2017-03-28T12:28:19.817",
      "trackedEntity": "PpqV8ytvW5i",
      "trackedEntityType": "nEenWmSyUEp",
      "program": "ur1Edk5Oe2n",
      "status": "ACTIVE",
      "orgUnit": "NnQpISrLYWZ",
      "orgUnitName": "Govt. Hosp. Bonthe",
      "enrolledAt": "2020-10-23T12:28:19.805",
      "occurredAt": "2020-10-07T12:28:19.805",
      "followUp": false,
      "deleted": false,
      "events": [],
      "relationships": [],
      "attributes": [],
      "notes": []
    }
  ],
  "page": 1,
  "total": 1,
  "pageSize": 5
}
```

#### Enrollments single object endpoint `GET /api/tracker/enrollments/{uid}`

The purpose of this endpoint is to retrieve one Enrollment given its uid.

##### 请求语法 { #request-syntax } 

`GET /api/tracker/enrollment/{uid}`

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`uid`|`String`|`uid`|Return the Enrollment with specified `uid`|
|`fields`|`String`| Any valid field filter (default `*,!relationships,!events,!attributes`) |Include specified sub-objects in the response| 

##### Example requests { #example-requests } 

A query for a Enrollment:

    GET /api/tracker/enrollments/iKaBMOyq7QQ

##### 回应格式 { #response-format } 

```json
{
  "enrollment": "iKaBMOyq7QQ",
  "createdAt": "2017-03-28T12:28:19.812",
  "createdAtClient": "2016-03-28T12:28:19.812",
  "updatedAt": "2017-03-28T12:28:19.817",
  "trackedEntity": "PpqV8ytvW5i",
  "trackedEntityType": "nEenWmSyUEp",
  "program": "ur1Edk5Oe2n",
  "status": "ACTIVE",
  "orgUnit": "NnQpISrLYWZ",
  "orgUnitName": "Govt. Hosp. Bonthe",
  "enrolledAt": "2020-10-23T12:28:19.805",
  "occurredAt": "2020-10-07T12:28:19.805",
  "followUp": false,
  "deleted": false,
  "events": [],
  "relationships": [],
  "attributes": [],
  "notes": []
}
```

### Relationships (`GET /api/tracker/relationships`) { #relationships-get-apitrackerrelationships } 

Relationships are links between two entities in the Tracker.
These entities can be tracked entity instances, enrollments, and events.

The purpose of this endpoint is to retrieve relationships between objects.

Unlike other tracked objects endpoints, relationships only expose one endpoint:

- `GET /api/tracker/relationships?[trackedEntity={trackedEntityUid}|enrollment={enrollmentUid}|event={eventUid}]&fields=[fields]`

#### Request parameters { #request-parameters } 

|Request parameter|类型|Allowed values|描述|
|---|---|---|---|
|`trackedEntity`|`String`|`uid`| Identifier of a Tracked Entity Instance|
|`enrollment`|`String`|`uid`| Identifier of an Enrollment |
|`event`|`String`|`uid`| Identifier of an Event|
|`fields`|`String`| Any valid field filter (default `relationship,relationshipType,from[trackedEntity[trackedEntity],enrollment[enrollment],event[event]],to[trackedEntity[trackedEntity],enrollment[enrollment],event[event]]`) |Include specified sub-objects in the response| 
|`order`|`String`|comma-delimited list of property name and sort direction pairs in format `propName:sortDirection`.|Supported fields: `createdAt`.|
|`includeDeleted`|`Boolean`|`true`&#124;`false`| whether to include soft-deleted elements in your query result|

The following rules apply to the query parameters.

- only one parameter among `trackedEntity`, `enrollment`, `event` can be passed

> **NOTE**
>
> Using tracked entity, Enrollment or Event params, will return any relationship where the trackedEntity, enrollment or
> event is part of the relationship (either from or to). As long as user has access, that is.
>

#### Example response { #example-response } 

```json
{
  "instances": [
    {
      "relationship": "SSfIicJKbh5",
      "relationshipType": "Mv8R4MPcNcX",
      "from": {
        "trackedEntity": {
          "trackedEntity": "neR4cmMY22o"
        }
      },
      "to": {
        "trackedEntity": {
          "trackedEntity": "rEYUGH97Ssd"
        }
      }
    },
    {
      "relationship": "S9kZGYPKk3x",
      "relationshipType": "Mv8R4MPcNcX",
      "from": {
        "trackedEntity": {
          "trackedEntity": "neR4cmMY22o"
        }
      },
      "to": {
        "trackedEntity": {
          "trackedEntity": "k8TU70vWtnP"
        }
      }
    }
  ],
  "page": 1,
  "pageSize": 2
}
```

## Tracker Access Control { #webapi_nti_access_control }

Tracker has a few different concepts in regards to access control, like sharing, organisation unit scopes, ownership, and access levels. The following sections provide a short introduction to the different topics.

### Metadata Sharing { #webapi_nti_metadata_sharing }


Sharing setting is standard DHIS2 functionality that applies to both Tracker and Aggregate metadata/data as well as dashboards and visualization items. At the core of sharing is the ability to define who can see/do what. In general, there are five possible sharing configurations – no access, metadata read, metadata write, data read, and data write. These access configurations can be granted at user and/or user group level (for more flexibility). With a focus on Tracker, the following metadata and their sharing setting is of particular importance: Data Element, Category Option, Program, Program Stage, Tracked Entity Type, Tracked Entity Attribute as well as Tracker related Dashboards and Dashboard Items.

How sharing setting works is straightforward – the settings are enforced during Tracker data import/export processes. To read value, one needs to have data read access. If a user is expected to modify data, he/she needs to have data write access. Similarly, if a user is expected to modify metadata, it is essential to grant metadata write access.

One critical point with Tracker data is the need to have a holistic approach. For example, a user won’t be able to see the Data Element value by having read access to just the Data Element. The user needs to have data read to access the parent Program Stage and Program where this Data Element belongs. It is the same with the category option combination. In Tracker, the Event is related to AttributeOptionCombo, which is made up of a combination of Category Options. Therefore, for a user to read data of an Event, he/she needs to have data read access to all Category Options and corresponding Categories that constitute the AttributeOptionCombo of the Event in question. If a user lacks access to just one Category Option or Category, then the user has no access to the entire Event.

When it comes to accessing Enrollment data, it is essential to have access to the Tracked Entity first. Access to a Tracked Entity is controlled through sharing setting of Program, Tracked Entity Type, and Tracked Entity Attribute. Once Enrollment is accessed, it is possible to access Event data, again depending on Program Stage and Data element sharing setting.

Another vital point to consider is how to map out access to different Program Stages of a Program. Sometimes we could be in a situation where we need to grant access to a specific stage – for example, “Lab Result” – to a specific group of users (Lab Technicians). In this situation, we can provide data write access to "Lab Result" stage, probably data read to one or more stages just in case we want Lab Technicians to read other medical results or no access if we think it not necessary for the Lab Technicians to see data other than lab related.

In summary, DHIS2 has a fine-grained sharing setting that we can use to implement access control mechanisms both at the data and metadata level. These sharing settings can be applied directly at the user level or user group level. How exactly to apply a sharing setting depends on the use-case at hand.

For more detailed information about data sharing, check out [Data sharing](https://docs.dhis2.org/en/use/user-guides/dhis-core-version-master/configuring-the-system/about-sharing-of-objects.html#data-sharing-for-event-based-programs).

### Organisation Unit Scopes { #webapi_nti_ou_scope }

Organisation units are one of the most fundamental objects in DHIS2. They define a universe under which a user is allowed to record and/or read data. There are three types of organisation units that can be assigned to a user. These are data capture, data view, and tracker search. As the name implies, these organisation units define a scope under which a user is allowed to conduct the respective operations.

However, to further fine-tune the scope, DHIS2 Tracker introduces a concept that we call **OrganisationUnitSelectionMode**. Such a mode is often used at the time exporting tracker objects. For example, given that a user has a particular tracker search scope, does it mean that we have to use this scope every time a user tries to search for a tracker, Enrollment, or Event object? Or is the user interested in limiting the searching just to the selected org unit, or the entire capture org unit scope, and so on. 

Users can do the fine-tuning by passing a specific value of ouMode in their API request:

*api/tracker/trackedEntities?orgUnit=UID&ouMode=specific_organisation_unit_selection_mode*

Currently, there are six selection modes available: *SELECTED, CHILDREN, DESCENDANTS, CAPTURE, ACCESSIBLE, and ALL*.

1. **SELECTED**: as the name implies, all operations intended by the requesting API narrow down to the selected organisation unit.
2. **CHILDREN**: under this mode, the organisation unit scope will be constructed using the selected organisation unit and its immediate children. 
3. **DESCENDANTS**: here, the selected organisation unit and everything underneath it, not just the immediate children, constitute the data operation universe.
4. **CAPTURE**: as the name implies, organisation units assigned as the user's data capture constitute the universe. Note that, of the three organisation units that can be assigned to a user data capture is the mandatory one. If a user does not have data view and tracker search organisation units, the system will fall back to data capture. This way, we are always sure that a user has at least one universe.
5. **ACCESSIBLE**: technically, this is the same scope as the user's tracker search organisation units.
6. **ALL**: the name ALL makes perfect sense if we are dealing with a superuser. For super users, this scope means the entire organisation unit available in the system. However, for non-superusers, ALL boils down to ACCESSIBLE organisation units.

It makes little sense to pass these modes at the time of tracker import operations. Because when writing tracker data, each of the objects needs to have a specific organisation unit attached to them. The system will then ensure if each of the mentioned organisation units falls under the CAPTURE scope. If not, the system will simply reject the write operation.

Note that there is 4 type of organisation unit associations relevant for Tracker objects. A TrackedEntity has an organisation unit, commonly referred to as the Registration Organisation unit. Enrollments have an organisation unit associated with them. Events also have an organisation unit associated with them. There is also an Owner organisation unit for a TrackedEntity-Program combination. 

When fetching Tracker objects, depending on the context, the organisation unit scope is applied to one of the above four organisation unit associations. 

For example, when retrieving TrackedEntities without the context of a program, the organisation unit scope is applied to the registration organisation unit of the TrackedEntity. Whereas, when retrieving TrackedEntities, including specific program data, the organisation unit scope is applied to the Owner organisation unit. 

  * **Explain how they relate to ownership - Link to Program Ownership**

### Tracker Program Ownership { #webapi_nti_ownership }

A new concept called Tracker Ownership is introduced from 2.30. This introduces a new organisation unit association for a TrackedEntity - Program combination.
We call this the Owner (or Owning) Organisation unit of a TrackedEntity in
the context of a Program. The Owner organisation unit is used to decide access privileges when reading and writing tracker data related to a program.
This, along with the Program's [Access Level](#webapi_nti_access_level) configuration, decides the access behavior for Program-related data (Enrollments and Events). 
A user can access a TrackedEntity's Program data if the corresponding Owner OrganisationUnit for that TrackedEntity-Program combination falls under the user's organisation unit scope (Search/Capture). For Programs that are configured with access level  *OPEN* or *AUDITED* , the Owner OrganisationUnit has to be in the user's search scope.
For Programs that are configured with access level  *PROTECTED* or *CLOSED* , the Owner OrganisationUnit has to be in the user's capture scope to be able to access the corresponding program data for the specific tracked entity.

#### 跟踪器所有权优先：打破常规 { #webapi_nti_tracker_ownership_override }

It is possible to temporarily override this ownership privilege for a
program that is configured with an access level of *PROTECTED*. Any user
will be able to temporarily gain access to the Program related data if
the user specifies a reason for accessing the TrackedEntity-Program
data. This act of temporarily gaining access is termed as *breaking the
glass*. Currently, temporary access is granted for 3 hours. DHIS2
audits breaking the glass along with the reason specified by the user.
It is not possible to gain temporary access to a program that has been
configured with an access level of *CLOSED*. To break the glass for a
TrackedEntity-Program combination, the following POST request can be used:

    / api / 33 / tracker / ownership / override？trackedEntityInstance = DiszpKrYNg8
      ＆program = eBAyeGv0exc＆reason =耐心+显示+急诊+急诊

#### 跟踪器所有权转移 { #webapi_nti_tracker_ownership_transfer }

It is possible to transfer the ownership of a TrackedEntity-Program
from one organisation unit to another. This will be useful in case of patient
referrals or migrations. Only a user who has Ownership access (or temporary access by breaking the glass) can transfer the ownership. To transfer ownership of a TrackedEntity-Program to another organisation unit, the following PUT request can be used:

    / api / 33 / tracker /所有权/转让？trackedEntityInstance = DiszpKrYNg8
      ＆program = eBAyeGv0exc＆ou = EJNxP3WreNP


### Access Level { #webapi_nti_access_level }

DHIS2 treats Tracker data with an extra level of protection. In addition to the standard feature of metadata and data protection through sharing settings, Tracker data are shielded with additional access level protection mechanisms.  Currently, there are four access levels that can be configured for a Program: Open, Audited, Protected, and Closed.

These access levels are only triggered when users try to interact with program data, namely Enrollments and Events data. The different Access Level configuration for Program is a degree of openness (or closedness) of program data. Note that all other sharing settings are still respected, and the access level is only an additional layer of access control. Here is a short description of the four access levels that can be configured for a Program. 

1. Open: This access level is the least restricted among the access levels. Data inside an OPEN program can be accessed and modified by users if the Owner organisation unit falls under the user's search scope.  With this access level, accessing and modifying data outside the capture scope is possible without any justification or consequence. 
2.  Audited: This is the same as the Open access level. The difference here is that the system will automatically add an audit log entry on the data being accessed by the specific user.
3.  Protected: This access level is slightly more restricted. Data inside a PROTECTED program can only be accessed by users if the Owner organisation unit falls under the user's capture scope. However, a user who only has the Owner organisation unit in the search scope can gain temporary ownership by [breaking the glass](#webapi_nti_tracker_ownership_override). The user has to provide a justification of why they are accessing the data at hand. The system will then put a log of both the justification and access audit and provide temporary access for 3 hours to the user. Note that when breaking the glass, the Owner Organisation Unit remains unchanged, and only the user who has broken the glass gains temporary access. 
4.  Closed: This is the most restricted access level. Data recorded under programs configured with access level CLOSED will not be accessible if the Owner Organisation Unit does not fall within the user's capture scope. It is also not possible to break the glass or gain temporary ownership in this configuration. Note that it is still possible to transfer the ownership to another organisation unit. Only a user who has access to the data can transfer the ownership of a TrackedEntity-Program combination to another Organisation Unit. If ownership is transferred, the Owner Organisation Unit is updated.


# Tracker (deprecated APIs) { #tracker-deprecated-apis } 

> **Note**
>Tracker has been re-implemented in DHIS2 2.36. The new endpoints are documented at
>[Tracker](https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html).
>
>The endpoints described in this document are in maintenance mode and do not receive any new
>features. Important bugs will still be fixed.
>
>* If you plan to use the tracker endpoints use the new version described in
>  [Tracker](https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html)
>* If you are still using the deprecated tracker endpoints in production, please plan to migrate
>  over to the new endpoints. [Migrating to new tracker endpoints](#webapi_tracker_migration) should
>  help you get started. Reach out on the [community of practice](https://community.dhis2.org) if
>  you need further assistance. NOTE: The feature for data sync(importMode=SYNC) is not implemented
>  in the new tracker endpoints, and if you are using this feature you will have to postpone the
>  migration until a new SYNC feature is in place.

## Migrating to new tracker endpoints { #webapi_tracker_migration }

The following sections highlight the important differences between the deprecated endpoints.

* `GET/POST/PUT/DELETE /api/trackedEntityInstance`
* `GET/POST/PUT/DELETE /api/enrollments`
* `GET/POST/PUT/DELETE /api/events`
* `GET/POST/PUT/DELETE /api/relationships`

and the newly introduced endpoints

* `POST /api/tracker`
* `GET  /api/tracker/enrollments`
* `GET  /api/tracker/events`
* `GET  /api/tracker/trackedEntities`
* `GET  /api/tracker/relationships`

### Property names { #webapi_tracker_migration_names }

API property names have changed so they are consistent across all the endpoints. The following table
lists the old and new property names.

|Tracker Object|Previously|Now|
|---|---|---|
|**Attribute**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**DataValue**|`created`<br>`lastUpdated`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`|`createdAt`<br>`updatedAt`<br>`createdBy`<br>`updatedBy`|
|**Enrollment**|`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`trackedEntityInstance`<br>`enrollmentDate`<br>`incidentDate`<br>`completedDate`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`|`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`trackedEntity`<br>`enrolledAt`<br>`occurredAt`<br>`completedAt`<br>`createdBy`<br>`updatedBy`|
|**Event**|`trackedEntityInstance`<br>`eventDate`<br>`dueDate`<br>`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`completedDate`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`<br>`assignedUser`*|`trackedEntity`<br>`occurredAt`<br>`scheduledAt`<br>`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`completedAt`<br>`createdBy`<br>`updatedBy`<br>`assignedUser`*|
|**Note**|`storedDate`<br>`lastUpdatedBy`|`storedAt`<br>`createdBy`|
|**ProgramOwner**|`ownerOrgUnit`<br>`trackedEntityInstance`|`orgUnit`<br>`trackedEntity`|
|**RelationshipItem**|`trackedEntityInstance.trackedEntityInstance`<br>`enrollment.enrollment`<br>`event.event`|`trackedEntity`<br>`enrollment`<br>`event`|
|**Relationship**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**TrackedEntity**|`trackedEntityInstance`<br>`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`|`trackedEntity`<br>`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`createdBy`<br>`updatedBy`|

> **Note**
>
>Property `assignedUser` was a string before and is now an object of the following shape (type `User`):
>```json
>{
>   "assignedUser": {
>     "uid": "ABCDEF12345",
>     "username": "username",
>     "firstName": "John",
>     "surname": "Doe"
>   }
>}
>```

### Tracker import changelog (`POST`) { #tracker-import-changelog-post } 

The previous tracker import endpoints

* `POST/PUT/DELETE /api/trackedEntityInstance`
* `POST/PUT/DELETE /api/enrollments`
* `POST/PUT/DELETE /api/events`
* `POST/PUT/DELETE /api/relationships`

are replaced by the new endpoint

* `POST /api/tracker`

[Tracker
Import](https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html#webapi_nti_import)
describes how to use this new endpoint.

### Tracker export changelog (`GET`) { #tracker-export-changelog-get } 

In addition to the changed names shown in [Property names](#webapi_tracker_migration_names) some
request parameters have been changed as well.

The following tables list the differences in old and new request parameters for `GET` enpoints.

#### Request parameter changes for `GET /api/tracker/enrollments` { #request-parameter-changes-for-get-apitrackerenrollments } 

|Previously|Now|
|---|---|
|`ou`|`orgUnit`|
|`lastUpdated`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedWithin`|
|`programStartDate`<br>`programEndDate`|`enrolledAfter`<br>`enrolledBefore`|
|`trackedEntityInstance`|`trackedEntity`|

#### Request parameter changes for `GET /api/tracker/events` { #request-parameter-changes-for-get-apitrackerevents } 

|Previously|Now|
|---|---|
|`trackedEntityInstance`|`trackedEntity`|
|`startDate`<br>`endDate`|`occurredAfter`<br>`occurredBefore`|
|`dueDateStart`<br>`dueDateEnd`|`scheduledAfter`<br>`scheduledBefore`|
|`lastUpdated`|Removed - obsolete, see: <br><ul><li>`updatedAfter`</li><li>`updatedBefore`</li></ul>|
|`lastUpdatedStartDate`<br>`lastUpdateEndDate`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedBefore`<br>`updatedWithin`|

#### Request parameter changes for `GET /api/tracker/trackedEntities` { #request-parameter-changes-for-get-apitrackertrackedentities } 

|Previously|Now|
|---|---|
|`trackedEntityInstance`|`trackedEntity`|
|`ou`|`orgUnit`|
|`programStartDate`<br>`programEndDate`|Removed - obsolete, see <br><ul><li>`enrollmentEnrolledAfter`</li><li>`enrollmentEnrolledBefore`</li></ul>|
|`programEnrollmentStartDate`<br>`programEnrollmentEndDate`|`enrollmentEnrolledAfter`<br>`enrollmentEnrolledBefore`|
|`programIncidentStartDate`<br>`programIncidentEndDate`|`enrollmentOccurredAfter`<br>`enrollmentOccurredBefore`|
|`eventStartDate`<br>`eventEndDate`|`eventOccurredAfter`<br>`eventOccurredBefore`|
|`lastUpdatedStartDate`<br>`lastUpdateEndDate`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedBefore`<br>`updatedWithin`|

## 跟踪器Web API { #webapi_tracker_api }

Tracker Web API consists of 3 endpoints that have full CRUD (create,
read, update, delete) support. The 3 endpoints are
`/api/trackedEntityInstances`, `/api/enrollments` and
`/api/events` and they are responsible for tracked entity instance,
enrollment and event items.

### 跟踪实体实例管理 { #webapi_tracked_entity_instance_management }

跟踪的实体实例在API中具有完整的CRUD支持。一起
使用API进行注册，需要使用以下大部分操作
支持跟踪的实体实例和程序。

    / api / 33 / trackedEntityInstances

#### 创建一个新的跟踪实体实例 { #webapi_creating_tei }

要在系统中创建新人员，您将使用
* trackedEntityInstances *资源。模板有效负载如下所示：

```json
{
  "trackedEntity": "tracked-entity-id",
  "orgUnit": "org-unit-id",
  "geometry": "<Geo JSON>",
  "attributes": [{
    "attribute": "attribute-id",
    "value": "attribute-value"
  }]
}
```

字段“ geometry”接受一个GeoJson对象，其中
GeoJson必须匹配TrackedEntityType的featureType
定义。一个示例GeoJson对象如下所示：

```json
{
  "type": "Point",
  "coordinates": [1, 1]
}
```

“坐标”字段在2.29中引入，并接受一个坐标
或多边形作为值。

For getting the IDs for `relationship` and `attributes` you can have a look
at the respective resources `relationshipTypes`, `trackedEntityAttributes`.
To create a tracked entity instance you must use the HTTP *POST* method. 
You can post the payload the following URL:

    / api / trackedEntityInstances

例如，让我们创建一个人员跟踪实体的新实例，然后
指定其名字和姓氏属性：

```json
{
  "trackedEntity": "nEenWmSyUEp",
  "orgUnit": "DiszpKrYNg8",
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "value": "Joe"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "value": "Smith"
    }
  ]
}
```

要将其推送到服务器，您可以使用cURL命令，如下所示：

```bash
curl -d @tei.json "https://play.dhis2.org/demo/api/trackedEntityInstances" -X POST
  -H "Content-Type: application/json" -u admin:district
```

要在一个请求中创建多个实例，您可以将有效负载包装在
像这样的外部数组并 POST 到与上面相同的资源：[]()

```json
{
  "trackedEntityInstances": [
    {
      "trackedEntity": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": "Joe"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "value": "Smith"
        }
      ]
    },
    {
      "trackedEntity": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": "Jennifer"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "value": "Johnson"
        }
      ]
    }
  ]
}
```

系统不允许创建跟踪实体实例
（以及注册和事件）具有已在
系统。这意味着不能重复使用 UID。

#### 更新跟踪的实体实例 { #webapi_updating_tei }

为了更新被跟踪的实体实例，有效载荷等于
上一节。不同之处在于您必须使用 HTTP *PUT*
发送有效负载时请求的方法。您还需要
将人员标识符附加到 *trackedEntityInstances* 资源中
像这样的 URL，其中 `<tracked-entity-instance-identifier>` 应该
被跟踪实体实例的标识符替换：

    / api / trackedEntityInstances / <tracked-entity-instance-id>

有效载荷必须包含所有，甚至未修改的属性和
关系。之前和之前存在的属性或关系
不再存在于当前有效载荷中，将从中删除
系统。这意味着如果属性/关系在
当前有效负载，所有现有的属性/关系都将被删除
从系统。从 2.31 开始，可以忽略空
当前有效负载中的属性/关系。一个请求参数
`ignoreEmptyCollection` 设置为 `true` 可以在你不这样做的情况下使用
希望发送任何属性/关系，也不想要它们
要从系统中删除。

不允许更新已删除的跟踪实体实例。
此外，不允许通过以下方式将跟踪的实体实例标记为已删除
更新请求。相同的规则适用于注册和活动。

#### 删除跟踪的实体实例 { #webapi_deleting_tei }

为了删除跟踪的实体实例，向 URL 发出请求
使用 *DELETE* 标识被跟踪的实体实例
方法。 URL 等于上面用于更新的 URL。

#### 创建并注册跟踪的实体实例 { #webapi_create_enroll_tei }

也可以创建（和更新）一个被跟踪的实体
实例，同时注册一个程序。

```json
{
  "trackedEntity": "tracked-entity-id",
  "orgUnit": "org-unit-id",
  "attributes": [{
    "attribute": "attribute-id",
    "value": "attribute-value"
  }],
  "enrollments": [{
    "orgUnit": "org-unit-id",
    "program": "program-id",
    "enrollmentDate": "2013-09-17",
    "incidentDate": "2013-09-17"
   }, {
    "orgUnit": "org-unit-id",
    "program": "program-id",
    "enrollmentDate": "2013-09-17",
    "incidentDate": "2013-09-17"
   }]
}
```

您可以像通常在创建或
更新一个新的跟踪实体实例。

```bash
curl -X POST -d @tei.json -H "Content-Type: application/json"
  -u user:pass "http://server/api/33/trackedEntityInstances"
```

#### 有效负载的完整示例包括：跟踪的实体实例，注册和事件 { #webapi_create_enroll_tei_create_event }

也可以创建（和更新）一个被跟踪的实体实例，在
同时注册一个程序并创建一个事件。

```json
{
  "trackedEntityType": "nEenWmSyUEp",
  "orgUnit": "DiszpKrYNg8",
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "value": "Joe"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "value": "Rufus"
    },
    {
     "attribute":"cejWyOfXge6",
     "value":"Male"
    }
  ],
  "enrollments":[
    {
      "orgUnit":"DiszpKrYNg8",
      "program":"ur1Edk5Oe2n",
      "enrollmentDate":"2017-09-15",
      "incidentDate":"2017-09-15",
      "events":[
        {
          "program":"ur1Edk5Oe2n",
          "orgUnit":"DiszpKrYNg8",
          "eventDate":"2017-10-17",
          "status":"COMPLETED",
          "storedBy":"admin",
          "programStage":"EPEcjy3FWmI",
          "coordinate": {
            "latitude":"59.8",
            "longitude":"10.9"
          },
          "dataValues": [
            {
              "dataElement":"qrur9Dvnyt5",
              "value":"22"
            },
            {
              "dataElement":"oZg33kd9taw",
              "value":"Male"
            }
         ]
      },
      {
         "program":"ur1Edk5Oe2n",
         "orgUnit":"DiszpKrYNg8",
         "eventDate":"2017-10-17",
         "status":"COMPLETED",
         "storedBy":"admin",
         "programStage":"EPEcjy3FWmI",
         "coordinate": {
           "latitude":"59.8",
           "longitude":"10.9"
         },
         "dataValues":[
           {
             "dataElement":"qrur9Dvnyt5",
             "value":"26"
           },
           {
             "dataElement":"oZg33kd9taw",
             "value":"Female"
           }
         ]
       }
     ]
    }
  ]  
}
```

您可以像通常在创建或
更新一个新的跟踪实体实例。

```bash
curl -X POST -d @tei.json -H "Content-Type: application/json"
  -u user:pass "http://server/api/33/trackedEntityInstances"
```

#### 生成的跟踪实体实例属性 { #webapi_generate_tei_attributes }

使用自动生成的跟踪实体实例属性
唯一值具有应用程序使用的三个端点。端点
都用于生成和保留值。

在 2.29 中，我们引入了 TextPattern 来定义和生成这些
模式。所有现有模式都将转换为有效的 TextPattern
升级到 2.29 时。

> **注意**
>
> 自 2.29 起，所有这些端点都将要求您包括任何
> `requiredValues` 端点报告的变量被列为
> 需要。现有模式，仅由`#` 组成，将被升级
> 到新的 TextPattern 语法`RANDOM(<old-pattern>)`。随机
> TextPattern 的段不是必需的变量，所以这个
> 对于 2.29 之前定义的模式，端点将像以前一样工作。

##### 寻找所需的值 { #finding-required-values } 

TextPattern 可以包含根据不同的变量而变化的变量
因素。其中一些因素对服务器来说是未知的，因此
这些变量的值必须在生成和
保留值。

此端点将返回必需值和可选值的映射，即
服务器将在生成新值时注入 TextPattern。
必须为生成提供必需的变量，但可选
仅当您知道自己在做什么时才应提供变量。

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/requiredValues

```json
{
  "REQUIRED": [
    "ORG_UNIT_CODE"
  ],
  "OPTIONAL": [
    "RANDOM"
  ]
}
```

##### 产生价值终点 { #webapi_generate_values }

在线 Web 应用程序和其他希望产生价值的客户
将立即使用可以使用简单的生成端点。这
端点将生成一个值，该值保证在
世代时间。该值也保证不被保留。作为
2.29，此端点还将保留生成的值 3 天。

如果您的 TextPattern 包含必需的值，您可以将它们作为
参数如下例：

过期时间也可以在生成时被覆盖，通过
将 `?expiration= <number-of-days> ` 添加到请求中。

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generate?ORG_UNIT_CODE=OSLO

```json
{
  "ownerObject": "TRACKEDENTITYATTRIBUTE",
  "ownerUid": "Gs1ICEQTPlG",
  "key": "RANDOM(X)-OSL",
  "value": "C-OSL",
  "created": "2018-03-02T12:01:36.680",
  "expiryDate": "2018-03-05T12:01:36.678"
}
```

##### 产生并保留价值终点 { #webapi_generate_reserve_values }

生成和保留端点由需要的离线客户端使用
能够注册具有唯一 ID 的跟踪实体。他们会
保留一些唯一的 ID，此设备将在以下情况下使用
注册新的跟踪实体实例。端点被称为
检索多个跟踪的实体实例保留值。一个
可选参数 numberToReserve 指定要生成多少个 id
（默认值为 1）。

如果您的 TextPattern 包含必需的值，您可以将它们作为
参数如下例：

与 /generate 端点类似，该端点也可以指定
过期时间同理。通过添加`?expiration=<number-of-days>`
您可以覆盖默认的 60 天。

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generateAndReserve?numberToReserve=3&ORG_UNIT_CODE=OSLO

```json
[
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "B-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "Q-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "S-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  }
]
```

##### 保留值 { #reserved-values } 

目前无法通过 api 访问保留值，但是，它们
由`generate` 和`generateAndReserve` 端点返回。这
下表解释了保留值对象的属性：

#####



Table: Reserved values

| Property | 描述 |
|---|---|
| ownerObject | The metadata type referenced when generating and reserving the value. Currently only TRACKEDENTITYATTRIBUTE is supported. |
| ownerUid | The uid of the metadata object referenced when generating and reserving the value. |
| key | A partially generated value where generated segments are not yet added. |
| 价值 | The fully resolved value reserved. This is the value you send to the server when storing data. |
| created | The timestamp when the reservation was made |
| expiryDate | The timestamp when the reservation will no longer be reserved |

过期的预订每天都会被删除。如果模式发生变化，则值
存储数据时将接受已经保留的数据，即使
它们与新模式不匹配，只要预订没有
已到期。

#### 图片属性 { #image-attributes } 

处理图像属性很像处理文件数据
值。具有图像值类型的属性的值是
关联的文件资源。一个 GET 请求
`/api/trackedEntityInstances/ <entityId> / <attributeId> /image`
端点将返回实际图像。可选的高度和宽度
参数可用于指定图像的尺寸。

```bash
curl "http://server/api/33/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/image?height=200&width=200"
  > image.jpg
```

The API also supports a *dimension* parameter. It can take three possible values (please note capital letters): `SMALL` (254x254), `MEDIUM` (512x512), `LARGE` (1024x1024) or `ORIGINAL`. Image type attributes will be stored in pre-generated sizes
and will be furnished upon request based on the value of the `dimension` parameter.

```bash
curl "http://server/api/33/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/image?dimension=MEDIUM"
```

#### File attributes { #file-attributes } 

Working with file attributes is a lot like working with image data
values. The value of an attribute with the file value type is the id of
the associated file resource. A GET request to the
`/api/trackedEntityInstances/<entityId>/<attributeId>/file`
endpoint will return the actual file content.

```bash
curl "http://server/api/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/file
```

#### 跟踪实体实例查询 { #webapi_tracked_entity_instance_query }

要查询跟踪的实体实例，您可以与
`/api/trackedEntityInstances` 资源。

    / api / 33 / trackedEntityInstances

##### 请求语法 { #webapi_tei_query_request_syntax }



Table: Tracked entity instances query parameters

| 查询参数 | 描述 |
|---|---|
| filter | 用作查询过滤器的属性。参数可以重复任意次。过滤器可以应用于格式为  <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>].维度过滤器值不区分大小写，可以与运算符一起重复任意次数。运算符可以是 EQ &#124; GT &#124;通用电气&#124; LT &#124;乐&#124; NE &#124;喜欢 &#124;在。 |
| 欧 | Organisation unit identifiers, separated by ";". |
| ouMode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; CAPTURE &#124; ALL. Default is SELECTED, which refers to the selected selected organisation units only. See table below for explanations. |
| program | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| 跟进 | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| trackedEntity | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| page | The page number. Default page is 1. |
| pageSize | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| lastUpdatedStartDate | Filter for teis which were updated after this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedEndDate | Filter for teis which were updated up until this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedDuration | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). Cannot be used together with *lastUpdatedStartDate* and/or *lastUpdatedEndDate*. |
| assignedUserMode | Restricts result to tei with events assigned based on the assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. See table below "Assigned user modes" for explanations. |
| assignedUser | Filter the result down to a limited set of teis with events that are assigned to the given user IDs by using *assignedUser=id1;id2*.This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |
| trackedEntityInstance | Filter the result down to a limited set of teis using explicit uids of the tracked entity instances by using *trackedEntityInstance=id1;id2*. This parameter will at the very least create the outer boundary of the results, forming the list of all teis using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary. |
| includeDeleted | Indicates whether to include soft deleted teis or not. It is false by default. |
| potentialDuplicate | Filter the result based on the fact that a TEI is a Potential Duplicate. true: return TEIs flagged as Potential Duplicates. false: return TEIs NOT flagged as Potential Duplicates. If omitted, we don't check whether a TEI is a Potential Duplicate or not.|

可用的组织单元选择模式在
下表。



Table: Organisation unit selection modes

| Mode | 描述 |
|---|---|
| SELECTED | Organisation units defined in the request. |
| CHILDREN | The selected organisation units and the immediate children, i.e. the organisation units at the level below. |
| DESCENDANTS | The selected organisation units and all children, i.e. all organisation units in the sub-hierarchy. |
| ACCESSIBLE | The data view organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| CAPTURE | The data capture organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. |
| 全部 | All organisation units in the system. Requires the ALL authority. |

The available assigned user modes are explained in the following table.



Table: Assigned user modes

| Mode | 描述 |
|---|---|
| CURRENT | Includes events assigned to the current logged in user. |
| PROVIDED | Includes events assigned to the user provided in the request. |
| NONE | Includes unassigned events only. |
| ANY | Includes all assigned events, doesn't matter who are they assigned to as long as they assigned to someone. |

查询不区分大小写。以下规则适用于查询
参数。

  - 必须使用 *ou* 指定至少一个组织单位
    参数（一个或多个）或 *ouMode=ALL* 必须指定。

  - 只能使用 *program* 和 *trackedEntity* 参数之一
    指定（零或一）。

  - 如果指定了 *programStatus* 那么 *program* 也必须是
    指定的。

  - 如果指定了 *followUp*，则还必须指定 *program*。

  - 如果指定了 *programStartDate* 或 *programEndDate*，则
    *程序* 也必须指定。

  - 过滤器项目只能指定一次。

查询与特定组织单位关联的所有实例
看起来像这样：

    /api/33/trackedEntityInstances.json?ou=DiszpKrYNg8

使用一个带有过滤器的属性和一个属性来查询实例
没有过滤器的属性，一个组织单位使用
后代组织单位查询方式：

    /api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A
      ＆filter = AMpUYgxuCaE＆ou = DiszpKrYNg8; yMCshbaVExv

对响应中包含一个属性的实例的查询
并且一个属性被用作
    筛选：

    /api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A
      ＆filter = AMpUYgxuCaE：LIKE：Road＆ou = DiszpKrYNg8

为过滤器指定了多个操作数和过滤器的查询
物品：

    api / 33 / trackedEntityInstances.json？ou = DiszpKrYNg8＆program = ur1Edk5Oe2n
      ＆filter = lw1SqmMlnfh：GT：150：LT：190

要在 *IN* 过滤器中使用多个值查询属性：

    api / 33 / trackedEntityInstances.json？ou = DiszpKrYNg8
      ＆filter = dv3nChNSIxy：IN：Scott; Jimmy; Santiago

限制对属于特定事件一部分的实例的响应
program 你可以包含一个 program 查询参数：

    api / 33 / trackedEntityInstances.json？filter = zHXD5Ve1Efw：EQ：A＆ou = O6uvpzGd5pu
      ＆ouMode = DESCENDANTS＆program = ur1Edk5Oe2n

要将程序注册日期指定为查询的一部分，请执行以下操作：

    api / 33 / trackedEntityInstances.json？filter = zHXD5Ve1Efw：EQ：A＆ou = O6uvpzGd5pu
      ＆program = ur1Edk5Oe2n＆programStartDate = 2013-01-01＆programEndDate = 2013-09-01

要限制对特定跟踪实体实例的响应，您
可以包含跟踪实体查询参数：

    api / 33 / trackedEntityInstances.json？filter = zHXD5Ve1Efw：EQ：A＆ou = O6uvpzGd5pu
      ＆ouMode = DESCENDANTS＆trackedEntity = cyl5vuJ5ETQ

默认情况下，实例以大小为 50 的页面返回，以更改
您可以使用 page 和 pageSize 查询参数：

    api / 33 / trackedEntityInstances.json？filter = zHXD5Ve1Efw：EQ：A＆ou = O6uvpzGd5pu
      ＆ouMode = DESCENDANTS＆page = 2＆pageSize = 3

您可以使用一系列运算符进行过滤：



Table: Filter operators

| Operator | 描述 |
|---|---|
| EQ | Equal to |
| GT | Greater than |
| GE | Greater than or equal to |
| LT | Less than |
| LE | Less than or equal to |
| NE | Not equal to |
| LIKE | Free text match (Contains) |
| SW | Starts with |
| EW | Ends with |
| IN | Equal to one of multiple values separated by ";" |

##### 回应格式 { #webapi_tei_query_response_format }

此资源支持 JSON、JSONP、XLS 和 CSV 资源
表示。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xml（应用程序/ xml）

JSON/XML 中的响应采用对象格式，看起来像
下列的。请注意，支持字段过滤，所以如果你想
一个完整的视图，您可能希望将 `fields=*` 添加到查询中：

```json
{
  "trackedEntityInstances": [
    {
      "lastUpdated": "2014-03-28 12:27:52.399",
      "trackedEntity": "cyl5vuJ5ETQ",
      "created": "2014-03-26 15:40:19.997",
      "orgUnit": "ueuQlqb8ccl",
      "trackedEntityInstance": "tphfdyIiVL6",
      "relationships": [],
      "attributes": [
        {
          "displayName": "Address",
          "attribute": "AMpUYgxuCaE",
          "type": "string",
          "value": "2033 Akasia St"
        },
        {
          "displayName": "TB number",
          "attribute": "ruQQnf6rswq",
          "type": "string",
          "value": "1Z 989 408 56 9356 521 9"
        },
        {
          "displayName": "Weight in kg",
          "attribute": "OvY4VVhSDeJ",
          "type": "number",
          "value": "68.1"
        },
        {
          "displayName": "Email",
          "attribute": "NDXw0cluzSw",
          "type": "string",
          "value": "LiyaEfrem@armyspy.com"
        },
        {
          "displayName": "Gender",
          "attribute": "cejWyOfXge6",
          "type": "optionSet",
          "value": "Female"
        },
        {
          "displayName": "Phone number",
          "attribute": "P2cwLGskgxn",
          "type": "phoneNumber",
          "value": "085 813 9447"
        },
        {
          "displayName": "First name",
          "attribute": "dv3nChNSIxy",
          "type": "string",
          "value": "Liya"
        },
        {
          "displayName": "Last name",
          "attribute": "hwlRTFIFSUq",
          "type": "string",
          "value": "Efrem"
        },
        {
          "code": "Height in cm",
          "displayName": "Height in cm",
          "attribute": "lw1SqmMlnfh",
          "type": "number",
          "value": "164"
        },
        {
          "code": "City",
          "displayName": "City",
          "attribute": "VUvgVao8Y5z",
          "type": "string",
          "value": "Kranskop"
        },
        {
          "code": "State",
          "displayName": "State",
          "attribute": "GUOBQt5K2WI",
          "type": "number",
          "value": "KwaZulu-Natal"
        },
        {
          "code": "Zip code",
          "displayName": "Zip code",
          "attribute": "n9nUvfpTsxQ",
          "type": "number",
          "value": "3282"
        },
        {
          "code": "National identifier",
          "displayName": "National identifier",
          "attribute": "AuPLng5hLbE",
          "type": "string",
          "value": "465700042"
        },
        {
          "code": "Blood type",
          "displayName": "Blood type",
          "attribute": "H9IlTX2X6SL",
          "type": "string",
          "value": "B-"
        },
        {
          "code": "Latitude",
          "displayName": "Latitude",
          "attribute": "Qo571yj6Zcn",
          "type": "string",
          "value": "-30.659626"
        },
        {
          "code": "Longitude",
          "displayName": "Longitude",
          "attribute": "RG7uGl4w5Jq",
          "type": "string",
          "value": "26.916172"
        }
      ]
    }
  ]
}
```

#### 跟踪实体实例网格查询 { #webapi_tracked_entity_instance_grid_query }

要查询跟踪的实体实例，您可以与
*/api/trackedEntityInstances/grid* 资源。有两种类型
查询：其中一个 *query* 查询参数和可选的 *attribute*
参数已定义，其中 *attribute* 和 *filter*
定义了参数。此端点使用更紧凑的“网格”格式，
并且是上一节中查询的替代方法。

    / api / 33 / trackedEntityInstances / query

##### 请求语法 { #webapi_tei_grid_query_request_syntax }



Table: Tracked entity instances query parameters

| 查询参数 | 描述 |
|---|---|
| query | Query string. Attribute query parameter can be used to define which attributes to include in the response. If no attributes but a program is defined, the attributes from the program will be used. If no program is defined, all attributes will be used. There are two formats. The first is a plan query string. The second is on the format <operator\>:<query\>. Operators can be EQ &#124; LIKE. EQ implies exact matches on words, LIKE implies partial matches on words. The query will be split on space, where each word will form a logical AND query. |
| attribute | 要包含在响应中的属性。也可以用作查询的过滤器。参数可以重复任意次。过滤器可以应用于格式为  <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>].维度过滤器值不区分大小写，可以与运算符一起重复任意次数。运算符可以是 EQ &#124; GT &#124;通用电气&#124; LT &#124;乐&#124; NE &#124;喜欢 &#124;在。可以省略过滤器，以便在没有任何约束的情况下简单地在响应中包含属性。 |
| filter | 用作查询过滤器的属性。参数可以重复任意次。过滤器可以应用于格式为  <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>].维度过滤器值不区分大小写，可以与运算符一起重复任意次数。运算符可以是 EQ &#124; GT &#124;通用电气&#124; LT &#124;乐&#124; NE &#124;喜欢 &#124;在。 |
| 欧 | Organisation unit identifiers, separated by ";". |
| ouMode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; ALL. Default is SELECTED, which refers to the selected organisation units only. See table below for explanations. |
| program | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| 跟进 | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| trackedEntity | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| eventStatus | Status of any event associated with the given program and the tracked entity instance. Can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED. |
| eventStartDate | Start date of event associated with the given program and event status. |
| eventEndDate | End date of event associated with the given program and event status. |
| programStage | The programStage for which the event related filters should be applied to. If not provided all stages will be considered. |
| skipMeta | Indicates whether meta data for the response should be included. |
| page | The page number. Default page is 1. |
| pageSize | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| assignedUserMode | Restricts result to tei with events assigned based on the assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser | Filter the result down to a limited set of teis with events that are assigned to the given user IDs by using *assignedUser=id1;id2*.This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |
| trackedEntityInstance | Filter the result down to a limited set of teis using explicit uids of the tracked entity instances by using *trackedEntityInstance=id1;id2*. This parameter will at the very least create the outer boundary of the results, forming the list of all teis using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary. |
| potentialDuplicate | Filter the result based on the fact that a TEI is a Potential Duplicate. true: return TEIs flagged as Potential Duplicates. false: return TEIs NOT flagged as Potential Duplicates. If omitted, we don't check whether a TEI is a Potential Duplicate or not.|

可用的组织单元选择模式在
下表。



Table: Organisation unit selection modes

| Mode | 描述 |
|---|---|
| SELECTED | Organisation units defined in the request. |
| CHILDREN | Immediate children, i.e. only the first level below, of the organisation units defined in the request. |
| DESCENDANTS | All children, i.e. at only levels below, e.g. including children of children, of the organisation units defined in the request. |
| ACCESSIBLE | All descendants of the data view organisation units associated with the current user. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| CAPTURE | The data capture organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. |
| 全部 | All organisation units in the system. Requires authority. |

请注意，您可以使用过滤器指定“属性”或直接使用“过滤器”参数来限制
实例返回。

某些规则适用于返回的属性。

  - 如果在没有任何属性或程序的情况下指定“查询”，则所有属性
    标记为“在没有程序的列表中显示”包含在响应中。

  - 如果指定了程序，则链接到该程序的所有属性都将
    包含在响应中。

  - 如果指定了被跟踪实体类型，则所有被跟踪实体类型属性
    将包含在响应中。

您可以使用由空格分隔的单词来指定查询 - 即
情况系统会独立查询每个单词并返回
每个词都包含在任何属性中的记录。一个查询项可以
一次指定为属性，一次指定为过滤器（如果需要）。这
查询不区分大小写。以下规则适用于查询
参数。

  - 必须使用 *ou* 指定至少一个组织单位
    参数（一个或多个）或 *ouMode=ALL* 必须指定。

  - 只能使用 *program* 和 *trackedEntity* 参数之一
    指定（零或一）。

  - 如果指定了 *programStatus* 那么 *program* 也必须是
    指定的。

  - 如果指定了 *followUp*，则还必须指定 *program*。

  - 如果指定了 *programStartDate* 或 *programEndDate*，则
    *程序* 也必须指定。

  - 如果指定了 *eventStatus*，则 *eventStartDate* 和
    *eventEndDate* 也必须指定。

  - 不能与过滤器一起指定查询。

  - 属性项目只能指定一次。

  - 过滤器项目只能指定一次。

查询与特定组织单位关联的所有实例
看起来像这样：

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8

查询特定值和组织单位的所有属性，
使用精确的单词匹配：

    /api/33/trackedEntityInstances/query.json?query=scott&ou=DiszpKrYNg8

使用部分词查询特定值的所有属性
比赛：

    /api/33/trackedEntityInstances/query.json?query=LIKE:scott&ou=DiszpKrYNg8

您可以查询由 URL 字符分隔的多个单词
空间为 %20，将对每个空间使用逻辑 AND 查询
    单词：

    /api/33/trackedEntityInstances/query.json?query=isabel%20may&ou=DiszpKrYNg8

指定要包含在响应中的属性的查询：

    /api/33/trackedEntityInstances/query.json?query=isabel
      ＆attribute = dv3nChNSIxy＆attribute = AMpUYgxuCaE＆ou = DiszpKrYNg8

使用一个带有过滤器的属性和一个属性来查询实例
没有过滤器的属性，一个组织单位使用
后代组织单位查询方式：

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      ＆attribute = AMpUYgxuCaE＆ou = DiszpKrYNg8; yMCshbaVExv

对响应中包含一个属性的实例的查询
并且一个属性被用作
    筛选：

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      ＆filter = AMpUYgxuCaE：LIKE：Road＆ou = DiszpKrYNg8

为过滤器指定了多个操作数和过滤器的查询
物品：

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8&program=ur1Edk5Oe2n
      ＆filter = lw1SqmMlnfh：GT：150：LT：190

使用 IN 中的多个值查询属性
    筛选：

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8
      ＆attribute = dv3nChNSIxy：IN：Scott; Jimmy; Santiago

限制对属于特定事件一部分的实例的响应
program 你可以包含一个 program 查询参数：

    /api/33/trackedEntityInstances/query.json?filter=zHXD5Ve1Efw:EQ:A
      ＆ou = O6uvpzGd5pu＆ouMode = DESCENDANTS＆program = ur1Edk5Oe2n

要将程序注册日期指定为查询的一部分，请执行以下操作：

    /api/33/trackedEntityInstances/query.json?filter=zHXD5Ve1Efw:EQ:A
      ＆ou = O6uvpzGd5pu＆program = ur1Edk5Oe2n＆programStartDate = 2013-01-01
      ＆programEndDate = 2013-09-01

要限制对特定跟踪实体实例的响应，您
可以包含跟踪实体查询参数：

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      ＆ou = O6uvpzGd5pu＆ouMode = DESCENDANTS＆trackedEntity = cyl5vuJ5ETQ

默认情况下，实例以大小为 50 的页面返回，以更改
您可以使用 page 和 pageSize 查询参数：

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      ＆ou = O6uvpzGd5pu＆ouMode = DESCENDANTS＆page = 2＆pageSize = 3

查询具有给定状态的事件的实例
给定的时间跨度：

    /api/33/trackedEntityInstances/query.json?ou=O6uvpzGd5pu
      &program=ur1Edk5Oe2n&eventStatus=COMPLETED
      &eventStartDate=2014-01-01&eventEndDate=2014-09-01

您可以使用一系列运算符进行过滤：



Table: Filter operators

| Operator | 描述 |
|---|---|
| EQ | Equal to |
| GT | Greater than |
| GE | Greater than or equal to |
| LT | Less than |
| LE | Less than or equal to |
| NE | Not equal to |
| LIKE | Free text match (Contains) |
| SW | Starts with |
| EW | Ends with |
| IN | Equal to one of multiple values separated by ";" |

##### 回应格式 { #webapi_tei_grid_query_response_format }

此资源支持 JSON、JSONP、XLS 和 CSV 资源
表示。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xml（应用程序/ xml）

  - csv（应用程序/ csv）

  - xls（application / vnd.ms-excel）

JSON 中的响应采用表格格式，看起来像
下列的。 *headers* 部分描述了每列的内容。
实例、创建、上次更新、组织单位和跟踪实体列
总是存在。以下列对应属性
在查询中指定。 *rows* 部分包含一行
实例。

```json
{
  "headers": [{
    "name": "instance",
    "column": "Instance",
    "type": "java.lang.String"
  }, {
    "name": "created",
    "column": "Created",
    "type": "java.lang.String"
  }, {
    "name": "lastupdated",
    "column": "Last updated",
    "type": "java.lang.String"
  }, {
    "name": "ou",
    "column": "Org unit",
    "type": "java.lang.String"
  }, {
    "name": "te",
    "column": "Tracked entity",
    "type": "java.lang.String"
  }, {
    "name": "zHXD5Ve1Efw",
    "column": "Date of birth type",
    "type": "java.lang.String"
  }, {
    "name": "AMpUYgxuCaE",
    "column": "Address",
    "type": "java.lang.String"
  }],
  "metaData": {
    "names": {
      "cyl5vuJ5ETQ": "Person"
    }
  },
  "width": 7,
  "height": 7,
  "rows": [
    ["yNCtJ6vhRJu", "2013-09-08 21:40:28.0", "2014-01-09 19:39:32.19", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "21 Kenyatta Road"],
    ["fSofnQR6lAU", "2013-09-08 21:40:28.0", "2014-01-09 19:40:19.62", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "56 Upper Road"],
    ["X5wZwS5lgm2", "2013-09-08 21:40:28.0", "2014-01-09 19:40:31.11", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "56 Main Road"],
    ["pCbogmlIXga", "2013-09-08 21:40:28.0", "2014-01-09 19:40:45.02", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "12 Lower Main Road"],
    ["WnUXrY4XBMM", "2013-09-08 21:40:28.0", "2014-01-09 19:41:06.97", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "13 Main Road"],
    ["xLNXbDs9uDF", "2013-09-08 21:40:28.0", "2014-01-09 19:42:25.66", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "14 Mombasa Road"],
    ["foc5zag6gbE", "2013-09-08 21:40:28.0", "2014-01-09 19:42:36.93", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "15 Upper Hill"]
  ]
}
```

#### 跟踪实体实例过滤器 { #webapi_tei_filters }

To create, read, update and delete tracked entity instance filters you
can interact with the */api/trackedEntityInstanceFilters* resource. Tracked entity instance filters are shareable and follows the same pattern of sharing as any other metadata object. When using the */api/sharing* the type parameter will be *trackedEntityInstanceFilter*.

    / api / 33 / trackedEntityInstanceFilters

##### 创建和更新跟踪的实体实例过滤器定义 { #create-and-update-a-tracked-entity-instance-filter-definition } 

用于创建和更新跟踪实体实例过滤器
系统，您将使用 *trackedEntityInstanceFilters*
资源。跟踪实体实例过滤器定义用于
Tracker Capture 应用程序显示相关的预定义“工作列表”
跟踪器用户界面。



Table: Payload

| Payload values | 描述 | 例 |
|---|---|---|
| 名称 | Name of the filter. Required. ||
| 描述 | A description of the filter. ||
| sortOrder | The sort order of the filter. Used in Tracker Capture to order the filters in the program dashboard. ||
| style | Object containing css style. | ( "color": "blue", "icon": "fa fa-calendar"} |
| program | Object containing the id of the program. Required. | { "id" : "uy2gU8kTjF"} |
| entityQueryCriteria | An object representing various possible filtering values. See *Entity Query Criteria* definition table below.
| eventFilters | A list of eventFilters. See *Event filters* definition table below. | [{"programStage": "eaDH9089uMp", "eventStatus": "OVERDUE", "eventCreatedPeriod": {"periodFrom": -15, "periodTo": 15}}] |

Table: Entity Query Criteria definition

||||
|---|---|---|
| attributeValueFilters | A list of attributeValueFilters. This is used to specify filters for attribute values when listing tracked entity instances | "attributeValueFilters"=[{       "attribute": "abcAttributeUid",       "le": "20",       "ge": "10",       "lt": "20",       "gt": "10",       "in": ["India", "Norway"],       "like": "abc",       "sw": "abc",       "ew": "abc",       "dateFilter": {         "startDate": "2014-05-01",         "endDate": "2019-03-20",         "startBuffer": -5,         "endBuffer": 5,         "period": "LAST_WEEK",         "type": "RELATIVE"       }     }] |
| enrollmentStatus | The TEIs enrollment status. Can be none(any enrollmentstatus) or ACTIVE&#124;COMPLETED&#124;CANCELLED ||
| followup | When this parameter is true, the filter only returns TEIs that have an enrollment with status followup. ||
| organisationUnit | To specify the uid of the organisation unit | "organisationUnit": "a3kGcGDCuk7" |
| ouMode | To specify the OU selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL | "ouMode": "SELECTED" |
| assignedUserMode | To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUsers | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |
| displayColumnOrder | To specify the output ordering of columns | "displayOrderColumns": ["enrollmentDate", "program"] |
| order | To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "orderDimension:direction". Note: Supported orderDimensions are trackedEntity, created, createdAt, createdAtClient, updatedAt, updatedAtClient, enrolledAt, inactive and the tracked entity attributes | "order"="a3kGcGDCuk6:desc" |
| eventStatus | Any valid EventStatus | "eventStatus": "COMPLETED" |
| programStage | To specify a programStage uid to filter on. TEIs will be filtered based on presence of enrollment in the specified program stage.| "programStage"="a3kGcGDCuk6" |
| trackedEntityType | To specify a trackedEntityType filter TEIs on. | "trackedEntityType"="a3kGcGDCuk6" |
| trackedEntityInstances | To specify a list of trackedEntityInstances to use when querying TEIs. | "trackedEntityInstances"=["a3kGcGDCuk6","b4jGcGDCuk7"] |
| enrollmentIncidentDate | DateFilterPeriod object date filtering based on enrollment incident date. | "enrollmentIncidentDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| eventDate | DateFilterPeriod object date filtering based on event date. | "eventDate": {     "startBuffer": -5,     "endBuffer": 5,     "type": "RELATIVE"   } |
| enrollmentCreatedDate | DateFilterPeriod object date filtering based on enrollment created date. | "enrollmentCreatedDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| lastUpdatedDate | DateFilterPeriod object date filtering based on last updated date. | "lastUpdatedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   } |

Table: Event filters definition

||||
|---|---|---|
| programStage | Which programStage the TEI needs an event in to be returned. | "eaDH9089uMp" |
| eventStatus | The events status. Can be none(any event status) or ACTIVE&#124;COMPLETED&#124;SCHEDULE&#124;OVERDUE | ACTIVE |
| eventCreatedPeriod | Period object containing a period in which the event must be created. See *Period* definition below. | { "periodFrom": -15, "periodTo": 15} |
| assignedUserMode | To specify the assigned user selection mode for events. Possible values are CURRENT (events assigned to current user)&#124; PROVIDED (events assigned to users provided in "assignedUsers" list) &#124; NONE (events assigned to no one) &#124; ANY (events assigned to anyone). If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUsers | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |


Table: DateFilterPeriod object definition

||||
|---|---|---|
| type | Specify whether the date period type is ABSOLUTE &#124; RELATIVE | "type" : "RELATIVE" |
| period | Specify if a relative system defined period is to be used. Applicable only when "type" is RELATIVE. (see [Relative Periods](#webapi_date_relative_period_values) for supported relative periods) | "period" : "THIS_WEEK" |
| 开始日期 | Absolute start date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| 结束日期 | Absolute end date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| startBuffer | Relative custom start date. Applicable only when "type" is RELATIVE | "startBuffer":-10 |
| endBuffer | Relative custom end date. Applicable only when "type" is RELATIVE | "startDate":+10 |

Table: Period definition

||||
|---|---|---|
| periodFrom | Number of days from current day. Can be positive or negative integer. | -15 |
| periodTo | Number of days from current day. Must be bigger than periodFrom. Can be positive or negative integer. | 15 |

##### 跟踪实体实例过滤器查询 { #tracked-entity-instance-filters-query } 

要在系统中查询被跟踪实体实例过滤器，您可以
与 */api/trackedEntityInstanceFilters* 资源交互。



Table: Tracked entity instance filters query parameters

| 查询参数 | 描述 |
|---|---|
| program | Program identifier. Restricts filters to the given program. |

### 招生管理 { #webapi_enrollment_management }

注册在 API 中具有完整的 CRUD 支持。与 API 一起
对于跟踪的实体实例，使用所需的大多数操作
支持被跟踪的实体实例和程序。

    / api / 33 /注册

#### 将跟踪的实体实例注册到程序中 { #webapi_enrolling_tei }

要让人员加入计划，您首先需要获得
*trackedEntityInstances* 资源中人员的标识符。
然后，您需要从 *programs* 中获取程序标识符
资源。模板有效负载如下所示：

```json
{
  "trackedEntityInstance": "ZRyCnJ1qUXS",
  "orgUnit": "ImspTQPwCqd",
  "program": "S8uo8AlvYMz",
  "enrollmentDate": "2013-09-17",
  "incidentDate": "2013-09-17"
}
```

此有效负载应在对注册的 *POST* 请求中使用
由以下 URL 标识的资源：

    / api / 33 /注册

The different status of an enrollment are:

* **ACTIVE**: It is used meanwhile when the tracked entity participates on the program.
* **COMPLETED**: It is used when the tracked entity finished its participation on the program.
* **CANCELLED**: "Deactivated" in the web UI. It is used when the tracked entity cancelled its participation on the program.

For cancelling or completing an enrollment, you can make a *PUT*
request to the `enrollments` resource, including the identifier and the
action you want to perform. For cancelling an enrollment for a tracked
entity instance:

    / api / 33 / enrollments / <enrollment-id> /取消

要完成被跟踪实体实例的注册，您可以创建一个
*PUT* 请求到以下 URL：

    / api / 33 / enrollments / <enrollment-id> /已完成

For deleting an enrollment, you can make a *DELETE* request to the
following URL:

    / api / 33 / enrollments / <enrollment-id>

#### 注册实例查询 { #webapi_enrollment_instance_query }

要查询注册，您可以与 */api/enrollments* 交互
资源。

    / api / 33 /注册

##### 请求语法 { #webapi_enrollment_query_request_syntax }



Table: Enrollment query parameters

| 查询参数 | 描述 |
|---|---|
| 欧 | Organisation unit identifiers, separated by ";". |
| ouMode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; CAPTURE &#124; ALL. Default is SELECTED, which refers to the selected organisation units only. See table below for explanations. |
| program | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| 跟进 | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| lastUpdatedDuration | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). |
| trackedEntity | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| trackedEntityInstance | Tracked entity instance identifier. Should not be used together with trackedEntity. |
| page | The page number. Default page is 1. |
| pageSize | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| includeDeleted | Indicates whether to include soft deleted enrollments or not. It is false by default. |

可用的组织单元选择模式在
下表。



Table: Organisation unit selection modes

| Mode | 描述 |
|---|---|
| SELECTED | Organisation units defined in the request (default). |
| CHILDREN | Immediate children, i.e. only the first level below, of the organisation units defined in the request. |
| DESCENDANTS | All children, i.e. at only levels below, e.g. including children of children, of the organisation units defined in the request. |
| ACCESSIBLE | All descendants of the data view organisation units associated with the current user. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| 全部 | All organisation units in the system. Requires authority. |

查询不区分大小写。以下规则适用于查询
参数。

  - 必须使用 *ou* 指定至少一个组织单位
    参数（一个或多个）或 *ouMode=ALL* 必须指定。

  - 只能使用 *program* 和 *trackedEntity* 参数之一
    指定（零或一）。

  - 如果指定了 *programStatus* 那么 *program* 也必须是
    指定的。

  - 如果指定了 *followUp*，则还必须指定 *program*。

  - 如果指定了 *programStartDate* 或 *programEndDate*，则
    *程序* 也必须指定。

查询与特定组织单位关联的所有注册
看起来像这样：

    /api/33/enrollments.json?ou=DiszpKrYNg8

限制对作为特定活动一部分的注册的响应
程序，您可以包含程序查询
    范围：

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

要将程序注册日期指定为查询的一部分，请执行以下操作：

    /api/33/enrollments.json?&ou=O6uvpzGd5pu&program=ur1Edk5Oe2n
      ＆programStartDate = 2013-01-01＆programEndDate = 2013-09-01

限制对特定被跟踪实体的注册的响应
您可以包含跟踪实体查询
    范围：

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

限制对特定被跟踪实体的注册的响应
例如，您可以包含一个跟踪实体实例查询参数，在
在这种情况下，我们已将其限制为可查看的可用注册
当前的
    用户：

    /api/33/enrollments.json?ouMode=ACCESSIBLE&trackedEntityInstance=tphfdyIiVL6

默认情况下，注册以 50 页大小的页面返回，以更改
这您可以使用 page 和 pageSize 查询
    参数：

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&page=2&pageSize=3

##### 回应格式 { #webapi_enrollment_query_response_format }

此资源支持 JSON、JSONP、XLS 和 CSV 资源
表示。

  - json（应用程序/ json）

  - jsonp（应用程序/ javascript）

  - xml（应用程序/ xml）

JSON/XML 中的响应采用对象格式，看起来像
下列的。请注意，支持字段过滤，所以如果你想
一个完整的视图，您可能希望将 `fields=*` 添加到查询中：

```json
{
  "enrollments": [
    {
      "lastUpdated": "2014-03-28T05:27:48.512+0000",
      "trackedEntity": "cyl5vuJ5ETQ",
      "created": "2014-03-28T05:27:48.500+0000",
      "orgUnit": "DiszpKrYNg8",
      "program": "ur1Edk5Oe2n",
      "enrollment": "HLFOK0XThjr",
      "trackedEntityInstance": "qv0j4JBXQX0",
      "followup": false,
      "enrollmentDate": "2013-05-23T05:27:48.490+0000",
      "incidentDate": "2013-05-10T05:27:48.490+0000",
      "status": "ACTIVE"
    }
  ]
}
```

### 大事记 { #webapi_events }

本节关于发送和读取事件。

    / api / 33 / events

The different status of an event are:

* **ACTIVE**: If a event has ACTIVE status, it is possible to edit the event details. COMPLETED events can be turned ACTIVE again and vice versa.
* **COMPLETED**: An event change the status to COMPLETED only when a user clicks the complete button. If a event has COMPLETED status, it is not possible to edit the event details. ACTIVE events can be turned COMPLETED again and vice versa.
* **SKIPPED**: Scheduled events that no longer need to happen. In Tracker Capture, there is a button for that.
* **SCHEDULE**: If an event has no event date (but it has an due date) then the event status is saved as SCHEDULE.
* **OVERDUE**: If the due date of a scheduled event (no event date) has expired, it can be interpreted as OVERDUE.
* **VISITED**: (Removed since 2.38. VISITED migrate to ACTIVE). In Tracker Capture its possible to reach VISITED by adding a new event with an event date, and then leave before adding any data to the event - but it is not known to the tracker product team that anyone uses the status for anything. The VISITED status is not visible in the UI, and in all means treated in the same way as an ACTIVE event.


#### 发送事件 { #webapi_sending_events }

DHIS2 支持三种事件： 没有注册的单一事件
（也称为匿名事件），注册的单一事件
和多个注册的事件。注册意味着
数据链接到使用标识的跟踪实体实例
某种标识符。

要将事件发送到 DHIS2，您必须与 *events* 资源进行交互。
发送事件的方法类似于发送聚合数据
值。您将需要一个*程序*，可以使用
*programs* 资源，一个 *orgUnit*，可以使用
*organisationUnits* 资源，以及有效数据元素的列表
可以使用 *dataElements* 资源查找的标识符。
对于注册的事件，*跟踪实体实例*标识符是
需要，请在有关
*trackedEntityInstances* 资源。用于向程序发送事件
多个阶段，您还需要包括 *programStage*
标识符，programStages 的标识符可以在
*programStages* 资源。

XML 格式的没有注册示例有效负载的简单单个事件
我们从“住院发病率和死亡率”发送事件的地方
可以看到演示数据库中“Ngelehun CHC”设施的程序
以下：

```xml
<?xml version="1.0" encoding="utf-8"?>
<event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
  eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
  <coordinate latitude="59.8" longitude="10.9" />
  <dataValues>
    <dataValue dataElement="qrur9Dvnyt5" value="22" />
    <dataValue dataElement="oZg33kd9taw" value="Male" />
    <dataValue dataElement="msodh3rEMJa" value="2013-05-18" />
  </dataValues>
</event>
```

为了执行一些测试，我们可以将 XML 负载保存为文件
调用*event.xml* 并将其作为 POST 请求发送到事件资源
在 API 中使用 curl 和以下命令：

```bash
curl -d @event.xml "https://play.dhis2.org/demo/api/33/events"
  -H "Content-Type:application/xml" -u admin:district
```

JSON格式的相同负载如下所示：

```json
{
  "program": "eBAyeGv0exc",
  "orgUnit": "DiszpKrYNg8",
  "eventDate": "2013-05-17",
  "status": "COMPLETED",
  "completedDate": "2013-05-18",
  "storedBy": "admin",
  "coordinate": {
    "latitude": 59.8,
    "longitude": 10.9
  },
  "dataValues": [
    {
      "dataElement": "qrur9Dvnyt5", 
      "value": "22"
    },
    {
      "dataElement": "oZg33kd9taw", 
      "value": "Male"
    }, 
    {
      "dataElement": "msodh3rEMJa", 
      "value": "2013-05-18"
    }
  ]
}
```

要发送它，您可以将其保存到一个名为 *event.json* 的文件中并使用 curl
像这样：

```bash
curl -d @event.json "localhost/api/33/events" -H "Content-Type:application/json"
  -u admin:district
```

我们还支持同时发送多个事件。一个有效载荷
XML 格式可能如下所示：

```xml
<?xml version="1.0" encoding="utf-8"?>
<events>
  <event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
    eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
    <coordinate latitude="59.8" longitude="10.9" />
    <dataValues>
      <dataValue dataElement="qrur9Dvnyt5" value="22" />
      <dataValue dataElement="oZg33kd9taw" value="Male" />
    </dataValues>
  </event>
  <event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
    eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
    <coordinate latitude="59.8" longitude="10.9" />
    <dataValues>
      <dataValue dataElement="qrur9Dvnyt5" value="26" />
      <dataValue dataElement="oZg33kd9taw" value="Female" />
    </dataValues>
  </event>
</events>
```

您将收到一份包含回复的导入摘要，该回复可以是
检查以获取有关请求结果的信息，
比如成功导入了多少值。 JSON 格式的负载
格式如下：

```json
{
  "events": [
  {
    "program": "eBAyeGv0exc",
    "orgUnit": "DiszpKrYNg8",
    "eventDate": "2013-05-17",
    "status": "COMPLETED",
    "storedBy": "admin",
    "coordinate": {
      "latitude": "59.8",
      "longitude": "10.9"
    },
    "dataValues": [
      {
        "dataElement": "qrur9Dvnyt5", 
        "value": "22"
      },
      {
        "dataElement": "oZg33kd9taw", 
        "value": "Male"
      }
    ]
  },
  {
    "program": "eBAyeGv0exc",
    "orgUnit": "DiszpKrYNg8",
    "eventDate": "2013-05-17",
    "status": "COMPLETED",
    "storedBy": "admin",
    "coordinate": {
      "latitude": "59.8",
      "longitude": "10.9"
    },
    "dataValues": [
      {
        "dataElement": "qrur9Dvnyt5", 
        "value": "26"
      },
      {
        "dataElement": "oZg33kd9taw", 
        "value": "Female"
      }
    ]
  } ]
}
```

您还可以使用GeoJson在事件上存储任何类型的几何图形。在此处可以看到使用GeoJson代替以前的经度和纬度属性的有效负载示例：

```json
{
  "program": "eBAyeGv0exc",
  "orgUnit": "DiszpKrYNg8",
  "eventDate": "2013-05-17",
  "status": "COMPLETED",
  "storedBy": "admin",
  "geometry": {
    "type": "POINT",
    "coordinates": [59.8, 10.9]
  },
  "dataValues": [
    {
      "dataElement": "qrur9Dvnyt5", 
      "value": "22"
    }, 
    { 
      "dataElement": "oZg33kd9taw", 
      "value": "Male"
    }, 
    {
      "dataElement": "msodh3rEMJa", 
      "value": "2013-05-18"
    }
  ]
}
```

作为导入摘要的一部分，您还将获得标识符
*引用*您刚刚发送的事件，以及一个 *href* 元素
指向此事件的服务器位置。下表
描述每个元素的含义。



Table: Events resource format

| Parameter | 类型 | 需要 | 选项（默认为默认） | 描述 |
|---|---|---|---|---|
| program | string | 真正 || Identifier of the single event with no registration program |
| orgUnit | string | 真正 || Identifier of the organisation unit where the event took place |
| eventDate | date | 真正 || The date of when the event occurred |
| completedDate | date | 假 || The date of when the event is completed. If not provided, the current date is selected as the event completed date |
| status | enum | 假 | ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED | Whether the event is complete or not |
| storedBy | string | 假 | Defaults to current user | Who stored this event (can be username, system-name, etc) |
| coordinate | double | 假 || Refers to where the event took place geographically (latitude and longitude) |
| dataElement | string | 真正 || Identifier of data element |
| 价值 | string | 真正 || Data value or measure for this event |

##### OrgUnit匹配 { #orgunit-matching } 

默认情况下，orgUnit 参数将匹配
ID，您还可以使用 orgUnit id 匹配方案选择
参数 orgUnitIdScheme=SCHEME，其中选项为：*ID*、*UID*、
*UUID*、*CODE* 和 *NAME*。还有 *ATTRIBUTE:* 方案，它
匹配*唯一*元数据属性值。

#### 更新事件 { #webapi_updating_events }

要更新现有事件，有效负载的格式是相同的，但是
您要发布到的 URL 必须将标识符添加到 URL 的末尾
字符串并且请求必须是 PUT。

有效载荷必须包含所有属性，即使是未修改的属性。
以前存在但现在不存在的属性
系统将删除任何更多的有效载荷。

不允许更新已删除的事件。同样适用
跟踪实体实例和注册。

```bash
curl -X PUT -d @updated_event.xml "localhost/api/33/events/ID"
  -H "Content-Type: application/xml" -u admin:district
```

```bash
curl -X PUT -d @updated_event.json "localhost/api/33/events/ID"
  -H "Content-Type: application/json" -u admin:district
```

#### 删除活动 { #webapi_deleting_events }

要删除现有事件，您只需要发送 DELETE 请求
带有对您正在使用的服务器的标识符引用。

```bash
curl -X DELETE "localhost/api/33/events/ID" -u admin:district
```

#### 为用户分配事件 { #webapi_user_assign_event }

可以将用户分配给事件。这可以通过在更新或创建事件时在有效负载中包含适当的属性来完成。

      “ assignedUser”：“ <id>”

id是指用户的if。一次只能为一个事件分配一个用户。

必须先在程序阶段启用用户分配，然后才能将用户分配给事件。
#### 获取事件 { #webapi_getting_events }

要获取现有事件，您可以发出 GET 请求，包括
像这样的标识符：

```bash
curl "http://localhost/api/33/events/ID" -H "Content-Type: application/xml" -u admin:district
```

#### 查询和阅读事件 { #webapi_querying_reading_events }

本节说明如何读出已存储的事件
在 DHIS2 实例中。有关事件数据的更高级用途，请
请参阅事件分析部分。从输出格式
`/api/events` 端点将匹配用于发送事件的格式
到它（分析事件 api 不支持）。 XML 和
支持 JSON，可以通过添加 .json/.xml 或通过设置
适当的*接受*标题。查询默认分页，
默认页面大小为 50 个事件，*field* 过滤的工作原理与
元数据，添加 *fields* 参数并包含您想要的属性，
即 *?fields=program,status*。



Table: Events resource query parameters

| 键 | 类型 | 需要 | 描述 |
|---|---|---|---|
| program | identifier | true (if not programStage is provided) | Identifier of program |
| programStage | identifier | 假 | Identifier of program stage |
| programStatus | enum | 假 | Status of event in program, ca be ACTIVE &#124; COMPLETED &#124; CANCELLED |
| 跟进 | boolean | 假 | Whether event is considered for follow up in program, can be true &#124; false or omitted. |
| trackedEntityInstance | identifier | 假 | Identifier of tracked entity instance |
| orgUnit | identifier | 真正 | Identifier of organisation unit |
| ouMode | enum | 假 | Org unit selection mode, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS |
| 开始日期 | date | 假 | Only events newer than this date |
| 结束日期 | date | 假 | Only events older than this date |
| status | enum | 假 | Status of event, can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED |
| lastUpdatedStartDate | date | 假 | Filter for events which were updated after this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedEndDate | date | 假 | Filter for events which were updated up until this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedDuration | string | 假 | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). Cannot be used together with *lastUpdatedStartDate* and/or *lastUpdatedEndDate*. |
| skipMeta | boolean | 假 | Exclude the meta data part of response (improves performance) |
| page | 整数 | 假 | Page number |
| pageSize | 整数 | 假 | Number of items in each page |
| totalPages | boolean | 假 | Indicates whether to include the total number of pages in the paging response. |
| skipPaging | boolean | 假 | Indicates whether to skip paging in the query and return all events. |
| 数据元素标识方案 | string | 假 | Data element ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| categoryOptionComboIdScheme | string | 假 | Category Option Combo ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| orgUnitIdScheme | string | 假 | Organisation Unit ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| 程序标识方案 | string | 假 | Program ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| 程序阶段标识方案 | string | 假 | Program Stage ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| 方案 | string | 假 | Allows to set id scheme for data element, category option combo, orgUnit, program and program stage at once. |
| order | string | 假 | The order of which to retrieve the events from the API. Usage: order=<property\>:asc/desc - Ascending order is default. <br>Properties: event &#124; program &#124; programStage &#124; enrollment &#124; enrollmentStatus &#124; orgUnit &#124; orgUnitName &#124; trackedEntityInstance &#124; eventDate &#124; followup &#124; status &#124; dueDate &#124; storedBy &#124; created &#124; lastUpdated &#124; completedBy &#124; completedDate<br> order=orgUnitName:DESC order=lastUpdated:ASC |
| event | comma delimited string | 假 | Filter the result down to a limited set of IDs by using *event=id1;id2*. |
| skipEventId | boolean | 假 | Skips event identifiers in the response |
| attributeCc (\*\*) | string | 假 | Attribute category combo identifier (must be combined with *attributeCos*) |
| attributeCos (\*\*) | string | 假 | Attribute category option identifiers, separated with ; (must be combined with *attributeCc*) |
| async | false &#124; true | 假 | Indicates whether the import should be done asynchronous or synchronous. |
| includeDeleted | boolean | 假 | When true, soft deleted events will be included in your query result. |
| assignedUserMode | enum | 假 | Assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser | comma delimited strings | 假 | Filter the result down to a limited set of events that are assigned to the given user IDs by using *assignedUser=id1;id2*. This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |

> **注意**
>
>如果查询既不包含`attributeCC`也不包含`attributeCos`，则服务器将为用户具有读取访问权限的所有属性选项组合返回事件。

##### 例子 { #examples } 

查询具有特定组织单位的子级的所有事件：

    /api/29/events.json?orgUnit=YuQRtpLP10I&ouMode=CHILDREN

查询某个组织的所有后代的所有事件
单位，暗示子层次结构中的所有组织单位：

    /api/33/events.json?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS

使用特定程序和组织单位查询所有事件：

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

查询具有一定节目和组织单位的所有事件，
按截止日期排序
    上升：

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=dueDate

查询某节目中活动日期最新的10个活动
和组织单位 - 按到期日降序分页和排序：

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      ＆order = eventDate：desc＆pageSize = 10＆page = 1

查询具有特定节目和组织单位的所有事件
特定的跟踪实体实例：

    /api/33/events.json?orgUnit=DiszpKrYNg8
      ＆program = eBAyeGv0exc＆trackedEntityInstance = gfVxE3ALA9m

查询某个程序和组织单位较旧的所有事件
或等于
    2014-02-03：

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&endDate=2014-02-03

查询具有一定节目阶段、组织单位和
2014年被跟踪实体实例：

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      ＆trackedEntityInstance = gfVxE3ALA9m＆startDate = 2014-01-01＆endDate = 2014-12-31

与事件数据值关联的查询文件。在获取图像文件的特定情况下
可以提供附加参数来获取不同尺寸的图像。如果维度是
未提供，系统将返回原图。在以下情况下将忽略该参数
获取非图像文件，例如 pdf。可能的尺寸值为 *small(254 x 254)，
中 (512 x 512)、大 (1024 x 1024) 或原始*。除了提到的那些值之外的任何值都将是
丢弃并返回原始图像。

    / api / 33 / events / files？eventUid = hcmcWlYkg9u＆dataElementUid = C0W4aFuVm4P＆dimension = small

检索具有指定组织单位和程序的事件，并使用 _Attribute:Gq0oWTf2DtN_ 作为
标识符方案

    /api/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN

检索具有指定组织单位和程序的事件，并使用 UID 作为标识符方案
orgUnits，代码作为程序阶段的标识符方案，以及 _Attribute:Gq0oWTf2DtN_ 作为标识符
具有指定属性的其余元数据的方案。

    api/events.json?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=属性：Gq0oWTf2DtN
      &orgUnitIdScheme=UID&programStageIdScheme=代码

#### 事件网格查询 { #event-grid-query } 

除了上面的事件查询端点，还有一个事件网格
查询终点，其中更紧凑的“网格”事件格式
回。这可以通过与
/api/events/query.json|xml|xls|csv 端点。

    / api / 33 / events / query

事件查询和读取中提到的大部分查询参数
上面的部分在此处有效。但是，由于要返回的网格
带有适用于所有行（事件）的特定列集，它
必须指定程序阶段。混合是不可能的
来自不同程序或程序阶段的事件返回。

从单个程序阶段返回事件，也为新的事件打开
功能 - 例如根据事件对事件进行排序和搜索
数据元素值。 api/events/query 对此有支持。以下是
一些例子

返回仅包含选定数据元素的事件网格的查询
对于一个程序阶段

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      ＆dataElement = qrur9Dvnyt5，fWIAEtYVEGk，K6uUAvq500H＆order = lastUpdated：desc
      ＆pageSize = 50＆page = 1＆totalPages = true

返回包含所有数据元素的事件网格的查询
程序
    阶段

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      ＆includeAllDataElements = true

基于数据元素过滤事件的查询
    价值

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      ＆filter = qrur9Dvnyt5：GT：20：LT：50

除了过滤，上面的例子还说明了一个
事情：没有提到要返回的数据元素的事实
在网格中。发生这种情况时，系统默认返回只返回
在程序阶段标记为“在报告中显示”的那些数据元素
配置。

我们还可以扩展上面的查询以返回一个排序的网格（asc|desc）
基于数据元素
    价值

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      ＆filter = qrur9Dvnyt5：GT：20：LT：50＆order = qrur9Dvnyt5：desc

#### 事件过滤器 { #webapi_event_filters }

要创建、读取、更新和删除事件过滤器，您
可以与`/api/eventFilters` 资源交互。

    / api / 33 / eventFilters

##### 创建和更新事件过滤器定义 { #create-and-update-an-event-filter-definition } 

用于创建和更新事件过滤器
系统，您将使用 *eventFilters*
资源。 *POST* 用于创建，*PUT* 方法用于更新。事件过滤器定义用于
Tracker Capture 应用程序显示相关的预定义“工作列表”
跟踪器用户界面。



Table: Request Payload

| Request Property | 描述 | 例 |
|---|---|---|
| 名称 | Name of the filter. | "name":"My working list" |
| 描述 | A description of the filter. | "description":"for listing all events assigned to me". |
| program | The uid of the program. | "program" : "a3kGcGDCuk6" |
| programStage | The uid of the program stage. | "programStage" : "a3kGcGDCuk6" |
| eventQueryCriteria | Object containing parameters for querying, sorting and filtering events. | "eventQueryCriteria": {     "organisationUnit":"a3kGcGDCuk6",     "status": "COMPLETED",     "createdDate": {       "from": "2014-05-01",       "to": "2019-03-20"     },     "dataElements": ["a3kGcGDCuk6:EQ:1", "a3kGcGDCuk6"],     "filters": ["a3kGcGDCuk6:EQ:1"],     "programStatus": "ACTIVE",     "ouMode": "SELECTED",     "assignedUserMode": "PROVIDED",     "assignedUsers" : ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "followUp": false,     "trackedEntityInstance": "a3kGcGDCuk6",     "events": ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "fields": "eventDate,dueDate",     "order": "dueDate:asc,createdDate:desc"   } |



Table: Event Query Criteria definition

||||
|---|---|---|
| 跟进 | Used to filter events based on enrollment followUp flag. Possible values are true&#124;false. | "followUp": true |
| organisationUnit | To specify the uid of the organisation unit | "organisationUnit": "a3kGcGDCuk7" |
| ouMode | To specify the OU selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL | "ouMode": "SELECTED" |
| assignedUserMode | To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUsers | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |
| displayOrderColumns | To specify the output ordering of columns | "displayOrderColumns": ["eventDate", "dueDate", "program"] |
| order | To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "dataItem:direction". | "order"="a3kGcGDCuk6:desc,eventDate:asc" |
| dataFilters | To specify filters to be applied when listing events | "dataFilters"=[{       "dataItem": "abcDataElementUid",       "le": "20",       "ge": "10",       "lt": "20",       "gt": "10",       "in": ["India", "Norway"],       "like": "abc",       "dateFilter": {         "startDate": "2014-05-01",         "endDate": "2019-03-20",         "startBuffer": -5,         "endBuffer": 5,         "period": "LAST_WEEK",         "type": "RELATIVE"       }     }] |
| status | Any valid EventStatus | "eventStatus": "COMPLETED" |
| events | To specify list of events | "events"=["a3kGcGDCuk6"] |
| completedDate | DateFilterPeriod object date filtering based on completed date. | "completedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| eventDate | DateFilterPeriod object date filtering based on event date. | "eventDate": {     "startBuffer": -5,     "endBuffer": 5,     "type": "RELATIVE"   } |
| dueDate | DateFilterPeriod object date filtering based on due date. | "dueDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| lastUpdatedDate | DateFilterPeriod object date filtering based on last updated date. | "lastUpdatedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   } |



Table: DateFilterPeriod object definition

||||
|---|---|---|
| type | Specify whether the date period type is ABSOLUTE &#124; RELATIVE | "type" : "RELATIVE" |
| period | Specify if a relative system defined period is to be used. Applicable only when "type" is RELATIVE. (see [Relative Periods](#webapi_date_relative_period_values) for supported relative periods) | "period" : "THIS_WEEK" |
| 开始日期 | Absolute start date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| 结束日期 | Absolute end date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| startBuffer | Relative custom start date. Applicable only when "type" is RELATIVE | "startBuffer":-10 |
| endBuffer | Relative custom end date. Applicable only when "type" is RELATIVE | "startDate":+10 |

可用的分配用户选择模式在
下表。



Table: Assigned user selection modes (event assignment)

| Mode | 描述 |
|---|---|
| CURRENT | Assigned to the current logged in user |
| PROVIDED | Assigned to the users provided in the "assignedUser" parameter |
| NONE | Assigned to no users. |
| ANY | Assigned to any users. |

下面显示了可用于创建/更新eventFilter的示例有效负载。

```json
{
  "program": "ur1Edk5Oe2n",
  "description": "Simple Filter for TB events",
  "name": "TB events",
  "eventQueryCriteria": {
    "organisationUnit":"DiszpKrYNg8",
    "eventStatus": "COMPLETED",
    "eventDate": {
      "startDate": "2014-05-01",
      "endDate": "2019-03-20",
      "startBuffer": -5,
      "endBuffer": 5,
      "period": "LAST_WEEK",
      "type": "RELATIVE"
    },
    "dataFilters": [{
      "dataItem": "abcDataElementUid",
      "le": "20",
      "ge": "10",
      "lt": "20",
      "gt": "10",
      "in": ["India", "Norway"],
      "like": "abc"
    },
    {
      "dataItem": "dateDataElementUid",
      "dateFilter": {
        "startDate": "2014-05-01",
        "endDate": "2019-03-20",
        "type": "ABSOLUTE"
      }
    },
    {
      "dataItem": "anotherDateDataElementUid",
      "dateFilter": {
        "startBuffer": -5,
        "endBuffer": 5,
        "type": "RELATIVE"
      }
    },
    {
      "dataItem": "yetAnotherDateDataElementUid",
      "dateFilter": {
        "period": "LAST_WEEK",
        "type": "RELATIVE"
      }
    }],
    "programStatus": "ACTIVE"
  }
}
```


##### 检索和删除事件过滤器 { #retrieving-and-deleting-event-filters } 

可以使用以下api检索特定的事件过滤器

    GET /api/33/eventFilters/{uid}

可以使用以下api检索所有事件过滤器。

    GET /api/33/eventFilters?fields=*

可以使用以下api检索特定程序的所有事件过滤器

    GET /api/33/eventFilters?filter=program:eq:IpHINAT79UW

可以使用以下API删除事件过滤器

    删除/ api / 33 / eventFilters / {uid}

### 人际关系 { #relationships } 
关系是跟踪器中两个实体之间的链接。这些实体可以跟踪实体实例，注册和事件。

有多个端点，可让您查看，创建，删除和更新关系。最常见的是/ api / trackedEntityInstances端点，您可以在其中将关系包括在有效负载中以创建，更新或删除它们（如果忽略它们）-类似于在同一端点中处理注册和事件的方式。如果在字段过滤器中请求，所有跟踪器端点，/ api / trackedEntityInstances，/ api / enrollments和/ api / events也会列出它们的关系。

但是，关系的标准端点是/ api / relationships。该端点为关系提供所有正常的CRUD操作。

You can view a list of relationships by trackedEntityInstance, enrollment or event:

    GET /api/relationships?[tei={teiUID}|enrollment={enrollmentUID}|event={eventUID}]


该请求将返回您有权访问的任何关系的列表，其中包括您指定的trackedEntityInstance，注册或事件。每个关系都使用以下JSON表示：

```json
{
  "relationshipType": "dDrh5UyCyvQ",
  "relationshipName": "Mother-Child",
  "relationship": "t0HIBrc65Rm",
  "bidirectional": false,
  "from": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "vOxUH373fy5"
    }
  },
  "to": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "pybd813kIWx"
    }
  },
  "created": "2019-04-26T09:30:56.267",
  "lastUpdated": "2019-04-26T09:30:56.267"
}
```

您还可以使用以下端点查看指定的关系：

    GET /api/relationships/<id>

要创建或更新关系，可以使用以下端点：

    POST / api / relationships
    PUT / api /关系

并使用以下有效负载结构：

```json
{
  "relationshipType": "dDrh5UyCyvQ",
  "from": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "vOxUH373fy5"
    }
  },
  "to": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "pybd813kIWx"
    }
  }
}
```

要删除关系，可以使用以下端点：

      删除/ api / relationships / <id>

在示例有效负载中，我们使用trackedEntityInstances之间的关系。因此，有效负载的“从”和“到”属性包括“ trackedEntityInstance”对象。如果您的关系包括其他实体，则可以使用以下属性：

```json
{
  "enrollment": {
    "enrollment": "<id>"
  }
}
```

```json
{
  "event": {
    "event": "<id>"
  }
}
```

Relationship can be soft deleted. In that case, you can use the `includeDeleted` request parameter to see the relationship.
    GET /api/relationships?tei=pybd813kIWx?includeDeleted=true

### 更新策略 { #webapi_tei_update_strategies }

支持所有 3 个跟踪器端点的两种更新策略：
注册和事件创建。当您生成一个
客户端的标识符，不确定它是否被创建
在服务器上。



Table: Available tracker strategies

| Parameter | 描述 |
|---|---|
| CREATE | Create only, this is the default behavior. |
| CREATE_AND_UPDATE | Try and match the ID, if it exist then update, if not create. |

要更改参数，请使用策略参数：

    POST / api / 33 / trackedEntityInstances？strategy = CREATE_AND_UPDATE

### 跟踪器批量删除 { #webapi_tracker_bulk_deletion }

批量删除跟踪器对象的工作方式与添加和删除跟踪器对象的方式类似
更新跟踪器对象，唯一的不同是
`importStrategy`是*DELETE*。

*示例：批量删除跟踪实体实例：*

```json
{
  "trackedEntityInstances": [
    {
      "trackedEntityInstance": "ID1"
    }, {
      "trackedEntityInstance": "ID2"
    }, {
      "trackedEntityInstance": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/trackedEntityInstances?strategy=DELETE"
```

*示例：批量删除注册：*

```json
{
  "enrollments": [
    {
       "enrollment": "ID1"
    }, {
      "enrollment": "ID2"
    }, {
      "enrollment": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/enrollments?strategy=DELETE"
```

*示例：批量删除事件：*

```json
{
  "events": [
    {
      "event": "ID1"
    }, {
      "event": "ID2"
    }, {
      "event": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/events?strategy=DELETE"
```

### 通过POST和PUT方法重复使用标识符和删除项目 { #webapi_updating_and_deleting_items }

跟踪器端点 */trackedEntityInstances*、*/enrollments*、*/events*
支持 CRUD 操作。系统跟踪使用的标识符。
因此，已创建然后删除的项目（例如事件、
注册）不能再次创建或更新。如果试图删除
已删除的项目，系统返回成功响应为
删除已删除的项目意味着没有更改。

系统不允许通过更新（* PUT *）删除项目或
创建（* POST *）方法。因此，* PUT *和* POST *方法中的* deleted *属性将被忽略，并且在* POST *方法中默认设置
为* false *。

### 导入参数 { #webapi_import_parameters }

可以使用一组导入参数来自定义导入过程：



Table: Import parameters

| Parameter | Values (default first) | 描述 |
|---|---|---|
| 数据元素标识方案 | id &#124; name &#124; code &#124; attribute:ID | Property of the data element object to use to map the data values. |
| orgUnitIdScheme | id &#124; name &#124; code &#124; attribute:ID | Property of the org unit object to use to map the data values. |
| 方案 | id &#124; name &#124; code&#124; attribute:ID | Property of all objects including data elements, org units and category option combos, to use to map the data values. |
| dryRun | false &#124; true | Whether to save changes on the server or just return the import summary. |
| strategy | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | Save objects of all, new or update import status on the server. |
| skipNotifications | true &#124; false | Indicates whether to send notifications for completed events. |
| skipFirst | true &#124; false | Relevant for CSV import only. Indicates whether CSV file contains a header row which should be skipped. |
| importReportMode | FULL, ERRORS, DEBUG | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |

#### CSV导入/导出 { #webapi_events_csv_import_export }

除了用于事件导入/导出的 XML 和 JSON 之外，在 DHIS2.17 中我们
引入了对 CSV 格式的支持。对这种格式的支持建立在
上一节已经描述过，所以这里我们只写
CSV 特定部分是什么。

要使用 CSV 格式，您必须使用 `/api/events.csv`
端点，或添加 *content-type: text/csv* 以进行导入，并 *accept:
text/csv* 用于在使用 `/api/events` 端点时导出。

CSV 中用于导出和导入的列的顺序
如下：



Table: CSV column

| Index | 键 | 类型 | 描述 |
|---|---|---|---|
| 1 | event | identifier | Identifier of event |
| 2 | status | enum | Status of event, can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED |
| 3 | program | identifier | Identifier of program |
| 4 | programStage | identifier | Identifier of program stage |
| 5 | enrollment | identifier | Identifier of enrollment (program instance) |
| 6 | orgUnit | identifier | Identifier of organisation unit |
| 7 | eventDate | date | Event date |
| 8 | dueDate | date | Due Date |
| 9 | latitude | double | Latitude where event happened |
| 10 | longitude | double | Longitude where event happened |
| 11 | dataElement | identifier | Identifier of data element |
| 12 | 价值 | string | Value / measure of event |
| 13 | storedBy | string | Event was stored by (defaults to current user) |
| 14 | providedElsewhere | boolean | Was this value collected somewhere else |
| 14 | completedDate | date | Completed date of event |
| 14 | completedBy | string | Username of user who completed event |

*具有 2 个不同数据值的 2 个事件的示例
    每个：*

```csv
EJNxP3WreNP，COMPLETED，<pid>，<psid>，<enrollment-id>，<ou>，2016-01-01,2016-01-01 ,,, <de>，1 ,,
EJNxP3WreNP，COMPLETED，<pid>，<psid>，<enrollment-id>，<ou>，2016-01-01,2016-01-01 ,,, <de>，2 ,,
qPEdI1xn7k0，COMPLETED，<pid>，<psid>，<enrollment-id>，<ou>，2016-01-01,2016-01-01 ,,, <de>，3 ,,
qPEdI1xn7k0，COMPLETED，<pid>，<psid>，<enrollment-id>，<ou>，2016-01-01,2016-01-01 ,,, <de>，4 ,,
```

#### 导入策略：SYNC { #webapi_sync_import_strategy }

导入策略 SYNC 应仅用于内部同步
任务而不是常规导入。 SYNC 策略允许所有 3
操作：CREATE、UPDATE、DELETE 出现在有效载荷中
同时。

### 跟踪器所有权管理 { #webapi_tracker_ownership_management }

从 2.30 开始引入了一个名为 Tracker Ownership 的新概念。那里
现在将成为跟踪实体实例的一个所有者组织单位
程序的上下文。配置了访问权限的程序
*PROTECTED* 或 *CLOSED* 的级别将遵守所有权
特权。仅属于所属组织单位的用户
被跟踪的实体-程序组合将能够访问数据
与该被跟踪实体的该计划相关。

#### 跟踪器所有权优先：打破常规 { #webapi_tracker_ownership_override_api }

可以临时覆盖此所有权特权
访问级别配置为 *PROTECTED* 的程序。任何用户
将能够临时访问程序相关数据，如果
用户指定访问被跟踪实体程序的原因
数据。这种暂时获得访问权限的行为被称为*破坏
玻璃*。目前，临时访问权限为 3 小时。 DHIS2
审计打破玻璃以及用户指定的原因。
无法临时访问已被删除的程序
配置访问级别为 *CLOSED*。打破玻璃
被跟踪的实体程序组合，您可以发出 POST 请求作为
显示：

    / api / 33 / tracker / ownership / override？trackedEntityInstance = DiszpKrYNg8
      ＆program = eBAyeGv0exc＆reason =耐心+显示+急诊+急诊

#### 跟踪器所有权转移 { #webapi_tracker_ownership_transfer_api }

可以转移被跟踪实体程序的所有权
从一个组织单位到另一个组织单位。这将有助于患者
转介或迁移。只有所有者（或破坏了
glass）可以转让所有权。转移被跟踪的所有权
entity-program 到另一个组织单位，你可以发出 PUT 请求
如图所示：

    / api / 33 / tracker /所有权/转让？trackedEntityInstance = DiszpKrYNg8
      ＆program = eBAyeGv0exc＆ou = EJNxP3WreNP


## 潜在重复   { #potential-duplicates } 

潜在的重复项是我们在重复数据删除功能中使用的记录。由于重复数据删除功能的性质，此API端点受到一定程度的限制。

A potential duplicate represents a pair of records which are suspected to be a duplicate.

潜在重复项的有效负载如下所示：

```json
{
  "teiA": "<id>",
  "teiB": "<id>",
  "status": "OPEN|INVALID|MERGED"
}
```

您可以使用以下端点检索可能重复的列表：

    GET /api/potentialDuplicates

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| teis | List of tracked entity instances | List of string (separated by comma)| existing tracked entity instance id |
| status | Potential duplicate status | string | `OPEN <default>`, `INVALID`, `MERGED`, `ALL` |

| Status code | 描述
|---|---|
| 400 | Invalid input status

You can inspect individual potential duplicate records:

    GET /api/potentialDuplicates/<id>

| Status code | 描述
|---|---|
| 404 | Potential duplicate not found

You can also filter potential duplicates by Tracked Entity Instance (referred as tei) :

    GET /api/potentialDuplicates/tei/<tei>

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| status | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED`, `ALL <default>` |

| Status code | 描述
|---|---|
| 400 | Invalid input status
| 403 | User do not have access to read tei
| 404 | Tei not found

要创建新的潜在重复项，可以使用以下端点：

    POST / api / potentialDuplicates

The payload you provide must include both teiA and teiB

```json
{
  "teiA": "<id>",
  "teiB": "<id>"
}
```

| Status code | 描述
|---|---|
| 400 | Input teiA or teiB is null or has invalid id
| 403 | User do not have access to read teiA or teiB
| 404 | Tei not found
| 409 | Pair of teiA and teiB already existing

To update a potential duplicate status:

    PUT /api/potentialDuplicates/<id>

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| status | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED` |

| Status code | 描述
|---|---|
| 400 | You can't update a potential duplicate to MERGED as this is possible only by a merging request
| 400 | You can't update a potential duplicate that is already in a MERGED status

## Flag Tracked Entity Instance as Potential Duplicate { #flag-tracked-entity-instance-as-potential-duplicate } 

To flag as potential duplicate a Tracked Entity Instance (referred as tei)

 `PUT /api/trackedEntityInstances/{tei}/potentialDuplicate`

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| flag | either flag or unflag a tei as potential duplicate | string | `true`, `false` |


| Status code | 描述
|---|---|
| 400 | Invalid flag must be true of false
| 403 | User do not have access to update tei
| 404 | Tei not found

## Merging Tracked Entity Instances { #merging-tracked-entity-instances } 
Tracked entity instances can now be merged together if they are viable. To initiate a merge, the first step is to define two tracked entity instances as a Potential Duplicate. The merge endpoint
will move data from the duplicate tracked entity instance to the original tracked entity instance, and delete the remaining data of the duplicate.

To merge a Potential Duplicate, or the two tracked entity instances the Potential Duplicate represents, the following endpoint can be used:

    POST /potentialDuplicates/<id>/merge

| Parameter name | 描述 | 类型 | Allowed values |
|---|---|---|---|
| mergeStrategy | Strategy to use for merging the potentialDuplicate | enum | AUTO(default) or MANUAL |

The endpoint accepts a single parameter, "mergeStrategy", which decides which strategy to use when merging. For the AUTO strategy, the server will attempt to merge the two tracked entities
automatically, without any input from the user. This strategy only allows merging tracked entities without conflicting data (See examples below). The other strategy, MANUAL, requires the
user to send in a payload describing how the merge should be done. For examples and rules for each strategy, see their respective sections below.

### Merge Strategy AUTO { #merge-strategy-auto } 
The automatic merge will evaluate the mergability of the two tracked entity instances, and merge them if they are deemed mergable. The mergability is based on whether the two tracked entity instances
has any conflicts or not. Conflicts refers to data which cannot be merged together automatically. Examples of possible conflicts are:
- The same attribute has different values in each tracked entity instance
- Both tracked entity instances are enrolled in the same program
- Tracked entity instances have different types

If any conflict is encountered, an errormessage is returned to the user.

When no conflicts are found, all data in the duplicate that is not already in the original will be moved over to the original. This includes attribute values, enrollments (Including events) and relationships.
After the merge completes, the duplicate is deleted and the potentialDuplicate is marked as MERGED.

When requesting an automatic merge like this, a payload is not required and will be ignored.

### Merge Strategy MANUAL { #merge-strategy-manual } 
The manual merge is suitable when the merge has resolvable conflicts, or when not all the data is required to be moved over during a merge. For example, if an attribute has different values in both tracked
entity instances, the user can specify whether to keep the original value, or move over the duplicate's value. Since the manual merge is the user explicitly requesting to move data, there are some different
checks being done here:
- Relationship cannot be between the original and the duplicate (This results in an invalid self-referencing relationship)
- Relationship cannot be of the same type and to the same object in both tracked entity instances (IE. between original and other, and duplicate and other; This would result in a duplicate relationship)

There are two ways to do a manual merge: With and without a payload.

When a manual merge is requested without a payload, we are telling the API to merge the two tracked entity instances without moving any data. In other words, we are just removing the duplicate and marking the
potentialDuplicate MERGED. This might be valid in a lot of cases where the tracked entity instance was just created, but not enrolled for example.

Otherwise, if a manual merge is requested with a payload, the payload refers to what data should be moved from the duplicate to the original. The payload looks like this:
```json
{
  "trackedEntityAttributes": ["B58KFJ45L9D"],
  "enrollments": ["F61SJ2DhINO"],
  "relationships": ["ETkkZVSNSVw"]
}
```

This payload contains three lists, one for each of the types of data that can be moved. `trackedEntityAttributes` is a list of uids for tracked entity attributes, `enrollments` is a list of uids for enrollments and `relationships` 
a list of uids for relationships. The uids in this payload have to refer to data that actually exists on the duplicate. There is no way to add new data or change data using the merge endpoint - Only moving data.


### Additional information about merging { #additional-information-about-merging } 
Currently it is not possible to merge tracked entity instances that are enrolled in the same program, due to the added complexity. A workaround is to manually remove the enrollments from one of the tracked entity
instances before starting the merge.

All merging is based on data already persisted in the database, which means the current merging service is not validating that data again. This means if data was already invalid, it will not be reported during the merge.
The only validation done in the service relates to relationships, as mentioned in the previous section.



## Program Notification Template { #program-notification-template } 

Program Notification Template lets you create message templates which can be sent as a result of different type of events.
Message and Subject templates will be translated into actual values and can be sent to the configured destination. Each program notification template will be
transformed to either MessageConversation object or ProgramMessage object based on external or internal notificationRecipient. These intermediate objects will
only contain translated message and subject text.
There are multiple configuraiton parameters in Program Notification Tempalte which are critical for correct working of notifications.
All those are explained in the table below.

    POST /api/programNotificationTemplates

```json
{
    "name": "Case notification",
    "notificationTrigger": "ENROLLMENT",
    "subjectTemplate": "Case notification V{org_unit_name}",
    "displaySubjectTemplate": "Case notification V{org_unit_name}",
    "notifyUsersInHierarchyOnly": false,
    "sendRepeatable": false,
    "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
    "notifyParentOrganisationUnitOnly": false,
    "displayMessageTemplate": "Case notification A{h5FuguPFF2j}",
    "messageTemplate": "Case notification A{h5FuguPFF2j}",
    "deliveryChannels": [
        "EMAIL"
    ]
}
```

下表中说明了这些字段。


Table: Program Notification Template payload

| 领域 | 需要 | 描述 | Values |
|---|---|---|---|
| 名称 | 是的 | name of Program Notification Tempalte | case-notification-alert |
| notificationTrigger | 是的 | When notification should be triggered. Possible values are ENROLLMENT, COMPLETION, PROGRAM_RULE, SCHEDULED_DAYS_DUE_DATE| 注册 |
| subjectTemplate | 不 | Subject template string | Case notification V{org_unit_name} |
| messageTemplate | 是的 | Message template string | Case notification A{h5FuguPFF2j} |
| notificationRecipient | YES | Who is going to receive notification. Possible values are USER_GROUP, ORGANISATION_UNIT_CONTACT, TRACKED_ENTITY_INSTANCE, USERS_AT_ORGANISATION_UNIT, DATA_ELEMENT, PROGRAM_ATTRIBUTE, WEB_HOOK  | USER_GROUP |
| deliveryChannels | 不 | Which channel should be used for this notification. It can be either SMS, EMAIL or HTTP | SMS |
| sendRepeatable | 不 | Whether notification should be sent multiple times | 假 |

NOTE: WEB_HOOK notificationRecipient is used only to POST http request to an external system. Make sure to choose HTTP delivery channel when using WEB_HOOK.

### Retrieving and deleting Program Notification Template { #retrieving-and-deleting-program-notification-template } 

The list of Program Notification Templates can be retrieved using GET.

    GET /api/programNotificationTemplates

For one particular Program Notification Template.

    GET /api/33/programNotificationTemplates/{uid}

To get filtered list of Program Notification Templates

    GET /api/programNotificationTemplates/filter?program=<uid>
    GET /api/programNotificationTemplates/filter?programStage=<uid>

Program Notification Template can be deleted using DELETE.

    DELETE /api/33/programNotificationTemplates/{uid}


## Program Messages { #program-messages } 

程序消息可让您向跟踪的实体实例发送消息，
与组织单位关联的联系地址、电话号码和
电子邮件地址。您可以通过 `messages` 资源发送消息。

    / api / 33 /消息

### 发送程序信息 { #sending-program-messages } 

程序消息可以使用两个传递渠道发送：

  - 短信（SMS）

  - 电子邮件地址（EMAIL）

程序消息可以发送给各种收件人：

  - 跟踪实体实例：系统将查找值的属性
    输入 PHONE_NUMBER 或 EMAIL（取决于指定的递送
    通道）并使用相应的属性值。

  - 组织单位：系统将使用电话号码或邮箱
    为组织单位注册的信息。

  - 电话号码列表：系统将使用明确定义的
    电话号码。

  - 电子邮件地址列表：系统将使用明确定义的
    电子邮件地址。

下面是使用 POST 请求发送消息的示例 JSON 负载。
请注意，消息资源接受一个名为
`programMessages` 可以包含任意数量的程序消息。

    开机自检/ api / 33 / messages

```json
{
  "programMessages": [{
    "recipients": {
      "trackedEntityInstance": {
        "id": "UN810PwyVYO"
      },
      "organisationUnit": {
        "id": "Rp268JB6Ne4"
      },
      "phoneNumbers": [
        "55512345",
        "55545678"
      ],
      "emailAddresses": [
        "johndoe@mail.com",
        "markdoe@mail.com"
      ]
    },
    "programInstance": {
      "id": "f3rg8gFag8j"
    },
    "programStageInstance": {
      "id": "pSllsjpfLH2"
    },
    "deliveryChannels": [
      "SMS", "EMAIL"
    ],
    "notificationTemplate": "Zp268JB6Ne5",
    "subject": "Outbreak alert",
    "text": "An outbreak has been detected",
    "storeCopy": false
  }]
}
```

下表中说明了这些字段。



Table: Program message payload

| 领域 | 需要 | 描述 | Values |
|---|---|---|---|
| recipients | 是的 | Recipients of the program message. At least one recipient must be specified. Any number of recipients / types can be specified for a message. | Can be trackedEntityInstance, organisationUnit, an array of phoneNumbers or an array of emailAddresses. |
| programInstance | Either this or programStageInstance required | The program instance / enrollment. | Enrollment ID. |
| programStageInstance | Either this or programInstance required | The program stage instance / event. | Event ID. |
| deliveryChannels | 是的 | Array of delivery channels. | SMS &#124; EMAIL |
| subject | 不 | The message subject. Not applicable for SMS delivery channel. | Text. |
| 文本 | 是的 | The message text. | Text. |
| storeCopy | 不 | Whether to store a copy of the program message in DHIS2. | false (default) &#124; true |

通过 SMS 向被跟踪对象发送消息的简约示例
实体实例如下所示：

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messages"
  -H "Content-Type:application/json" -u admin:district
```

```json
{
  "programMessages": [{
    "recipients": {
      "trackedEntityInstance": {
        "id": "PQfMcpmXeFE"
      }
    },
    "programInstance": {
      "id": "JMgRZyeLWOo"
    },
    "deliveryChannels": [
      "SMS"
    ],
    "text": "Please make a visit on Thursday"
  }]
}
```

### 检索和删除程序消息 { #retrieving-and-deleting-program-messages } 

可以使用GET检索消息列表。

    GET /api/33/messages

To get the list of sent tracker messages, the below endpoint can be used. ProgramInstance or ProgramStageInstance uid has to be provided.

    GET /api/33/messages/scheduled/sent?programInstance={uid}
    GET /api/33/messages/scheduled/sent?programStageInstance={uid}

To get the list of all scheduled message

    GET / api / 33 / messages / scheduled
    GET / api / 33 / messages / scheduled？scheduledAt = 2020-12-12

也可以使用GET检索一条特定的消息。

    GET /api/33/messages/{uid}

可以使用DELETE删除消息。

    删除/ api / 33 / messages / {uid}


### 查询程序信息 { #querying-program-messages } 

程序消息API支持基于
请求参数。可以根据下面提到的过滤消息
查询参数。所有请求都应使用 GET HTTP 动词
检索信息。



Table: Query program messages API

| Parameter | 网址 |
|---|---|
| programInstance | /api/33/messages?programInstance=6yWDMa0LP7 |
| programStageInstance | /api/33/messages?programStageInstance=SllsjpfLH2 |
| trackedEntityInstance | /api/33/messages?trackedEntityInstance=xdfejpfLH2 |
| organisationUnit | /api/33/messages?ou=Sllsjdhoe3 |
| processedDate | /api/33/messages?processedDate=2016-02-01 |



# 电子邮件 { #email } 

## 电子邮件 { #webapi_email } 

Web API 具有用于发送电子邮件的资源。对于电子邮件
发送 需要已正确设置 SMTP 配置
并且 DHIS2 实例的系统通知电子邮件地址具有
被定义。您可以从电子邮件设置屏幕设置 SMTP 设置
和来自常规设置屏幕的系统通知电子邮件地址
在 DHIS2 中。

    / api / 33 /电子邮件

### 系统通知 { #webapi_email_system_notification } 

*notification* 资源可让您发送系统电子邮件通知
使用 JSON 或 XML 格式的给定主题和文本。电子邮件将发送至
DHIS2 通用系统中定义的通知电子邮件地址
设置：

```json
{
  "subject": "Integrity check summary",
  "text": "All checks ran successfully"
}
```

您可以通过发布到通知来发送系统电子邮件通知
像这样的资源：

```bash
curl -d @email.json "localhost/api/33/email/notification" -X POST 
  -H "Content-Type:application/json" -u admin:district
```

### 出站电子邮件 { #outbound-emails } 

您还可以通过发布到
通知资源如下所述。 `F_SEND_EMAIL` 或 `ALL`
权限必须在系统中才能使用这个 api。主题
参数是可选的。 “DHIS 2”字符串将作为默认主题发送
如果 url 中没有提供。应该对 URL 进行编码才能使用它
应用程序接口。

```bash
curl "localhost/api/33/email/notification?recipients=xyz%40abc.com&message=sample%20email&subject=Test%20Email" 
  -X POST -u admin:district
```

### 测试讯息 { #webapi_email_test_message } 

通过发送测试电子邮件来测试 SMTP 设置是否正确
您可以自己与 *test* 资源进行交互。发送测试邮件
您的 DHIS2 用户帐户必须具有有效的电子邮件地址
与之相关。您可以像这样发送测试电子邮件：

```bash
curl "localhost/api/33/email/test" -X POST -H "Content-Type:application/json" -u admin:district
```






# 数据存储 { #data-store } 

## 数据存储 { #webapi_data_store } 

使用 *dataStore* 资源，开发人员可以存储任意数据
他们的应用程序。对数据存储密钥的访问基于其共享设置。
默认情况下，所有创建的密钥都可以公开访问（读取和写入）。
此外，对数据存储命名空间的访问仅限于用户的
访问相应的应用程序，如果应用程序保留了命名空间。
例如，有权访问“sampleApp”应用程序的用户也将
能够使用数据存储中的 sampleApp 命名空间。如果一个命名空间
没有保留，使用它不需要特定的访问权限。

    / api / 33 / dataStore

Note that there are reserved namespaces used by the system that require 
special authority to be able to read or write entries. 
For example the namespace for the android settings app `ANDROID_SETTINGS_APP`
will require the `M_androidsettingsapp` authority.

### 数据存储结构 { #webapi_data_store_structure } 

数据存储条目由命名空间、键和值组成。这
命名空间和键的组合是唯一的。值数据类型为 JSON。

Table: Data store structure

| 项目 | 描述 | 数据类型 |
|---|---|---|
| 命名空间 | Namespace for organization of entries. | 串 |
| 键 | Key for identification of values. | 串 |
| 值 | Value holding the information for the entry. | JSON格式 |
| Encrypted | Indicates whether the value of the given key should be encrypted | Boolean |

### 获取键和名称空间 { #webapi_data_store_get_keys_and_namespaces } 

有关所有现有名称空间的列表：

    GET /api/33/dataStore

清单示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore" -u admin:district
```

响应示例：

```json
[
  "foo",
  "bar"
]
```

有关命名空间中所有键的列表：

    GET /api/33/dataStore/<namespace>

清单示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -u admin:district
```

响应示例：

```json
[
  "key_1",
  "key_2"
]
```

要从名称空间检索现有键的值：

    GET /api/33/dataStore/<namespace>/<key>

卷曲请求检索示例：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1"-u admin:district
```

响应示例：

```json
{
  "foo":"bar"
}
```

要从名称空间检索现有键的元数据：

    GET /api/33/dataStore/<namespace>/<key>/metaData

卷曲请求检索示例：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1/metaData" -u admin:district
```

响应示例：

```json
{
  "id": "dsKeyUid001", 
  "created": "...",
  "user": {...},
  "namespace": "foo",
  "key": "key_1"
}
```

### Query API { #query-api } 
The query API is allows you to query and filter values over all keys in a namespace. The `fields` parameter is used to specify the query. This is useful for retrieving specific values of keys across a namespace in a single request. 

    GET /api/dataStore/<namespace>?fields=

The list of `fields` can be:

* empty: returns just the entry keys
* `.`: return the root value as stored
* comma separated list of paths: `<path>[,<path>]`; each `<path>` can be a simple property name (like `age`) or a nested path (like `person.age`) 

Furthermore, entries can be filtered using one or more `filter` parameters 
and sorted using the `order` parameter. 

Multiple filters can be combined using `rootJunction=OR` (default) or `rootJunction=AND`. 

All details on the `fields`, `filter` and `order` parameters are given in the following sections.

#### Paging { #paging } 
By default, results use paging. Use `pageSize` and `page` to adjust size and offset. 
The parameter `paging=false` can be used to opt-out and always return all matches. 
This should be used with caution as there could be many entries in a namespace. The default page size is 50.

    GET /api/dataStore/<namespace>?fields=.&page=2&pageSize=10

When paging is turned off, entries are returned as plain result array as the root JSON structure. The same effect can be achieved while having paged results by using `headless=true`.

```json
{
  "pager": { ... },
  "entries": [...]
}
```
vs.
```json
[...]
```

#### Value extraction { #value-extraction } 
The data store allows extracting entire simple or complex values 
as well as the extraction of parts of complex JSON values.

> **Note**
> 
> For clarity of the examples the responses shown mostly omit the outermost object with the `pager` information
> and the `entries` array that the examples show.

To filter a certain set of fields add a `fields` parameter to the namespace 
query:

    GET /api/dataStore/<namespace>?fields=name,description

This returns a list of all entries having a non-null `name` and/or a 
`description` field like in the following example:

```json
[
  {"key": "key1", "name": "name1", "description": "description1"},
  {"key": "key2", "name": "name2", "description": "description2"}
]
```

If for some reason we even want entries where none of the extracted fields 
is non-null contained in the result list the `includeAll` parameter can be 
added:

    GET /api/dataStore/<namespace>?fields=name,description&includeAll=true

The response now might look like this:

```json
[
  {"key": "key1", "name": "name1", "description": "description1"},
  {"key": "key2", "name": "name2", "description": "description2"},
  {"key": "key3", "name": null, "description": null},
  {"key": "key4", "name": null, "description": null}
]
```

The extraction is not limited to simple root level members but can pick 
nested members as well by using square or round brackets after a members name:

    GET /api/dataStore/<namespace>?fields=name,root[child1,child2]
    GET /api/dataStore/<namespace>?fields=name,root(child1,child2)

The example response could look like this:

```json
[
  { "key": "key1", "name": "name1", "root": {"child1": 1, "child2": []}},
  { "key": "key2", "name": "name2", "root": {"child1": 2, "child2": []}}
]
```

The same syntax works for nested members:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3]]]
    GET /api/dataStore/<namespace>?fields=root(level1(level2(level3)))

Example response here:

```json
[
  { "key": "key1", "root": {"level1": {"level2": {"level3": 42}}}},
  { "key": "key1", "root": {"level1": {"level2": {"level3": 13}}}}
]
```

When such deeply nested values are extracted we might not want to keep the 
structure but extract the leaf member to a top level member in the response.
Aliases can be used to make this happen. An alias can be placed anywhere 
after a member name using `~hoist` followed by the alias in round brackets like so:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3~hoist(my-prop)]]]

The response now would look like this:

```json
[
  { "key": "key1", "my-prop": 42},
  { "key": "key2", "my-prop": 13}
]
```

If the full path should be kept while giving an alias to a nested member the 
parent path needs to be repeated using dot-syntax to indicate the nesting.
This can also be used to restructure a response in a new different structure 
like so:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3~hoist(my-root.my-prop)]]]

The newly structured response now looks like this:

```json
[
  { "key": "key1", "my-root": {"my-prop": 42}},
  { "key": "key2", "my-root": {"my-prop": 13}}
]
```

OBS! An alias cannot be used to rename an intermediate level. However, an alias
could be used to resolve a name collision with the `key` member.

    GET /api/dataStore/<namespace>?fields=id,key~hoist(value-key)

```json
[
  { "key": "key1", "id": 1, "value-key": "my-key1"},
  { "key": "key2", "id": 2, "value-key": "my-key2"}
]
```

### Sorting results { #sorting-results } 
Results can be sored by a single property using the `order=<path>[:direction]` parameter.
This can be any valid value `<path>` or the entry key (use `_` as path).

By default, sorting is alphanumeric assuming the value at the path is a string of mixed type.

For example to extract the name property and also sort the result by it use:

    GET /api/dataStore/<namespace>?fields=name&order=name

To switch to descending order use `:desc`:

    GET /api/dataStore/<namespace>?fields=name&order=name:desc

Sometimes the property sorted by is numeric so alphanumeric interpretation would be confusing.
In such cases special ordering types `:nasc` and `:ndesc` can be used.

In summary, order can be one of the following:

* `asc`: alphanumeric ascending order
* `desc:`: alphanumeric descending order
* `nasc`: numeric ascending order
* `ndesc`: numeric descending order

> **OBS!**
> 
> When using numeric order all matches must have a numeric value for the property at the provided `<path>`.

### Filtering entries { #filtering-entries } 
To filter entries within the query API context add one or more `filter` parameters
while also using the `fields` parameter.

Each `filter` parameter has the following form:

* unary operators: `<path>:<operator>`
* binary operators: `<path>:<operator>:<value>`
* set operators: `<path>:<operator>:[<value>,<value>,...]`

Unary operators are:

| Operator | 描述 |
| -------- | ----------- |
| `null`   | value is JSON `null` |
| `!null`  | value is defined but different to JSON `null` |
| `empty`  | value is an empty object, empty array or JSON string of length zero |
| `!empty` | value is different to an empty object, empty array or zero length string |

Binary operators are:

| Operator | 描述 |
| -------- | ----------- |
| `eq`     | value is equal to the given boolean, number or string |
| `!eq`, `ne`, `neq` | value is not equal to the given boolean, number or string |
| `lt`     | value is numerically or alphabetically less than the given number or string |
| `le`     | value is numerically or alphabetically less than or equal to the given number or string |
| `gt`     | value is numerically or alphabetically greater than the given number or string |
| `ge`     | value is numerically or alphabetically greater than or equal to the given number or string |

Text pattern matching binary operators are:

| Operator | Case Insensitive |  描述 |
| -------- | ---------------- | ----------- |
| `like`   | `ilike`          | value matches the text pattern given |
| `!like`  | `!ilike`         | value does not match the text pattern given |
| `$like`  | `$ilike`, `startswith`   | value starts with the text pattern given |
| `!$like` | `!$ilike`, `!startswith` | value does not start with the text pattern given |
| `like$`  | `ilike$`, `endswith`     | value ends with the text pattern given |
| `!like$` | `!ilike$`, `!endswith`   | value does not end with the text pattern given |

For operators that work for multiple JSON node types the semantic is determined from the provided value.
If the value is `true` or `false` the filter matches boolean JSON values.
If the value is a number the filter matches number JSON values.
Otherwise, the value matches string JSON values or mixed types of values.

> **Tip**
>
> To force text comparison for a value that is numeric quote the value in single quotes.
> For example, the value `'13'` is the text 13 while `13` is the number 13.  

Set operators are:

| Operator | 描述 |
| -------- | ----------- |
| `in`     | entry value is textually equal to one of the given values (is in set) |
| `!in`    | entry value is not textually equal to any of the given values (is not in set) |

The `<path>` can be:

* `_`: the entry key is
* `.`: the entry root value is
* `<member>`: the member of the root value is
* `<member>.<member>`: the member at the path is (up to 5 levels deep)

A `<member>` path expression can be a member name or in case of arrays an array index.
In case of an array the index can also be given in the form: `[<index>]`.
For example, the path `addresses[0].street` would be identical to `addresses.0.street`.

Some example queries are found below.

Name (of root object) is "Luke":

    GET /api/dataStore/<namespace>?fields=.&filter=name:eq:Luke

Age (of root object) is greater than 42 (numeric):

    GET /api/dataStore/<namespace>?fields=.&filter=age:gt:42

Root value is a number greater than 42 (numeric matching inferred from the value):

    GET /api/dataStore/<namespace>?fields=.&filter=.:gt:42

Enabled (of root object) is true (boolean matching inferred from the value):

    GET /api/dataStore/<namespace>?fields=.&filter=enabled:eq:true

Root object has name containing "Pet" and has an age greater than 20:

    GET /api/dataStore/<namespace>?fields=.&filter=name:like:Pet&filter=age:gt:20

Root object is either flagged as minor or has an age less than 18:

    GET /api/dataStore/<namespace>?fields=.&filter=minor:eq:true&filter=age:lt:18&rootJunction=or

### 创造价值 { #webapi_data_store_create_values } 

为命名空间创建新的键和值：

    POST / api / 33 / dataStore / <namespace> / <key>

假设有效的JSON有效负载，创建示例的curl请求：

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X POST
  -H "Content-Type: application/json" -d "{\"foo\":\"bar\"}" -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'key_1' created."
}
```

如果您需要加密存储的数据（例如用户
凭据或类似的），您可以像这样将查询附加到 url：

    GET /api/33/dataStore/<namespace>/<key>?encrypt=true

### 更新值 { #webapi_data_store_update_values } 

更新命名空间中存在的密钥：

    PUT /api/33/dataStore/<namespace>/<key>

假设有效的JSON有效负载，示例curl请求更新：

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X PUT -d "[1, 2, 3]"
  -H "Content-Type: application/json" -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' updated."
}
```

### 删除键 { #webapi_data_store_delete_keys } 

要从名称空间中删除现有键：

    删除/ api / 33 / dataStore / <namespace> / <key>

删除示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X DELETE -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' deleted from namespace 'foo'."
}
```

要删除名称空间中的所有键：

    删除/ api / 33 / dataStore / <namespace>

删除示例curl请求：

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -X DELETE -u admin:district
```

响应示例：

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Namespace 'foo' deleted."
}
```

### Sharing data store keys { #webapi_data_store_sharing } 

Sharing of data store keys follows the same principle as for other metadata sharing (see
[Sharing](#webapi_sharing)).

To get sharing settings for a specific data store key:

    GET /api/33/sharing?type=dataStore&id=<uid>

Where the id for the data store key comes from the `/metaData` endpoint for that key:

    GET /api/33/dataStore/<namespace>/<key>/metaData

As usual the `access` property in the response reflects the capabilities of the 
current user for the target entry.
Namespace wide protection might still apply and render a user incapable to
perform certain changes.

To modify sharing settings for a specific data store key:

    POST / api / 33 / sharing？type = dataStore＆id = <uid>

具有以下要求：

```json
{
  "object": {
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userAccesses": [],
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

## 用户数据存储 { #webapi_user_data_store } 

除了在所有用户之间共享的 *dataStore*
系统，还可以使用基于用户的数据存储。数据存储到
*userDataStore* 与单个用户相关联，以便每个用户
在相同的命名空间和组合键上可以有不同的数据。全部
对 *userDataStore* 的调用将与登录的
用户。这意味着只能查看、更改、删除和添加值
与当前登录的用户相关联。

    / api / 33 / userDataStore

### 用户数据存储结构 { #webapi_user_data_store_structure } 

*userDataStore* 由用户、命名空间、键和关联的
值。用户、命名空间和密钥的组合是唯一的。

Table: User data store structure

| 项目 | 描述 | Data Type |
|---|---|---|
| 用户 | The user this data is associated with | 串 |
| 命名空间 | The namespace the key belongs to | 串 |
| 键 | The key a value is stored on | 串 |
| 值 | The value stored | JSON格式 |
| Encrypted | Indicates whether the value should be encrypted | Boolean |

### 获取名称空间 { #webapi_user_data_store_get_namespaces } 

返回所有现有名称空间的数组

    GET /api/33/userDataStore

请求示例：

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore"
```

```json
[
  "foo",
  "bar"
]
```

### 取得金钥 { #webapi_user_data_store_get_keys } 

返回给定名称空间中所有现有键的数组

    GET /api/userDataStore/<namespace>

请求示例：

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
[
  "key_1",
  "key_2"
]
```

### 获取价值 { #webapi_user_data_store_get_values } 

返回给定名称空间和键的值

    GET /api/33/userDataStore/<namespace>/<key>

请求示例：

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "some": "value"
}
```

### 创造价值 { #webapi_user_data_store_create_values } 

向给定名称空间中的给定键添加新值。

    POST / api / 33 / userDataStore / <namespace> / <key>

请求示例：

```bash
curl -X POST -H "Content-Type: application/json" -u admin:district -d "['some value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'bar' in namespace 'foo' created."
}
```

如果您需要加密该值（例如用户凭据
等等）您可以像这样将查询附加到网址：

    GET /api/33/userDataStore/<namespace>/<key>?encrypt=true

### 更新值 { #webapi_user_data_store_update_values } 

更新现有值

    PUT /api/33/userDataStore/<namespace>/<key>

请求示例：

```bash
curl -X PUT -H "Content-Type: application/json" -u admin:district -d "['new value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"Created",
  "httpStatusCode":201,
  "status":"OK",
  "message":"Key 'bar' in namespace 'foo' updated."
}
```

### 删除键 { #webapi_user_data_store_delete_key } 

删除金钥

    删除/ api / 33 / userDataStore / <namespace> / <key>

请求示例：

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"Key 'bar' deleted from the namespace 'foo."
}
```

### 删除名称空间 { #webapi_user_data_store_delete_namespace } 

删除给定名称空间中的所有键

    删除/ api / 33 / userDataStore / <namespace>

请求示例：

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"All keys from namespace 'foo' deleted."
}
```

### Admin Access to another User's Datastore { #admin-access-to-another-users-datastore } 
Admins can manipulate another user's datastore by adding the `username`
parameter to any of the manipulations described above to not have them affect
the admins own datastore but the datastore of the user given by the `username`
parameter.

For example, to add a value to `Peter`'s datastore an admin uses:

    POST /api/userDataStore/<namespace>/<key>?username=Peter



# Organisation unit profile { #org_unit_profile }

The organisation unit profile resource allows you to define and retrieve an information profile for organisation units in DHIS 2.

```
/api/organisationUnitProfile
```

A single organisation unit profile can be created and applies to all organisation units.

The information part of the organisation unit profile includes:

- Name, short name, description, parent organisation unit, level, opening date, closed date, URL.
- Contact person, address, email, phone number (if exists).
- Location (longitude/latitude).
- Metadata attributes (configurable).
- Organisation unit group sets and groups (configurable).
- Aggregate data for data elements, indicators, reporting rates, program indicators (configurable).

## Create organisation unit profile { #create-organisation-unit-profile } 

To define the organisation unit profile you can use a `POST` request:

```
POST /api/organisationUnitProfile
```

The payload in JSON format looks like this, where `attributes` refers to metadata attributes,  `groupSets` refer to organisation unit group sets and `dataItems` refers to data elements, indicators, data sets and program indicators:

```json
{
  "attributes": [
    "xqWyz9jNCA5",
    "n2xYlNbsfko"
  ],
  "groupSets": [
    "Bpx0589u8y0",
    "J5jldMd8OHv"
  ],
  "dataItems": [
    "WUg3MYWQ7pt",
    "vg6pdjObxsm",
    "DTVRnCGamkV",
    "Uvn6LCg7dVU",
    "eTDtyyaSA7f"
  ]
}
```

The `F_ORG_UNIT_PROFILE_ADD` authority is required to define the profile.

## Get organisation unit profile { #get-organisation-unit-profile } 

To retrieve the organisation unit profile definition you can use a `GET` request:

```
GET /api/organisationUnitProfile
```

The response will be in JSON format.

## Get organisation unit profile data { #get-organisation-unit-profile-data } 

To retrieve the organisation unit profile data you can use a `GET` request:

```
GET /api/organisationUnitProfile/{org-unit-id}/data?period={iso-period}
```

The organisation unit profile data endpoint will combine the profile definition with the associated information/data values. 

* The `org-unit-id` path variable is required and refers to the ID of the organisation unit to provide aggregated data for.
* The `iso-period` query parameter is optional and refers to the ISO period ID for the period to provide aggregated data for the data items. If none is specified, the _this year_ relative period will be used as fallback.

The response will include the following sections:

* `info`: Fixed information about the organisation unit.
* `attributes`: Metadata attributes with corresponding attribute values.
* `groupSets`: Organisation unit group sets with the corresponding organisation unit group which the organisation unit is a member of.
* `dataItems`: Data items with the corresponding aggregated data value.

Note that access control checks are performed and metadata items which are not accessible to the current user will be omitted.

请求示例如下所示：

```
GET /api/organisationUnitProfile/DiszpKrYNg8/data?period=2021
```

The profile data response payload in JSON format will look like this, where the `id` and `label` fields refer to the metadata item, and the `value` field refers to the associated value:

```json
{
  "info": {
    "id": "DiszpKrYNg8",
    "code": "OU_559",
    "name": "Ngelehun CHC",
    "shortName": "Ngelehun CHC",
    "parentName": "Badjia",
    "level": 4,
    "levelName": "Facility",
    "openingDate": "1970-01-01T00:00:00.000",
    "longitude": -11.4197,
    "latitude": 8.1039
  },
  "attributes": [
    {
      "id": "n2xYlNbsfko",
      "label": "NGO ID",
      "value": "GHE51"
    },
    {
      "id": "xqWyz9jNCA5",
      "label": "TZ code",
      "value": "NGE54"
    }
  ],
  "groupSets": [
    {
      "id": "Bpx0589u8y0",
      "label": "Facility Ownership",
      "value": "Public facilities"
    },
    {
      "id": "J5jldMd8OHv",
      "label": "Facility Type",
      "value": "CHC"
    }
  ],
  "dataItems": [
    {
      "id": "WUg3MYWQ7pt",
      "label": "Total Population",
      "value": 3503
    },
    {
      "id": "DTVRnCGamkV",
      "label": "Total population < 1 year",
      "value": 140
    },
    {
      "id": "vg6pdjObxsm",
      "label": "Population of women of child bearing age (WRA)",
      "value": 716
    },
    {
      "id": "Uvn6LCg7dVU",
      "label": "ANC 1 Coverage",
      "value": 368.2
    },
    {
      "id": "eTDtyyaSA7f",
      "label": "FIC <1y",
      "value": 291.4
    }
  ]
}
```

## Upload image for organisation unit { #upload-image-for-organisation-unit } 

To upload an image for an organisation unit you can use the `fileResources` endpoint.

```
/api/fileResources
```

The `fileResource` endpoint accepts a raw file as the request body. The `JPG`, `JPEG` and `PNG` formats are supported for organisation unit images. The domain for organisation unit images is `ORG_UNIT`.

Please consult *File resources* in the *Metadata* section for details about the `fileResources` endpoint. 

To upload an image you can send a `POST` request with `ORG_UNIT` as domain query parameter together with the image as the request payload. The `Content-Type` header should match the type of file being uploaded.

```
POST /api/fileResources?domain=ORG_UNIT
```

The `id ` property of the `response` > `fileResource` object in the JSON response will contain a reference to the identifier of the file resource.

The organisation unit entity has an `image` property which refers to the file resource image. To set the file resource reference on an organisation unit you can send a `PATCH` request to the organisation unit with a JSON payload:

```
PATCH /api/organisationUnits/{id}
```

```json
{ 
  "image": "{file-resource-id}" 
}
```

Alternatively, you can use a `PUT` request with the full organisation unit payload (fields omitted for brevity):

```
PUT /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-iid}"
  }
}
```

## Get image for organisation unit { #get-image-for-organisation-unit } 

The organisation unit entity has an `image` object which refers to a file resource by identifier. You can get the organisation unit information from the `organisationUnits` endpoint. If set, the JSON format looks like this:

```
GET /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-id}"
  }
}
```

The image file resource identifier can be used to make a request to the `fileResources` endpoint to retrieve the file content:

```
GET /api/fileResources/{id}/data
```

The `Content-Type` header will reflect the type of file being retrieved.



# 应用 { #apps } 

## 应用 { #webapi_apps } 

`/api/apps` 端点可用于安装、删除和
列出应用程序。应用程序密钥基于应用程序名称，但与所有
删除了非字母数字字符，并用破折号替换了空格。
*My app!* 将返回密钥 *My-app*。

> **注意**
>
> 在 2.28 之前，应用密钥是从 ZIP 的名称派生的
> 存档，不包括文件扩展名。使用旧格式的 URL
> 仍应在 api 中返回正确的应用程序。

    / api / 33 / apps

### 获取应用 { #webapi_get_apps } 

> **注意**
>
> 2.28之前的app属性folderName指的是实际
> 已安装应用程序的路径。能够在云上存储应用程序
> 服务，folderName 的用途已更改，现在将引用应用程序
> 键。

您可以通过列出应用程序中的所有应用程序来读取应用程序的密钥
资源并查找 *key* 属性。列出所有已安装的应用程序
JSON：

```bash
curl -u user:pass -H "Accept: application/json" "http://server.com/api/33/apps"
```

您也可以简单地将Web浏览器指向资源URL：

    http://server.com/api/33/apps

应用列表也可以按应用类型和名称过滤，通过附加
URL 的一个或多个 *filter* 参数：

    http://server.com/api/33/apps?filter=appType:eq:DASHBOARD_APP&filter=name:ilike:youtube

应用程序名称支持 *eq* 和 *ilike* 过滤器运算符，而 *appType*
仅支持 *eq*。

### 安装应用 { #webapi_install_app } 

要安装应用程序，可以发出以下命令：

```bash
curl -X POST -u user:pass -F file=@app.zip "http://server.com/api/33/apps"
```

### 删除应用 { #webapi_delete_app } 

要删除一个应用程序，您可以发出以下命令：

```bash
curl -X DELETE -u user:pass "http://server.com/api/33/apps/<app-key>"
```

### 重新加载应用 { #webapi_reload_apps } 

要强制重新加载当前安装的应用程序，您可以发出
以下命令。如果您直接手动添加文件，这很有用
到文件系统，而不是通过 DHIS2 用户上传
界面。

```bash
curl -X PUT -u user:pass "http://server.com/api/33/apps"
```

### 在实例之间共享应用 { #webapi_share_apps_between_instances } 

如果 DHIS2 实例已配置为使用云存储，应用程序
现在将安装并存储在云服务上。这将启用
多个实例在已安装的应用程序上共享相同的版本，而不是
在每个单独的实例上安装相同的应用程序。

> **注意**
>
> 在 2.28 之前，安装的应用程序只会存储在实例的
> 本地文件系统。 2.28 之前安装的应用程序仍可在
> 实例已安装，但不会与其他人共享
> 实例，因为它仍然位于实例本地文件系统上。

## 应用商店 { #webapi_app_store } 

The Web API exposes the content of the DHIS2 App Store as a JSON
representation which can found at the `/api/appHub` resource.

    /api/33/appHub

### 获取应用 { #webapi_get_app_store_apps } 

您可以使用GET请求检索应用程序：

    GET /api/33/appHub

JSON响应示例如下所述。

```json
{
  [
    {
      "name": "Tabular Tracker Capture",
      "description": "Tabular Tracker Capture is an app that makes you more effective.",
      "sourceUrl": "https://github.com/dhis2/App-repository",
      "appType": "DASHBOARD_WIDGET",
      "status": "PENDING",
      "id": "NSD06BVoV21",
      "developer": {
        "name": "DHIS",
        "organisation": "Uio",
        "address": "Oslo",
        "email": "dhis@abc.com",
      },
      "versions": [
        {
          "id": "upAPqrVgwK6",
          "version": "1.2",
          "minDhisVersion": "2.17",
          "maxDhisVersion": "2.20",
          "downloadUrl": "https://dhis2.org/download/appstore/tabular-capture-12.zip",
          "demoUrl": "http://play.dhis2.org/demo"
        }
      ],
      "images": [
        {
          "id": "upAPqrVgwK6",
          "logo": "true",
          "imageUrl": "https://dhis2.org/download/appstore/tabular-capture-12.png",
          "description": "added feature snapshot",
          "caption": "dialog",
        }
      ]
    }
  ]
}
```

### 安装应用 { #webapi_install_app_store_apps } 

您可以在 DHIS2 实例上安装应用程序，前提是您拥有
适当的权限。使用 `id` 属性引用应用程序
应用程序的相关版本。使用 POST 安装应用程序
使用版本 ID 请求以下资源：

    POST /api/33/appHub/{app-version-id}



# OpenAPI { #openapi } 

The DHIS2 server can provide an OpenAPI document for its API.
This document is created on the fly from analysis of the actual API.
It means the document is complete but details may be lost or misrepresented
due to limitations in the analysis.

Both JSON and YAML format are supported by all OpenAPI endpoints.
YAML should be requested with `Accept` header of `application/x-yaml`.

To fetch a single document containing all endpoints of the server use:

    GET /api/openapi.json
    GET /api/openapi.yaml

OBS! Be aware that this generates a document that is several MBs in size.

A document for a specific endpoint can be accessed by appending either 
`openapi.json` or `openapi.yaml` to an endpoint root path. 
For example, to generate a document for the `/users` endpoints use:

    GET /api/users/openapi.json
    GET /api/users/openapi.yaml

To generate a document with a specific selection of root paths and/or tags the
general `/openapi` endpoint can be used with one or more `tag` and `path`
selectors.

    GET /api/openapi/openapi.json?path=/users&path=/dataElements
    GET /api/openapi/openapi.yaml?tag=system&tag=metadata

Available tags are:

* `user`
* `data`
* `metadata`
* `ui`
* `analytics`
* `system`
* `messaging`
* `tracker`
* `integration`
* `login`
* `query`
* `management`
