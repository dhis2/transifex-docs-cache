---
revision_date: '2024-02-16'
tags:
- DHIS Version 2.40
- Gestion
template: single.html
---

# Installation { #installation }

Le chapitre sur l'installation fournit des informations sur comment installer DHIS2 dans différents contextes, notamment sur le serveur central en ligne, le réseau local hors ligne, l'application autonome et le package autonome appelé DHIS2 Live.

## Présentation { #install_introduction }

DHIS2 fonctionne sur toutes les plateformes pour lesquelles il existe un JDK Java, ce qui inclut les systèmes d'exploitation les plus courants tels que Windows, Linux et Mac. Il fonctionne également sur le système de base de données PostgreSQL. DHIS2 est présenté sous la forme d'une archive Web Java standard (fichier WAR) et fonctionne donc sur tous les conteneurs Servlet tels que Tomcat et Jetty.

L'équipe de DHIS2 recommande le système d'exploitation Ubuntu 18.04 LTS, le système de base de données PostgreSQL et le conteneur Tomcay Servlet comme cadre approprié pour les installations de serveurs.

Ce chapitre fournit un guide pour la configuration de la teck stack (pile technologique) ci-dessus. Il doit cependant être lu comme un guide opérationnel et non comme une documentation complète pour l'environnement mentionné. Nous nous référons à la documentation officielle d'Ubuntu, PostgreSQL et Tomcat pour des informations détaillées.

Le package Ubuntu `dhis2-tools` automatise la plupart des tâches décrites dans le guide ci-dessous et est recommandé pour la plupart des utilisateurs, en particulier ceux qui ne maîtrisent pas la ligne de commande ou l'administration des serveurs. Il est décrit plus en détail dans un des chapitres de ce guide.

## Spécifications du serveur { #install_server_specifications }

DHIS2 est une application très exigeante en matière de base de données et nécessite que votre serveur ait suffisamment de mémoire vive, de cœurs d'unité centrale et de disques rapides. Ces recommandations doivent être considérées comme des règles de base et non comme des mesures exactes. DHIS2 évolue de façon linéaire en fonction de la quantité de RAM et du nombre de cœurs de CPU. Plus vous en avez, mieux l'application performe.

- *RAM :* Au moins 2 Go pour une petite instance, 12 Go pour une instance moyenne, 64 Go ou plus pour une grande instance.
- *Cœurs CPU :* 4 cœurs CPU pour une petite instance, 8 cœurs CPU  pour une instance moyenne, 16 cœurs CPU ou plus pour une grande instance.
- *Disque :* Le SSD est recommandé comme périphérique de stockage. La vitesse de lecture
  minimum est de 150 Mb/s ; 200 Mb/s est bon ; 350 Mb/s ou plus est
  l'idéal. Au moins 100 Go d'espace de stockage sont recommandés, mais
  cela dépendra entièrement de la quantité de données contenues dans le
  tableaux des valeurs de données. Les tables d'analyse nécessitent une quantité importante
  d'espace de stockage. Faites une planification à l’avance et assurez-vous que votre serveur puise être amélioré 
  avec plus d'espace disque si nécessaire.

## Configuration logicielle requise { #install_software_requirements }

Les versions ultérieures de DHIS2 nécessitent les versions logicielles suivantes pour fonctionner.

- Un système d'exploitation pour lequel un Java JDK ou JRE version 8 ou 11 existe. Linux est recommandé.
- JavaJDK. OpenJDK est recommandé.
    - Pour DHIS 2 version 2.38 et plus, JDK 11 est requis.
    - Pour DHIS 2 version 2.35 et plus, JDK 11 est recommandé et JDK 8 ou plus est requis.
    - Pour les versions DHIS 2 antérieures à 2.35, JDK 8 est requis.
- PostgreSQL database version 9.6 ou plus. Une version ultérieure de PostgreSQL telle que la version 14 est recommandée.
- Extension de base de données PostGIS version 2.2 ou plus.
- Conteneur de servlet Tomcat version 8.5.50 ou plus, ou autre API de servlet
  Conteneurs de servlets compatibles 3.1.
- Configuration du cluster uniquement (facultatif) : entrepôt de données Redis version 4 ou ultérieure.

## Configuration du serveur { #install_server_setup }

Cette section décrit la configuration d'une instance de serveur DHIS2 sur Ubuntu 18.04 64 bit avec PostgreSQL comme système de base de données et Tomcat comme conteneur Servlet. Ce guide n'est pas un guide étape par étape, mais plutôt une référence sur la façon dont DHIS2 peut être installé sur un serveur. Il existe plusieurs stratégies d'installation possibles, qui diffèrent en fonction du système d'exploitation et de la base de données que vous utilisez, ainsi que d'autres facteurs. Le terme *invoquer* fait référence à l'exécution d'une commande donnée dans un terminal.

Pour ce guide, nous supposons que 8 Go de RAM sont alloués à PostgreSQL de même qu'à Tomcat/JVM, et qu'un système d'exploitation de 64 bits est utilisé. *Si vous utilisez une configuration différente, veuillez ajuster les valeurs suggérées en conséquence\!*

Nous recommandons que la mémoire disponible soit répartie de manière presque équitable entre la base de données et la JVM. N'oubliez pas d'accorder une partie de la mémoire physique au système d'exploitation pour qu'il puisse effectuer ses tâches, par exemple 2 Go environ. Les étapes marquées comme *facultatives*, comme l'étape de réglage des performances, peuvent être effectuées ultérieurement.

### Création d'un utilisateur pour exécuter DHIS2 { #install_creating_user }

Vous devriez créer un utilisateur dédié pour lancer DHIS2.

> **Important**
>
> Vous ne devez pas exécuter le serveur DHIS2 en tant qu'utilisateur privilégié tel que super-utilisateur.

Créez un nouvel utilisateur appelé "dhis" en appelant :

```sh
sudo useradd -d /home/dhis -m dhis -s /bin/false
```

Ensuite, pour définir le mot de passe de votre compte, appelez :

```sh
sudo passwd dhis
```

Créez un mot de passe sécurisé comportant au moins 15 caractères aléatoires.

### Création du répertoire de configuration { #install_creating_config_directory }

Commencez par créer un répertoire adapté aux fichiers de configuration de DHIS2. Ce répertoire sera également utilisé pour les applications, les fichiers et les fichiers journaux. Voici un exemple de répertoire :

```sh
mkdir /home/dhis/config
chown dhis:dhis /home/dhis/config
```

DHIS2 recherchera une variable d'environnement appelée `DHIS2_HOME` pour localiser son répertoire de configuration. Ce répertoire sera appelé `DHIS2_HOME` dans ce guide d'installation. Nous définirons la variable d'environnement lors d'une étape ultérieure du processus d'installation.

Si aucune variable d'environnement `DHIS2_HOME` n'est trouvée, l'emplacement du fichier de configuration par défaut `/opt/dhis2` est utilisé.

### Définition du fuseau horaire et de l'emplacement du serveur { #install_setting_server_tz }

Il peut être nécessaire de reconfigurer le fuseau horaire du serveur pour qu'il corresponde au fuseau horaire de l'endroit que le serveur DHIS2 couvrira. Si vous utilisez un serveur privé virtuel, le fuseau horaire par défaut peut ne pas correspondre au fuseau horaire de l'emplacement de votre DHIS2. Vous pouvez facilement reconfigurer le fuseau horaire en appelant la commande ci-dessous et en suivant les instructions.

```sh
sudo dpkg-reconfigure tzdata
```

PostgreSQL est sensible aux paramètres régionaux. Vous devrez donc installer votre emplacement en premier. Pour vérifier les paramètres régionaux existants et en installer de nouveaux (par exemple, Norvégien):

```sh
locale -a
sudo locale-gen nb_NO.UTF-8
```

### Installation de PostgreSQL { #install_postgresql_installation }

Installez PostgreSQL en appelant :

```sh
sudo apt-get install -y postgresql-12 postgresql-12-postgis-3
```

Créez un utilisateur non privilégié appelé *dhis* en appelant :

```sh
sudo -u postgres createuser -SDRP dhis
```

Entrez un mot de passe sécurisé à l'invite. Créez une base de données en appelant :

```sh
sudo -u postgres createdb -O dhis dhis2
```

Revenez à votre session en appelant `exit` (sortir). Vous avez maintenant un utilisateur PostgreSQL appelé *dhis* et une base de données appelée *dhis2*.

L'extension *PostGIS* est nécessaire au fonctionnement de plusieurs fonctions SIG/cartographie. DHIS 2 tentera d'installer l'extension PostGIS lors du démarrage. Si l'utilisateur de la base de données DHIS 2 n'a pas l'autorisation de créer des extensions, vous pouvez la créer à partir de la console en utilisant l'utilisateur *postgres* avec les commandes suivantes :

```sh
sudo -u postgres psql -c "create extension postgis;" dhis2
```

Pour ajouter des index trigrammes et les combiner avec des types de colonnes primitifs, deux extensions doivent être créées dans la base de données pour DHIS 2 version 2.38 et plus. Les extensions font déjà partie de l'installation par défaut de posgresql :

```sh
sudo -u postgres psql -c "create extension btree_gin;" dhis2
sudo -u postgres psql -c "create extension pg_trgm;" dhis2
```

Quittez la console et revenez à votre utilisateur précédent en entrant *\\q* suivi de *exit* (quitter).

### Optimisation des performances de PostgreSQL { #install_postgresql_performance_tuning }

Le réglage de PostgreSQL est nécessaire pour obtenir un système performant, mais facultatif pour le fonctionnement de DHIS2. Les différents paramètres peuvent être spécifiés dans le fichier de configuration `postgresql.conf` ou, de préférence, dans un fichier spécifique du répertoire `conf.d`'. Les paramètres sont basés sur l'allocation de 8 Go de RAM à PostgreSQL et doivent être ajustés en fonction de l'environnement.

```sh
sudo nano /etc/postgresql/12/main/postgresql.conf
```

Définissez les propriétés suivantes.

```properties
max_connections = 200
```

Détermine le nombre maximum de connexions autorisées par PostgreSQL.

```properties
shared_buffers = 3GB
```

Détermine la quantité de mémoire à allouer exclusivement à la mise en cache de PostgreSQL. Ce paramètre contrôle la taille de la mémoire partagée du noyau qui doit être réservée à PostgreSQL. Il doit être fixé à environ 40% de la mémoire totale dédiée à PostgreSQL.

```properties
work_mem = 24MB
```

Détermine la quantité de mémoire utilisée pour les opérations internes de tri et de hachage. Ce paramètre s'applique à chaque connexion et à chaque requête, de sorte qu'une grande quantité de mémoire peut être consommée si cette valeur est trop élevée. Il est essentiel de définir correctement cette valeur pour optimiser les performances d'agrégation de DHIS2.

```properties
maintenance_work_mem = 1GB
```

Détermine la quantité de mémoire que PostgreSQL peut utiliser pour les opérations de maintenance telles que la création d'index, l'exécution du vacuum et l'ajout de clés étrangères. Augmenter cette valeur peut améliorer les performances de création d'index pendant les processus de génération d'analyses.

```properties
temp_buffers = 16MB
```

Définit le nombre maximum de tampons temporaires utilisés par chaque session de la base de données. Il s'agit de tampons locaux utilisés uniquement pour l'accès aux tableaux temporaires.

```properties
effective_cache_size = 8GB
```

Estimation de la quantité de mémoire disponible pour la mise en cache du disque par le système d'exploitation (il ne s'agit pas d'une allocation) ; elle est utilisée par PostgreSQL pour déterminer si un plan de requête tiendra ou non dans la mémoire. Définir une valeur plus élevée que la mémoire disponible entraînera de mauvaises performances. Cette valeur doit être incluse dans le paramètre `shared_buffers`. PostgreSQL a deux couches de cache : La première couche utilise la mémoire partagée du noyau et est contrôlée par le paramètre shared_buffers. PostgreSQL délègue la seconde couche au cache disque du système d'exploitation et la taille de la mémoire disponible peut être fournie avec le paramètre `effective_cache_size`.

```properties
checkpoint_completion_target = 0.8
```

Définit la mémoire utilisée pour la mise en mémoire tampon pendant le processus d'écriture WAL. Augmenter cette valeur peut améliorer le débit dans les systèmes à forte densité d'écriture.

```properties
synchronous_commit = off
```

Spécifie si les transactions doivent attendre que les enregistrements WAL soient écrits sur le disque avant d'être renvoyées au client ou non. Si cette option est désactivée, les performances seront considérablement améliorées. Cela implique également qu'il y aura un léger décalage entre le moment où la transaction au client est déclarée réussie et le moment où elle est réellement sûre, mais l'état de la base de données ne peut pas être corrompu et c'est une bonne alternative pour les systèmes exigeants en termes de performances et d'écriture comme DHIS2.

```properties
wal_writer_delay = 10s
```

Spécifie le décalage entre les opérations d'écriture WAL. Y définir une valeur élevée permettra d'améliorer les performances des systèmes à forte densité d'écriture, car de nombreuses opérations d'écriture peuvent être exécutées en un seul vidage sur le disque.

```properties
random_page_cost = 1.1
```

*SSD uniquement*: Définit l'estimation par le planificateur de requêtes du coût d'une page de disque non extraite de manière séquentielle. Une valeur faible incitera le système à préférer les scans d'index aux scans séquentiels. Une valeur faible convient aux bases de données qui fonctionnent sur des disques SSD ou qui sont massivement mises en cache dans la mémoire. La valeur par défaut est 4.0, ce qui est raisonnable pour les disques traditionnels.

```properties
max_locks_per_transaction = 96
```

Spécifie le nombre moyen de verrous d'objets alloués pour chaque transaction. Cette valeur est principalement définie pour permettre la réalisation des mises à niveau de routine qui touchent un grand nombre de tableaux.

```properties
track_activity_query_size = 8192
```

Spécifie le nombre d'octets réservés au suivi de la commande en cours d'exécution pour chaque session active. Il permet d'afficher la chaîne de requête complète pour la surveillance des requêtes en cours d'exécution.

Redémarrez PostgreSQL en appelant la commande suivante :

```sh
sudo systemctl restart postgresql
```

### Installation de Java { #install_java_installation }

Le JDK Java recommandé pour DHIS 2 est OpenJDK 11 (pour les version 2.35 et plus). Vous pouvez l'installer avec la commande suivante :

```
sudo apt-get install -y openjdk-11-jdk
```

Si vous préférez OpenJDK 8 (pour les versions antérieures à la 2.35), vous pouvez l'installer avec cette commande :

```
sudo apt-get install -y openjdk-8-jdk
```

Vérifiez que votre installation est correcte en appelant :

```
java -version
```

### Configuration de DHIS2 { #install_database_configuration }

Les informations de connexion à la base de données sont fournies à DHIS2 via un fichier de configuration appelé `dhis.conf`. Créez ce fichier et sauvegardez-le dans le répertoire `DHIS2_HOME`. À titre d'exemple, cet emplacement pourrait être :

```sh
/home/dhis/config/dhis.conf
```

Un fichier de configuration pour PostgreSQL correspondant à la configuration ci-dessus a les propriétés suivantes :

```propriétés
# ------------------------------------------------- ---------------------
# Connexion à la base de données
# ------------------------------------------------- ---------------------

# Classe de pilote JDBC
connexion.driver_class = org.postgresql.Driver

# URL de connexion à la base de données
connexion.url = jdbc:postgresql:dhis2

# Nom d'utilisateur de la base de données
connexion.nom d'utilisateur = dhis

# Mot de passe de la base de données
connexion.mot de passe = xxxx

# ------------------------------------------------- ---------------------
# Serveur
# ------------------------------------------------- ---------------------

# Activer les paramètres sécurisés si déployé sur HTTPS, par défaut 'off', peut être 'on'
# serveur.https = activé

# URL de base du serveur
# serveur.base.url = https://serveur.com
```

Il est fortement recommandé d'activer le paramètre `server.https` et de déployer DHIS 2 avec un protocole HTTPS crypté. Ce paramètre activera par exemple des cookies sécurisés. Le déploiement HTTPS est requis lorsque ce paramètre est activé.

Le paramètre `server.base.url` fait référence à l'URL à laquelle les utilisateurs finaux accèdent au système sur le réseau.

Notez que le fichier de configuration prend en charge les variables d'environnement. Cela signifie que vous pouvez définir certaines propriétés comme variables d'environnement et les résoudre. C'est le cas de l'exemple suivant où `DB_PASSWD` est le nom de la variable d'environnement :

```properties
connection.password = ${DB_PASSWD}
```

Notez que ce fichier contient le mot de passe de votre base de données DHIS2 en texte clair et qu'il doit donc être protégé contre tout accès non autorisé. Pour ce faire, appelez la commande suivante qui garantit que seul l'utilisateur *dhis* est autorisé à le lire :

```sh
chmod 600 dhis.conf
```

### Installation de Tomcat et DHIS2 { #install_tomcat_dhis2_installation }

Pour installer le conteneur de servlet Tomcat, nous utiliserons le package utilisateur de Tomcat en appelant :

```sh
sudo apt-get install -y tomcat8-user
```

Ce package nous permet de créer facilement une nouvelle instance Tomcat. L'instance sera créée dans le répertoire actuel. Le répertoire personnel de l'utilisateur `dhis` est un emplacement approprié :

```sh
cd /home/dhis/
sudo tomcat8-instance-create tomcat-dhis
sudo chown -R dhis:dhis tomcat-dhis/
```

Ceci créera une instance dans un répertoire appelé `tomcat-dhis`. Notez que le package `tomcat8-user` permet de créer le nombre d'instances DHIS2 souhaité.

Modifiez ensuite le fichier `tomcat-dhis/bin/setenv.sh` et ajoutez les lignes ci-dessous.

* `JAVA_HOME` définit l'emplacement de l'installation du JDK.
* `JAVA_OPTS` transmet les paramètres à la JVM.
    * `-Xms` définit l'allocation initiale de mémoire à l'espace de mémoire du tas Java.
    * `-Xmx` définit l'allocation maximale de mémoire à l'espace mémoire du tas Java. Cela doit refléter la quantité de mémoire que vous voulez allouer à l'application logicielle DHIS 2 sur votre serveur.
* `DHIS2_HOME` définit l'emplacement du fichier de configuration `dhis.conf` pour DHIS 2.

Vérifiez que le chemin des binaires Java est correct car il peut varier d'un système à l'autre. Par exemple, sur les systèmes AMD, vous pouvez voir `/java-11-openjdk amd64`. Vous devez adapter ces valeurs à votre environnement.

```sh
JAVA_HOME='/usr/lib/jvm/java-11-openjdk-amd64/'
JAVA_OPTS='-Xms4000m -Xmx7000m'
DHIS2_HOME='/home/dhis/config'
```

Le fichier de configuration de Tomcat se trouve dans `tomcat-dhis/conf/server.xml`. L'élément qui définit la connexion au DHIS est l'élément *Connector* avec le port 8080. Vous pouvez changer le numéro de port dans l'élément Connector par un autre port si nécessaire. L'attribut `relaxedQueryChars` permet d'autoriser certains caractères dans les URL utilisées par le front-end DHIS2.

```xml
<Connector port="8080" protocol="HTTP/1.1"
  connectionTimeout="20000"
  redirectPort="8443"
  relaxedQueryChars="[]" />
```

L'étape suivante consiste à télécharger le fichier DHIS2 WAR et à le placer dans le répertoire _webapps_ de Tomcat. Vous pouvez télécharger les fichiers DHIS2 WAR à partir de l'emplacement suivant :

```sh
https://releases.dhis2.org/
```

Placez le fichier WAR dans le répertoire `webapps` de Tomcat. Nous voulons nommer le fichier WAR `ROOT.war` afin de le rendre disponible directement sur `localhost` sans chemin de contexte :

```sh
mv dhis.war tomcat-dhis/webapps/ROOT.war
```

DHIS2 ne doit jamais fonctionner en mode utilisateur privilégié. Après avoir modifié le `fichier setenv.sh`, modifiez le script de démarrage pour vous assurer que le script n'a pas été appelé en mode super-utilisateur.

```sh
#!/bin/sh
set -e

if [ "$(id -u)" -eq "0" ]; then
  echo "This script must NOT be run as root" 1>&2
  exit 1
fi

export CATALINA_BASE="/home/dhis/tomcat-dhis"
/usr/share/tomcat8/bin/startup.sh
echo "Tomcat started"
```

### Fonctionnement de DHIS2 { #install_running_dhis2 }

DHIS2 peut désormais être lancé en appelant :

    sudo -u dhis tomcat-dhis/bin/startup.sh

> **Important**
>
> Le serveur DHIS2 ne doit jamais être exécuté en mode super-utilisateur ou autre utilisateur privilégié.

DHIS2 peut être arrêté en appelant :

    sudo -u dhis tomcat-dhis/bin/shutdown.sh

Pour surveiller le comportement de Tomcat, le journal est la principale source d'information. Le journal peut être consulté avec la commande suivante :

    tail -f tomcat-dhis/logs/catalina.out

En supposant que le fichier WAR s'appelle ROOT.war, vous pouvez maintenant accéder à votre instance DHIS2 à l'URL suivante :

    http://localhost:8080

## Configuration de l'entrepôt de fichiers { #install_file_store_configuration }

DHIS2 peut recueillir et stocker des fichiers. Par défaut, les fichiers seront stockés sur le système de fichiers local du serveur qui fait fonctionner DHIS2 dans un répertoire de *fichiers* sous l'emplacement du répertoire externe `DHIS2_HOME`.

Vous pouvez également configurer DHIS2 pour qu'il stocke les fichiers sur des fournisseurs de stockage basés sur le cloud. AWS S3 est le seul fournisseur pris en charge actuellement. Pour activer le stockage sur le cloud, vous devez définir les propriétés supplémentaires suivantes dans votre fichier `dhis.conf` :

```propriétés
# Fournisseur d'entrepôts de fichiers. Actuellement, 'filesystem' et 'aws-s3' sont pris en charge.
filestore.provider = 'aws-s3'

# Répertoire dans le répertoire externe sur le système de fichiers local et le compartiment sur AWS S3
filestore.container = fichiers

# La configuration suivante s'applique uniquement au stockage sur cloud (AWS S3)

# Emplacement du centre de données. Facultatif mais recommandé pour des raisons de performances.
filestore.emplacement = eu-west-1

# Nom d'utilisateur / Clé d'accès sur AWS S3
filestore.identité = xxxx

# Mot de passe / Clé secrète sur AWS S3 (sensible)
filestore.secret = xxxx
```

Cette configuration est un exemple qui reflète les paramètres par défaut et doit être modifiée en fonction de vos besoins. En d'autres termes, vous pouvez l'omettre complètement si vous prévoyez d'utiliser les valeurs par défaut. Si vous voulez utiliser un fournisseur externe, le dernier bloc de propriétés doit être défini, et la propriété *fournisseur* doit être réglée sur un fournisseur pris en charge (actuellement, c'est uniquement AWS S3).

> **Remarque**
>
> Si vous avez configuré le stockage SUR cloud dans dhis.conf, tous les fichiers que vous téléchargez
> ou les fichiers générés par le système utiliseront le stockage sur cloud.

Pour un système de production, la configuration initiale de l'entrepôt de fichiers doit être soigneusement étudiée, car le déplacement des fichiers entre les fournisseurs de stockage tout en conservant l'intégrité des références de la base de données peut s'avérer complexe. Gardez à l'esprit que le contenu de l'entrepôt de fichiers peut contenir des informations sensibles et intégrales et qu'il est recommandé de protéger l'accès au dossier et de s'assurer qu'un plan de sauvegarde est prévu dans le cadre d'une implémentation de production.

> **Remarque**
>
> AWS S3 est le seul fournisseur pris en charge, mais d'autres fournisseurs devraient
> être ajoutés à l'avenir, comme Google Cloud Store et Azure Blob Storage.
> Faites-nous savoir si vous avez un cas d'utilisation pour des fournisseurs supplémentaires.

## Configuration du compte de service Google { #install_google_service_account_configuration }

DHIS2 peut se connecter à plusieurs API de services Google. Par exemple, le SIG de DHIS2 peut utiliser l'API de Google Earth Engine pour charger des couches de cartes. Pour fournir des jetons d'accès à l'API, vous devez configurer un compte de service Google et créer une clé privée :

  - Créez un compte de service Google. Veuillez consulter la [plateforme d'identification
    plateforme](https://developers.google.com/identity/protocols/OAuth2ServiceAccount#overview)
     

  - Visitez la [Console Google Cloud](https://console.cloud.google.com)
    et allez dans API Manager \> Identifiants \> Créer des identifiants \>
    Clé du compte de service. Sélectionnez votre compte de service et JSON comme type de
    clé et cliquez sur Créer.

  - Renommez la clé JSON en *dhis-google-auth.json*.

Après avoir téléchargé le fichier de clé, placez le fichier `dhis-google-auth.json` dans le répertoire `DHIS2_HOME` (le même emplacement que le fichier `dhis.conf`). Cet emplacement pourrait ressembler à ceci :

    /home/dhis/config/dhis-google-auth.json

## Configuration d'OpenID Connect (OIDC) { #install_oidc_configuration } 

DHIS2 prend en charge la couche d'identité de l'OpenID Connect (OIDC) pour une identification unique (IU). L'OIDC est un protocole d'authentification standard qui permet aux utilisateurs de se connecter à un fournisseur d'identité (IdP) comme Google. Une fois que les utilisateurs parviennent à se connecter à leur IdP, ils sont donc automatiquement connectés à DHIS2.

Cette section fournit des informations générales sur l'utilisation de DHIS2 avec un fournisseur OIDC, ainsi que des exemples de configuration complets.

L'authentification du 'code d’autorisation' de DHIS2 OIDC se présente comme suit :

1. Un utilisateur tente de se connecter à DHIS2 et clique sur le bouton du fournisseur OIDC sur la page de connexion.

2. DHIS2 redirige le navigateur vers la page de connexion de l'IdP.

3. S'il n'est pas déjà connecté, l'utilisateur est invité à fournir ses informations d'identification. Une fois authentifié avec succès, l'IdP le redirige vers le serveur DHIS2. La redirection comprend un code d'autorisation unique généré pour l'utilisateur.

4. Le serveur DHIS2 renvoie en interne le code d'autorisation de l'utilisateur au serveur IdP avec son propre identifiant client et ses informations d'identification secrètes client.

5. L'IdP renvoie un jeton d'identification au serveur DHIS2. Ce dernier valide le jeton.

6. Le serveur DHIS2 recherche l'utilisateur interne de DHIS2 avec les informations trouvées dans le jeton d'identification (par défaut, e-mail), autorise l'utilisateur et termine le processus de connexion.

### Conditions requises pour utiliser OIDC avec DHIS2 : { #requirements-for-using-oidc-with-dhis2 }

#### Compte du serveur IdP { #idp-server-account }

Vous devez disposer d'un compte administrateur sur un fournisseur d'identité en ligne (IdP) ou sur un serveur autonome pris en charge par DHIS2.

Les IdP suivants sont actuellement pris en charge et testés :

* Google
* Azure AD
* WSO2
* Okta (Voir le tutoriel : [ici](#configure-openid-connect-with-okta))

Il existe également une configuration de **fournisseur générique** qui peut prendre en charge "n'importe quel" fournisseur compatible avec OIDC.

#### Compte utilisateur DHIS2 { #dhis2-user-account }

Vous devez créer expressément les utilisateurs sur le serveur DHIS2 avant qu'ils puissent se connecter au fournisseur d'identité. Leur importation à partir d'un répertoire externe tel qu'Active Directory n'est pas prise en charge actuellement. La création et la gestion d'utilisateurs avec un magasin d'identités externe ne sont pas pris en charge par la norme OIDC.

#### Requêtes d'IdP et cartographie des utilisateurs { #idp-claims-and-mapping-of-users } 

Pour se connecter à DHIS2 avec l'OIDC, l'utilisateur doit être enregistré dans l'IdP et ensuite connecté à un compte utilisateur précréé dans DHIS2. L'OIDC utilise une méthode basée sur les requêtes pour partager les attributs des comptes utilisateurs avec d'autres applications. Les requêtes comportent des attributs de compte utilisateur tels que l'adresse électronique, le numéro de téléphone, le nom, etc. DHIS2 utilise une requête IdP pour établir des liens de correspondance entre les comptes utilisateurs de l'IdP et ceux hébergés dans le serveur DHIS2. Par défaut, DHIS2 exige que l'IdP transmette la requête _email_. En fonction de votre IdP, vous devrez peut-être configurer DHIS2 de manière à ce qu'il utilise une requête IdP différente.

Si vous utilisez Google ou Azure AD comme IdP, par défaut, le système va utiliser _email_ pour faire correspondre les identités IdP avec les comptes d'utilisateurs DHIS2.

> **Remarque**
>
> Pour qu'un utilisateur DHIS2 puisse se connecter avec un IdP, la case du profil d'utilisateur : *Authentification externe, uniquement OpenID ou LDAP* doit être cochée et le champ *OpenID* doit correspondre à la revendication (revendication de mise en correspondance) renvoyée par l'IdP. L'email est la revendication par défaut utilisée par Google et Azure AD.

### Configurer le fournisseur d'identité pour l'OIDC { #configure-the-identity-provider-for-oidc } 

Cette section fournit des informations générales sur la configuration d'un fournisseur d'identité (IdP) pour utiliser OIDC avec DHIS2. Il s'agit d'une étape dans un processus à plusieurs étapes. Chaque fournisseur d'identité a des méthodes de configuration légèrement différentes. Consultez la documentation de votre IdP pour savoir comment créer et configurer une application OIDC. Ici, nous nous référons au serveur DHIS2 en tant qu'"application" OIDC.

#### Rediriger l'URL { #redirect-url } 

Tous les IdP nécessiteront une URL de redirection vers votre serveur DHIS2. 
Vous pouvez le construire en utilisant le modèle suivant :

```
(protocol):/(your DHIS2 host)/oauth2/code/PROVIDER_KEY
```

Exemple d'utilisation de Google IdP :

```
https://mydhis2-server.org/oauth2/code/google
```

Liens externes vers des instructions pour configurer votre IdP :

* [Google](https://developers.google.com/identity/protocols/oauth2/openid-connect)
* [Tutoriel Azure AD](https://medium.com/xebia-engineering/authentication-and-authorization-using-azure-active-directory-266980586ab8)


### Exemple de configuration Google { #example-setup-for-google }

1. Créez un compte et connectez-vous. Pour Google, par exemple, vous pouvez vous rendre sur la [console des développeurs] à l'adresse suivante :  (https://console.developers.google.com).
2. Dans le tableau de bord des développeurs Google, cliquez sur 'Créer un nouveau projet'.
3. Suivez les instructions pour créer un ID client et un secret client OAuth 2.0.
4. Définissez votre "URL de redirection autorisée" sur : `https://mydhis2-server.org/oauth2/code/google`
5. Copiez et conservez l' "identifiant client" et le "secret client" dans un endroit sécurisé.

> **Conseil**
>
> Lors des tests sur une instance DHIS2 locale exécutée par exemple sur votre ordinateur portable, vous pouvez utiliser localhost comme URL de redirection, comme suit : `https://localhost:8080/oauth2/code/google`
> *N'oubliez pas d'ajouter également l'URL de redirection dans la console des développeurs Google*

#### Exemple Google dhis.conf : { #google-dhisconf-example }
```propriétés

# Permet la connexion à OIDC
oidc.oauth2.login.enabled = activé

# Identifiant client, qui vous est fourni dans la console des développeurs Google
oidc.provider.google.client_id = mon identifiant client

# Secret client, qui vous est fourni dans la console des développeurs Google
oidc.provider.google.client_secret = mon secret client

# [Facultatif] URL de redirection autorisé, identique à celui défini dans la console des développeurs Google
# Si votre nom d'hôte public est différent de ce qui se trouve dans le serveur,
# vous devez fournir votre URL publique complète, comme dans l'exemple ci-dessous.
oidc.provider.google.redirect_url = https://mydhis2-server.org/oauth2/code/google

# [Facultatif] Où serez-vous redirigé après déconnexion ?
# Si votre nom d'hôte public est différent de ce qui se trouve dans le serveur,
# vous devez fournir votre URL publique complète, comme dans l'exemple ci-dessous.
oidc.logout.redirect_url = https://mydhis2-server.org

```

### Exemple de configuration pour Azure AD { #example-setup-for-azure-ad }

Assurez-vous que votre compte Azure AD dans le portail Azure est configuré avec une URL de redirection comme celle-ci : `(protocol):/(host)/oauth2/code/PROVIDER_KEY`.
Pour enregistrer votre serveur DHIS2 en tant qu' "application" dans le portail Azure, suivez les étapes suivantes :

> **Remarque**
>
> PROVIDER_KEY est la partie "nom" de la clé de configuration, par exemple : "oidc.provider.PROVIDER_KEY.tenant = My Azure SSO"
> Si vous voulez configurer plusieurs fournisseurs Azure, vous pouvez utiliser ce formulaire de nom : (azure.0), (azure.1) etc.
> Exemple d'URL de redirection : https://mydhis2-server.org/oauth2/code/azure.0

1. Recherchez et sélectionnez *Inscriptions d’applications*.
2. Cliquez sur *Nouvelle inscription*.
3. Dans le champ *Nom*, entrez un nom qui décrit votre instance DHIS2.
4. Dans le champ *URI de redirection*, entrez l'URL de redirection tel que spécifié ci-dessus.
5. Cliquez sur *S'inscrire*.

#### Exemple Azure AD dhis.conf : { #azure-ad-dhisconf-example }
```propriétés

# Permet la connexion à OIDC
oidc.oauth2.login.enabled = activé

# Premier fournisseur (azure.0) :

# Alias ou nom qui s'affichera sur le bouton de connexion sur l'écran de connexion de DHIS2.
oidc.provider.azure.0.tenant = nom de l'organisation

# ID client, qui vous est fourni dans le portail Azure
oidc.provider.azure.0.client_id = mon Id client

# Secret client, qui vous est fourni dans le portail Azure
oidc.provider.azure.0.client_secret = mon secret client

# [Facultatif] URL de redirection autorisé, tel que défini dans le portail Azure
# Si votre nom d'hôte public est différent de ce qui se trouve sur le serveur,
# vous devez fournir votre URL publique complète, comme dans l'exemple ci-dessous.
oidc.provider.azure.0.redirect_url = https://mydhis2-server.org/oauth2/code/azure.0

# [Facultatif] Où serez-vous redirigé après déconnexion ?
# Si votre nom d'hôte public est différent de ce qui se trouve sur le serveur,
# vous devez fournir votre URL publique complète, comme dans l'exemple ci-dessous.
oidc.logout.redirect_url = https://mydhis2-server.org

# [Facultatif], par défaut 'e-mail'
oidc.provider.azure.0.mapping_claim = e-mail

# [Facultatif], par défaut "activé"
oidc.provider.azure.0.support_logout = activé


# Deuxième fournisseur (azure.1) :

oidc.provider.azure.1.tenant = autre nom d'organisation
...
```

### Fournisseurs génériques { #generic-providers }

Le fournisseur générique peut être utilisé pour configurer "n'importe quel" fournisseur d'OIDC standard compatible avec "Spring Security".

Dans l'exemple ci-dessous, nous allons configurer le fournisseur du gouvernement norvégien _HelseID_ OIDC à l'aide de la clé du fournisseur `helseid`.

Le fournisseur défini apparaîtra sous forme de bouton sur la page de connexion avec la clé du fournisseur comme nom par défaut, ou la valeur de `display_alias` si elle est définie. La clé du fournisseur est arbitraire et peut consister en n'importe quelle chaîne alphanumérique, excepté les noms réservés utilisés par les fournisseurs spécifiques (`google`, `azure.0,azure.1...`, `wso2`).

> **Remarque**
> Le fournisseur générique utilise les valeurs de configuration par défaut codées en dur suivantes :
> **(Ne peuvent pas subir de modifications)**
> * Authentification du client, `ClientAuthenticationMethod.BASIC` : [rfc](https://tools.ietf.org/html/rfc6749#section-2.3)
> * Requêtes authentifiées, `AuthenticationMethod.HEADER` : [rfc](https://tools.ietf.org/html/rfc6750#section-2)

#### Exemple de dhis.conf générique (helseid) : { #generic-helseid-dhisconf-example }

```propriétés

# Permet la connexion OIDC
oidc.oauth2.login.enabled = activé

# Variables obligatoires :
oidc.provider.helseid.client_id = CLIENT_ID
oidc.provider.helseid.client_secret = CLIENT_SECRET
oidc.provider.helseid.mapping_claim = helseid://claims/identity/email
oidc.provider.helseid.authorization_uri = https://helseid.no/connect/authorize
oidc.provider.helseid.token_uri = https://helseid.no/connect/token
oidc.provider.helseid.user_info_uri = https://helseid.no/connect/userinfo
oidc.provider.helseid.jwk_uri = https://helseid.no/.well-known/openid-configuration/jwks
oidc.provider.helseid.end_session_endpoint = https://helseid.no/connect/endsession
oidc.provider.helseid.scopes = helseid://scopes/identity/email

# [Facultatif] URI de redirection autorisé, tel que défini dans le portail Azure
# Si votre nom d'hôte public est différent de ce qui se trouve sur le serveur,
# vous devez fournir votre URL publique complète, comme dans l'exemple ci-dessous.
oidc.provider.helseid.redirect_url = https://mydhis2-server.org/oauth2/code/helseid

# [Facultatif], par défaut "activé"
oidc.provider.helseid.enable_logout = activé

# [Facultatif] Où serez-vous redirigé après déconnexion ?
# Si votre nom d'hôte public est différent de ce qui se trouve sur le serveur,
# vous devez fournir votre URL publique complète, comme dans l'exemple ci-dessous.
oidc.logout.redirect_url = https://mydhis2-server.org

# [Facultatif] Prise en charge de PKCE, voir : https://oauth.moustiquaire/2/pkce/), la valeur par défaut est 'fausse'
oidc.provider.helseid.enable_pkce = activé

# [Facultatif] Variables supplémentaires ajoutées à la requête.
# Doivent être des paires clé/valeur telles que : "KEY1 VALUE1,KEY2 VALUE2,..."
oidc.provider.helseid.extra_request_parameters = acr_values lvl4, other_key value2

# [Facultatif] Il s'agit de l'alias/nom affiché sur le bouton de connexion sur la page de connexion de DHIS2
oidc.provider.helseid.display_alias = HelseID

# [Facultatif] Lien vers une URL pour obtenir un logo. (Peut utiliser des URL absolues ou relatives)
oidc.provider.helseid.logo_image = ../security/btn_helseid.svg
# [Facultatif] Remplissage CSS pour l'image du logo
oidc.provider.helseid.logo_image_padding = 0px 1px
```

### Authentification du jeton du porteur JWT { #jwt-bearer-token-authentication }

L'authentification avec des *jetons bearer JWT* peut être activée pour les clients basés sur l'API lorsque OIDC est configuré. 
Le client DHIS2 Android est le type de client qui doit utiliser l'authentification JWT si la connexion OIDC est activée.

>**Note**
>
> DHIS2 ne prend actuellement en charge que le flux d'attribution du code d'autorisation OAuth2 pour l'authentification avec JWT (également connu sous le nom de "OAuth à trois niveaux" (three-legged OAuth en anglais)).
> Actuellement, avec DHIS2, seul Google peut être utilisé en tant que fournisseur d'OIDC lors de l'utilisation de jetons JWT.


### Conditions requises { #requirements } 
* Configurez votre fournisseur Google OIDC comme décrit ci-dessus
* Désactivez le paramètre de configuration ```oauth2.authorization.server.enabled```
* Activez le paramètre de configuration ```oidc.jwt.token.authentication.enabled``` en le réglant sur 'on' (activer)
* Générez un Id_client pour Android OAuth2 tel que décrit [ici](https://developers.google.com/identity/protocols/oauth2/native-app#creatingcred)

### Exemple d'authentification JWT { #jwt-authentication-example }

La section `dhis.conf` suivante montre un exemple de la façon d'activer l'authentification JWT pour un client basé sur API.

```propriétés

# Permet la connexion à OIDC
oidc.oauth2.login.enabled = activé

# Variables de configuration minimales requises :
oidc.provider.google.client_id = mon_client_id
oidc.provider.google.client_secret = mon_client_secret

# Activer la prise en charge de JWT
oauth2.authorization.server.enabled = désactivé
oidc.jwt.token.authentication.enabled = activé

# Définir le client 1 à l'aide des jetons JWT
oidc.provider.google.ext_client.0.client_id = JWT_CLIENT_ID

# Définir le client 2 à l'aide des jetons JWT
oidc.provider.google.ext_client.1.client_id = JWT_CLIENT_ID

```

> **Remarque**
>
> Consultez le lien suivant pour obtenir un tutoriel sur la configuration d'Okta en tant que fournisseur d'OIDC générique.
> [lien](../tutorials/configure-oidc-with-okta.md)

## Configuration de LDAP { #install_ldap_configuration }

DHIS2 peut utiliser un serveur LDAP pour l'authentification des utilisateurs.
L'authentification LDAP nécessite que chaque entrée corresponde à un utilisateur dans la base de données DHIS2. L'utilisateur DHIS2 sera utilisé pour représenter des autorités / rôles d’utilisateur.

Pour configurer l'authentification LDAP, vous devez définir l'URL du serveur LDAP, un utilisateur gestionnaire, une base de recherche et un filtre de recherche LDAP. Cette configuration doit être effectuée dans le fichier de configuration de DHIS 2 `dhis.conf`.
Les utilisateurs ou entrées LDAP sont identifiés avec des noms distinctifs (DN à partir de maintenant). Voici un exemple de configuration :

```propriétés
# URL du serveur LDAP
ldap.url = ldaps://domain.org:636

# Nom distinctif de l'entrée du gestionnaire LDAP
ldap.manager.dn = cn=johndoe,dc=domain,dc=org

# Mot de passe d'entrée du gestionnaire LDAP
ldap.manager.password = xxxx

# Recherche de base LDAP
ldap.search.base = dc=domaine,dc=org

# Filtre de recherche LDAP
ldap.search.filter = (cn={0})
```

Les propriétés de configuration LDAP sont expliquées ci-dessous :

- *ldap.url :* L'URL du serveur LDAP avec lequel s'authentifier
  L'utilisation du SSL ou du cryptage est fortement recommandée afin de
  sécuriser l’authentification. Prenons l'exemple de l'URL suivant
  *ldaps://domain.org:636*, où ldaps fait référence au protocole,
  *domain.org* fait référence au nom de domaine ou à l'adresse IP, et *636*
  fait référence au port (636 est la valeur par défaut pour LDAPS).
- *ldap.manager.dn:* Un utilisateur du gestionnaire LDAP doit être relié au 
  serveur LDAP pour permettre le processus d'authentification des utilisateurs. 
  fait référence au DN de cette entrée, c'est à dire que ce n'est pas l'utilisateur qui va
  authentifié lors de la connexion à DHIS2, mais plutôt l'utilisateur qui
  est relié au serveur LDAP afin d'effectuer l'authentification.
- *ldap.manager.password :* Le mot de passe de l'utilisateur du gestionnaire LDAP.
- *ldap.search.base :* La base de recherche ou le nom unique de
  l'objet de la base de recherche, qui définit l'emplacement dans le répertoire
  à partir duquel commence la recherche LDAP.
- *ldap.search.filter :* Le filtre permettant de faire correspondre les DN des entrées dans le
  répertoire LDAP. La variable {0} sera remplacée par le nom d'utilisateur DHIS2,
  ou autrement, l'identifiant LDAP défini pour l'utilisateur
  avec le nom d'utilisateur fourni.

DHIS2 utilisera le nom d'utilisateur et le mot de passe fournis pour essayer de s'authentifier avec une entrée du serveur LDAP, puis recherchera des rôles/autorités d'utilisateur auprès d'un utilisateur DHIS2 correspondant. Cela implique qu'un utilisateur doit avoir une entrée correspondante dans le répertoire LDAP ainsi qu'un utilisateur DHIS2 pour pouvoir se connecter.

Lors de l'authentification, DHIS2 essaiera de se connecter au serveur LDAP en utilisant l'URL du serveur LDAP configuré ainsi que le DN et le mot de passe du gestionnaire. Une fois la connexion établie, il recherche une entrée dans le répertoire à l'aide de la base de recherche LDAP et du filtre de recherche configurés.

La variable {0} du filtre configuré sera remplacée avant l'application du filtre. Par défaut, elle sera remplacée par le nom d'utilisateur fourni. Vous pouvez également définir un identifiant LDAP personnalisé pour le compte utilisateur DHIS2 concerné. Vous pouvez le faire via l'interface utilisateur du module utilisateur DHIS2 sur l'écran d'ajout ou d'édition en définissant la propriété "Identifiant LDAP". Une fois définie, l'identifiant LDAP remplacera la variable {0} dans le filtre. Cette fonction est utile lorsque le nom commun LDAP ne convient pas ou ne peut pas, pour une raison quelconque, être utilisé comme nom d'utilisateur DHIS2.

## Configuration du cryptage{ #install_encryption_configuration }

DHIS2 permet de crypter les données. L'activation du cryptage nécessite une configuration supplémentaire. Pour assurer la sécurité de l'algorithme de cryptage, vous devrez définir un mot de passe (clé) dans le fichier de configuration `dhis.conf` via la propriété *encryption.password* :

```properties
encryption.password = xxxx
```

La propriété *encryption.password* est le mot de passe (clé) utilisé lors du cryptage et du décryptage des données dans la base de données.

Si un mot de passe de cryptage n'est pas défini dans `dhis.conf`, un mot de passe par défaut sera utilisé. Notez que l'utilisation du mot de passe par défaut n'augmente pas la sécurité en raison de la nature open source du DHIS 2.

Le mot de passe ne doit pas être modifié une fois défini et les données cryptées. Autrement, ces données ne pourront plus être décryptées par l'application.

Le mot de passe doit comporter au moins **24 caractères**. Une combinaison de chiffres et de lettres minuscules et majuscules est recommandé. Le mot de passe de cryptage doit être gardé secret.

> **Important**
>
> Il n'est pas possible de récupérer les données cryptées si le mot de passe de cryptage est perdu ou modifié. Si le mot de passe est perdu, les données cryptées le seront également. A l’inverse, le cryptage n’offre aucune sécurité si le mot de passe est compromis. Il faut donc s'assurer que le mot de passe est conservé dans un endroit sûr.
>

Etant donné que la clé de cryptage est stockée dans le fichier de configuration `dhis.conf` et non dans la base de données, lors du déplacement d'une base de données entre différents environnements de serveur par le biais d'un vidage et d'une restauration (dump and restore), la clé de cryptage doit être la même dans tous ces environnements pour permettre à DHIS 2 de décrypter le contenu de la base de données.

La prise en charge du cryptage dépend de la disponibilité des fichiers de stratégie *Java Cryptography Extension* (JCE). Ces fichiers sont inclus dans toutes les versions d'OpenJDK et d'Oracle JDK 8 Update 144 et les versions ultérieures.

## Configuration de la base de données réplica en lecture { #install_read_replica_configuration }

DHIS 2 permet d'utiliser des réplicas en lecture seule de la base de données principale (la base de données principale de DHIS 2). L'objectif des réplicas en lecture est d'améliorer les performances des requêtes en lecture de la base de données et d'augmenter les capacités au-delà des contraintes d'une seule base de données. Les opérations à forte intensité de lecture en bénéficieront, notamment les requêtes d'analyse et les requêtes d'événements.

La configuration exige que vous ayez créé une ou plusieurs instances répliquées de la base de données principale de DHIS 2. PostgreSQL permet de le faire grâce à un concept appelé *réplication en flux*. La configuration des réplicas en lecture pour PostgreSQL n'est pas abordée dans ce guide.

Les réplicas en lecture peuvent être définis dans le fichier de configuration `dhis.conf`. Vous pouvez en spécifier jusqu'à 5 par instance DHIS 2. Chaque réplica est désignée par un nombre compris entre 1 et 5. L'URL de connexion JDBC doit être définie pour chaque réplica. Le nom d'utilisateur et le mot de passe peuvent être spécifiés. Dans le cas contraire, le nom d'utilisateur et le mot de passe de la base de données principale seront utilisés en lieu et place.

La configuration des réplicas en lecture dans `dhis.conf` ressemble à celle ci-dessous.
Chaque réplica est spécifié avec le préfixe de la clé de configuration *readN*, où N fait référence au numéro du réplica.

```propriétés
# Configuration du réplica en lecture 1

# URL de connexion à la base de données, nom d'utilisateur et mot de passe
read1.connection.url = jdbc:postgresql://127.0.0.11/dbread1
read1.connection.username = dhis
read1.connection.password = xxxx

# Configuration du réplica en lecture 2

# URL de connexion à la base de données, nom d'utilisateur et mot de passe
read2.connection.url = jdbc:postgresql://127.0.0.12/dbread2
read2.connection.username = dhis
read2.connection.password = xxxx

# Configuration du réplica en lecture 3

# URL de connexion à la base de données, retour à la base de données principale pour le nom d'utilisateur et le mot de passe
read3.connection.url = jdbc:postgresql://127.0.0.13/dbread3
```

Vous devez redémarrer votre conteneur de servlets pour que les modifications s'appliquent. DHIS 2 répartira automatiquement la charge entre les réplicas en lecture. L'ordre des réplicas n'a pas d'importance.

## Configuration du cluster de serveur Web { #install_web_server_cluster_configuration }

Cette section décrit comment configurer l'application  DHIS 2 pour qu'elle s'exécute dans un cluster.

### Présentation du clustering { #install_cluster_configuration_introduction }

Le clustering est une technique courante permettant d'améliorer l'évolutivité et la disponibilité du système. Elle consiste à installer plusieurs serveurs web, par exemple des instances Tomcat, pour qu'ils servent une seule application. Le clustering permet d'*étendre* une application de manière à ce que de nouveaux serveurs puissent être ajoutés afin d'améliorer ses performances. Elle garantit également une *grande disponibilité*, car le système peut tolérer que des instances tombent en panne sans pour autant rendre le système inaccessible aux utilisateurs.

Quelques paramètres doivent être configurés pour que DHIS 2 s'exécute dans un cluster.

* Un entrepôt de données Redis doit être installé et les informations de connexion doivent
être fournies pour chaque instance de l'application DHIS 2 dans `dhis.conf`.

* Les instances et les serveurs DHIS 2 doivent partager le même dossier *fichiers* utilisé pour 
les applications et les téléchargements de fichiers, soit par l'intermédiaire de l'option de *stockage de fichiers cloud AWS S3*, 
soit par un lecteur réseau partagé.

* L'invalidation du cache de l'instance DHIS 2 doit être activée.

* Un équilibreur de charge tel que nginx doit être configuré pour distribuer les requêtes Web
dans les instances du cluster.

### Invalidation du cache de l'instance DHIS 2 avec Redis { #install_cluster_cache_invalidation_redis }

DHIS 2 peut invalider les caches des différentes instances en surveillant les événements envoyés et émis par un serveur Redis, lorsqu'il est configuré à cet effet.

C'est le moyen le plus simple d'activer l'invalidation du cache. Si vous prévoyez déjà d'utiliser [Redis pour la configuration du cluster de stockage de données partagé](#install_cluster_configuration_redis), le serveur Redis sera partagé pour les deux cas.

#### Prérequis { #prerequisites }

* Serveur Redis

#### Configuration de Redis { #redis-configuration }

Aucune configuration spécifique dans Redis n'est nécessaire pour que l'invalidation du cache DHIS 2 fonctionne.

Lorsque vous choisissez d'activer la configuration du cluster de stockage de données partagé avec Redis, vous partagerez la configuration de l'hôte/port Redis avec le système d’invalidation du cache. En d'autres termes, vous ne pouvez configurer qu'**un** serveur Redis partagé.

#### Configuration de DHIS 2 { #dhis-2-configuration }

Les propriétés suivantes doivent être spécifiées dans le fichier de configuration DHIS 2 `dhis.conf` :

```propriétés
# Configuration de l'invalidation du cache

redis.cache.invalidation.enabled = activé

# Configuration du Redis partagé
redis.host = REDIS_HOST
redis.port = REDIS_PORT
redis.password = PASSWORD (Facultatif, uniquement s'il est activé sur le serveur Redis)
redis.use.ssl = vrai (Facultatif, uniquement s'il activé sur le serveur Redis)
```

### Configuration du cluster de stockage de données partagé Redis { #install_cluster_configuration_redis }

Pour configurer un cluster, vous avez besoin d'un serveur Redis qui va gérer les sessions utilisateur partagées, le cache de l'application et les nœuds du cluster.

Pour optimiser les performances, les événements *Redis Keyspace* pour les _commandes génériques_ et les _événements expirés_ doivent être activés sur le serveur Redis. Si vous utilisez un serveur Redis géré par une plateforme cloud (comme *AWS ElastiCache pour Redis* ou *Azure Cache pour Redis*), il vous faudra activer les notifications d'événements keyspace à l'aide des interfaces de console cloud respectives. Si vous configurez un serveur Redis autonome, l'activation des notifications d'événements keyspace peut être effectuée dans le fichier *redis.conf* par l'ajout ou le dé-commentement de la ligne suivante :

```
notify-keyspace-events Egx
```

DHIS2 se connectera à Redis si la propriété de configuration *redis.enabled* dans `dhis.conf` est définie sur *activé* avec les propriétés suivantes :

- *redis.host* : Spécifie où le serveur Redis est exécuté. La valeur par défaut est *localhost*. Obligatoire.

- *redis.port* : Spécifie le port sur lequel le serveur Redis écoute. La valeur par défaut est *6379*. Facultatif.

- *redis.password* : Spécifie le mot de passe d'authentification. Si un mot de passe n'est pas nécessaire, il peut rester vide.

- *redis.use.ssl* : Spécifie si SSL est activé sur le serveur Redis. La valeur par défaut est *faux*. Facultatif.

Lorsque Redis est activé, DHIS2 attribue automatiquement à l'une des instances en cours d'exécution le rôle de leader du cluster. L'instance leader sera utilisée pour exécuter des travaux ou des tâches programmées qui doivent être exécutés exclusivement par une instance. En option, vous pouvez configurer la propriété *leader.time.to.live.minutes* dans `dhis.conf` pour définir la fréquence à laquelle le choix du leader doit avoir lieu. Cela donne aussi une indication sur le temps nécessaire pour qu'une autre instance prenne le relais après que le leader précédent ne soit plus disponible. La valeur par défaut est 2 minutes. Notez que l'attribution d'un leader dans le cluster n'est effectuée que si Redis est activé. Ci-dessous, un exemple de fichier de configuration `dhis.conf` avec Redis activé et la fréquence du choix du leader configurée.

```propriétés
# Configuration de Redis

redis.enabled = activé

# Configuration de Redis partagé
redis.host = HÔTE_REDIS
redis.port = PORT_REDIS
redis.password = MOT DE PASSE (Facultatif, uniquement s'il est activé sur le serveur Redis)
redis.use.ssl = vrai (Facultatif, uniquement s'il est activé sur le serveur Redis)

# Facultatif, la valeur par défaut est 2 minutes
leader.time.to.live.minutes=4
```

### Configuration du dossier de fichiers { #files-folder-configuration }

DHIS 2 va stocker plusieurs types de fichiers hors de l'application elle-même, tels que des applications, des fichiers sauvegardés lors de saisies de données et des avatars d'utilisateurs. Lorsqu'il est déployé dans un cluster, l'emplacement de ces fichiers doit être partagé entre toutes les instances. Sur le système de fichiers local, l'emplacement est le suivant :

```
{DHIS2_HOME}/files
```

Ici, `DHIS2_HOME` fait référence à l'emplacement du fichier de configuration DHIS 2 tel que spécifié par la variable d'environnement DHIS 2, et `fichiers` est le dossier de fichiers immédiatement en dessous.

Il existe deux manières d'obtenir un emplacement partagé :

* Utiliser l'option *Stockage de fichiers cloud AWS S3*. Les fichiers seront stockés dans un
compartiment S3 qui est automatiquement partagé entre toutes les instances DHIS 2 présentes dans le cluster.
Consulter la section *Configuration de l'entrepôt de fichiers* pour obtenir des conseils.
* Configurer un dossier partagé entre toutes les instances et tous les serveurs DHIS 2 
présents dans le cluster. Sur Linux, cela peut être réalisé avec *NFS* (Network File System)
qui est un protocole de système de fichiers en réseau. Notez que seuls les sous-dossiers `fichiers`
sous `DHIS2_HOME` doit être partagé, pas le dossier parent.

### Configuration de l'équilibreur de charge { #install_load_balancing }

Lorsqu'un cluster d'instances Tomcat est installé, un *équilibreur de charge* peut être utilisé pour acheminer les requêtes web entrantes vers les instances backend du cluster. Un équilibreur de charge veille à ce que la charge soit répartie uniformément entre les instances du cluster. Il détectera également l'indisponibilité d'une instance et, le cas échéant, arrêtera les requêtes de routine vers cette instance et utilisera les autres instances disponibles.

L'équilibrage de la charge peut être réalisé de plusieurs manières. *nginx* est une approche simple. En l'utilisant, vous devrez définir un élément *upstream* qui énumère l'emplacement des instances backend, puis utiliser cet élément dans le bloc d'emplacement *proxy*.

```text
http {

  # Upstream element with sticky sessions

  upstream dhis_cluster {
    ip_hash;
    server 193.157.199.131:8080;
    server 193.157.199.132:8080;
  }

  # Proxy pass to backend servers in cluster

  server {
    listen 80;

    location / {
      proxy_pass   http://dhis_cluster/;
    }
  }
}  
```

DHIS 2 conserve l'état des sessions utilisateur côté serveur dans une certaine mesure. L'utilisation de "sessions persistantes" est une approche simple qui permet d'éviter de reproduire l'état de la session du serveur en acheminant les demandes d'un même client vers le même serveur. La directive *ip\_hash* de l'élément upstream garantit cette fonction.

Plusieurs instructions ont été omises par souci de concision dans l'exemple ci-dessus. Consultez la section proxy inverse pour obtenir un guide détaillé.

## Configuration d'ActiveMQ Artemis { #webapi_artemis_configuration }

Par défaut, DHIS2 lance une instance intégrée d'ActiveMQ Artemis au démarrage. Pour la plupart des cas d'utilisation, vous n'avez rien à faire. Si vous avez un service ActiveMQ Artemis existant que vous voulez utiliser à la place de l'instance intégrée, vous pouvez changer la configuration par défaut dans votre fichier `dhis.conf` avec les propriétés de configuration du tableau suivant.

| Propriété                  | Valeur (par défaut en premier) | Description                                                  |
| ------------------------- | --------------------- | ------------------------------------------------------------ |
| artemis.mode                 | INTÉGRÉ \| NATIF    | Le mode par défaut `INTÉGRÉ` lance un service AMQP interne au démarrage de l'instance DHIS2. Si vous voulez vous connecter à un service AMQP externe, définissez le mode sur `NATIF`. |
| artemis.host                 | 127.0.0.1             | Hôte auquel se connecter.                                             |
| artemis.port                 | 15672                 | Si le mode est défini sur `INTÉGRÉ`, le serveur intégré se connectera à ce port. Si c'est sur `NATIF`, le client utilisera ce port pour se connecter. |
| artemis.username             | invité                 | Nom d'utilisateur auquel se connecter si vous utilisez le mode `NATIVE`.               |
| artemis.password             | invité                 | Mot de passe auquel se connecter si vous utilisez le mode `NATIF`.               |
| artemis.embedded.persistence | désactivé \| activé         | Si le mode est défini sur `INTÉGRÉ`, cette propriété va contrôlé la persistance de la file d'attente interne. |


## Surveillance { #monitoring }

DHIS 2 peut exporter des métriques compatibles avec Prometheus pour la surveillance des instances DHIS2. L'infrastructure de surveillance de DHIS2 est conçue pour exposer les métriques liées à l'exécution de l'application et d'autres informations relatives à l'application.

Les métriques liées à l'infrastructure (telles que les métriques de l'hôte, Tomcat ou Postgres) ne sont pas directement exposées par le moteur de surveillance de l'application et doivent être collectées séparément. Les métriques actuellement exposées par l'application sont :

- API DHIS 2 (temps de réponse, nombre d'appels, etc.)
- JVM (taille du tas, récupération de l'espace mémoire, etc.)
- Mise en veille prolongée (requêtes, cache, etc.)
- C3P0 Database pool
- Disponibilité des applications
- CPU

La surveillance peut être activé dans `dhis.conf` avec les propriétés suivantes (la valeur par défaut est `désactivé` pour toutes les propriétés) :

```propriétés
surveillance.api.enabled = activé
surveillance.jvm.enabled = activé
surveillance.dbpool.enabled = activé
surveillance.hibernate.enabled = désactivé
surveillance.uptime.enabled = activé
surveillance.cpu.enabled = activé
```

L'approche recommandée pour collecter et visualiser ces métriques est Prometheus et Grafana.

Pour plus d'informations, consultez la page consacrée à la [surveillance de l'infrastructure](https://github.com/dhis2/wow-backend/blob/master/guides/surveillance.md) et le chapitre sur l'[Installation de Prometheus et Grafana](#surveillance).

## Configuration du système { #install_system_configuration }

Cette section aborde diverses propriétés de configuration du système.

```propriétés
system.read_only_mode = on | désactivé
```

Définit le système sur le mode lecture seule. Ceci est utile lorsque vous exécutez DHIS 2 sur une base de données réplica en lecture seule, afin d'éviter que DHIS 2 n'effectue des opérations d'écriture sur la base de données. Peut être `activé` ou `désactivé`. La valeur par défaut est `désactivé`.

```properties
system.session.timeout = (seconds)
```

Définit le délai d'expiration de la session utilisateur en secondes. La valeur par défaut est 3 600 secondes (1 heure).

```properties
system.sql_view_table_protection = on | off
```

Active ou désactive la protection des tables de base de données sensibles pour les vues SQL. Grâce à cette protection, les tables de base de données contenant des données sensibles ne pourront pas être interrogées par le biais des vues SQL. La désactivation n'est pas recommandée. Peut être `activé` ou `désactivé`. La valeur par défaut est `on`.

```properties
system.system.sql_view_write_enabled = on | off
```

Active ou désactive les autorisations d'écriture pour les vues SQL. Cela empêchera la vue SQL d'effectuer des écritures sous-jacentes (la requête peut être une sélection qui nécessite une autorisation d'écriture). L'activation n'est pas recommandée. La désactivation n'est pas recommandée ; peut être `activé` ou `désactivé`. La valeur par défaut est `on`.

```properties
system.program_rule.server_execution = on | off
```

Active ou désactive l'exécution des règles de programme côté serveur. Il s'agit des règles de programme qui ont des actions d'attribution de valeurs, d'envoi de messages ou de programmation d'envoi de messages. Peut être `activé` ou `désactivé`. La valeur par défaut est `activé`.

## Configuration du proxy inverse { #install_reverse_proxy_configuration }

Un proxy inverse est un serveur proxy qui agit pour le compte d'un autre serveur. L'utilisation d'un proxy inverse en combinaison avec un conteneur de servlets n'est pas obligatoire mais présente de nombreux avantages :

  - Les requêtes peuvent être mises en correspondance et transmises à plusieurs conteneurs de servlets.
    Cela rend le système plus flexible et facilite l'exécution de plusieurs
    instances DHIS2 sur un même serveur. Cela permet également de
    modifier la configuration du serveur interne sans affecter les clients.

  - L'application DHIS2 peut être exécutée dans un mode autre que super-utilisateur sur un port
    différent de 80, ce qui réduit la vulnérabilité face au piratage de
    détournement.

  - Le proxy inverse peut agir comme un serveur SSL unique et être configuré
    pour inspecter les demandes de contenu malveillant, enregistrer les demandes et
    les réponses et fournir des messages d'erreur non sensibles qui
    améliorer la sécurité.

### Configuration de base de Nginx { #install_basic_nginx_setup }

Nous vous recommandons d'utiliser [nginx](http://www.nginx.org) comme proxy inverse en raison de sa faible empreinte mémoire et sa facilité d'utilisation. Pour l'installer, appelez la commande suivante :

    sudo apt-get install -y nginx

nginx peut maintenant être lancé, rechargé et arrêté avec les commandes suivantes :

    sudo /etc/init.d/nginx start
    sudo /etc/init.d/nginx reload
    sudo /etc/init.d/nginx stop

Maintenant que nous avons installé nginx, nous allons continuer la configuration normale du proxy des requêtes vers notre instance Tomcat, qui, nous le supposons, s'exécute avec l'adresse `http://localhost:8080`. Pour configurer nginx, vous pouvez ouvrir le fichier de configuration en appelant :

    sudo nano /etc/nginx/nginx.conf

La configuration de nginx se fait autour d'une hiérarchie de blocs représentant le http, le serveur et l'emplacement, où chaque bloc hérite des paramètres des blocs parents. L'extrait suivant va configurer nginx pour qu'il passe (redirige) les requêtes du port 80 (qui est le port sur lequel nginx écoute par défaut) vers notre instance Tomcat. Ajoutez la configuration suivante dans le fichier nginx.conf :

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  server {
    listen               80;
    client_max_body_size 10M;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  http;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

Vous pouvez désormais accéder à votre instance DHIS2 à l'adresse *http://localhost*. Etant donné que le proxy inverse a été installé, nous pouvons améliorer la sécurité en configurant Tomcat pour qu'il n'écoute que les connexions locales. Dans */conf/server.xml*, vous pouvez ajouter un attribut *address* avec la valeur *localhost* à l'élément Connector pour HTTP 1.1 comme suit :

```xml
<Connector address="localhost" protocol="HTTP/1.1" />
```

### Activation de SSL avec nginx { #install_enabling_ssl_on_nginx }

Afin d'améliorer la sécurité, il est recommandé de configurer le serveur qui exécute DHIS2 de manière à ce qu'il communique avec les clients via une connexion cryptée et de s'identifier auprès des clients à l'aide d'un certificat de confiance. Ceci peut être réalisé via SSL qui est un protocole de communication cryptographique fonctionnant sur TCP/IP. Tout d’abord, installez la bibliothèque *openssl* requise :

    sudo apt-get install -y openssl

Pour configurer nginx de manière à ce qu'il utilise SSL, vous aurez besoin d'un certificat SSL approprié provenant d'un fournisseur SSL. Le coût d'un certificat varie en fonction de la puissance du cryptage. Un certificat abordable de [Rapid SSL Online (http://www.rapidsslonline.com) devrait répondre à la plupart des besoins. Pour générer le CSR (demande de signature de certificat), vous pouvez appeler la commande ci-dessous. À l'invite du *Nom commun*, entrez le nom du domaine qualifié pour le site que vous sécurisez.

    openssl req -new -newkey rsa:2048 -nodes -keyout server.key -out server.csr

Après avoir reçu vos fichiers de certificat (.pem ou .crt), vous devez les placer avec le fichier server.key généré, dans un emplacement accessible par nginx. Le répertoire où se trouve votre fichier nginx.conf peut servir d'emplacement à cet effet.

Vous trouverez ci-dessous un bloc serveur nginx où les fichiers de certificats sont nommés server.crt et server.key. Étant donné que les connexions SSL se font généralement sur le port 443 (HTTPS), nous transmettons les requêtes sur ce port (443) à l'instance DHIS2 qui s'exécute à l'adresse `http://localhost:8080`. Le premier bloc serveur réécrira toutes les requêtes connectées au port 80 et forcera l'utilisation de HTTPS/SSL. Ceci est également nécessaire car DHIS2 utilise beaucoup de redirections en interne, lesquelles doivent être transmises pour pouvoir utiliser HTTPS. N'oubliez pas de remplacer *\<server-ip\>* par l'IP de votre serveur. Ces blocs doivent remplacer celui de la section précédente.

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  # HTTP server - rewrite to force use of SSL

  server {
    listen     80;
    rewrite    ^ https://<server-url>$request_uri? permanent;
  }

  # HTTPS server

  server {
    listen               443 ssl;
    client_max_body_size 10M;

    ssl                  on;
    ssl_certificate      server.crt;
    ssl_certificate_key  server.key;

    ssl_session_cache    shared:SSL:20m;
    ssl_session_timeout  10m;

    ssl_protocols              TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers                RC4:HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

Notez la dernière valeur de l'en-tête `https` qui est nécessaire pour informer le conteneur de servlets que la requête arrive par HTTPS. Pour que Tomcat produise correctement les en-têtes d'URL d'`Emplacement` en utilisant HTTPS, vous devez également ajouter deux autres paramètres au Connector dans le fichier `server.xml` de Tomcat :

```xml
<Connector scheme="https" proxyPort="443" />
```

### Activation de la mise en cache avec nginx { #install_enabling_caching_ssl_nginx }

Les demandes de rapports, de graphiques, de cartes et d'autres ressources liées à l'analyse mettent souvent un certain temps avant de recevoir des réponses et peuvent utiliser une grande partie des ressources du serveur. Afin d'améliorer les temps de réponse, de réduire la charge sur le serveur et d'éviter d'éventuels temps d'arrêt, nous pouvons introduire un proxy de cache dans notre configuration de serveur. Le contenu mis en cache sera stocké dans le répertoire /var/cache/nginx, et jusqu'à 250 Mo de stockage y seront alloués. Nginx créera ce répertoire automatiquement.

```text
http {
  ..
  proxy_cache_path  /var/cache/nginx  levels=1:2  keys_zone=dhis:250m  inactive=1d;


  server {
    ..

    # Proxy pass to servlet container and potentially cache response

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
      proxy_cache               dhis;
    }
  }
}
```

**Important**
> >>>>>>>>
Sachez qu'un cache côté serveur court-circuite les fonctions de sécurité de DHIS2 dans le sens où les requêtes qui atteignent le cache côté serveur seront servies directement à partir du cache hors de contrôle de DHIS2 et du conteneur de servlets. Cela signifie que les URL des requêtes peuvent être devinées de même que les rapports récupérés dans le cache par des utilisateurs non autorisés. Par conséquent, si vous collectez des informations sensibles, la mise en place d'un cache côté serveur n'est pas recommandée.

### Limitation de débit avec nginx { #install_rate_limiting }

Certains appels d'API web dans DHIS 2, tels que les API d'`analyses`, nécessitent beaucoup de calculs. Par conséquent, il est préférable de limiter le débit de ces API afin d'équilibrer l'utilisation des ressources du serveur par les utilisateurs du système. La limitation de débit peut être effectuée avec `nginx`. Il existe plusieurs approches pour effectuer la limitation de débit et ceci est destiné à documenter l'approche basée sur nginx.

La configuration nginx ci-dessous limitera le débit de l'API Web des `analyses` et comporte les éléments suivants au niveau des blocs *http* et *emplacement* (la configuration est abrégée par souci de concision) :

```text
http {
  ..
  limit_req_zone $binary_remote_addr zone=limit_analytics:10m rate=5r/s;

  server {
    ..

    location ~ ^/api/(\d+/)?analytics(.*)$ {
      limit_req    zone=limit_analytics burst=20;
      proxy_pass   http://localhost:8080/api/$1analytics$2$is_args$args;
      ..
    }
  }
}
```

Les différents éléments de la configuration peuvent être décrits comme suit :

- *limit_req_zone $binary_remote_addr* : la limitation du débit est effectuée par adresse IP de requête.
- *zone=limit_analytics:20m* : une zone de limite de débit pour l'API des analyses qui peut contenir jusqu'à 10 Mo d'adresses IP de requête.
- *taux=20r/s* : Chaque IP reçoit 5 requêtes par seconde.
- *emplacement ~ ^/api/(\d+/)?analytics(.\*)$* : les requêtes pour le point d'extrémité de l'API des analyses sont limitées en débit.
- *burst=20* : des rafales contenant jusqu'à 20 requêtes seront mises en file d'attente et traitées ultérieurement ; des demandes supplémentaires conduiront à un `503`.

Pour obtenir une explication complète, veuillez consulter la [documentation nginx](https://www.nginx.com/blog/rate-limiting-nginx/).

### Rendre les ressources disponibles avec nginx { #install_making_resources_available_with_nginx }

Dans certains cas, il est souhaitable de rendre certaines ressources accessibles au public sur le web sans exiger une quelconque authentification. C'est le cas, par exemple, lorsque vous souhaitez rendre les ressources liées à l'analyse des données de l'API Web disponibles dans un portail Web. L'exemple suivant permet d'accéder aux graphiques, aux cartes, aux rapports, aux tableaux de rapports et aux ressources documentaires par le biais d'une authentification de base en insérant un en-tête HTTP d'*Autorisation* dans la demande. Il supprimera l'en-tête Cookie de la requête et l'en-tête Set-Cookie de la réponse afin d'éviter de modifier l'utilisateur connecté. Il est recommandé de créer un utilisateur à cette fin, en ne lui accordant que les autorisations minimales requises. La valeur d'autorisation peut être construite en codant le nom d'utilisateur avec base64, suivi de deux points et le mot de passe et en lui ajoutant le préfixe "Basic", plus précisément "Basic base64_encode(nom d'utilisateur:mot de passe)". Il vérifiera la méthode HTTP utilisée pour les requêtes et renverra *405 Method Not Allowed* s'il détecte autre chose que GET.

En utilisant cette approche, il peut être avantageux de créer un domaine séparé pour les utilisateurs publics. En effet, nous ne voulons pas modifier les informations d'identification des utilisateurs déjà connectés lorsqu'ils accèdent aux ressources publiques. Par exemple, si votre serveur est déployé à l'adresse somedomain.com, vous pouvez créer un sous-domaine dédié à api.somedomain.com et orienter les URL de votre portail vers ce sous-domaine.

```text
http {
  ..

  server {
    listen       80;
    server_name  api.somedomain.com;

    location ~ ^/(api/(charts|chartValues|reports|reportTables|documents|maps|organisationUnits)|dhis-web-commons/javascripts|images|dhis-web-commons-ajax-json|dhis-web-mapping|dhis-web-visualizer) {
    if ($request_method != GET) {
        return 405;
      }

      proxy_pass         http://localhost:8080;
      proxy_redirect     off;
      proxy_set_header   Host               $host;
      proxy_set_header   X-Real-IP          $remote_addr;
      proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto  http;
      proxy_set_header   Authorization      "Basic YWRtaW46ZGlzdHJpY3Q=";
      proxy_set_header   Cookie             "";
      proxy_hide_header  Set-Cookie;
    }
  }
}
```


### Bloquer des versions spécifiques d'applications Android avec nginx { #install_block_android_versions }

Dans certains cas, l'administrateur du système peut vouloir bloquer certains clients Android sur la base de leur version de l'application DHIS2 ; par exemple, si les utilisateurs sur le terrain n'ont pas mis à jour leur version de l'application Android vers une version spécifique et que l'administrateur du système veut bloquer leur accès pour forcer une mise à jour, ou à l'inverse, si l'administrateur du système veut bloquer les nouvelles versions de l'application car elles n'ont pas encore été testées. Ceci peut être facilement implémenté en utilisant des règles spécifiques *User-Agent* dans le fichier de configuration `nginx`.

```text
http {

  server {
    listen       80;
    server_name  api.somedomain.com;

    # Block the latest Android App as it has not been tested
    if ( $http_user_agent ~ 'com\.dhis2/1\.2\.1/2\.2\.1/' ) {
        return 403;
    }

    # Block Android 4.4 (API is 19) as all users should have received new tablets
    if ( $http_user_agent ~ 'com\.dhis2/.*/.*/Android_19' ) {
        return 403;
    }
  }
}
```

>**Remarque**
> Pour l'implémentation de la méthode décrite ci-dessus, notez ce qui suit : 
> * Avant la version 1.1.0, la chaîne *User-Agent* n'était pas envoyée.
> * De la version 1.1.0 à la version 1.3.2, le *User-Agent* suivait le modèle Dhis2/AppVersion/AppVersion/Android_XX.
> * Depuis la version 2.0.0 et plus, le *User-Agent* suit le modèle com.dhis2/SdkVersion/AppVersion/Android_XX
> * Android_XX fait référence au niveau de l'API Android, c'est-à-dire à la version d'Android telle que répertoriée [ici] (https://developer.android.com/studio/releases/platforms).
> * nginx utilise [PCRE](http://www.pcre.org/) pour la mise en correspondance des expressions régulières.

## Référence de configuration DHIS2 (dhis.conf) { #install_dhis2_configuration_reference }

Dans ce qui suit, nous allons décrire l'ensemble complet des options de configuration pour le fichier de configuration `dhis.conf`. Le fichier de configuration doit être placé dans un répertoire vers lequel est orienté une variable d'environnement `DHIS2_HOME`.

> **Remarque**
>
> Vous ne devez pas utiliser ce fichier de configuration directement, mais plutôt comme référence pour les options de configuration disponibles. Plusieurs propriétés sont facultatives.

```properties
# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Mandatory]
# ----------------------------------------------------------------------

# Hibernate SQL dialect
connection.dialect = org.hibernate.dialect.PostgreSQLDialect

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password (sensitive)
connection.password = xxxx

# Max size of connection pool (default: 40)
connection.pool.max_size = 40

# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Optional]
# ----------------------------------------------------------------------

# Minimum number of Connections a pool will maintain at any given time (default: 5).
connection.pool.min_size=5

# Initial size of connection pool (default : 5)
#Number of Connections a pool will try to acquire upon startup. Should be between minPoolSize and maxPoolSize
connection.pool.initial_size=5

#Determines how many connections at a time will try to acquire when the pool is exhausted.
connection.pool.acquire_incr=5

#Seconds a Connection can remain pooled but unused before being discarded. Zero means idle connections never expire. (default: 7200)
connection.pool.max_idle_time=7200

#Number of seconds that Connections in excess of minPoolSize should be permitted to remain idle in the pool before being culled (default: 0)
connection.pool.max_idle_time_excess_con=0

#If this is a number greater than 0, dhis2 will test all idle, pooled but unchecked-out connections, every this number of seconds. (default: 0)
connection.pool.idle.con.test.period=0

#If on, an operation will be performed at every connection checkout to verify that the connection is valid. (default: false)
connection.pool.test.on.checkout=false

#If on, an operation will be performed asynchronously at every connection checkin to verify that the connection is valid. (default: on)
connection.pool.test.on.checkin=on

#Defines the query that will be executed for all connection tests. Ideally this config is not needed as postgresql driver already provides an efficient test query. The config is exposed simply for evaluation, do not use it unless there is a reason to.
connection.pool.preferred.test.query=select 1

#Configure the number of helper threads used by dhis2 for jdbc operations. (default: 3)
connection.pool.num.helper.threads=3

# Database datasource pool type. Supported pool types are: 
#
# * c3p0 (default): For information see https://www.mchange.com/projects/c3p0/
# 
# * hikari: For information see https://github.com/brettwooldridge/HikariCP
#
# * unpooled: Some implementations might want to have more control over the pooling and database cluster architecture 
# (e.g., using PgBouncer as pool manager behind HAProxy for load balancing). In these cases, the internal pool is un-necessary 
# and gets in the way.
db.pool.type=c3p0

# ----------------------------------------------------------------------
# Server [Mandatory]
# ----------------------------------------------------------------------

# Base URL to the DHIS 2 instance
server.base.url = https://play.dhis2.org/dev 

# Enable secure settings if system is deployed on HTTPS, can be 'off', 'on'
server.https = off

# ----------------------------------------------------------------------
# System [Optional]
# ----------------------------------------------------------------------

# System mode for database read operations only, can be 'off', 'on'
system.read_only_mode = off

# Session timeout in seconds, default is 3600
system.session.timeout = 3600

# SQL view protected tables, can be 'on', 'off'
system.sql_view_table_protection = on

# SQL view write enabled, can be 'on', 'off'
system.sql_view_write_enabled = off

# Disable server-side program rule execution, can be 'on', 'off'
system.program_rule.server_execution = on

# ----------------------------------------------------------------------
# Encryption [Optional]
# ----------------------------------------------------------------------

# Encryption password (sensitive)
encryption.password = xxxx

# ----------------------------------------------------------------------
# File store [Optional]
# ----------------------------------------------------------------------

# File store provider, currently 'filesystem' and 'aws-s3' are supported
filestore.provider = filesystem

# Directory / bucket name, folder below DHIS2_HOME on file system, 'bucket' on AWS S3
filestore.container = files

# Datacenter location (not required)
filestore.location = eu-west-1

# Public identity / username
filestore.identity = dhis2-id

# Secret key / password (sensitive)
filestore.secret = xxxx

# ----------------------------------------------------------------------
# LDAP [Optional]
# ----------------------------------------------------------------------

# LDAP server URL
ldap.url = ldaps://300.20.300.20:636

# LDAP manager user distinguished name
ldap.manager.dn = cn=JohnDoe,ou=Country,ou=Admin,dc=hisp,dc=org

# LDAP manager user password (sensitive)
ldap.manager.password = xxxx

# LDAP entry distinguished name search base
ldap.search.base = dc=hisp,dc=org

# LDAP entry distinguished name filter
ldap.search.filter = (cn={0})

# ----------------------------------------------------------------------
# Node [Optional]
# ----------------------------------------------------------------------

# Node identifier, optional, useful in clusters
node.id = 'node-1'

# ----------------------------------------------------------------------
# Monitoring [Optional]
# ----------------------------------------------------------------------

# DHIS2 API monitoring
monitoring.api.enabled = on

# JVM monitoring
monitoring.jvm.enabled = on

# Database connection pool monitoring
monitoring.dbpool.enabled = on

# Hibernate monitoring, do not use in production
monitoring.hibernate.enabled = off

# Uptime monitoring
monitoring.uptime.enabled = on

# CPU monitoring
monitoring.cpu.enabled = on

# ----------------------------------------------------------------------
# Analytics [Optional]
# ----------------------------------------------------------------------

# Analytics server-side cache expiration in seconds
analytics.cache.expiration = 3600

# Analytics unlogged tables. Accepts on/off. It's `off` by default. If enabled, this will boost the analytics table export process significantly.
# But this comes with a cost: "unlogged" tables cannot be replicated. It means that clustering won't be possible. Also, analytics tables will be automatically truncated if PostgreSQL is suddenly reset (abrupt reset/crash). If PostgreSQL is reset gracefully, it won't impact any table. The analytics tables will remain in place accordingly.
analytics.table.unlogged = on

# ----------------------------------------------------------------------
# System telemetry [Optional]
# ----------------------------------------------------------------------

# System monitoring URL
system.monitoring.url = 

# System monitoring username
system.monitoring.username = 

# System monitoring password (sensitive)
system.monitoring.password = xxxx

# ----------------------------------------------------------------------
# System update notifications [Optional]
# ----------------------------------------------------------------------

system.update_notifications_enabled = on

# ----------------------------------------------------------------------
# App Hub [Optional]
# ----------------------------------------------------------------------

# Base URL to the DHIS2 App Hub service
apphub.base.url = https://apps.dhis2.org"
# Base API URL to the DHIS2 App Hub service, used for app updates
apphub.api.url = https://apps.dhis2.org/api


# Number of possible concurrent sessions on different computers or browsers for each user. If configured to 1, the
# user will be logged out from any other session when a new session is started.
max.sessions.per_user = 10
```

## Journal des modifications { #install_changelog }

Le DHIS2 écrit des entrées dans les changelogs lorsque certaines entités sont modifiées dans le système. Ces entités appartiennent à deux catégories : _Agrégat_ et _Tracker_. La catégorie _Agrégat_ comprend les modifications apportées aux valeurs des données agrégées. Quant à la catégorie _Tracker_, elle comprend les modifications apportées aux instances de programme, aux éléments de propriété temporaire du programme, aux valeurs des attributs des entités suivies et aux valeurs des données des entités suivies.

Le changelog pour les deux catégories est activé par défaut. Vous pouvez contrôler l'activation ou la désactivation du changelog par catégorie par le biais du fichier de configuration `dhis.conf` en utilisant les propriétés décrites ci-dessous. Les options de propriétés sont `on`  (par défaut) et `off`.

L'avantage du changelog réside dans le fait qu'il permet de voir les modifications effectuées sur les données. L'avantage que présente la désactivation du changelog est une amélioration mineure des performances en évitant le coût d'écriture des éléments du changelog dans la base de données, et une réduction de la capacité de stockage de la base de données utilisée. Il est donc recommandé d'activer le changelog, et il faudra faire preuve d'une grande prudence en le désactivant.

```propriétés
# Le changelog de la catégorie Agrégat, peut être défini sur 'on', 'off'
changelog.aggregate = on

# Le changelog de la catégorie Tracker, peut être défini sur 'on', 'off'
changelog.tracker = on
```

## Journalisation des applications { #install_application_logging }

Cette section traite de la journalisation des applications dans DHIS 2.

### Fichiers journaux { #log-files }

La sortie du journal de l'application DHIS2 est dirigée vers plusieurs fichiers et emplacements. Tout d'abord, la sortie du journal est envoyée à la sortie standard. Le conteneur de servlets Tomcat envoie généralement la sortie standard vers un fichier sous "logs" (journaux) :

    <tomcat-dir>/logs/catalina.out

Ensuite, la sortie du journal est écrite dans un répertoire "logs" sous le répertoire d'accueil de DHIS2, tel que défini par les variables d'environnement de `DHIS2_HOME`. Il existe un fichier journal principal pour toutes les sorties, et des fichiers journaux distincts pour les différents processus en arrière plan. Le fichier principal comprend également les journaux des processus en arrière plan. Les fichiers journaux sont plafonnés à 50 Mo et leur contenu reçoit continuellement de nouveaux éléments.

    <DHIS2_HOME>/logs/dhis.log    
    <DHIS2_HOME>/logs/dhis-analytics-table.log
    <DHIS2_HOME>/logs/dhis-data-exchange.log
    <DHIS2_HOME>/logs/dhis-data-sync.log

### Configuration des journaux { #log-configuration }

Pour remplacer la configuration du journal par défaut, vous pouvez spécifier une propriété de système Java avec le nom `log4j2.configurationFile` et une valeur orientée vers le fichier de configuration [Log4j version 2](https://logging.apache.org/log4j/2.x/manual/configuration.html)
 sur le système de fichiers comme ce qui suit :

```propriétés
-Dlog4j2.configurationFile=/home/dhis/config/log4j2.properties
```

Les propriétés du système Java peuvent être définies, par exemple via la variable d'environnement *JAVA\_OPTS* ou dans le script de démarrage Tomcat.

Pour remplacer la configuration du journal, une deuxième approche consiste à spécifier les propriétés de journalisation dans le fichier de configuration `dhis.conf`. Les propriétés prises en charge sont :

```propriétés
# Taille maximale des fichiers journaux, la valeur par défaut est '100Mo'
journalisation.file.max_size = 250 Mo

# Nombre maximum de fichiers d'archives de journaux glissants, la valeur par défaut est 0
journalisation.file.max_archives = 2
```

DHIS2 supprimera progressivement la journalisation vers la sortie standard / catalina.out et il est donc recommandé de se fier aux journaux situés dans `DHIS2_HOME`.

DHIS2 fournira les valeurs de contexte suivantes :

* `sessionId` : ID de session de l'utilisateur actuel
* `xRequestID` : un identifiant alphanumérique tel qu'envoyé par l'en-tête HTTP `X-Request-ID` pour la requête en cours de traitement ; vide si non fourni

Pour utiliser les variables de contexte dans le journal, ajoutez-les en utilisant `-X{<name>}` à votre modèle de journal comme dans cet exemple :

    * %-5p %d{ISO8601} %m (%F [%t]) %X{sessionId} %X{xRequestID}%n

### Configuration du niveau de journalisation { #log-level-configuration }

Pour définir le niveau de journalisation des packages individuels, vous pouvez spécifier des propriétés au format `logging.level.{noms-de-package}` dans `dhis.conf`. Par exemple, pour définir le niveau de journalisation pour l'ensemble du Spring Framework à DEBUG et plus, vous pouvez spécifier :

```
logging.level.org.springframework = DEBUG
```
Pour définir le niveau de journalisation sur DEBUG pour les services DHIS2, vous pouvez spécifier :

```
logging.level.org.hisp.dhis = DEBUG
```

Les niveaux de journalisation courants sont `DEBUG`, `INFO`, `WARN` et `ERROR`.

> **Remarque**
>
> La configuration du niveau du journal n'est pas prise en charge par la version intégrée de DHIS2 Jetty.

## Travailler avec la base de données PostgreSQL { #install_working_with_the_postgresql_database }

Les opérations courantes lors de la gestion d'une instance DHIS2 sont le vidage et la restauration des bases de données. Notez que lorsque vous effectuez des sauvegardes de la base de données DHIS 2, il est préférable d'exclure les tables générées par le système, telles que les tables de ressources et d'analyses. Pour effectuer un vidage (copie) de votre base de données dans un fichier, vous pouvez appeler la commande suivante.

```bash
pg_dump {database} -U {user} -T "_*" -T "analytics*"  -f {filename}
```
Dans l'exemple suivant, le nom de la base de données est `dhis2`, l'utilisateur est `dhis` et le nom du fichier de sortie est `dhis2.sql`  :

```bash
pg_dump dhis2 -U dhis -T "analytics*" -T "_*" -f dhis2.sql
```

La compression du fichier de sortie est recommandée. Avec `gzip`, cette compression peut être fait comme ceci :

```bash
pg_dump dhis2 -U dhis -T "analytics*" -T "_*" | gzip > dhis2.sql.gz
```

Pour restaurer la copie de la base de données sur un autre système, vous devez d'abord créer une base de données vide tel que décrit dans la section sur l'installation. Vous devez également décompresser la copie à l'aide de la commande `gunzip` si vous aviez créé une version compressée. Pour restaurer la copie, vous pouvez appeler la commande suivante :

```bash
psql -d dhis2 -U dhis -f dhis2.sql
```



# Upgrading { #upgrading-dhis2 }

## Upgrading vs. Updating { #upgrading-vs-updating }

When we talk about upgrading DHIS2, we generally simply mean "moving to a newer version". However, there is an important distinction between *upgrading* and *updating*.

**Upgrading**
:   Moving to a newer base version of DHIS2 (for example, from 2.34 to 2.36). Upgrading typically requires planning, testing, training (for new features or interfaces), which may take significant time and effort.

**Updating**
:   Moving to a newer patch of the current DHIS2 version (for example, from 2.35.1 to 2.35.4). Updating mainly provides bug fixes without changing the functionality of the software. It is lower risk, and we advise everyone to keep their version up to date.

## Before you begin { #upgrading-before-you-begin }

> **Caution**
>
> It is important to note that once you upgrade you will not be able to use the upgraded database with an older version of DHIS2. That is to say **it is not possible to downgrade**.
>
> If you wish to revert to an older version, you must do so with a copy of the database that was created from that older version, or a previous version. Therefore, it is almost always a good idea to make a copy of your database before you uprgrade.

## Performing the upgrade { #upgrading-process }

Regardless of whether you are upgrading or updating, the technical process is more-or-less identical. We will just refer to it as upgrading.

### 1 Safeguard your data { #upgrading-safeguard-your-data }

Depending on what sort of DHIS2 instance you have, and what you use it for, the first step is to make sure that you can recover any important data if anything goes wrong with the upgrade.

This means performing standard system admin tasks, such as:

1. Backing up your database
2. Testing in a development environment
3. Scheduling down time (to avoid data being entered during the upgrade)
4. etc.

### 2 Upgrade the software { #upgrading-upgrade-the-software }

#### From v2.29 or below { #upgrading-pre-230 }

If you are starting from v2.29 or below, you must first upgrade to v2.30 version-by-version, manually, following the upgrade notes you find under the specific version numbers on [our releases site](https://github.com/dhis2/dhis2-releases). When you are at v2.30 you can go to the next section.

#### From v2.30 or above { #upgrading-post-230 }

If you are starting from at least v2.30:

1. **Read all of the upgrade notes from your current version up to the target version on [our releases site](https://github.com/dhis2/dhis2-releases).** Make sure your environment meets all of the requirements
2. Stop the server
3. Make a final copy of your database (and ensure it is not corrupted)
4. Drop any materialized SQL views from your database
5. Replace the war file with the target version (There is no need to upgrade to intermediate versions; in fact, it is not recommended)
6. Start the server

You should now be ready to enjoy the new fixes and features.



# Surveillance { #monitoring }

## Introduction { #monitoring } 

DHIS2 peut exporter des mesures compatibles avec [Prometheus] (https://prometheus.io/) pour surveiller les nœuds de DHIS2.

This section describes the steps required to install Prometheus and [Grafana](https://grafana.com/) using a standard installation procedure (`apt-get`) and Docker and configure Grafana to show DHIS2 metrics.

For a list of the metrics exposed by a DHIS2 instance, please refer to the monitoring guide on [GitHub](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md).

## Setup { #monitoring_setup } 

The next sections describe how to set up Prometheus and Grafana and how to set up Prometheus to pull data from one or more DHIS2 instances.

### Installing Prometheus + Grafana on Ubuntu and Debian { #prometheus } 

- Download Prometheus from the official [download](https://prometheus.io/download/) page.

- Make sure to filter for your operating system and your CPU architecture (Linux and amd64).

- Make sure to select the latest stable version, and not the “rc” one, as it is not considered stable enough for now.

- Download the archive, either by clicking on the link or using `wget`.

```
wget https://github.com/prometheus/prometheus/releases/download/v2.15.2/prometheus-2.15.2.linux-amd64.tar.gz
```

- Untar the zip 

```
tar xvzf prometheus-2.15.2.linux-amd64.tar.gz
```

The archive contains many important files, but here is the main ones you need to know.

- `prometheus.yml`: the configuration file for Prometheus. This is the file that you are going to modify in order to tweak your Prometheus server, for example to change the scraping interval or to configure custom alerts;
- `prometheus`: the binary for your Prometheus server. This is the command that you are going to execute to launch a Prometheus instance on your Linux box;
- `promtool`: this is a command that you can run to verify your Prometheus configuration.

### Configuring Prometheus as a service { #prometheus_service } 

- Create a `Prometheus` user with a `Prometheus` group.

```
useradd -rs /bin/false prometheus
```

- Move the Prometheus binaries to the local bin directory

```
cd prometheus-2.15.2.linux-amd64/ 
cp prometheus promtool /usr/local/bin
chown prometheus:prometheus /usr/local/bin/prometheus
```

- Create a folder in the `/etc` folder for Prometheus and move the console files, console libraries and the prometheus configuration file to this newly created folder.

```
mkdir /etc/prometheus
cp -R consoles/ console_libraries/ prometheus.yml /etc/prometheus
```

Create a data folder at the root directory, with a prometheus folder inside.

```
mkdir -p data/prometheus
chown -R prometheus:prometheus /data/prometheus /etc/prometheus/*
```

### Create a Prometheus service { #prometheus_create_service } 

To create a Prometheus _systemd_ service, head over to the `/lib/systemd/system` folder and create a new systemd file named `prometheus.service`.

```
cd /lib/systemd/system
touch prometheus.service
```

- Edit the newly created file, and paste the following content inside:

```properties
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prometheus
Group=prometheus
ExecStart=/usr/local/bin/prometheus \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path="/data/prometheus" \
  --web.console.templates=/etc/prometheus/consoles \
  --web.console.libraries=/etc/prometheus/console_libraries \
  --web.listen-address=0.0.0.0:9090 \
  --web.enable-admin-api

Restart=always

[Install]
WantedBy=multi-user.target
```

- Save the file and enable the Prometheus service at startup

```
systemctl enable prometheus
systemctl start prometheus
```

- Test that the service is running

```
systemctl status prometheus

...
Active: active (running)
```

- It should be now possible to access the Prometheus UI by accessing `http://localhost:9090`.


### Set-up Nginx reverse proxy { #prometheus_nginx } 

Prometheus does not natively support authentication or TLS encryption. If Prometheus has to be exposed outside the boundaries of the local network, it is important to enable authentication and TLS encryption. The following steps show how to use Nginx as a reverse proxy.

- Install Nginx, if not already installed

```
apt update
apt-get install nginx
```

By default, Nginx will start listening for HTTP requests in the default `http` port, which is `80`.

If there is already an Nginx instance running on the machine and you are unsure on which port it is listening on, run the following command:

```
> lsof | grep LISTEN | grep nginx

nginx   15792   root   8u   IPv4   1140223421   0t0   TCP *:http (LISTEN)
```

The last column shows the port used by Nginx (`http` -> `80`).

By default, Nginx configuration is located in `/etc/nginx/nginx.conf`

Make sure that `nginx.conf` contains the `Virtual Host Config` section

```
##
# Virtual Host Configs
##

include /etc/nginx/conf.d/*.conf;
include /etc/nginx/sites-enabled/*;

```

- Create a new file in `/etc/nginx/conf.d` called `prometheus.conf`

```
touch /etc/nginx/conf.d/prometheus.conf
```

- Edit the newly created file, and paste the following content inside:

```
server {
  listen 1234;

  location / {
    proxy_pass           http://localhost:9090/;
  }
}
```

- Restart Nginx  and browse to http://localhost:1234

```
systemctl restart nginx

# in case of start-up errors
journalctl -f -u nginx.service
```

- Configure Prometheus for reverse proxying, by editing `/lib/systemd/system/prometheus.service` and add the following argument to the list of arguments passed to the Prometheus executable.

```
--web.external-url=https://localhost:1234
```

- Restart the service

```
systemctl daemon-reload
systemctl restart prometheus


# in case of errors
journalctl -f -u prometheus.service
```

### Enable reverse proxy authentication { #prometheus_auth } 

This section shows how to configure basic authentication via the reverse proxy. If you need a different authentication mechanism (SSO, etc.) please check the relevant documentation.

- Make sure that `htpasswd` is installed on the system

```
apt-get install apache2-utils
```

- Create an authentication file

```
cd /etc/prometheus
htpasswd -c .credentials admin 
```

Choose a strong password, and make sure that the pass file was correctly created.

- Edit the previously created Nginx configuration file (`/etc/nginx/conf.d/prometheus.conf`), and add the authentication information.

```
server {
  listen 1234;

  location / {
    auth_basic           "Prometheus";
    auth_basic_user_file /etc/prometheus/.credentials;
    proxy_pass           http://localhost:9090/;
  }
}
```

- Restart Nginx

```
systemctl restart nginx

# in case of errors
journalctl -f -u nginx.service
```

- `http://localhost:1234` should now prompt for username and password.

### Installing Grafana on Ubuntu and Debian { #grafana } 

- Add a `gpg` key and install the OSS Grafana package from APT repo

```sh
apt-get install -y apt-transport-https

wget -q -O - "https://packages.grafana.com/gpg.key" | sudo apt-key add -

add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"

apt-get update

apt-get install grafana
```

- If the system is using `systemd`, a new `grafana-service` is automatically created. Check the `systemd` file to gain some insight on the Grafana installation

```
cat /usr/lib/systemd/system/grafana-server.service
```

This file is quite important because it offers information about the newly installed Grafana instance.

The file shows:

The **Grafana server binary** is located at `/usr/sbin/grafana-server`.
The file that defines all the **environment variables** is located at `/etc/default/grafana-server`
The **configuration file** is given via the `CONF_FILE` environment variable.
The **PID of the file** is also determined by the `PID_FILE_DIR` environment variable.
**Logging**, **data**, **plugins** and **provisioning** paths are given by environment variables.

- Start the server

```
systemctl start grafana-server
```

- Access Grafana web console: http://localhost:3000

The default login for Grafana is `admin` and the default password is also `admin`.
You will be prompted to change the password on first access.

- Configure Prometheus as a Grafana datasource

Access to the datasources panel by clicking on `Configuration` > `Data sources` via the left menu.

Click on `Add a datasource`

Select a Prometheus data source on the next window.

Configure the datasource according to the Prometheus setup (use authentication, TSL, etc.)

### Installing Prometheus + Grafana using Docker { #prometheus_grafana_docker } 

This section describes how to start-up a Prometheus stack containing Prometheus and Grafana.

The configuration is based on this project: https://github.com/vegasbrianc/prometheus

- Clone this Github project: https://github.com/vegasbrianc/prometheus

- Start the Prometheus stack using:

```
docker stack deploy -c docker-stack.yml prom
```

The above command, may result in the following error:

*This node is not a swarm manager. Use "docker swarm init" or "docker swarm join" to connect this node to swarm and try again*

If that happens, you need to start Swarm. You can use the following command line:

```
docker swarm init --advertise-addr <YOUR_IP>
```

Once this command runs successfully, you should be able to run the previous command without problems.

The stack contains also a Node exporter for Docker monitoring. If you are not interested in Docker monitoring, you can comment out the relevant sections in the `docker-stack.yml` file:

- `node-exporter`
- `cadvisor`

- To stop the Prometheus stack:

```
docker stack rm prom
```

The Prometheus configuration (`prometheus.yml`) file is located in the `prometheus` folder.

- Access Grafana web console at: http://localhost:3000 with username: `admin` and password: `foobar`

### Configure Prometheus to pull metrics from one or more DHIS2 instances { #prometheus_dhis2 } 

Prior to using Prometheus, it needs basic configuring. Thus, we need to create a configuration file named `prometheus.yml`

> **Note**
>
> The configuration file of Prometheus is written in YAML which strictly forbids to use tabs. If your file is incorrectly formatted, Prometheus will not start. Be careful when you edit it.

Prometheus’ configuration file is divided into three parts: `global`, `rule_files`, and `scrape_configs`.

In the global part we can find the general configuration of Prometheus: `scrape_interval` defines how often Prometheus scrapes targets, `evaluation_interval` controls how often the software will evaluate rules. Rules are used to create new time series and for the generation of alerts.

The `rule_files` block contains information of the location of any rules we want the Prometheus server to load.

The last block of the configuration file is named `scape_configs` and contains the information which resources Prometheus monitors.

A simple DHIS2 Prometheus monitoring file looks like this example:

```yaml
global:
  scrape_interval:     15s
  evaluation_interval: 15s 

scrape_configs:
  - job_name: 'dhis2'
    metrics_path: '/dhis/api/metrics'
    basic_auth:
      username: admin
      password: district
    static_configs:
      - targets: ['localhost:80']
```

The global `scrape_interval` is set to 15 seconds which is enough for most use cases.

In the `scrape_configs` part we have defined the DHIS2 exporter.
The `basic_auth` blocks contains the credentials required to access the `metrics` API: consider creating an ad-hoc user only for accessing the `metrics` endpoint.

Prometheus may or may not run on the same server as DHIS2: in the above configuration, it is assumed that Prometheus monitors only one DHIS2 instance, running on the same server as Prometheus, so we use `localhost`.

### Configure the DHIS2 exporter { #dhis2_metrics_conf } 

The monitoring subsystem is disabled by default in DHIS2.

Each metrics cluster has to be explicitly enabled in order for the metrics to be exported. To configure DHIS2 to export one or more metrics, check this [document](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md#dhis2-monitoring-configuration).




# Audit { #audit }

## Introduction { #introduction } 

DHIS2 prend en charge un nouveau service d'audit basé sur _Apache ActiveMQ Artemis_. Artemis est utilisé comme système de messagerie asynchrone par DHIS2.

Une fois qu'une entité est enregistrée dans la base de données, un message d'audit sera généré et envoyé au service utilisateur de la messagerie Artemis. Le message sera ensuite traité dans un autre fil de discussion.

Les journaux d'audit peuvent être récupérés à partir de la base de données de DHIS2. Actuellement, aucun point d'extrémité d'une interface utilisateur ou d'une API n’est disponible pour récupérer les entrées d’audit.

Vous trouverez une explication détaillée de l'architecture du système d'audit [ici](https://github.com/dhis2/wow-backend/blob/master/guides/auditing.md).

## What we log { #what_we_log }

This is the list of operations we log as part of the audit system:

- Operations on user accounts (like but not limited to creation, profile edits)
- Operations on user roles, groups and authority groups
- Operations on metadata objects (like but not limited to categories, organization units, reports)
- Operations on tracked objects (like but not limited to instances, attributes, data values)
- Jobs configuration
- Breaking the glass operations

## Single Audit table { #audit_table } 

All audit entries, except the ones related to tracked entities, will be saved into one single table named `audit`

| Colonne     | Type                        | Description |
|------------|-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|
| auditid    | integer                     | Primary key. |
| audittype  | texte                        | READ, CREATE, UPDATE, DELETE, SEARCH |
| auditscope | texte                        | METADATA, AGGREGATE, TRACKER |
| klass      | texte                        | Audit Entity Java class name. |
| attributes | jsonb                       | A JSON string with attributes of the audited object. Example: `{"valueType":"TEXT", "categoryCombo":"SWQW313FQY", "domainType":"TRACKER"}`. |
| données       | bytea                       | Compressed JSON string of the audit entity in byte array format (not humanly readable). |
| createdat  | timestamp without time zone | Time of creation. |
| createdby  | texte                        | Username of the user performing the audited operation. |
| uid        | texte                        | The UID of the audited object. |
| code       | texte                        | The code of the audited object. |

The audit service makes use of two new concepts: *Audit Scope* and *Audit Type*.

## Audit Scope { #audit_scope } 

An audit scope is a logical area of the application which can be audited. Currently there are three audit scopes.

| **Scope** | Clé       | Audited objects                                              |
| --------- | --------- | ------------------------------------------------------------ |
| Tracker   | tracker   | Tracked Entity Instance, Tracked Entity Attribute Value, Enrollment, Event. |
| Métadonnées  | metadata  | All metadata objects (e.g. Data Element, Organisation Unit). |
| Agrégation | aggregate | Aggregate Data Value.                                        |


## Audit Type { #audit_type } 

An audit type is an action that triggers an audit operation. Currently we support the following four types.

| Nom     | Clé      | Description         |
| -------- | -------- | ------------------- |
| Read     | READ     | Object was read.    |
| Créer   | CREATE   | Object was created. |
| Mise à jour   | UPDATE   | Object was updated. |
| Supprimer   | DELETE   | Object was deleted. |
| Disabled | DISABLED | Disable audit.      |

> **Caution**
>
> The READ audit type may generate a lot of data in the database and may have an impact on the performance.


## Tracked entity audits { #tracked-entity-audits } 

Operations on tracked entities like instances, attributes and values are stored, respectively in the `trackedentityinstanceaudit`, `trackedentityattributevalueaudit` and `trackedentitydatavalueaudit` tables.

### trackedentityinstanceaudit { #trackedentityinstanceaudit } 

| Colonne     | Type                        | Description |
|------------|-----------------------------|-------------|
| trackedentityinstanceauditid | integer | Primary key. |
| trackedentityinstance | texte  | Tracked entity instance name.  |
| créé  | timestamp without time zone | Time of creation. |
| accessedby | texte | Username of the user performing the audited operation. |
| audittype | texte | READ, CREATE, UPDATE, DELETE, SEARCH |
| commentaire | texte | The code of the audited object. |

This data can be retrieved via [API](#webapi_tracked_entity_instance_audits).

### trackedentityattributevalueaudit { #trackedentityattributevalueaudit } 

| Colonne     | Type                        | Description |
|------------|-----------------------------|-------------|
| trackedentityattributevalueauditid | integer | Primary key. |
| trackedentityinstanceid | integer | Instance ID of which the attribute value belongs to.  |
| trackedentityattributeid | integer | Attribute ID.  |
| créé  | timestamp without time zone | Time of creation. |
| modifiedby  | texte | Username of the user performing the audited operation. |
| audittype | texte  | READ, CREATE, UPDATE, DELETE, SEARCH |
| valeur | texte | The value of the audited object. |
| encryptedvalue | texte | The encrypted value if confidentiality flag is set. |


This data can be retrieved via [API](#webapi_tracked_entity_attribute_value_audits).

### trackedentitydatavalueaudit { #trackedentitydatavalueaudit } 

| Colonne     | Type                        | Description |
|------------|-----------------------------|-------------|
| trackedentitydatavalueauditid | integer | Primary key. |
| programstageinstanceid | integer | Program stage ID of which the data value belongs to.  |
| dataelementid | integer | ID of the data element.  |
| créé | timestamp without time zone | Time of creation. |
| modifiedby | texte | Username of the user performing the audited operation. |
| audittype | texte | READ, CREATE, UPDATE, DELETE, SEARCH |
| valeur | texte | The value of the audited object. |
| providedelsewhere | bool | Indicates whether the user provided the value elsewhere or not. |

This data can be retrieved via [API](#webapi_tracked_entity_data_value_audits).

## Briser le verre { #breaking-the-glass } 
Breaking the glass features allows to access records a DHIS2 user doesn't have access in special circumstances. As a result of such, users must enter a reason to access such records.

A video explaining how it works can be found in our Youtube channel [here](https://www.youtube.com/watch?v=rTwg5Ix_E_M).

The breaking the glass event is stored in the `programtempownershipaudit` table, described below:

| Colonne     | Type  | Description |
|------------|-------|-------------|
| programtempownershipauditid | integer | Primary key. |
| programid | integer | Program ID of which the tracked entity belongs to.  |
| trackedentityinstanceid | integer | Instance ID of which the attribute value belongs to.  |
| créé  | timestamp without time zone | Time of creation. |
| accessedby  | texte | Username of the user performing the audited operation. |
| reason       | texte | The reason as inserted in the dialog. |


## Setup { #audit_configuration } 

The audit system is enabled by default for the following scopes and types.

Scopes (case sensitive):

- `CREATE`
- `UPDATE`
- `DELETE`

Types:

- `METADATA`
- `TRACKER`
- `AGGREGATE`

This means that **no action is required** to enable the default audit system. The default setting is equivalent to the following `dhis.conf` configuration.

```properties
audit.metadata = CREATE;UPDATE;DELETE
audit.tracker = CREATE;UPDATE;DELETE
audit.aggregate = CREATE;UPDATE;DELETE
```

The audit can be configured using the _audit matrix_. The audit matrix represents the valid combinations of scopes and types, and is defined with the following properties in the `dhis.conf` configuration file. Each property accepts a semicolon (`;`) delimited list of audit types.

* `audit.metadata`
* `audit.tracker`
* `audit.aggregate`

### Artemis { #artemis } 
[Apache ActiveMQ Artemis](https://activemq.apache.org/components/artemis/documentation/) is an open source project to build a multi-protocol, embeddable, very high performance, clustered, asynchronous messaging system. It has been part of DHIS2 since version 2.31 and used as a system to consume audit logs.

By default, DHIS2 will start an embedded Artemis server, which is used internally by the application to store and access audit events.

However, if you have already an Artemis server, you can connect to it from DHIS2 to send audit events, as described in our [official documentation](#webapi_amqp_configuration): in this setup, audit events will flow from DHIS2 to the external Artemis system.

### log4j2 { #log4j2 } 
[log4j2](https://logging.apache.org/log4j/2.x/index.html) is the default DHIS2 logging library used to handle output messages. It's used to control what events are recored in which file.

The application ships a [log4j2 default configuration file](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-web/dhis-web-commons-resources/src/main/webapp/WEB-INF/classes/log4j2.xml), which instructs what information to log and where (console). DHIS2 then takes care of import that file and instruction logging as described in the [log4j configuration class](https://github.com/dhis2/dhis2-core/blob/2.38/dhis-2/dhis-support/dhis-support-system/src/main/java/org/hisp/dhis/system/log/Log4JLogConfigInitializer.java), that is, redirecting output from console to files.

From 2.36 to 2.38, audit log file `dhis-audit.log` is rotated [every day at midnight](https://github.com/dhis2/dhis2-core/blob/2.38/dhis-2/dhis-support/dhis-support-system/src/main/java/org/hisp/dhis/system/log/Log4JLogConfigInitializer.java#L171).

An example of custom log4j2 configuration can be found [here](): it shows how to configure DHIS2 to save all logs into an external storage location, rotate them on a weekly basis and retain them for 30 days. Please read the [application logging section](#install_application_logging) on how to use it.

## Examples { #examples } 

This section demonstrates how to configure the audit system in `dhis.conf`.

To enable audit of create and update of metadata and tracker only:

```properties
audit.metadata = CREATE;UPDATE
audit.tracker = CREATE;UPDATE
audit.aggregate = DISABLED
```

To only audit tracker related objects create and delete:

```properties
audit.metadata = DISABLED
audit.tracker = CREATE;DELETE
audit.aggregate = DISABLED
```

To completely disable audit for all scopes:
```properties
audit.metadata = DISABLED
audit.tracker = DISABLED
audit.aggregate = DISABLED
```

We recommend keeping the audit trails into a file, as by default in version 2.38. For older versions, the following configuration saves the audit logs into the `$DHIS2_HOME/logs/dhis-audit.log` file:
```properties
audit.database = off
audit.logger = on
```

To store audit data into the database, add the following to your `dhis.conf` file (default up until version 2.38):
```properties
audit.database = on
audit.logger = off
```

To extract logs from the `audit` table, you can use [`dhis2-audit-data-extractor`](https://github.com/dhis2/dhis2-utils/tree/master/tools/dhis2-audit-data-extractor) from the system where DHIS2 is running:
```
$ python extract_audit.py extract
```

Please read the documentation for full details.

To parse entries from log file, you can use the python script as follow:
```
$ grep "auditType" dhis-audit.log | python extract_audit.py parse
```

Or use `jq` as follow:

```
$ grep "auditType" dhis-audit.log | jq -r .
```

To select events within a specific date, you can use `jq` as follow (in this example, we're selecting all events happened between January 2022 and end of June 2022):

```
$ grep "auditType" dhis-audit.log | jq -r '.[] | select ( (.datetime >="2022-01-01") and (.datetime <= "2022-06-30") )'
```

Same with `extract_audit`:
```
$ python3 extract_audit.py extract -m stdout -f JSON | jq -r '.[] | select ( (.datetime >="2022-01-01") and (.datetime <= "2022-06-30") )'
```


# Utilisation de passerelles pour l'établissement de rapports SMS { #sms_report_sending }

DHIS2 prend en charge la réception des données par [SMS](https://docs.dhis2.org/master/en/dhis2_user_manual_en/mobile.html). Cependant, le SMS doit être compressé. L'application Android de DHIS2 fait office de couche transparente pour l'envoi des informations par SMS où l'utilisateur n'a pas à se préoccuper de la rédaction du SMS. Pour envoyer des SMS à l'aide de l'application Android, la passerelle SMS doit être correctement configurée. Cette section explique les différentes options disponibles et comment procéder.

## Envoi de SMS { #sms_report_sening }

Avant toute chose, il est important de préciser que cette section traite principalement de la configuration de la **réception de SMS** (des appareils mobiles vers le serveur DHIS2). Cette configuration est nécessaire lorsque l'on envisage d'utiliser l'application pour envoyer (synchroniser) par SMS, les informations enregistrées dans l'application vers le serveur DHIS2. Dans l'application, cette configuration peut être effectuée dans *Paramètres* > *Paramètres SMS*.

L’envoi de SMS, du serveur DHIS2 vers les appareils mobiles, est relativement simple à configurer. S'il s'agit juste d'envoyer des notifications aux téléphones des utilisateurs depuis DHIS2 lorsque certains événements se produisent (messagerie, seuils, etc.), seul l'envoi de SMS est requis.

Tout ceci peut être configuré sur la page de configuration du service SMS dans la [section Configuration mobile](https://docs.dhis2.org/master/en/user/html/mobile_sms_service.html).

Les fournisseurs habituels tels que *Bulk SMS* et *Clickatell* sont pris en charge par défaut, et ces deux fournisseurs permettent d'envoyer des SMS vers des numéros de la plupart des pays.

Notez également qu'il est possible d'utiliser différentes passerelles SMS pour l'envoi et la réception de SMS. Ainsi, même si vous mettez en place une des solutions ci-dessous pour la réception de SMS, vous pouvez toujours utiliser l'une des solutions susmentionnées pour l'envoi.

## Utilisation d'un appareil Android comme passerelle SMS { #sms_report_android_gateway }

La solution la plus simple, et de loin, consiste à utiliser un appareil Android comme passerelle SMS. Tout téléphone ou tablette fonctionnant sous Android OS (4.4, Kitkat ou supérieur) devrait faire l'affaire. L'appareil aura besoin d'une connexion internet permanente pour transférer les messages vers votre serveur DHIS2 et d'une carte SIM pour recevoir les SMS.

Il vous faudra télécharger et installer l'application Passerelle SMS Android de DHIS2 sur l'appareil mobile. Vous trouverez une liste des [versions] disponibles à cette adresse : (https://github.com/dhis2/dhis2-sms-android-gateway/releases). Vous pourrez y télécharger le fichier APK le plus récent et l'installer. Des instructions sont fournies sur la page de l'application elle-même, mais il suffit de lancer l'application et d'entrer les informations de votre serveur DHIS2 (URL, nom d'utilisateur et mot de passe).

Une fois l'application installée et opérationnelle, entrez le numéro de téléphone de cette passerelle sur la page de configuration des appareils mobiles qui utilisent l'application DHIS2 Capture. Ainsi, lorsque des SMS seront envoyés à partir de ces appareils, ils sont reçus par la passerelle et automatiquement transmis au serveur DHIS2 où ils sont traités.

L'utilisation de cette passerelle est idéale quand il s'agit de tester la fonctionnalité SMS, mais elle ne doit pas être utilisée pour la production, car elle présente plusieurs défauts, tels que l'impossibilité de gérer des SMS en plusieurs parties ou des SMS simultanés, et elle peut même être tuée par le système d'exploitation Android. Par conséquent, si vous envisagez de passer un projet au niveau de la production, il serait nécessaire d'étudier l'une des solutions plus permanentes et plus fiables pour les passerelles présentées ci-dessous.

### Envoi de SMS à l'aide d'une passerelle Android { #sending-sms-using-an-android-device-gateway }

Cette option n'est actuellement ni prise en charge ni documentée.

## Passerelles SMS dédiées { #sms_report_dedicated_gateway }

This section discusses the use of more permanent and dedicated SMS gateways and the options available. Each of these options below will involve a provider (or yourself) having an SMPP connection to a phone carrier in country and using this connection to receive incoming SMS and forward them on to your DHIS2 server over the internet using HTTP.

These solutions can either use a **long number** or **short code**. A long number is a standard mobile phone number of the type that most private people use, i.e. +61 400123123. A short code is simply a short number, such as 311. Short codes typically cost more to set up and maintain.

### Ensuring incoming SMS to DHIS2 server are formatted correctly { #ensuring-incoming-sms-to-dhis2-server-are-formatted-correctly } 

When sending incoming SMS to a DHIS2 server via the API you use the following URL: *https://<DHIS2_server_url>/api/sms/inbound*

In DHIS2 version 2.34 and below, this endpoint requires the format of inbound SMS to be in a very specific format, i.e. the message itself must be a parameter called text, the phone number of the sender must be a parameter called originator.

When using all of the below SMS gateway options, when you configure them to forward incoming SMS on to another web service, they will each have their own format, which will be different to the one expected by the DHIS2 API. For this reason then, it’s necessary to reformat them before sending them on to the DHIS2 server.

One option is to run your own very simple web service, which simply receives the incoming SMS from the gateway provider, reformats it to the one required for DHIS2 and forwards it on to your DHIS2 API. Such a service would need to be written by a software developer.

In DHIS2 version 2.35, it is planned to support these cases with a templating system for incoming SMS, so you can specify the format of the messages which will be sent from your provider. That way, you can configure the DHIS2 server to accept incoming SMS from any other SMS gateway provider and they can directly send incoming SMS to the DHIS2 API, without the need for such a formatting web service.

### Using RapidPro { #using-rapidpro } 

[RapidPro](https://rapidpro.io/) is a service run by UNICEF in over 50 countries around the world. It is a collection of software which works with in-country phone carriers to enable organisations to design SMS solutions for their projects, such as SMS reporting or awareness campaigns.

The RapidPro service will involve an SMPP connection to one or more phone carriers in-country, usually via a shortcode, potentially dedicated to Health work for NGOs. It’s then possible to add a webhook so that incoming SMS are forwarded to another web service, such as the formatting web service described above. If the shortcode is used for other purposes as well, it may be necessary to add the phone numbers of your reporting devices to a separate group, so that only the incoming SMS from those devices is forwarded to the webhook.

RapidPro is currently set up and running in roughly half of the countries which are currently using or piloting DHIS2. Before considering one of the solutions below, which can be costly in terms of both finance and time, it is worth getting in contact with Unicef to see if RapidPro is available and if it can be used for health reporting in your country.

### Using commercial SMS gateway providers { #using-commercial-sms-gateway-providers } 

Of the commercial SMS gateway providers mentioned in the Sending SMS section above, they will usually have capability to *send* SMS in most countries but can only support *receiving* SMS in a limited amount of countries. The majority of countries they support receiving SMS in are not those using DHIS2. Of the countries that are using DHIS2, most are already covered by having a RapidPro service running in-country.

However, it is worth researching what commercial options are available for your country. In some countries there will be small national companies that provide SMS services, they’ll have existing SMPP connections with the phone providers you can use.

### Using phone carriers directly { #using-phone-carriers-directly } 

If none of the above solutions are available it would be necessary to approach the phone carriers in your country directly. The first question to ask them would be whether they are aware of any companies which are operating SMPP connections with them which you may be able to approach.

If not, as a final option, you would need to consider setting up and maintaining your own SMPP connection with the phone provider. However, not all phone providers might offer such a service.

You would need to run your own server running software such as [Kannel](https://www.kannel.org/), which connects (usually via a VPN) to an SMPP service running in the phone providers network. With this in place, any incoming SMS for the configured long number or shortcode are sent from the phone carrier to your Kannel server and you can then forward on these messages as above.

### Receiving concatenated or multipart SMS { #receiving-concatenated-or-multipart-sms } 

When syncing data via SMS with the DHIS2 Android App, it uses a compressed format to use as little space (characters of text) as possible. Despite this, it will quite often be the case that a message will extend over the 160 character limit of one standard SMS. On most modern mobile devices these messages will still be sent as one concatenated or multipart SMS, and received as one message. 

When selecting an SMS gateway then, it is important to confirm that the phone carrier used supports concatenated SMS. Most of them will support this, but it is important to confirm as the SMS functionality will not work if SMS are split. This relies on something called a UDH (User Data Header). When discussing with providers then, ensure you ask if it is supported.



# Using the User Impersonation Feature in DHIS2 { #user_impersonation }

## Aperçu { #overview } 

User impersonation, also known as user switching, is a powerful feature provided in DHIS2 for administrative users to
log in as another user. This feature is especially useful for troubleshooting or resolving user-related issues, as it
allows an administrator to experience DHIS2 exactly as the user does.

This feature is built upon the `SwitchUserFilter` from Spring Security, but with additional configuration options.

> **Note**
>
> The feature is **disabled** by default. To enable it, you must set the `switch_user_feature.enabled` property
> to `true` in
> your `dhis.conf` file.
>
> This feature is considered **experimental** and is only meant to be called from configured IP address(s). Hence, to
> use it
> you must know the IP address from which you will be calling it and configure the `switch_user_allow_listed_ips`
> property
> in the `dhis.conf` file. This restriction might be removed in the future.

## How It Works { #how-it-works } 

The user impersonation feature operates in the following manner:

1. An administrative user makes a request to a specific URL (e.g., `/impersonate?username=USERNAME`) with the `username`
   paramètre du segment
   indicating the username of the user they wish to impersonate.

2. The user impersonation feature intercepts this request, switches the `SecurityContext` to the new user, and redirects
   to the home page.

3. While impersonating another user, the administrative user can make requests as if they were the impersonated user.

4. To switch back to the original user, the administrative user makes a request to another URL (
   e.g., `/impersonateExit`). The user impersonation feature intercepts this request, switches the `SecurityContext`
   back to the original user, and redirects to the home page.

## How To Use { #how-to-use } 

Follow these steps to use the user impersonation feature:

1. Log in as an administrative user with either the `ALL` or `F_IMPERSONATE_USER` authority.
2. Navigate to the URL for user impersonation (e.g., `/impersonate?username=USERNAME`).
3. Provide the `username` parameter of the user you wish to impersonate.
4. The system will switch your session to that of the impersonated user, and you will be redirected to the home page.
5. Perform any actions necessary for troubleshooting or user support.
6. When you're finished, navigate to the URL to end impersonation (e.g., `/impersonateExit`). Your session will be
   switched back to your original administrative user.

## Configuration { #configuration } 

The user impersonation feature configuration options.

* `switch_user_feature.enabled` (Enable or disable the feature, default: `disabled`)
* `switch_user_allow_listed_ips` (Default allowed IP(s) are; `localhost,127.0.0.1,[0:0:0:0:0:0:0:1]`)

## Security restrictions { #security-restrictions } 
* Feature must be enabled in the `dhis.conf` configuration file, default value is; `disabled`.
* Users trying to impersonate need to send requests from an allowed IP.
* Users without the `ALL` authority can not impersonate another user that has the `ALL` authority.
* Users can not impersonate themselves.

## Security Implications { #security-implications } 

This feature should be used with caution due to its inherent security implications. Only trusted administrators should
be granted the capability to impersonate users. It's also recommended to pay attention to the log events related to the
user impersonation.

User impersonation events are logged in the following
format: `Authentication event: AuthenticationSwitchUserEvent; username: USER_DOING_THE_IMPERSONATION; targetUser: USER_BEING_IMPERSONATED;`

