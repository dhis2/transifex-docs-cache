---
revision_date: '2024-01-18'
tags:
- Version principale de DHIS 2.38
- Développement
template: single.html
---

# Aperçu { #webapi } 

L'API Web est un composant qui permet aux systèmes externes d'accéder 
aux données stockées dans une instance DHIS2 et de les manipuler. Plus 
précisément, elle fournit une interface programmatique à un large éventail de 
données exposées et de méthodes de service pour des applications telles que des clients 
logiciels tiers, des portails web et des modules DHIS2 internes.

## Introduction { #webapi_introduction } 

The Web API adheres to many of the principles behind the REST
architectural style. To mention some few and important ones:

1.  Les éléments fondamentaux sont appelés *ressources*. Une 
    ressource peut être tout ce qui est exposé sur le web, d'un document à un 
    processus d'entreprise - tout ce avec quoi un client peut vouloir interagir.
    Les aspects informatifs d'une ressource peuvent être récupérés ou échangés 
    par le biais de *représentations* de la ressource. Une représentation est une vue de 
    resource's state at any given time. For instance, the *reportTable*
    resource in DHIS2 represents a tabular report of aggregated data for
    un certain ensemble de paramètres. Cette ressource peut être récupérée dans 
    variety of representation formats including HTML, PDF, and MS Excel.

2.  Toutes les ressources peuvent être identifiées de manière unique par un *URI* (également 
    appelé *URL*). Toutes les ressources ont une représentation par défaut. Vous pouvez 
    indiquer que vous êtes intéressé par une représentation spécifique en 
    fournissant un en-tête HTTP *Accept*, une extension de fichier ou un paramètre de requête *format*. 
    query parameter. So in order to retrieve the PDF representation of a
    report table you can supply an *Accept: application/pdf* header or
    append *.pdf* or *?format=pdf* to your request URL.

3.  Les interactions avec l'API nécessitent l'utilisation correcte des *méthodes* ou 
    *verbes* HTTP. Cela implique que pour une ressource, vous devez émettre une requête *GET* 
    lorsque vous souhaitez la récupérer, une requête *POST* lorsque vous souhaitez 
    en créer une, une requête *PUT* lorsque vous souhaitez la mettre à jour et une requête *DELETE* lorsque 
    you want to remove it. So if you want to retrieve the default
    representation of a report table you can send a GET request to e.g.
    */reportTable/iu8j/hYgF6t*, where the last part is the report table
    identifier.

4.  Resource representations are *linkable*, meaning that
    representations advertise other resources which are relevant to the
    current one by embedding links into itself (please be aware that you
    need to request *href* in your field filter to have this working.
    This feature greatly improves the usability and robustness of the
    API as we will see later. For instance, you can easily navigate to
    the indicators which are associated with a report table from the
    *reportTable* resource through the embedded links using your
    preferred representation format.

While all of this might sound complicated, the Web API is actually very
simple to use. We will proceed with a few practical examples in a
minute.

## Authentification { #webapi_authentication } 

L'API Web DHIS2 prend en charge trois protocoles d'authentification : 

- [L'authentification de base](#webapi_basic_authentication)
- [Les jetons d'accès personnels (PAT)](#webapi_pat_authentication)
- [OAuth 2](#webapi_oauth2)

Vous pouvez vérifier et obtenir des informations sur l'utilisateur actuellement authentifié 
en envoyant une requête GET à l'URL suivante :

    /api/33/me

Et plus d'informations sur les autorisations (et si un utilisateur a une certaine 
autorisation) en utilisant les points d'extrémité :

    /api/33/me/authorities
    /api/33/me/authorities/ALL

## L'authentification de base { #webapi_basic_authentication } 

L'API Web DHIS2 prend en charge *l'authentification de base*. L'authentification de base 
est une technique permettant aux clients d'envoyer des informations d'identification par HTTP à un 
serveur web. Techniquement parlant, le nom d'utilisateur est suivi de deux points et 
le mot de passe, encodé en Base64, est préfixé par Basic et fourni en tant que valeur 
de l'en-tête HTTP *Autorisation*. De manière plus formelle, il s'agit de : 

    Autorisation : Basic base64encode( nom d'utilisateur:mot de passe)

La plupart des environnements de développement compatibles avec les réseaux prennent en charge 
l'authentification de base, comme *Apache HttpClient* et *Spring RestTemplate*. 
Il est important de noter que ce schéma d'authentification n'offre aucune sécurité 
puisque le nom d'utilisateur et le mot de passe sont envoyés en texte clair et peuvent être facilement 
observés par un pirate. L'utilisation de Basic n'est recommandée que si le serveur 
utilise SSL/TLS (HTTPS) pour crypter la communication avec les clients. Considérez qu'il 
s'agit d'une exigence impérative pour assurer des interactions sécurisées avec l'API 
Web.

## Authentification à deux facteurs { #webapi_2fa } 

DHIS2 prend en charge l'authentification à deux facteurs. Cette fonction peut être activée pour chaque utilisateur. 
Lorsque cette option est activée, les utilisateurs sont invités à saisir un code 2FA lorsqu'ils se connectent. Pour 
en savoir plus sur l'authentification à deux facteurs, cliquez ici (https : www.google.com/landing/2step/).

## Jeton d'accès personnel { #webapi_pat_authentication }
Les jetons d'accès personnels (PAT) sont une alternative à l'utilisation de mots de passe lors 
de l'authentification au système DHIS2 lorsque l'on utilise l'API.

Les jetons d'accès personnel peuvent être une alternative plus sécurisée à l'authentification 
de base HTTP et devraient être votre choix privilégié lorsque vous créez une nouvelle application, un script, etc.

L'authentification de base HTTP est considérée comme non sécurisée car, entre autres, 
elle envoie votre nom d'utilisateur et votre mot de passe de façon indiscrète. Il est possible qu'elle soit abandonnée dans les versions 
futures de DHIS2 ou qu'elle devienne facultative, ce qui signifie que l'authentification de base devra 
être explicitement activée dans la configuration.

#### Problèmes de sécurité majeurs ! { #important-security-concerns } 

Vos jetons hériteront automatiquement de toutes les permissions et autorisations dont dispose votre utilisateur. Il est donc extrêmement important de limiter l'accès que vous accordez à votre jeton en fonction de l'utilisation que vous comptez en faire, voir **Configurer votre jeton**.

**Si vous souhaitez que le jeton n'ait accès qu'à une partie restreinte et spécifique du serveur, il est plutôt recommandé de créer un nouvel utilisateur spécial auquel vous n'attribuerez que les rôles et autorisations auxquels vous souhaitez qu'il ait accès.**


### Créer un jeton { #creating-a-token } 
Pour créer un nouveau PAT, vous avez deux possibilités :
* A. Créez un jeton dans l'interface utilisateur de la page de profil de votre compte.
* B. Create a token via the API

### A. Création d'un jeton sur la page du compte { #a-creating-a-token-on-the-accounts-page } 
Connectez-vous avec votre nom d'utilisateur et votre mot de passe, allez sur votre page de profil 
(cliquez en haut à droite, et choisissez « Modifier le profil » dans le menu déroulant). 
Sur votre page de profil, choisissez « Jetons d'accès personnels » dans le 
menu à gauche. 
Vous devriez maintenant être sur la page « Gérer les jetons d'accès personnels » et voir le 
texte : « Vous n'avez pas de jetons d'accès personnels actifs ». 
Cliquez sur « Générer un nouveau jeton » pour créer un nouveau jeton.
Une fenêtre contextuelle « Générer un nouveau jeton » s'affiche et vous propose deux choix :

#### 1. Contexte serveur/script: { #1-serverscript-context } 
_"Ce type est utilisé pour les intégrations et les scripts qui ne seront pas accessibles par un navigateur"._

Si vous prévoyez d'utiliser le jeton dans une application, un script ou autre, ce 
type de jeton devrait être votre choix.

#### 2. Contexte navigateur: { #2-browser-context } 
_"Ce type d'application est utilisé pour les applications, telles que les portails publics, auxquelles on accède à l'aide d'un navigateur web"._

Si vous devez créer un lien vers DHIS2 sur une page web, ou par exemple l'intégrer dans une iframe, 
c'est probablement le type de jeton qu'il vous faut.


### Configuration de votre jeton { #configuring-your-token } 

Après avoir choisi le type de jeton que vous désirez, vous pouvez configurer différentes contraintes d'accès à 
votre jeton. Par contrainte, nous entendons la manière de limiter et de restreindre l'utilisation de votre jeton. 
Cela peut être d'une importance cruciale si vous envisagez d'utiliser le jeton dans un environnement public, 
par exemple sur un tableau de bord public d'un autre site, intégré dans une iframe. 
Étant donné que les jetons ont toujours les mêmes accès/autorisations que ceux dont dispose actuellement votre utilisateur, il convient d'être particulièrement 
vigilant si vous avez l'intention de les utiliser dans un environnement que vous ne contrôlez pas à 100 %.

**NB** : Si quelqu'un d'autre met la main sur votre jeton, il peut faire tout ce que votre utilisateur est capable de faire. 
Il n'est pas possible de faire la distinction entre les actions effectuées à l'aide du jeton et les autres actions
effectuées par votre utilisateur.

**Important** : Il est fortement conseillé de créer un utilisateur distinct et unique ayant uniquement les rôles/autorisations 
si vous envisagez d'utiliser les jetons PAT dans un environnement non sécurisé et/ou public,
par exemple, sur un PC ou un serveur que vous ne contrôlez pas à 100 %, ou « intégré » dans une page web sur un autre serveur.

#### Les différents types de contraintes sont les suivants: { #the-different-constraint-types-are-as-follows } 
* Temps d'expiration
* Adresses UP autorisées
* Méthodes HTTP autorisées
* Référents HTTP autorisés

##### Temps d'expiration { #expiry-time } 
La durée d'expiration définit simplement la durée pendant laquelle vous souhaitez que votre jeton soit utilisable, le délai par défaut étant de 30 
jours. Passé ce délai, le jeton renverra simplement un message 401 (non autorisé).
Vous pouvez définir le délai d'expiration que vous souhaitez, mais il est fortement conseillé de définir un délai d'expiration 
raisonnable pour votre cas d'utilisation.

#### Adresses IP autorisées { #allowed-ip-addresses } 
Il s'agit d'une liste d'adresses IP séparées par des virgules, à partir desquelles vous souhaitez limiter la provenance des requêtes de jetons.

 **Important** La validation de l'adresse IP repose sur l'en-tête X-Transféré-À, qui peut être usurpé. 
Pour des raisons de sécurité, assurez-vous qu'un équilibreur de charge ou un proxy inverse écrase cet en-tête.

#### Méthodes HTTP autorisées { #allowed-http-methods } 
Une liste de méthodes HTTP séparées par des virgules que vous souhaitez que votre jeton puisse utiliser.
Si vous n'avez besoin de votre jeton que pour consulter des données, et non pour les modifier ou les supprimer, la sélection de la méthode GET HTTP 
est judicieuse.

#### Références HTTP autorisées { #allowed-http-referrers } 
Le référent HTTP est un en-tête ajouté à la requête lorsque vous cliquez sur un lien, il indique le site/la page 
sur lequel/laquelle vous étiez lorsque vous avez cliqué sur le lien. 
Pour en savoir plus sur l'en-tête du référent HTTP, cliquez sur le lien suivant : https://en.wikipedia.org/wiki/HTTP_referer

Cela peut servir à limiter l'utilisation d'un jeton « public » intégré à une autre page sur un autre site. 
S'assurer que l'en-tête du référent correspond au nom d'hôte du site d'où le jeton doit provenir peut
éviter l'utilisation abusive du jeton, par exemple si quelqu'un le publie sur un forum public.

**Important** Ceci n'est pas une fonctionnalité de sécurité. L'en-tête `référence` peut être facilement usurpé. 
Ce paramètre est destiné à dissuader les développeurs tiers non autorisés à se connecter 
aux instances d'accès public.

#### Sauvegarder votre jeton: { #saving-your-token } 
Lorsque vous avez fini de configurer votre jeton, vous pouvez l'enregistrer en cliquant sur le bouton « Générer un nouveau jeton »
en bas à droite de la fenêtre contextuelle.
Le jeton sera alors sauvegardé et une clé secrète sera générée sur le serveur.
La nouvelle clé secrète sera affichée en bas de la liste des jetons PAT sur fond vert,
et le texte « Jeton nouvellement créé ».
La clé du jeton secret ressemble à ceci :
```
d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```
**Important**: Cette clé de jeton secrète générée ne sera affichée qu'une seule fois. Il est donc important 
que vous la copiez maintenant et que vous la sauvegardiez en lieu sûr pour une utilisation ultérieure. 
La clé de jeton secrète sera hachée de manière sécurisée sur le serveur, et seul le hachage de cette 
clé sera enregistré dans la base de données ; ceci pour minimiser les risques relatifs à la sécurité s'il arrivait qu'une personne obtienne 
un accès non autorisé à la base de données, de la même manière que les mots de passe sont gérés.

### B. Créer un jeton via l'API { #b-creating-a-token-via-the-api } 

Exemple de création d'un nouveau jeton d'accès personnel avec l'API :

```
POST https://play.dhis2.org/dev/api/apiToken
Content-Type: application/json
Authorization: Basic admin district

{}
```
**NB**: N'oubliez pas le corps JSON vide (`{}`) dans la charge utile ! 

Il renverra une réponse contenant un jeton similaire à celui-ci :
```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "response": {
     "responseType": "ApiTokenCreationResponse",
     "key": "d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092",
     "uid": "jJYrtIVP7qU",
     "klass": "org.hisp.dhis.security.apikey.ApiToken",
     "errorReports": []
  }
}
```

**Important** : La clé symbolique n'apparaît qu'une seule fois dans cette réponse.
Vous devez la copier et l'enregistrer dans un endroit sûr pour pouvoir l'utiliser ultérieurement !

Le jeton lui-même se compose de trois parties :
1. Préfixe : (`d2pat_`) indique de quel type de jeton il s'agit.
2. Octets aléatoires codés en Base64: (`5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ`)
3. Somme de contrôle CRC32 : (`1151814092`) la partie de la somme de contrôle est complétée par 0 de sorte qu'elle conserve toujours une longueur de dix caractères.


#### Configurez votre token via l'API: { #configure-your-token-via-the-api } 
Pour modifier l'une des contraintes de votre jeton, vous pouvez envoyer la requête API HTTP suivante.

**NB**: Seules les contraintes peuvent être modifiées après la création du jeton ! 

```
PUT https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: Basic admin district
```

```json
{
  "version": 1,
  "type": "PERSONAL_ACCESS_TOKEN",
  "expire": 163465349603200,
  "attributes": [
      {
        "type": "IpAllowedList",
        "allowedIps": ["192.168.0.1"]
      },
      {
        "type": "MethodAllowedList",
        "allowedMethods": ["GET"]
      }
  ]
}
```

### Utiliser votre jeton d'accès personnel { #using-your-personal-access-token } 

Pour envoyer un requête avec votre jeton nouvellement créé, utilisez convenablement l'en-tête 
d'autorisation .
Le format de l'en-tête d'autorisation est le suivant :
```
Autorisation : ApiToken [YOUR_SECRET_API_TOKEN_KEY]
```
**Exemple**:
```
GET https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


### Supprimer votre jeton d'accès personnel { #deleting-your-personal-access-token } 
Vous pouvez supprimer vos PAT soit dans l'interface utilisateur de votre page de profil où vous les avez créés,
soit via l'API comme ceci :
```
DELETE https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


## OAuth2 { #webapi_oauth2 } 

DHIS2 supporte le protocole d'authentification *OAuth2*. OAuth2 est une norme 
ouverte d'autorisation qui permet aux clients tiers de se 
connecter au nom d'un utilisateur DHIS2 et d'obtenir un *jeton porteur* réutilisable 
pour les demandes ultérieures à l'API Web. DHIS2 ne prend pas en charge les rôles 
OAuth2 à granularité fine, mais fournit aux applications un accès basé sur les rôles 
de l'utilisateur DHIS2.

Chaque client pour lequel vous souhaitez autoriser l'authentification OAuth 2 doit être
enregistré dans DHIS2. Pour ajouter un nouveau client OAuth2, allez dans `Applications > Paramètres > Clients OAuth2`
dans l'interface utilisateur, cliquez sur *Ajouter nouveau* et entrez le nom du client souhaité et les types de subventions.

#### Ajouter un client à l'aide de l'API Web { #adding-a-client-using-the-web-api } 

Un client OAuth2 peut être ajouté via l'API Web. Par exemple, nous pouvons
envoyer une charge utile comme celle-ci :

```json
{
  "name": "OAuth2 Demo Client",
  "cid": "demo",
  "secret": "1e6db50c-0fee-11e5-98d0-3c15c2c6caf6",
  "grantTypes": [
    "password",
    "refresh_token",
    "authorization_code"
  ],
  "redirectUris": [
    "http://www.example.org"
  ]
}
```

La charge utile peut être envoyée avec la commande suivante :

```bash
SERVER="https://play.dhis2.org/dev"
curl -X POST -H "Content-Type: application/json" -d @client.json
  -u admin:district "$SERVER/api/oAuth2Clients"
```

Nous utiliserons ce client comme base pour nos prochains exemples de types de subventions.

#### Mot de passe du type d'octroi { #webapi_oauth2_password } 

Le type d'octroi le plus simple est le type d'octroi *mot de passe*. Ce 
type d'octroi est similaire à l'authentification de base en ce sens qu'il 
exige du client qu'il recueille le nom d'utilisateur et le mot de passe de l'utilisateur. Prenons 
l'exemple de notre serveur de démonstration :

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d grant_type=password -d username=admin -d password=district
```

Vous obtiendrez une réponse similaire à ceci :

```json
{
  "expires_in": 43175,
  "scope": "ALL",
  "access_token": "07fc551c-806c-41a4-9a8c-10658bd15435",
  "refresh_token": "a4e4de45-4743-481d-9345-2cfe34732fcc",
  "token_type": "bearer"
}
```

Pour l'instant, nous allons nous concentrer sur le `access_token`, qui 
sera utilisé comme jeton d'authentification (porteur). A titre d'exemple, nous allons obtenir 
tous les éléments de données en utilisant notre jeton :

```bash
SERVER="https://play.dhis2.org/dev"
curl -H "Authorization: Bearer 07fc551c-806c-41a4-9a8c-10658bd15435" "$SERVER/api/33/dataElements.json"
```

#### Type d'octroi rafraîchir\_jeton { #webapi_refresh_token } 

En général, les jetons d'accès ont une validité limitée. Vous pouvez jeter un coup d'oeil 
à la propriété `expires_in` ( expire en) de la réponse dans l'exemple précédent 
pour comprendre quand un jeton expire. Pour obtenir un nouveau `access_token` (jeton d'accès), vous 
pouvez faire un autre aller-retour vers le serveur et utiliser `refresh_token` (rafraîchir le jeton) 
qui vous permet d'obtenir un jeton mis à jour sans avoir besoin de demander les 
informations d'identification de l'utilisateur une fois de plus.

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"
REFRESH_TOKEN="a4e4de45-4743-481d-9345-2cfe34732fcc"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d "grant_type=refresh_token" -d "refresh_token=$REFRESH_TOKEN"
```

La réponse sera exactement la même que lorsque vous obtenez un jeton au départ.

#### Type de subvention code_d'autorisation { #webapi_authorization_code } 

Le type de subvention « code autorisé » est l'approche recommandée si vous ne souhaitez 
pas stocker les informations d'identification de l'utilisateur en externe. Elle permet au DHIS2 de collecter le 
nom d'utilisateur et le mot de passe directement auprès de l'utilisateur au lieu que le client 
les collecte et s'authentifie ensuite au nom de l'utilisateur. Veuillez noter 
que cette approche utilise la partie `redirectUris` de la charge utile du 
client.

Étape 1 : Visitez l'URL suivante à l'aide d'un navigateur web. Si vous avez plus d'un
URI de redirection, vous pouvez ajouter `&redirect_uri=http://www.example.org` 
à l'URL :

```bash
SERVER="https://play.dhis2.org/dev"
$SERVER/uaa/oauth/authorize?client_id=demo&response_type=code
```

Étape 2 : Une fois que l'utilisateur s'est connecté avec succès et a accepté votre accès client
il sera redirigé vers votre uri de redirection comme suit :

    http://www.example.org/?code=XYZ

Étape 3 : Cette étape est similaire à celle de l'octroi du mot de passe,
en utilisant le code fourni, nous allons maintenant demander un jeton d'accès :

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -u demo:$SECRET -H "Accept: application/json" $SERVER/uaa/oauth/token
-d "grant_type=authorization_code" -d "code=XYZ"
```

## Messages d'erreur et d'information { #webapi_error_info_messages } 

L'API Web utilise un format cohérent pour tous les messages d'erreur, d'avertissement et 
d'information :

```json
{
  "httpStatus": "Forbidden",
  "message": "Vous n'avez pas la permission de lire ce type d'objet.",
  "httpStatusCode": 403,
  "status": "ERROR"
}
```

Here we can see from the message that the user tried to access a
resource I did not have access to. It uses the http status code 403, the
http status message *forbidden* and a descriptive message.



Tableau : Propriétés de WebMessage

| Nom | Description |
|---|---|
| Statut http | Message de statut HTTP pour cette réponse, voir RFC 2616 (Section 10) pour plus d'informations. |
| Code de statut http | Code de statut HTTP pour cette réponse, voir RFC 2616 (Section 10) pour plus d'informations. |
| statut | Les valeurs possibles du statut DHIS2 sont *OK* &#124 ; *AVERTISSEMENT* &#124 ; *ERREUR*, où `OK` signifie que tout a réussi, `ERREUR` signifie que l'opération ne s'est pas terminée et `AVERTISSEMENT` signifie que l'opération a partiellement réussi, si le message contient une propriété `réponse`, veuillez y jeter un coup d'oeil pour obtenir plus d'informations. |
| message | Un message convivial indiquant si l'opération a réussi ou non. |
| Message dev | Un message plus technique, adapté aux développeurs (non utilisé actuellement). |
| réponse | Extension point for future extension to the WebMessage format. This will be documented when it starts being used. |

## Format de la date et de la période { #webapi_date_perid_format } 

Tout au long de l'API Web, nous faisons référence à des dates et à des périodes. Le format de la date
est le suivant :

    aaaa-MM-jj

Par exemple, si vous voulez exprimer le 20 mars 2014, vous devez utiliser
*2014-03-20*.

Le format de la période est décrit dans le tableau suivant (également disponible sur 
le point d'extrémité de l'API `/api/periodTypes`)



Tableau : Format de la période

| Intervale | Format | Exemple | Description |
|---|---|---|---|
| Jour | aaaaMMjj | 20040315 | 15 Mars, 2004 |
| Semaine | aaaaWn | 2004W10 | Semaine 10 2004 |
| Semaine Mercredi | aaaaMerWn | 2015MerS5 | Semaine 5 avec début le mercredi |
| Semaine Jeudi | aaaaJeuSn | 2015JeuS6 | Semaine 6 avec début le Jeudi |
| Semaine Samedi | aaaaSamSn | 2015SamS7 | Semaine 7 avec début le Samedi |
| Semaine Dimanche | aaaaDimSn | 2015DimS8 | Semaine 8 avec début le Dimanche |
| Bi-hebdomadaire | aaaaBiSn | 2015BiS1 | Semaine 1-2 20015 |
| Mois | aaaaMM | 200403 | Mars 2004 |
| Bi-mensuel | aaaaMMB | 200401B | Janvier-février 2004 |
| Trimestre | aaaaTn | 2004Q1 | Janvier-Mars 2004 |
| Semestre | aaaaSn | 2004S1 | Janvier-juin 2004 |
| Semestre Avril | aaaaAvrilSn | 2004AvrilS1 | Avril-Septembre 2004 |
| Année | aaaa | 2004 | 2004 |
| Année financière Avril | aaaaAvril | 2004Avril | Avril 2004 - mars 2005 |
| Année financière Juillet | aaaaJuillet | 2004Juillet | juillet 2004-juin 2005 |
| Année financière Octobre | aaaaOctobre | 2004Octobre | Octobre 2004-septembre 2005 |


### Périodes relatives { #webapi_date_relative_period_values } 


Dans certaines parties de l'API, comme pour la ressource analytique, vous pouvez 
utiliser des périodes relatives en plus des périodes fixes (définies ci-dessus). 
Les périodes relatives sont relatives à la date actuelle et permettent, par exemple, 
de créer des rapports dynamiques. Les valeurs disponibles pour les périodes relatives sont les suivantes :

    CETTE_SEMAINE, LA SEMAINE_DERNIÈRE, LES _4_ DERNIÈRES SEMAINES, LES _12 _DERNIÈRES SEMAINES, LES _52_ DERNIÈRES SEMAINES,
CE_MOIS, LE MOIS_DERNIER, CE_BIMESTRE, LE MOIS_DERNIER, CE_TRIMESTRE, LE TRIMESTRE_DERNIER,
    CES_SIX_MOIS, LES_SIX_DERNIERS MOIS, MOIS_CETTE_ANNÉE, TRIMESTRES_CETTE_ANNÉE,
    CETTE _ANNÉE, MOIS_ANNÉE_ DERNIÈRE, TRIMESTRES_ANNÉE_DERNIÈRE, ANNÉE_DERNIÈRE, _5_DERNIÈRES ANNÉES, _10_DERNIÈRES ANNÉES, _10_DERNIÈRES ANNÉES_FINANCIÈRES, _12_DERNIERS MOIS, 
    3 _DERNIERS_ MOIS, 6 _DERNIERS_ BIMESTRES, 4 _DERNIERS_ TRIMESTRES, 2 _DERNIERS_ SIX MOIS, CETTE _ANNÉE _FINANCIÈRE,
    DERNIÈRE_ANNÉE_FINANCIÈRE, 5 _DERNIÈRES _ANNÉES_FINANCIÈRES

### Périodes de dates personnalisées { #webapi_date_custom_date_periods }

Les ressources analytiques `query` supportent des paramètres supplémentaires pour exprimer des périodes.

Default `pe` dimension fallbacks to:

- `eventDate` pour `/analytics/events/query`
- `enrollmentDate` pour `/analytics/enrollments/query`

It is, however, possible to add conditions on one or more date fields and combine them.

#### Utilisation de périodes de dates personnalisées { #usage-of-custom-date-periods } 

Dans les ressources prenant en charge des périodes de dates personnalisées, il existe des paramètres de requête supplémentaires qui seront combinés pour exprimer des conditions sur la dimension temporelle.

| période de date personnalisée | ressources de requête d'événements  | ressource de requête d'inscription |
|--------------------|------------------------|---------------------------|
| `date d'événement`        | Hôpital public Londres                    | **Cliniques**: Clinique publique Alberta / Clinique publique Windsor ET                       |
| `date d'inscription`   | Hôpital public Londres                    | Hôpital public Londres                       |
| `date programmée`    | Hôpital public Londres                    | **Cliniques**: Clinique publique Alberta / Clinique publique Windsor ET                       |
| `date d'incident`     | Hôpital public Londres                    | Hôpital public Londres                       |
| `dernière mise à jour`      | Hôpital public Londres                    | Hôpital public Londres                       |

Les conditions peuvent être exprimées sous la forme suivante :

`analytics/events/query/...?...&eventDate=2021&...`

Il est possible de combiner plusieurs champs temporels dans la même requête :

`analytics/events/query/...?...&eventDate=2021&incidentDate=202102&...`

Toutes ces conditions peuvent être combinées avec la dimension `pe` :

`analytics/events/query/...?...&dimension=pe:TODAY&enrollmentDate=2021&incidentDate=202102&...`

Les formats pris en charge sont décrits dans la section « Format de date et de période » ci-dessus. Un format supplémentaire est fourni pour exprimer un intervalle de dates : `aaaaMMjj_aaaaMMjj` et `aaaa-MM-jj_aaaa-MM-jj`.

Dans l'exemple ci-dessous, le point d'extrémité renvoie les événements prévus entre 20210101 et 20210104 :

`analytics/events/query/...?...&dimension=pe:TODAY&enrollmentDate=2021&incidentDate=202102&scheduledDate=20210101_20210104&...`


## Autorités { #authorities } 
Les identifiants et les noms des autorisations du système peuvent être répertoriés à l'aide de la fonction :

    /api/authorities

Il renvoie le format suivant :
```json
{
  "systemAuthorities": [
    {
      "id": "ALL",
      "name": "ALL"
    },
    {
      "id": "F_ACCEPT_DATA_LOWER_LEVELS",
      "name": "Accept data at lower levels"
    }
    //...
  ]
}
```



# Métadonnées { #metadata } 

## Identifier schemes { #webapi_identifier_schemes } 

This section provides an explanation of the identifier scheme concept.
Identifier schemes are used to map metadata objects to other metadata
during import, and to render metadata as part of exports. Note
that not all schemes work for all API calls, and not all
schemes can be used for both input and output. This is outlined in the
sections explaining the various API endpoints.

The full set of identifier scheme object types available are listed
below, using the name of the property to use in queries:

  - idScheme

  - dataElementIdScheme (Schéma d'identifiant d'élément de données)

  - categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie)

  - orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation)

  - programIdScheme (Schéma d'identification du programme)

  - programmeStageIdScheme (Schéma d'identification de l'étape de programme)

  - trackedEntityIdScheme

  - trackedEntityAttributeIdScheme

The general idScheme applies to all types of objects. It can be
overridden by specific object types.

The default scheme for all parameters is UID (stable DHIS2
identifiers). The supported identifier schemes are described in the
table below.

Table: Scheme Values

| Schéma | Description |
|---|---|
| ID, UID | Correspondre avec l'identifiant permanent DHIS2. il s'agit du schéma d'identification par défaut. |
| CODE | Correspondre avec le code DHIS2, principalement utilisé pour échanger des données avec un système externe. |
| NOM | Match on DHIS2 Name, please note that this uses what is available as *object.name*, and not the translated name. Also note that names are not always unique, and in that case, they can not be used. |
| ATTRIBUT:ID | Match on metadata attribute, this attribute needs to be assigned to the type you are matching on, and also that the unique property is set to *true*. The main usage of this is also to exchange data with external systems, it has some advantages over *CODE* since multiple attributes can be added, so it can be used to synchronize with more than one system. |

Note that identifier schemes is not an independent feature but needs to
be used in combination with resources such as data value import and metadata import.

As an example, to specify CODE as the general id scheme and override
with UID for organisation unit id scheme you can use these query
parameters:

    ?idScheme=CODE&orgUnitIdScheme=UID

As another example, to specify an attribute for the organisation unit id
scheme, code for the data element id scheme and use the default UID id
scheme for all other objects you can use these parameters:

    ?orgUnitIdScheme=ATTRIBUTE:j38fk2dKFsG&dataElementIdScheme=CODE

## Browsing the Web API { #webapi_browsing_the_web_api } 

The entry point for browsing the Web API is `/api`. This resource
provides links to all available resources. Four resource representation
formats are consistently available for all resources: HTML, XML, JSON,
and JSONP. Some resources will have other formats available, like MS
Excel, PDF, CSV, and PNG. To explore the API from a web browser, navigate
to the `/api` entry point and follow the links to your desired
resource, for instance `/api/dataElements`. For all resources which
return a list of elements certain query parameters can be used to modify
the response:

Tableau : Paramètres de requête

| Paramètre | Option values | Default option | Description |
|---|---|---|---|
| paging | true &#124; false | vrai | Indicates whether to return lists of elements in pages. |
| page | number | 1 | Defines which page number to return. |
| taille de la page | number | 50 | Defines the number of elements to return for each page. |
| Ordre | property:asc/iasc/desc/idesc || Order the output using a specified order, only properties that are both persisted and simple (no collections, idObjects etc) are supported. iasc and idesc are case insensitive sorting. |

An example of how these parameters can be used to get a full list of
data element groups in XML response format is:

    /api/dataElementGroups.xml?links=false&paging=false

You can query for elements on the name property instead of returning
a full list of elements using the *query* query variable. In this example
we query for all data elements with the word "anaemia" in the name:

    /api/dataElements?query=anaemia

You can get specific pages and page sizes of objects like this:

    /api/dataElements.json?page=2&pageSize=20

You can completely disable paging like this:

    /api/indicatorGroups.json?paging=false

To order the result based on a specific property:

    /api/indicators.json?order=shortName:desc

You can find an object based on its ID across all object types through
the *identifiableObjects* resource:

    /api/identifiableObjects/<id>

### Translation { #webapi_translation } 

DHIS2 supports translations of database content, such as data elements,
indicators, and programs. All metadata objects in the Web API have
properties meant to be used for display / UI purposes, which include
*displayName*, *displayShortName*, *displayDescription* and
*displayFormName* (for data elements and tracked entity attributes).

Table: Translate options

| Paramètre | Valeurs | Description |
|---|---|---|
| translate | true &#124; false | Translate display\* properties in metadata output (displayName, displayShortName, displayDescription, and displayFormName for data elements and tracked entity attributes). Default value is true. |
| locale | Locale to use | Translate metadata output using a specified locale (requires translate=true). |

### Translation API { #webapi_translation_api } 

The translations for an object is rendered as part of the object itself
in the *translations* array. Note that the *translations* array in the
JSON/XML payloads is normally pre-filtered for you, which means they
can not directly be used to import/export translations (as that would
normally overwrite locales other than current users).

Example of data element with translation array filtered on user locale:

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute French",
  "translations": [
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    }
  ]
}
```

Example of data element with translations turned off:

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute Flaccid Paralysis (Deaths < 5 yrs)",
  "translations": [
    {
      "property": "FORM_NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "Accute Flaccid Paral"
    },
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "DESCRIPTION",
      "locale": "en_FK",
      "value": "aa"
    }
  ]
}
```

Note that even if you get the unfiltered result, and are using the
appropriate type endpoint i..e `/api/dataElements` we do not allow
updates, as it would be too easy to make mistakes and overwrite the
other available locales.

To read and update translations you can use the special translations
endpoint for each object resource. These can be accessed by *GET* or
*PUT* on the appropriate `/api/<object-type>/<object-id>/translations` endpoint.

As an example, for a data element with identifier `FTRrcoaog83`, you could use
`/api/dataElements/FTRrcoaog83/translations` to get and update
translations. The fields available are `property` with options *NAME*,
*SHORT_NAME*, *FORM_NAME*, *DESCRIPTION*, `locale` which supports any valid
locale ID and the translated property `value`.

Example of NAME property for French locale:

```json
{
  "property": "NAME",
  "locale": "fr",
  "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
}
```

This payload would then be added to a translation array, and sent back
to the appropriate endpoint:

```json
{
  "translations": [
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
    }
  ]
}
```

For a data element with ID *FTRrcoaog83* you can *PUT* this to
`/api/dataElements/FTRrcoaog83/translations`. Make sure to send all
translations for the specific object and not just for a single locale
(if not you will potentially overwrite existing locales for other
locales).

### Web API versions { #webapi_api_versions } 

The Web API is versioned starting from DHIS 2.25. The API versioning
follows the DHIS2 major version numbering. As an example, the API
version for DHIS 2.33 is `33`.

You can access a specific API version by including the version number
after the `/api` component, as an example like this:

    /api/33/dataElements

If you omit the version part of the URL, the system will use the current
API version. As an example, for DHIS 2.25, when omitting the API part,
the system will use API version 25. When developing API clients it is
recommended to use explicit API versions (rather than omitting the API
version), as this will protect the client from unforeseen API changes.

The last three API versions will be supported. As an example, DHIS
version 2.27 will support API version 27, 26 and 25.

Note that the metadata model is not versioned and that you might
experience changes e.g. in associations between objects. These changes
will be documented in the DHIS2 major version release notes.

## Metadata object filter { #webapi_metadata_object_filter } 

To filter the metadata there are several filter operations that can be
applied to the returned list of metadata. The format of the filter
itself is straight-forward and follows the pattern
*property:operator:value*, where *property* is the property on the
metadata you want to filter on, *operator* is the comparison operator
you want to perform and *value* is the value to check against (not all
operators require value). Please see the *schema* section to discover
which properties are available. Recursive filtering, ie. filtering on
associated objects or collection of objects, is supported as well.

Table: Available Operators

| Opérateur | Types | Value required | Description |
|---|---|---|---|
| eq | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | vrai | Equality |
| !eq | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | vrai | Inequality |
| ne | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | vrai | Inequality |
| like | string | vrai | Case sensitive string, match anywhere |
| !like | string | vrai | Case sensitive string, not match anywhere |
| $like | string | vrai | Case sensitive string, match start |
| !$like | string | vrai | Case sensitive string, not match start |
| like$ | string | vrai | Case sensitive string, match end |
| !like$ | string | vrai | Case sensitive string, not match end |
| ilike | string | vrai | Case insensitive string, match anywhere |
| !ilike | string | vrai | Case insensitive string, not match anywhere |
| $ilike | string | vrai | Case insensitive string, match start |
| !$ilike | string | vrai | Case insensitive string, not match start |
| ilike$ | string | vrai | Case insensitive string, match end |
| !ilike$ | string | vrai | Case insensitive string, not match end |
| gt | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Supérieure à |
| ge | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Greater than or equal |
| lt | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Inférieur à |
| le | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Less than or equal |
| nulle | all | faux | Property is null |
| !null | all | faux | Property is not null |
| empty | collection | faux | Collection is empty |
| token | string | vrai | Match on multiple tokens in search property |
| !token | string | vrai | Not match on multiple tokens in search property |
| recherche | string &#124; boolean &#124; integer &#124; float &#124; date | vrai | Find objects matching 1 or more values |
| !in | string &#124; boolean &#124; integer &#124; float &#124; date | vrai | Find objects not matching 1 or more values |

Operators will be applied as logical *and* query. If you need a *or*
query, you can have a look at the *in* filter and the section below.
The filtering mechanism allows for recursion. See below for some examples.

Get data elements with id property ID1 or ID2:

    /api/dataElements?filter=id:eq:ID1&filter=id:eq:ID2

Get all data elements which have a data set with id ID1:

    /api/dataElements?filter=dataSetElements.dataSet.id:eq:ID1

Get all data elements with aggregation operator *sum* and value type
*int*:

    /api/dataElements.json?filter=aggregationOperator:eq:sum&filter=type:eq:int

You can do filtering within collections, e.g. to get data elements which
are members of the *ANC* data element group you can use the following
query using the id property of the associated data element groups:

    /api/dataElements.json?filter=dataElementGroups.id:eq:qfxEYY9xAl6

To get data elements with a particular attribute value for a metadata 
attribute, a filter for the attribute ID and the attribute value can be 
specified using the same collection query syntax:

    /api/dataElements.json?filter=attributeValues.attribute.id:eq:n2xYlNbsfko&filter=attributeValues.value:eq:AFP

Since all operators are *and* by default, you can't find a data
element matching more than one id, for that purpose you can use the *in*
operator.

    /api/dataElements.json?filter=id:in:[fbfJHSPpUQD,cYeuwXTCPkU]

### Logical operators { #webapi_metadata_logical_operator } 

As mentioned in the section before, the default logical operator applied
to the filters is *AND* which means that all object filters must be
matched. There are however cases where you want to match on one of
several filters (maybe id and code field) and in those cases, it is
possible to switch the root logical operator from *AND* to *OR*
using the *rootJunction* parameter.

Example: Normal filtering where both id and code must match to have a
result returned

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1

Example: Filtering where the logical operator has been switched to OR
and now only one of the filters must match to have a result
    returned

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1&rootJunction=OR

### Identifiable token filter { #identifiable-token-filter } 

In addition to the specific property based filtering mentioned above,
we also have *token* based *AND* filtering across a set of
properties: id, code, and name (also shortName if available). These
properties are commonly referred to as *identifiable*. The idea is to
filter metadata whose id, name, code or short name containing something.

Example: Filter all data elements containing *2nd* in any of the
following: id,name,code, shortName

    /api/dataElements.json?filter=identifiable:token:2nd

It is also possible to specify multiple filtering values.

Example: Get all data elements where *ANC visit* is found in any of the *identifiable* properties. The system returns all data elements where both tokens (ANC and visit) are found anywhere in identifiable properties.

    /api/dataElements.json?filter=identifiable:token:ANC visit

It is also possible to combine the identifiable filter with property-based filter and expect the *rootJunction* to be applied.

    /api/dataElements.json?filter=identifiable:token:ANC visit&filter=displayName:ilike:tt1

    /api/dataElements.json?filter=identifiable:token:ANC visit
      &filter=displayName:ilike:tt1&rootJunction=OR

## Metadata field filter { #webapi_metadata_field_filter } 

In many situations, the default views of the metadata can be too
verbose. A client might only need a few fields from each object and want
to remove unnecessary fields from the response. To discover which fields
are available for each object please see the *schema* section.

The format for include/exclude allows for infinite recursion. To filter
at the "root" level you can just use the name of the field,
i.e. `?fields=id,name` which would only display the `id` and
`name` fields for every object. For objects that are either collections or
complex objects with properties on their own, you can use the format
`?fields=id,name,dataSets[id,name]` which would return `id`, `name` of
the root, and the `id` and `name` of every data set on that object.
Negation can be done with the exclamation operator, and we have a set of
presets of field select. Both XML and JSON formats are supported.

**Example**: Get `id` and `name` on the indicators resource:

    /api/indicators?fields=id,name

**Example**: Get `id` and `name` from data elements, and `id` and `name`
from the associated data sets:

    /api/dataElements?fields=id,name,dataSets[id,name]

To exclude a field from the output you can use the exclamation `!`
operator. This is allowed anywhere in the query and will simply not
include that property as it might have been inserted in some of the
presets.

A few presets (selected fields groups) are available and can be applied
using the `:` operator.

Table: Property operators

| Opérateur | Description |
|---|---|
| <field-name\> | Include property with name, if it exists. |
| <object\>[<field-name\>, ...] | Includes a field within either a collection (will be applied to every object in that collection), or just on a single object. |
| !<field-name\>, <object\>[!<field-name\> | Do not include this field name, it also works inside objects/collections. Useful when you use a preset to include fields. |
| \*, <object\>[\*] | Include all fields on a certain object, if applied to a collection, it will include all fields on all objects on that collection. |
| :<preset\> | Alias to select multiple fields. Three presets are currently available, see the table below for descriptions. |

Table: Field presets

| Preset | Description |
|---|---|
| all | All fields of the object |
| \* | Alias for all |
| identifiable | Includes id, name, code, created and lastUpdated fields |
| nameable | Includes id, name, shortName, code, description, created and lastUpdated fields |
| persisted | Returns all persisted property on an object, does not take into consideration if the object is the owner of the relation. |
| owner | Returns all persisted property on an object where the object is the owner of all properties, this payload can be used to update through the API. |

**Example**: Include all fields from data sets except organisation units:

    /api/dataSets?fields=:all,!organisationUnits

**Example**: Include only id, name and the collection of organisation units from a data set, but exclude the id from organisation units:

    /api/dataSets/BfMAe6Itzgt?fields=id,name,organisationUnits[:all,!id]

**Example**: Include nameable properties from all indicators:

    /api/indicators.json?fields=:nameable

### Field transformers { #webapi_field_transformers } 

Field transforms can be used to transform properties. The syntax is described below.

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

This will rename the *id* property to *i* and *name* property to *n*.

Multiple transformers can be applied to a single property by repeating the transformer operator:

    /api/dataElementGroups.json?fields=id,displayName,dataElements~isNotEmpty~rename(haveDataElements)

The supported transformer operators are described in the table below.

Table: Available Transformers

| Nom | Arguments | Description |
|---|---|---|
| size || Gives sizes of strings (length) and collections |
| isEmpty || Is string or collection empty |
| isNotEmpty || Is string or collection not empty |
| rename | Arg1: name | Renames the property name |
| paging | Arg1: page,Arg2: pageSize | Pages a collection, default pageSize is 50. |
| pluck | Optional Arg1: fieldName | Converts an array of objects to an array of a selected field of that object. By default, the first field that is returned by the collection is used (normally the ID). |

#### Examples { #webapi_field_transformers_examples } 

Examples of transformer usage are found below.

Get the size of a collection:

    /api/dataElements?fields=dataSets~size

Test if a collection is empty:

    /api/dataElements?fields=dataSets~isEmpty

Test if a collection is not empty:

    /api/dataElements?fields=dataSets~isNotEmpty

Rename properties:

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

Apply paging to a collection:

    /api/dataElementGroups?fields=id,displayName,dataElements~paging(1;20)

Get array with IDs of organisation units:

    /api/categoryOptions.json?fields=id,organisationUnits~pluck

Get array with names of organisation units:

    /api/categoryOptions.json?fields=id,organisationUnits~pluck[name]

## Metadata create, read, update, delete, validate { #webapi_metadata_crud } 

All metadata entities in DHIS2 have their own API endpoint which supports
*CRUD* operations (create, read, update and delete). The endpoint URLs
follows this format:

    /api/<entityName>

The _entityName_ uses the camel-case notation. As an example, the endpoint
for _data elements_ is:

    /api/dataElements

### Create / update parameters { #webapi_metadata_create_update } 

The following request query parameters are available across all metadata endpoints.

Table: Available Query Filters

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| preheatCache | booléen | faux | true &#124; false | Turn cache-map preheating on/off. This is on by default, turning this off will make initial load time for importer much shorter (but will make the import itself slower). This is mostly used for cases where you have a small XML/JSON file you want to import, and don't want to wait for cache-map preheating. |
| importStrategy (stratégie d'importation) | enum | faux | CREATE_AND_UPDATE &#124; CREATE &#124; UPDATE &#124; DELETE | Import strategy to use, see below for more information. |
| mergeMode | enum | faux | REPLACE, MERGE | Strategy for merging of objects when doing updates. REPLACE will just overwrite the property with the new value provided, MERGE will only set the property if it is not null (only if the property was provided). |

### Creating and updating objects { #webapi_creating_updating_objects } 

For creating new objects you will need to know the endpoint, the type
format, and make sure that you have the required authorities. As an
example, we will create and update a *constant*. To figure out the
format, we can use the new *schema* endpoint for getting format
description. So we will start with getting that info:

    http://<server>/api/schemas/constant.json

From the output, you can see that the required authorities for create
are `F_CONSTANT_ADD`, and the important properties are: *name* and
*value*. From this, we can create a JSON payload and save it as a file
called constant.json:

```json
{
  "name": "PI",
  "value": "3.14159265359"
}
```

The same content as an XML payload:

```xml
<constant name="PI" xmlns="http://dhis2.org/schema/dxf/2.0">
  <value>3.14159265359</value>
</constant>
```

We are now ready to create the new *constant* by sending a POST request to
the `constants` endpoint with the JSON payload using curl:

```bash
curl -d @constant.json "http://server/api/constants" -X POST
  -H "Content-Type: application/json" -u user:password
```

A specific example of posting the constant to the demo server:

```bash
curl -d @constant.json "https://play.dhis2.org/api/constants" -X POST
  -H "Content-Type: application/json" -u admin:district
```

If everything went well, you should see an output similar to:

```json
{
  "status": "SUCCESS",
  "importCount": {
    "imported": 1,
    "updated": 0,
    "ignored": 0,
    "deleted": 0
  },
  "type": "Constant"
}
```

The process will be exactly the same for updating, you make your changes
to the JSON/XML payload, find out the *ID* of the constant, and then
send a PUT request to the endpoint including ID:

```bash
curl -X PUT -d @pi.json -H "Content-Type: application/json"
  -u user:password "http://server/api/constants/ID"
```

### Deleting objects { #webapi_deleting_objects } 

Deleting objects is very straight forward, you will need to know the
*ID* and the endpoint of the type you want to delete, let's continue our
example from the last section and use a *constant*. Let's assume that
the id is *abc123*, then all you need to do is the send the DELETE
request to the endpoint + id:

```bash
curl -X DELETE -u user:password "http://server/api/constants/ID"
```

A successful delete should return HTTP status 204 (no content).

### Adding and removing objects in collections { #webapi_adding_removing_objects_collections } 

The collections resource lets you modify collections of
objects.

#### Adding or removing single objects { #webapi_collections_adding_removing_single_objects } 

In order to add or remove objects to or from a collection of objects you
can use the following
    pattern:

    /api/{collection-object}/{collection-object-id}/{collection-name}/{object-id}

You should use the POST method to add, and the DELETE method to remove
an object. When there is a many-to-many relationship between objects,
you must first determine which object owns the relationship. If it isn't
clear which object this is, try the call both ways to see which works.

The components of the pattern are:

  - collection object: The type of objects that owns the collection you
    want to modify.

  - collection object id: The identifier of the object that owns the
    collection you want to modify.

  - collection name: The name of the collection you want to modify.

  - object id: The identifier of the object you want to add or remove
    from the collection.

As an example, in order to remove a data element with identifier IDB
from a data element group with identifier IDA you can do a DELETE
request:

    DELETE /api/dataElementGroups/IDA/dataElements/IDB

To add a category option with identifier IDB to a category with
identifier IDA you can do a POST
request:

    POST /api/categories/IDA/categoryOptions/IDB

#### Adding or removing multiple objects { #webapi_collections_adding_removing_multiple_objects } 

You can add or remove multiple objects from a collection in one request
with a payload like this:

```json
{
  "identifiableObjects": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ]
}
```

Using this payload you can add, replace or delete items:

*Adding Items:*

    POST /api/categories/IDA/categoryOptions

*Replacing Items:*

    PUT /api/categories/IDA/categoryOptions

*Delete
Items:*

    DELETE /api/categories/IDA/categoryOptions

#### Adding and removing objects in a single request { #webapi_collections_adding_removing_objects_single_request } 

You can both add and remove objects from a collection in a single POST
request to the following URL:

    POST /api/categories/IDA/categoryOptions

The payload format is:

```json
{
  "additions": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ],
  "deletions": [{
      "id": "IDD"
    }, {
      "id": "IDE"
    }, {
      "id": "IDF"
    }
  ]
}
```

### Validating payloads { #webapi_validating_payloads } 

DHIS 2 supports system wide validation of metadata payloads, which means
that create and update operations on the API endpoints will be checked for
valid payload before allowing changes to be made. To find out what validations
are in place for a specific endpoint, have a look at the `/api/schemas`
endpoint, i.e. to figure out which constraints a data element have, you
would go to `/api/schemas/dataElement`.

You can also validate your payload manually by sending it to the proper
schema endpoint. If you wanted to validate the constant from the create
section before, you would send it like this:

    POST /api/schemas/constant

A simple (non-validating) example would be:

```bash
curl -X POST -d "{\"name\": \"some name\"}" -H "Content-Type: application/json"
  -u admin:district "https://play.dhis2.org/dev/api/schemas/dataElement"
```

Which will yield the result:

```json
[
   {
      "message" : "Required property missing.",
      "property" : "type"
   },
   {
      "property" : "aggregationOperator",
      "message" : "Required property missing."
   },
   {
      "property" : "domainType",
      "message" : "Required property missing."
   },
   {
      "property" : "shortName",
      "message" : "Required property missing."
   }
]
```

### Partial updates { #webapi_partial_updates } 

For our API endpoints that deal with metadata, we support partial updates (PATCH) using the JSON patch [standard](https://tools.ietf.org/html/rfc6902). The payload basically outlines a set of operation you want applied to a existing metadata object. For JSON patch details and examples, see [jsonpatch.com](http://jsonpatch.com/). Three operators are supported: `add`, `remove` and `replace`.

Below is a few examples relevant to DHIS2. Note that any update to a payload should be thought of as a HTTP PUT operation, i.e. any mutation must result in a valid PUT metadata payload.

The default `importReportMode` for JSON patch is `ERRORS_NOT_OWNER` which implies that when updating any property which is not owned by that particular object (for example trying to add a indicator group directly to an indicator) you will get an error.

As per the JSON patch specification you must always use the mimetype `application/json-patch+json` when sending patches.

#### Exemples { #examples }

##### Update name and value type of data element { #update-name-and-value-type-of-data-element } 

```
PATCH /api/dataElements/{id}
```

```json
[
  {"op": "add", "path": "/name", "value": "New Name"},
  {"op": "add", "path": "/valueType", "value": "INTEGER"}
] 
```

##### Add new data element to a data element group { #add-new-data-element-to-a-data-element-group } 

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "add", "path": "/dataElements/-", "value": {"id": "data-element-id"}}
]
```

##### Remove all data element associations from a data element group { #remove-all-data-element-associations-from-a-data-element-group } 

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "remove", "path": "/dataElements"}
]
```

##### Change domain and value type of a data element { #change-domain-and-value-type-of-a-data-element } 

```
PATCH /api/dataElements/{id}
```

```json
[
    {"op": "add", "path": "/domainType", "value": "TRACKER"},
    {"op": "add", "path": "/valueType", "value": "INTEGER"}
]
```

##### Remove a specific orgUnit from an orgUnit group { #remove-a-specific-orgunit-from-an-orgunit-group } 

```
PATCH /api/organisationUnitGroups/{id}
```

```json
[
  {"op": "remove", "path": "/organisationUnits/1"}
]
```


## Metadata export { #webapi_metadata_export } 

This section explains the metatada API which is available at
`/api/metadata`. XML and JSON resource representations are supported.

    /api/metadata

The most common parameters are described below in the "Export Parameter"
table. You can also apply this to all available types by using
`type:fields=<filter>` and `type:filter=<filter>`. You can also
enable/disable the export of certain types by setting `type=true|false`.

Table: Export Parameter

| Nom | Options | Description |
|---|---|---|
| fields | Same as metadata field filter | Default field filter to apply for all types, default is `:owner`. |
| filtre | Same as metadata object filter | Default object filter to apply for all types, default is `none`. |
| Ordre | Same as metadata order | Default order to apply to all types, default is `name` if available, or `created` if not. |
| translate | false/true | Enable translations. Be aware that this is turned off by default (in other endpoints this is on by default). |
| locale | <locale\> | Change from user locale, to your own custom locale. |
| defaults | INCLUDE/EXCLUDE | Should auto-generated category object be included or not in the payload. If you are moving metadata between 2 non-synced instances, it might make sense to set this to EXCLUDE to ease the handling of these generated objects. |
| skipSharing | false/true | Enabling this will strip the sharing properties from the exported objects. This includes *user*, *publicAccess*, *userGroupAccesses*, *userAccesses*, and *externalAccess*. |
| download | false/true | Enabling this will add HTTP header Content-Disposition that specifies that the data should be handled as an attachment and will be offered by web browsers as a download. |

### Metadata export examples { #webapi_metadata_export_examples } 

Export all metadata. Be careful as the response might be very large depending
on your metadata configuration:

    /api/metadata

Export all metadata ordered by lastUpdated descending:

    /api/metadata?defaultOrder=lastUpdated:desc

Export metadata only including indicators and indicator groups:

    /api/metadata?indicators=true&indicatorGroups=true

Export id and displayName for all data elements, ordered by displayName:

    /api/metadata?dataElements:fields=id,name&dataElements:order=displayName:desc

Export data elements and indicators where name starts with "ANC":

    /api/metadata?filter=name:$like:ANC&dataElements=true&indicators=true

### Metadata export with dependencies { #webapi_dataset_program_export_dependencies } 

When you want to exchange metadata for a data set, program, category combo,
dashboard, option set or data element group
from one DHIS2 instance to another instance there are six dedicated endpoints available:

```
/api/dataSets/{id}/metadata.json

/api/programs/{id}/metadata.json

/api/categoryCombos/{id}/metadata.json

/api/dashboards/{id}/metadata.json

/api/optionSets/{id}/metadata.json

/api/dataElementGroups/{id}/metadata.json
```

These exports can then be imported using `/api/metadata`.

These endpoints also support the following parameters:

Table: Export Parameter

| Nom | Options | Description |
|---|---|---|
| skipSharing | false/true | Enabling this will strip the sharing properties from the exported objects. This includes *user*, *publicAccess*, *userGroupAccesses*, *userAccesses*, and *externalAccess*. |
| download | false/true | Enabling this will add HTTP header Content-Disposition that specifies that the data should be handled as an attachment and will be offered by web browsers as a download. |

## Metadata import { #webapi_metadata_import } 

This section explains the metadata import API. XML and JSON resource
representations are supported. Metadata can be imported using a *POST* request.

    /api/metadata

The importer allows you to import metadata payloads which may include many
different entities and any number of objects per entity. The metadata export
generated by the metadata export API can be imported directly.

The metadata import endpoint support a variety of parameters, which are
listed below.

Table: Import Parameter

| Nom | Options (first is default) | Description |
|---|---|---|
| Mode d'importation  | COMMIT, VALIDATE | Sets overall import mode, decides whether or not to only `VALIDATE` or also `COMMIT` the metadata, this has similar functionality as our old dryRun flag. |
| identifier | UID, CODE, AUTO | Sets the identifier scheme to use for reference matching. `AUTO` means try `UID` first, then `CODE`. |
| importReportMode | ERRORS, FULL, DEBUG | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |
| preheatMode | REFERENCE, ALL, NONE | Sets the preheater mode, used to signal if preheating should be done for `ALL` (as it was before with *preheatCache=true*) or do a more intelligent scan of the objects to see what to preheat (now the default), setting this to `NONE` is not recommended. |
| importStrategy (stratégie d'importation) | CREATE_AND_UPDATE, CREATE, UPDATE, DELETE | Sets import strategy, `CREATE_AND_UPDATE` will try and match on identifier, if it doesn't exist, it will create the object. |
| Mode atomique | ALL, NONE | Sets atomic mode, in the old importer we always did a *best effort* import, which means that even if some references did not exist, we would still import (i.e. missing data elements on a data element group import). Default for new importer is to not allow this, and similar reject any validation errors. Setting the `NONE` mode emulated the old behavior. |
| ~~mergeMode~~ | ~~REPLACE, MERGE~~ | ~~Sets the merge mode, when doing updates we have two ways of merging the old object with the new one, `MERGE` mode will only overwrite the old property if the new one is not-null, for `REPLACE` mode all properties are overwritten regardless of null or not.~~ (*) |
| flushMode | AUTO, OBJECT | Sets the flush mode, which controls when to flush the internal cache. It is *strongly* recommended to keep this to `AUTO` (which is the default). Only use `OBJECT` for debugging purposes, where you are seeing hibernate exceptions and want to pinpoint the exact place where the stack happens (hibernate will only throw when flushing, so it can be hard to know which object had issues). | 
| skipSharing | false, true | Skip sharing properties, does not merge sharing when doing updates, and does not add user group access when creating new objects. |
| skipValidation | false, true | Skip validation for import. `NOT RECOMMENDED`. |
| async | false, true | Asynchronous import, returns immediately with a *Location* header pointing to the location of the *importReport*. The payload also contains a json object of the job created. |
| inclusionStrategy | NON_NULL, ALWAYS, NON_EMPTY | *NON_NULL* includes properties which are not null, *ALWAYS* include all properties, *NON_EMPTY* includes non empty properties (will not include strings of 0 length, collections of size 0, etc.) |
| userOverrideMode | NONE, CURRENT, SELECTED | Allows you to override the user property of every object you are importing, the options are NONE (do nothing), CURRENT (use import user), SELECTED (select a specific user using overrideUser=X) |
| overrideUser | User ID | If userOverrideMode is SELECTED, use this parameter to select the user you want override with. |

> (*) Currently the `mergeMode=MERGE` option of the import service has limitations and doesn't support all objects. It doesn't work with some object types such as Embedded objects, or objects which are saved as JSONB format in database ( sharing, attributeValues, etc...). Fixing those issues are complicated and would just cause new issues. Therefore, this `mergedMode=MERGE` is deprecated and currently is not recommended to use. The update mode should always be mergedMode=REPLACE. We have developed a new [JSON Patch API](#webapi_partial_updates) which can be used as an alternative approach. This feature is introduced in 2.37 release.


An example of a metadata payload to be imported looks like this. Note how
each entity type have their own property with an array of objects:

```json
{
  "dataElements": [
    {
      "name": "EPI - IPV 3 doses given",
      "shortName": "EPI - IPV 3 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    },
    {
      "name": "EPI - IPV 4 doses given",
      "shortName": "EPI - IPV 4 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    }
  ],
  "indicators": [
    {
      "name": "EPI - ADS stock used",
      "shortName": "ADS stock used",
      "numerator": "#{LTb8XeeqeqI}+#{Fs28ZQJET6V}-#{A3mHIZd2tPg}",
      "numeratorDescription": "ADS 0.05 ml used",
      "denominator": "1",
      "denominatorDescription": "1",
      "annualized": false,
      "indicatorType": {
        "id": "kHy61PbChXr"
      }
    }
  ]
}
```

When posting this payload to the metadata endpoint, the response will contain
information about the parameters used during the import and a summary per
entity type including how many objects were created, updated, deleted and
ignored:

```json
{
  "importParams": {
    "userOverrideMode": "NONE",
    "importMode": "COMMIT",
    "identifier": "UID",
    "preheatMode": "REFERENCE",
    "importStrategy": "CREATE_AND_UPDATE",
    "atomicMode": "ALL",
    "mergeMode": "REPLACE",
    "flushMode": "AUTO",
    "skipSharing": false,
    "skipTranslation": false,
    "skipValidation": false,
    "metadataSyncImport": false,
    "firstRowIsHeader": true,
    "username": "UNICEF_admin"
  },
  "status": "OK",
  "typeReports": [
    {
      "klass": "org.hisp.dhis.dataelement.DataElement",
      "stats": {
        "created": 2,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 2
      }
    },
    {
      "klass": "org.hisp.dhis.indicator.Indicator",
      "stats": {
        "created": 1,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 1
      }
    }
  ],
  "stats": {
    "created": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0,
    "total": 3
  }
}
```


## Schema { #webapi_schema } 

A resource which can be used to introspect all available DXF 2 objects
can be found on `/api/schemas`. For specific resources you can have a
look at `/api/schemas/<type>`.

To get all available schemas in XML:

    GET /api/schemas.xml

To get all available schemas in JSON:

    GET /api/schemas.json

To get JSON schema for a specific class:

    GET /api/schemas/dataElement.json


## Icons { #webapi_icons } 

DHIS2 includes a collection of icons that can be used to give visual
context to metadata. These icons can be accessed through the icons
resource.

    GET /api/icons

This endpoint returns a list of information about the available icons.
Each entry contains information about the icon, and a reference to the
actual icon.

```json
{
  key: "mosquito_outline",
  description: "Mosquito outline",
  keywords: [
    "malaria",
    "mosquito",
    "dengue"
  ],
  href: "<dhis server>/api/icons/mosquito_outline/icon.svg"
}
```

The keywords can be used to filter which icons to return. Passing a list
of keywords with the request will only return icons that match all the
keywords:

    GET /api/icons?keywords=shape,small

A list of all unique keywords can be found at the keywords resource:

    GET /api/icons/keywords

## Render type { #webapi_render_type } 

Some metadata types have a property named *renderType*. The render type
property is a map between a *device* and a *renderingType*. Applications
can use this information as a hint on how the object should be rendered
on a specific device. For example, a mobile device might want to render
a data element differently than a desktop computer.

There is currently two different kinds of renderingTypes available:

1.  Value type rendering

2.  Program stage section rendering

There is also 2 device types available:

1.  MOBILE

2.  DESKTOP

The following table lists the metadata and rendering types available.
The value type rendering has addition constraints based on the metadata
configuration, which will be shown in a second table.

Table: Metadata and RenderingType overview

| Metadata type | Available RenderingTypes |
|---|---|
| Program Stage Section | * LISTING (default)<br> * SEQUENTIAL<br> * MATRIX |
| Élément de données | * DEFAULT<br> * DROPDOWN<br> * VERTICAL_RADIOBUTTONS<br> * HORIZONTAL_RADIOBUTTONS<br> * VERTICAL_CHECKBOXES<br> * HORIZONTAL_CHECKBOXES<br> * SHARED_HEADER_RADIOBUTTONS<br> * ICONS_AS_BUTTONS<br> * SPINNER<br> * ICON<br> * TOGGLE<br> * VALUE<br> * SLIDER<br> * LINEAR_SCALE<br> * AUTOCOMPLETE<br> * QR_CODE<br> * BAR_CODE<br> * GS1_DATAMATRIX |

Since handling the default rendering of data elements and tracked entity
attributes are depending on the value type of the object, there is also
a DEFAULT type to tell the client it should be handled as normal.
Program Stage Section is LISTING as default.

Table: RenderingTypes allowed based on value types

| Type de valeur               | Is object an optionset? | RenderingTypes allowed |
|--------------------------|---|---|
| TRUE_ONLY                | Non | DEFAULT, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, TOGGLE |
| BOOLÉEN                  | Non ||
| -                        | Oui | DEFAULT, DROPDOWN, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, SHARED_HEADER_RADIOBUTTONS, ICONS_AS_BUTTONS, SPINNER, ICON |
| INTEGER                  | Non | DEFAULT, VALUE, SLIDER, LINEAR_SCALE, SPINNER |
| TEXT                     | Non | DEFAULT, VALUE, AUTOCOMPLETE, QR_CODE, BAR_CODE, GS1_DATAMATRIX |
| INTEGER_POSITIVE         | Non ||
| INTEGER_NEGATIVE         | Non ||
| INTEGER_ZERO_OR_POSITIVE | Non ||
| NUMBER                   | Non ||
| UNIT_INTERVAL            | Non ||
| PERCENTAGE               | Non ||

A complete reference of the previous table can also be retrieved using
the following endpoint:

    GET /api/staticConfiguration/renderingOptions

Value type rendering also has some additional properties that can be
set, which is usually needed when rendering some of the specific types:

Table: renderType object properties

| Propriété | Description | Type |
|---|---|---|
| type | The RenderingType of the object, as seen in the first table. This property is the same for both value type and program stage section, but is the only property available for program stage section. | Enum (See list in the Metadata and Rendering Type table) |
| min | Only for value type rendering. Represents the minimum value this field can have. | Entier |
| max | Only for value type rendering. Represents the maximum value this field can have. | Entier |
| step | Only for value type rendering. Represents the size of the steps the value should increase, for example for SLIDER og LINEAR_SCALE | Entier |
| decimalPoints | Only for value type rendering. Represents the number of decimal points the value should use. | Entier |

The *renderingType* can be set when creating or updating the metadata listed in the first table. An example payload for the rendering type for program stage section looks like this:

```json
{
  "renderingType": {
    "type": "MATRIX"
  }
}
```

For data element and tracked entity attribute:

```json
{
  "renderingType": {
    "type": "SLIDER",
    "min": 0,
    "max": 1000,
    "step": 50,
    "decimalPoints": 0
  }
}
```

## Object Style { #webapi_object_style } 

Most metadata have a property names "style". This property can be used
by clients to represent the object in a certain way. The properties
currently supported by style is as follows:

Table: Style properties

| Propriété | Description | Type |
|---|---|---|
| color | A color, represented by a hexadecimal. | String (#000000) |
| icon | An icon, represented by a icon-name. | Chaîne |

Currently, there is no official list or support for icon-libraries, so
this is currently up to the client to provide. The following list shows
all objects that support style:

  - Élément de données

  - Data element category option

  - Ensemble de données

  - Indicateur

  - Option

  - Programme

  - Indicateur du programme

  - Program Section

  - Étape du programme

  - Program Stage Section

  - Relationship (Tracker)

  - Attribut d’entité suivie

  - Type d'entité suivie

When creating or updating any of these objects, you can include the
following payload to change the style:

```json
{
  "style": {
    "color": "#ffffff",
    "icon": "my-beautiful-icon"
  }
}
```

## Indicateurs { #webapi_indicators } 

This section describes indicators and indicator expressions.

### Aggregate indicators { #webapi_aggregate_indicators } 

To retrieve indicators you can make a GET request to the indicators
resource like this:

    /api/indicators

Indicators represent expressions which can be calculated and presented
as a result. The indicator expressions are split into a numerator and
denominator. The numerators and denominators are mathematical
expressions which can contain references to data elements, other indicators, constants and
organisation unit groups. The variables will be substituted with data
values when used e.g. in reports. Variables which are allowed in
expressions are described in the following table.

Table: Indicator variables

| Variable | Objet | Description |
|---|---|---|
| #{<data-element-id\>.<category-option-combo-id\>.<attribute-option-combo-id\>} | Opérande de l'élément de données | Refers to a combination of an aggregate data element and a category option combination. Both category and attribute option combo ids are optional, and a wildcard "\*" symbol can be used to indicate any value. |
| #{<dataelement-id\>.<category-option-group-id\>.<attribute-option-combo-id\>} | Category Option Group | Refers to an aggregate data element and a category option group, containing multiple category option combinations. |
| #{<data-element-id\>} | Aggregate data element | Refers to the total value of an aggregate data element across all category option combinations. |
| D{<program-id\>.<data-element-id\>} | Élément de données de programme | Refers to the value of a tracker data element within a program. |
| A{<program-id\>.<attribute-id\>} | Program tracked entity attribute | Refers to the value of a tracked entity attribute within a program. |
| I{<program-indicator-id\>} | Indicateur de programme | Refers to the value of a program indicator. |
| R{<dataset-id\>.<metric\>} | Taux de déclaration | Refers to a reporting rate metric. The metric can be REPORTING_RATE, REPORTING_RATE_ON_TIME, ACTUAL_REPORTS, ACTUAL_REPORTS_ON_TIME, EXPECTED_REPORTS. |
| C{<constant-id\>} | Constante | Refers to a constant value. |
| N{<indicator-id\>} | Indicateur | Refers to an existing Indicator. |
| OUG{<orgunitgroup-id\>} | Groupe d'unités d'organisation | Refers to the count of organisation units within an organisation unit group. |

Within a Data element operand or an Aggregate data element, the following substitutions may be made:

| Élément | Valeur | Description |
|---|---|---|
| data-element-id | data-element-id | An aggregate data element |
| data-element-id | deGroup:data-element-group-id | All the aggregate data elements in a data element group |
| category-option-combo-id | category-option-combo-id | A category option combination |
| category-option-combo-id | co:category-option-id | All the category option combinations in a category option |
| category-option-combo-id | coGroup:category-option-group-id | All the category option combinations in a category option group |
| category-option-combo-id | coGroup:co-group-id1&co-group-id2... | All the category option combinations that are members of multiple category option groups |

The syntax looks like
    this:

    #{<dataelement-id>.<catoptcombo-id>} + C{<constant-id>} + OUG{<orgunitgroup-id>}

A corresponding example looks like this:

    #{P3jJH5Tu5VC.S34ULMcHMca} + C{Gfd3ppDfq8E} + OUG{CXw2yu5fodb}

Note that for data element variables the category option combo
identifier can be omitted. The variable will then represent the total
for the data element, e.g. across all category option combos. Example:

    #{P3jJH5Tu5VC} + 2

Data element operands can include any of category option combination and
attribute option combination, and use wildcards to indicate any
    value:

    #{P3jJH5Tu5VC.S34ULMcHMca} + #{P3jJH5Tu5VC.*.j8vBiBqGf6O} + #{P3jJH5Tu5VC.S34ULMcHMca.*}

An example using a data element group:

    #{deGroup:oDkJh5Ddh7d} + #{deGroup:GBHN1a1Jddh.j8vBiBqGf6O}

An example using a category option, data element group, and a category option group:

    #{P3jJH5Tu5VC.co:FbLZS3ueWbQ} + #{deGroup:GBHN1a1Jddh.coGroup:OK2Nr4wdfrZ.j8vBiBqGf6O}

An example using multiple category option groups:

    #{P3jJH5Tu5VC.coGroup:OK2Nr4wdfrZ&j3C417uW6J7&ddAo6zmIHOk}

An example using a program data element and a program attribute:

    ( D{eBAyeGv0exc.vV9UWAZohSf} * A{IpHINAT79UW.cejWyOfXge6} ) / D{eBAyeGv0exc.GieVkTxp4HH}

An example combining program indicators and aggregate indicators:

    I{EMOt6Fwhs1n} * 1000 / #{WUg3MYWQ7pt}

An example using a reporting rate:

    R{BfMAe6Itzgt.REPORTING_RATE} * #{P3jJH5Tu5VC.S34ULMcHMca}

Another reporting rate example using actual data set reports and expected reports:

    R{BfMAe6Itzgt.ACTUAL_REPORTS} / R{BfMAe6Itzgt.EXPECTED_REPORTS}

An example using an existing indicator:

    N{Rigf2d2Zbjp} * #{P3jJH5Tu5VC.S34ULMcHMca}

Expressions can be any kind of valid mathematical expression, as an
example:

    ( 2 * #{P3jJH5Tu5VC.S34ULMcHMca} ) / ( #{FQ2o8UBlcrS.S34ULMcHMca} - 200 ) * 25

### ![](resources/images/pivot_table/table_layout.png) { #webapi_program_indicators } 

To retrieve program indicators you can make a GET request to the program
indicators resource like this:

    /api/programIndicators

Program indicators can contain information collected in a program.
Indicators have an expression which can contain references to data
elements, attributes, constants and program variables. Variables which
are allowed in expressions are described in the following table.



Table: Program indicator variables

| Variable | Description |
|---|---|
| #{<programstage-id\>.<dataelement-id\>} | Refers to a combination of program stage and data element id. |
| A{<attribute-id\>} | Refers to a tracked entity attribute. |
| V{<variable-id\>} | Refers to a program variable. |
| C{<constant-id\>} | Refers to a constant. |

The syntax looks like
    this:

    #{<programstage-id>.<dataelement-id>} + #{<attribute-id>} + V{<varible-id>} + C{<constant-id>}

A corresponding example looks like
    this:

    #{A03MvHHogjR.a3kGcGDCuk6} + A{OvY4VVhSDeJ} + V{incident_date} + C{bCqvfPR02Im}

### Expressions { #webapi_expressions } 

Expressions are mathematical formulas which can contain references to
data elements, constants and organisation unit groups. To validate and
get the textual description of an expression, you can make a GET request
to the expressions resource:

    /api/expressions/description?expression=<expression-string>

The response follows the standard JSON web message format. The *status*
property indicates the outcome of the validation and will be "OK" if
successful and "ERROR" if failed. The *message* property will be "Valid"
if successful and provide a textual description of the reason why the
validation failed if not. The *description* provides a textual
description of the expression.

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Valid",
  "description": "Acute Flaccid Paralysis"
}
```

## Les unités d’organisation { #webapi_organisation_units } 

The *organisationUnits* resource follows the standard conventions as
other metadata resources in DHIS2. This resource supports some
additional query parameters.

### Get list of organisation units { #webapi_list_of_organisation_units } 

To get a list of organisation units you can use the following resource.

    /api/33/organisationUnits

Table: Organisation units query parameters

| Paramètre de requête | Options | Description |
|---|---|---|
| userOnly | faux &#124; vrai | Data capture organisation units associated with current user only. |
| userDataViewOnly | faux &#124; vrai | Data view organisation units associated with current user only. |
| userDataViewFallback | faux &#124; vrai | Data view organisation units associated with current user only with fallback to data capture organisation units. |
| requête | string | Query against the name, code and ID properties. |
| District | entier | Organisation units at the given level in the hierarchy. |
| maxLevel | entier | Organisation units at the given max level or levels higher up in the hierarchy. |
| withinUserHierarchy | faux &#124; vrai | Limits search and retrieval to organisation units that are within the users data capture scope. |
| withinUserSearchHierarchy | faux &#124; vrai | Limits search and retrieval to organisation units that are within the current users search scope. Note: "withinUserHierarchy", if true, takes higher precedence. |
| memberCollection | string | For displaying count of members within a collection, refers to the name of the collection associated with organisation units. |
| memberObject | UID | For displaying count of members within a collection, refers to the identifier of the object member of the collection. |

### Get organisation unit with sub-hierarchy { #webapi_organisation_units_with_sub_hierarchy } 

To get an organisation unit including organisation units in its sub-hierarchy you can use the following resource.

    /api/33/organisationUnits/{id}

Table: Organisation unit parameters

| Paramètre de requête | Options | Description |
|---|---|---|
| Inclut les enfants | faux &#124; vrai | Include immediate children of the specified organisation unit, i.e. the units at the immediate level below in the subhierarchy. |
| includeDescendants | faux &#124; vrai | Include all children of the specified organisation unit, i.e. all units in the sub-hierarchy. |
| includeAncestors | faux &#124; vrai | Include all parents of the specified organisation unit. |
| District | entier | Include children of the specified organisation unit at the given level of the sub-hierarchy. This is relative to the organisation unit, starting on 1 for the level immediately below the org unit. |

### Get organisation units by category option  { #webapi_organisation_units_by_category_options }

Purpose-built endpoint to retrieve associations between category options and organisation units. This endpoint is the preferred way to retrieve program organisation unit associations.

    /api/33/categoryOptions/orgUnits?categoryOptions={categoryOptionIdA},{categoryOptionIdB}

responses will have the following format:

```json
{
  "<categoryOptionIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdC>": []
}
```

Category options that are accessible by all organisation units are returned with an empty array (`[]`) of organisation units.

### Get organisation units by programs { #webapi_organisation_units_by_programs } 

Purpose-built endpoint to retrieve associations between programs and organisation units. This endpoint is the preferred way to retrieve program organisation unit associations.

    /api/33/programs/orgUnits?programs={programIdA},{programIdB}

responses will have the following format:

```json
{
  "<programIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdC>": []
}
```

Programs which are accessible by all organisation units are returned with an empty array (`[]`) of organisation units.

### Split organisation unit { #webapi_organisation_unit_split }

The organisation unit split endpoint allows you to split organisation units into a number of target organisation units. 

#### Request { #request } 

Split organisation units with a POST request:

```
POST /api/organisationUnits/split
```

The payload in JSON format looks like the following:

```json
{
  "source": "rspjJHg4WY1",
  "targets": [
    "HT0w9YLMLyn",
    "rEpnzuNpRKM"
  ],
  "primaryTarget": "HT0w9YLMLyn",
  "deleteSource": true
}
```

The JSON properties are described in the following table.

Table: Split payload fields

| Champ         | Obligatoire | Valeur |
| ------------- | -------- |------ |
| source        | Oui      | Identifier of the organisation unit to split (the source organisation unit). |
| targets       | Oui      | Array of identifiers of the organisation units to split the source into (the target organisation units). |
| primaryTarget | Non       | Identifier of the organisation unit to transfer the aggregate data, events and tracked entities associated with the source over to. If not specified, the first target will be used. |
| deleteSource  | Non       | Whether to delete the source organisation unit after the operation. Default is `true`. |

The split operation will split the source org unit into the target org units. It is recommended to first create new target org units before performing the split, and at a minimum ensure that no aggregate data exists for the target org units. Any number of target org units can be specified.

The split operation will transfer all of the metadata associations of the source org unit over to the target org units. This includes data sets, programs, org unit groups, category options, users, visualizations, maps and event reports.

The operation will transfer all data records of the source org unit over to the org unit specified as the primary target, or if not specified, the first specified target org unit. This includes aggregate data values, data approval records, events, tracked entities and more.

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| Code d'erreur | Description                                     |
| ---------- | ----------------------------------------------- |
| E1510      | Source org unit must be specified               |
| E1511      | At least two target org units must be specified |
| E1512      | Source org unit cannot be a target org unit     |
| E1513      | Primary target must be specified                |
| E1514      | Primary target must be a target org unit        |
| E1515      | Target org unit does not exist                  |

### Merge organisation units { #webapi_organisation_unit_merge}

The organisation unit merge endpoint allows you to merge a number of organisation units into a target organisation unit.

#### Request { #request } 

Merge organisation units with a POST request:

```
POST /api/organisationUnits/merge
```

The payload in JSON format looks like the following:

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "dataValueMergeStrategy": "LAST_UPDATED",
  "dataApprovalMergeStrategy": "LAST_UPDATED",
  "deleteSources": true
}
```

The JSON properties are described in the following table.

Table: Merge payload fields

| Champ                     | Obligatoire | Valeur |
| ------------------------- | -------- | ----- |
| sources                   | Oui      | Array of identifiers of the organisation units to merge (the source organisation units). |
| target                    | Oui      | Identifier of the organisation unit to merge the sources into (the target organisation unit). |
| dataValueMergeStrategy    | Non       | Strategy for merging data values. Options: `LAST_UPDATED` (default), `DISCARD`. |
| dataApprovalMergeStrategy | Non       | Strategy for merging data approval records. Options: `LAST_UPDATED` (default), `DISCARD`. |
| deleteSources             | Non       | Whether to delete the source organisation units after the operation. Default is true. |

The merge operation will merge the source org units into the target org unit. It is recommended to first create a new target org unit before performing the merge, and at a minimum ensure that no aggregate data exists for the target org unit. Any number of source org units can be specified.

The merge operation will transfer all of the metadata associations of the source org units over to the target org unit. This includes data sets, programs, org unit groups, category options, users, visualizations, maps and event reports. The operation will also transfer all event and tracker data, such as events, enrollments, ownership history, program ownership and tracked entities, over to the target org unit.

The specified data value merge strategy defines how data values are handled. For strategy `LAST_UPDATED`, data values for all source org units are transferred over to the target org unit, and in situation where data values exist for the same parameters, the last updated or created data value will be used. This is done to avoid duplication of data. For strategy `DISCARD`, data values are not transferred over to the target org unit, and simply deleted. The specified data approval merge strategy defines how data approval records are handled, and follows the same logic as data values.

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| Code d'erreur | Description                                     |
| ---------- | ----------------------------------------------- |
| E1500      | At least two source orgs unit must be specified |
| E1501      | Target org unit must be specified               |
| E1502      | Target org unit cannot be a source org unit     |
| E1503      | Source org unit does not exist                  |

## Ensembles de données { #webapi_data_sets } 

The *dataSets* resource follows the standard conventions as other
metadata resources in DHIS2. This resource supports some additional
query parameters.

    /api/33/dataSets

To retrieve the version of a data set you can issue a GET request:

    GET /api/33/dataSets/<uid>/version

To bump (increase by one) the version of a data set you can issue a POST
request:

    POST /api/33/dataSets/<uid>/version

### Data set notification template { #webapi_dataset_notifications } 

The *dataset notification templates* resource follows the standard
conventions as other metadata resources in DHIS2.

    GET /api/33/dataSetNotficationTemplates

To retrieve data set notification template you can issue a GET request:

    GET /api/33/dataSetNotficationTemplates/<uid>

To add data set notification template you can issue a POST request:

    POST /api/33/dataSetNotficationTemplates

To delete data set notification template you can issue a DELETE request:

    DELETE /api/33/dataSetNotficationTemplates/<uid>

JSON payload sample is given below:

```json
{
  "name": "dataSetNotificationTemplate1",
  "dataSetNotificationTrigger": "DATA_SET_COMPLETION",
  "relativeScheduledDays": 0,
  "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
  "dataSets": [{
    "id": "eZDhcZi6FLP"
  }],
  "deliveryChannels": ["SMS","EMAIL"],
  "subjectTemplate": "V{data_set_name}",
  "messageTemplate": "V{data_set_name}V{registration_period}",
  "sendStrategy": "SINGLE_NOTIFICATION"
}

```

`notificationRecipient` can be one of:
- `USER_GROUP` for internal messages
- `ORGANISATION_UNIT_CONTACT` for external messages


## Filled organisation unit levels { #webapi_filled_organisation_unit_levels } 

The *filledOrganisationUnitLevels* resource provides an ordered list of
organisation unit levels, where generated levels are injected into the
list to fill positions for which it does not exist a persisted level.

    GET /api/33/filledOrganisationUnitLevels

To set the organisation unit levels you can issue a POST request with a
JSON payload and content type `application/json` looking like this:

```json
{
  "organisationUnitLevels": [{
    "name": "National",
    "level": 1,
    "offlineLevels": 3
  }, {
    "name": "District",
    "level": 2
  }, {
    "name": "Chiefdom",
    "level": 3
  }, {
    "name": "Facility",
    "level": 4
  }]
}
```

## Les prédicteurs { #webapi_predictors } 

A predictor allows you to generate data values based on an expression.
This can be used for example to generate targets, thresholds,
or estimated values.

To retrieve predictors you can make a GET request to the predictors
resource like this:

    /api/predictors

### Creating a predictor { #webapi_create_predictor } 

You can create a predictor with a POST request to the predictors
resource:

    POST /api/predictors

A sample payload looks like this:

```json
{
  "id": "AG10KUJCrRk",
  "name": "Malaria Outbreak Threshold Predictor",
  "shortName": "Malaria Outbreak Predictor",
  "description": "Computes the threshold for potential malaria outbreaks based on the mean plus 1.5x the std dev",
  "output": {
    "id": "nXJJZNVAy0Y"
  },
  "generator": {
    "expression": "AVG(#{r6nrJANOqMw})+1.5*STDDEV(#{r6nrJANOqMw})",
    "description": "Maximum normal malaria case count",
    "missingValueStrategy": "NEVER_SKIP",
    "slidingWindow": false
  },
  "periodType": "Monthly",
  "sequentialSampleCount": 4,
  "sequentialSkipCount": 1,
  "annualSampleCount": 3,
  "organisationUnitLevels": [4]
}
```

The output element refers to the identifier of the data element for
which to saved predicted data values. The generator element refers to the
expression to use when calculating the predicted values.

### Predictor expressions { #webapi_predictor_expressions } 

A predictor always has a generator expression that describes how the
predicted value is calculated. A predictor may also have a skip test
expression returning a boolean value. When the skip test expression is
present, it is evaluated in each of the sampled periods to tell whether
values from that period should be skipped.

The following variables may be used in either a generator expression
or a skip test expression:

| Variable    | Objet     | Description |
| ----------- | ---------- | ----------- |
| #{<dataelement-id>} | Aggregate data element | Refers to the total value of an aggregate data element across all category option combinations. |
| #{<dataelement-id>.<categoryoptcombo-id> | Opérande de l'élément de données | Refers to a combination of an aggregate data element and a category option combination. |
| D{<program-id>.<dataelement-id>} | Élément de données de programme | Refers to the value of a tracker data element within a program. |
| A{<program-id>.<attribute-id>} | Program tracked entity attribute | Refers to the value of a tracked entity attribute within a program. |
| I{<program-indicator-id>} | Indicateur de programme | Refers to the value of a program indicator. |
| R{<dataset-id>.<metric>} | Taux de déclaration | Refers to a reporting rate metric. The metric can be REPORTING_RATE, REPORTING_RATE_ON_TIME, ACTUAL_REPORTS, ACTUAL_REPORTS_ON_TIME, EXPECTED_REPORTS. |
| C{<constant-id>} | Constante | Refers to a constant value. |
| OUG{<orgunitgroup-id>} | Groupe d'unités d'organisation | Refers to the count of organisation units within an organisation unit group. |
| [days] | Number of days | The number of days in the current period. |

### Generating predicted values { #webapi_generating_predicted_values } 

To run all predictors (generating predicted values) you can make a POST
request to the run resource:

    POST /api/predictors/run

To run a single predictor you can make a POST request to the run
resource for a predictor:

    POST /api/predictors/AG10KUJCrRk/run

## Règles du programme { #webapi_program_rules } 

This section is about sending and reading program rules, and explains
the program rules data model. The program rules give functionality to
configure dynamic behaviour in the programs in DHIS2.

### Program rule model { #webapi_program_rule_model } 

The program rules data model consists of programRuleVariables,
programRules and programRuleActions. The programRule contains an
expression - when this expression is true, the child programRuleActions
is triggered. The programRuleVariables is used to address data elements,
tracked entity data values and other data values needed to run the
expressions. All programRules in a program share the same library of
programRuleVariables, and one programRuleVariable can be used in several
programRules' expressions.

![](resources/images/program_rules/program-rule-model.jpg)

#### Program rule model details { #program-rule-model-details } 

The following table gives a detailed overview over the programRule
model.

Table: programRule

| nom | Description | Compulsory |
|---|---|---|
| de paludisme) ». | The program of which the programRule is executed in. | Compulsory |
| nom | The name with which the program rule will be displayed to dhis2 configurators. Not visible to the end user of the program. | Compulsory |
| Description | The description of the program rule, can be used by configurators to describe the rule. Not visible to the end user of the program. | Compulsory |
| Étape du programme | If a programStage is set for a program rule, the rule will only be evaluated inside the specified program stage. | optional |
| condition | The expression that needs to be evaluated to true in order for the program rule to trigger its child actions. The expression is written using operators, function calls, hard coded values, constants and program rule variables. `d2:hasValue('hemoglobin') && #{hemoglobin} <= 7 `| Compulsory |
| priorité | The priority to run the rule in cases where the order of the rules matters. In most cases the rules does not depend on being run before or after other rules, and in these cases the priority can be omitted. If no priority is set, the rule will be run after any rules that has a priority defined. If a priority(integer) is set, the rule with the lowest priority will be run before rules with higher priority. | optional |

#### Program rule action model details { #program-rule-action-model-details } 

The following table gives a detailed overview over the programRuleAction
model.

Table: programRuleAction

| nom | Description | Compulsory |
|---|---|---|
| programRule | The programRule that is the parent of this action. | Compulsory |
| programRule- ActionType | The type of action that is to be performed.<br>  * `DISPLAYTEXT` - Displays a text in a given widget.<br> * `DISPLAYKEYVALUEPAIR` - Displays a key and value pair(like a program indicator) in a given widget.<br> * `HIDEFIELD` - Hide a specified dataElement or trackedEntityAttribute.<br>    -         *content* - if defined, the text in *content* will be displayed to the end user in the instance where a value is previously entered into a field that is now about to be hidden (and therefore blanked). If *content* is not defined, a standard message will be shown to the user in this instance.<br>   -         *dataElement* - if defined, the HIDEFIELD action will hide this dataElement when the rule is effective.<br>   -         *trackedEntityDataValue* - if defined, the HIDEFIELD action will hide this trackedEntityDataValue when the rule is effective.<br>  * `HIDESECTION` - Hide a specified section.<br>    -         *programStageSection* - must be defined. This is the programStageSection that will be hidden in case the parent rule is effective.<br>  * `ASSIGN` - Assign a dataElement a value(help the user calculate something or fill in an obvious value somewhere)<br>    -         *content* - if defined, the value in *data* is assigned to this variable. If content id defined, and thus a variable is assigned for use in other rules, it is important to also assign a *programRule.priority* to make sure the rule with an ASSIGN action runs before the rule that will in turn evaluate the assigned variable.<br>   -         *data* - must be defined, data forms an expression that is evaluated and assigned to either a variable(#{myVariable}), a dataElement, or both.<br>   -         *dataElement* - if defined, the value in *data* is assigned to this data element.<br>  Either the content or dataElement must be defined for the ASSIGN action to be effective.<br> * `SHOWWARNING` - Show a warning to the user, not blocking the user from completing the event or registration.<br>    -         *content* - if defined, content is a static part that is displayed at the end of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the warning message.<br>   -         *dataElement* - if defined, the warning message is displayed next to this data element.<br>   -         *trackedEntityAttribute* - if defined, the warning message is displayed next to this tracked entity attribute.<br>  Either dataElement or trackedEntityAttribute must be specified.<br> * `SHOWERROR` - Show an error to the user, blocking the user from completing the event or registration.<br>    -         *content* - if defined, content is a static part that is displayed in the start of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the error message.<br>   -         *dataElement* - if defined, the error message is linked to this data element.<br>   -         *trackedEntityAttribute* - if defined, the error message is linked to this tracked entity attribute.<br>  Either dataElement or trackedEntityAttribute must be specified.<br> * `WARNINGONCOMPLETE` - Show a warning to the user on the "Complete form" dialog, but allowing the user to complete the event.<br>    -         *content* - if defined, content is a static part that is displayed at the end of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the warning message.<br>   -         *dataElement* - if defined, the warning message prefixed with the name/formName of the data element.<br>  * `ERRORONCOMPLETE` - Show an error to the user on in a modal window when the user tries to complete the event. The user is prevented from completing the event.<br>    -         *content* - if defined, content is a static part that is displayed in the start of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the error message.<br>   -         *dataElement* - if defined, the error message is linked to this data element.<br>  * `CREATEEVENT` - Create an event within the same enrollment.<br>    -         *content*<br>   -         *data* - if defined, contains data values to assign the created event. The format is <uid\>:<data value\>. Where several values is specified, these are separated with comma.<br> AcMrnleqHqc:100,AqK1IHqCkEE:'Polyhydramnios'   -         *programStage* - must be defined, and designates the program stage that the rule shall create an event of.<br>  * `SETMANDATORYFIELD` - Set a field to be mandatory.<br>    -         *dataElement* - if defined, this data element will be set to be mandatory in the data entry form.<br>   -         *trackedEntityAttribute* - if defined, this tracked entity attribute will be set to mandatory in the registration form or profile.<br>  * `SENDMESSAGE` - To send message at completion of event/enrollment or at data value update.<br>    -         *messageTemplate* - if defined, this template will be delivered either as SMS or EMAIL depending upon DeliveryChannel value in message template.<br>  * `SCHEDULEMESSAGE` - To schedule message at completion of event/enrollment or at data value update.<br>    -         *messageTemplate* - if defined, this template will be delivered either as SMS or EMAIL depending upon DeliveryChannel value in message template.<br>   -         *Date to send message* - Expression which is going to be used for evaluation of scheduled date. This expression should result in Date, any other resultant will be discarded and notification will not get scheduled. | Compulsory |
| location | Used for actionType DISPLAYKEYVALUEPAIR and DISPLAYTEXT to designate which widget to display the text or keyvaluepair in. Compulsory for DISPLAYKEYVALUEPAIR and DISPLAYTEXT. | See description |
| content | Used for user messages in the different actions. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, DISPLAYTEXT and DISPLAYKEYVALUEPAIR. Optional for HIDEFIELD and ASSIGN. | See description |
| données | Used for expressions in the different actions. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for ASSIGN. Optional for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, DISPLAYTEXT, CREATEEVENT and DISPLAYKEYVALUEPAIR | See description |
| élément de données | Used for linking rule actions to dataElements. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, ASSIGN and HIDEFIELD | See description |
| trackedEntity- Attribute | Used for linking rule actions to trackedEntityAttributes. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for SHOWWARNING, SHOWERROR and HIDEFIELD. | See description |
| option | Used for linking rule actions to options. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for HIDEOPTION | See description |
| optionGroup | Used for linking rule actions to optionGroups. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for SHOWOPTIONGROUP, HIDEOPTIONGROUP. | See description |
| Étape du programme | Only used for CREATEEVENT rule actions. Compulsory for CREATEEEVENT. | See description |
| programStage- Section | Only used for HIDESECTION rule actions. Compulsory for HIDESECTION | See description |

##### ProgramRuleAction Validation { #programruleaction-validation } 
There are certain validations added to ProgramRuleAction model in 2.37. Main purpose was to keep user from creating erroneous ProgramRules in order to keep the database consistent. These validations depends on program rule action type. Each action type has its own respective validation. 

Table: ProgramRuleAction Validations

| nom | validation check for id existence |
|---|---|
|SENDMESSAGE| Notification template id |
|SCHEDULEMESSAGE| Notification template id |
|HIDESECTION| ProgramStage section id |
|HIDEPROGRAMSTAGE| ProgramStage id |
|HIDEFIELD| DataElement or TrackedEntityAttribute id |
|HIDEOPTION| Option id |
|HIDEOPTIONGROUP| Option group id |
|SHOWOPTIONGROUP| Option group id |
|SETMANDATORYFIELD| DataElement or TrackedEntityAttribute id |
|SHOWERROR| Always valid |
|SHOWWARNING| Always valid |
|DISPLAYTEXT| DataElement or TrackedEntityAttribute id |
|DISPLAYKEYVALUEPAIR||
|ASSIGN| DataElement or TrackedEntityAttribute id |
|WARNINGONCOMPLETE| DataElement or TrackedEntityAttribute id |
|ERRORONCOMPLETE| DataElement or TrackedEntityAttribute id |

Apart from above validations, `data` field in program rule action which normally contains expression can also be evaluated using below api endpoint.

    POST /api/programRuleActions/data/expression/description?programId=<uid>


```json
{
  "condition": "1 + 1"
}
```

#### Program rule variable model details { #program-rule-variable-model-details } 

The following table gives a detailed overview over the
programRuleVariable model.

Table: programRuleVariable

| nom | Description | Compulsory |
|---|---|---|
| nom | the name for the programRuleVariable - this name is used in expressions. #{myVariable} \> 5 | Compulsory |
| sourceType | Defines how this variable is populated with data from the enrollment and events. <br> * DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE - In tracker capture, gets the newest value that exists for a data element, within the events of a given program stage in the current enrollment. In event capture, gets the newest value among the 10 newest events on the organisation unit.<br> * DATAELEMENT_NEWEST_EVENT_PROGRAM - In tracker capture, get the newest value that exists for a data element across the whole enrollment. In event capture, gets the newest value among the 10 newest events on the organisation unit.<br> * DATAELEMENT_CURRENT_EVENT - Gets the value of the given data element in the current event only.<br> * DATAELEMENT_PREVIOUS_EVENT - In tracker capture, gets the newest value that exists among events in the program that precedes the current event. In event capture, gets the newvest value among the 10 preceeding events registered on the organisation unit.<br> * CALCULATED_VALUE - Used to reserve a variable name that will be assigned by a ASSIGN program rule action<br> * TEI_ATTRIBUTE - Gets the value of a given tracked entity attribute | Compulsory |
| Type de valeur | valueType parameter defines the type of the value that this ProgramRuleVariable can contain. Its value is dependent on sourceType parameter. If source is DataElement or TrackedEntityAttribute<br> then valueType will be derived from valueType of the source. When the sourceType is CALCULATED_VALUE, then valueType should be provided by the user otherwise it will default <br> to ValueType.TEXT| Compulsory
| élément de données | Used for linking the programRuleVariable to a dataElement. Compulsory for all sourceTypes that starts with DATAELEMENT_. | See description |
| trackedEntity- Attribute | Used for linking the programRuleVariable to a trackedEntityAttribute. Compulsory for sourceType TEI_ATTRIBUTE. | See description |
| useCodeFor- OptionSet | If checked, the variable will be populated with the code - not the name - from any linked option set. Default is unchecked, meaning that the name of the option is populated. ||
| Étape du programme | Used for specifying a specific program stage to retreive the programRuleVariable value from. Compulsory for DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE. | See description |

### Creating program rules { #webapi_creating_program_rules } 

- To perform crud operations, `programRules` resource is available in API.

To retrieve list of programRules you can do a GET request like this:

    /api/programRules

To retrieve single programRule you can do a GET request like this:

    /api/programRules/<program_rule_uid>

To save/add single programRule you can do a POST request like this:

    /api/programRules/<program_rule_uid>

To update single programRule you can do a PUT request like this:

    /api/programRules/<program_rule_uid>

To delete single programRule you can do a DELETE request like this:

    /api/programRules/<program_rule_uid>

To retrieve description of programRule condition you can use POST and provide condition string in the POST body.

    /api/programRules/condition/description?<program_rule_uid>

## Forms { #webapi_forms } 

To retrieve information about a form (which corresponds to a data set
and its sections) you can interact with the `form` resource. The form
response is accessible as XML and JSON and will provide information
about each section (group) in the form as well as each field in the
sections, including labels and identifiers. By supplying period and
organisation unit identifiers the form response will be populated with
data values.

Table: Form query parameters

| Paramètre | Option | Description |
|---|---|---|
| pe | ISO period | Period for which to populate form data values. |
| ou | UID | Organisation unit for which to populate form data values. |
| metaData | faux &#124; vrai | Whether to include metadata about each data element of form sections. |

To retrieve the form for a data set you can do a GET request like this:

    /api/dataSets/<dataset-id>/form.json

To retrieve the form for the data set with identifier "BfMAe6Itzgt" in
XML:

    /api/dataSets/BfMAe6Itzgt/form

To retrieve the form including metadata in JSON:

    /api/dataSets/BfMAe6Itzgt/form.json?metaData=true

To retrieve the form filled with data values for a specific period and
organisation unit in XML:

    /api/dataSets/BfMAe6Itzgt/form.xml?ou=DiszpKrYNg8&pe=201401

When it comes to custom data entry forms, this resource also allows for
creating such forms directly for a data set. This can be done through a
POST or PUT request with content type text/html where the payload is the
custom form markup such as:

```bash
curl -d @form.html "localhost/api/dataSets/BfMAe6Itzgt/form"
  -H "Content-Type:text/html" -u admin:district -X PUT
```

## Documents { #webapi_documents } 

References to files can be stored with the document resource.



Table: Document fields

| Field name | Description |
|---|---|
| nom | unique name of document |
| external | flag identifying the location of the document. TRUE for external files, FALSE for internal ones |
| url | the location of the file. URL for external files. File resource id for internal ones (see [File resources](#webapi_file_resources)) |

A GET request to the documents endpoint will return all documents:

    /api/documents

A POST request to the documents endpoint will create a new document:

```bash
curl -X POST -d @document.json -H "Content-type: application/json"
  "http://dhis.domain/api/documents"
```

```json
{
  "name": "dhis home",
  "external": true,
  "url": "https://www.dhis2.org"
}
```

A GET request with the id of a document appended will return information
about the document. A PUT request to the same endpoint will update the
fields of the document:

    /api/documents/<documentId>

Appending */data* to the GET request will return the actual file content
of the document:

    /api/documents/<documentId>/data

## CSV metadata import { #webapi_csv_metadata_import } 

DHIS2 supports import of metadata in the CSV format, such as data elements, organisation units and validation rules. Properties for the various metadata objects are identified based on the column order/column index (see below for details). You can omit non-required object properties/columns, but since the column order is significant, an empty column must be included. In other words, if you would like to specify properties/columns which appear late in the column order but not specify certain columns which appear early in the order you can include empty/blank columns for them.

The first row of the CSV file is considered to be a header and is ignored during import. The _comma_ character should be used as a text delimiter. Text which contains commas must be enclosed in _double quotes_.

To upload metadata in CSV format you can make a POST request to the metadata endpoint:

    POST /api/metadata?classKey=CLASS-KEY

The following object types are supported. The `classKey` query parameter is mandatory and can be found next to each object type in the table below.

Table: Object types and keys

| Type d'objet | Class key |
|---|---|
| Des éléments de données | DATA_ELEMENT |
| Groupes d'éléments de données | DATA_ELEMENT_GROUP |
| Les options de catégorie | CATEGORY_OPTION |
| Category option groups | CATEGORY_OPTION_GROUP |
| Unités d’organisation | ORGANISATION_UNIT |
| Groupes d'unités d'organisation | ORGANISATION_UNIT_GROUP |
| Règles de validation | VALIDATION_RULE |
| Option sets | OPTION_SET |
| Les traductions | TRANSLATION |

> **Tip**
>
> If using *curl*, the `--data-binary` option should be used as it preserves line breaks and newlines, which is essential for CSV data.

As an example, to upload a file of data elements in CSV format with `curl` you can use the following command:

```bash
curl --data-binary @data_elements.csv "http://localhost/api/metadata?classKey=DATA_ELEMENT"
  -H "Content-Type:application/csv" -u admin:district
```

The formats for the currently supported object types for CSV import are listed in the following sections.

### Eléments de données { #webapi_csv_data_elements } 

Table: Data Element CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 char. Unique. |
| 2 | UID | Non | UID | Stable identifier. Exactly 11 alpha-numeric characters, beginning with a letter. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 char. |
| 4 | Nom abrégé | Non | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 char. Unique. |
| 5 | Description | Non || Free text description. |
| 6 | Nom du formulaire | Non || Max 230 char. |
| 7 | Type de domaine | Non | AGGREGATE &#124; TRACKER | Domain type for data element, can be aggregate or tracker. Max 16 char. |
| 8 | Type de valeur | Non | INTEGER &#124; NUMBER &#124; UNIT_INTERVAL &#124; PERCENTAGE &#124; INTEGER_POSITIVE &#124; INTEGER_NEGATIVE &#124; INTEGER_ZERO_OR_POSITIVE &#124; FILE_RESOURCE &#124; COORDINATE &#124;TEXT &#124; LONG_TEXT &#124; LETTER &#124; PHONE_NUMBER &#124; EMAIL &#124; BOOLEAN &#124; TRUE_ONLY &#124; DATE &#124; DATETIME | Value type. Max 16 char. |
| 9 | Type d'agrégation | Non | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX &#124; NONE | Aggregation type indicating how to aggregate data in various dimensions. Max 16 char. |
| 10 | La combinaison de catégories | Non | UID | UID of category combination. Will default to default category combination if not specified. |
| 11 | Url | Non || URL to data element resource. Max 255 char. |
| 12 | Zero is significant | Non | faux &#124; vrai | Indicates whether zero values will be stored for this data element. |
| 13 | Ensemble d'options | Non | UID | UID of option set to use for data. |
| 14 | Comment option set | Non | UID | UID of option set to use for comments. |

An example of a CSV file for data elements can be seen below. The first
row will always be ignored. Note how you can skip columns and rely on
default values to be used by the system. You can also skip columns which
you do not use which appear to the right of the ones

```csv
name,uid,code,shortname,description
"Women participated skill development training",,"D0001","Women participated in training"
"Women participated community organizations",,"D0002","Women participated in organizations"
```

### Les unités d’organisation { #webapi_csv_org_units } 

Table: Organisation Unit CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 characters. Unique. |
| 2 | UID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 char. |
| 4 | Parent | Non | UID | UID of parent organisation unit. |
| 5 | Nom abrégé | Non | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 characters. Unique. |
| 6 | Description | Non || Free text description. |
| 7 | Date d'ouverture | Non | 1970-01-01 | Opening date of organisation unit in YYYY-MM-DD format. |
| 8 | Closed date | Non || Closed date of organisation unit in YYYY-MM-DD format, skip if currently open. |
| 9 | Commentaire | Non || Free text comment for organisation unit. |
| 10 | Feature type | Non | NONE &#124; MULTI_POLYGON &#124; POLYGON &#124; POINT &#124; SYMBOL | Geospatial feature type. |
| 11 | Coordinates | Non || Coordinates used for geospatial analysis in Geo JSON format. |
| 12 | URL | Non || URL to organisation unit resource. Max 255 char. |
| 13 | Personne de contact | Non || Contact person for organisation unit. Max 255 char. |
| 14 | Addresse | Non || Address for organisation unit. Max 255 char. |
| 15 | Adresses électronique | Non || Email for organisation unit. Max 150 char. |
| 16 | Numéro de téléphone | Non || Phone number for organisation unit. Max 150 char. |

A minimal example for importing organisation units with a parent unit
looks like this:

```csv
name,uid,code,parent
"West province",,"WESTP","ImspTQPwCqd"
"East province",,"EASTP","ImspTQPwCqd"
```

### Règles de validation { #webapi_csv_validation_rules } 

Table: Validation Rule CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 characters. Unique. |
| 2 | UID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 |
| 4 | Description | Non || Free text description. |
| 5 | Instruction | Non || Free text instruction. |
| 6 | Importance | Non | MEDIUM &#124; HIGH &#124; LOW | Importance of validation rule. |
| 7 | Rule type (ignored) | Non | VALIDATION &#124; SURVEILLANCE | Type of validation rule. |
| 8 | Opérateur | Non | equal_to &#124; not_equal_to &#124; greater_than &#124; greater_than_or_equal_to &#124; less_than &#124; less_than_or_equal_to &#124; compulsory_pair &#124; exclusive_pair | Expression operator. |
| 9 | Type de période | Non | Monthly &#124; Daily &#124; Weekly &#124; Quarterly &#124; SixMontly &#124; Yearly | Period type. |
| 10 | Left side expression | Oui || Mathematical formula based on data element and option combo UIDs. |
| 11 | Left side expression description | Oui || Free text. |
| 12 | Left side missing value strategy | Non | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124; NEVER_SKIP | Behavior in case of missing values in left side expression. |
| 13 | Right side expression | Oui || Mathematical formula based on data element and option combo UIDs. |
| 14 | Right side expression description | Oui || Free text. |
| 15 | Right side missing value strategy | Non | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124; NEVER_SKIP | Behavior in case of missing values in right side expression. |

### Option sets { #webapi_csv_option_sets } 

Table: Option Set CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | OptionSetName | Oui || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionSetUID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionSetCode | Non || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionName | Oui || Option name. Max 230 characters. |
| 5 | OptionUID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 6 | OptionCode | Oui || Stable code. Max 50 char. |

The format for option sets is special. The three first values represent
an option set. The three last values represent an option. The first
three values representing the option set should be repeated for each
option.

```csv
optionsetname,optionsetuid,optionsetcode,optionname,optionuid,optioncode
"Color",,"COLOR","Blue",,"BLUE"
"Color",,"COLOR","Green",,"GREEN"
"Color",,"COLOR","Yellow",,"YELLOW"
"Sex",,,"Male",,"MALE"
"Sex",,,"Female",,"FEMALE"
"Sex",,,"Unknown",,"UNKNOWN"
"Result",,,"High",,"HIGH"
"Result",,,"Medium",,"MEDIUM"
"Result",,,"Low",,"LOW"
"Impact","cJ82jd8sd32","IMPACT","Great",,"GREAT"
"Impact","cJ82jd8sd32","IMPACT","Medium",,"MEDIUM"
"Impact","cJ82jd8sd32","IMPACT","Poor",,"POOR"
```

### Option group { #option-group } 

Table: Option Group CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | OptionGroupName | Oui || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionGroupUid | Non || Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionGroupCode | Non || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionGroupShortName | Oui || Short Name. Max 50 characters. Unique. Should be repeated for each option. |
| 5 | OptionSetUid | Oui || Stable identifier. Max 11 char. Should be repeated for each option. |
| 6 | OptionUid | Non || Stable identifier. Max 11 char. |
| 7 | OptionCode | Non || Stable code. Max 50 char. |

Sample OptionGroup CSV payload

```csv
optionGroupName,optionGroupUid,optionGroupCode,optionGroupShortName,optionSetUid,optionUid,optionCode
optionGroupA,,,groupA,xmRubJIhmaK,,OptionA
optionGroupA,,,groupA,xmRubJIhmaK,,OptionB
optionGroupB,,,groupB,QYDAByFgTr1,,OptionC
```
### Option Group Set { #option-group-set } 



Table: Option Group Set CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | OptionGroupSetName | Oui || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionGroupSetUid | Non || Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionGroupSetCode | Non || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionGroupSetDescription | Non || Description. Should be repeated for each option. |
| 5 | DataDimension | Non || TRUE, FALSE |
| 6 | OptionSetUid | Non || OptionSet UID. Stable identifier. Max 11 char. |

Sample OptionGroupSet CSV payload

```csv
name,uid,code,description,datadimension,optionsetuid
optiongroupsetA,,,,,xmRubJIhmaK
optiongroupsetB,,,,false,QYDAByFgTr1
```
To add OptionGroups to an imported OptionGroupSet, follow the steps as importing collection membership

### Collection membership { #collection-membership } 

In addition to importing objects, you can also choose to only import the
group-member relationship between an object and a group. Currently, the
following group and object pairs are supported

  - Organisation Unit Group - Organisation Unit

  - Data Element Group - Data Element

  - Indicator Group - Indicator

  - Option Group Set - Option Group

The CSV format for these imports are the same



Table: Collection membership CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | UID | Oui | UID | The UID of the collection to add an object to |
| 2 | UID | Oui | UID | The UID of the object to add to the collection |

### Other objects { #webapi_csv_other_objects } 



Table: Data Element Group, Category Option, Category Option Group, Organisation Unit Group CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 characters. Unique. |
| 2 | UID | Non | UID | Stable identifier. Max 11 chars. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 char. |
| 4 | Nom abrégé | Non || Short name. Max 50 characters. |

An example of category options looks like this:

```csv
name,uid,code,shortname
"Male",,"MALE"
"Female",,"FEMALE"
```

## Deleted objects { #webapi_deleted_objects } 

The deleted objects resource provides a log of metadata objects being
deleted.

    /api/deletedObjects

Whenever an object of type metadata is deleted, a log is being kept of
the uid, code, the type and the time of when it was deleted. This API is
available at `/api/deletedObjects` field filtering and object filtering
works similarly to other metadata resources.

Get deleted objects of type data elements:

    GET /api/deletedObjects.json?klass=DataElement

Get deleted object of type indicator which was deleted in 2015 and
forward:

    GET /api/deletedObjects.json?klass=Indicator&deletedAt=2015-01-01

## Favorites { #webapi_favorites } 

Certain types of metadata objects can be marked as favorites for the
currently logged in user. This applies currently for dashboards.

    /api/dashboards/<uid>/favorite

To make a dashboard a favorite you can make a *POST* request (no content
type required) to a URL like this:

    /api/dashboards/iMnYyBfSxmM/favorite

To remove a dashboard as a favorite you can make a *DELETE* request
using the same URL as above.

The favorite status will appear as a boolean *favorite* field on the
object (e.g. the dashboard) in the metadata response.

## Subscriptions { #webapi_subscription } 

A logged user can subscribe to certain types of objects. Currently
subscribable objects are those of type EventChart, EventReport,
Map, Visualization and EventVisualization.

> **Note**
>
> The EventChart and EventReport objects are deprecated. Use EventVisualization instead.

To get the subscribers of an object (return an array of user IDs) you
can make a *GET* request:

    /api/<object-type>/<object-id>/subscribers

See example as follows:

    /api/visualizations/DkPKc1EUmC2/subscribers

To check whether the current user is subscribed to an object (returns a
boolean) you can perform a *GET* call:

    /api/<object-type>/<object-id>/subscribed

See example as follows:

    /api/visualizations/DkPKc1EUmC2/subscribed

To subscribe/de-subscribe to an object you perform a *POST/DELETE*
request (no content type required):

    /api/<object-type>/<object-id>/subscriber

## File resources { #webapi_file_resources } 

*File resources* are objects used to represent and store binary content.
The *FileResource* object itself contains the file meta-data (name,
Content-Type, size, etc.) as well as a key allowing retrieval of the
contents from a database-external file store. The *FileResource* object
is stored in the database like any other but the content (file) is
stored elsewhere and is retrievable using the contained reference
*(storageKey)*.

    /api/fileResources

The contents of file resources are not directly accessible but are
referenced from other objects (such as data values) to store binary
content of virtually unlimited size.

To create a file resource that does not require a corresponding data value,
POST to the endpoint `/api/fileResources` with a multipart upload:

```bash
curl "https://server/api/fileResources" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

To create both a file resource and a data value that references the file,
POST to the `/api/dataValues/file` endpoint in DHIS 2.36 or later:

```bash
curl "https://server/api/dataValues/file?de=xPTAT98T2Jd
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

For the `api/fileResources` endpoint, the only form parameter required is
*file*, which is the file to upload. For the `api/dataValues/file`
endpoint, the parameters required are the same as for a post to
`api/dataValues`, with the addition of *file*.

The filename and content-type should also be included in the request but
will be replaced with defaults when not supplied.

On successfully creating a file resource the returned data will contain
a `response` field which in turn contains the `fileResource` like this:

```json
{
  "httpStatus": "Accepted",
  "httpStatusCode": 202,
  "status": "OK",
  "response": {
    "responseType": "FileResource",
    "fileResource": {
      "name": "name-of-file.png",
      "created": "2015-10-16T16:34:20.654+0000",
      "lastUpdated": "2015-10-16T16:34:20.667+0000",
      "externalAccess": false,
      "publicAccess": "--------",
      "user": { ... },
      "displayName": "name-of-file.png",
      "contentType": "image/png",
      "contentLength": 512571,
      "contentMd5": "4e1fc1c3f999e5aa3228d531e4adde58",
      "storageStatus": "PENDING",
      "id": "xm4JwRwke0i"
    }
  }
}
```

Note that the response is a *202 Accepted*, indicating that the returned
resource has been submitted for background processing (persisting to the
external file store in this case). Also, note the `storageStatus` field
which indicates whether the contents have been stored or not. At this
point, the persistence to the external store is not yet finished (it is
likely being uploaded to a cloud-based store somewhere) as seen by the
`PENDING` status.

Even though the content has not been fully stored yet the file resource
can now be used, for example as referenced content in a data value (see
[Working with file data values](#datavalue_file)). If we need to check
the updated *storageStatus* or otherwise retrieve the metadata of the
file, the `fileResources` endpoint can be queried.

```bash
curl "https://server/api/fileResources/xm4JwRwke0i" -H "Accept: application/json"
```

This request will return the `FileResource` object as seen in the
response of the above example.

### File resource constraints { #webapi_file_resources_constraints } 

  - File resources *must* be referenced (assigned) from another object
    in order to be persisted in the long term. A file resource which is
    created but not referenced by another object such as a data value is
    considered to be in *staging*. Any file resources which are in this
    state and are older than *two hours* will be marked for deletion
    and will eventually be purged from the system.

  - The ID returned by the initial creation of the file resource is not
    retrievable from any other location unless the file resource has
    been referenced (in which the ID will be stored as the reference),
    so losing it will require the POST request to be repeated and a new
    object to be created. The *orphaned* file resource will be cleaned
    up automatically.

  - File resource objects are *immutable*, meaning modification is not
    allowed and requires creating a completely new resource instead.

### File resource blocklist { #file-resource-blocklist } 

Certain types of files are blocked from being uploaded for security reasons.

The following content types are blocked.

| Content type | Content type |
| ------------------------------------- | ---- |
| text/html                             | application/x-ms-dos-executable |
| text/css                              | application/vnd.microsoft.portable-executable |
| text/javascript                       | application/vnd.apple.installer+xml |
| font/otf                              | application/vnd.mozilla.xul+xml |
| application/x-shockwave-flash         | application/x-httpd-php  |
| application/vnd.debian.binary-package | application/x-sh |
| application/x-rpm                     | application/x-csh |
| application/java-archive              |  |

The following file extensions are blocked.

| File extension | File extension | File extension |
| ---- | ---- | ---- |
| html | deb  | xul  |
| htm  | rpm  | php  |
| css  | jar  | bin  |
| js   | jsp  | sh   |
| mjs  | exe  | csh  |
| otf  | msi  | bat  |
| swf  | mpkg |      |

## Metadata versioning { #webapi_metadata_versioning } 

This section explains the metadata versioning APIs.

  - `/api/metadata/version`: This endpoint will return the current metadata
    version of the system on which it is invoked.



Table: Query Parameters

| Nom | Obligatoire | Description |
|---|---|---|
| versionName | faux | If this parameter is not specified, it will return the current version of the system or otherwise it will return the details of the versionName passed as parameter. (versionName is of the syntax "Version_<id\>" |

### Get metadata version examples { #webapi_metadata_versioning_examples } 

**Example:** Get the current metadata version of this system

Request:

```
/api/metadata/version
```

Response:

```json
{
  "name": "Version_4",
  "created": "2016-06-30T06:01:28.684+0000",
  "lastUpdated": "2016-06-30T06:01:28.685+0000",
  "externalAccess": false,
  "displayName": "Version_4",
  "type": "BEST_EFFORT",
  "hashCode": "848bf6edbaf4faeb7d1a1169445357b0",
  "id": "Ayz2AEMB6ry"
}
```

**Example:** Get the details of version with name "Version_2"

Request:

```
/api/metadata/version?versionName=Version_2
```

Response:

```json
{
  "name": "Version_2",
  "created": "2016-06-30T05:59:33.238+0000",
  "lastUpdated": "2016-06-30T05:59:33.239+0000",
  "externalAccess": false,
  "displayName": "Version_2",
  "type": "BEST_EFFORT",
  "hashCode": "8050fb1a604e29d5566675c86d02d10b",
  "id": "SaNyhusVxBG"
}
```

  - `/api/metadata/version/history`: This endpoint will return the list of all
    metadata versions of the system on which it is invoked.



Table: Query Parameters

| Nom | Obligatoire | Description |
|---|---|---|
| baseline | faux | If this parameter is not specified, it will return list of all metadata versions. Otherwise we need to pass a versionName parameter of the form "Version_<id\>". It will then return the list of versions present in the system which were created after the version name supplied as the query parameter. |

### Get the list of all metadata versions { #webapi_get_list_of_metadata_versions } 

**Example:** Get the list of all versions in this system

Request:

```
/api/metadata/version/history
```

Response:

```json
{
  "metadataversions": [{
    "name": "Version_1",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:54:41.139+0000",
    "id": "SjnhUp6r4hG",
    "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798"
  }, {
    "name": "Version_2",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:59:33.238+0000",
    "id": "SaNyhusVxBG",
    "hashCode": "8050fb1a604e29d5566675c86d02d10b"
  }, {
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }]
}
```

**Example:** Get the list of all versions in this system created after "Version_2"

Request:

```
/api/metadata/version/history?baseline=Version_2
```

Response:

```json
{
  "metadataversions": [{
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }, {
    "name": "Version_4",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:28.684+0000",
    "id": "Ayz2AEMB6ry",
    "hashCode": "848bf6edbaf4faeb7d1a1169445357b0"
  }]
 }
```

  - `/api/metadata/version/create`: This endpoint will create the metadata
    version for the version type as specified in the parameter.



Table: Query Parameters

| Nom | Obligatoire | Description |
|---|---|---|
| type | vrai | The type of metadata version which needs to be created.<br>  * BEST_EFFORT<br> * ATOMIC |

Users can select the type of metadata which needs to be created.
Metadata Version type governs how the importer should treat the given
version. This type will be used while importing the metadata. There are
two types of metadata.

  - *BEST_EFFORT*: This type suggests that missing references can be
    ignored and the importer can continue importing the metadata (e.g.
    missing data elements on a data element group import).

  - *ATOMIC*: This type ensures a strict type checking of the metadata
    references and the metadata import will fail if any of the references
    do not exist.

> **Note**
>
> It's recommended to have an ATOMIC type of versions to ensure that all
> systems (central and local) have the same metadata. Any missing
> reference is caught in the validation phase itself. Please see the
> importer details for a full explanation.

### Create metadata version { #webapi_create_metadata_version } 

**Example:** Create metadata version of type `BEST_EFFORT`

Request:

```bash
curl -X POST -u admin:district "https://play.dhis2.org/dev/api/metadata/version/create?type=BEST_EFFORT"
```

Response:

```json
{
  "name": "Version_1",
  "created": "2016-06-30T05:54:41.139+0000",
  "lastUpdated": "2016-06-30T05:54:41.333+0000",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407+0000",
    "lastUpdated": "2016-04-06T00:06:06.571+0000",
    "externalAccess": false,
    "displayName": "John Traore",
    "id": "xE7jOejl9FI"
  },
  "displayName": "Version_1",
  "type": "BEST_EFFORT",
  "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798",
  "id": "SjnhUp6r4hG"
}
```

  - `/api/metadata/version/{versionName}/data`: This endpoint will download
    the actual metadata specific to the version name passed as path
    parameter.

  - `/api/metadata/version/{versionName}/data.gz`: This endpoint will download
    the actual metadata specific to the version name passed as path
    parameter in a compressed format (gzipped).



Table: Path parameters

| Nom | Obligatoire | Description |
|---|---|---|
| versionName | vrai | Path parameter of the form "Version_<id\>" so that the API downloads the specific version |

### Download version metadata { #webapi_download_version_metadata } 

**Example:** Get the actual metadata for "Version 5"

Request:

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/version/Version_5/data"
```

Response:

```json
{
  "date": "2016-06-30T06:10:23.120+0000",
  "dataElements": [
    {
      "code": "ANC 5th Visit",
      "created": "2016-06-30T06:10:09.870+0000",
      "lastUpdated": "2016-06-30T06:10:09.870+0000",
      "name": "ANC 5th Visit",
      "id": "sCuZKDsix7Y",
      "shortName": "ANC 5th Visit ",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "zeroIsSignificant": false,
      "valueType": "NUMBER",
      "categoryCombo": {
        "id": "p0KPaWEg3cf"
      },
      "user": {
        "id": "xE7jOejl9FI"
      }
    }
  ]
}
```

## Metadata synchronization { #webapi_metadata_synchronization } 

This section explains the Metadata Synchronization API available
starting 2.24

  - `/api/metadata/sync`: This endpoint performs metadata sync of the
    version name passed in the query parameter by downloading and
    importing the specified version from the remote server as defined in
    the settings app.



Tableau : Paramètres de requête

| Nom | Obligatoire | Description |
|---|---|---|
| versionName | vrai | versionName query parameter of the form "Version_<id\>" . The api downloads this version from the remote server and imports it in the local system. |

  - This API should be used with utmost care. Please note that there is
    an alternate way to achieve sync in a completely automated manner by
    leveraging the Metadata Sync Task from the "Data Administration"
    app. See Chapter 22, Section 22.17 of User Manual for more details
    regarding Metadata Sync Task.

  - This sync API can alternatively be used to sync metadata for the
    versions which have failed from the metadata sync scheduler. Due to
    its dependence on the given metadata version number, care should be
    taken for the order in which this gets invoked. E.g. If this api is
    used to sync some higher version from the central instance, then the
    sync might fail as the metadata dependencies are not present in the
    local instance.

  - Assume the local instance is at `Version_12` and if this endpoint is used
    to sync `Version_15` (of type `BEST_EFFORT`) from the central
    instance, the scheduler will start syncing metadata from
    `Version_16`. So the local instance will not have the metadata
    versions between `Version_12` and `Version_15`. You need to manually
    sync the missing versions using these endpoints only.

### Sync metadata version { #webapi_metadata_synchronization_version } 

**Example:** Sync Version_6 from central system to this system

Request:

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/sync?versionName=Version_6"
```

## Metadata repository { #webapi_metadata_repository } 

DHIS2 provides a metadata repository containing metadata packages with
various content. A metadata package is a DHIS2-compliant JSON document
which describes a set of metadata objects.

To retrieve an index over available metadata packages you can issue a
GET request to the *metadataRepo* resource:

    GET /api/synchronization/metadataRepo

A metadata package entry contains information about the package and a
URL to the relevant package. An index could look like this:

```json
{
  "packages": [
    {
      "id": "sierre-leone-demo",
      "name": "Sierra Leone demo",
      "description": "Sierra Leone demo database",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/sierra-leone-demo/metadata.json"
    },
    {
      "id": "trainingland-org-units",
      "name": "Trainingland organisation units",
      "description": "Trainingland organisation units with four levels",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
    }
  ]
}
```

A client can follow the URLs and install a metadata package through a
POST request with content type *text/plain* with the metadata package
URL as the payload to the *metadataPull* resource:

    POST /api/synchronization/metadataPull

An example curl command looks like this:

```bash
curl "localhost:8080/api/synchronization/metadataPull" -X POST
  -d "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
  -H "Content-Type:text/plain" -u admin:district
```

## Reference to created by user { #reference-to-created-by-user } 

Each object created in DHIS2 will have a property named `user` which is linked to `User` who created the object.

From version 2.36 we have changed the name of this property to `createdBy` to avoid confusion.

However, in order to keep the backwards compability, the legacy `user` property is still included in the payload and works normally as before.

```json
{
  "createdBy": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  },
  "user": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  }
}
```

## Metadata proposal workflow { #webapi_metadata_proposal_workflow }

The metadata proposal workflow endpoint allows for a workflow of proposing and accepting changes to metadata.

```
/api/metadata/proposals
```

### Propose a metadata change { #webapi_metadata_proposal_propose }

A proposal always targets a single metadata object using:

    POST /api/metadata/proposals

Depending on the payload the proposal could:

* Add a new metadata object.
* Update an existing metadata object references by ID.
* Remove an existing metadata object referenced by ID.

To propose adding a new metadata object send a JSON payload like the following:

```json
{
  "type": "ADD",
  "target": "ORGANISATION_UNIT",
  "change": {"name":"My Unit", "shortName":"MyOU", "openingDate": "2020-01-01"}
}
```
The `change` property contains the same JSON object that could directly be posted to the corresponding endpoint to create the object.

To propose updating an existing metadata object send a JSON payload like in the below example:

```json
{
  "type": "UPDATE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>",
  "change": [
    {"op": "replace", "path": "/name", "value": "New name"}
  ]
}
```
The `targetId` refers to the object by its ID which should be updated. The `change` property here contains a JSON patch payload. This is the same
patch payload that could be posted to the corresponding endpoint to directly apply the update.

To propose the removal of an existing object send a payload like in the last example:

```json
{
  "type": "REMOVE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>"
}
```
The `targetId` refers to the object  by its ID which should be removed. A free text `comment` can be added to any type of comment.

Only `target` type `ORGANISATION_UNIT` is supported currently.

### Accept a metadata change proposal { #webapi_metadata_proposal_accept }
To accept an open proposal use `POST` on the proposal resource

    POST /api/metadata/proposals/<uid>

When successful the status of the proposal changes to status `ACCEPTED`. Once accepted the proposal can no longer be rejected.

Should a proposal fail to apply it changes to status `NEEDS_UPDATE`. The `reason` field contains a summary of the failures when this information is 
available.

### Oppose a metadata change proposal { #webapi_metadata_proposal_oppose }
If a proposal isn't quite right and needs adjustment this can be indicated by opposing the proposal by sending a `PATCH` for the proposal resource

    PATCH /api/metadata/proposals/<uid>

Optionally a plain text body can be added to this to give a `reason` why the proposal got opposed.

A opposed proposal must be in state `PROPOSED` and will change to state `NEEDS_UPDATE`.

### Adjust a metadata change proposal { #webapi_metadata_proposal_adjust }
A proposal in state `NEEDS_UPDATE` needs to be adjusted before it can be accepted. To adjust the proposal a `PUT` request is made for the proposal's 
resource

    PUT /api/metadata/proposals/<uid>

Such an adjustment can either be made without a body or with a JSON body containing an object with the updated `change` and `targetId` for the 
adjustment:

```json
{
  "targetId": "<id>",
  "change": ...
}
```
The JSON type of the `change` value depends on the proposal `type` analogous to when a proposal is initially made.

### Reject a metadata change proposal { #webapi_metadata_proposal_reject }
To reject an open proposal use `DELETE` on the proposal resource

    DELETE /api/metadata/proposals/<uid>

This changes the status of the proposal conclusively to `REJECTED`. No further changes can be made to this proposal. It is kept as a documentation of the events.

### List metadata change proposals { #webapi_metadata_proposal_list }
All proposals can be listed:

    GET /api/metadata/proposals/

The result list can be filtered using the `filter` parameter.
For example, to list only accepted proposals use:

    GET /api/metadata/proposals?filter=status:eq:ACCEPTED

Similarly to only show open proposals use:

    GET /api/metadata/proposals?filter=status:eq:PROPOSED

Filters can also be applied to any field except `change`. Supported filter operators are those described in the Gist Metadata API. This also includes property transformers described for Gist API.

List of available fields are:

| Champ       | Description |
| ----------- | -------------------------------------------------------------- |
| identifiant          | unique identifier of the proposal |
| type        | `ADD` a new object, `UPDATE` an existing object, `REMOVE` an existing object |
| statut      | `PROPOSED` (open proposal), `ACCEPTED` (successful), `NEEDS_UPDATE` (accepting caused error or opposed), `REJECTED` |
| target      | type of metadata object to add/update/remove; currently only `ORGANISATION_UNIT` |
| targetId    | UID of the updated or removed object, not defined for `ADD` |
| createdBy (créé par)   | the user that created the proposal |
| créé     | the date time when the proposal was created |
| finalisedBy | the user that accepted or rejected the proposal |
| finalised   | the date time when the proposal changed to a conclusive state of either accepted or rejected |
| commentaire     | optional plain text comment given for the initial proposal |
| raison      | optional plain text given when the proposal was opposed or the errors occurring when accepting a proposal failed | 
| change      | JSON object for `ADD` proposal, JSON array for `UPDATE` proposal, nothing for `REMOVE` proposal |

### Viewing metadata change proposals { #webapi_metadata_proposal_show }
Individual change proposals can be viewed using 

    GET /api/metadata/proposals/<uid>

The `fields` parameter can be used to narrow the fields included for the shown object. For example:

    GET /api/metadata/proposals/<uid>?fields=id,type,status,change


# Métadonnées Gist API { #gist_api } 
<!--DHIS2-SECTION-ID:gist_api-->

L'API Gist des métadonnées est une API JSON RESTful en lecture uniquement qui permet de récupérer et de parcourir 
des métadonnées. Les éléments de cette API contiennent la gist du même élément dans l'API Métadonnées.

L'API est spécifiquement conçue pour éviter :

* Les charges utiles des réponses volumineuses en raison de l'inclusion d'objets partiels imbriqués
  imbriqués.
* Traitement des demandes en mémoire, à forte intensité de ressources 
  (par exemple, le filtrage en mémoire ou la navigation dans le graphe d'objets).
* _n + 1_ requêtes de base de données à la suite de la navigation dans le graphe d'objets lors de la restitution de 
  la réponse.

## Comparaison avec l'API des métadonnées { #gist_vs_metadata_api } 
<!--DHIS2-SECTION-ID:gist_vs_metadata_api-->

L'API standard des métadonnées est une API flexible et puissante, conçue pour répondre à 
tous les cas d'utilisation. 
L'inconvénient est que toutes les fonctionnalités et combinaisons ne peuvent pas être mises à l'échelle tout en 
conservant de bonnes performances en présence d'un grand nombre d'éléments. 
En particulier, les listes d'éléments où chaque élément possède une propriété qui est une 
grande collection d'objets complexes se sont avérées problématiques car elles font 
rapidement référence à une grande partie du graphe d'objets entier.

L'API `/gist` a été ajoutée pour fournir une API de métadonnées où la mise à l'échelle est 
notre première priorité. L'inconvénient est qu'il y a des limites plus distinctes à ce qui est 
techniquement raisonnable, ce qui signifie que toutes les fonctionnalités de l'API standard 
de métadonnées n'existent pas pour l'API Gist.

L'API Gist utilise une stratégie de division et de conquête pour éviter les réponses avec de grands 
graphes d'objets partiels. Au lieu d'inclure des objets ou des listes imbriqués, elle fournit
un URI de point de terminaison `/gist` où cet objet ou cette liste peut être visualisé de manière isolée.

**L'API `/gist` se réfère aux données imbriquées en utilisant les URI plutôt que de les inclure.** 
Cela signifie que si un client est intéressé par ces informations imbriquées, il faudra plus de 
requêtes, mais chacune d'entre elles reste raisonnablement petite et s'adaptera 
bien dans le contexte d'un grand nombre d'éléments potentiels.

Les différences connues :

* les éléments n'incluent que les champs des objets identifiables référencés si ceux-ci n'ont 
  pas de point de terminaison propre 
* ils n'incluent jamais directement les collections d'objets identifiables 
* les éléments par défaut n'incluent pas tous les champs disponibles, mais un sous-ensemble qui dépend 
  du contexte et des paramètres 
* les listes ne peuvent pas être utilisées sans pagination (il n'y a donc pas de paramètre `pagination`) 
* les champs avec les collections ne sont pas paginés en utilisant le transformateur `pagination` mais à travers 
  un point de terminaison API paginé pour la propriété particulière de la collection 
* les éléments d'une liste, la taille d'une propriété de collection ou le résultat 
  toujours en compte le partage d'objets (l'ensemble des éléments pris en compte est toujours l'ensemble 
  visible par l'utilisateur)
* Gist propose les transformateurs de champs de collection  `membre(<id>)` et  `non-membre(<id>)`
* Gist propose un filtre de vérification d'accès de type `peutLire` et `peuModifier` au lieu de filtrer 
  selon la propriété `accès`
* La Gist propose d'utiliser les UID des attributs comme noms de champs et de propriétés de filtrage pour permettre 
  l'établissement de listes ou le filtrage en fonction de valeurs d'attributs personnalisées
* Gist propose le regroupement de filtres

Les limites connues :

* par défaut, seuls les champs persistants sont inclus ; une poignée de champs spéciaux 
  non persistants (champs synthétiques) peuvent être ajoutés explicitement ; d'autres 
  les champs non persistants peuvent être extraits à l'aide de la transformation `de`
* les filtres ne peuvent être appliqués qu'aux champs persistants
* les commandes ne peuvent être appliquées qu'aux champs persistants
* les filtres de jeton ne sont pas disponibles
* l'ordre est toujours sensible à la casse
* Le transformateur `pluck` limité aux propriétés de texte
* Les champs contenant des collections d'éléments simples (non identifiables) ne peuvent pas toujours 
  être inclus en fonction de la manière dont ils sont stockés

Lorsque cela est possible, l'utilisation de l'API `/gist` doit être considérée comme la meilleure façon 
d'obtenir des informations sur les métadonnées.


## Points de terminaison { #gist_endpoints } 
<!--DHIS2-SECTION-ID:gist_Points de terminaison-->

L'API `/gist` a 3 types de points de terminaison :

* <code>/api/&lt;object-type><b>/gist </b></code>: liste paginée de tous les objets connus et visibles du type (implicite `auto=S`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;<b>/gist</b></code> : affichage d'un seul objet par identifiant (implicite `auto=L`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;/&lt;field-name&gt;<b>/gist</b></code> : liste paginée de tous les éléments connus et visibles dans la collection du champ de l'objet propriétaire (implicite `auto=M` ; dans le cas d'un champ simple, juste la valeur du champ).

Ces points de terminaison correspondent aux points de terminaison de l'API standard de métadonnées sans 
le suffixe `/gist` et partagent la majorité des paramètres et de leurs options avec 
cette API.


## Données de navigation { #gist_browse } 
<!--DHIS2-SECTION-ID:gist_browse-->

Puisque l'API `/gist` évite les structures de données profondément intégrées dans la réponse, les 
détails des objets complexes ou des listes d'objets référencés sont plutôt fournis 
sous la forme d'un URI vers le point de terminaison gist qui renvoie uniquement l'objet complexe ou 
la liste d'objets. Ces URI sont fournies par le champ `pointsdeterminaisonsdel'api` d'un élément qui est 
automatiquement ajouté à un élément lorsque de telles références existent. 
La propriété item elle-même peut contenir un résultat de transformation sur l'objet 
ou la collection tel que sa taille, sa contenance, sa non contenance, son (ses) identifiant(s) 
ou une propriété extraite telle que son nom.

Pour parcourir manuellement les données, il peut être pratique d'utiliser le paramètre `absoluteUrls=true`. 
Les liens entre les parties de la liste peuvent maintenant être suivis directement dans les navigateurs qui 
affichent les réponses JSON.


## Paramètres { #gist_parameters } 
<!--DHIS2-SECTION-ID:gist_paramètres-->

Tous les points de terminaison de l'API `/gist` acceptent le même ensemble de paramètres.
Les paramètres et leurs options qui n'ont pas de sens dans le contexte du point de terminaison sont 
ignorés.


### Aperçu { #overview } 
Les paramètres par ordre alphabétique :

| Paramètre      | Options               |  Par défaut     | Description          |
| -------------- | --------------------- | ------------ | ---------------------|
| `Urls absolus` | `vrai` or `faux`     | `faux`      | `vrai` utilise les chemins relatifs dans les liens, `faux` utilise les URL absolues dans les liens |
| `automatique`         | `XS`, `S`, `M`, `L`, `XL` | (en fonction du contexte) | étendue des champs sélectionnés par `*` le sélecteur de champ  |
| `champs`       | (en fonction du point de terminaison) | `*`          | liste de champs ou de préréglages séparés par des virgules à inclure |
| `filtre`       | `<field>:<operator>` ou `<field>:<operator>:<value>` |   | liste de filtres de champs de requête séparés par des virgules (peut être utilisée plus d'une fois) |
| `sans titre`     | `vrai` or `faux`     | `faux`      | `true` skip wrapping result in a pager (ignores `total`), `false` use a pager wrapper object around the result list |
| `inversé`      | `vrai` or `faux`     | `faux`      | La valeur `vrai` renvoie les éléments **pas** dans la liste, la valeur `faux` renvoie les éléments dans la liste. |
| `locale`       |                       | (langue configurée du compte utilisateur) | remplacement de la langue de traduction |
| `ordre`        | `<field>` or  `<field>:asc` or `<field>:desc` | `:asc` | comma separated list of query order fields (can be used more than once) |
| `page`         | 1-n                   | 1            | numéro de page |
| `taille de la page`     | 1-1000                | 50           | nombre d'éléments sur une page |
| `jonction de racines` | `ET` or `OU`         | `ET`        | combinaison logique de `filtres`, `ET`= tous doivent correspondre, `OU`= au moins un doit correspondre |
| `total`        | `vrai` or `faux`     | `faux`      | `vrai` ajoute le nombre total de correspondances à la pagination, `faux` ne compte pas le nombre total de correspondances |
| `traduire`    | `vrai` or `faux`     | `vrai`       | `vrai` traduit toutes les propriétés traduisibles, `faux` saute la traduction des propriétés traduisibles (pas d'effet sur les noms d'affichage synthétiques) |


### Le paramètre `absoluteUrls` { #gist_parameters_absoluteUrls } 
<!--DHIS2-SECTION-ID:gist_les paramètres_absoluteUrls-->

Par défaut, les URIs dans les `points de terminaison api`, `href` et les membres `précedent` et `suivant` de la`pagination` 
sont relatifs, et commencent par le chemin `/<object-type>/`.

Les URI peuvent être changés en URL absolues en utilisant le paramètre `absoluteUrls`.

Par exemple, `/api/users/rWLrZL8rP3K/gist?fields=id,href` renvoie :

```json
{
  "id": "rWLrZL8rP3K",
  "href": "/users/rWLrZL8rP3K/gist"
}
```

tandis que `/api/users/rWLrZL8rP3K/gist?fields=id,href&absoluteUrls=true` 
renvoie :

```json
{
  "id": "rWLrZL8rP3K",
  "href": "http://localhost:8080/api/users/rWLrZL8rP3K/gist?absoluteUrls=true"
}
```

Comme le montre l'exemple, le paramètre `absoluteUrls` est également transmis ou reporté 
dans les URLs incluses, ce qui permet de parcourir les réponses en suivant les 
URLs fournies.


### Le Paramètre `auto` { #the-auto-parameter } 
Chaque point d'accès définit implicitement une valeur par défaut pour l'étendue des champs correspondant 
au sélecteur de champs`*` / `:tout` :

* `/api/<object-type>/gist` : implique que `auto=S`
* `/api/<object-type>/<object-id>/gist`: implique que `auto=L`
* `/api/<object-type>/<object-id>/<field-name>/gist`: implique que `auto=M`

Le paramètre `auto` est utilisé pour surcharger manuellement la valeur par défaut afin que les éléments 
de la liste incluent plus ou moins de champs. Ce paramètre agit à nouveau comme une valeur par défaut qui peut 
être modifiée pour chaque champ à l'aide d'une transformation explicite.

Les options possibles pour `auto` sont (" les tailles de t-shirt ") :

* `XS` : inclut uniquement les identifiants et les propriétés textuelles
* `S` : exclut les propriétés complexes (objets), les collections sont uniquement liées (non comptabilisées)
* `M` : complexe inclus en tant qu'URL de référence, les références et les collections en tant qu'URL de comptage et de référence
* `L` : comme `M` mais les références et les collections sont incluses en tant qu'identifiants (OBS ! non consolidé en taille)
* `XL` : comme `L` mais les références et les collections sont incluses en tant qu'objets de l'identifiant : `{ "id" : <id>}`

Par exemple, `/api/users/gist` listerait les éléments avec les champs `identifiant`, `nom`, 
`prénom`, `numéro de téléphone`, `email`, `dernière mise à jour` alors que 
`/api/users/gist?auto=XS` ne liste que l' `identifiant`, le `nom`,
le `prénom`, le `numéro de téléphone`, l'`email`. L'utilisation de `/api/users/gist?auto=L` inclurait également `unités d'organisation`, `unités d'organisation de visualisation des données`, 
`Unités d'organisation de recherche d'instances d'entités suivis` et `groupes d'utilisateurs`, chacun avec la liste des identifiants des
membres des listes/ensembles.


### Le paramètre `champs` { #gist_parameters_fields } 
<!--DHIS2-SECTION-ID:gist_les paramètres_champs-->

Spécifie la liste des champs à inclure pour chaque élément de la liste.

Les champs sont inclus dans les résultats des objets JSON pour un élément dans l'ordre indiqué. 
Un preset dans la liste des champs est étendu aux champs qu'il contient en fonction de la 
position qu'il occupe dans la liste `fields`. 
Les champs de la présélection sont classés de simple à complexe.

Si aucun paramètre `fields` n'est fourni, `fields=*` est pris en compte.
Notez que les champs du `*`preset dépendent également du paramètre `auto`.

Pour supprimer un champ, utilisez `!<name>` ou `-<name>` dans la liste des champs.
Par exemple, pour supprimer les groupes d'utilisateurs d'un utilisateur, utilisez :

    /api/users/gist?fields=*,!groupes d'utilisateurs

Le même principe peut être utilisé pour spécifier le transformateur à utiliser pour un 
champ. Par exemple, pour inclure les identifiants des groupes d'utilisateurs de l'utilisateur, utilisez :

    /api/users/gist?fields=*,groupes d'utilisateurs::identifiants

Le paramètre `champs` permet de lister les champs des objets imbriqués. 
Par exemple, pour ajouter `références de l'utilisateur` avec `identifiant` et `nom` d'un utilisateur, utilisez :

    /api/users/gist?fields=*,références de l'utilisateur[identifiant,Nom d'utilisateur]

Cela crée des éléments du genre :

```json
{
  ...
  "références de l'utilisateur": {
    "identifiant": "Z9oOHPi3FHB",
    "Nom d'utilisateur": "invité"
  }
}
```

Lors de l'inclusion de champs imbriqués de collections, le champ imbriqué doit être une 
propriété textuelle.

Par exemple pour inclure tous les `nom`s des `groupes d'utilisateurs` d'un utilisateur par :

    /api/users/gist?fields=*,groupes d'utilisateurs[nom]

La liste des `groupes d'utilisateurs` est la suivante:

```json
{
  "groupes d'utilisateurs ": {
    "nom": [
      "_PROGRAMME_Programme pour les patients hospitalisés",
      "_PROGRAMME_Programme TB",
      "_ENSEMBLE DE DONNÉES_Superutilisateur",
      "_PROGRAMME_Superutilisateur",
      "_ENSEMBLE DE DONNÉES_Agent de saisie des données",
      "_ENSEMBLE DE DONNÉES_Agent M et E"
    ]
  }
}
```
Ce qui précède est fonctionnellement identique à :

    /api/users/gist?fields=*,groupe d'utilisateurs::pluck( nom)~renommer(groupe d'utilisateurs.nom)

Lorsque l'on demande un seul champ, comme `/api/users/gist?fields=nom`, la réponse est une liste (toujours paginée) de valeurs simples :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50
  },
  "utilisateurs": [
    "Kamara",
    "Wakiki",
    "Nana",
    "Malai",
    ...
  ]
}
```

Lorsque l'on demande un champ unique de l'objet d'un propriétaire spécifique qui a une valeur simple 
(sans collection), comme par exemple 
`/api/users/rWLrZL8rP3K/gist fields=surname`, la réponse comprend uniquement la valeur 
JSON simple:

```json
"Wakiki"
```

Pour plus de détails sur les préréglages de champs, voir la section [Champs](#gist_fields).

### Le paramètre `filtre` { #gist_parameters_filter } 
<!--DHIS2-SECTION-ID:gist_paramètres_filtre-->

Pour filtrer la liste des éléments renvoyés, ajoutez un ou plusieurs paramètres `filtre`.

Plusieurs filtres peuvent être spécifiés sous la forme d'une liste séparée par des virgules d'un seul paramètre 
ou comme de multiples paramètres `filtre`, chacun avec un seul `filtre`.

Il existe deux types de filtres :

* unitaire: `<field>:<operator>`
* binaire: `<field>:<operator>:<value>`

Un champ peut être : 

* un champ persistant du type d'élément énuméré
* un champ maintenu d'un objet directement référencé (relation 1:1)
* l'UID d'un attribut

Les opérateurs unitaires disponibles sont les suivants :

| Opérateur unitaire | Description                                                 |
| -------- | ----------------------------------------------------------------- |
| `nul`   | le champ est _nul_ (non défini)                                       |
| `!nul`  | le champ est _non nul_ (défini)                                     |
| `vide`  | Le champ est une collection ou une chaîne _vide_                           |
| `!vide` | le champ est une collection ou une chaîne de caractères _non vide_                       |

Les opérateurs binaires disponibles sont les suivants :

| Opérateur binaire   | Description                                              |
| ----------------- | -------------------------------------------------------- |
| `eq`              | champ _égal_ valeur                                     |
| `ieq`             | champ _égal_ valeur (insensible à la casse)                  |
| `!eq`, `neq`, `ne`| champ _non égal_ valeur                               |
| `lt`              | champ _inférieur à_ valeur                               |
| `le`, `lte`       | champ _inférieur ou égal à_ valeur                   |
| `gt`              | champ _supérieur à_ valeur                            |
| `ge`, `gte`       | champ _supérieur ou égal à_ valeur                |
| `in`              | le champ est une collection et la valeur est un élément _contenu dans_ la collection |
| `!in`             | le champ est une collection et la valeur est un élément _non contenu dans_ la collection |

Si la `<value>` d'un filtre `in` ou `!in` est une liste, il est donné sous la forme suivante
`[valeur1,valeur2,...]`, par exemple: `groupes d'utilisateurs:dans:[fbfJHSPpUQD,cYeuwXTCPkU]`.

Toute comparaison `>`, `>=`, `<` `<=`, `==` ou `!=` appliquée à un champ de collection 
avec une valeur numérique comparera la taille de la collection à la valeur, par 
exemple : `groupes d'utilisateurs:gt:0`.

Toute comparaison `>`, `>=`, `<` `<=`, `==` ou `!=` appliquée à un champ de texte 
avec une valeur numérique entière comparera la longueur du texte à la valeur, par 
exemple : `nom:eq:4` (nom a une longueur de 4).


Les opérateurs de recherche de motifs binaires disponibles sont les suivants :

| Opérateur binaire                   | Description                              |
| --------------------------------- | ---------------------------------------- |
| `like`, `ilike`                   | champ _contient_ `<value>` ou champ _correspond_ au motif `<value>` (lorsque les caractères génériques `*` ou `?` sont présents dans la valeur) |
| `!like`, `!ilike`                 | le champ ne _contient pas_ `<value>` ou le champ ne _correspond pas_ au motif `<value>` (lorsque les caractères génériques `*` ou `?` sont présents dans la valeur) |
| `$like`, `$ilike`, `démarreAvec`   | le champ _commence avec_ `<value>`            |
| `!$like`, `!$ilike`, `!démarreAvec`| le champ ne_commence pas avec_ `<value>`    |
| `like$`, `ilike$`, `se termine avec`     | le champ _se termine par_ `<value>`              |
| `!like$`, `!ilike$`, `!se termine avec`  | le champ ne_se termine pas par_ `<value>`      |

Les opérateurs `like` et `!like` peuvent être utilisés soit en fournissant un terme de recherche, 
et dans ce cas la correspondance est toute valeur où le terme apparaît à tout endroit, soit 
en fournissant le motif de recherche en utilisant `*` comme _nombre quelconque de caractères_ 
et `?` comme _caractère unique_.

Tous les opérateurs de recherche de motifs nommés `like` sont sensibles à la casse. Tous les autres 
sont insensibles à la casse. 

Notez que les filtres sur les valeurs d'attributs utilisent une comparaison basée sur le texte, ce qui signifie que 
tous les filtres textuels sont pris en charge.

Par exemple, pour ne répertorier que les organisations de deuxième niveau, utilisez

    /api/organisationUnits/gist?filter=level:eq:2

De même, lorsqu'il s'agit de lister les `enfants` d'une unité d'organisation particulière, la 
collection peut être filtrée. Pour ne lister que les enfants qui sont connectés à
à un programme, on peut utiliser:

    /api/organisationUnits/rZxk3S0qN63/children/gist?filter=programs:gt:0

Opérateurs binaires pour le filtrage basé sur l'accès (le partage) :

| Opérateur binaire   | Description                                              |
| ----------------- | -------------------------------------------------------- |
| `peutLire`         | L'utilisateur `<value>` de métadonnées a t'il le droit de consulter l'objet |
| `peutModifier`        | L'utilisateur `<value>` de métadonnées a t-il le droit de modifier l'objet ? |
| `peut Lire les données`     | L'utilisateur `<value>` des données a t'il le droit de consulter l'objet    |
| `peutModifier les données`    | L'utilisateur `<value>` des données a t-il le droit de modifier l'objet ?   |
| `peutAccéder`       | L'utilisateur a t'il la `<value0>` permission `<value1>` d'accéder à l'objet   |

Lorsque l'identifiant de l'utilisateur `<value>` est omis, la vérification est effectuée pour 
l'utilisateur actuellement connecté. De même, si `<value0>` est omis pour le filtre `peutAccéder`, 
la vérification est effectuée pour l'utilisateur actuellement connecté.

Lorsqu'il est appliqué à une propriété de valeur simple, ici `code`, le filtre limite la réponse à 
ces  éléments de données (propriétaire de l'objet) que l'utilisateur peut lire/modifier :

    /api/dataElements/gist?filter=code:canWrite:OYLGMiazHtW

Lorsqu'il est appliqué à une propriété de référence, ici `combinaison de catégories`, le filtre limite la réponse 
à ces éléments de données ayant une combinaison de catégories que l'utilisateur peut lire/modifier:

    /api/dataElements/gist?filter=categoryCombo:canWrite:OYLGMiazHtW

Lorsqu'il est appliqué à une propriété de collection de référence, ici `groupe d'éléments de données`, le 
filtre limite la réponse à ces éléments de données pour lesquels un groupe d'éléments de données existe dans la 
propriété de collection et que l'utilisateur peut lire/modifier :

    /api/dataElements/gist?filter=dataElementGroups:canWrite:OYLGMiazHtW

La fonction `peutAccéder` demande deux arguments, le premier est l'identifiant de l'utilisateur, le second le modèle d'accès,
par exemple, pour vérifier l'accès en lecture et en modification des métadonnées, le motif est `rw%` :

    /api/dataElements/gist?filter=code:canAccess:[OYLGMiazHtW,rw%]


En outre, les filtres peuvent être regroupés pour permettre de combiner les filtres sélectionnés avec 
un OU logique lorsque le combinateur de filtre général est un ET logique, ou inversement 
avec un ET logique lorsque le combinateur général est un OU logique.

Pour les groupes, le modèle de filtre est élargi comme suit :

* unitaire: `<group>:<field>:<operator>`
* binaire: `<group>:<field>:<operator>:<value>`

Le groupe est un nombre arbitraire compris entre `0` et `9` (en cas d'omission, `0` est 
pris en compte). 

La meilleure façon d'expliquer ce comportement est de donner un petit exemple pour un 
type d'objet imaginaire avec une propriété `age` et `nom`.

    ?filter=1:age:eq:50&filter=2:name:eq:foo&filter=2:name:eq:bar

Le filtre ci-dessus a deux groupes `1` et `2`, et le groupe `2` a 2 membres. 
Ceci est équivalent au SQL (notez les `et` et `ou` ainsi que les 
accolades de regroupement) :

    e.age = 50 and (e.name = 'foo' or e.name = 'bar')

Maintenant, si le même `filtre` est utilisé en combinaison avec `rootJunction=OR`

    ?filter=1:age:eq:50&filter=2:name:eq:foo&filter=2:name:eq:bar&rootJunction=OR

l'effet serait équivalent plutôt au code SQL suivant :

    e.age = 50 or (e.name = 'foo' and e.name = 'bar')


### Le paramètre `sans titre` { #gist_parameters_headless } 
<!--DHIS2-SECTION-ID:gist_paramètres_sans titre-->

Les points d'extrémité qui renvoient une liste enveloppent par défaut les éléments dans une enveloppe contenant 
le `pager` et la liste, qui est nommée en fonction du type d'objet listé.

Par exemple, l'option `/api/organisationUnits/gist` renvoie :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50,
    "page suivante": "/organisationUnits/gist?page=2"
  },
  "unités d'organisation": [
    ...
  ]
}
```

Avec `headless=true`, la réponse à `/api/organisationUnits/gist?headless=true` 
est juste la partie de la liste `[...]` de l'exemple ci-dessus.


### Le Paramètre `inverse`  { #the-inverse-parameter } 
Le `inverse` peut être utilisé dans le contexte d'un champ de collection gist de la forme 
`/api/<object-type>/<object-id>/<field-name>/gist` pour ne pas lister tous les éléments qui
sont contenus dans la collection membre mais tous les éléments qui ne sont **pas** contenus 
dans la collection membre.

Par exemple, alors que 

    /api/organisationUnits/rZxk3S0qN63/children/gist

listerait toutes les unités d'organisation qui sont des enfants de `rZxk3S0qN63` l'inverse

    /api/organisationUnits/rZxk3S0qN63/children/gist?inverse=true

listerait toutes les unités d'organisation qui ne sont pas des enfants de `rZxk3S0qN63`. 
Cela pourrait par exemple être utilisé pour composer une liste de toutes les unités qui peuvent devenir des enfants 
d'une unité particulière.

Les filtres et les commandes s'appliquent normalement, c'est-à-dire qu'ils filtrent ou commandent les éléments
non contenus dans la collection de membres.


### Le paramètre `local`  { #gist_parameters_locale } 
<!--DHIS2-SECTION-ID:gist_paramètres_local-->
Le paramètre `locale` est généralement utilisé à des fins de test pour changer 
de manière ad-hoc la langue de traduction des noms d'affichage. 

Si elle n'est pas spécifiée, la langue de traduction est celle configurée dans les paramètres 
du compte de l'utilisateur.

Exemples:

    /api/organisationUnits/gist?locale=en
    /api/organisationUnits/gist?locale=en_GB

### Le paramètre `ordre`  { #gist_parameters_order } 
<!--DHIS2-SECTION-ID:gist_paramètres_ordre-->

Pour trier la liste des éléments, une ou plusieurs expressions d'ordre peuvent être données.

Une expression d'ordre est soit un simple nom de champ persistant, soit un nom de champ 
suivi de `:asc` (ordre croissant - par défaut) ou de `:desc` 
(ordre décroissant).

Par exemple, pour trier les unités d'organisation par ordre alphabétique de nom, utilisez :

    /api/organisationUnits/gist?order=name

L'ordre alphabétique inverse serait utilisé :

    /api/organisationUnits/gist?order=name:desc

Pour trier les unités d'organisation en premier lieu par niveau, puis par nom, utilisez :

    /api/organisationUnits/gist?order=level,name

On commencera par la (les) racine(s) au niveau 1. Pour commencer avec les unités foliaires, utilisez :

    /api/organisationUnits/gist?order=level:desc,name

Si aucun ordre n'est spécifié, la liste des résultats aura un ordre stable basé sur 
l'organisation interne des données.


### Le paramètre `page`  { #gist_parameters_page } 
<!--DHIS2-SECTION-ID:gist_paramètres_page-->

Fait référence à la page consultée dans la liste des pages, en commençant par `1` pour la première page.

Si le paramètre `page` n'est pas présent, il est égal à `page=1`.

La `page` est toujours en relation avec la `taille de la page`.
Si une `page` est indiquée au-delà du nombre de correspondances existantes, une liste d'éléments vide 
est renvoyée.


### Le paramètre `taille de la page` { #gist_parameters_pageSize } 
<!--DHIS2-SECTION-ID:gist_paramètres_taille de la page-->

Indique le nombre d'éléments d'une `page`. Le maximum est de 1000 éléments.

Si le paramètre `taille de la page` n'est pas présent, il est égal à `taille de la page=50`.


### Le paramètre `jonction de racines`  { #gist_parameters_rootJunction } 
<!--DHIS2-SECTION-ID:gist_paramètres_jonction de racines-->

Le paramètre `jonction de racines` peut être utilisé pour définir explicitement la jonction logique 
utilisée entre les filtres. Les possibilités sont les suivantes :

* `ET` : tous les filtres doivent correspondre à une donnée pour qu'elle soit incluse dans les résultats
* `OU` : l'un des filtres correspond à une donnée pour qu'elle soit incluse dans les résultats

La valeur par défaut est `ET`


### Le paramètre  `total` { #gist_parameters_total } 
<!--DHIS2-SECTION-ID:gist_paramètres_total-->

Par défaut, une requête gist ne comptera **pas** le nombre total de correspondances si celles-
ci dépassent la limite `taille de la page`. Au lieu de cela, nous acceptons les coûts supplémentaires 
que le comptage total implique.

Si l'on ne compte pas le nombre total de correspondances (`Total=faux`), la réponse `pager`
suppose qu'il y a une page `suivante` dans le cas où des éléments `taille de la page` ont été trouvés. Ceci
pourrait cependant s'avérer faux lorsque l'on navigue sur la page. De plus, le champ `total`
indiquant le nombre de correspondances totales n'est pas inclus dans le `pager`.

Par exemple, `/api/organisationUnits/gist` renvoie un `pager` :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50,
    "page suivante": "/organisationUnits/gist?page=2"
  }
}
```

Lorsque l'on compte le nombre total de correspondances (`Total=vrai`), la réponse `pager` 
contiendra le champ `total` avec le nombre réel de correspondances totales au prix 
d'une opération supplémentaire sur la base de données.

La réponse à `/api/organisationUnits/gist?total=true` renvoie maintenant ce `pager` :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50,
    "total": 1332,
    "page suivante": "/organisationUnits/gist?total=true&page=2",
    "nombre de pages": 27
  }
}
```


### Le paramètre `traduire`  { #gist_parameters_translate } 
<!--DHIS2-SECTION-ID:gist_paramètres_traduire-->

Les champs tels que `nom` ou `Nomcourt` peuvent être traduits (internationalisés).

Par défaut, tout champ traduisible ayant une traduction est renvoyé traduit
à condition que la langue de l'interface soit configurée par l'utilisateur qui demande la gist.

Pour retourner le champ non traduit, utilisez `traduit=faux`.

Par exemple, `/api/organisationUnits/gist` renvoie des éléments comme suit :

```json
{
  "nom": "Un nom traduit",
  ...
}
```

Alors que `/api/organisationUnits/gist?translate=false` renverrait des éléments comme :

```json
{
  "nom"
  "Nom du champ brut",
  ...
}
```

Notez que les champs synthétiques `Afficher le nom` et `Afficher le nom court` renvoient toujours
la valeur traduite, indépendamment du paramètre `traduire`.


## Champs  { #gist_fields } 
<!--DHIS2-SECTION-ID:gist_champs -->

Les champs inclus par défaut (sans le paramètre `champs`) correspondent à 
`champs=*`. 
Cela signifie que la liste des champs affichés dépend du type d'objet, du contexte du point d'extrémité 
ainsi que du paramètre `auto`. 

Notez que l'API `/gist` exclut toujours certains champs qui ne sont généralement pas 
importants pour les clients, comme par exemple les champs `traductions` ou `partage`. 
Ceux-ci peuvent être ajoutés explicitement.

Lorsqu'elle n'est pas explicitement fournie par un nom dans les paramètres `champs`, la liste 
des champs est calculée à partir d'un préréglage.
Un préréglage peut être utilisé dans la liste des champs comme un nom de champ. 
Il se développe en zéro, un ou plusieurs champs en fonction du type d'objet, du point 
d'extrémité utilisé et du sélecteur.


### Préréglages des champs { #field-presets } 

* `*` / `:tous`: les champs par défaut dépendent du contexte et du paramètre `auto`
* `:identifiable` : tous les champs maintenus de l'interface `Objet identifiable` 
* `:propriétaire` : tous les champs maintenus pour lesquels le type listé est le propriétaire
* `:nommable` : tous les champs maintenus de l'interface `ObjetNommable`
* `:maintenus` : littéralement tous les champs maintenus 


### Transformateurs de champ { #field-transformers } 
Un transformateur ou une transformation peut être appliqué à un champ en ajoutant 
l'un des indicateurs `::`, `~` ou `@` suivi de l'expression du transformateur.

Les expressions de transformateur disponibles sont les suivantes :

| Transformateur        | Type de résultat JSON    | Description                       |
| ------------------ | ------------------- | --------------------------------- |
| `renommer(<name>)`   | -                   | renomme le champ dans la réponse en `<name>` |
| `taille`             | `nombre`            | nombre d'éléments dans le champ de la collection |
| `estVide`          | `booléen`           | vide d'un champ de collecte   |
| `n'estPasvide`       | `booléen`           | non-emptiness of a collection field |
| `identifiants`              | `chaîne` or `[chaîne]` | Identifiant d'un objet ou identifiant d'éléments d'une collecte |
| `Identifiant - Objets`       | `[{ "identifiant": <id> }]`  | Identifiants des éléments de la collecte en tant qu'objet |
| `membre(<id>)`     | `booléen`           | a un membre avec `<id>` pour le champ de collecte |
| `pas-membre(<id>)` | `booléen`           | n'a pas de membre avec `<id>` pour le champ de collecte |
| `pluck(<field>)`   | `chaîne` or `[chaîne]` | extrait une seule propriété de texte de l'objet ou de chaque élément de la collecte |
| `de(<field>,...)`| dépend du type de grain | extrait un champ non pérenne d'un ou plusieurs champs pérennes |

Un champ peut recevoir à la fois le transformateur `renommer` et l'un des autres 
transformateurs, par exemple :

    /api/organisationUnits/gist?fields=*,children::size~rename(child-count)

Les éléments renvoyés n'ont plus de membre `enfants` mais un membre `nombre-d'enfants`
à la place. Notez que `renommer` affecte aussi le nom du membre de la référence de l'URI
donnée dans `l'apidespointsd'Extrémités`

La transformation `from` peut être utilisée avec un ou plusieurs champs pérennes en 
paramètre. Ceux-ci seront chargés à partir de la base de données, définis dans une instance 
de l'objet élément listé avant que la propriété non pérenne transformée avec 
`from` ne soit extraite de cette instance en appelant le getter. Cela permet 
d'extraire des champs dérivés tout en utilisant la même logique que celle utilisée dans l'API de métadonnées habituelle.

Par exemple, le nom d'un utilisateur (propriété non pérenne) `nom` est composé des 
propriétés pérennes `Prénom` et `nom`. Il peut être obtenu de cette manière :

    /api/users/gist?fields=id,name~from(firstName,surname)

Puisque le nom d'un utilisateur est un cas si commun, une auto-détection a été ajoutée pour 
que dans ce cas spécial, la transformation `from` soit ajoutée automatiquement à `nom`.
Nous sommes autorisés à utiliser ce qui suit, qui ajoute en interne la transformation 
`from` :

    /api/users/gist?fields=id,name

Bien que cela rende les propriétés non-perrennes accessibles en général, elles doivent toujours 
être incluses dans les `champs` de manière explicite. Pour un utilisateur, cela peut se 
faire de la manière suivante :

    /api/users/gist?fields=*,name


## Champs synthétiques { #gist_syntheticFields } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques-->

L'API `/gist` est étroitement liée aux propriétés qui existent dans la base de données.
Cela signifie que les propriétés qui ne sont pas stockées dans la base de données ne sont généralement pas 
disponibles.
L'exception à cette règle sont les propriétés "synthétiques" qui sont dynamiquement 
calculées sur la base d'une ou plusieurs propriétés stockées dans la base de données.

Les propriétés synthétiques sont disponibles pour tous les points d'extrémité où existent 
les propriétés maintenues nécessaires au calcul de la propriété synthétique.

A l'exception de la propriété `points d'extrémité de l'api` qui est automatiquement ajoutée si nécessaire 
toutes les autres propriétés synthétiques ne sont pas incluses par défaut et doivent faire 
l'objet d'une demande explicite dans la liste des `champs`. 


### Aperçu { #overview } 
Champs synthétiques par ordre alphabétique :

| Champ              | Description                                             |
| ------------------ | ------------------------------------------------------- |
| `points d'extrémité de l'api`     | contient des liens permettant de parcourir des objets ou des collections complexes imbriqués |
| `href`             | lien vers l'élément de la liste elle-même ( affichage d'un seul élément)         |
| `Nom d'affichage`      | `nom` traduit (toujours traduit)                   |
| `afficherNomCourt` | translated `displayName` (always translated)            |
| `accès`           | résumé sur la capacité de l'utilisateur actuel à lire/saisir/modifier les données |


### Le Champ `href` { #gist_syntheticFields_href } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques_href-->

Chaque élément d'une réponse `/gist` peut avoir un lien vers lui-même. Ce lien est donné 
dans la propriété `href`.

Pour ajouter le champ `href`, utilisez (par exemple) :

    /api/<object-type>/gist?fields=*,href

### Le champ `afficherNom` et `afficherNomCourt` { #gist_syntheticFields_displayName } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques_afficherNom-->

Par définition, le `afficherNom` est le `nom` traduit et le `afficherNomCourt` est le `nom court` traduit. 

Pour ajouter `afficherNom` ou `afficherNomCourt` à la liste, utilisez (par exemple) :

    /api/<object-type>/gist?fields=*,afficherNom
    /api/<object-type>/gist?fields=*,afficherNomCourt

Notez que par défaut, toutes les propriétés traduisibles comme `nom` et `nomCourt` 
seront également traduites. Lorsque `traduire=faux` est utilisé pour désactiver cela, 
`afficherNom` et `afficherNomCourt` restent traduits. 


### Le Champ `points d'extrémité de l'api`  { #gist_syntheticFields_apiEndpoints } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques_points d'extrémité de l'api-->

Cette propriété permet de parcourir des objets complexes ou des listes 
d'éléments qui sont inclus dans la réponse `/gist` sous la forme d'une valeur simple 
transformée comme un nombre d'éléments.

L'objet `points d'extrémité de l'api` aura un membre du même nom pour chaque membre 
de l'élément qui a été transformé en valeur simple.

Par exemple, 

    /api/users/gist?fields=id,userGroups::size,organisationUnits::size 

renvoie les éléments du formulaire :

```json
{
  "identifiant": "rWLrZL8rP3K",
  "groupes d'utilisateurs": 0,
  "unités d'organisation": 1,
  "points d'extrémité de l'api": {
    "unités d'organisation": "/utilisateurs/rWLrZL8rP3K/unités d'organisation/gist",
    "groupes d'utilisateurs": "/utilisateurs/rWLrZL8rP3K/groupes d'utilisateurs/gist"
  }
}
```

La liste des `groupes d'utilisateurs` et des `unités d'organisation` est incluse dans leur `taille`. 
Chacun a un membre correspondant dans `points d'extrémité de l'api` avec un chemin pour parcourir la
liste.

Les chemins peuvent être transformés en URL en utilisant le paramètre `Urls absolus`. 

    /api/users/gist?fields=id,userGroups::size,organisationUnits::size&absoluteUrls=true

renvoie les éléments du formulaire :

```json
{
  "identifiant": "rWLrZL8rP3K",
  "groupes d'utilisateurs": 0,
  "unités d'organisation": 1,
  "points d'extrémité de l'api": {
    "unités d'organisation":"http://{host}/api/users/rWLrZL8rP3K/organisationUnits/gist?absoluteUrls=true",
    "groupes d'utilisateurs": http://{host}/api/users/rWLrZL8rP3K/userGroups/gist?absoluteUrls=true"
  }
}
```

### Le Champ `accès` { #the-access-field } 
Le résumé `accès` est basé sur le `partage` et l'utilisateur actuel.
Cela signifie qu'il n'est applicable qu'aux objets ayant une propriété `partage`.

Par exemple, lors de l'établissement d'une liste d'éléments de données avec le champ `accès`

    /api/dataElements/gist?fields=*,access

les éléments de données renvoyés contiennent un membre `"accès"` comme ci-dessous :

```json
"accès": {
  "gérer": faux,
  "externaliser": faux,
  "modifier": faux,
  "lire": vrai,
  "mettre à jour": faux,
  "supprimer": faux
}
```

### Attributs comme Champs { #gist_attributeFields }
DHIS2 permet de créer et d'ajouter des attributs personnalisés aux objets de métadonnées. 
Leurs valeurs sont contenues dans la propriété `valeurs d'attributs` d'un objet de métadonnées 
sous la forme d'une carte dont la clé est l'UID de l'attribut.

Pour lister directement une ou plusieurs valeurs d'attributs spécifiques de cette carte comme s'il 
s'agissait de champs habituels de l'objet de métadonnées, l'UID de l'attribut peut être utilisé comme s'il 
s'agissait du nom d'un champ habituel.

Par exemple, pour inclure la valeur de l'attribut avec l'UID `Y1LUDU8sWBR` en tant que 
la propriété `unité de mesure` dans la liste, utilisez :

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(unit-of-measure)

Il en résulte des éléments de liste du type
```json
{
  "identifiant": "qrur9Dvnyt5",
  "nom": "Âge en années",
  "unité de mesure" : "années"
}
```

Par défaut, les valeurs sont récupérées au format JSON et extraites de la carte des 
valeurs d'attributs. Cela signifie que la liste contiendra le type JSON approprié pour
le type de valeur d'attribut. Cela implique un surcoût lié à la récupération de toutes 
les valeurs d'attributs. Pour isoler la valeur dans la base de données, la transformation `PLUCK` 
peut être utilisée.

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(unit-of-measure)~pluck

Le résultat sera le même, mais la valeur est désormais extraite sous forme de texte dans la 
base de données, ce qui transforme toute valeur JSON en une chaîne de caractères dans le résultat de la propriété. 

## Exemples { #gist_examples } 
<!--DHIS2-SECTION-ID:gist_exemples-->
Quelques exemples partant de simples listes et allant jusqu'à des cas d'utilisation très spécifiques. 

Il est préférable de toujours fournir une liste explicite de `champs` pour que cette section 
le fasse.

Liste des unités d'organisation avec leur identifiant et leur nom :

    /api/organisationUnits/gist?fields=id,name

Liste des unités d'organisation avec leur identifiant, leur nom et leur nombre total :

    /api/organisationUnits/gist?fields=id,name&total=true

Liste des utilisateurs avec l'identifiant et le nom d'utilisateur :

    /api/users/gist?fields=id,userCredentials.username

Liste des utilisateurs avec l'identifiant, le nom d'utilisateur et la date de la dernière connexion :

    /api/users/gist?fields=id,userCredentials[username,lastLogin]

Ne listez que les unités d'organisation au deuxième niveau avec l'identifiant, le nom et le niveau :

    /api/organisationUnits/gist?fields=id,name,level&filter=level:eq:2

Listez uniquement les unités d'organisation qui ont plus d'un enfant avec l'identifiant, le nom et 
le nombre d'enfants :

    /api/organisationUnits/gist?fields=id,name,children::size&filter=children:gt:1

Listez uniquement les unités d'organisation qui ne sont pas encore enfants d'une autre unité
`zFDYIgyGmXG` :

    /api/organisationUnits/zFDYIgyGmXG/children/gist?fields=id,name&inverse=true

Listez les utilisateurs et indiquez s'ils sont membres d'un groupe d'utilisateurs spécifique. 
`NTC8Gj7p8P` et nommer ce champ `est-membre` dans la réponse :

    /api/users/gist?fields=id,userCredentials.username,userGroups::member(NTC8GjJ7p8P)~rename(is-member)

Listez les liens vers tous les utilisateurs dans des pages de 10 éléments :

    /api/users/gist?fields=href&absoluteUrls&pageSize=10




# Données { #data }

## Valeurs des données { #webapi_data_values }

Cette section traite de l'envoi et de la lecture des données.

    /api/dataValueSets

### Envoi de données { #webapi_sending_data_values }

Pour envoyer des données, vous pouvez lancer une requête POST à la ressource suivante.

```
POST /api/dataValueSets
```

Un cas d'utilisation courant pour l'intégration des systèmes est la nécessité d'envoyer un ensemble de valeurs de données d'un système tiers vers DHIS. Dans cet exemple, nous utiliserons la démonstration DHIS2 sur `http://play.dhis2.org/demo`. Supposons que nous avons collecté des données basées sur les cas à l'aide d'un simple logiciel client installé sur des téléphones portables pour l'ensemble de données *Mortalité <5 ans* dans la communauté du *Ngelehun CHC* (dans la chefferie *Badjia*, district *Bo*) pour le mois de janvier 2014. Nous avons maintenant agrégé nos données dans un rapport statistique et nous voulons envoyer ces données à l'instance DHIS2. L'URL de base de l'API de démonstration est `http://play.dhis2.org/demo/api`. Les liens suivants sont associés à l'URL de base.


La ressource la plus appropriée pour notre objectif d'envoi de valeurs de données est `/api/dataValueSets`. Un ensemble de valeurs de données représente des données qui ont une relation, généralement parce qu'elles ont été saisies dans le même formulaire. Le format ressemble à ceci :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="dataSetID"
  completeDate="date" period="période" orgUnit="orgUnitID" attributOptionCombo="aocID">
  <dataValue dataElement="dataElementID"
    categoryOptionCombo="cocID" value="1" comment="comment1"/>
  <dataValue dataElement="dataElementID"
    categoryOptionCombo="cocID" value="2" comment="comment2"/>
  <dataValue dataElement="dataElementID"
    categoryOptionCombo="cocID" value="3" comment="comment3"/>
</dataValueSet>
```

JSON est pris en charge dans ce format :

```json
{
  "dataSet": "dataSetID",
  "completeDate": "date",
  "période": "période",
  "orgUnit": "orgUnitID",
  "attributeOptionCombo": "aocID",
  "valeurs de données": [
    {
      "dataElement": "dataElementID",
      "categoryOptionCombo": "cocID",
      "valeur": "1",
      "commentaire": "commentaire1"
    },
    {
      "dataElement": "dataElementID",
      "categoryOptionCombo": "cocID",
      "valeur": "2",
      "commentaire": "commentaire2"
    },
    {
      "dataElement": "dataElementID",
      "categoryOptionCombo": "cocID",
      "valeur": "3",
      "commentaire": "commentaire3"
    }
  ]
}
```

CSV est pris en charge dans ce format :

```csv
"élément de données", "période", "orgunit", "catoptcombo", "attroptcombo", "valeur", "strby", "lstupd", "cmt"
"dataElementID", "période", "orgUnitID", "cocID", "aocID", "1", "nom d'utilisateur", "2015-04-01", "comment1"
"dataElementID", "période", "orgUnitID", "cocID", "aocID", "2", "nom d'utilisateur", "2015-04-01", "comment2"
"dataElementID", "période", "orgUnitID", "cocID", "aocID", "3", "nom d'utilisateur", "2015-04-01", "comment3"
```

> **Remarque**
>
> Veuillez vous référer à la section date et période ci-dessus pour les formats d'heure.

À partir de l'exemple, nous l'importance d'identifier la période, l'ensemble de données, l'unité d'organisation (établissement) et les éléments de données qui nécessite des rapports.

Pour obtenir l'identifiant de l'ensemble de données, nous adressons une requête à la ressource `/api/dataSets`. De là, nous trouverons le lien vers l'ensemble de données *Mortalité < 5 ans* qui nous conduit à `/api/dataSets/pBOMPrpg1QX`.
La ressource de l'ensemble de données *Mortalité < 5 ans* fournit des liens vers les éléments de données qu'elle abrite. D'ici nous pouvons suivre ces liens et obtenir les identifiants des données éléments. Par souci de concision, nous allons déclarer des données pour seulement trois éléments de données : *Rougeole* avec l'identifiant `f7n9E0hX8qk`, *Dysenterie* avec l'identifiant `Ix2HsbDMLea` et *Choléra* avec l'identifiant `eY5ehpbEsB7`.

Il ne nous reste que l'identifiant de l'organisation unité. L'*ensemble de données* fournit un lien vers les unités d'organisation qui produisent des rapports dessus. Nous recherchons donc *Ngelehun CHC* et suivons le lien vers la représentation HTML dans `/api/organisationUnits/DiszpKrYNg8`, qui nous indique que l'identifiant de cette unité d'organisation est `DiszpKrYNg8`.

À partir de nos données basées sur les cas, nous supposons que nous avons 12 cas de rougeole, 14 cas de dysenterie et 16 cas de choléra. Nous avons maintenant assez d'informations pour pouvoir composer le message XML de l'ensemble de valeurs des données :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-02-03" period="201401" orgUnit="DiszpKrYNg8">
  <dataValue dataElement="f7n9E0hX8qk" value="12"/>
  <dataValue dataElement="Ix2HsbDMLea" value="14"/>
  <dataValue dataElement="eY5ehpbEsB7" value="16"/>
</dataValueSet>
```

Au format JSON :

```json
{
  "ensembleDeDonnées": "pBOMPrpg1QX",
  "date": "03/02/2014",
  "période": "201401",
  "unitéD'organisation": "DiszpKrYNg8",
  "valeursDeDonnées": [
    {
      "élémentDeDonnées": "f7n9E0hX8qk",
      "valeur": "1"
    },
    {
      "élémentDeDonnées": "Ix2HsbDMLea",
      "valeur": "2"
    },
    {
      "élémentDeDonnées": "eY5ehpbEsB7",
      "valeur": "3"
    }
  ]
}
```

Pour effectuer des tests fonctionnels, nous utiliserons l'outil _curl_ qui permet de transférer facilement des données à l'aide du protocole HTTP. Tout d'abord, nous sauvegardons le contenu XML de l'ensemble de données dans un fichier appelé `datavalueset.xml`. Dans le répertoire où se trouve ce fichier, nous invoquons ce qui suit à partir de la ligne de commande :

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

Pour envoyer du contenu JSON, vous devez définir l'en-tête "type de contenu" comme suit :

```bash
curl -d @datavalueset.json "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/json" -u admin:district
```

La commande enverra une requête à l'API Web de démonstration, définissez `application/xml` comme type de contenu et authentifiez-vous en utilisant `admin`/`district` comme nom d'utilisateur/mot de passe. Si tout se passe bien, le code d'état HTTP `200 OK` sera renvoyé. Vous pouvez vérifier la réception des données en ouvrant le module de saisie de données dans DHIS2 et en sélectionnant l'unité d'organisation, l'ensemble de données et la période utilisés dans cet exemple.

L'API suit la sémantique normale pour la gestion des erreurs et les codes d'état HTTP. Si vous fournissez un nom d'utilisateur ou un mot de passe invalide, `401 Non autorisé` est renvoyé. Si vous fournissez un type de contenu autre que `application/xml`, `415 Type de média non pris en charge` est renvoyé. Si le contenu XML n'est pas valide selon l'espace de noms DXF, `400 Mauvaise requête` est renvoyé. Si vous fournissez un identifiant invalide dans le contenu XML, `409 Conflit` est renvoyé avec un message descriptif.

### Envoi de données en masse { #webapi_sending_bulks_data_values }

L'exemple précédent nous a montré comment envoyer un ensemble de données associées qui partagent la même période et la même unité d’organisation. L'exemple suivant nous montrera comment envoyer de grandes quantités de données qui ne sont pas nécessairement associés.

Encore une fois, nous interagirons avec la ressource `/api/dataValueSets`. Cette fois nous n'allons pas spécifier les attributs `dataSet` et `completeDate`. De plus, nous allons spécifiez les attributs `period` et `orgUnit` comme éléments de données individuelles et non élément d’ensemble de données externes. Cela nous permettra d'envoyer des données pour différentes périodes et unités d'organisation :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0">
  <dataValue dataElement="f7n9E0hX8qk"
    period="201401" orgUnit="DiszpKrYNg8" value="12"/>
  <dataValue dataElement="f7n9E0hX8qk"
    period="201401" orgUnit="FNnj3jKGS7i" value="14"/>
  <dataValue dataElement="f7n9E0hX8qk"
    period="201402" orgUnit="DiszpKrYNg8" value="16"/>
  <dataValue dataElement="f7n9E0hX8qk"
    period="201402" orgUnit="Jkhdsf8sdf4" value="18"/>
</dataValueSet>
```

Au format JSON :

```json
{
  "dataValues": [
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201401",
      "orgUnit": "DiszpKrYNg8",
      "valeur": "12"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201401",
      "orgUnit": "FNnj3jKGS7i",
      "valeur": "14"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201402",
      "orgUnit": "DiszpKrYNg8",
      "valeur": "16"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201402",
      "orgUnit": "Jkhdsf8sdf4",
      "valeur": "18"
    }
  ]
}
```

Au format CSV :

```csv
"dataelement","period","orgunit","categoryoptioncombo","attributeoptioncombo","value"
"f7n9E0hX8qk","201401","DiszpKrYNg8","bRowv6yZOF2","bRowv6yZOF2","1"
"Ix2HsbDMLea","201401","DiszpKrYNg8","bRowv6yZOF2","bRowv6yZOF2","2"
"eY5ehpbEsB7","201401","DiszpKrYNg8","bRowv6yZOF2","bRowv6yZOF2","3"
```

Nous effectuons les tests en utilisant "curl" pour envoyer les données au format XML :

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

Notez que lorsque vous utilisez le format CSV, vous devez utiliser l'option de données binaires pour conserver le retour-à-la-ligne dans le fichier CSV :

```bash
curl --data-binary @datavalueset.csv "https://play.dhis2.org/demo/24/api/dataValueSets"
  -H "Content-Type:application/csv" -u admin:district
```

La ressource ensemble de valeurs de données fournit une réponse XML qui est utile lorsque vous voulez vérifier l'impact de votre requête. La première fois que nous envoyons la requête " ensemble de données " ci-dessus, le serveur répondra avec le résumé d'importation suivant :

```xml
<importSummary>
  <dataValueCount imported="2" updated="1" ignored="1"/>
  <dataSetComplete>faux</dataSetComplete>
</importSummary>
```

Ce message nous indique que 3 données ont été importées, 1 donnée a été mise à jour et 0 donnée a été ignorée. La seule mise à jour résulte de l'envoi de cette donnée dans l'exemple précédent. Une donnée sera ignorée si elle fait référence à un élément de données, une période, une unité d'organisation ou un ensemble de données qui n'existent pas. Dans notre cas, cette valeur unique ignorée est due au fait que la dernière donnée faisait référence à une unité d'organisation non valide. L'élément complet de l'ensemble de données affichera la date à laquelle l'ensemble de données a été achevé, ou " faux " si aucun attribut d'élément de données n'a été fourni.

### Paramètres d'importation { #webapi_data_values_import_parameters }

Le processus d'importation peut être personnalisé à l'aide d'un ensemble de paramètres d'importation :

Tableau : Paramètres d'importation

| Paramètre | Valeurs (par défaut en premier) | Description |
|---|---|---|
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | uide &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'élément de données à utiliser pour faire correspondre les données. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | uide &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'unité d'organisation à utiliser pour faire correspondre les données. |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | uide &#124; nom &#124; code &#124; attribut:ID | Propriété des objets de combinaisons d’options de catégorie et d’options d’attribut à utiliser pour faire correspondre les valeurs de données. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'objet d'ensemble de données à utiliser pour faire correspondre les données. |
| categoryIdScheme (Schéma de l'identifiant de catégorie) | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'objet de catégorie à utiliser pour faire correspondre les données (ADX uniquement). |
| categoryOptionIdScheme (Schéma de l'identifiant d'option de catégorie) | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'objet d'option catégorie à utiliser pour faire correspondre les données (ADX uniquement). |
| idScheme | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'un des objets ci-dessus s'ils ne sont pas spécifiés, à utiliser pour faire correspondre les données. |
| preheatCache | faux &#124; vrai | Indique s'il faut précharger les caches de métadonnées avant de commencer l'importation des données. Ceci permettra d'accélérer l'importation de grandes quantités de métadonnées. |
| dryRun | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| importStrategy (stratégie d'importation) | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipExistingCheck (ignorer les contrôles existants) | faux &#124; vrai | Ne contrôle pas les données existantes. Améliore les performances. À utiliser uniquement pour les bases de données vides ou lorsque les données à importer n'existent pas encore. |
| skipAudit (ignorer l'audit) | faux &#124; vrai | "Ignorer l'audit" signifie que les valeurs d'audit ne seront pas générées. Améliore les performances au détriment de la capacité à auditer les modifications. Nécessite l'autorité "F_SKIP_DATA_IMPORT_AUDIT". |
| async | faux &#124; vrai | Indique si l'importation doit être effectuée de manière asynchrone ou synchrone. La première option (asynchrone) est adapté aux importations très volumineuses car il garantit que la requête n’expire pas, bien qu’il entraîne une surcharge de performances. La deuxième (synchrone) est plus rapide mais nécessite que la connexion soit maintenue jusqu'à la fin du processus. |
| force | faux &#124; vrai | Indique si l'importation doit être forcée. L'importation de données peut être rejetée pour diverses raisons liées au verrouillage de l'ensemble des données, par exemple en raison de l'approbation, de la période de saisie des données, des jours d'expiration, etc. Pour passer outre ces verrouillages et forcer la saisie des données, il est possible d'utiliser l'importation de données en définissant force=true. Cependant, il faut être un \*superutilisateur\* pour que ce paramètre fonctionne. |

Tous les paramètres sont facultatifs et peuvent être fournis en tant que paramètres de requête dans l'URL de la requête comme ceci :

    /api/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=name
      &dryRun=true&importStrategy=CREER

Ils peuvent également être fournis en tant qu'attributs XML sur l'élément " ensemble de valeurs de données ", tel qu'indiqué ci-dessous. Les attributs XML remplacent les paramètres de la chaîne de requête.

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataElementIdScheme="code"
  orgUnitIdScheme="name" dryRun="true" importStrategy="CREATE">
</dataValueSet>
```

Notez que le paramètre `preheatCache` peut avoir un impact considérable sur les performances. Pour les petits fichiers d'importation, maintenir "faux" permettra de gagner en rapidité. Pour les gros fichiers d'importation qui contiennent un grand nombre d'éléments de données et d'unités d'organisation distincts, le définir sur "vrai" permettra de gagner en rapidité en termes d'ordre de grandeur.

#### Exigences en matière de valeur des données { #webapi_data_values_import_requirement }

L’importation de valeurs de données prend en charge un ensemble de types de valeurs. Chaque type de valeur a une exigence particulière. Le tableau suivant répertorie les cas extrêmes pour les types valeur.



Tableau : Exigences relatives au type de valeur

| Type de valeur | Exigences | Commentaire |
|---|---|---|
| BOOLÉEN | vrai &#124; C'est vrai &#124; VRAI &#124; faux &#124; Faux &#124; FAUX &#124; 1 &#124; 0 &#124; t &#124; f &#124; | Utilisé lorsque la valeur est booléenne, vraie ou fausse. Le service d'importation ne prête pas attention au fait que l'entrée commence par une lettre majuscule ou minuscule, ou qu'elle soit entièrement en lettres majuscules. |

#### Schémas d'identifiants { #webapi_data_values_identifier_schemes }

En ce qui concerne les schémas d'identifiants, les identifiants utilisés dans les messages XML utilisent par défaut les identifiants d'objets stables de DHIS2 appelés `UID`. Dans certaines situations d'interopérabilité, il se peut qu'un système externe détermine les identifiants des objets. Dans ce cas, nous pouvons utiliser la propriété `code` des unités d'organisation et d'autres objets pour définir des identifiants fixes. Lors de l'importation des valeurs de données, nous devons donc référencer la propriété "code" et non la propriété "identifiant" de ces objets de métadonnées. Les schémas d'identifiants peuvent être spécifiés dans le message XML ainsi que dans la requête en tant que paramètres de requête. Pour les spécifier dans la charge utile XML, vous pouvez procéder comme suit :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0"
  dataElementIdScheme="CODE" orgUnitIdScheme="UID" idScheme="CODE">
</dataValueSet>
```

Le tableau des paramètres ci-dessus explique comment les schémas d'identifiants peuvent être spécifiés comme paramètres de requête. Les règles suivantes déterminent l'ordre de priorité :

  - Les schémas d'identifiants définis dans la charge utile XML ou JSON ont priorité sur
    les schémas d'identifiants définis comme paramètres de requête URL.

  - Les schémas d'identifiants spécifiques tels que dataElementIdScheme ou
    orgUnitIdScheme ont priorité sur le idScheme général.

  - Si aucun schéma d'identifiants explicite n'est défini, le schéma d'identifiants par défaut est `code`
    pour le format ADX et `uid` pour tous les autres formats.

Les schémas d'identifiants suivants sont disponibles.

  - uid

  - code

  - nom

  - attribut (suivi de l'UID de l'attribut)

L'option d'attribut est spéciale et fait référence aux attributs de métadonnées qui ont été marqués comme *uniques*. En utilisant cette option, l'`attribut` doit être immédiatement suivi de l'identifiant de l'attribut, par exemple "attribut : DnrLSdo4hMl".

#### Importation de valeurs de données asynchrones { #webapi_data_values_async_import }

Les valeurs de données peuvent être envoyées et importées de manière asynchrone à travers un paramètre de requête `async` défini sur *vrai* :

    /api/dataValueSets?async=true

Cela lancera une tâche d'importation asynchrone dont vous pourrez surveiller l'état grâce à l'API de résumés des tâches. La réponse de l'API indique l'identifiant unique de la tâche, du type de tâche et de l'URL que vous pouvez utiliser pour surveiller l’état de l'importation. La réponse ressemblera à ceci :

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Initiated dataValueImport",
  "response": {
    "name": "dataValueImport",
    "id": "YR1UxOUXmzT",
    "created": "2018-08-20T14:17:28.429",
    "jobType": "DATAVALUE_IMPORT",
    "relativeNotifierEndpoint": "/api/system/tasks/DATAVALUE_IMPORT/YR1UxOUXmzT"
  }
}
```

Veuillez lire la section sur *l'état des tâches asynchrones* pour en savoir plus.

### Format des valeurs de données CSV { #webapi_data_values_csv }

La section suivante décrit le format CSV utilisé dans DHIS2. La première ligne est supposée être une ligne d'en-tête et sera ignorée lors de l'importation.



Tableau : format CSV de DHIS2

||||
|---|---|---|
| Colonne | Obligatoire | Description |
| Élément de données | Oui | Fait référence à l'ID par défaut, peut également être un nom et un code basés sur le schéma d'identifiants sélectionné |
| Période | Oui | Au format ISO |
| Unité d'organisation | Oui | Fait référence à l'ID par défaut, peut également être un nom et un code basés sur le schéma d'identifiants sélectionné |
| Combinaison d'options de catégorie | Non | Fait référence à l'identifiant |
| Combinaison d'options d'attribut | Non | Fait référence à l'ID (à partir de la version 2.16) |
| Valeur | Non | Valeur de données |
| Stocké par | Non | Fait référence au nom d'utilisateur de l'utilisateur qui a saisi la valeur |
| Dernière mise à jour | Non | Date au format ISO |
| Commentaire | Non | Commentaire en texte libre |
| Suivi | Non | vrai ou faux |

Ci-dessous un exemple de fichier CSV pouvant être importé dans DHIS2 :

```csv
"dataelement","period","orgunit","catoptcombo","attroptcombo","value","storedby","timestamp"
"DUSpd8Jq3M7","201202","gP6hn503KUX","Prlt0C1RF0s",,"7","bombali","2010-04-17"
"DUSpd8Jq3M7","201202","gP6hn503KUX","V6L425pT3A0",,"10","bombali","2010-04-17"
"DUSpd8Jq3M7","201202","OjTS752GbZE","V6L425pT3A0",,"9","bombali","2010-04-06"
```

### Génération d'un modèle d'ensemble de valeurs de données { #webapi_data_values_template }

Pour générer un modèle d'ensemble de valeurs de données pour un ensemble de données spécifique, vous pouvez utiliser la ressource `/api/dataSets/<id>/dataValueSet`. les formats de réponse XML et JSON sont pris en charge. Exemple:

    /api/dataSets/BfMAe6Itzgt/dataValueSet

Ci-dessous les paramètres que vous pouvez utiliser pour ajuster davantage la sortie :



Tableau : Paramètres de requête de valeurs de données

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| période | Non | La période d'utilisation sera incluse sans aucun contrôle. |
| orgUnit (Unité d'organisation) | Non | L'unité d'organisation à utiliser ; prend en charge plusieurs unités d'organisation ; l'identifiant et le code peuvent être utilisés. |
| commentaire | Non | Sur la prise en compte des commentaires, par défaut : Oui. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Non | Schéma d'unités d'organisation à utiliser ; prend en charge l'identifiant &#124; code. |
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | Non | Schéma d'élément de données à utiliser ; prend en charge l'identifiant &#124; code. |

### Lecture des valeurs de données { #webapi_reading_data_values }

Pour lire les valeurs de données, vous pouvez effectuer une requête GET à la ressource suivante.

```
GET /api/dataValueSets
```

Les valeurs de données peuvent être récupérées au format *XML*, *JSON*, *CSV* et *ADX*. Etant donné que nous voulons lire des données, nous utiliserons le verbe HTTP *GET*. Nous spécifierons également que notre intérêt pour la représentation des ressources XML en incluant un en-tête HTTP `Accepter` dans notre requête. Les paramètres de requête suivants sont acceptés :


Tableau : Paramètres de requête d'ensemble de valeurs de données

| Paramètre | Description |
|---|---|
| dataSet (ensemble de données) | Identifiant de l'ensemble de données. Peut être répété plusieurs fois. |
| dataElementGroup (groupe d'éléments de données) | Identifiant du groupe d'éléments de données. Peut être répété autant de fois que vous le voulez (pas pris en charge pour le format ADX). |
| période | Identifiant de période au format ISO. Peut être répété plusieurs fois. |
| date de début | Date de début pour la période des valeurs à exporter. |
| date de fin | Date de fin pour la période des valeurs à exporter. |
| orgUnit (Unité d'organisation) | Identifiant de l’unité d’organisation. Peut être répété plusieurs fois. |
| subordonnées | Permet de spécifier s'il faut inclure les unités d’organisation subordonnées dans la hiérarchie des unités d'organisation. |
| orgUnitGroup (groupe d'unités d'organisation) | Identifiant du groupe d’unités d’organisation. Peut être répété plusieurs fois. |
| attributeOptionCombo (combinaison d'options d'attribut) | Identifiant de la combinaison d’options d’attribut. Peut être répété plusieurs fois. |
| includeDeleted | Permet de spécifier s'il faut inclure les valeurs de données supprimées. |
| lastUpdated (dernière mise à jour) | Inclut uniquement les valeurs de données mises à jour depuis l'horodatage donné. |
| lastUpdatedDuration (durée de la dernière mise à jour) | Inclut uniquement les valeurs de données mises à jour pendant la durée spécifique. Le format est <value\><time-unit\>, où les unités de temps prises en charge sont "j" (jours), "h" (heures), "m" (minutes) et "s" (secondes). |
| limite | Le nombre maximum de résultats dans la réponse. |
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | Propriété de l'objet d'élément de données à utiliser pour les valeurs de données dans la réponse. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Propriété de l'objet d'unité d'organisation à utiliser pour les valeurs de données dans la réponse. |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété de la combinaison d'options de catégorie à utiliser pour les valeurs de données dans la réponse. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété des objets de combinaison d'options d'attribut à utiliser pour les valeurs de données dans la réponse. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | Propriété de l'objet d'ensemble de données à utiliser dans la réponse. |
| categoryIdScheme (Schéma de l'identifiant de catégorie) | Propriété de l'objet catégorie à utiliser dans la réponse (ADX uniquement). |
| categoryOptionIdScheme (Schéma de l'identifiant d'option de catégorie) | Propriété de l'objet d'options de catégorie à utiliser dans la réponse (ADX uniquement). |
| idScheme | Propriété de l'un des objets ci-dessus, s'ils ne sont pas spécifiés, à utiliser dans la réponse. S’il n’est pas spécifié, l’idScheme par défaut pour le format ADX est "code" et pour tous les autres formats, c'est "uid". |
| inputOrgUnitIdScheme | Propriété d'identification utilisée pour les valeurs du paramètre `orgUnit` fournies ; `id` ou `code` |
| inputDataSetIdScheme | Propriété d'identification utilisée pour les valeurs du paramètre `dataSet` fournies ; `id` ou `code` |
| inputDataElementGroupIdScheme | Propriété d'identification utilisée pour les valeurs du paramètre `dataElementGroup` fournies ; `id` ou `code` |
| inputIdScheme | Propriété d'identification utilisée pour l'une des valeurs des paramètres `dataSet`, `dataElementGroup`, `orgUnit`, `orgUnitGroup`, `attributeOptionCombo` fournies, à moins que l'un des trois schémas ci-dessus ne remplace explicitement cette entrée par défaut ; `id` ou `code` |

Les paramètres suivants provenant de la liste ci-dessus sont requis :
- dataSet ou dataElementGroup (pour le format ADX, cela doit être dataSet)
- period, (startDate et endDate), lastUpdated, ou lastUpdatedDuration
- orgUnit ou orgUnitGroup

Les formats de réponse suivants sont pris en charge :

  - xml (application/xml)

  - json (application/json)

  - csv (application/csv)

  - adx (application/adx+xml)

En supposant que nous avons publié les valeurs de données dans DHIS2 conformément à la section précédente intitulée *Envoi de valeurs de données*, nous pouvons maintenant constituer notre requête pour un ensemble de valeurs de données unique et l'exécuter en utilisant l'URL :

```bash
curl "https://play.dhis2.org/demo/api/dataValueSets?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8"
  -H "Accept:application/xml" -u admin:district
```

Nous pouvons également utiliser les paramètres de requête "date de début" et "date de fin" pour demander un plus grand nombre de valeurs de données. En d'autres termes, vous pouvez également demander des valeurs de données pour plusieurs ensembles de données, unités d'organisation et périodes afin d'exporter de plus grandes quantités de données. Notez que le paramètre de requête "période" est prioritaire sur les paramètres "date de début" et "date de fin". Voici un exemple :

```bash
curl "https://play.dhis2.org/demo/api/dataValueSets?dataSet=pBOMPrpg1QX&dataSet=BfMAe6Itzgt
  &startDate=2013-01-01&endDate=2013-01-31&orgUnit=YuQRtpLP10I&orgUnit=vWbkYPRmKyS&children=true"
  -H "Accept:application/xml" -u admin:district
```

Pour récupérer les valeurs de données qui ont été créées ou mises à jour au cours des 10 derniers jours, vous pouvez effectuer la requête suivante :

    /api/dataValueSets?dataSet=pBOMPrpg1QX&orgUnit=DiszpKrYNg8&lastUpdatedDuration=10d

La réponse ressemblera à ceci :

```xml
<?xml version='1.0' encoding='UTF-8'?>
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-01-02" period="201401" orgUnit="DiszpKrYNg8">
<dataValue dataElement="eY5ehpbEsB7" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10003"/>
<dataValue dataElement="Ix2HsbDMLea" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10002"/>
<dataValue dataElement="f7n9E0hX8qk" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10001"/>
</dataValueSet>
```

Vous pouvez demander à ce que les données soient rendues au format JSON de la manière suivante :

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8

La réponse ressemblera à ceci :

```json
{
  "dataSet": "pBOMPrpg1QX",
  "completeDate": "2014-02-03",
  "period": "201401",
  "orgUnit": "DiszpKrYNg8",
  "dataValues": [
    {
      "dataElement": "eY5ehpbEsB7",
      "categoryOptionCombo": "bRowv6yZOF2",
      "period": "201401",
      "orgUnit": "DiszpKrYNg8",
      "value": "10003"
    },
    {
      "dataElement": "Ix2HsbDMLea",
      "categoryOptionCombo": "bRowv6yZOF2",
      "period": "201401",
      "orgUnit": "DiszpKrYNg8",
      "value": "10002"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "categoryOptionCombo": "bRowv6yZOF2",
      "period": "201401",
      "orgUnit": "DiszpKrYNg8",
      "value": "10001"
    }
  ]
}
```

Notez que les valeurs de données sont mises en corbeille, c'est-à-dire qu'une valeur supprimée a la propriété `supprimée` définie sur "vrai" et n'est pas supprimée de façon permanente. Ceci est utile lors de l'intégration de plusieurs systèmes afin de signaler les suppressions. Vous pouvez inclure les valeurs supprimées dans la réponse comme suit :

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8&includeDeleted=true

Vous pouvez également demander à ce que les données soient rendues au format CSV de la manière suivante :

    /api/dataValueSets.csv?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8

La réponse ressemblera à ceci :

```csv
dataelement,period,orgunit,catoptcombo,attroptcombo,value,storedby,lastupdated,comment,flwup
f7n9E0hX8qk,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,12,system,2015-04-05T19:58:12.000,comment1,false
Ix2HsbDMLea,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,14,system,2015-04-05T19:58:12.000,comment2,false
eY5ehpbEsB7,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,16,system,2015-04-05T19:58:12.000,comment3,false
FTRrcoaog83,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,12,system,2014-03-02T21:45:05.519,comment4,false
```

Les contraintes suivantes s'appliquent à la ressource Ensembles de valeurs de données :

  - Au moins un ensemble de données doit être spécifié.

  - Soit au moins une période, soit une date de début et une date de fin doivent être
    spécifiés.

  - Au moins une unité d'organisation doit être spécifiée.

  - Les unités d'organisation doivent faire partie de la hiérarchie des unités d'organisation 
    de l’utilisateur authentifié.

  - La limite ne peut pas être inférieure à zéro.

### Envoi, lecture et suppression de valeurs de données individuelles { #webapi_sending_individual_data_values }

Cet exemple montrera comment envoyer des valeurs de données individuelles à enregistrer dans une requête. Ceci peut être réalisé par l'envoi d'une requête *POST* à la ressource `dataValues` :

    POST /api/dataValues

Les paramètres de requête suivants sont pris en charge pour cette ressource :

Tableau : Paramètres de requête de valeurs de données

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| de | Oui | Identifiant de l'élément de données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| co | Non | Identifiant de la combinaison d'options de catégorie, la valeur par défaut sera utilisée en cas d'omission |
| cc | Non (doit être combiné avec cp) | Identifiant de la combinaison de catégories d'attribut |
| cp | Non (doit être combiné avec CC) | Identifiants d'options de catégorie d'attribut, séparés par ; pour plusieurs valeurs |
| ds | Non | Ensemble de données, pour vérifier si la fonction POST or DELETE (publier ou effacer) est autorisée pour la période et l'unité d'organisation. S'il est spécifié, l'élément de données doit être affecté à cet ensemble de données. Dans le cas contraire, un ensemble de données contenant l'élément de données sera sélectionné pour vérifier si l'opération est autorisée. |
| valeur | Non | Valeur de données. Pour les valeurs booléennes, les éléments suivants seront acceptés : vrai &#124; Vrai &#124; VRAI &#124; faux &#124; Faux &#124; FAUX &#124; 1 &#124; 0 &#124; t &#124; f &#124; |
| commentaire | Non | Commentaire sur les données |
| suivi | Non | Le suivi de la valeur de données permet de faire basculer la valeur booléenne actuelle |

Si l'un des identifiants fournis n'est pas valide, si la valeur de données ou le commentaire n'est pas valide ou si les données sont verrouillées, la réponse contiendra le code d'état *409 Conflit* et un message texte descriptif. Si l'opération conduit à une valeur enregistrée ou mise à jour, *200 OK* sera renvoyé. Ci-après, un exemple de requête :

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s&value=12"
  -X POST -u admin:district
```

Cette ressource permet également une syntaxe spéciale pour associer la valeur à une combinaison d'options d'attribut. Pour ce faire, il suffit d'envoyer l'identifiant de la combinaison de catégories d'attribut, ainsi que les identifiants des options de catégories d'attribut que la valeur représente au sein de la combinaison. La combinaison de catégories est spécifiée avec le paramètre `cc`, tandis que les options de catégorie sont spécifiées sous la forme d'une chaîne de caractères séparés par des points-virgules avec le paramètre `cp`. Il faut s'assurer que les options de catégorie font toutes partie de la combinaison de catégories. Voici un exemple :

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu&ou=DiszpKrYNg8
  &pe=201308&cc=dzjKKQq0cSO&cp=wbrDrL2aYEc;btOyqprQ9e8&value=26"
  -X POST -u admin:district
```

Vous pouvez récupérer une valeur de données avec une requête en utilisant la méthode *GET* (obtenir). Les paramètres de valeur, de commentaire et de suivi ne sont pas applicables ici :

```bash
curl "https://play.dhis2.org/demo/api/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s"
  -u admin:district
```

Vous pouvez supprimer une valeur de données avec une requête en utilisant la méthode *DELETE*.

### Envoi de valeurs de données individuelles en tant que charge utile { #webapi_sending_individual_data_values_as_payload }

Vous pouvez envoyer des valeurs de données individuelles sous forme de charge utile JSON en utilisant la ressource suivante avec `Content-Type : application/json`.

```
POST /api/dataValues
```

La ressource créera une nouvelle valeur de données ou mettra à jour une valeur de données si elle existe déjà. Le format de charge utile JSON est défini ci-dessous.

```json
{
  "dataElement": "fbfJHSPpUQD",
  "categoryOptionCombo": "PT59n8BQbqM",
  "period": "202201",
  "orgUnit": "DiszpKrYNg8",
  "value": "10",
  "comment": "OK"
}
```

Le point de terminaison prend en charge la spécification de combinaisons d’options d’attribut dans une structure imbriquée.

```json
{
  "dataElement": "BOSZApCrBni",
  "categoryOptionCombo": "TkDhg29x18A",
  "attribute": {
    "combo": "O4VaNks6tta",
    "options": [
      "C6nZpLKjEJr", "i4Nbp8S2G6A"
    ]
  },
  "dataSet": "lyLU2wR22tC",
  "period": "202201",
  "orgUnit": "DiszpKrYNg8",
  "value": "15",
  "comment": "Good"
}
```

Le code d'état sera `201 Créé` si la valeur de données a été enregistrée ou mise à jour avec succès, ou `409 Conflit` en cas d'erreur de validation.

### Utilisation des valeurs de données de fichiers { #datavalue_file }

Lorsqu'il s'agit de valeurs de données dont l'élément de données est de type *fichier*, la méthode décrite ci-dessus ne s'applique plus. Ces valeurs de données sont spéciales dans la mesure où le contenu de la valeur est une référence UID à un objet *Ressource de fichier* et non une constante autonome. Ces valeurs de données se comportent comme les autres valeurs de données qui stockent du contenu textuel, mais elles doivent être traitées différemment afin de produire des entrées et des sorties pertinentes.

Il existe deux méthodes pour stocker les valeurs de données des ressources de fichiers.

* Téléchargez le fichier sur le point de terminaison `/api/dataValues/file` tel que
  décrit dans la section des ressources de fichiers. Cela fonctionne avec les versions 2.36 et supérieures.

* Si vous écrivez un code qui doit être compatible
  avec les versions DHIS2 inférieures à la 2.36, alors le processus est le suivant :

1.  Téléchargez le fichier sur le point de terminaison `/api/fileResources` tel que décrit
    dans la section des ressources de fichiers.

2.  Récupérez la propriété `id` de la ressource de fichier renvoyée.

3.  Stockez l'identifiant récupéré avec la propriété `valeur` de la valeur de données et en utilisant l'une
    des méthodes décrites ci-dessus.

Seules les relations un à un entre les valeurs de données et les ressources de fichiers sont autorisées. Cette règle est appliquée en interne, de sorte que l'enregistrement de l'identifiant d'une ressource de fichier dans plusieurs valeurs de données ne soit pas possible et entraîne une erreur. La suppression de la valeur de données entraîne la suppression de la ressource de fichier référencée. La suppression directe des ressources de fichiers n'est pas possible.

La valeur de données peut maintenant être récupérée normalement, mais c'est l'UID de la ressource du fichier qui sera renvoyé. Afin de récupérer le vrai contenu (c'est-à-dire le fichier stocké dans la ressource associée à la valeur de données), vous devez effectuer une requête GET à `/api/dataValues/files` en reproduisant les paramètres de la requête comme pour la valeur de données elle-même. Le point de terminaison `/api/dataValues/files` ne prend en charge que les requêtes GET.

Il convient de noter qu'en raison du fonctionnement asynchrone du mécanisme de stockage sous-jacent, le contenu du fichier peut ne pas être immédiatement téléchargeable à partir du point de terminaison `/api/dataValues/files`. Ceci est particulièrement valable pour les fichiers volumineux qui peuvent nécessiter des téléchargements en arrière-plan vers un entrepôt de fichiers externe (en fonction de la configuration du système). Récupérer les métadonnées de la ressource du fichier à partir du point de terminaison `/api/fileResources/<id>` permet de vérifier le `storageStatus` (état du stockage) du contenu avant d'essayer de le télécharger.

## Format de données ADX { #webapi_adx_data_format }

Depuis la version 2.20, nous prenons en charge une norme internationale d'échange de données agrégées appelée ADX. ADX est développé et maintenu par le comité Quality, Research and Public Health (Qualité, Recherche et Santé Publique) de l'IHE (Integrating the HealthCare Enterprise). La page wiki décrivant les activités du comité QRPH se trouve à l'adresse [wiki.ihe.net](http://wiki.ihe.net/index.php?title=Quality,_Research_and_Public_Health#Current_Domain_Activities). ADX fait toujours l'objet d'un développement actif et a maintenant été publié pour une implémentation à titre expérimental. Notez qu'actuellement, c'est la fonctionnalité de lecture et d'écriture des données formatées ADX qui est implémentée dans DHIS2, c'est-à-dire ce qui est décrit comme acteurs Consommateur de Contenu et Producteur de Contenu dans le profil ADX.

La structure d'un message de données ADX est assez similaire à celle des données DXF 2 décrites précédemment et que vous connaissez probablement. Il existe quelques différences importantes. Nous les décrirons à l'aide d'un petit exemple :

```xml
<adx xmlns="urn:ihe:qrph:adx:2015" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="urn:ihe:qrph:adx:2015 ../schema/adx_loose.xsd"
  exported="2015-02-08T19:30:00Z">
  <group orgUnit="OU_559" period="2015-06-01/P1M"
    completeDate="2015-07-01" dataSet="(TB/HIV)VCCT">
    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
  </group>
</adx>
```

### L'élément racine ADX { #the-adx-root-element }

L'élément racine ADX n'a qu'un seul attribut obligatoire, qui est l'horodatage *exporté*. Comme d'autres éléments ADX, le schéma est extensible dans le sens où il ne restreint pas les attributs spécifiques d'applications supplémentaires.

### L'élément du groupe ADX { #the-adx-group-element }

Contrairement à dxf2, ADX exige que les valeurs de données soient regroupées par unité d'organisation, période et ensemble de données. L'exemple ci-dessus montre un rapport de données pour l'ensemble de données "( TB/VIH) VCCT" de la base de données de démonstration en ligne. Cet exemple utilise des codes comme identifiants et non des uids dhis2. Le code est la forme d'identifiant préférée lors de l'utilisation d'ADX.

Les attributs d'unité d'organisation, de période et d'ensemble de données sont obligatoires dans ADX. L'élément de groupe peut contenir des attributs supplémentaires. Dans notre implémentation de DHIS2, tout attribut supplémentaire est simplement transmis à l'importateur sous-jacent. Cela signifie que tous les attributs qui ont actuellement une signification dans dxf2 (comme completeDate dans l'exemple ci-dessus) peuvent continuer à être utilisés dans ADX et seront traités de la même manière.

Une différence importante entre ADX et dxf2 réside dans la manière dont les périodes sont encodées. ADX utilise strictement la norme ISO8601 et encode la période de déclaration sous la forme (date|heure) / (durée). Dans l'exemple ci-dessus, la période est donc une période d'un mois (P1M) qui commence le 01/06/2015. Il s'agit donc des données de juin 2015. La notation est un peu plus longue, mais elle est très souple et nous permet de prendre en charge tous les types de période existants dans DHIS2.

### Définitions des périodes ADX { #adx-period-definitions }

Les périodes commencent par la date à laquelle la durée commence, suivie d'un "/" et de la notation de la durée, comme indiqué dans le tableau. Le tableau suivant détaille tous les types de période dans DHIS2 et la manière dont ils sont représentés en ADX, ainsi que des exemples.

Tableau : Périodes ADX

| Type de période | Notation de durée | Exemples) | Durée(s) |
|---|---|---|---|
| Quotidien  | P1D | 2017-10-01/P1M | 01 octobre 2017 |
| Hebdomadaire | P7D | 2017-10-02/P7D | 02 oct 2017-08 oct 2017 |
| Hebdomadaire Mercredi | P7D | 04-10-2017/P7D | 04 octobre 2017-10 octobre 2017 |
| Hebdomadaire Jeudi | P7D | 05-10-2017/P7D | 05 octobre 2017-011 octobre 2017 |
| Hebdomadaire Samedi | P7D | 07-10-2017/P7D | 07 octobre 2017-13 octobre 2017 |
| Hebdomadaire Dimanche | P7D | 01-10-2017/P7D | 01 octobre 2017-07 octobre 2017 |
| Bihebdomadaire | P14D | 02-10-2017/P14D | 02 octobre 2017-15 octobre 2017 |
| Mensuel | P1M | 2017-10-01/P1M | 01 octobre 2017-31 octobre 2017 |
| Bimensuel | P2M | 01-11-2017/P2M | 01 novembre 2017-31 décembre 2017 |
| Trimestriel | P3M | 01-09-2017/P3M | 01 septembre 2017-31 décembre 2017 |
| Semestriel | P6M | 01-01-2017/P6M<br>01-07-2017/P6M | 1er janvier 2017-30 juin 2017<br>1er juillet 2017-31 décembre 2017 |
| Semestriel Avril | P6M | 01-04-2017/P6M<br>01-10-2017/P6M | 1er avril 2017-30 septembre 2017<br>1er octobre 2017-31 mars 2018 |
| Semestriel Novembre | P6M | 01-10-2017/P6M<br>01-05-2018/P6M | 1er novembre 2017-30 avril 2018<br>1er mai 2018-31 octobre 2018 |
| Annuel | P1Y | 01-01-2017/P1Y | 01 janvier 2017-31 décembre 2017 |
| Financière Avril | P1Y | 01-04-2017/P1Y | 1er avril 2017-31 mars 2018 |
| Financière Juillet | P1Y | 01-07-2017/P1Y | 1er juillet 2017-30 juin 2018 |
| Financière Octobre | P1Y | 01-10-2017/P1Y | 01 octobre 2017-30 septembre 2018 |
| Financière Novembre | P1Y | 01-11-2017/P1Y | 01 novembre 2017-31 octobre 2018 |

### Valeurs de données ADX { #adx-data-values }

L'élément "valeur de données" dans ADX est très similaire à son équivalent dans DXF. Les attributs obligatoires sont *élément de données* et *valeur*. Les attributs *unité d'organisation* et *période* n'apparaissent pas dans l'élément "valeur de données" car ils sont requis au niveau *groupe*.

La différence la plus significative est la manière dont la désagrégation est représentée. DXF utilise la combinaison d'options de catégorie pour représenter la désagrégation des données. Dans ADX, les désagrégations (par exemple GROUPE_D'ÂGE et SEXE) sont exprimées explicitement en tant qu'attributs. Si vous utilisez `code` comme schéma d'identification pour `catégorie`, vous devez attribuer un code à toutes les catégories utilisées pour les éléments de données de l'ensemble de données et, de plus, ce code doit pouvoir être utilisé en tant qu'attribut XML. La contrainte concernant un nom d'attribut XML est décrite dans la norme XML du W3C. En pratique, cela signifie qu'il n'y a pas d'espaces, pas de caractères non alphanumériques autres que "_" et que le nom ne peut pas commencer par une lettre. L'exemple ci-dessus montre des exemples de "bons" codes de catégorie ("GENRE" et "ÂGE_VIH"). Les mêmes restrictions s'appliquent si vous utilisez `nom` ou `attribut` comme schémas d'identification.

Dans ADX, seuls les identifiants de catégorie sont utilisés comme attributs XML ; les identifiants d'autres types de métadonnées ne doivent pas être utilisés comme attributs XML. Notez que cette syntaxe n'est pas appliquée par DHIS2 lorsque vous attribuez des noms, des codes ou des attributs DHIS2, mais vous obtiendrez un message d'erreur avec une explication si vous essayez d'importer des données ADX et que les identifiants de catégorie ne sont pas attribués ou ne conviennent pas.

Les principaux avantages de l’utilisation de dimensions explicites de données désagrégées sont les suivants :

  - Le système qui produit les données n'a pas besoin d'être synchronisé avec la
    combinaison d'options de catégorie dans DHIS2.

  - Le producteur et le consommateur peuvent faire correspondre leurs codes à une source tierce 
    qui fait autorité, telle qu'un service de terminologie. Notez que dans 
    l'exemple ci-dessus, les codes de genre et de groupe d'âge utilisent des listes de codes
    de l'[Observatoire mondial de la santé de l'OMS](http://apps.who.int/gho/data/node.resources.api).

Cette fonction peut être très utile, par exemple pour produire des données désagrégées à partir d'un système de DME, mais il peut arriver qu'un mapping de *combinaison d'options de catégorie* soit plus facile ou plus souhaitable. L'implémentation d'ADX dans DHIS2 permettra de vérifier l'existence d'un attribut de *combinaison d'options de catégorie* et, s'il existe, de l'utiliser au lieu des attributs de dimension éclatés. De même, un attribut de *combinaison d'options d'attributs* sur l'élément *groupe* sera traité de la même manière que les attributs existants. Sinon, la combinaison d'options d'attributs peut être utilisée comme catégories éclatées, comme pour la *valeur de données*.

Dans l'exemple simple ci-dessus, tous les éléments de données de l'ensemble de données ont la même dimensionnalité (combinaison de catégories), ce qui rend les données parfaitement rectangulaires. Les ensembles de données peuvent contenir des éléments de données ayant des combinaisons de catégories différentes, ce qui donne un message de données ADX *décalé vers la droite* (c'est-à-dire que les valeurs des différents éléments de données peuvent avoir des nombres de catégories différents).

### Importation de données ADX { #importing-adx-data }

DHIS2 expose un point de terminaison pour les données POST ADX dans `/api/dataValueSets` en utilisant *application/xml+adx* comme type de contenu. Ainsi, par exemple, la commande curl suivante peut être utilisée pour POST (publier) les exemples de données ci-dessus dans le serveur de démonstration DHIS2 :

```bash
curl -u admin:district -X POST -H "Content-Type: application/adx+xml"
  -d @data.xml "https://play.dhis2.org/demo/api/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=code"
```

Notez que les paramètres de requête sont les mêmes que ceux utilisés avec les données DXF. Le point de terminaison ADX doit interpréter tous les paramètres DXF existants avec la même sémantique que DXF.

### Exportation de données ADX { #exporting-adx-data }

DHIS2 expose un point de terminaison pour les ensembles de données GET ADX dans `/api/dataValueSets` en utilisant *application/xml+adx* comme type de contenu. Ainsi, par exemple, la commande curl suivante peut être utilisée pour récupérer les données ADX :

```bash
curl -u admin:district -H "Accept: application/adx+xml"
 "https://play.dhis2.org/demo/api/dataValueSets?dataValueSets?orgUnit=M_CLINIC&dataSet=MALARIA&period=201501"
```

Notez que les paramètres de requête sont les mêmes que ceux utilisés avec les données DXF. Une différence importante est que les identifiants d'ensemble de données et d'unité d'organisation peuvent être soit des uids, soit des codes.

## Suivi { #webapi_follow_up }

Cette section couvre les données de marquage pour le suivi.

### Suivi de la valeur de données { #data-value-follow-up }

Le point de terminaison de suivi des valeurs de données permet de marquer les valeurs de données pour le suivi.

```
PUT /api/36/dataValues/followup
```

La charge utile au format `JSON` ressemble à ceci :

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "categoryOptionCombo": "psbwp3CQEhs",
  "attributeOptionCombo": "HllvX50cXC0",
  "followup": true
}
```

Les champs `combinaison d'options de catégorie` et `combinaison d'options d'attributs` sont facultatifs. Une charge utile `JSON` minimale ressemble à ceci :

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "followup": false
}
```

Le champ `suivi` doit être défini sur `vrai` pour marquer une valeur de données pour le suivi, et sur `faux` pour retirer le marquage.

Le code d'état de la réponse sera `200 OK` si l'opération réussit, et `409 Conflit` en cas d'erreur avec la requête.

Pour mettre à jour plusieurs valeurs de données à la fois pour le suivi :

    PUT /api/dataValues/followups

avec la charge utile `JSON` :

```json
{
  "values": [
    {
      "dataElement": "s46m5MS0hxu",
      "period": "202005",
      "orgUnit": "DiszpKrYNg8",
      "categoryOptionCombo": "psbwp3CQEhs",
      "attributeOptionCombo": "HllvX50cXC0",
      "followup": true
    }
  ]
}
```

Chaque élément de cette mise à jour comporte les mêmes champs et exigences que le point de terminaison de la mise à jour unique.

La mise à jour groupée renvoie également `200 OK` en cas de succès ou `409 Conflit` en cas d'erreurs dans la requête.



# Validation des données { #data-validation }

## Validation { #webapi_validation }

Pour générer un résumé de validation des données, vous pouvez interagir avec la ressource de validation. La ressource "ensemble de données" est optimisée pour les clients chargés de la saisie des données et de la validation d'un ensemble de données ou d'un formulaire. Elle est accessible de la manière suivante :

    GET /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

En plus de la validation des règles basées sur un ensemble de données, il existe deux méthodes supplémentaires de validation : validation personnalisée et validation programmée.

La première variable path (de chemin) est un identifiant qui fait référence à l'ensemble de données à valider. Les représentations XML et JSON des ressources sont prises en charge. La réponse contient les violations des règles de validation. Cette fonction sera étendue à d'autres types de validation dans les versions à venir.

Pour récupérer les règles de validation relatives à un ensemble de données spécifique, c'est-à-dire les règles de validation avec des formules où tous les éléments de données font partie de l'ensemble de données en question, vous pouvez lancer une requête GET à la ressource `validationRules` de la manière suivante :

    GET /api/validationRules?dataSet=<dataset-id>

Les règles de validation ont un côté gauche et un côté droit, dont la validité est comparée en fonction d'un opérateur. Les valeurs valides de l'opérateur sont indiquées dans le tableau ci-dessous.



Tableau : Opérateurs

| Valeur | Description |
|---|---|
| égal_à | Egale à |
| pas_égale_à | Pas égal à |
| supérieure_à | Supérieure à |
| supérieure_ou_égale_à_ | Supérieure ou égal à |
| inférieure_à | Inférieur à |
| inférieure_ou_égale_à_ | inférieur ou égal à |
| paire_obligatoire | Si l’un des côtés est présent, l’autre doit également l’être. |
| paire_exclusive | Si l’un des côtés est présent, l’autre ne doit pas être |

Les expressions du côté gauche et du côté droit sont des expressions mathématiques qui peuvent contenir des références à des éléments de données et à des combinaisons d'options de catégorie au format suivant :

    ${<dataelement-id>.<catoptcombo-id>}

Les expressions du côté gauche et du côté droit ont une *stratégie de valeur manquante*. Cette stratégie indique comment le système doit traiter les valeurs de données manquantes pour les références d'éléments de données ou de combinaisons d'options de catégorie dans la formule, en déterminant si la règle de validation doit être vérifiée ou ignorée. Les stratégies de valeurs manquantes valides sont présentées dans le tableau ci-dessous.



Tableau : Stratégies de valeur manquante

| Valeur | Description |
|---|---|
| IGNORER_SI_UNE_VALEUR_MANQUE | Ignore la règle de validation si une valeur de données est manquante |
| IGNORER_SI_TOUTES-LES_VALEURS_MANQUENT | Ignore la règle de validation si toutes les valeurs de données sont manquantes |
| NE-JAMAIS_IGNORER | N'ignore jamais la règle de validation, quelles que soient les valeurs de données manquantes |

## Résultats de la validation { #webapi_validation_results }

Les résultats de validation sont les résultats des violations constatées lors d'une analyse de validation. Si vous choisissez "conserver les résultats" lorsque vous lancez ou programmez une analyse de validation, toutes les violations constatées seront stockées dans la base de données. Lorsqu'un résultat est stocké dans la base de données, il est utilisé à trois fins :

1.  Générer des analyses basées sur les résultats stockés.

2.  Les résultats qui n'ont pas généré de notification le feront,
    une fois.

3.  Garder la trace des résultats qui ont généré ou non une
    notification.

4.  Ignorer les règles déjà vérifiées lors de
    l'analyse de validation.

Cela signifie que si vous ne conservez pas vos résultats, vous ne pourrez pas générer d'analyses pour les résultats de validation. Si cette option est sélectionnée, les résultats généreront des notifications à chaque fois qu'il y en aura et l'analyse de validation pourrait être plus lente.

### Résultats de la validation de la requête { #query-validation-results }

Les résultats de validation conservés peuvent être consultés au point d'extrémité suivant :

    GET /api/33/validationResults

Vous pouvez également inspecter un résultat individuel à l'aide de l'identifiant du résultat de validation dans ce point d'extrémité :

    GET /api/33/validationResults/<id>

Les résultats de validation peuvent également être filtrés par les propriétés suivantes :

* Unité organisationnelle : `ou=<UID>`
* Règle de validation : `vr=<UID>`
* Période : `pe=<ISO-expression>`

Chacune des propriétés de filtre ci-dessus peut apparaître plusieurs fois, par exemple :

    GET /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

Plusieurs valeurs pour le même filtre sont combinées avec OR, les résultats doivent correspondre à l'une des valeurs données.

Si plusieurs propriétés de filtre sont utilisées et qu'elles sont combinées avec AND, les résultats devront correspondre à l'une des valeurs de chacune des propriétés.

Pour le filtre de période, les résultats doivent se superposer à l'une des périodes spécifiées.

De plus, les résultats de validation peuvent également être filtrés en fonction de leur date de création :

    GET /api/36/validationResults?createdDate=<date>

Ce filtre peut être combiné avec n’importe quel autre filtre.

### Déclencher des notifications de résultats de validation { #trigger-validation-result-notifications }

Les résultats de la validation sont envoyés aux utilisateurs concernés une fois par jour. Ils peuvent également être déclenchés manuellement pour être exécutés sur demande, à l'aide du point d'extrémité de l'API suivant :

    POST /api/33/validation/sendNotifications

Seuls les résultats non envoyés sont envoyés via ce point d'extrémité.

### Supprimer les résultats de validation { #delete-validation-results }

Les résultats de validation peuvent être supprimés manuellement en utilisant l'ID,

    DELETE /api/36/validationResults/<id>

ou les filtres

    DELETE /api/36/validationResults?<filters>

Les paramètres de filtre pris en charge sont :

* `ou=<UID>` pour faire correspondre tous les résultats de validation d'une unité d'organisation. Plusieurs unités utilisent 'OU' lorsque le paramètre est fourni plus d'une fois
* `vr=<UID>` pour faire correspondre tous les résultats de validation d'une règle de validation. Plusieurs règles utilisent 'OU' lorsque le paramètre est fourni plus d'une fois
* `pe=<ISO-expression>` pour faire correspondre tous les résultats de validation liés à une période qui se superpose à la période spécifiée
* `created=<ISO-expression>` pour faire correspondre tous les résultats de validation créés au cours de la période fournie
* `notificationSent=<boolean>` pour faire correspondre uniquement les résultats de validation pour lesquels une notification a été ou n'a pas été envoyée

Si les filtres sont combinés, toutes les conditions doivent être vraies (AND logic (ET logique)).

Quelques exemples:

Pour supprimer tous les résultats de validation liés à l'unité d'organisation dont l'UID est `NqwvaQC1ni4` pour le premier trimestre (Q1) 2020, utilisez :

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

Pour supprimer tous les résultats de validation créés au cours de la semaine 1 de 2019 et pour lesquels une notification a été envoyée, utilisez :

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

Toute opération de suppression nécessitera l'autorité _Effectuer des tâches de maintenance_.


## Détection des valeurs atypiques { #outlier-detection }

Le point d'extrémité de détection des valeurs atypiques permet de détecter les valeurs atypiques dans les valeurs de données agrégées.

```
GET /api/36/outlierDetection
```

Ce point d'extrémité prend en charge deux algorithmes pour détecter les valeurs atypiques :

* **Z-score :** Le z-score est défini comme l'écart absolu entre le score et la moyenne divisé par l'écart type. Un paramètre de seuil faisant référence au nombre d'écarts types par rapport à la moyenne doit être spécifié avec l'algorithme z-score pour définir les limites supérieure et inférieure de ce qui est considéré comme une valeur atypique.
* **Z-score modifié :** Identique au z-score, à la différence qu'il utilise la médiane au lieu de la moyenne comme mesure de la tendance centrale. Les paramètres sont les mêmes que pour le Z-score.
* **Min-max :** Les valeurs des éléments de données min-max (minimales et maximales) font référence aux limites personnalisées qui peuvent être insérées dans DHIS 2 en fonction de la combinaison d'éléments de données, d'unités d'organisation et d'options de catégorie.

Les valeurs atypiques seront *classées selon leur importance*, par défaut selon l'écart absolu par rapport à la moyenne, avec la valeur la plus importante en premier. Ceci permet d'identifier rapidement les valeurs atypiques qui ont le plus grand impact sur la qualité et l’analyse des données.

### Paramètres de requête{ #request-query-parameters }

Les paramètres de requête suivants sont pris en charge.

| Paramètre de requête | Description                                                  | Obligatoire | Options (par défaut en premier)                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | Ensemble de données, peut être spécifié plusieurs fois.                   | No [*]    | Identifiant de l'ensemble de données.                      |
| de              | Élément de données, peut être spécifié plusieurs fois.               | No [*]    | Identifiant de l'élément de données.                  |
| date de début       | Date en début de l'intervalle pour contrôler les valeurs atypiques.               | Oui       | Date (aaaa-MM-jj).                        |
| date de fin         | Date en fin de l'intervalle pour vérifier les valeurs aberrantes.                 | Oui       | Date (aaaa-MM-jj).                        |
| ou              | Unité d'organisation, peut être spécifiée plusieurs fois.          | Oui       | Identifiant de l’unité d’organisation.             |
| algorithme       | Algorithme à utiliser pour la détection des valeurs atypiques.                      | Non        | `Z_SCORE`, `MIN_MAX`, `MOD_Z_SCORE`       |
| seuil       | Seuil pour les valeurs atypiques. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Numérique, supérieur à zéro. Par défaut : 3.0. |
| Date de début des données   | Date en début de l'intervalle pour le calcul de la moyenne et de l'écart type. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Date (aaaa-MM-jj). |
| Date de fin des données     | Date en fin de l'intervalle pour le calcul de la moyenne et de l'écart type. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Date (aaaa-MM-jj).   |
| orderBy         | Field to order by. `Z_SCORE` and `MOD_Z_SCORE`algorithm only.| Non        | `MEAN_ABS_DEV`, `Z_SCORE`                 |
| Résultats maximum      | Limite maximale pour la sortie.                                    | Non        | Entier, supérieur à zéro. Par défaut : 500. |

[*] Vous devez spécifier soit des ensembles de données avec le paramètre `ds`, qui inclura tous les éléments de données dans les ensembles de données, _ou_ spécifier des éléments de données avec le paramètre `de`.

Au moins un ensemble de données ou élément de données, une date de début et une date de fin, et au moins une unité d'organisation doivent être définis.

Les paramètres `Date de début` et `Date de fin` sont obligatoires et font référence à l'intervalle de temps dans lequel vous voulez détecter les valeurs atypiques. Les paramètres `Date de début des données` et `Date de fin des données` sont facultatifs et font référence à l'intervalle de temps à utiliser pour les données lors du calcul de la moyenne et de l'écart type. Ils sont utilisés pour calculer éventuellement le z-score.

### Utilisation et exemples { #usage-and-examples }

Obtenez les valeurs atypiques à l'aide de l'algorithme z-score par défaut :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
```

Obtenez des valeurs atypiques à l'aide d'un algorithme et d'un seuil spécifiques :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=Z_SCORE&threshold=2.5
```

Obtenez les valeurs atypiques classées par z-score :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &orderBy=Z_SCORE
```

Obtenez les 10 principales valeurs atypiques :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &maxResults=10
```

Obtenez des valeurs atypiques avec un intervalle défini pour les données à utiliser lors du calcul de la moyenne et de l'écart type :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &dataStartDate=2018-01-01&dataEndDate=2020-12-31
```

Obtenez les valeurs atypiques à l'aide de l'algorithme min-max :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=MIN_MAX
```

### Format de réponse { #response-format }

Les formats de réponse suivants sont pris en charge.

| Format | Format API                                                   |
| ------ | ------------------------------------------------------------ |
| JSON   | `/api/36/outlierDetection.json` or `Accept: application/json` (default format) |
| CSV    | `/api/36/outlierDetection.csv` or `Accept: application/csv`  |

La réponse contient les champs suivants :

| Champ      | Description                                                  |
| ---------- | ------------------------------------------------------------ |
| de         | Identifiant de l'élément de données.                                     |
| Nom de l'élément de données     | Nom de l'élément de données.                                           |
| pe         | Identifiant ISO de la période.                                       |
| ou         | Identifiant de l’unité d’organisation.                                |
| ouName     | Nom de l'unité d'organisation.                                      |
| coc        | Identifiant de la combinaison d’options de catégorie.                      |
| cocName    | Nom de la combinaison d’options de catégorie.                            |
| aoc        | Identifiant de la combinaison d’options d’attribut.                     |
| aocName    | Nom de la combinaison d’options d’attribut.                           |
| valeur      | Valeur de données.                                                  |
| moyenne       | Moyenne des valeurs de données dans la dimension de temps.                   |
| stdDev     | Écart-type.                                          |
| absDev     | Pour le z-score, il s'agit de l'écart absolu par rapport à la moyenne. Pour min-max, il s'agit de l'écart absolu par rapport à la limite min ou max. |
| zScore     | Le z-score. Algorithme du z-score uniquement.                         |
| lowerBound | La limite inférieure.                                          |
| upperBound | La limite supérieure.                                          |
| suivi   | Si la valeur de données est marquée pour le suivi.                  |

Les champs de `moyenne`, `écart type` et `z-score` ne sont présents que lorsque l'`algorithme` est `Z_SCORE`.

La réponse ressemblera à ceci. La section `métadonnées` contient des métadonnées de requête et de réponse. La section `Valeurs atypique` contient les valeurs atypiques.

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### Contraintes et validation { #constraints-and-validation }

Les contraintes suivantes s'appliquent lors de la validation de la requête. Chaque erreur de validation a un code d'erreur correspondant.

| Code d'erreur | Message                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | Au moins un élément de données doit être spécifié                  |
| E2201      | La date de début et la date de fin doivent être précisées                    |
| E2202      | La date de début doit être antérieure à la date de fin                           |
| E2203      | Au moins une unité d'organisation doit être spécifiée             |
| E2204      | Le seuil doit être un nombre positif                          |
| E2205      | Les résultats maximum doivent être exprimés en nombres positifs                        |
| E2206      | Le nombre maximum de résultats dépasse la limite autorisée : {d}               |
| E2207      | La date de début des données doit être antérieure à la date de fin des données                 |
| E2208      | Valeurs de données non numériques rencontrées lors de la détection des valeurs atypiques |

## Analyse des données { #webapi_data_analysis }

Plusieurs ressources permettant d'effectuer des analyses de données et de détecter les problèmes de qualité et de validation des données sont fournies.

**Remarque :** Ce point d'extrémité est obsolète et sera supprimé dans la version 2.38. Utilisez plutôt le point d'extrémité  `outlierAnalysis`.

### Analyse des règles de validation { #webapi_data_analysis_validation_rules } 

Pour exécuter des règles de validation et extraire les violations :

    GET /api/dataAnalysis/validationRules

Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'analyse des règles de validation

| Paramètre de requête | Description | Option |
|---|---|---|
| vrg | Groupe de règles de validation | Identifiant |
| ou | Unité d’organisation | Identifiant |
| date de début | Date de début de la période | Date |
| date de fin | Date de fin de la période | Date |
| conserver | S'il faut conserver les violations dans le système | faux &#124; vrai |
| notification | S'il faut envoyer des notifications sur les violations | faux &#124; vrai |

Exemple de sortie :
```json
[{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### Analyse des valeurs atypiques sur la base de l'écart type { #webapi_data_analysis_std_dev_outlier }

Pour identifier les valeurs atypiques parmi les données en fonction des écarts types de la valeur  moyenne :

    GET /api/dataAnalysis/stdDevOutlier

Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'analyse des valeurs atypiques de l'écart type

| Paramètre de requête | Description | Option |
|---|---|---|
| ou | Unité d’organisation | Identifiant |
| date de début | Date de début de la période | Date |
| date de fin | Date de fin de la période | Date |
| ds | Ensembles de données, le paramètre peut être répété | Identifiant |
| écart type | Nombre d'écarts types par rapport à la moyenne | Valeur numérique |

### Analyse des valeurs aberrantes basée sur les valeurs min/max { #webapi_data_analysis_min_max_outlier }

Pour identifier les valeurs atypiques sur la base des valeurs min/max :

    GET /api/dataAnalysis/minMaxOutlier

Les paramètres de requête pris en charge équivalent à la ressource *analyse des valeurs atypiques en fonction de l'écart type* décrite ci-dessus.

### Analyse des données de suivi { #follow-up-data-analysis }

Pour identifier les données marquées pour le suivi :

    GET /api/dataAnalysis/followup

Au moins un ensemble de données ou élément de données, une date ou période de début et de fin, et au moins une unité d'organisation doivent être définis.

Les paramètres de requête suivants sont pris en charge.

| Paramètre  | Description                                                  | Obligatoire | Options (par défaut en premier)                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ou         | Unité d'organisation, peut être spécifiée plusieurs fois.          | Oui       | Identifiant de l’unité d’organisation.             |
| ds         | Ensemble de données, peut être spécifié plusieurs fois.                   | No [*]    | Identifiant de l'ensemble de données.                      |
| de         | Élément de données, peut être spécifié plusieurs fois.               | No [*]    | Identifiant de l'élément de données.                  |
| date de début  | Date en début de l'intervalle pour contrôler les valeurs atypiques.               | No [*]    | Date (aaaa-MM-jj).                        |
| date de fin    | Date en fin de l'intervalle pour vérifier les valeurs aberrantes.                 | No [*]    | Date (aaaa-MM-jj).                        |
| pe         | ID de période ISO.                                               | No [*]    | ID ISO de la période.                        |
| peType     | Période ISO.                                                  | No [*]    | Chaîne ISO de la période.                        |
| coc        | Les combinaisons d’options de catégorie peuvent être spécifiées plusieurs fois.     | Non        | Identifiant de la combinaison d’options de catégorie.         |
| Résultats maximum | Limite maximale pour la sortie.                                    | Non        | Entier, supérieur à zéro. Par défaut : 50.  |

[*] Vous devez spécifier soit des ensembles de données avec le paramètre `ds`, qui intégrera tous les éléments de données dans les ensembles de données, _ou_ spécifier des éléments de données avec le paramètre `de`.
     De même, `Date de début` et `date de fin` _ou_ `période` doivent être spécifiés.

Les paramètres `Date de début` et `Date de fin` font référence à l'intervalle de temps au cours duquel vous voulez détecter les valeurs atypiques.
Si une période `pe` est fournie à la place, le début et la fin de l'intervalle sont également ceux de la période.

Si aucune combinaison d'options `coc` n'est fournie, tous les éléments de données de type valeur numérique seront pris en compte.


## Intégrité des données { #webapi_data_integrity } 
The data integrity capabilities of the data administration module are
available through the web API. This section describes how to run the
data integrity process as well as retrieving the result. The details of
the analysis performed are described in the user manual.

### Liste des vérifications d'intégrité des données disponibles { #webapi_data_integrity_list }
A description of the available checks is returned by

    GET /api/dataIntegrity

L'élément `nom` parmi les éléments de contrôle renvoyés est l'identifiant utilisé pour le paramètre des `contrôles` pour déclarer l’ensemble des contrôles à exécuter.

Les contrôles sont regroupés sémantiquement par l'élément `section` et classés dans l'un des quatre niveaux de `sévérité` :

| Gravité | Description |
| -------- | ----------- |
| INFO     | Indique qu'il s'agit uniquement d'une information. |
| AVERTISSEMENT  | A warning indicates that this may be a problem, but not necessarily an error. It is however recommended triaging these issues. |
| SEVERE   | An error which should be fixed, but which may not necessarily lead to the system not functioning. |
| CRITIQUE | An error which must be fixed, and which may lead to end-user error or system crashes. |

### Running a selection of data integrity checks { #webapi_data_integrity_run }
Since 2.38 data integrity checks have two levels, the summary level giving 
statistical overview, and the details level giving a list of issues each 
pointing to an individual data integrity violation.

Pour déclencher une analyse récapitulative pour un ensemble de contrôles exécutés :

    POST /api/dataIntegrity/summary?checks=<name1>,<name2>

This triggers a job that runs the check(s) asynchronously. 
The job details are given in the POST response that returns immediately once the job is scheduled.
The response's `Localtion` header points to the URL where the results can be fetched (see below). 

Pour récupérer le résumé sur l'intégrité des données du ou des contrôle(s) déclenchés, utilisez :

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>

When the `checks` parameter is omitted all checks are run/fetched.

The response is a "map" of check results, one for each check that has completed already.
This information is cached for 1h or until the check is rerun.
To wait for the summary to be available in the cache a `timeout` in milliseconds can be added:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>&timeout=500

Une réponse récapitulative pourrait ressembler à  ceci :
```json
{
  "<name1>": {
    "name": "<name1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 12,
    "percentage": 2.3
  },
  "<name2>": {
    "name": "<name2>",
    "finishedTime": "2022-02-15 14:58",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 4,
    "percentage": 5.1
  }
}
```
Alongside the check's information of `name`, `section`, `severity`, 
`description` and optionally `introduction` and `recommendation` the summary 
contains the number of issues found as `count` and when possible how large 
this count is in relation to all relevant entries as `percentage`.
The `finishedTime` indicates when the analysis of the check finished.
The cache will hold the result for 1h from this moment.

> **Note**
> 
> If a summary (or details) response "map" does not contain any data (field) for
> a check included in the `checks` parameter list it is likely the case that
> the check either never ran or has not yet finished running.
> You can either use client side polling or add the `timeout` parameter to use
> server side waiting for the requested results.

Similarly to run a selection of details checks first trigger them using `POST`:

    POST /api/dataIntegrity/details?checks=<name1>,<name2>

Récupérez ensuite les résultats du cache en utilisant :

    GET /api/dataIntegrity/details?checks=<name1>,<name2>&timeout=500

Again, not providing the `checks` parameter will run all checks.
Omitting the `timeout` will not wait for results to be found in the cache 
but instead not have a result for the requested check.

The `/details` response returns a similar map again, just that each entry 
does not have a `count` and `percentage` member but a list of `issues`.

```json
{
  "<name1>": {
    "name": "<name1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issues": [{
      "id": "<id-or-other-identifier>",
      "name": "<name-of-the-id-obj>",
      "comment": "optional plain text description or hint of the issue",
      "refs": ["<id1>", "<id2>"]
    }]
  },
  "<name2>": {
    "name": "<name2>",
    "finishedTime": "2022-02-15 14:59",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issues": []
  }
}
```
The issue objects always have `id` and `name` members. Sometimes an 
additional `comment` is available that gives more context or insight into 
why the data integrity is violated. In addition, the `refs` list might 
sometimes also give the ids of other objects that contributed to the violation.
The `finishedTime` indicates when the analysis of the check finished.
The cache will hold the result for 1h from this moment.

> **Tip**
>
> A set of checks can also be specified using wild-cards. To include all 
> checks with _element_ in the name use `checks=*element*`. Like full names 
> such patterns can be used in a comma separated list and be mixed with full 
> names as well. Duplicates will be eliminated. 

Should a check analysis fail due to programming error or unforeseen data inconsistencies
both the summary and the details will have an `error` field describing the error that occurred.
In such case no data is available for the check.

```json
{
  "<name1>": {
    "name": "<name1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "error": "what has happened",
    "issues": []
  }
}
```

### Running full data integrity report (legacy) { #webapi_data_integrity_run_legacy } 

The operation of performing data integrity analysis is a resource (and
time) demanding task. It is therefore run as an asynchronous process and
only when explicitly requested. Starting the task is done by forming an
empty POST request to the *dataIntegrity* endpoint:

    POST /api/dataIntegrity

If successful the request will return HTTP 202 immediately. The location
header of the response points to the resource used to check the status
of the request. The payload also contains a json object of the job
created. Forming a GET request to the given location yields an empty
JSON response if the task has not yet completed and a JSON taskSummary
object when the task is done. Polling (conservatively) to this resource
can hence be used to wait for the task to finish.

### Fetching asynchronous integrity summary (legacy) { #webapi_data_integrity_fetch_results } 

Once data integrity is finished running the result can be fetched from
the `system/taskSummaries` resource like so:

    GET /api/system/taskSummaries/DATA_INTEGRITY

The returned object contains a summary for each point of analysis,
listing the names of the relevant integrity violations. As stated in the
leading paragraph for this section the details of the analysis (and the
resulting data) can be found in the user manual chapter on Data
Administration.

## Enregistrements des ensembles de données complets{ #webapi_complete_data_set_registrations }

Cette section traite de l'enregistrement d'ensembles de données complétés en tant qu'ensembles de données. Un enregistrement marque un ensemble de données comme étant complètement capturé.

### Compléter les ensembles de données { #webapi_completing_data_sets }

Cette section explique comment enregistrer des ensembles de données comme étant complets. Cela s'obtient en interagissant avec la ressource *completeDataSetRegistrations*:

    GET /api/33/completeDataSetRegistrations

Le point d'extrémité utilise la méthode *POST* pour enregistrer les ensembles de données complets. De façon pratique, ce point d'extrémité est très similaire à celui de *dataValueSets* (ensembles de valeurs de données), avec la possibilité d'importer des enregistrements complets en bloc.

L'importation de charges utiles au format *XML* et *JSON* est prise en charge. Le format de base de cette charge utile, donné en *XML* dans cet exemple, ressemble à ceci :

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

L'attribut *storedBy* (stocké par) est facultatif (car il peut être retiré de l'objet d'enregistrement complet). Vous pouvez également définir la propriété *date* (heure de l'enregistrement) en tant qu'attribut. Si l'heure n'est pas définie, l'heure actuelle sera utilisée.

Le processus d'importation prend en charge les paramètres de requête suivants :



Tableau : Paramètres de requête d'enregistrement d'ensembles de données complets

| Paramètre | Valeurs | Description |
|---|---|---|
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'ensemble de données permettant de mettre en correspondance les enregistrements complets. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'unité d'organisation permettant de mettre en correspondance les enregistrements complets. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de la combinaison d'options d'attribut permettant de mettre en correspondance les enregistrements complets. |
| idScheme | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de tous les objets, y compris les ensembles de données, les unités d'organisation et les combinaisons d'options d'attribut, qui permettent de mettre en correspondance enregistrements complets. |
| preheatCache | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| dryRun | faux &#124; vrai | Si l'enregistrement s'applique aux sous-unités |
| importStrategy (stratégie d'importation) | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipExistingCheck (ignorer les contrôles existants) | faux &#124; vrai | Ne contrôle pas les enregistrements complets existants. Améliore les performances. À utiliser uniquement pour les bases de données vides ou lorsque les enregistrements à importer n'existent pas encore. |
| async | faux &#124; vrai | Indique si l'importation doit être effectuée de manière asynchrone ou synchrone. La première option (asynchrone) est adapté aux importations très volumineuses car il garantit que la requête n’expire pas, bien qu’il entraîne une surcharge de performances. La deuxième (synchrone) est plus rapide mais nécessite que la connexion soit maintenue jusqu'à la fin du processus. |

Les éléments `idScheme` (schéma de l'identifiant), `dataSetIdScheme`  (schéma de l'identifiant de l'ensemble de données), `orgUnitIdScheme` (schéma de l'identifiant de l'unité d'organisation), `attributeOptionComboIdScheme` (schéma de l'identifiant de la combinaison d'options d'attribut),
`dryRun` (essai) et `strategy` (stratégie) (notez la dénomination différente du paramètre `importStrategy` (stratégie d'importation))
peuvent également être définis dans le cadre de la charge utile.
Avec XML, ce sont des attributs ; avec JSON, ce sont des éléments du nœud `completeDataSetRegistrations` (enregistrements des ensembles de données complets).

Par exemple :
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

Si le paramètre URL et la charge utile définissent un schéma, la charge utile est prioritaire.

### Lecture des enregistrements d'ensembles de données complets { #webapi_reading_complete_data_sets }

Cette section explique comment récupérer les enregistrements d'ensembles de données complets. Nous utiliserons la ressource *completeDataSetRegistrations*. Les paramètres de requête à utiliser sont les suivants :



Tableau : Paramètres de requête d'ensemble de valeurs de données

| Paramètre | Description |
|---|---|
| dataSet (ensemble de données) | Identifiant de l'ensemble de données, plusieurs ensembles de données sont autorisés |
| période | Identifiant de la période au format ISO. Plusieurs périodes sont autorisées. |
| date de début | Date de début de la période des valeurs à exporter |
| date de fin | Date de fin de la période des valeurs à exporter |
| créé | Inclut uniquement les enregistrements créées depuis l'horodatage donné |
| Durée de la création | Inclut uniquement les enregistrements créées pendant la durée indiquée. Le format est <value\><unité-de-temps\>, où les unités de temps prises en charge sont "d", "h", "m", "s " *(jours, heures, minutes, secondes).* L'unité de temps est liée à l'heure actuelle. |
| orgUnit (Unité d'organisation) | Identifiant de l'unité d'organisation ; peut être spécifié plusieurs fois. Non applicable si un groupe d'unités d'organisation est fourni. |
| orgUnitGroup (groupe d'unités d'organisation) | Identifiant du groupe d’unités d’organisation ; peut être spécifié plusieurs fois. Non applicable si une unité d'organisation est fournie. |
| subordonnées | Permet de spécifier s'il faut inclure les unités d’organisation subordonnées dans la hiérarchie des unités d'organisation |
| limite | Le nombre maximum d'enregistrements à inclure dans la réponse. |
| idScheme | Propriété d'identifiant utilisée pour les objets de métadonnées dans la réponse. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | Propriété d'identifiant utilisée pour les ensembles de données dans la réponse. Elle remplace le schéma de l'identifiant. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Propriété d'identifiant utilisée pour les unités d'organisation dans la réponse. Elle remplace le schéma de l'identifiant. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété d'identifiant utilisée pour les combinaisons d'options d'attribut dans la réponse. Elle remplace le schéma de l'identifiant. |
Les paramètres `ensemble de données` et `unité d'organisation` peuvent être répétés afin d'inclure plusieurs ensembles de données et unités d'organisation.

Les paramètres `période`, `date de début`, `date de fin`, `créé` et `durée de création` fournissent plusieurs façons de définir la dimension temporelle de la requête, donc un seul peut être utilisé. Par exemple, cela n'a pas de sens de définir à la fois la date de début/fin et les périodes.

Voici donc un exemple de requête :

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX&dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

Vous pouvez obtenir la réponse au format *xml* et *json*. Vous pouvez indiquer le format de réponse que vous préférez via l'en-tête HTTP *Accepter* comme dans l'exemple ci-dessus. Pour xml, utilisez *application/xml* ; pour json, utilisez *application/json*.

### Annuler la finalisation des ensembles de données { #webapi_uncompleting_data_sets }

Cette section explique comment annuler l'enregistrement de la complétude d'un ensemble de données. Pour annuler la finalisation d'un ensemble de données, vous interagirez avec la ressource completeDataSetRegistrations :

    GET /api/33/completeDataSetRegistrations

Cette ressource prend en charge la fonction *DELETE* pour annuler l'inscription. Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'enregistrement d'ensembles de données complets

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| ds | Oui | Identifiant de l'ensemble de données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| cc | Non (doit combiner avec cp) | Identifiant de la combinaison d'attributs (pour la vérification du verrouillage) |
| cp | Non (doit combiner avec cp) | Identifiants d'options d'attribut, séparés par ; pour plusieurs valeurs (pour le contrôle du verrouillage) |
| multiOu (unités d'organisation multiples) | Non (faux par défaut) | Si l'enregistrement s'applique aux sous-unités |



# Approbation des données { #data-approval } 

## Approbation des données { #webapi_data_approval } 

Cette section explique comment approuver, désapprouver et vérifier le statut 
d'approbation en utilisant la ressource *dataApprovals* (Approbation des données). L'approbation se fait par flux 
de travail d'approbation des données, par période, par unité d'organisation et par combinaison d'options d'attributs.

    /api/33/dataApprovals

Un processus d'approbation des données est associé à plusieurs entités :

* Un type de période qui définit la fréquence d'approbation
* Une combinaison de catégories facultative
* Un ou plusieurs niveaux d'approbation des données qui font partie du flux de travail
* Un ou plusieurs ensembles de données utilisés pour la collecte de données

### Obtenir le statut d'approbation { #webapi_data_approval_get_status } 

Pour obtenir des informations sur l'approbation d'un ensemble de données, vous pouvez envoyer une requête GET :

    /api/dataApprovals?wf=rIUL3hYOjJc&pe=201801&ou=YuQRtpLP10I



Tableau : Paramètres de requête pour l'approbation des données

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| wf | Oui | Identifiant du workflow d'approbation des données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| aoc | Non | Identifiant de combinaison d'options d'attributs |

> **Remarque**
>
> Pour des raisons de compatibilité en amont, le paramètre `ds` pour l'ensemble de données peut être donné à la place de `wf` pour le flux de travail dans cette demande d'approbation de données et dans d'autres, comme décrit ci-dessous. Si l'ensemble de données est donné, le flux de travail associé à cet ensemble de données sera utilisé.

Vous obtiendrez une réponse similaire à celle-ci :

```json
{
" peutApprouver " : faux,
" peutDésapprouver " : faux,
" peutAccepter " : faux,
" peutRefuser " : faux,
" status " : " APPROUVÉ_ICI ",
" approuvéPar " : "Utilisateur A",
" approuvéÀ " : "2022-01-13T12:56:07.005",
" acceptéPar " : "Utilisateur A",
" AcceptéÀ " : "2022-01-13T12:56:07.005"
}
```

Les paramètres obtenus sont les suivants :

Tableau : Paramètres obtenus pour l'approbation des données

| Paramètre de retour | Description |
|---|---|
| peutApprouver        | Si l'utilisateur actuel peut approuver cette sélection de données. |
| peutDésapprouver      | Si l'utilisateur actuel peut désapprouver cette sélection de données. |
| peutAccepter         | Si l'utilisateur actuel peut accepter cette sélection de données. |
| peutRefuser       | Si l'utilisateur actuel peut refuser cette sélection de données. |
| État             | L'un des états d'approbation des données est indiqué dans le tableau ci-dessous. |
| approuvéPar        | Si la sélection est approuvée, et si disponible (pas toujours nécessaire), le nom de l'utilisateur qui a approuvé la sélection. |
| approuvéÀ        | Si la sélection est approuvée, et si disponible (pas toujours nécessaire), la date et l'heure à laquelle le niveau d'approbation le plus élevé a été créé. |
| acceptéPar        | Si la sélection est approuvée, et si disponible (pas toujours nécessaire), le nom de l'utilisateur qui a effectué la dernière mise à jour. |
| acceptéÀ        | Si la sélection est approuvée, et si disponible (pas toujours nécessaire), la date et l'heure de la dernière mise à jour du niveau d'approbation le plus élevé. |


Tableau : États d'approbation des données

| État | Description |
|---|---|
| NON APPROUVÉ | L'approbation des données ne s'applique pas à cette sélection. (Les données ne sont ni approuvées ni non approuvées). |
| NON APPROUVÉ_EN ATTENTE | Les données pourraient être approuvées pour cette sélection, mais elles attendent une approbation de niveau inférieur avant d'être prêtes à être approuvées. |
| NON APPROUVÉ_AUTRE PART | Les données ne sont pas approuvées et attendent d'être approuvées autre part (elles ne peuvent pas être approuvées ici). |
| NON APPROUVÉ_ PRÊT | Les données ne sont pas approuvées et sont prêtes à être approuvées pour cette sélection. |
| APPROUVÉ_ICI | Les données sont approuvées et ont été approuvées ici (elles pourraient donc être non approuvées ici). |
| APPROUVÉ_AUTRE PART | Les données sont approuvées, mais n'ont pas été approuvées ici (et ne peuvent donc pas être non approuvées ici) : <br>* Les données sont approuvées à un niveau supérieur.<br>* Les données sont approuvées pour un plus grand nombre d'options de catégories. <br>* Les données sont approuvées pour toutes les sous-périodes de la période sélectionnée. <br>Dans les deux premiers cas, il existe un seul objet d'approbation des données qui couvre la sélection. Dans le troisième cas, il n'y en a pas. |
| ACCEPTÉ_ICI | Les données sont approuvées et acceptées ici (elles pourraient donc être non approuvées ici). |
| ACCEPTÉ_AUTRE PART | Les données sont approuvées et acceptées, mais à un autre endroit. |

Notez que lorsque vous demandez l'état de l'approbation des données, vous pouvez spécifier
toute combinaison de paramètres d'interrogation. La combinaison que vous spécifiez
ne doit pas nécessairement décrire l'endroit où les données doivent être approuvées à l'un 
des niveaux d'approbation. Par exemple :

  - L'unité d'organisation peut ne pas être à un niveau d'approbation. Le
    statut d'approbation est déterminé par le fait que les données sont approuvées à un
    niveau d'approbation pour un ascendant de l'unité d'organisation.

  - Vous pouvez spécifier des options de catégories d'attributs individuelles. Le statut
    d'approbation est déterminé par le fait que les données sont approuvées pour une
    combinaison d'options de catégorie d'attributs qui comprend une ou plusieurs de ces
    options.

  - Vous pouvez spécifier une période plus longue que celle de
    l'ensemble de données, au cours de laquelle les données sont saisies et approuvées. Le statut 
    d'approbation est déterminé par l'approbation des données pour toutes les
    périodes de l'ensemble de données au cours de la période spécifiée.

Pour les ensembles de données associés à une combinaison de catégories, il est possible 
de récupérer les enregistrements d'approbation des données pour les combinaisons d'options d'attributs individuels 
à partir de la ressource suivante, au moyen d'une requête GET :

    /api/dataApprovals/categoryOptionCombos?wf=rIUL3hYOjJc&pe=201801&ou=YuQRtpLP10I

### Obtenir le statut d'approbation en bloc { #bulk-get-approval-status } 

Pour obtenir une liste de plusieurs statuts d'approbation, vous pouvez envoyer une requête GET similaire à celle-ci :

    /api/dataApprovals/approvals?wf=rIUL3hYOjJc&pe=201801,201802&ou=YuQRtpLP10I

Les paramètres `wf`, `pe`, `ou`, et `aoc` sont les mêmes que pour obtenir un statut d'approbation unique, sauf que vous pouvez fournir une liste séparée par des virgules d'une ou plusieurs valeurs pour chaque paramètre.

Vous obtiendrez une réponse contenant une liste de paramètres d'approbation et de statuts, comme suit :

```json
[
  {
    "aoc": "HllvX50cXC0",
    "pe": "201801",
    "niveau": "KaTJLhGmU95",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "peutApprouver": faux,
      "peutDésapprouver": vrai,
      "peutAccepter": vrai,
      "peutRefuser": faux,
      "peutLirelesdonnées": vrai,
      "approuvéPar": "Utilisateur A",
      "approuvéÀ": "2022-01-13T12:56:07.005",
      "acceptéPar": "Utilisateur A",
      "acceptéPar": "2022-01-13T12:56:07.005"      
    },
    "statut": "APPROUVÉ_ICI",
    "wf": "rIUL3hYOjJc"
  },
  {
    "aoc": "HllvX50cXC0",
    "pe": "201802",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "peutApprouver": vrai,
      "peutDésapprouver": faux,
      "peutAccepter": faux,
      "peutRefuser": faux,
      "peutLirelesdonnées":  vrai
    },
    "statut": "DÉSAPPROUVÉ_PRÊT",
    "wf": "rIUL3hYOjJc"
  }
]
```

Les champs obtenus sont décrits dans le tableau ci-dessous.

| Champ       | Description |
| ----------- | ----------- |
| aoc         | Identifiant de combinaison d'options d'attributs |
| pe          | Identifiant de période |
| ou          | Identifiant d'unité d'organisation |
| autorisations | Les autorisations : mêmes définitions que pour l'obtention d'un statut d'approbation unique (voir le tableau _Paramètres d'approbation des données renvoyés_). |
| État       | Un des états d'approbation des données (comme pour obtenir un statut d'approbation unique.) |
| wf          | Identifiant du workflow d'approbation des données |

### Approuver les données { #webapi_data_approval_approve_data } 

Pour approuver des données, vous pouvez envoyer une demande *POST* à la ressource 
*dataApprovals*. Pour annuler l'approbation des données, vous pouvez envoyer une 
demande *SUPPRIMER* à la ressource dataApprovals.

    POST DELETE /api/33/dataApprovals

Pour accepter des données déjà approuvées, vous pouvez envoyer une demande 
*POSTER* à la ressource *Acceptationdesdonnées*. Pour annuler l'acceptation de données, 
vous pouvez envoyer une demande *SUPPRIMER* à la ressource *Acceptationdesdonnées*.

    POST DELETE /api/33/dataAcceptances

Ces demandes contiennent les paramètres suivants :



Tableau : Paramètres d'action pour l'approbation des données

| Paramètres d'action | Obligatoire | Description |
|---|---|---|
| wf | Oui | Identifiant du workflow d'approbation des données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| aoc | Non | Identifiant de combinaison d'options d'attributs |

Notez que, contrairement à la requête sur le statut d'approbation des données, vous devez 
spécifier des paramètres qui correspondent à une sélection de données susceptibles d'être 
approuvées. En particulier, les deux éléments suivants doivent être vrais :

  - Le niveau de l'unité d'organisation doit être spécifié par un niveau d'approbation 
    dans le flux de travail.

  - La période spécifiée doit correspondre au type de période du 
    flux de travail.

### Approuver les données en bloc { #webapi_data_approval_bulk_approve_data } 

Vous pouvez approuver un ensemble d'enregistrements de données en postant dans 
la ressource `/api/dataApprovals/approvals`.

    POST /api/33/dataApprovals/approvals

Vous pouvez approuver un bloc d'enregistrements de données en postant dans 
la ressource `/api/dataApprovals/approvals`.

    POST /api/33/dataApprovals/unapprovals

Vous pouvez accepter un grand nombre d'enregistrements en envoyant un message à la ressource
`/api/dataAcceptances/acceptances`.

    POST /api/33/dataAcceptances/acceptances

Vous pouvez refuser un bloc d'enregistrements en envoyant un message à la ressource
`/api/dataAcceptances/acceptances`.

    POST /api/33/dataAcceptances/unacceptances

La charge utile d'approbation est prise en charge en tant que JSON et ressemble à ceci :

```json
{
  "wf": [
    "pBOMPrpg1QX", "lyLU2wR22tC"
  ],
  "pe": [
    "201601", "201602"
  ],
  "approvals": [
    {
      "ou": "cDw53Ej8rju",
      "aoc": "ranftQIH5M9"
    },
    {
      "ou": "cDw53Ej8rju",
      "aoc": "fC3z1lcAW5x"
    }
  ]
}
```

### Obtenir les niveaux d'approbation des données { #get-data-approval-levels } 

Pour récupérer les flux de travail d'approbation des données et leurs niveaux d'approbation, 
vous pouvez effectuer une requête GET similaire à celle-ci :

/api/dataApprovalWorkflows ?
champs=identifiant, nom, type de période, niveau d'approbation des données [identifiant, nom, niveau, niveau de l'unité d'organisation]


### Responsables de l'approbation des données { #authorities-for-data-approval } 

- `F_FLUX DE TRAVAIL_ DE L' APPROBATION_DES DONNÉES` : permet à l'utilisateur d'ajouter/mettre à jour le flux de travail relatif à l'approbation des données.
-  `F_NIVEAU_D'APPROBATION DES_DONNÉES` : permet à l'utilisateur d'ajouter/mettre à jour le niveau d'approbation des données.


# Partage { #sharing } 

## Partage { #webapi_sharing } 

La solution de partage vous permet de partager la plupart des objets du système avec 
des groupes d'utilisateurs spécifiques et de définir si les objets doivent être accessibles 
au public ou privés. Pour obtenir et définir le statut de partage des objets, vous pouvez 
interagir avec la ressource de *partage*.

    /api/33/sharing

### Obtenir le statut de partage { #webapi_get_sharing_status } 

Pour demander le statut de partage d'un objet, faites une requête GET à :

    /api/33/sharing?type=dataElement&id=fbfJHSPpUQD

La réponse se présente comme suit.

```json
{
  "meta": {
    "autoriserl'accèspublic": vrai,
    "autoriserl'accèsexterne": faux
  },
  "objet": {
    "id": "fbfJHSPpUQD",
    "nom": "CPN 1ère visite",
    "accèspublic": "rw------",
    "accèsexterne": faux,
    "utilisateur": {},
    "accès au groupe d'utilisateurs": [
      {
        "id": "hj0nnsVsPLU",
        "accès": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "accès": "r-------"
      }
    ]
  }
}
```

### Définir le statut de partage { #webapi_set_sharing_status } 

Vous pouvez définir le statut de partage d'un objet en utilisant la même URL avec 
une requête POST, où la charge utile au format JSON ressemble à ceci :

```json
{
  "objet": {
    "accèspublic": "rw------",
    "accèsexterne": faux,
    "utilisateur": {},
    "accès au groupe d'utilisateurs": [
      {
        "id": "hj0nnsVsPLU",
        "accès": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "accès": "r-------"
      }
    ]
  }
}
```

Dans cet exemple, la charge utile définit l'objet comme ayant un accès public en lecture et 
en modification, aucun accès externe (sans connexion), un accès en lecture et en modification à 
un groupe d'utilisateurs et un accès en lecture uniquement à un autre groupe d'utilisateurs. Vous pouvez 
soumettre ceci à la ressource de partage en utilisant curl :

```bash
curl -d @sharing.json "localhost/api/33/sharing?type=dataElement&id=fbfJHSPpUQD"
  -H "Content-Type:application/json" -u admin:district
```
**Remarque**
> Il est possible de créer des combinaisons de partage surprenantes. Par
> exemple, si `accèsexterne` est défini à `vrai` mais que `accèspublic` est
> défini à `--------`, les utilisateurs n'auront accès à l'objet 
> que lorsqu'ils seront déconnectés.




## Nouvel objet de partage { #new-sharing-object } 
Depuis la version 2.36, une nouvelle propriété `partage` a été introduite afin de remplacer les anciennes propriétés de partage `accès utilisateur`, `accès groupe utilisateur`, `accès public`, `accès externe` dans toutes les classes de métadonnées pour lesquelles le partage est activé. Cet objet `Partage` est sauvegardé en tant que colonne JSONB dans la base de données. 
Cependant, afin de rendre le système compatible avec les anciennes versions, les anciens objets de partage continuent de fonctionner normalement, à la fois pour l'importation et l'exportation. Dans le backend, les données de partage seront sauvegardées dans la nouvelle colonne JSONb `Partage` au lieu des anciennes tables `*Accès`.

Le format est le suivant :
```json
{
  "nom": "CPN 1ère visite",
  "accès public": "rw------",
  "accès externe": faux,
  "accès aux groupes d'utilisateurs": [
      {
          "accès": "r-r-----",
          "groupe d'utilisateur Uid": "Rg8wusV7QYi",
          "nom d'affichage": "Coordinateurs du programme VIH",
          "id": "Rg8wusV7QYi"
      }
  ],
  "accès utilisateur": [],
  "utilisateur": {
      "nom d'affichage": "Tom Wakiki",
      "nom": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "Nom d'utilisateur": "système"
  },
  "partage": {
      "propriétaire": "GOLswS44mh8",
      "externe": faux,
      "utilisateurs": {},
      "groupes d'utilisateurs": {
          "Rg8wusV7QYi": {
              "accès": "r-r-----",
              "id": "Rg8wusV7QYi"
          }
      },
      "public": "rw------"
  }
}
```

### Définir le statut de partage en utilisant la nouvelle Api JSON Patch { #webapi_set_sharing_status_using_json_patch_api } 
Vous pouvez utiliser [JSON Patch API](#webapi_partial_updates) pour mettre à jour le partage d'un objet en envoyant une requête `PATCH` à ce point de terminaison avec l'en-tête `Type de contenu : application/json-patch+json`
```
api/dataElements/fbfJHSPpUQD
```
Veuillez noter que cette fonction ***supporte uniquement*** le nouveau format `partage`. La charge utile au format JSON ressemble à ceci :
```json
[
  {
    "op": "remplacer",
    "chemin d'accès": "/partage/utilisateurs",
    "valeur": {
      "NOOF56dveaZ": {
        "accès": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "accès": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
Vous pouvez ajouter des utilisateurs à la propriété `partage` d'un objet comme suit
```json
[
  {
    "op": "ajouter",
    "chemin d'accès": "/partage/utilisateurs",
    "valeur": {
      "NOOF56dveaZ": {
        "accès": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "accès": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
Vous pouvez ajouter un utilisateur à `partage` comme ceci
```json
[
  {
    "op": "ajouter",
    "chemin d'accès": "/partage/utilisateurs/NOOF56dveaZ",
    "valeur": {
      "accès": "rw------",
      "id": "NOOF56dveaZ"
    }
  }
]
```
Vous pouvez supprimer un utilisateur de `partage` comme suit
```json
[
  { 
    "op": "supprimer", 
    "chemin d'accès": "/partage/utilisateurs/N3PZBUlN8vq"
  }
]
```

## Partage en cascade du tableau de bord { #cascade-sharing-for-dashboard } 

### Aperçu { #overview } 

- La fonction  `partage en cascade` est disponible pour les tableaux de bord. Cette fonction copie les  `Accès utilisateur` et  `Accès groupe d'utilisateurs` d'un tableau de bord vers tous les objets de ses  `Éléments de tableau de bord`, y compris une  `Carte`, un  `Rapport d'événement`, un  `Graphique d'événement`, une  `Visualisation`. 
- Cette fonction ne copie pas l'accès `MODIFIER_LES METADONNEES`. Les `accès d'utilisateur` et `accès de groupe d'utilisateur` copiés recevront **uniquement** la permission `LECTURE_DES METADONNEES`. 
- Le paramètre `Accèspublic` du tableau de bord n'est pas copié.
- Si un objet cible a l'option `Accès public` activée, alors il sera ignoré et ne recevra pas les `Accès utilisateur` ou les `Accès groupe d'utilisateurs` du tableau de bord.
- L'utilisateur actuel doit avoir la permission de partage `LECTURE_DE METADONNEES` sur tous les objets cibles. Si ce n'est pas le cas, l'erreur `E5001` est déclenchée.
- L'utilisateur actuel doit avoir la permission de partage `MODIFIER_LES METADONNEES` pour mettre à jour n'importe quel objet cible. Si un objet cible doit être mis à jour et que l'utilisateur n'a pas cette permission, l'erreur `E3001` est déclenchée.

### Exemple de cas d'utilisation { #sample-use-case } 

- Le tableau de bord A est partagé avec l'utilisateur A avec la permission `METADONNEES_LECTURE_MODIFIER`. 
- Le tableau de bord A a une visualisation A qui a un élément de données A.
- La Visualisation A, l'Elément de données A ont un `accès public` *désactivé* et ne sont *pas partagés* avec l'utilisateur A.
- Après avoir exécuté le partage en cascade pour le tableau de Bord A, l'utilisateur A aura un accès `LECTURE_DE METADONNEES` à la Visualisation A et à l'Élément de Données A.

### Point de terminaison de l'API  { #api-endpoint } 

- Envoyer une requête `POST` au point de terminaison 
```
api/dashboards/cascadeSharing/{dashboardUID}
```


### Paramètres de l'API { #api-parameters } 

| Nom | Par défaut | Description |
| --- | --- | -- |
| dryRun | faux | Si ce paramètre est fixé à `vrai`, la fonction de partage en cascade sera exécutée sans mettre à jour aucun objet. </br>La réponse comprendra les erreurs éventuelles et tous les objets qui seront mis à jour. </br>Cela permet à l'utilisateur de connaître le résultat avant d'exécuter la fonction de partage en cascade.
| atomic | faux | Si ce paramètre est fixé à `vrai`, alors la fonction de partage en cascade s'arrêtera et ne mettra à jour aucun objet s'il y a une erreur. </br>Sinon, si cette valeur est ` fausse `, la fonction essaiera de procéder avec le mode du best effort (meilleur effort).

Exemple de réponse : 

```json
{
  "rapports d'erreur": [
    {
      "message": "Pas d'objet correspondant à la référence. L'identificateur était s46m5MS0hxu, et l'objet était l'élément de données .",
      "mainKlass": "org.hisp.dhis.dataelement.DataElement",
      "code d'erreur": "E5001",
      "Propriétés de l'erreur": [
        "s46m5MS0hxu",
        "élément de données "
      ]
    }
  ],
  "countUpdatedDashBoardItems": 1,
  "mettre à jour les objets": {
    "élément de données ": [
      {
        "id": "YtbsuPPo010",
        "nom": "Dose de rougeole administrée"
      },
      {
        "id": "l6byfWFUGaP",
        "nom": "Doses de fièvre jaune administrées"
      }
    ]
  }
}
```

### Propriétés de la réponse : { #response-properties } 

- `Rapports d'erreurs` : inclut toutes les erreurs survenues au cours du processus de partage en cascade.
- `countUpdatedDashBoardItems` : Nombre `d'éléments du tableau de bord` qui seront ou ont été mis à jour, en fonction du mode `dryRun`.
- `updateObjects` (Mise à jour des objets): Liste de tous les objets qui seront ou ont été mis à jour en fonction du mode `dryRun`.

## Patch API du partage en vrac { #webapi_bulk_sharing } 
- L'API de partage en vrac vous permet d'appliquer des paramètres de partage à plusieurs objets de métadonnées. Cela signifie qu'il est possible d'ajouter ou de supprimer de nombreux utilisateurs et groupes d'utilisateurs à de nombreux objets en une seule opération API.
- Cette API ne doit pas prendre en charge la synchronisation des objets de métadonnées au fil du temps, mais la traiter comme une opération ponctuelle.
- L'API doit respecter le contrôle d'accès au partage, de sorte que l'utilisateur actuel ait accès à la modification du partage des objets en cours de mise à jour.
- Deux nouveaux points de terminaison api ont été introduits à partir de la version 2.38 pour permettre le partage en masse des mises à jour de correctifs, comme décrit ci-dessous.
- Veuillez noter que ces requêtes `PATCH` doivent utiliser l'en-tête `Content-type:application/json-patch+json`

### Utilisation de `/api/{object-type}/sharing` avec une requête `PATCH`
- Ce point d'accès permet à l'utilisateur d'appliquer un ensemble de paramètres de partage à plusieurs objets de métadonnées *d'un type d'objet*.
- Notez que nous supportons toujours les requêtes JsonPatch pour un objet avec le point de terminaison `api/{object-type}/{uid}`. Par exemple, vous pouvez toujours mettre à jour le partage d'un Élément de Données en envoyant une requête PATCH à `api/dataElements/cYeuwXTCPkU/sharing`

Exemple:
```
curl -X PATCH -d @payload.json -H "Content-Type: application/json-patch+json" "https://play.dhis2.org/dev/api/dataElements/sharing"
```

### Utiliser `/api/metadata/sharing` avec une requête `PATCH`{ #using-apimetadatasharing-with-patch-request } 
- Ce point de terminaison permet à l'utilisateur d'appliquer des paramètres de partage pour *plusieurs types d'objets* en une seule charge utile.

Exemple:
```
curl -X PATCH -d @payload.json -H "Content-Type: application/json-patch+json" "https://play.dhis2.org/dev/api/metadata/sharing"
```

## Paramètres { #parameters } 
- Les deux points de terminaison de l'api du patch ont le même paramètre :

| Nom  |  Par défaut  |  Description  |
| ---- | ---- | -------------------- |
| atomic | faux | Si ce paramètre est fixé sur vrai, la fonction de traitement par lots s'arrête et ne met à jour aucun objet en cas d'erreur. <br>Sinon, si ce paramètre est fixé sur faux, la fonction essaye de procéder en mode " best effort " (meilleur effort). |


## Validation { #validation } 
- L'existence de tous les identifiants d'objets sera validée.
- L'utilisateur actuel doit avoir l'autorisation de lire/modifier les métadonnées pour mettre à jour les objets.
- Toutes les validations existantes du service d'importation de métadonnées seront également appliquées.

## Réponse { #response } 
- Le format de la réponse doit être le même que celui de l'api `/api/metadata`.

## Formats de charge utile { #payload-formats } 
- La charge utile pour un seul type d'objet utilisant `/api/{type objet}/partage` se présente comme suit
```json
{
  "dataSets":[
    "cYeuwXTCPkU",
    "aYeuwXTCPkU"
  ],
  "patch":[
    {
      "op":"add",
      "path":"/sharing/users/DXyJmlo9rge",
      "value":{
        "access":"rw------",
        "id":"DXyJmlo9rge"
      }
    },
    {
      "op":"remove",
      "path":"/sharing/users/N3PZBUlN8vq"
    }
  ]
}
```

- La charge utile pour plusieurs types d'objets en une seule charge utile en utilisant `api/métadonnée/partage`
```json
{
  "dataElements": {
    "fbfJHSPpUQD": [
      {
        "op": "replace",
        "path": "/sharing/users",
        "value": {
          "NOOF56dveaZ": {
            "access": "rw------",
            "id": "CotVI2NX0rI"
          },
          "Kh68cDMwZsg": {
            "access": "rw------",
            "id": "DLjZWMsVsq2"
          }
        }
      }
    ]
  },
  "dataSets": {
    "cYeuwXTCPkA": [
      {
        "op": "remove",
        "path": "/sharing/users/N3PZBUlN8vq"
      }
    ],
    "cYeuwXTCPkU": [
      {
        "op": "add",
        "path": "/sharing/users/DXyJmlo9rge",
        "value": {
          "access": "rw------",
          "id": "DXyJmlo9rge"
        }
      }
    ]
  },
  "programs": {
    "GOLswS44mh8": [
      {
        "op": "add",
        "path": "/sharing/userGroups",
        "value": {
          "NOOF56dveaZ": {
            "access": "rw------",
            "id": "NOOF56dveaZ"
          },
          "Kh68cDMwZsg": {
            "access": "rw------",
            "id": "Kh68cDMwZsg"
          }
        }
      }
    ]
  }
}
```


# Programmation { #webapi_scheduling }

DHIS2 permet de programmer des tâches de différents types. Chaque type de tâche possède des propriétés de configuration différentes, ce qui vous permet de contrôler plus finement la façon dont les tâches sont exécutées. En outre, vous pouvez configurer une même tâche de manière à ce qu'elle s'exécute avec différentes configurations et à différents intervalles, si nécessaire.



Tableau : Principales propriétés

| Propriété | Description | Type |
|---|---|---|
| nom | Nom de la tâche. | Chaîne |
| expression cron | L'expression cron qui définit l'intervalle d'exécution de la tâche. | Chaîne (expression Cron) |
| type de tâches | Le type de tâche représente la tâche qui est exécutée. Le tableau suivant donne un aperçu des types de tâches existants. Chaque type de tâche peut avoir un ensemble spécifique de paramètres pour la configuration de la tâche. | Chaîne (Enum) |
| paramètres de tâches | Paramètres de tâches, le cas échéant pour le type de tâche. | (Voir la liste des types de tâches) |
| activé | Une tâche peut être ajoutée au système sans être programmée en mettant `enabled` à false dans la charge utile JSON. Utilisez ceci si vous voulez arrêter temporairement la programmation d'une tâche, ou si la configuration d'une tâche n'est pas encore terminée. | Booléen |



### Job Parameters { #job-parameters } 

Tableau : Paramètres des tâches de `DATA_INTEGRITY`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `vérifications` | tableau de chaînes | `[]` = tous | noms des contrôles à effectuer dans l'ordre d'exécution |
| `type`   | enum            | `RAPPORT`   | RAPPORT, RÉSUMÉ ou DÉTAILS                       |

Tableau : Paramètres des tâches de `ANALYTICS_TABLE`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `années précédentes` | int  | 0       | Nombre d'années écoulées à inclure |
| `Sauter les types de tableau` | tableau de enum  | `[]`    | Omettre la génération de tableaux ; Valeurs possibles : `VALEUR_DONNÉE`, `COMPLÉTUDE`, `COMPLÉTUDE_CIBLE`, `UNITÉ_D'ORGANISATION_CIBLE`, `ÉVÉNEMENT`, `INSCRIPTION`, `RÉSULTAT DE_VALIDATION` |
| `Sauter les tableaux ressources` | booléen | `faux`   | Ignorer la génération des tableaux de ressources |
| `Ignorer les Programmes` | tableau de chaînes | `[]`    | Liste facultative de programmes (d'identifiants) à ignorer |

Tableau : Paramètres des tâches de `CONTINUOUS_ANALYTICS_TABLE`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `années précédentes` | int           | `0`     | Nombre d'années écoulées à inclure |
| `Sauter les types de tableau` | tableau de enum | `[]`    | Omettre la génération de tableaux ; Valeurs possibles : `VALEUR_DONNÉE`, `COMPLÉTUDE`, `COMPLÉTUDE_CIBLE`, `UNITÉ_D'ORGANISATION_CIBLE`, `ÉVÉNEMENT`, `INSCRIPTION`, `RÉSULTAT DE_VALIDATION` |
| `Mise à jour complète de l'heure de la journée` | int           | `0`     | Heure de la journée pour la mise à jour complète des tableaux d'analyse (0-23) |

Tableau : Paramètres des tâches de `DATA_SYNC`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `taille de la page` | int | `10000` | nombre de valeurs de données traitées en tant qu'unité |

Tableau : Paramètres des tâches de `META_DATA_SYNC`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `Taille de la page du programme tracker` | int | `20` | nombre d'entités suivies traitées en tant qu'unité |
| `Taille de la page du programme d'événements` | int | `60` | nombre d'événements traités en tant qu'unité           |
| `Taille de la page des données` | int | `10000` | nombre de valeurs de données traitées en tant qu'unité  |

Tableau : Paramètres des tâches `MONITORING` (Analyse des règles de validation)

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `début relatif` | int | `0` | Un nombre lié à la date d'exécution qui correspond au début de la période à suivre. |
| `fin relative` | int | `0` | Un nombre lié à la date d'exécution qui correspond à la fin de la période à suivre. |
| `groupes de règles de validation` | tableau de chaînes | `[]` | Groupes de règles de validation (UID) à inclure dans la tâche  |
| `envoyer une notification` | booléen | `faux` | Définir sur `vrai` si la tâche doit envoyer des notifications basées sur les groupes de règles de validation |
| `persiste les résultats` | booléen | `faux` | Définir sur `true` si la tâche doit persister les résultats de la validation. |

Tableau : Paramètres des tâches de `PUSH_ANALYSIS`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `analyse push` | tableau de chaînes | `[]` |  Les UID des analyses push que vous souhaitez exécuter |

Tableau : Paramètres des tâches de `PREDICTOR`.

| Nom          | Type          | Par défaut | Description                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `début relatif` | int | `0` | Un nombre lié à la date d'exécution qui correspond au début de la période à suivre. |
| `fin relative` | int | `0` | Un nombre lié à la date d'exécution qui correspond au début de la période à suivre. |
| `Les prédicteurs` | tableau de chaînes | `[]` | Prédicteurs (UID) à inclure dans la tâche                                                      |
| `groupes de prédicteurs` | tableau de chaînes | `[]` | Groupes de prédicteurs (UID) à inclure dans la tâche                                                |


### Get available job types { #get-available-job-types } 

Pour obtenir une liste de tous les types de travaux disponibles, vous pouvez utiliser le point d'extrémité suivant :

    GET /api/jobConfigurations/jobTypes

La réponse contient des informations sur chaque type de travail, notamment le nom, le type de travail, la clé, le type de programmation et les paramètres disponibles. Le type de programmation peut être soit `CRON`, ce qui signifie que les travaux peuvent être programmés en utilisant une expression cron avec le champ `cronExpression`, soit `FIXED_DELAY`, ce qui signifie que les travaux peuvent être programmés pour s'exécuter avec un délai fixe entre les deux avec le champ `delay`. Le champ delay est donné en secondes.

Une réponse ressemblera à ceci :

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

### Créer une configuration de tâches { #create-a-job-configuration } 

Pour configurer les tâches, vous pouvez envoyer une requête POST à la ressource suivante :

    /api/jobConfigurations

Une tâche sans paramètres au format JSON ressemble à ceci :

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

Exemple d'un tableau d'analyse de tâches avec des paramètres au format JSON :

```json
{
  "name": "Analytics tables last two years",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * * ? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

Exemple d'une tâche d'analyse push avec des paramètres au format JSON :

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

Exemple de tâche avec le type de programmation `FIXED_DELAY` et un délai de 120 secondes :

```json
{
  "name": "Continuous analytics table",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "delay": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
```

### Obtenir des configurations de tâches { #get-job-configurations } 

Liste de toutes les configurations de tâches :

    GET /api/jobConfigurations

Retrouver une tâche :

    GET /api/jobConfigurations/{id}

Le contenu de la réponse se présente comme suit :

```json
{
  "lastUpdated": "2018-02-22T15:15:34.067",
  "id": "KBcP6Qw37gT",
  "href": "http://localhost:8080/api/jobConfigurations/KBcP6Qw37gT",
  "created": "2018-02-22T15:15:34.067",
  "name": "analytics last two years",
  "jobStatus": "SCHEDULED",
  "displayName": "analytics last two years",
  "enabled": true,
  "externalAccess": false,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "2018-02-26T03:00:00.000",
  "cronExpression": "0 0 3 ? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorite": false,
  "configurable": true,
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "manage": true
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favorites": [],
  "translations": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
```

### Update a Job Configuration { #update-a-job-configuration } 

Update a job with parameters using the following endpoint and JSON payload format:

    PUT /api/jobConfiguration/{id}

```json
{
  "name": "analytics last two years",
  "enabled": true,
  "cronExpression": "0 0 3 ? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

### Delete a Job Configuration { #delete-a-job-configuration } 

Delete a job using:

    DELETE /api/jobConfiguration/{id}

Notez que certaines tâches avec des paramètres de configuration personnalisés peuvent ne pas être ajoutées si 
les paramètres système requis ne sont pas configurés. C'est le cas par exemple de la synchronisation des 
données, qui nécessite la configuration d'un serveur distant.

### Run Jobs Manually { #run-jobs-manually } 

Jobs can be run manually using:

    POST /api/jobConfiguration/{id}/execute


### Observe Running Jobs { #observe-running-jobs } 
The execution steps and state can be observed while the job is running.
To get an overview of all running jobs by job type use:

    GET /api/scheduling/running

Comme il ne peut y avoir qu'une seule tâche en cours pour chaque type à la fois, l'état d'une 
tâche en cours peut être visualisé en détail à l'aide de la commande suivante:

    GET /api/scheduling/running/{type}

For example, to see status of a running `ANALYTICS_TABLE` job use

    GET /api/scheduling/running/ANALYTICS_TABLE

Une tâche est une séquence de processus. Chaque processus comporte une séquence d'` étapes `
Dans chaque étape, il peut y avoir zéro, un ou plusieurs `éléments`. Les éléments peuvent être
traités de manière strictement séquentielle ou parallèle, n éléments à la fois. Souvent, le
nombre d'` éléments total` est souvent connu à l'avance.

En général, les étapes d'un processus et les éléments d'une étape sont « découverts » 
en tant qu'« effet secondaire » du traitement des données. Alors que la plupart des processus ont 
une séquence fixe d'étapes, certains processus peuvent avoir des étapes variables en fonction des 
données traitées. Les éléments dépendent généralement des données. La plupart des travaux ne comprennent 
qu'un seul processus.

Each of the nodes in the process-stage-item tree has a status that is either
* `RUNNING`: is currently processed (not yet finished)
* `SUCCESS`: when completed successful
* `ERROR`: when completed with errors or when an exception has occurred
* `CANCELLED`: when cancellation was requested and the item will not complete

### See Completed Job Runs { #see-completed-job-runs } 
Une fois qu'une tâche s'est achevée avec succès ou avec un échec à la suite d'une 
exception ou d'une annulation, l'état passe de l'ensemble des états d'exécution aux états 
des tâches achevées. Cet ensemble ne conserve que l'état d'exécution le plus récent 
pour chaque type de tâche. L'aperçu est disponible à l'adresse suivante : 

    GET /api/scheduling/completed

Details on a particular job type are accordingly provided at:

    GET /api/scheduling/completed/{type}

In case of the `ANALYTICS_TABLE` job this would be:

    GET /api/scheduling/completed/ANALYTICS_TABLE

### Request Cancelling a Running Jobs { #request-cancelling-a-running-jobs } 
Une fois qu'une tâche est lancée, elle se déroule selon une séquence d'étapes. Chaque étape peut 
à son tour comporter des collections d'éléments à traiter. Bien que les tâches ne puissent généralement 
pas être arrêtées à tout moment, nous pouvons demander une annulation et le 
processus s'arrête de manière coopérative une fois qu'il a terminé un élément ou une étape 
et qu'il reconnaît qu'une annulation a été demandée. Cela signifie que les tâches ne s'arrêtent pas 
immédiatement et ne partent pas à un moment inconnu en plein milieu d'un 
traitement. Au contraire, elles s'arrêtent lorsqu'il est possible de passer à 
la fin. Cela signifie toujours que le processus global est inachevé et qu'il n'est pas 
annulé. Il se peut qu'il ait simplement effectué un certain nombre d'étapes et en ait sauté 
d'autres à la fin.

To cancel a running job use:

    POST /api/scheduling/cancel/{type}

For example, to cancel the `ANALYTICS_TABLE` job run:

    POST /api/scheduling/cancel/ANALYTICS_TABLE

En fonction de l'étape en cours et de l'élément exécuté, l'annulation peut prendre de 
quelques millisecondes à quelques minutes avant d'être effective. 
Cependant, le statut de l'ensemble du processus sera affiché comme `ANNULÉ ` 
immédiatement après avoir été vérifié à l'aide de

    GET /api/scheduling/running/ANALYTICS_TABLE

Seuls les tâches qui ont été scindées en processus, étapes et éléments peuvent être 
annulées de manière efficace. Toutes les tâches n'ont pas encore été scindées. Celles-ci seront exécutées jusqu'à leur 
terme, même si l'annulation a été demandée.



# Synchronization { #webapi_synchronization }

This section covers pull and push of data and metadata.

## Data value push { #webapi_sync_data_push }

To initiate a data value push to a remote server one must first configure the
URL and credentials for the relevant server from System settings >
Synchronization, then make a POST request to the following resource:

    /api/33/synchronization/dataPush

## Metadata pull { #webapi_sync_metadata_pull }

To initiate a metadata pull from a remote JSON document you can make a
POST request with a *url* as request payload to the following resource:

    /api/33/synchronization/metadataPull

## Availability check { #webapi_sync_availability_check }

To check the availability of the remote data server and verify user
credentials you can make a GET request to the following resource:

    /api/33/synchronization/availability



# Audit { #audit }

## Auditing { #webapi_auditing } 

DHIS2 does automatic auditing on all updates and deletions of aggregate
data values, tracked entity data values, tracked entity attribute
values, and data approvals. This section explains how to fetch this
data.

### Aggregate data value audits { #webapi_auditing_aggregate_audits } 

The endpoint for aggregate data value audits is located at
`/api/audits/dataValue`, and the available parameters are displayed in
the table below.



Table: Aggregate data value query parameters

| Paramètre | Option | Description |
|---|---|---|
| ds | Ensemble de données | One or more data set identifiers to get data elements from. |
| de | Élément de données | One or more data element identifiers. |
| pe | ISO Period | One or more period ISO identifiers. |
| ou | Unité d'organisation | One or more org unit identifiers. |
| auditType | UPDATE &#124; DELETE | Filter by audit type. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show |

Get all audits for data set with ID *lyLU2wR22tC*:

    /api/33/audits/dataValue?ds=lyLU2wR22tC

### Tracked entity data value audits { #webapi_tracked_entity_data_value_audits } 

The endpoint for tracked entity data value audits is located at
`/api/audits/trackedEntityDataValue`, and the available parameters are
displayed in the table below.



Table: Tracked entity data value query parameters

| Paramètre | Option | Description |
|---|---|---|
| de | Élément de données | One or more data element identifiers. |
| ps | Program Stage Entity | One or more program stage instance identifiers. |
| auditType | UPDATE &#124; DELETE | Filter by audit type. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show |

Get all audits which have data element ID eMyVanycQSC or qrur9Dvnyt5:

    /api/33/audits/trackedEntityDataValue?de=eMyVanycQSC&de=qrur9Dvnyt5

### Tracked entity attribute value audits { #webapi_tracked_entity_attribute_value_audits } 

The endpoint for tracked entity attribute value audits is located at
`/api/audits/trackedEntityAttributeValue`, and the available parameters
are displayed in the table below.



Table: Tracked entity attribute value query parameters

| Paramètre | Option | Description |
|---|---|---|
| tea | Tracked Entity Attributes | One or more tracked entity attribute identifiers. |
| te | Tracked Entity Instances | One or more tracked entity instance identifiers. |
| auditType | UPDATE &#124; DELETE | Filter by audit type. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show |

Get all audits which have attribute with ID VqEFza8wbwA:

    /api/33/audits/trackedEntityAttributeValue?tea=VqEFza8wbwA

### Tracked entity instance audits { #webapi_tracked_entity_instance_audits } 

Once auditing is enabled for tracked entity instances (by setting
allowAuditLog of tracked entity types to true), all read and search
operations are logged. The endpoint for accessing audit logs is
api/audits/trackedEntityInstance. Below are available parameters to
interact with this endpoint.



Table: Tracked entity instance audit query parameters

| Paramètre | Option | Description |
|---|---|---|
| tei | Instance d'entité suivie | One or more tracked entity instance identifiers |
| user | Utilisateur | One or more user identifiers |
| auditType | SEARCH &#124; READ | Audit type to filter for |
| date de début | Start date | Start date for audit filtering in yyyy-mm-dd format. |
| date de fin | End date | End date for audit filtering in yyyy-mm-dd format. |
| skipPaging | faux &#124; vrai | Turn paging on / off. |
| page | 1 (default) | Specific page to ask for. |
| taille de la page | 50 (default) | Page size. |

Get all tracked entity instance audits of type READ with
startDate=2018-03-01 and endDate=2018-04-24 in a page size of 5:

    /api/33/audits/trackedEntityInstance.json?startDate=2018-03-01
      &endDate=2018-04-24&auditType=READ&pageSize=5

### Enrollment audits { #webapi_enrollment_audits } 

Once auditing is enabled for enrollments (by setting allowAuditLog of
tracker programs to true), all read operations are logged. The
endpoint for accessing audit logs is api/audits/enrollment. Below are
available parameters to interact with this endpoint.



Table: Enrollment audit query parameters

| Paramètre | Option | Description |
|---|---|---|
| en | Inscription | One or more tracked entity instance identifiers |
| user | Utilisateur | One or more user identifiers |
| date de début | Start date | Start date for audit filtering in yyyy-mm-dd format. |
| date de fin | End date | End date for audit filtering in yyyy-mm-dd format. |
| skipPaging | faux &#124; vrai | Turn paging on / off. |
| page | 1 (default) | Specific page to ask for. |
| taille de la page | 50 (default) | Page size. |

Get all enrollment audits with startDate=2018-03-01 and
endDate=2018-04-24 in a page size of 5:

    /api/audits/enrollment.json?startDate=2018-03-01&endDate=2018-04-24&pageSize=5

Get all enrollment audits for user admin:

    /api/audits/enrollment.json?user=admin

### Data approval audits { #data-approval-audits } 

The endpoint for data approval audits is located at
/api/audits/dataApproval, and the available parameters are displayed in
the table below.



Tableau : Paramètres de requête pour l'approbation des données

| Paramètre | Option | Description |
|---|---|---|
| dal | Data Approval Level | One or more data approval level identifiers. |
| wf | Déroulement | One or more data approval workflow identifiers. |
| ou | Unité d'organisation | One or more organisation unit identifiers. |
| aoc | Attribute Option Combo | One or more attribute option combination identifiers. |
| date de début | Start Date | Starting Date for approvals in yyyy-mm-dd format. |
| date de fin | End Date | Ending Date for approvals in yyyy-mm-dd format. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show. |

Get all audits for data approval workflow RwNpkAM7Hw7:

    /api/33/audits/dataApproval?wf=RwNpkAM7Hw7




# Messagerie { #messaging } 

## Message conversations { #webapi_message_conversations } 

DHIS2 features a mechanism for sending messages for purposes such as
user feedback, notifications, and general information to users. Messages
are grouped into conversations. To interact with message conversations
you can send POST and GET request to the *messageConversations*
resource.

    /api/33/messageConversations

Messages are delivered to the DHIS2 message inbox but can also be sent
to the user's email addresses and mobile phones as SMS. In this example,
we will see how we can utilize the Web API to send, read and manage
messages. We will pretend to be the *DHIS2 Administrator* user and send
a message to the *Mobile* user. We will then pretend to be the mobile
user and read our new message. Following this, we will manage the admin
user inbox by marking and removing messages.

### Writing and reading messages { #webapi_writing_messages } 

The resource we need to interact with when sending and reading messages
is the *messageConversations* resource. We start by visiting the Web API
entry point at <http://play.dhis2.org/demo/api> where we find and follow
the link to the *messageConversations* resource at
<http://play.dhis2.org/demo/api/messageConversations>. The description
tells us that we can use a POST request to create a new message using
the following XML format for sending to multiple users:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <users>
    <user id="user1ID" />
    <user id="user2ID" />
    <user id="user3ID" />
  </users>
</message>
```

For sending to all users contained in one or more user groups, we can
use:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <userGroups>
    <userGroup id="userGroup1ID" />
    <userGroup id="userGroup2ID" />
    <userGroup id="userGroup3ID" />
  </userGroups>
</message>
```

For sending to all users connected to one or more organisation units, we
can use:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <organisationUnits>
    <organisationUnit id="ou1ID" />
    <organisationUnit id="ou2ID" />
    <organisationUnit id="ou3ID" />
  </organisationUnits>
</message>
```

Since we want to send a message to our friend the mobile user we need to
look up her identifier. We do so by going to the Web API entry point and
follow the link to the *users* resource at `/api/users`. We continue by
following link to the mobile user at `/api/users/PhzytPW3g2J` where we learn
that her identifier is *PhzytPW3g2J*. We are now ready to put our XML
message together to form a message where we want to ask the mobile user
whether she has reported data for January 2014:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>Mortality data reporting</subject>
  <text>Have you reported data for the Mortality data set for January 2014?</text>
  <users>
    <user id="PhzytPW3g2J" />
  </users>
</message>
```

To test this we save the XML content into a file called *message.xml*.
We use cURL to dispatch the message the DHIS2 demo instance where we
indicate that the content-type is XML and authenticate as the *admin*
user:

```bash
curl -d @message.xml "https://play.dhis2.org/demo/api/messageConversations"
  -H "Content-Type:application/xml" -u admin:district -X POST
```

A corresponding payload in JSON and POST command looks like this:

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}
```

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Content-Type:application/json" -u admin:district -X POST
```

If all is well we receive a *201 Created* HTTP status code. Also, note
that we receive a *Location* HTTP header which value informs us of the
URL of the newly created message conversation resource - this can be
used by a consumer to perform further action.

We will now pretend to be the mobile user and read the message which was
just sent by dispatching a GET request to the *messageConversations*
resource. We supply an *Accept* header with *application/xml* as the
value to indicate that we are interested in the XML resource
representation and we authenticate as the *mobile* user:

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Accept:application/xml" -u mobile:district
```

In response we get the following XML:

```xml
<messageConversations xmlns="http://dhis2.org/schema/dxf/2.0"
  link="https://play.dhis2.org/demo/api/messageConversations">
  <messageConversation name="Mortality data reporting" id="ZjHHSjyyeJ2"
    link="https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"/>
  <messageConversation name="DHIS2 version 2.7 is deployed" id="GDBqVfkmnp2"
    link="https://play.dhis2.org/demo/api/messageConversations/GDBqVfkmnp2"/>
</messageConversations>
```

From the response, we are able to read the identifier of the newly sent
message which is *ZjHHSjyyeJ2*. Note that the link to the specific
resource is embedded and can be followed in order to read the full
message. We can reply directly to an existing message conversation once we know
the URL by including the message text as the request payload. We
are now able to construct a URL for sending our reply:

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

If all went according to plan you will receive a *200 OK* status code.

In 2.30 we added an URL search parameter:

    queryString=?&queryOperator=?

The filter searches for matches in subject, text, and senders for message
conversations. The default query operator is *token*, however other operators
can be defined in the query.

### Managing messages { #webapi_managing_messages } 

As users receive and send messages, conversations will start to pile up
in their inboxes, eventually becoming laborious to track. We will now
have a look at managing a user's messages inbox by removing and marking
conversations through the Web-API. We will do so by performing some
maintenance in the inbox of the "DHIS Administrator" user.

First, let's have a look at removing a few messages from the inbox. Be
sure to note that all removal operations described here only remove the
relation between a user and a message conversation. In practical terms
this means that we are not deleting the messages themselves (or any
content for that matter) but are simply removing the message thread from
the user such that it is no longer listed in the
`/api/messageConversations` resource.

To remove a message conversation from a users inbox we need to issue a
*DELETE* request to the resource identified by the id of the message
conversation and the participating user. For example, to remove the user
with id `xE7jOejl9FI` from the conversation with id `jMe43trzrdi`:

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations/jMe43trzrdi
```

If the request was successful the server will reply with a *200 OK*. The
response body contains an XML or JSON object (according to the accept
header of the request) containing the id of the removed user.

```json
{
  "removed" : ["xE7jOejl9FI"]
}
```

On failure the returned object will contain a message payload which
describes the error.

```json
{
  "message" : "No user with uid: dMV6G0tPAEa"
}
```

The observant reader will already have noticed that the object returned
on success in our example is actually a list of ids (containing a single
entry). This is due to the endpoint also supporting batch removals. The
request is made to the same *messageConversations* resource but follows
slightly different semantics. For batch operations, the conversation ids
are given as query string parameters. The following example removes two
separate message conversations for the current user:

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm"
  -X DELETE -u admin:district
```

If you have sufficient permissions, conversations can be removed on
behalf of another user by giving an optional user id parameter.

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm&user=PhzytPW3g2J"
  -X DELETE -u admin:district
```

As indicated, batch removals will return the same message format as for
single operations. The list of removed objects will reflect successful
removals performed. Partially erroneous requests (i.e. non-existing id)
will therefore not cancel the entire batch operation.

Messages carry a boolean *read* property. This allows tracking whether a
user has seen (opened) a message or not. In a typical application
scenario (e.g. the DHIS2 web portal) a message will be marked read as
soon as the user opens it for the first time. However, users might want
to manage the read or unread status of their messages in order to keep
track of certain conversations.

Marking messages read or unread follows similar semantics as batch
removals, and also supports batch operations. To mark messages as read
we issue a *POST* to the `messageConversations/read` resource with a
request body containing one or more message ids. To mark messages as
unread we issue an identical request to the `messageConversations/unread`
resource. As is the case for removals, an optional *user* request parameter
can be given.

Let's mark a couple of messages as read by the current user:

```bash
curl "https://play.dhis2.org/dev/api/messageConversations/read"
  -d '["ZrKML5WiyFm","Gc03smoTm6q"]' -X POST
  -H "Content-Type: application/json" -u admin:district
```

The response is a *200 OK* with the following JSON body:

```json
{
  "markedRead": ["ZrKML5WiyFm", "Gc03smoTm6q"]
}
```

You can add recipients to an existing message conversation. The resource is located at:

    /api/33/messageConversations/id/recipients

The options for this resource is a list of users, user groups and
organisation units. The request should look like this:

```json
{
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}

```

### Message Attachments { #webapi_message_attachments } 

Creating messages with attachments is done in two steps: uploading the
file to the *attachments* resource, and then including one or several of
the attachment IDs when creating a new message.

A POST request to the *attachments* resource will upload the file to the
server.

```
curl -F file=@attachment.png "https://play.dhis2.org/demo/api/messageConversations/attachments"
  -u admin:district
```

The request returns an object that represents the attachment. The id of
this object must be used when creating a message in order to link the
attachment with the message.

```json
{
  "created": "2018-07-20T16:54:18.210",
  "lastUpdated": "2018-07-20T16:54:18.212",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407",
    "lastUpdated": "2018-03-09T23:06:54.512",
    "externalAccess": false,
    "displayName": "John Traore",
    "favorite": false,
    "id": "xE7jOejl9FI"
  },
  "lastUpdatedBy": {
    "id": "xE7jOejl9FI",
    "name": "John Traore"
  },
  "favorite": false,
  "id": "fTpI4GOmujz"
}
```

When creating a new message, the ids can be passed in the request body
to link the uploaded files to the message being created.

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "attachments": [
    "fTpI4GOmujz",
    "h2ZsOxMFMfq"
  ]
}
```

When replying to a message, the ids can be passed as a request
parameter.

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?attachments=fTpI4GOmujz,h2ZsOxMFMfq"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

Once a message with an attachment has been created, the attached file
can be accessed with a GET request to the following URL:

    /api/messageConversations/<mcv-id>/<msg-id>/attachments/<attachment-id>

Where <mcv-id> is the *message conversation* ID, <msg-id> is the ID of
the *message* that contains the attachment and <attachment-id> is the
ID of the specific *message attachment*.

### Tickets and Validation Result Notifications { #webapi_messaging_tickets } 

You can use the "write feedback" tool to create tickets and messages.
The only difference between a ticket and a message is that you can give
a status and a priority to a ticket. To set the status:

    POST /api/messageConversations/<uid>/status

To set the priority:

    POST /api/messageConversations/<uid>/priority

In 2.29, messages generated by validation analysis now also be used in
the status and priority properties. By default, messages generated by
validation analysis will inherit the priority of the validation rule in
question, or the highest importance if the message contains multiple
rules.

In 2.30, validation rules can be assigned to any user while tickets
still need to be assigned to a user in the system's feedback recipient
group.



Table: A list of valid status and priority values

| Statut | Priority |
|---|---|
| OPEN | LOW |
| PENDING | MEDIUM |
| INVALID | HIGH |
| SOLVED ||

You can also add an internal message to a ticket, which can only be seen
by users who have "Manage tickets" permissions. To create an internal
reply, include the "internal" parameter, and set it to

```bash
curl -d "This is an internal message"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?internal=true"
  -H "Content-Type:text/plain" -u admin:district -X POST
```




# Visualisations { #visualizations } 
## Tableaux de bord { #webapi_dashboard } 

The dashboard is designed to give you an overview of multiple analytical
items like maps, charts, pivot tables and reports which together can
provide a comprehensive overview of your data. Dashboards are available
in the Web API through the *dashboards* resource. A dashboard contains a
list of dashboard *items*. An item can represent a single resource, like
a chart, map or report table, or represent a list of links to analytical
resources, like reports, resources, tabular reports and users. A
dashboard item can contain up to eight links. Typically, a dashboard
client could choose to visualize the single-object items directly in a
user interface, while rendering the multi-object items as clickable
links.

    /api/dashboards

### Browsing dashboards { #webapi_browsing_dashboards } 

To get a list of your dashboards with basic information including
identifier, name and link in JSON format you can make a *GET* request to
the following URL:

    /api/dashboards.json

The dashboards resource will provide a list of dashboards. Remember that
the dashboard object is shared so the list will be affected by the
currently authenticated user. You can retrieve more information about a
specific dashboard by following its link, similar to this:

    /api/dashboards/vQFhmLJU5sK.json

A dashboard contains information like name and creation date and an
array of dashboard items. The response in JSON format will look similar
to this response (certain information has been removed for the sake of
brevity).

```json
{
  "lastUpdated" : "2013-10-15T18:17:34.084+0000",
  "id": "vQFhmLJU5sK",
  "created": "2013-09-08T20:55:58.060+0000",
  "name": "Mother and Child Health",
  "href": "https://play.dhis2.org/demo/api/dashboards/vQFhmLJU5sK",
  "publicAccess": "--------",
  "restrictFilters": false,
  "externalAccess": false,
  "itemCount": 17,
  "displayName": "Mother and Child Health",
  "access": {
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "read": true,
    "manage": true
  },
  "user": {
    "id": "xE7jOejl9FI",
    "name": "John Traore",
    "created": "2013-04-18T15:15:08.407+0000",
    "lastUpdated": "2014-12-05T03:50:04.148+0000",
    "href": "https://play.dhis2.org/demo/api/users/xE7jOejl9FI"
  },
  "dashboardItems": [{
    "id": "bu1IAnPFa9H",
    "created": "2013-09-09T12:12:58.095+0000",
    "lastUpdated": "2013-09-09T12:12:58.095+0000"
    }, {
    "id": "ppFEJmWWDa1",
    "created": "2013-09-10T13:57:02.480+0000",
    "lastUpdated": "2013-09-10T13:57:02.480+0000"
  }],
  "layout": {
    "spacing": {
      "column": 5,
      "row": 5
    },
    "columns": [{
      "index": 0,
      "span": 2
    }, {
      "index": 1,
      "span": 1
    }]
  },
  "userGroupAccesses": []
}
```

A more tailored response can be obtained by specifying specific fields
in the request. An example is provided below, which would return more
detailed information about each object on a users dashboard.

    /api/dashboards/vQFhmLJU5sK/?fields=:all,dashboardItems[:all]

### Searching dashboards { #webapi_searching_dasboards } 

When a user is building a dashboard it is convenient
to be able to search for various analytical resources using the
*/dashboards/q* resource. This resource lets you search for matches on
the name property of the following objects: visualizations, eventVisualizations maps,
users, reports and resources. You can do a search by making a *GET*
request on the following resource URL pattern, where my-query should be
replaced by the preferred search query:

    /api/dashboards/q/my-query.json

For example, this query:

    /api/dashboards/q/ma?count=6&maxCount=20&max=REPORT&max=MAP

Will search for the following:

* Analytical object name contains the string "ma"
* Return up to 6 of each type
* For REPORT and MAP types, return up to 20 items



Table: dashboards/q query parameters

| Paramètre de requête | Description | Type | Par défaut |
|---|---|---|---|
| compter | The number of items of each type to return | Positive integer | 6 |
| maxCount | The number of items of max types to return | Positive integer | 25 |
| max | The type to return the maxCount for | String [MAP&#124;USER&#124;REPORT&#124;RESOURCE&#124;VISUALIZATION#124;EVENT_VISUALIZATION,EVENT_CHART,EVENT_REPORT] | N/A |

JSON and XML response formats are supported. The response in JSON format
will contain references to matching resources and counts of how many
matches were found in total and for each type of resource. It will look
similar to this:

```json
{
  "visualizations": [{
    "name": "ANC: ANC 3 Visits Cumulative Numbers",
    "id": "arf9OiyV7df",
    "type": "LINE"
  }, {
    "name": "ANC: 1st and 2rd trends Monthly",
    "id": "jkf6OiyV7el",
    "type": "PIVOT_TABLE"
  }],
  "eventVisualizations": [{
    "name": "Inpatient: Cases 5 to 15 years this year (case)",
    "id": "TIuOzZ0ID0V",
    "type": "LINE_LIST"
  }, {
    "name": "Inpatient: Cases last quarter (case)",
    "id": "R4wAb2yMLik",
    "type": "LINE_LIST"
  }],
  "maps": [{
    "name": "ANC: 1st visit at facility (fixed) 2013",
    "id": "YOEGBvxjAY0"
  }, {
    "name": "ANC: 3rd visit coverage 2014 by district",
    "id": "ytkZY3ChM6J"
  }],
  "reports": [{
    "name": "ANC: 1st Visit Cumulative Chart",
    "id": "Kvg1AhYHM8Q"
  }, {
    "name": "ANC: Coverages This Year",
    "id": "qYVNH1wkZR0"
  }],
  "searchCount": 8,
  "visualizationCount": 2,
  "eventVisualizationCount": 2,
  "mapCount": 2,
  "reportCount": 2,
  "userCount": 0,
  "eventReports": 0,
  "eventCharts" :0,
  "resourceCount": 0
}
```

### Creating, updating and removing dashboards { #webapi_creating_updating_removing_dashboards } 

Creating, updating and deleting dashboards follow standard REST
semantics. In order to create a new dashboard you can make a *POST*
request to the `/api/dashboards` resource. From a consumer perspective
it might be convenient to first create a dashboard and later add items
to it. JSON and XML formats are supported for the request payload. To
create a dashboard with the name "My dashboard" you can use a payload in
JSON like this:

    {
      "name": "My dashboard"
    }

To update, e.g. rename, a dashboard, you can make a *PUT* request with a
similar request payload the same api/dashboards resource.

To remove a dashboard, you can make a *DELETE* request to the specific
dashboard resource similar to this:

    /api/dashboards/vQFhmLJU5sK

### Adding, moving and removing dashboard items and content { #webapi_adding_moving_removing_dashboard_items } 

In order to add dashboard items a consumer can use the
`/api/dashboards/<dashboard-id>/items/content` resource, where
<dashboard-id\> should be replaced by the relevant dashboard
identifier. The request must use the *POST* method. The URL syntax and
parameters are described in detail in the following table.



Table: Items content parameters

| Paramètre de requête | Description | Options |
|---|---|---|
| type | Type of the resource to be represented by the dashboard item | visualization &#124; map &#124; eventVisualization &#124; users &#124; reports &#124; resources &#124; app |
| identifiant | Identifier of the resource to be represented by the dashboard item | Resource identifier |

A *POST* request URL for adding a visualization to a specific dashboard could look like this, where the last id query parameter value is the chart resource identifier:

    /api/dashboards/vQFhmLJU5sK/items/content?type=visualization&id=LW0O27b7TdD

When adding resource of type map, visualization and app, the API
will create and add a new item to the dashboard. When adding a resource
of type users, reports and resources, the API will try to
add the resource to an existing dashboard item of the same type. If no
item of same type or no item of same type with less than eight resources
associated with it exists, the API will create a new dashboard item and
add the resource to it.

In order to move a dashboard item to a new position within the list of
items in a dashboard, a consumer can make a *POST* request to the
following resource URL, where `<dashboard-id>` should be replaced by the
identifier of the dashboard, `<item-id>` should be replaced by the
identifier of the dashboard item and `<index>` should be replaced by the
new position of the item in the dashboard, where the index is
zero-based:

    /api/dashboards/<dashboard-id>/items/<item-id>/position/<index>

To remove a dashboard item completely from a specific dashboard a
consumer can make a *DELETE* request to the below resource URL, where
`<dashboard-id>` should be replaced by the identifier of the dashboard
and `<item-id>` should be replaced by the identifier of the dashboard
item. The dashboard item identifiers can be retrieved through a GET
request to the dashboard resource URL.

    /api/dashboards/<dashboard-id>/items/<item-id>

To remove a specific content resource within a dashboard item a consumer
can make a *DELETE* request to the below resource URL, where
`<content-resource-id>` should be replaced by the identifier of a
resource associated with the dashboard item; e.g. the identifier of a
report or a user. For instance, this can be used to remove a single
report from a dashboard item of type reports, as opposed to removing the
dashboard item completely:

    /api/dashboards/<dashboard-id>/items/<item-id>/content/<content-resource-id>

### Defining a dashboard layout { #webapi_dasboard_layout } 

You can define and save a layout for each dashboard. The following object is responsible to hold this setting.

    {
      "layout": {
        "spacing": {
          "column": 5,
          "row": 5
        },
        "columns": [{
          "index": 0,
          "span": 2
        }, {
          "index": 1,
          "span": 1
        }]
      }
    }

The layout definition will be applied for all dashboard items related to the given dashboard, respecting layout attributes like spacing, columns, span and so on. See, below, a brief description of each attribute.

Table: Layout attributes

| Attribut | Description | Type |
|---|---|---|
| layout | This is the root object | Objet |
| spacing | Defines the spacing for specific layout components. Currently, it supports columns and rows. | Objet |
| colonnes | Stores specific parameters related to columns (at the moment, index and span) | Array of objects |

## Visualization { #webapi_visualization } 

The Visualization API is designed to help clients to interact with charts and pivot/report tables. The endpoints of this API are used by the Data Visualization application which allows the creation, configuration and management of charts and pivot tables based on the client's definitions. The main idea is to enable clients and users to have a unique and centralized API providing all types of charts and pivot tables as well as specific parameters and configuration for each type of visualization.

This API was introduced to unify both `charts` and `reportTables` APIs and entirely replace them by the `visualizations` API.

A Visualization object is composed of many attributes (some of them related to charts and others related to pivot tables), but the most important ones responsible to reflect the core information of the object are: *"id", "name", "type", "dataDimensionItems", "columns", "rows" and "filters".*

The root endpoint of the API is `/api/visualizations`, and the list of current attributes and elements are described in the table below.



Table: Visualization attributes

| Champ | Description |
|---|---|
| identifiant | The unique identifier. |
| code | A custom code to identify the Visualization. |
| nom | The name of the Visualization |
| type | The type of the Visualization. The valid types are: COLUMN, STACKED_COLUMN, BAR, STACKED_BAR, LINE, AREA, PIE, RADAR, GAUGE, YEAR_OVER_YEAR_LINE YEAR_OVER_YEAR_COLUMN, SINGLE_VALUE, PIVOT_TABLE. |
| title | A custom title. |
| subtitle | A custom subtitle. |
| Description | Defines a custom description for the Visualization. |
| créé | The date/time of the Visualization creation. |
| date de début | The beginning date used during the filtering. |
| date de fin | The ending date used during the filtering. |
| sortOrder | The sorting order of this Visualization. Integer value. |
| user | An object representing the creator of the Visualization. |
| publicAccess | Sets the permissions for public access. |
| displayDensity | The display density of the text. |
| fontSize | The font size of the text. |
| fontStyle | Custom font styles for: visualizationTitle, visualizationSubtitle, horizontalAxisTitle, verticalAxisTitle, targetLineLabel, baseLineLabel, seriesAxisLabel, categoryAxisLabel, legend. |
| relativePeriods | An object representing the relative periods used in the analytics query. |
| legendSet | An object representing the definitions for the legend. |
| legendDisplayStyle | The legend's display style. It can be: FILL or TEXT. |
| legendDisplayStrategy | The legend's display style. It can be: FIXED or BY_DATA_ITEM. |
| Type d'agrégation | Determines how the values in the pivot table are aggregated. Valid options: SUM, AVERAGE, AVERAGE_SUM_ORG_UNIT, LAST, LAST_AVERAGE_ORG_UNIT, FIRST, FIRST_AVERAGE_ORG_UNIT, COUNT, STDDEV, VARIANCE, MIN, MAX, NONE, CUSTOM or DEFAULT. |
| regressionType | A valid regression type: NONE, LINEAR, POLYNOMIAL or LOESS. |
| targetLineValue | The chart target line. Accepts a Double type. |
| targetLineLabel | The chart target line label. |
| rangeAxisLabel | The chart vertical axis (y) label/title. |
| domainAxisLabel | The chart horizontal axis (x) label/title. |
| rangeAxisMaxValue | The chart axis maximum value. Values outside of the range will not be displayed. |
| rangeAxisMinValue | The chart axis minimum value. Values outside of the range will not be displayed. |
| rangeAxisSteps | The number of axis steps between the minimum and maximum values. |
| rangeAxisDecimals | The number of decimals for the axes values. |
| baseLineValue | A chart baseline value. |
| baseLineLabel | A chart baseline label. |
| digitGroupSeparator | The digit group separator. Valid values: COMMA, SPACE or NONE. |
| topLimit | The top limit set for the Pivot table. |
| Critères de mesure | Describes the criteria applied to this measure. |
| percentStackedValues | Uses stacked values or not. More likely to be applied for graphics/charts. Boolean value. |
| noSpaceBetweenColumns | Show/hide space between columns. Boolean value. |
| regression | Indicates whether the Visualization contains regression columns. More likely to be applicable to Pivot/Report. Boolean value. |
| externalAccess | Indicates whether the Visualization is available as external read-only. Only applies when no user is logged in. Boolean value. |
| userOrganisationUnit | Indicates if the user has an organisation unit. Boolean value. |
| userOrganisationUnitChildren | Indicates if the user has a children organisation unit. Boolean value. |
| userOrganisationUnitGrandChildren | Indicates if the user has a grand children organisation unit . Boolean value. |
| reportingParams | Object used to define boolean attributes related to reporting. |
| rowTotals | Displays (or not) the row totals. Boolean value. |
| colTotals | Displays (or not) the columns totals. Boolean value. |
| rowSubTotals | Displays (or not) the row sub-totals. Boolean value. |
| colSubTotals | Displays (or not) the columns sub-totals. Boolean value. |
| cumulativeValues | Indicates whether the visualization is using cumulative values. Boolean value. |
| hideEmptyColumns (cacher les colonnes vides) | Indicates whether to hide columns with no data values. Boolean value. |
| hideEmptyRows (cacher les lignes vides) | Indicates whether to hide rows with no data values. Boolean value. |
| fixColumnHeaders | Keeps the columns' headers fixed (or not) in a Pivot Table. Boolean value. |
| fixRowHeaders | Keeps the rows' headers fixed (or not) in a Pivot Table. Boolean value. |
| completedOnly | Indicates whether to hide columns with no data values. Boolean value. |
| skipRounding (ignorer l'arrondissement des valeurs) | Apply or not rounding. Boolean value. |
| showDimensionLabels | Shows the dimension labels or not. Boolean value. |
| hideTitle | Hides the title or not. Boolean value. |
| hideSubtitle | Hides the subtitle or not. Boolean value. |
| hideLegend | Show/hide the legend. Very likely to be used by charts. Boolean value. |
| showHierarchy (afficher la hiérarchie) | Displays (or not) the organisation unit hierarchy names. Boolean value. |
| showData | Used by charts to hide or not data/values within the rendered model. Boolean value. |
| lastUpdatedBy | Object that represents the user that applied the last changes to the Visualization. |
| lastUpdated (dernière mise à jour) | The date/time of the last time the Visualization was changed. |
| favorites | List of user ids who have marked this object as a favorite. |
| subscribers | List of user ids who have subscribed to this Visualization. |
| translations | Set of available object translation, normally filtered by locale. |
| outlierAnalysis | Object responsible to keep settings related to outlier analysis. The internal attribute 'outlierMethod' supports: IQR, STANDARD_Z_SCORE, MODIFIED_Z_SCORE. The 'normalizationMethod' accepts only Y_RESIDUALS_LINEAR for now. |
| seriesKey | Styling options for and whether or not to display the series key. |
| légende | Options for and whether or not to apply legend colors to the chart series. |

### Retrieving visualizations { #webapi_visualization_retrieving_visualizations } 

To retrieve a list of all existing visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared visualizations plus your private ones.

    GET /api/visualizations.json

If you want to retrieve the JSON definition of a specific Visualization you can add its respective identifier to the URL:

    GET /api/visualizations/hQxZGXqnLS9.json

The following representation is an example of a response in JSON format (for brevity, certain information has been removed). For the complete schema, please use `GET /api/schemas/visualization`.

```json
{
  "lastUpdated": "2020-02-06T11:57:09.678",
  "href": "http://my-domain/dhis/api/visualizations/hQxZGXqnLS9",
  "id": "hQxZGXqnLS9",
  "created": "2017-05-19T17:22:00.785",
  "name": "ANC: ANC 1st visits last 12 months cumulative values",
  "publicAccess": "rw------",
  "userOrganisationUnitChildren": false,
  "type": "LINE",
  "access": {},
  "reportingParams": {
    "parentOrganisationUnit": false,
    "reportingPeriod": false,
    "organisationUnit": false,
    "grandParentOrganisationUnit": false
  },
  "dataElementGroupSetDimensions": [],
  "attributeDimensions": [],
  "yearlySeries": [],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "title": {
        "textMode": "CUSTOM",
        "text": "Any Title"
      }
    }
  ],
  "filterDimensions": [
    "dx"
  ],
  "columns": [
    {
      "id": "ou"
    }
  ],
  "dataElementDimensions": [],
  "categoryDimensions": [],
  "rowDimensions": [
    "pe"
  ],
  "columnDimensions": [
    "ou"
  ],
  "dataDimensionItems": [
    {
      "dataDimensionItemType": "DATA_ELEMENT",
      "dataElement": {
        "id": "fbfJHSPpUQD"
      }
    }
  ],
  "filters": [
    {
      "id": "dx"
    }
  ],
  "rows": [
    {
      "id": "pe"
    }
  ]
}
```
A more tailored response can be obtained by specifying, in the URL, the fields you want to extract. Ie.:

    GET /api/visualizations/hQxZGXqnLS9.json?fields=interpretations

will return

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### Creating, updating and removing visualizations { #webapi_visualization_add_update_remove_visualizations } 

These operations follow the standard *REST* semantics. A new Visualization can be created through a `POST` request to the `/api/visualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
  "columns": [
    {
      "dimension": "J5jldMd8OHv",
      "items": [
        {
          "name": "CHP",
          "id": "uYxK4wmcPqA",
          "displayName": "CHP",
          "displayShortName": "CHP",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        },
        {
          "name": "Hospital",
          "id": "tDZVQ1WtwpA",
          "displayName": "Hospital",
          "displayShortName": "Hospital",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        }
      ]
    }
  ],
  "rows": [
    {
      "dimension": "SooXFOUnciJ",
      "items": [
        {
          "name": "DOD",
          "id": "B0bjKC0szQX",
          "displayName": "DOD",
          "displayShortName": "DOD",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        },
        {
          "name": "CDC",
          "id": "OK2Nr4wdfrZ",
          "displayName": "CDC",
          "displayShortName": "CDC",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        }
      ]
    }
  ],
  "filters": [
    {
      "dimension": "ou",
      "items": [
        {
          "name": "Sierra Leone",
          "id": "ImspTQPwCqd",
          "displayName": "Sierra Leone",
          "displayShortName": "Sierra Leone",
          "dimensionItemType": "ORGANISATION_UNIT"
        },
        {
          "name": "LEVEL-1",
          "id": "LEVEL-H1KlN4QIauv",
          "displayName": "LEVEL-1"
        }
      ]
    }
  ],
  "name": "HIV Cases Monthly",
  "description": "Cases of HIV across the months",
  "category": "XY1vwCQskjX",
  "showDimensionLabels": true,
  "hideEmptyRows": true,
  "hideEmptyColumns": true,
  "skipRounding": true,
  "aggregationType": "SUM",
  "regressionType": "LINEAR",
  "type": "PIVOT_TABLE",
  "numberType": "VALUE",
  "measureCriteria": "Some criteria",
  "showHierarchy": true,
  "completedOnly": true,
  "displayDensity": "NORMAL",
  "fontSize": "NORMAL",
  "digitGroupSeparator": "SPACE",
  "legendDisplayStyle": "FILL",
  "legendDisplayStrategy": "FIXED",
  "hideEmptyRowItems": "BEFORE_FIRST_AFTER_LAST",
  "fixColumnHeaders": true,
  "fixRowHeaders": false,
  "regression": false,
  "cumulative": true,
  "sortOrder": 1,
  "topLimit": 2,
  "rowTotals": true,
  "colTotals": true,
  "hideTitle": true,
  "hideSubtitle": true,
  "hideLegend": true,
  "showData": true,
  "percentStackedValues": true,
  "noSpaceBetweenColumns": true,
  "rowSubTotals": true,
  "colSubTotals": true,
  "userOrgUnitType": "TEI_SEARCH",
  "externalAccess": false,
  "publicAccess": "--------",
  "reportingParams": {
    "reportingPeriod": true,
    "organisationUnit": true,
    "parentOrganisationUnit": true,
    "grandParentOrganisationUnit": true
  },
  "parentGraphMap": {
    "ImspTQPwCqd": ""
  },
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": false,
    "write": true,
    "manage": false
  },
  "optionalAxes": [
    {
      "dimensionalItem": "fbfJHSPpUQD",
      "axis": 1
    },
    {
      "dimensionalItem": "cYeuwXTCPkU",
      "axis": 2
    }
  ],
  "relativePeriods": {
    "thisYear": false,
    "quartersLastYear": true,
    "last52Weeks": false,
    "thisWeek": false,
    "lastMonth": false,
    "last14Days": false,
    "biMonthsThisYear": false,
    "monthsThisYear": false,
    "last2SixMonths": false,
    "yesterday": false,
    "thisQuarter": false,
    "last12Months": false,
    "last5FinancialYears": false,
    "thisSixMonth": false,
    "lastQuarter": false,
    "thisFinancialYear": false,
    "last4Weeks": false,
    "last3Months": false,
    "thisDay": false,
    "thisMonth": false,
    "last5Years": false,
    "last6BiMonths": false,
    "last4BiWeeks": false,
    "lastFinancialYear": false,
    "lastBiWeek": false,
    "weeksThisYear": false,
    "last6Months": false,
    "last3Days": false,
    "quartersThisYear": false,
    "monthsLastYear": false,
    "lastWeek": false,
    "last7Days": false,
    "thisBimonth": false,
    "lastBimonth": false,
    "lastSixMonth": false,
    "thisBiWeek": false,
    "lastYear": false,
    "last12Weeks": false,
    "last4Quarters": false
  },
  "user": {},
  "yearlySeries": [
    "THIS_YEAR"
  ],
  "userGroupAccesses": [
    {
      "access": "rwx-----",
      "userGroupUid": "ZoHNWQajIoe",
      "displayName": "Bo District M&E officers",
      "id": "ZoHNWQajIoe"
    }
  ],
  "userAccesses": [
    {
      "access": "--------",
      "displayName": "John Barnes",
      "id": "DXyJmlo9rge",
      "userUid": "DXyJmlo9rge"
    }
  ],
  "legendSet": {
    "name": "Death rate up",
    "id": "ham2eIDJ9k6",
    "legends": [
      {
        "startValue": 1,
        "endValue": 2,
        "color": "red",
        "image": "some-image"
      },
      {
        "startValue": 2,
        "endValue": 3,
        "color": "blue",
        "image": "other-image"
      }
    ]
  },
  "outlierAnalysis": {
    "enabled": true,
    "outlierMethod": "IQR",
    "thresholdFactor": 1.5,
    "normalizationMethod": "Y_RESIDUALS_LINEAR",
    "extremeLines": {
      "enabled": true,
      "value": 3.5
    }
  },
  "legend": {
    "strategy": "FIXED",
    "style": "FILL",
    "set": {
      "id": "fqs276KXCXi",
      "displayName": "ANC Coverage"
    },
    "showKey": false
  },
  "seriesKey": {
    "hidden": true,
    "label": {
      "fontStyle": {
        "textColor": "#cccddd"
      }
    }
  },
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ]
}
```

To update a specific Visualization, you can send a `PUT` request to the same `/api/visualizations` resource with a similar payload `PLUS` the respective Visualization's identifier, ie.:

    PUT /api/visualizations/hQxZGXqnLS9

Finally, to delete an existing Visualization, you can make a `DELETE` request specifying the identifier of the Visualization to be removed, as shown:

    DELETE /api/visualizations/hQxZGXqnLS9

## Event visualization { #webapi_event_visualization } 
<!--DHIS2-SECTION-ID:webapi_event_visualization-->
The EventVisualization API is designed to help clients to interact with event charts and reports. The endpoints of this API are used by the Event Visualization application which allows the creation, configuration and management of charts and reports based on the client's definitions. The main idea is to enable clients and users to have a unique and centralized API providing all types of event charts and reports as well as specific parameters and configuration for each type of event visualization.
This API was introduced with the expectation to unify both `eventCharts` and `eventReports` APIs and entirely replace them in favour of the `eventVisualizations` API (which means that the usage of `eventCharts` and `eventReports` APIs should be avoided). In summary, the following resources/APIs:
    /api/eventCharts, /api/eventReports
*are being replaced by*
    /api/eventVisualizations

> **Note**
>
> New applications and clients should avoid using the `eventCharts` and `eventReports` APIs because they are deprecated. Use the `eventVisualizations` API instead.

An EventVisualization object is composed of many attributes (some of them related to charting and others related to reporting), but the most important ones responsible to reflect the core information of the object are: *"id", "name", "type", "dataDimensionItems", "columns", "rows" and "filters".*
The root endpoint of the API is `/api/eventVisualizations`, and the list of current attributes and elements are described in the table below.



Table: EventVisualization attributes

| Champ | Description |
|---|---|
| identifiant | The unique identifier. |
| code | A custom code to identify the EventVisualiation. |
| nom | The name of the EventVisualiation |
| type | The type of the EventVisualiation. The valid types are: COLUMN, STACKED_COLUMN, BAR, STACKED_BAR, LINE, LINE_LIST, AREA, STACKED_AREA, PIE, RADAR, GAUGE, YEAR_OVER_YEAR_LINE, YEAR_OVER_YEAR_COLUMN, SINGLE_VALUE, PIVOT_TABLE, SCATTER, BUBBLE. |
| title | A custom title. |
| subtitle | A custom subtitle. |
| Description | Defines a custom description for the EventVisualiation. |
| créé | The date/time of the EventVisualiation creation. |
| date de début | The beginning date used during the filtering. |
| date de fin | The ending date used during the filtering. |
| sortOrder | The sorting order of this EventVisualiation. Integer value. |
| user | An object representing the creator of the Visualization. |
| publicAccess | Sets the permissions for public access. |
| displayDensity | The display density of the text. |
| fontSize | The font size of the text. |
| relativePeriods | An object representing the relative periods used in the analytics query. |
| legendSet | An object representing the definitions for the legend. |
| legendDisplayStyle | The legend's display style. It can be: FILL or TEXT. |
| legendDisplayStrategy | The legend's display style. It can be: FIXED or BY_DATA_ITEM. |
| Type d'agrégation | Determines how the values are aggregated (if applicable). Valid options: SUM, AVERAGE, AVERAGE_SUM_ORG_UNIT, LAST, LAST_AVERAGE_ORG_UNIT, FIRST, FIRST_AVERAGE_ORG_UNIT, COUNT, STDDEV, VARIANCE, MIN, MAX, NONE, CUSTOM or DEFAULT. |
| regressionType | A valid regression type: NONE, LINEAR, POLYNOMIAL or LOESS. |
| targetLineValue | The chart target line. Accepts a Double type. |
| targetLineLabel | The chart target line label. |
| rangeAxisLabel | The chart vertical axis (y) label/title. |
| domainAxisLabel | The chart horizontal axis (x) label/title. |
| rangeAxisMaxValue | The chart axis maximum value. Values outside of the range will not be displayed. |
| rangeAxisMinValue | The chart axis minimum value. Values outside of the range will not be displayed. |
| rangeAxisSteps | The number of axis steps between the minimum and maximum values. |
| rangeAxisDecimals | The number of decimals for the axes values. |
| baseLineValue | A chart baseline value. |
| baseLineLabel | A chart baseline label. |
| digitGroupSeparator | The digit group separator. Valid values: COMMA, SPACE or NONE. |
| topLimit | The top limit set for the Pivot table. |
| Critères de mesure | Describes the criteria applied to this measure. |
| percentStackedValues | Uses stacked values or not. More likely to be applied for graphics/charts. Boolean value. |
| noSpaceBetweenColumns | Show/hide space between columns. Boolean value. |
| externalAccess | Indicates whether the EventVisualization is available as external read-only. Boolean value. |
| userOrganisationUnit | Indicates if the user has an organisation unit. Boolean value. |
| userOrganisationUnitChildren | Indicates if the user has a children organisation unit. Boolean value. |
| userOrganisationUnitGrandChildren | Indicates if the user has a grand children organisation unit. Boolean value. |
| rowTotals | Displays (or not) the row totals. Boolean value. |
| colTotals | Displays (or not) the columns totals. Boolean value. |
| rowSubTotals | Displays (or not) the row sub-totals. Boolean value. |
| colSubTotals | Displays (or not) the columns sub-totals. Boolean value. |
| cumulativeValues | Indicates whether the EventVisualization is using cumulative values. Boolean value. |
| hideEmptyRows (cacher les lignes vides) | Indicates whether to hide rows with no data values. Boolean value. |
| completedOnly | Indicates whether to hide columns with no data values. Boolean value. |
| showDimensionLabels | Shows the dimension labels or not. Boolean value. |
| hideTitle | Hides the title or not. Boolean value. |
| hideSubtitle | Hides the subtitle or not. Boolean value. |
| showHierarchy (afficher la hiérarchie) | Displays (or not) the organisation unit hierarchy names. Boolean value. |
| showData | Used by charts to hide or not data/values within the rendered model. Boolean value. |
| lastUpdatedBy | Object that represents the user that applied the last changes to the EventVisualization. |
| lastUpdated (dernière mise à jour) | The date/time of the last time the EventVisualization was changed. |
| favorites | List of user ids who have marked this object as a favorite. |
| subscribers | List of user ids who have subscribed to this EventVisualization. |
| translations | Set of available object translation, normally filtered by locale. |
| de paludisme) ». | The program associated. |
| Étape du programme | The program stage associated. |
| programStatus | The program status. It can be ACTIVE, COMPLETED, CANCELLED. |
| eventStatus | The event status. It can be ACTIVE, COMPLETED, VISITED, SCHEDULE, OVERDUE, SKIPPED. |
| dataType | The event data type. It can be AGGREGATED_VALUES or EVENTS. |
| columnDimensions | The dimensions defined for the columns. |
| rowDimensions | The dimensions defined for the rows. |
| filterDimensions | The dimensions defined for the filters. |
| outputType | Indicates output type of the EventVisualization. It can be EVENT, ENROLLMENT or TRACKED_ENTITY_INSTANCE. |
| collapseDataDimensions | Indicates whether to collapse all data dimensions into a single dimension. Boolean value. |
| hideNaData | Indicates whether to hide N/A data. Boolean value. |

### Retrieving event visualizations { #webapi_event_visualization_retrieving_event_visualizations } 
<!--DHIS2-SECTION-ID:webapi_event_visualization_retrieving_event_visualizations-->
To retrieve a list of all existing event visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared event visualizations plus your private ones.
    GET /api/eventVisualizations.json
If you want to retrieve the JSON definition of a specific EventVisualization you can add its respective identifier to the URL:
    GET /api/eventVisualizations/hQxZGXqnLS9.json
The following representation is an example of a response in JSON format (for brevity, certain information has been removed). For the complete schema, please use `GET /api/schemas/eventVisualization`.

```json
{
    "lastUpdated": "2021-11-25T17:18:03.834",
    "href": "http://localhost:8080/dhis/api/eventVisualizations/EZ5jbRTxRGh",
    "id": "EZ5jbRTxRGh",
    "created": "2021-11-25T17:18:03.834",
    "name": "Inpatient: Mode of discharge by facility type this year",
    "publicAccess": "rw------",
    "userOrganisationUnitChildren": false,
    "type": "STACKED_COLUMN",
    "subscribed": false,
    "userOrganisationUnit": false,
    "rowSubTotals": false,
    "cumulativeValues": false,
    "showDimensionLabels": false,
    "sortOrder": 0,
    "favorite": false,
    "topLimit": 0,
    "collapseDataDimensions": false,
    "userOrganisationUnitGrandChildren": false,
    "displayName": "Inpatient: Mode of discharge by facility type this year",
    "percentStackedValues": false,
    "noSpaceBetweenColumns": false,
    "showHierarchy": false,
    "hideTitle": false,
    "showData": true,
    "hideEmptyRows": false,
    "hideNaData": false,
    "regressionType": "NONE",
    "completedOnly": false,
    "colTotals": false,
    "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {},
      "public": "rw------"
    },
    "programStatus": "CANCELLED",
    "hideEmptyRowItems": "NONE",
    "hideSubtitle": false,
    "outputType": "EVENT",
    "hideLegend": false,
    "externalAccess": false,
    "colSubTotals": false,
    "rowTotals": false,
    "digitGroupSeparator": "SPACE",
    "program": {
      "id": "IpHINAT79UW"
    },
    "access": {
      "read": true,
      "update": true,
      "externalize": true,
      "delete": true,
      "write": true,
      "manage": true
    },
    "lastUpdatedBy": {
      "displayName": "John Traore",
      "name": "John Traore",
      "id": "xE7jOejl9FI",
      "username": "admin"
    },
    "relativePeriods": {
      "thisYear": false,
      ...
    },
    "programStage": {
      "id": "A03MvHHogjR"
    },
    "createdBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "attributeDimensions": [],
    "translations": [],
    "filterDimensions": [
      "ou",
      "H6uSAMO5WLD"
    ],
    "interpretations": [],
    "userGroupAccesses": [],
    "subscribers": [],
    "columns": [
      {
        "id": "X8zyunlgUfM"
      }
    ]
    "periods": [],
    "categoryDimensions": [],
    "rowDimensions": [
      "pe"
    ],
    "itemOrganisationUnitGroups": [],
    "programIndicatorDimensions": [],
    "attributeValues": [],
    "columnDimensions": [
      "X8zyunlgUfM"
    ],
    "userAccesses": [],
    "favorites": [],
    "dataDimensionItems": [],
    "categoryOptionGroupSetDimensions": [],
    "organisationUnitGroupSetDimensions": [],
    "organisationUnitLevels": [],
    "organisationUnits": [
      {
        "id": "ImspTQPwCqd"
      }
    ],
    "filters": [
      {
        "id": "ou"
      },
      {
        "id": "H6uSAMO5WLD"
      }
    ],
    "rows": [
      {
        "id": "pe"
      }
    ]
}
```

A more tailored response can be obtained by specifying, in the URL, the fields you want to extract. Ie.:
    GET /api/eventVisualizations/hQxZGXqnLS9.json?fields=interpretations
will return

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### Creating, updating and removing event visualizations { #webapi_event_visualization_add_update_remove_event_visualizations } 
<!--DHIS2-SECTION-ID:webapi_event_visualization_add_update_remove_event_visualizations-->
These operations follow the standard *REST* semantics. A new EventVisualization can be created through a `POST` request to the `/api/eventVisualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
    "name": "Inpatient: Cases under 10 years last 4 quarters",
    "publicAccess": "rw------",
    "userOrganisationUnitChildren": false,
    "type": "STACKED_COLUMN",
    "subscribed": false,
    "userOrganisationUnit": false,
    "rowSubTotals": false,
    "cumulativeValues": false,
    "showDimensionLabels": false,
    "sortOrder": 0,
    "favorite": false,
    "topLimit": 0,
    "collapseDataDimensions": false,
    "userOrganisationUnitGrandChildren": false,
    "displayName": "Inpatient: Cases under 10 years last 4 quarters",
    "percentStackedValues": false,
    "noSpaceBetweenColumns": false,
    "showHierarchy": false,
    "hideTitle": false,
    "showData": true,
    "hideEmptyRows": false,
    "userAccesses": [],
    "userGroupAccesses": [],
    "hideNaData": false,
    "regressionType": "NONE",
    "completedOnly": false,
    "colTotals": false,
    "programStatus": "CANCELLED",
    "sharing": {
      "owner": "GOLswS44mh8",
      "external": false,
      "users": {},
      "userGroups": {},
      "public": "rw------"
    },
    "displayFormName": "Inpatient: Cases under 10 years last 4 quarters",
    "hideEmptyRowItems": "NONE",
    "hideSubtitle": false,
    "outputType": "EVENT",
    "hideLegend": false,
    "externalAccess": false,
    "colSubTotals": false,
    "rowTotals": false,
    "digitGroupSeparator": "SPACE",
    "access": {
      "read": true,
      "update": true,
      "externalize": false,
      "delete": true,
      "write": true,
      "manage": true
    },
    "lastUpdatedBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "relativePeriods": {
      "thisYear": false,
    ...
    },
    "program": {
      "id": "IpHINAT79UW",
      "enrollmentDateLabel": "Date of enrollment",
      "incidentDateLabel": "Date of birth",
      "name": "Child Programme"
    },
    "programStage": {
      "id": "A03MvHHogjR",
      "executionDateLabel": "Report date",
      "name": "Birth"
    },
    "createdBy": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "user": {
      "displayName": "Tom Wakiki",
      "name": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "username": "system"
    },
    "translations": [],
    "filterDimensions": [
      "ou"
    ],
    "interpretations": [],
    "dataElementDimensions": [
      {
        "filter": "LE:10",
        "dataElement": {
          "id": "qrur9Dvnyt5"
        }
      }
    ],
    "periods": [],
    "categoryDimensions": [],
    "rowDimensions": [
      "pe"
    ],
    "columnDimensions": [
      "qrur9Dvnyt5"
    ],
    "organisationUnits": [
      {
        "id": "ImspTQPwCqd"
      }
    ],
    "filters": [
      {
        "dimension": "ou",
        "items": [
          {
            "id": "ImspTQPwCqd"
          }
        ]
      },
      {
        "dimension": "H6uSAMO5WLD",
        "items": []
      }
    ],
    "columns": [
      {
        "dimension": "X8zyunlgUfM",
        "items": [],
        "repetition": {
          "indexes": [1, 2, 3, -2, -1, 0]
        }
      },
      {
        "dimension": "eventDate",
        "items": [
          {
            "id": "2021-07-21_2021-08-01"
          },
          {
            "id": "2021-01-21_2021-02-01"
          }
        ]
      },
      {
        "dimension": "incidentDate",
        "items": [
          {
            "id": "2021-10-01_2021-10-30"
          }
        ]
      },
      {
        "dimension": "eventStatus",
        "items": [
          {
            "id": "ACTIVE"
          },
          {
            "id": "COMPLETED"
          }
        ]
      },
      {
        "dimension": "createdBy",
        "items": [
          {
            "id": "userA"
          }
        ]
      },
      {
        "dimension": "lastUpdatedBy",
        "items": [
          {
            "id": "userB"
          }
        ]
      }
    ],
    "rows": [
      {
        "dimension": "pe",
        "items": [
          {
              "id": "LAST_12_MONTHS"
          }
        ]
      }
    ]
}
```

> **Note**
>
> The `repetition` attribute (in `rows`, `columns` or `filters`) indicates the events indexes to be retrieved. Taking the example above (in the previous `json` payload), it can be read as follows:
> 
    1 = First event
    2 = Second event
    3 = Third event
    ...
    -2 = Third latest event
    -1 = Second latest event
    0 = Latest event (default)

To update a specific EventVisualization, you can send a `PUT` request to the same `/api/eventVisualizations` resource with a similar payload `PLUS` the respective EventVisualization's identifier, ie.:
    PUT /api/eventVisualizations/hQxZGXqnLS9
Finally, to delete an existing EventVisualization, you can make a `DELETE` request specifying the identifier of the EventVisualization to be removed, as shown:
    DELETE /api/eventVisualizations/hQxZGXqnLS9

## Interprétations { #webapi_interpretations } 

For resources related to data analysis in DHIS2, such as visualizations, maps, event reports, event charts and even visualizations you can write and share data interpretations. An interpretation can be a comment, question, observation or interpretation about a data report or visualization.

    /api/interpretations

### Reading interpretations { #webapi_reading_interpretations } 

To read interpretations we will interact with the
`/api/interpretations` resource. A typical GET request using field
filtering can look like this:

    GET /api/interpretations?fields=*,comments[id,text,user,mentions]

The output in JSON response format could look like below (additional
fields omitted for brevity):

```json
{
  "interpretations": [
    {
      "id": "XSHiFlHAhhh",
      "created": "2013-05-30T10:24:06.181+0000",
      "text": "Data looks suspicious, could be a data entry mistake.",
      "type": "MAP",
      "likes": 2,
      "user": {
        "id": "uk7diLujYif"
      },
      "reportTable": {
        "id": "LcSxnfeBxyi"
      },
      "visualization": {
        "id": "LcSxnfeBxyi"
      }
    }, {
      "id": "kr4AnZmYL43",
      "created": "2013-05-29T14:47:13.081+0000",
      "text": "Delivery rates in Bo looks high.",
      "type": "VISUALIZATION",
      "likes": 3,
      "user": {
        "id": "uk7diLujYif"
      },
      "visualization": {
        "id": "HDEDqV3yv3H"
      },
      "mentions": [
        {
          "created": "2018-06-25T10:25:54.498",
          "username": "boateng"
        }
      ],
      "comments": [
        {
          "id": "iB4Etq8yTE6",
          "text": "This report indicates a surge.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "iB4Etq8yTE6",
          "text": "Likely caused by heavy rainfall.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "SIjkdENan8p",
          "text": "Have a look at this @boateng.",
          "user": {
            "id": "xE7jOejl9FI"
          },
          "mentions": [
            {
              "created": "2018-06-25T10:03:52.316",
              "username": "boateng"
            }
          ]
        }
      ]
    }
  ]
}
```



Table: Interpretation fields

| Champ | Description |
|---|---|
| identifiant | The interpretation identifier. |
| créé | The time of when the interpretation was created. |
| type | The type of analytical object being interpreted. Valid options: VISUALIZATION, MAP, EVENT_REPORT, EVENT_CHART, EVENT_VISUALIZATION, DATASET_REPORT. |
| user | Association to the user who created the interpretation. |
| visualization | Association to the visualization if type is VISUALIZATION |
| eventVisualization | Association to the event visualization if type is EVENT_VISUALIZATION |
| map | Association to the map if type is MAP. |
| eventReport | Association to the event report is type is EVENT_REPORT. |
| eventChart | Association to the event chart if type is EVENT_CHART. |
| dataSet (ensemble de données) | Association to the data set if type is DATASET_REPORT. |
| comments | Array of comments for the interpretation. The text field holds the actual comment. |
| mentions | Array of mentions for the interpretation. A list of users identifiers. |

For all analytical objects you can append */data* to the URL to retrieve
the data associated with the resource (as opposed to the metadata). As
an example, by following the map link and appending /data one can
retrieve a PNG (image) representation of the thematic map through the
following URL:

    https://play.dhis2.org/demo/api/maps/bhmHJ4ZCdCd/data

For all analytical objects you can filter by *mentions*. To retrieve all
the interpretations/comments where a user has been mentioned you have
three options. You can filter by the interpretation mentions (mentions
in the interpretation
    description):

    GET /api/interpretations?fields=*,comments[*]&filter=mentions.username:in:[boateng]

You can filter by the interpretation comments mentions (mentions in any
comment):

    GET /api/interpretations?fields=*,comments[*]
      &filter=comments.mentions.username:in:[boateng]

You can filter by intepretations which contains the mentions either
in the interpretation or in any comment (OR junction):

    GET /api/interpretations?fields=*,comments[*]&filter=mentions:in:[boateng]

### Writing interpretations { #webapi_writing_interpretations } 

When writing interpretations you will supply the interpretation text as
the request body using a POST request with content type "text/plain".
The URL pattern looks like the below, where {object-type} refers to the
type of the object being interpreted and {object-id} refers to the
identifier of the object being interpreted.

    /api/interpretations/{object-type}/{object-id}

Valid options for object type are *visualization*, *map*,
*eventReport*, *eventChart*, *eventVisualization* and *dataSetReport*.

Some valid examples for interpretations are listed below.

> **Note**
>
> The `eventCharts` and `eventReports` APIs are deprecated. We recommend using the `eventVisualizations` API instead.

    /api/interpretations/visualization/hQxZGXqnLS9
    /api/interpretations/map/FwLHSMCejFu
    /api/interpretations/eventReport/xJmPLGP3Cde
    /api/interpretations/eventChart/nEzXB2M9YBz
    /api/interpretations/eventVisualization/nEzXB2M9YBz
    /api/interpretations/dataSetReport/tL7eCjmDIgM

As an example, we will start by writing an interpretation for the visualization with identifier *EbRN2VIbPdV*. To write visualization interpretations we will interact with the `/api/interpretations/visualization/{visualizationId}` resource.
The interpretation will be the request body. Based on this we can put
together the following request using cURL:

```bash
curl -d "This visualization shows a significant ANC 1-3 dropout" -X POST
  "https://play.dhis2.org/demo/api/interpretations/visualization/EbRN2VIbPdV" -H "Content-Type:text/plain" -u admin:district
```

Notice that the response provides a Location header with a value
indicating the location of the created interpretation. This is useful
from a client perspective when you would like to add a comment to the
interpretation.

### Updating and removing interpretations { #webapi_updating_removing_interpretations } 

To update an existing interpretation you can use a PUT request where the
interpretation text is the request body using the following URL pattern,
where {id} refers to the interpretation identifier:

    /api/interpretations/{id}

Based on this we can use curl to update the interpretation:

```bash
curl -d "This visualization shows a high dropout" -X PUT
  "https://play.dhis2.org/demo/api/interpretations/visualization/EV08iI1cJRA" -H "Content-Type:text/plain" -u admin:district
```

You can use the same URL pattern as above using a DELETE request to
remove the interpretation.

### Creating interpretation comments { #webapi_creating_interpretation_comments } 

When writing comments to interpretations you will supply the comment
text as the request body using a POST request with content type
"text/plain". The URL pattern looks like the below, where
{interpretation-id} refers to the interpretation identifier.

    /api/interpretations/{interpretation-id}/comments

Second, we will write a comment to the interpretation we wrote in the
example above. By looking at the interpretation response you will see
that a *Location* header is returned. This header tells us the URL of
the newly created interpretation and from that, we can read its
identifier. This identifier is randomly generated so you will have to
replace the one in the command below with your own. To write a comment
we can interact with the `/api/interpretations/{id}/comments`
resource like this:

```bash
curl -d "An intervention is needed" -X POST
  "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments"
  -H "Content-Type:text/plain" -u admin:district
```

### Updating and removing interpretation comments { #webapi_updating_removing_interpretation_comments } 

To updating an interpretation comment you can use a PUT request where
the comment text is the request body using the following URL pattern:

    /api/interpretations/{interpretation-id}/comments/{comment-id}

Based on this we can use curl to update the comment:

```bash
curl "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments/idAzzhVWvh2"
  -d "I agree with that." -X PUT -H "Content-Type:text/plain" -u admin:district
```

You can use the same URL pattern as above using a DELETE request to the
remove the interpretation comment.

### Liking interpretations { #webapi_liking_interpretations } 

To like an interpretation you can use an empty POST request to the
*like* resource:

    POST /api/interpretations/{id}/like

A like will be added for the currently authenticated user. A user can
only like an interpretation once.

To remove a like for an interpretation you can use a DELETE request to
the same resource as for the like operation.

The like status of an interpretation can be viewed by looking at the
regular Web API representation:

    GET /api/interpretations/{id}

The like information is found in the *likes* field, which represents the
number of likes, and the *likedBy* array, which enumerates the users who
have liked the interpretation.

```json
{
  "id": "XSHiFlHAhhh",
  "text": "Data looks suspicious, could be a data entry mistake.",
  "type": "VISUALIZATION",
  "likes": 2,
  "likedBy": [
    {
      "id": "k7Hg12fJ2f1"
    },
    {
      "id": "gYhf26fFkjFS"
    }
  ]
}
```
## SQL views { #webapi_sql_views } 

The SQL views resource allows you to create and retrieve the result set
of SQL views. The SQL views can be executed directly against the
database and render the result set through the Web API resource.

    /api/sqlViews

SQL views are useful for creating data views which may be more easily
constructed with SQL compared combining the multiple objects of the Web
API. As an example, lets assume we have been asked to provide a view of
all organization units with their names, parent names, organization unit
level and name, and the coordinates listed in the database. The view
might look something like this:

```sql
SELECT ou.name as orgunit, par.name as parent, ou.coordinates, ous.level, oul.name from organisationunit ou
INNER JOIN _orgunitstructure ous ON ou.organisationunitid = ous.organisationunitid
INNER JOIN organisationunit par ON ou.parentid = par.organisationunitid
INNER JOIN orgunitlevel oul ON ous.level = oul.level
WHERE ou.coordinates is not null
ORDER BY oul.level, par.name, ou.name
```

We will use *curl* to first execute the view on the DHIS2 server. This
is essentially a materialization process, and ensures that we have the
most recent data available through the SQL view when it is retrieved
from the server. You can first look up the SQL view from the
api/sqlViews resource, then POST using the following command:

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/execute" -X POST -u admin:district
```

The next step in the process is the retrieval of the data.The basic
structure of the URL is as follows

    http://{server}/api/sqlViews/{id}/data(.csv)

The `{server}` parameter should be replaced with your own server. The
next part of the URL `/api/sqlViews/` should be appended with the
specific SQL view identifier. Append either `data` for XML data or
`data.csv` for comma delimited values. Support response formats are
json, xml, csv, xls, html and html+css. As an example, the following
command would retrieve XML data for the SQL view defined above.

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv" -u admin:district
```

There are three types of SQL views:

  - *SQL view:* Standard SQL views.

  - *Materialized SQL view:* SQL views which are materialized, meaning
    written to disk. Needs to be updated to reflect changes in
    underlying tables. Supports criteria to filter result set.

  - *SQL queries:* Plain SQL queries. Support inline variables for
    customized queries.

### Criteria { #webapi_sql_view_criteria } 

You can do simple filtering on the columns in the result set by
appending *criteria* query parameters to the URL, using the column names
and filter values separated by columns as parameter values, on the
following format:

    /api/sqlViews/{id}/data?criteria=col1:value1&criteria=col2:value2

As an example, to filter the SQL view result set above to only return
organisation units at level 4 you can use the following
    URL:

    https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv?criteria=level:4

### Variables { #webapi_sql_view_variables } 

SQL views support variable substitution. Variable substitution is only
available for SQL view of type *query*, meaning SQL views which are not
created in the database but simply executed as regular SQL queries.
Variables can be inserted directly into the SQL query and must be on
this format:

    ${variable-key}

As an example, an SQL query that retrieves all data elements of a given
value type where the value type is defined through a variable can look
like this:

    select * from dataelement where valuetype = '${valueType}';

These variables can then be supplied as part of the URL when requested
through the *sqlViews* Web API resource. Variables can be supplied on
the following format:

    /api/sqlViews/{id}/data?var=key1:value1&var=key2:value2

An example query corresponding to the example above can look like this:

    /api/sqlViews/dI68mLkP1wN/data.json?var=valueType:int

The *valueType* variable will be substituted with the *int* value, and
the query will return data elements with int value type.

The variable parameter must contain alphanumeric characters only. The
variables must contain alphanumeric, dash, underscore and whitespace
characters only.

SQL Views of type *query* also support two system-defined variables that allow the query to access information about the user executing the view:

| variable | signifie |
| -------- | ----- |
| ${_current_user_id} | the user's database id |
| ${_current_username} | the user's username |

Values for these variables cannot be supplied as part of the URL. They are always filled with information about the user.

For example, the following SQL view of type *query* shows all the organisation units that are assigned to the user:

```sql
    select ou.path, ou.name
    from organisationunit ou_user
    join organisationunit ou on ou.path like ou_user.path || '%'
    join usermembership um on um.organisationunitid = ou_user.organisationunitid
    where um.userinfoid = ${_current_user_id}
    order by ou.path
```

### Filtering { #webapi_sql_view_filtering } 

The SQL view api supports data filtering, equal to the [metadata object
filter](#webapi_metadata_object_filter). For a complete list of filter
operators you can look at the documentation for [metadata object
filter](#webapi_metadata_object_filter).

To use filters, simply add them as parameters at the end of the request
url for your SQL view like
    this:

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:eq:2&filter=orgunit_name:ilike:bo

This request will return a result including org units with "bo" in the
name and which has org unit level 2.

The following example will return all org units with `orgunit_level` 2 or
4:

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:in:[2,4]

And last, an example to return all org units that does not start with
"Bo"

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_name:!like:Bo


## Data items { #webapi_data_items } 

This endpoint allows the user to query data related to a few different dimensional items. These items are: `INDICATOR`, `DATA_ELEMENT`, `DATA_SET`, `PROGRAM_INDICATOR`, `PROGRAM_DATA_ELEMENT`, `PROGRAM_ATTRIBUTE`. The endpoint supports only `GET` requests and, as other endpoints, can return responses in JSON or XML format.

The URL is `/api/dataItems` and as you can imagine, it is able to retrieve different objects through the same endpoint in the same `GET` request. For this reason, some queriable attributes available will differ depending on the dimensional item(s) being queried.

To understand the statement above let's have a look at the followings request examples:

1) `GET /api/dataItems?filter=dimensionItemType:eq:DATA_ELEMENT&filter=valueType:eq:TEXT`
In this example the item type `DATA_ELEMENT` has a `valueType` attribute which can be used in the query.

2) `GET /api/dataItems?pageSize=50&order=displayName:asc&filter=dimensionItemType:eq:PROGRAM_INDICATOR&filter=displayName:ilike:someName&filter=programId:eq:WSGAb5XwJ3Y`

Here, the `PROGRAM_INDICATOR` allows filtering by `programId`.

So, based on the examples `1)` and `2)` if you try filtering a `DATA_ELEMENT` by `programId` or filter a `PROGRAM_INDICATOR` by `valueType`, you should get no results.
In other words, the filter will be applied only when the attribute actually exists for the respective data item.

Another important aspect to be highlighted is that this endpoint does NOT follow the same querying standards as other existing endpoints, like [Metadata object filter](#webapi_metadata_object_filter) for example. As a consequence, it supports a smaller set of features and querying.
The main reason for that is the need for querying multiple different items that have different relationships, which is not possible using the existing filtering components (used by the others endpoints).

### Possible endpoint responses { #webapi_data_items_possible_responses } 

Base on the `GET` request/query, a few different responses are possible. Below we are summarizing each possibility.

#### Results found (HTTP status code 200) { #results-found-http-status-code-200 } 

```
{
  "pager": {
    "page": 1,
    "pageCount": 27,
    "total": 1339,
    "pageSize": 50,
    "nextPage": "https://play.dhis2.org/dev/api/36/dataItems?page=2&filter=displayName:ilike:a&filter=id:eq:nomatch&rootJunction=OR&displayName:asc=&paging=true"
  },
  "dataItems": [
    {
      "simplifiedValueType": "TEXT",
      "displayName": "TB program Gender",
      "displayShortName": "TB prog. Gen.",
      "valueType": "TEXT",
      "name": "TB program Gender",
      "shortName": ""TB prog. Gen.",
      "id": "ur1Edk5Oe2n.cejWyOfXge6",
      "programId": "ur1Edk5Oe2n",
      "dimensionItemType": "PROGRAM_ATTRIBUTE"
    },
    ...
  ]
}
```

#### Results not found (HTTP status code 200) { #results-not-found-http-status-code-200 } 

```
{
  "pager": {
    "page": 1,
    "pageCount": 1,
    "total": 0,
    "pageSize": 50
  },
  "dataItems": []
}
```

#### Invalid query (HTTP status code 409) { #invalid-query-http-status-code-409 } 

```
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Unable to parse element `INVALID_TYPE` on filter `dimensionItemType`. The values available are: [INDICATOR, DATA_ELEMENT, DATA_ELEMENT_OPERAND, DATA_SET, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE]",
  "errorCode": "E2016"
}
```

#### Unhandled error (HTTP status code 500) { #unhandled-error-http-status-code-500 } 

```
{
  "httpStatus": "Internal Server Error",
  "httpStatusCode": 500,
  "status": "ERROR"
}
```

### Pagination { #webapi_data_items_pagination } 

This endpoint also supports pagination as a default option. If needed, you can disable pagination by adding `paging=false` to the `GET` request.
ie.: `/api/dataItems?filter=dimensionItemType:in:[INDICATOR]&paging=false`.

Here is an example of a payload when the pagination is enabled. Remember that pagination is the default option and does not need to be explicitly set.

```
{
  "pager": {
    "page": 1,
    "pageCount": 20,
    "total": 969,
    "pageSize": 50,
    "nextPage": "https://play.dhis2.org/dev/api/dataItems?page=2&filter=dimensionItemType:in:[INDICATOR]"
  },
  "dataItems": [...]
}
```

> **Note**
>
> For elements where there is an associated Program, the program name should also be returned as part of the element name (as a prefix). The only exception is `Program Indicators`. We will not prefix the element name in this case, in order to keep the same behavior as existing endpoints.
>
> The /dataItems endpoint will bring only data items that are defined as aggregatable type. The current list of valid aggregatable types is:
`TEXT, LONG_TEXT`, `LETTER`, `BOOLEAN`, `TRUE_ONLY`, `NUMBER`, `UNIT_INTERVAL`, `PERCENTAGE`, `INTEGER`, `INTEGER_POSITIVE`, `INTEGER_NEGATIVE`, `INTEGER_ZERO_OR_POSITIVE`, `COORDINATE`.
>
> Even though the response returns several different attributes, the filtering can only be applied to specific ones: `displayName`, `name`, `valueType`, `id`, `dimensionItemType`, `programId`.
>
> The `order` will be considered invalid if it is set on top of `name` (ie.: order=*name:asc*) and a `filter` is set to `displayName` (ie.: filter=*displayName:ilike:aName*), and vice-versa.

### Response attributes { #webapi_data_items_response_attributes } 

Now that we have a good idea of the main features and usage of this endpoint let's have a look in the list of attributes returned in the response.



Table: Data items attributes

| Champ | Description |
|---|---|
| identifiant | The unique identifier. |
| code | A custom code to identify the dimensional item. |
| nom | The name given for the item. |
| Nom d'affichage | The display name defined. |
| nomAbrégé | The short name given for the item. |
| displayShortName | The display short name defined. |
| dimensionItemType | The dimension type. Possible types: INDICATOR, DATA_ELEMENT, REPORTING_RATE, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE. |
| Type de valeur | The item value type (more specific definition). Possitble types: TEXT, LONG_TEXT, LETTER, BOOLEAN, TRUE_ONLY, UNIT_INTERVAL, PERCENTAGE, INTEGER, INTEGER_POSITIVE, INTEGER_NEGATIVE, INTEGER_ZERO_OR_POSITIVE, COORDINATE |
| simplifiedValueType | The genereal representation of a value type. Valid values: NUMBER, BOOLEAN, DATE, FILE_RESOURCE, COORDINATE, TEXT |
| programId | The associated programId. |

## Viewing analytical resource representations { #webapi_viewing_analytical_resource_representations } 

DHIS2 has several resources for data analysis. These resources include
*maps*, *visualizations*, *eventVisualizations*, *reports* and *documents*. By visiting these resources you will retrieve information about the resource. For instance, by navigating to `/api/visualizations/R0DVGvXDUNP` the response will contain the name, last date of modification and so on for the chart. To retrieve the analytical representation, for instance, a PNG representation of the visualization, you can append */data* to all these resources. For instance, by visiting `/api/visualizations/R0DVGvXDUNP/data` the system will return a PNG image of the visualization.



Table: Analytical resources

| Resource | Description | Data URL | Resource representations |
|---|---|---|---|
| eventCharts | Graphiques d'évènements | /api/eventCharts/<identifier\>/data | png |
| maps | Cartes | /api/maps/<identifier\>/data | png |
| visualizations | Pivot tables and charts | /api/visualizations/<identifier\>/data | json &#124; jsonp &#124; html &#124; xml &#124; pdf &#124; xls &#124; csv 
| eventVisualizations | Graphiques d'évènements | /api/eventVisualizations/<identifier\>/data | png 
| png |
| reports | **SIG:**Le SIG intégré à DHIS 2 permet de présenter et d'analyser vos
données à l'aide de cartes géographiques à thèmes. Vous pouvez y
visualiser aussi bien les éléments de données que les indicateurs ; et
en supposant que vous disposiez des coordonnées de toutes vos unités
d’organisation, vous pouvez parcourir votre hiérarchie
organisationnelle et faire apparaitre des cartes pour tous les niveaux à
l’aide de polygones ou de points. Toutes les informations affichées sur
les cartes sont générées par DHIS 2 ; tout ce que vous devez faire est
de procéder à l’enregistrement des coordonnées de vos unités
d'organisation pour que les cartes deviennent disponibles. Voir le
chapitre spécifique qui traite du SIG pour obtenir plus de détails. | /api/reports/<identifier\>/data | pdf &#124; xls &#124; html |
| documents | Ressources | /api/documents/<identifier\>/data | <follows document\> |

The data content of the analytical representations can be modified by
providing a *date* query parameter. This requires that the analytical
resource is set up for relative periods for the period dimension.



Table: Data query parameters

| Paramètre de requête | Valeur | Description |
|---|---|---|
| date | Date in yyyy-MM-dd format | Basis for relative periods in report (requires relative periods) |



Table: Query parameters for png / image types (visualizations, maps)

| Paramètre de requête | Description |
|---|---|
| width | Width of image in pixels |
| height | Height of image in pixels |

Some examples of valid URLs for retrieving various analytical
representations are listed below.

    /api/visualizations/R0DVGvXDUNP/data
    /api/visualizations/R0DVGvXDUNP/data?date=2013-06-01

    /api/visualizations/jIISuEWxmoI/data.html
    /api/visualizations/jIISuEWxmoI/data.html?date=2013-01-01
    /api/visualizations/FPmvWs7bn2P/data.xls
    /api/visualizations/FPmvWs7bn2P/data.pdf

    /api/eventVisualizations/x5FVFVt5CDI/data
    /api/eventVisualizations/x5FVFVt5CDI/data.png

    /api/maps/DHE98Gsynpr/data
    /api/maps/DHE98Gsynpr/data?date=2013-07-01

    /api/reports/OeJsA6K1Otx/data.pdf
    /api/reports/OeJsA6K1Otx/data.pdf?date=2014-01-01


# Analyse  { #analytics } 

## Analyses { #webapi_analytics }

Pour accéder aux données analytiques et agrégées dans DHIS2, vous pouvez utiliser la ressource *analyse*. L'importance de la ressource "analyse" réside dans le fait qu'elle vous permet d'interroger et d'extraire des données agrégées pour toutes les dimensions de données disponibles. Par exemple, vous pouvez demander à la ressource "analyse" de vous fournir des valeurs agrégées pour un ensemble d'éléments de données, de périodes et d'unités d'organisation. Vous pouvez également récupérer les données agrégées d'une combinaison de dimensions en vous basant sur des éléments de données et des groupes d'unités d'organisation.

    /api/33/analytics

### Paramètres de requête { #webapi_analytics_query_parameters }

La ressource "analyse" vous permet de définir un ensemble de paramètres de requête :



Tableau : Paramètres de requête

| Paramètre de requête | Obligatoire | Description | Options (par défaut en premier) |
|---|---|---|---|
| dimension | Oui | Dimensions et éléments de dimension à extraire. Ils sont répétés pour chaque paramètre. | N'importe quelle dimension |
| filtre | Non | Filtres et éléments de filtre à appliquer à la requête. Ils sont répétés pour chaque paramètre. | N'importe quelle dimension |
| Type d'agrégation | Non | Type d'agrégation à utiliser dans le processus d'agrégation. | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; LAST &#124; LAST_AVERAGE_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX |
| Critères de mesure | Non | Filtres pour les données/mesures. | EQ &#124; GT &#124; GE &#124; LT &#124; LE |
| preAggregationMeasureCriteria | Non | Filtres pour les données/mesures, appliqués avant l'agrégation. | EQ &#124; GT &#124; GE &#124; LT &#124; LE |
| date de début | Non | Date de début d’une plage de dates. Elle sera appliquée comme filtre, mais ne peut pas être utilisée avec une dimension ou un filtre de période. | Date |
| date de fin | Non | Date de fin d’une plage de dates. Elle sera appliquée comme filtre, mais ne peut pas être utilisée avec une dimension ou un filtre de période. | Date |
| skipMeta (ignorer les métadonnées) | Non | Exclut la partie métadonnées de la réponse (améliore les performances) | faux &#124; vrai |
| skipData (ignorer les données) | Non | Excluez la partie données de la réponse. | faux &#124; vrai |
| skipRounding (ignorer l'arrondissement des valeurs) | Non | Évite l'arrondissement des valeurs de données, c'est-à-dire que les valeurs fournies sont très précise. | faux &#124; vrai |
| hierarchyMeta | Non | Inclut les noms des unités d'organisation racines et le parcours hiérarchique des unités d'organisation dans les métadonnées. | faux &#124; vrai |
| ignoreLimit | Non | Ignore la limite de 50 000 enregistrements maximum dans la réponse - à utiliser avec précaution. | faux &#124; vrai |
| tableLayout (présentation du tableau) | Non | Utilise une source de données simples ou une présentation de tableau pour générer la réponse. | faux &#124; vrai |
| hideEmptyRows (cacher les lignes vides) | Non | Masque les lignes vides dans la réponse ; applicable lorsque la présentation du tableau est définie sur "vrai". | faux &#124; vrai |
| hideEmptyColumns (cacher les colonnes vides) | Non | Masque les colonnes vides dans la réponse ; applicable lorsque la présentation du tableau est définie sur "vrai". | faux &#124; vrai |
| showHierarchy (afficher la hiérarchie) | Non | Affiche le parcours hiérarchique complet de l'unité d'organisation ainsi que le nom de l'unité d'organisation. | faux &#124; vrai |
| includeNumDen (inclure le numérateur et le dénominateur) | Non | Inclut dans la réponse, le numérateur et le dénominateur utilisés pour calculer la valeur. | faux &#124; vrai |
| includeMetadataDetails (inclure les détails des métadonnées) | Non | Inclut les détails des métadonnées dans la réponse générée pour les données brutes. | faux &#124; vrai |
| displayProperty (afficher la propriété) | Non | Affiche la propriété des métadonnées. | NAME &#124; SHORTNAME |
| outputIdScheme (schéma d'identification de la sortie) | Non | Schéma d'identification utilisé pour les éléments de métadonnées dans la réponse à la requête. Il accepte des identifiants, des codes ou des attributs. | UID &#124; UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| outputOrgUnitIdScheme (schéma d'identification de l'unité d'organisation de sortie)  | Non | Schéma d'identification utilisé pour les éléments de métadonnées dans la réponse à la requête. Ce paramètre remplace le "outputIdScheme" spécialement pour les unités d'organisation. Il accepte des identifiants, des codes ou des attributs. | UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| outputDataElementIdScheme (schéma d'identification de l'élément de données de sortie) | Non | Schéma d'identification utilisé pour les éléments de métadonnées dans la réponse à la requête. Ce paramètre remplace le "outputIdScheme" spécialement pour les éléments de données. Il accepte des identifiants, des codes ou des attributs. | UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| inputIdScheme | Non | Schéma d'identification à utiliser pour les éléments de métadonnées dans la requête. Il peut être un identifiant, un code ou constitué d'attributs. | UID &#124; CODE &#124; ATTRIBUTE:<ID\> |
| approvalLevel (niveau d'a | Non | Inclut les données qui ont été approuvées au moins jusqu'au niveau d'approbation spécifié. Il fait référence à l'identifiant du niveau d'approbation. | Identifiant du niveau d'approbation |
| relativePeriodDate (Date de la période relative) | Non | Date utilisée comme base pour les périodes relatives. | Date. |
| userOrgUnit (unité d'organisation d'utilisateur) | Non | Définit explicitement les unités d'organisation d'utilisateur à utiliser. Elle remplace les unités d'organisation associées à l'utilisateur actuel. Plusieurs identifiants peuvent être séparés par un point-virgule. | Identifiants d’unité d’organisation. |
| colonnes | Non | Dimensions à utiliser comme colonnes pour la présentation du tableau. | N'importe quelle dimension (doit être une dimension de requête) |
| lignes | Non | Dimensions à utiliser comme lignes pour la présentation du tableau. | N'importe quelle dimension (doit être une dimension de requête) |
| Ordre | Non | Spécifie l'ordre des lignes en fonction de la valeur. | ASC &#124; DESC |
| timeField (champ du temps) | Non | Le champ de temps sur lequel baser l'agrégation des événements. Ceci s'applique uniquement aux éléments de données d'événements. Il peut s'agir d'une option prédéfinie ou de l'ID d'un attribut ou d'un élément de données ayant une valeur temporelle. | EVENT_DATE &#124; ENROLLMENT_DATE &#124; INCIDENT_DATE &#124; DUE_DATE &#124; COMPLETED_DATE &#124; CREATED &#124; LAST_UPDATED &#124; <Attribute ID\> &#124; <Data element ID\> |
| orgUnitField (champ d'unité d'organisation) | Non | The organisation unit field to base event aggregation on. Applies to event data items only. Can be the ID of an attribute or data element with the Organisation unit value type. The default option is specified as omitting the query parameter. <Attribute ID\> &#124; <Data element ID\> | <Attribute ID\> &#124; <Data element ID\> |
| enhancedConditions (conditions améliorées)           | Non       | Active des conditions améliorées pour les dimensions/filtres | false&#124;true |

Le paramètre de requête *dimension* définit les dimensions à inclure dans la requête d'analyse. Un nombre quelconque de dimensions peut être spécifié. Le paramètre "dimension" doit être répété pour chaque dimension à inclure dans la réponse à la requête. La réponse à la requête peut éventuellement contenir des valeurs agrégées pour toutes les combinaisons des éléments de dimension spécifiés.

Le paramètre *filtre* définit les dimensions à utiliser comme filtres pour les données extraites de la requête d'analyse. Un nombre quelconque de filtres peut être spécifié. Le paramètre "filtre" doit être répété pour chaque filtre à utiliser dans la requête. La différence entre un filtre et une dimension réside dans le fait que les dimensions du filtre ne font pas partie du contenu de la réponse à la requête et que les valeurs agrégées dans la réponse sont regroupées en fonction des dimensions du filtre. En d'autres termes, les données de la réponse seront agrégées selon les dimensions du filtre, mais les filtres ne seront pas inclus en tant que dimensions dans la réponse proprement dite. Par exemple, pour lancer une requête pour certains éléments de données filtrés par les périodes et les unités d'organisation, vous pouvez utiliser l'URL suivante :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&filter=pe:2014Q1;2014Q2
      &filter=ou:O6uvpzGd5pu;lc3eMKXaEfw

Le paramètre de requête *aggregationType* (type d'agrégation) vous permet de définir l'opérateur d'agrégation à utiliser pour la requête. Par défaut, l'opérateur d'agrégation défini pour les éléments de données inclus dans la requête sera utilisé. Si votre requête ne contient aucun élément de données mais des groupes d'éléments de données, l'opérateur d'agrégation du premier élément de données du premier groupe sera utilisé. L'ordre des groupes et des éléments de données n'est pas défini. Ce paramètre de requête vous permet de remplacer l'opérateur d'agrégation par défaut et de définir un opérateur spécifique. Par exemple, vous pouvez le définir sur "count" (compter) avec l'URL suivante :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2014Q1&dimension=ou:O6uvpzGd5pu
      &aggregationType=COUNT

Le paramètre de requête *measureCriteria* (critères de mesure) vous permet de filtrer les plages d'enregistrements de données à renvoyer. Vous pouvez demander au système de ne renvoyer que les enregistrements dont les valeurs agrégées sont égales, supérieures, supérieures ou égales, inférieures ou inférieures ou égales à certaines valeurs. Vous pouvez spécifier un nombre quelconque de critères dans le format suivant, où *criteria* et *value* doivent être remplacés par des valeurs réelles :

    /api/33/analytics?measureCriteria=criteria:value;criteria:value

À titre d'exemple, la requête suivante renverra uniquement les enregistrements pour lesquels la valeur est supérieure ou égale à 6 500 et inférieure à 33 000 :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&measureCriteria=GE:6500;LT:33000

Comme pour *measureCriteria*, le paramètre de requête *preAggregationMeasureCriteria* vous permet de filtrer les données avant que l'agrégation ne soit effectuée. Par exemple, la requête suivante n'agrège que les données dont la valeur initiale correspond aux critères définis :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&preAggregationMeasureCriteria=GE:10;LT:100

Les paramètres *startDate* (date de début) et *endDate* (date de fin) peuvent être utilisés pour définir une plage de dates personnalisée pour l'agrégation. Lorsque vous définissez une plage de dates, vous ne pouvez pas définir de périodes relatives ou fixes en tant que dimension ou filtre. La plage de dates va filtrer la réponse de l'outil d'analyse. Vous pouvez l'utiliser comme ceci :

    /api/33/analytics.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=ou:ImspTQPwCqd&startDate=2018-01-01&endDate=2018-06-01

Pour que la ressource analytique génère les données sous forme d'un tableau tout fait, vous pouvez définir le paramètre *tableLayout* (présentation du tableau) en lui attribuant la valeur "true" (vrai). Au lieu de générer une source de données normalisée, la ressource analytique va maintenant générer les données dans un tableau. Vous pouvez utiliser les paramètres *columns* (colonnes) et *rows* (lignes) avec des identifiants de dimension séparés par des points-virgules en guise de valeurs pour indiquer ceux qui doivent apparaître dans les colonnes et ceux qui doivent apparaître dans les lignes du tableau. Les dimensions des colonnes et des lignes doivent être utilisées comme dimension de données dans la requête (et non comme filtre). Une telle requête peut ressembler à ceci :

    /api/33/analytics.html?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014Q1;2014Q2
      &dimension=ou:O6uvpzGd5pu&tableLayout=true&columns=dx;ou&rows=pe

Le paramètre *order* peut être utilisé pour les ressources analytiques afin de générer des données ordonnées. Les données seront classées dans l'ordre croissant (ou décroissant) des valeurs. Voici un exemple de requête permettant de classer les valeurs par ordre décroissant :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:LAST_12_MONTHS
      &dimension=ou:O6uvpzGd5pu&order=DESC

### Dimensions et éléments { #webapi_analytics_dimensions_and_items }

DHIS2 dispose d'un modèle de données multidimensionnel avec plusieurs dimensions de données fixes et dynamiques. Les dimensions fixes sont l'élément de données, la période (temps) et l'unité d'organisation. Vous pouvez ajouter des dimensions de manière dynamique par le biais de catégories, de groupes d'éléments de données et de groupes d'unités d'organisation. Le tableau ci-dessous présente les dimensions de données disponibles dans DHIS2. Chaque dimension de données a un *identifiant de dimension* et chaque dimension peut avoir un ensemble d'*éléments de dimension*:



Tableau : Dimensions et éléments de dimension

| Dimension | Identifiant de la dimension | Éléments de dimension |
|---|---|---|
| Éléments de données, indicateurs, mesures du taux de déclaration des ensembles de données, opérandes d'éléments de données, indicateurs de programme, éléments de données de programme, attributs de programme, règles de validation | dx | Élément de données, indicateur, mesures du taux de déclaration de l'ensemble de données, opérande d'élément de données, indicateur de programme, identifiants d'attribut de programme, mot clé DE_GROUP-<group-id\>, IN_GROUP-<group-id\> , utilisez <dataelement-id\>.<optioncombo-id\> pour les opérandes d'éléments de données, <program-id\>.<dataelement-id\> pour les éléments de données du programme, <program-id\>.<attribute-id\> pour les attributs du programme, <validationrule-id\> pour les résultats de validation. |
| Périodes (temps) | pe | Périodes ISO et périodes relatives, voir "format de date et de période" |
| Hiérarchie d'unités d'organisation | ou | Identifiants d'unité d'organisation et mots-clés USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> et OU_GROUP-<group-id\> |
| Combinaisons d'options de catégories | co | Identifiants des combinaisons d'options de catégorie (omettre pour obtenir tous les éléments) |
| Combinaisons d'options d'attribut | ao | Identifiants des combinaisons d'options de catégorie (omettre pour obtenir tous les éléments) |
| Catégories | <category id\> | Identifiants des options de catégorie (omettre pour obtenir tous les éléments) |
| Des ensembles de groupes d'éléments de données | <group set id\> | Identifiants des groupes d'éléments de données (omettre pour obtenir tous les éléments) |
| Ensembles de groupes d'unités d'organisation | <group set id\> | Identifiants des groupes d'unités d'organisation (omettre pour obtenir tous les éléments) |
| Ensembles de groupes d'options de catégorie | <group set id\> | Category option group identifiers (omit to get all items) |

It is not necessary to be aware of which objects are used for the
various dynamic dimensions when designing analytics queries. You can get
a complete list of dynamic dimensions by visiting this URL in the Web API:

    /api/33/dimensions

Si vous souhaitez extraire uniquement les éléments dimensionnels d'une dimension dynamique donnée, vous pouvez utiliser l'exemple ci-dessous. La pagination est désactivée par défaut. Elle peut être activée si le paramètre de pagination `paging=true` est ajouté à l'URL.

    /api/33/dimensions/J5jldMd8OHv/items?paging=true

L'URL de base de la ressource analytique est `/api/analytics`. Pour demander des dimensions et des éléments de dimension spécifiques, vous pouvez utiliser une chaîne de requête au format suivant, où `dim-id` (identifiant de la dimension) et `dim-item` (élément de dimension) doivent être remplacés par des valeurs réelles :

    /api/33/analytics?dimension=dim-id:dim-item;dim-item&dimension=dim-id:dim-item;dim-item

Comme illustré ci-dessus, l'identifiant de la dimension est suivi de deux points, tandis que les éléments de la dimension sont séparés par des points-virgules. Par exemple, une requête portant sur deux éléments de données, deux périodes et deux unités d'organisation peut être effectuée à l'aide de l'URL suivante :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2016Q1;2016Q2&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

Pour obtenir des données ventilées par combinaisons d'options de catégorie au lieu des totaux des éléments de données, vous pouvez inclure la dimension de catégorie dans la chaîne de requête. Voici une exemple :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=co&dimension=pe:201601&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

When selecting data elements you can also select all data elements in a
group as items by using the DE_GROUP-<id> syntax:

    /api/33/analytics?dimension=dx:DE_GROUP-h9cuJOkOwY2
      &dimension=pe:201601&dimension=ou:O6uvpzGd5pu

Au moment de sélectionner les taux de déclaration des ensembles de données, la syntaxe contient un identifiant d'ensemble de données suivi d'une mesure de taux de déclaration :

    /api/33/analytics?dimension=dx:BfMAe6Itzgt.REPORTING_RATE;BfMAe6Itzgt.ACTUAL_REPORTS
      &dimension=pe:201601&dimension=ou:O6uvpzGd5pu

To query for program data elements (of tracker domain type) you can get
those by specifying the program for each data element using the
<program-id>.<dataelement-id> syntax:

    /api/33/analytics.json?dimension=dx:eBAyeGv0exc.qrur9Dvnyt5;eBAyeGv0exc.GieVkTxp4HH
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

To query for program attributes (tracked entity attributes) you can get
those by specifying the program for each attribute using the
<program.id>.<attribute-id> syntax:

    /api/33/analytics.json?dimension=dx:IpHINAT79UW.a3kGcGDCuk6;IpHINAT79UW.UXz7xuGCEhU
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:ImspTQPwCqd

Pour obtenir des ensembles de groupes d'unités d'organisation et des éléments de données, vous pouvez utiliser l'URL ci-dessous. Remarquez que l'identifiant de l'ensemble de groupes est utilisé comme identifiant de dimension et les groupes comme éléments de dimension :

    /api/33/analytics?dimension=Bpx0589u8y0:oRVt7g429ZO;MAs88nJc9nL
      &dimension=pe:2016&dimension=ou:ImspTQPwCqd

Pour obtenir des éléments de données et des catégories, vous pouvez utiliser l'URL suivante. Utilisez l'identifiant de la catégorie comme identifiant de dimension et les options de la catégorie comme éléments de dimension :

    /api/33/analytics?dimension=dx:s46m5MS0hxu;fClA2Erf6IO&dimension=pe:2016
      &dimension=YNZyaJHiHYq:btOyqprQ9e8;GEqzEKCHoGA&filter=ou:ImspTQPwCqd

Pour effectuer une requête en utilisant des périodes relatives et des unités d'organisation associées à l'utilisateur actuellement connecté, vous pouvez utiliser l'URL suivante :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:LAST_12_MONTHS&dimension=ou:USER_ORGUNIT

Lorsque vous sélectionnez des unités d'organisation pour une dimension, vous pouvez utiliser la syntaxe `LEVEL-<level>` pour sélectionner un niveau entier, éventuellement limité par un nombre quelconque d'unités d'organisation limites. La limite renvoie à un nœud supérieur dans une sous-hiérarchie, ce qui signifie que toutes les unités d'organisation au niveau indiqué sous l'unité d'organisation limite indiquée dans la hiérarchie seront incluses dans la réponse et sont fournies en tant qu'éléments de dimension d'unité d'organisation ordinaires. La valeur du niveau peut être un niveau numérique ou faire référence à l'identifiant de l'entité du niveau de l'unité d'organisation. Voici une requête simple pour toutes les unités d'organisation de niveau trois :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016&dimension=ou:LEVEL-3

Une requête pour les niveaux trois et quatre avec deux unités d'organisation limites peut se présenté comme suit :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:LEVEL-3;LEVEL-4;O6uvpzGd5pu;lc3eMKXaEf

When selecting organisation units you can also select all organisation
units in an organisation unit group to be included as dimension items
using the OU_GROUP-<id> syntax. The organisation units in the groups
can optionally be constrained by any number of boundary organisation
units. Both the level and the group items can be repeated any number of
times:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:OU_GROUP-w0gFTTmsUcF;OU_GROUP-EYbopBOJWsW;O6uvpzGd5pu;lc3eMKXaEf

Vous pouvez utiliser des schémas d'identification pour la partie métadonnées de la réponse analytique avec la propriété outputIdScheme. Vous pouvez utiliser l'identifiant, le code ou les attributs comme schéma d'identification. Voici un exemple :

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2017Q1;2017Q2&dimension=ou:O6uvpzGd5pu&outputIdScheme=CODE

Quelques éléments à prendre en compte lors de l'utilisation de la ressource analytique sont répertoriés ci-dessous.

  - Éléments de données, indicateur, taux de déclaration des ensembles de données, données de programme
    et les indicateurs de programme font partie d’une dimension de données commune,
    identifié comme "dx". Cela signifie que vous pouvez utiliser n'importe quelle élément de données, 
    indicateur et identifiant d'ensemble de données avec l'identifiant 
    de dimension "dx" dans la requête.

  - Pour les dimensions "catégorie", "ensemble de groupes d'éléments de données" et "ensemble de groupes d'unités d'organisation", 
    tous les éléments de dimension seront utilisés dans la requête si
    éléments de dimension ne sont pas spécifiés.

  - Pour la dimension de période, les éléments de dimension sont des identifiants de période ISO
    et/ou des périodes relatives. Consultez la section 
    "Format de date et de période" plus haut, pour mieux comprendre le format des périodes et
    les périodes relatives disponibles.

  - Pour la dimension d'unité d'organisation, vous pouvez spécifier des éléments qui seront 
    l'unité d'organisation ou les sous-unités de l'unité d'organisation
    associée à l'utilisateur actuellement authentifié pour la requête.
    Vous pouvez le faire en utilisant respectivement les clés `USER_ORGUNIT` ou `USER_ORGUNIT_CHILDREN` comme éléments.
    Vous pouvez également spécifier des identifiants d'unité d'organisation
    ou une combinaison des deux possibilités.

  - Pour la dimension d'unité d'organisation, vous pouvez spécifier le niveau hiérarchique 
    et l'unité d'organisation limite à utiliser pour la requête en utilisant le 
    format `LEVEL-<level>-<boundary-id>` ; par exemple
    `LEVEL-3-ImspTQPwCqd` prend en compte toutes les unités d'organisation inférieures à 
    l'unité d'organisation limite au niveau 3 de la hiérarchie.

  - Pour la dimension d'unité d'organisation, les éléments de dimension sont les
    unités d'organisation et leur sous-hiérarchie - les données seront agrégées
    pour toutes les unités d'organisation situées en dessous de l'unité d'organisation spécifiée dans la 
    hiérarchie.

  - Vous ne pouvez pas spécifier d'éléments de dimension pour la dimension de combinaison 
    d'options de catégorie. En lieu et place de cela, la réponse contiendra les éléments
    associés aux valeurs de données.

### La dimension dx { #webapi_analytics_dx_dimension }

La dimension `dx` est une dimension spéciale qui peut contenir tous les types de données suivants.



Tableau : Types de dimensions de données dx

| Type | Syntaxe | Description | Source des données |
|---|---|---|---|
| Indicateur | <indicator-id\> | Identifiant de l'indicateur. | Données agrégées |
| Groupe indicateur | IN_GROUP-<indicatorgroup-id\> | Mot clé suivi d'un identifiant de groupe d'indicateurs. Inclura tous les indicateurs du groupe dans la réponse. | Données agrégées |
| Élément de données | <dataelement-id\> | Identifiant de l'élément de données. | Données agrégées |
| Groupe d'éléments de données | DE_GROUP-<dataelementgroup-id\> | Mot clé suivi d'un identifiant de groupe d'éléments de données. Inclura tous les éléments de données du groupe dans la réponse. | Données agrégées |
| Opérande de l'élément de données | <dataelement-id\>.<categoryoptcombo-id\>.<attributeoptcombo-id\> | Identifiant de l'élément de données suivi d'une combinaison d'options de catégorie et d'un identifiant de combinaison d'options d'attributs, ou des deux. Le symbole joker « \* » peut être utilisé pour indiquer n'importe quelle valeur de combinaison d'options. L'identifiant de la combinaison d'options d'attributs peut être ignoré complètement. | Données agrégées |
| Ensemble de données | <dataset-id\>.<reporting-rate-metric\> | Identifiant de l’ensemble de données suivi de la mesure du taux de déclaration. Peut être REPORTING_RATE &#124; REPORTING_RATE_ON_TIME &#124; ACTUAL_REPORTS &#124; ACTUAL_REPORTS_ON_TIME &#124; EXPECTED_REPORTS. | Enregistrements de la complétude des ensembles de données |
| Élément de données de programme | <program-id\>.<dataelement-id\> | Identifiant du programme suivi de l'identifiant de l'élément de données. Lit les événements du programme spécifié. | Événements du programme en question |
| Indicateur de programme | <programindicator-id\> | Identifiant de l’indicateur du programme. Lit les événements du programme associés à l'identifiant du programme. | Événements du programme de l'indicateur de programme |
| Résultat de validation | <validationrule-id\> | Identifiant de la règle de validation. Inclura les violations à la règle de validation et requiert que les résultats de la validation soient générés et conservés. | Résultats de validation |

Les éléments de tous les différents types `dx` peuvent être combinés dans une requête d'analyse. Voici un exemple :

    /api/33/analytics.json
      ?dimension=dx:Uvn6LCg7dVU;BfMAe6Itzgt.REPORTING_RATE;IpHINAT79UW.a3kGcGDCuk6
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

La syntaxe de groupe peut également être utilisée avec n’importe quel autre élément. Voici un exemple :

    /api/33/analytics.json
      ?dimension=dx:DE_GROUP-qfxEYY9xAl6;IN_GROUP-oehv9EO3vP7;BfMAe6Itzgt.REPORTING_RATE
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

Les opérandes d'élément de données peuvent éventuellement spécifier des combinaisons d'options d'attribut et utiliser des caractères génériques, par exemple pour spécifier toutes les valeurs des combinaisons d'options de catégorie :

    /api/33/analytics.json
      ?dimension=dx:Uvn6LCg7dVU.*.j8vBiBqGf6O;Uvn6LCg7dVU.Z4oQs46iTeR
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

> **Tip**
>
> A great way to learn how to use the analytics API is to use the DHIS2
> *pivot table* app. You can play around with pivot tables using the
> various dimensions and items and click Download > Plain data source > JSON
> to see the resulting analytics API calls in the address bar of
> your Web browser.

### Formats de réponse { #webapi_analytics_response_formats }

The analytics response containing aggregate data can be returned in
various representation formats. As usual, you can indicate interest in a
specific format by appending a file extension to the URL, through the
`Accept` HTTP header or through the `format` query parameter. The
default format is JSON. The available formats and content-types are
listed below.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

  - csv (application/csv)

  - html (text/html)

  - html+css (text/html)

  - xls (application/vnd.ms-excel)

As an example, to request an analytics response in XML format you can
use the following URL:

    /api/33/analytics.xml?dimension=dx:fbfJHSPpUQD
      &dimension=pe:2016&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

The analytics responses must be retrieved using the HTTP *GET* method.
This allows for direct linking to analytics responses from Web pages as
well as other HTTP-enabled clients. To do functional testing we can use
the cURL library. By executing this command against the demo database
you will get an analytics response in JSON format:

```bash
curl "play.dhis2.org/demo/api/analytics.json?dimension=dx:eTDtyyaSA7f;FbKK4ofIv5R
  &dimension=pe:2016Q1;2016Q2&filter=ou:ImspTQPwCqd" -u admin:district
```

The JSON response will look like this:

```json
{
  "headers": [
    {
      "name": "dx",
      "column": "Data",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "pe",
      "column": "Period",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "value",
      "column": "Value",
      "meta": false,
      "type": "java.lang.Double"
    }
  ],
  "height": 4,
  "metaData": {
    "pe": [
      "2016Q1",
      "2016Q2"
    ],
    "ou": [
      "ImspTQPwCqd"
    ],
    "names": {
      "2016Q1": "Jan to Mar 2016",
      "2016Q2": "Apr to Jun 2016",
      "FbKK4ofIv5R": "Measles Coverage <1 y",
      "ImspTQPwCqd": "Sierra Leone",
      "eTDtyyaSA7f": "Fully Immunized Coverage"
    }
  },
  "rows": [
    [
      "eTDtyyaSA7f",
      "2016Q2",
      "81.1"
    ],
    [
      "eTDtyyaSA7f",
      "2016Q1",
      "74.7"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q2",
      "88.9"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q1",
      "84.0"
    ]
  ],
  "width": 3
}
```

The response represents a table of dimensional data. The *headers* array
gives an overview of which columns are included in the table and what
the columns contain. The *column* property shows the column dimension
identifier, or if the column contains measures, the word "Value". The
*meta* property is *true* if the column contains dimension items or
*false* if the column contains a measure (aggregated data values). The
*name* property is similar to the column property, except it displays
"value" in case the column contains a measure. The *type* property
indicates the Java class type of column values.

The *height* and *width* properties indicate how many data columns and
rows are contained in the response, respectively.

The *metaData periods* property contains a unique, ordered array of the
periods included in the response. The *metaData ou* property contains an
array of the identifiers of organisation units included in the response.
The *metaData names* property contains a mapping between the identifiers
used in the data response and the names of the objects they represent.
It can be used by clients to substitute the identifiers within the data
response with names in order to give a more meaningful view of the data
table.

The *rows* array contains the dimensional data table. It contains
columns with dimension items (object or period identifiers) and a column
with aggregated data values. The example response above has a
data/indicator column, a period column and a value column. The first
column contains indicator identifiers, the second contains ISO period
identifiers and the third contains aggregated data values.

### Constraints and validation { #webapi_analytics_constraints } 

There are several constraints to the input parameters you can provide to the
analytics resource. If any of the constraints are violated, the API will
return a *409 Conflict* response and a response message looking similar to this:

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Only a single indicator can be specified as filter",
  "errorCode": "E7108"
}
```

The `httpStatus` and `httpStatusCode` fields indicate the HTTP status and
status code per the HTTP specification. The `messsage` field provides a
human-readable description of the validation error. The `errorCode` field
provides a machine-readable code which can be used by clients to handle
validation errors. The possible validation errors for the aggregate analytics
API are described in the table below.

| Code d'erreur | Message |
| ---------- | ------- |
| E7100      | Query parameters cannot be null |
| E7101      | At least one dimension must be specified |
| E7102      | At least one data dimension item or data element group set dimension item must be specified |
| E7103      | Dimensions cannot be specified as dimension and filter simultaneously |
| E7104      | At least one period as dimension or filter, or start and dates, must be specified |
| E7105      | Periods and start and end dates cannot be specified simultaneously |
| E7106      | Start date cannot be after end date |
| E7107      | Start and end dates cannot be specified for reporting rates |
| E7108      | Only a single indicator can be specified as filter |
| E7109      | Only a single reporting rate can be specified as filter |
| E7110      | Category option combos cannot be specified as filter |
| E7111      | Dimensions cannot be specified more than once |
| E7112      | Reporting rates can only be specified together with dimensions of type |
| E7113      | Assigned categories cannot be specified when data elements are not specified |
| E7114      | Assigned categories can only be specified together with data elements, not indicators or reporting rates |
| E7115      | Data elements must be of a value and aggregation type that allow aggregation |
| E7116      | Indicator expressions cannot contain cyclic references |
| E7117      | A data dimension 'dx' must be specified when output format is DATA_VALUE_SET |
| E7118      | A period dimension 'pe' must be specified when output format is DATA_VALUE_SET |
| E7119      | An organisation unit dimension 'ou' must be specified when output format is DATA_VALUE_SET |
| E7120      | User is not allowed to view org unit |
| E7121      | User is not allowed to read data for object |
| E7122      | Data approval level does not exist |
| E7123      | Current user is constrained by a dimension but has access to no dimension items |
| E7124      | Dimension is present in query without any valid dimension options |
| E7125      | Dimension identifier does not reference any dimension |
| E7126      | Column must be present as dimension in query |
| E7127      | Row must be present as dimension in query |
| E7128      | Query result set exceeded max limit |
| E7129      | Program is specified but does not exist |
| E7130      | Program stage is specified but does not exist |
| E7131      | Query failed, likely because the query timed out |

### Data value set format { #webapi_analytics_data_value_set_format } 

The analytics *dataValueSet* resource allows for returning aggregated
data in the data value set format. This format represents raw data
values, as opposed to data which has been aggregated along various
dimensions. Exporting aggregated data as regular data values is useful
for data exchange between systems when the target system contains data
of finer granularity compared to what the destination system is storing.

As an example, one can specify an indicator in the target system to
summarize data for multiple data elements and import this data for a
single data element in the destination system. As another example, one
can aggregate data collected at organisation unit level 4 in the target
system to level 2 and import that data in the destination system.

You can retrieve data in the raw data value set format from the
dataValueSet resource:

    /api/33/analytics/dataValueSet

The following resource representations are supported:

  - json (application/json)

  - xml (application/xml)

When using the data value set format, exactly three dimensions must be
specified as analytics dimensions with at least one dimension item each:

  - Data (dx)

  - Period (pe)

  - Organisation unit (ou)

Any other dimension will be ignored. Filters will be applied as with
regular analytics requests. Note that any data dimension type can be
specified, including indicators, data elements, data element operands,
data sets and program indicators.

An example request which aggregates data for specific indicators,
periods and organisation units and returns it as regular data values in
XML looks like this:

    api/analytics/dataValueSet.xml?dimension=dx:Uvn6LCg7dVU;OdiHJayrsKo
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:lc3eMKXaEfw;PMa2VCrupOd

A request which aggregates data for data element operands and uses CODE
as output identifier scheme looks like the below. When defining the
output identifier scheme, all metadata objects part of the response are
affected:

    api/analytics/dataValueSet.json?dimension=dx:fbfJHSPpUQD.pq2XI5kz2BY;fbfJHSPpUQD.PT59n8BQbqM
      &dimension=pe:LAST_12_MONTHS&dimension=ou:ImspTQPwCqd&outputIdScheme=CODE

When using attribute-based identifier schemes for export there is a risk
of producing duplicate data values. The boolean query parameter
duplicatesOnly can be used for debugging purposes to return only
duplicates data values. This response can be used to clean up the
duplicates:

    api/analytics/dataValueSet.xml?dimension=dx:Uvn6LCg7dVU;OdiHJayrsKo
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:lc3eMKXaEfw&duplicatesOnly=true

### Raw data format { #webapi_analytics_raw_data } 

The analytics *rawData* resource allows for returning the data stored in
the analytics data tables without any aggregation being performed. This
is useful for clients which would like to perform aggregation and
filtering on their own without having to denormalize data in the
available data dimensions themselves.

    /api/analytics/rawData

The following resource representations are supported:

  - json (application/json)

  - csv (application/csv)

This resource follows the syntax of the regular analytics resource. Only
a subset of the query parameters are supported. Additionally, a
*startDate* and *endDate* parameter are available. The supported
parameters are listed in the table below.



Tableau : Paramètres de requête

| Paramètre de requête | Required / Notes |
|---|---|
| dimension | Oui |
| date de début | No / yyyy-MM-dd |
| date de fin | No / yyyy-MM-dd |
| skipMeta (ignorer les métadonnées) | Non |
| skipData (ignorer les données) | Non |
| hierarchyMeta | Non |
| showHierarchy (afficher la hiérarchie) | Non |
| displayProperty (afficher la propriété) | Non |
| outputIdScheme (schéma d'identification de la sortie) | Non |
| outputOrgUnitIdScheme (schéma d'identification de l'unité d'organisation de sortie)  | Non |
| outputDataElementIdScheme (schéma d'identification de l'élément de données de sortie) | Non |
| inputIdScheme | Non |
| userOrgUnit (unité d'organisation d'utilisateur) | Non |

The *dimension* query parameter defines which dimensions (table columns)
should be included in the response. It can optionally be constrained
with items. The *filter* query parameter defines which items and
dimensions (table columns) should be used as a filter for the response.

For the organisation unit dimension, the response will contain data
associated with the organisation unit and all organisation units in the
sub-hierarchy (children in the tree). This is different compared to the
regular analytics resource, where only the explicitly selected
organisation units are included.

To retrieve a response with specific data elements, specific periods,
specific organisation units and all data for two custom dimensions you
can issue a request like this:

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      &dimension=J5jldMd8OHv&dimension=Bpx0589u8y0
      &dimension=pe:LAST_12_MONTHS
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji

The *startDate* and *endDate* parameters allow for fetching data linked
to any period between those dates. This avoids the need for defining all
periods explicitly in the
    request:

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      &dimension=J5jldMd8OHv&dimension=Bpx0589u8y0
      &startDate=2015-01-01&endDate=2015-12-31
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji

The *filter* parameter can be used to filter a response without
including that dimension as part of the response, this time in CSV
format:

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      &filter=J5jldMd8OHv:uYxK4wmcPqA;tDZVQ1WtwpA
      &startDate=2015-01-01&endDate=2015-12-31
      &dimension=ou:O6uvpzGd5pu

The *outputIdScheme* parameter is useful if you want human readable data
responses as it can be set to *NAME* like this:

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &filter=J5jldMd8OHv:uYxK4wmcPqA;tDZVQ1WtwpA
      &startDate=2017-01-01&endDate=2017-12-31
      &dimension=ou:O6uvpzGd5pu
      &outputIdScheme=NAME

The response from the *rawData* resource will look identical to the
regular analytics resource; the difference is that the response contains
raw, non-aggregated data, suitable for further aggregation by
third-party systems.

### Debugging { #webapi_analytics_debugging } 

When debugging analytics requests it can be useful to examine the data
value source of the aggregated analytics response. The
*analytics/debug/sql* resource will provide an SQL statement that
returns the relevant content of the datavalue table. You can produce
this SQL by doing a GET request with content type "text/html" or
"text/plain" like below. The dimension and filter syntax are identical to
regular analytics queries:

    /api/analytics/debug/sql?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &filter=pe:2016Q1;2016Q2&filter=ou:O6uvpzGd5pu

## Event analytics { #webapi_event_analytics } 

The event analytics API lets you access aggregated event data and query
*events* captured in DHIS2. This resource lets you retrieve events based
on a program and optionally a program stage, and lets you retrieve and
filter events on any event dimensions.

    /api/33/analytics/events

### Dimensions and items { #webapi_event_analytics_dimensions_items } 

Event dimensions include data elements, attributes, organisation units
and periods. The aggregated event analytics resource will return
aggregated information such as counts or averages. The query analytics
resource will simply return events matching a set of criteria and does
not perform any aggregation. You can specify dimension items in the form
of options from option sets and legends from legend sets for data
elements and attributes which are associated with such. The event
dimensions are listed in the table below.



Table: Event dimensions

| Dimension | Identifiant de la dimension | Description |
|---|---|---|
| Des éléments de données | <id\> | Data element identifiers |
| Attributs | <id\> | Attribute identifiers |
| Périodes | pe | Périodes ISO et périodes relatives, voir "format de date et de période" |
| Unités d’organisation | ou | Organisation unit identifiers and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |
| Ensembles de groupes d'unités d'organisation | <org unit group set id\> | Organisation unit group set identifiers |
| Catégories | <category id\> | Category identifiers (program attribute categories only) |

### Request query parameters { #webapi_event_analytics_request_query_parameters } 

The analytics event API lets you specify a range of query parameters.



Table: Query parameters for both event query and aggregate analytics

| Paramètre de requête | Obligatoire | Description | Options (par défaut en premier) |
|---|---|---|---|
| de paludisme) ». | Oui | Program identifier. | Any program identifier |
| stage | Non | Program stage identifier. | Any program stage identifier |
| date de début | Oui | Start date for events. | Date in yyyy-MM-dd format |
| date de fin | Oui | End date for events. | Date in yyyy-MM-dd format |
| dimension | Oui | Dimension identifier including data elements, attributes, program indicators, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. | Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN |
| filtre | Non | Dimension identifier including data elements, attributes, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. ||
| hierarchyMeta | Non | Inclut les noms des unités d'organisation racines et le parcours hiérarchique des unités d'organisation dans les métadonnées. | faux &#124; vrai |
| eventStatus | Non | Specify status of events to include. | ACTIVE &#124; COMPLETED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED. Can be comma separated (*for query only*). |
| programStatus | Non | Specify enrollment status of events to include. | ACTIVE &#124; COMPLETED &#124; CANCELLED. Can be comma separated (*for query only*). |
| relativePeriodDate (Date de la période relative) | string | Non | Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |
| colonnes | Non | Dimensions à utiliser comme colonnes pour la présentation du tableau. | N'importe quelle dimension (doit être une dimension de requête) |
| lignes | Non | Dimensions à utiliser comme lignes pour la présentation du tableau. | N'importe quelle dimension (doit être une dimension de requête) |



Table: Query parameters for event query analytics only

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| ou Mode | Non | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. More details [here].(https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html#webapi_nti_ou_scope) | DESCENDANTS, CHILDREN, SELECTED |
| asc | Non | Dimensions to be sorted ascending, can reference event date, org unit name and code and any item identifiers. | `ouname` &#124; `programstatus` &#124; `eventstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `eventdate` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| desc | Non | Dimensions to be sorted descending, can reference event date, org unit name and code and any item identifiers. | `ouname` &#124; `programstatus` &#124; `eventstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `eventdate` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| coordinatesOnly | Non | Whether to only return events which have coordinates. | faux &#124; vrai |
| coordinateOuFallback | Non | Program instance geometry is applied whenever organization unit geometry is missing. | faux &#124; vrai |
| dataIdScheme | Non | Id scheme to be used for data, more specifically data elements and attributes which have an option set or legend set, e.g. return the name of the option instead of the code, or the name of the legend instead of the legend ID, in the data response. | NAME &#124; CODE &#124; UID |
| headers | Non | The name of the headers to be returned as part of the response. | One or more headers name separated by comma |
| page | Non | The page number. Default page is 1. | Numeric positive value |
| taille de la page | Non | The page size. Default size is 50 items per page. | Numeric zero or positive value |
| eventDate | no | (`events` resource only) Custom period on `eventDate` (see "custom date periods" section) | see "date and period format" section |
| enrollmentDate | no | Custom period on `enrollmentDate` (see "custom date periods" section) | see "date and period format" section |
| scheduledDate | no | (`events` resource only) Custom period on `scheduledDate` (see "custom date periods" section) | see "date and period format" section |
| incidentDate | no | Custom period on `incidentDate` (see "custom date periods" section) | see "date and period format" section |
| lastUpdated (dernière mise à jour) | no | Custom period on `lastUpdated` (see "custom date periods" section) | see "date and period format" section |



Table: Query parameters for aggregate event analytics only

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| valeur | Non | Value dimension identifier. Can be a data element or an attribute which must be of numeric value type. | Data element or attribute identifier |
| Type d'agrégation | Non | Aggregation type for the value dimension. Default is AVERAGE. | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; LAST &#124; LAST_AVERAGE_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX |
| showHierarchy (afficher la hiérarchie) | Non | Affiche le parcours hiérarchique complet de l'unité d'organisation ainsi que le nom de l'unité d'organisation. | faux &#124; vrai |
| displayProperty (afficher la propriété) | Non | Affiche la propriété des métadonnées. | NAME &#124; SHORTNAME |
| sortOrder | Non | Sort the records on the value column in ascending or descending order. | ASC &#124; DESC |
| limite | Non | The maximum number of records to return. Cannot be larger than 10 000. | Numeric positive value |
| outputType | Non | Specify output type for analytical data which can be events, enrollments or tracked entity instances. The two last options apply to programs with registration only. | EVENT &#124; ENROLLMENT &#124; TRACKED_ENTITY_INSTANCE |
| collapseDataDimensions | Non | Collapse all data dimensions (data elements and attributes) into a single dimension in the response. | faux &#124; vrai |
| skipMeta (ignorer les métadonnées) | Non | Exclude the meta data part of the response (improves performance). | faux &#124; vrai |
| skipData (ignorer les données) | Non | Excluez la partie données de la réponse. | faux &#124; vrai |
| skipRounding (ignorer l'arrondissement des valeurs) | Non | Skip rounding of aggregate data values. | faux &#124; vrai |
| aggregateData | Non | Produce aggregate values for the data dimensions (as opposed to dimension items). | faux &#124; vrai |
| timeField (champ du temps) | Non | The time field to base event aggregation on. Applies to event data items only. Can be a predefined option or the ID of an attribute or data element having a time-based value type. | EVENT_DATE &#124; ENROLLMENT_DATE &#124; INCIDENT_DATE &#124; DUE_DATE &#124; COMPLETED_DATE &#124; <Attribute ID\> &#124; <Data element ID\> |
| orgUnitField (champ d'unité d'organisation) | Non | The organisation unit field to base event aggregation on. Applies to event data items only. Can be the ID of an attribute or data element with the Organisation unit value type. The default option is specified as omitting the query parameter. <Attribute ID\> &#124; <Data element ID\> | <Attribute ID\> &#124; <Data element ID\> |



Table: Query parameters for cluster event analytics only

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| clusterSize | Oui | Size of clusters in meters. | Numeric positive value |
| coordinateField | Non | Field to base geospatial event analytics on. Default is event. Can be set to identifiers of attributes and data elements of value type coordinate. | EVENT &#124; <attribute-id\> &#124; <dataelement-id\> |
| bbox | Oui | Bounding box / area of events to include in the response on the format "min longitude, min latitude, max longitude , max latitude". | Chaîne |
| includeClusterPoints | Non | Include information about underlying points for each cluster, be careful if cluster represent a very high number of points. | faux &#124; vrai |

### Event query analytics { #webapi_event_query_analytics } 

The *analytics/events/query* resource lets you query for captured
events. This resource does not perform any aggregation, rather it lets
you query and filter for information about events.

    /api/33/analytics/events/query

You can specify any number of dimensions and any number of filters in a
query. Dimension item identifiers can refer to any of data elements,
person attributes, person identifiers, fixed and relative periods and
organisation units. Dimensions can optionally have a query operator and
a filter. Event queries should be on the format described
    below.

    /api/33/analytics/events/query/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve events from the "Inpatient morbidity and
mortality" program between January and October 2016, where the "Gender"
and "Age" data elements are included and the "Age" dimension is filtered
on "18", you can use the following
    query:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji&dimension=oZg33kd9taw&dimension=qrur9Dvnyt5:EQ:18

To retrieve events for the "Birth" program stage of the "Child
programme" program between March and December 2016, where the "Weight"
data element, filtered for values larger than
    2000:

    /api/33/analytics/events/query/IpHINAT79UW?stage=A03MvHHogjR&startDate=2016-03-01
      &endDate=2016-12-31&dimension=ou:O6uvpzGd5pu&dimension=UXz7xuGCEhU:GT:2000

Sorting can be applied to the query for the event date of the event and
any dimensions. To sort descending on the event date and ascending on
the "Age" data element dimension you can
    use:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&desc=EVENTDATE&asc=qrur9Dvnyt5

Paging can be applied to the query by specifying the page number and the
page size parameters. If page number is specified but page size is not,
a page size of 50 will be used. If page size is specified but page
number is not, a page number of 1 will be used. To get the third page of
the response with a page size of 20 you can use a query like
    this:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&page=3&pageSize=20

#### Filtering { #filtering } 

Filters can be applied to data elements, person attributes and person
identifiers. The filtering is done through the query parameter value on
the following format:

    &dimension=<item-id>:<operator>:<filter-value>

As an example, you can filter the "Weight" data element for values
greater than 2000 and lower than 4000 like this:

    &dimension=UXz7xuGCEhU:GT:2000&dimension=UXz7xuGCEhU:LT:4000

You can filter the "Age" data element for multiple, specific ages using
the IN operator like this:

    &dimension=qrur9Dvnyt5:IN:18;19;20

You can specify multiple filters for a given item by repeating the
operator and filter components, all separated with semi-colons:

    &dimension=qrur9Dvnyt5:GT:5:LT:15

The available operators are listed below.



Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| !EQ | Pas égal à |
| IEQ | Equal to, ignoring case |
| !IEQ | Not equal to, ignoring case |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Like (free text match) |
| !LIKE | Not like (free text match) |
| ILIKE | Like, ignoring case (free text match) |
| !ILIKE | Not like, ignoring case (free text match) |
| IN | Equal to one of multiple values separated by ";" |

#### Time Field Filtering { #time-field-filtering } 

By default, the `query` endpoints filter periods based on `eventDate`.
However, it is possible to filter entries based on `lastUpdated` instead, by using the `timeField` query parameter.
    &timeField=LAST_UPDATED

#### Enhanced conditions { #enhanced-conditions } 

By default `enhancedConditions` flag is set to `false`. This means all conditions expressed in `dimension` and `filter` are meant as `AND` conditions.
For example:

    dimension=a:GT:20:LT:40&dimension=b:GT:1:LT:5

translates into the following logical condition:

    a>20 and a<40 and b>1 and b<5 

However, there are cases in which more control on conditions might be needed and can be enabled by setting `enhancedConditions` query parameter to `true`.
By doing so, a client can use a special `_OR_` separator to join conditions using `OR` logical operator.

Exemple:

    dimension=a:GT:20:LT:40_OR_b:GT:1:LT:5&dimension=c:EQ:test

translates into the following logical condition:

    ((a>20 and a<40) or (b>1 and b<5)) and c = "test"

#### Response formats { #response-formats } 

The default response representation format is JSON. The requests must be
using the HTTP *GET* method. The following response formats are
supported.

  - json (application/json)

  - jsonp (application/javascript)

  - xls (application/vnd.ms-excel)

As an example, to get a response in Excel format you can use a file
extension in the request URL like this:

    /api/33/analytics/events/query/eBAyeGv0exc.xls?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=oZg33kd9taw&dimension=qrur9Dvnyt5

You can set the hierarchyMeta query parameter to true in order to
include names of all ancestor organisation units in the meta-section of
the response:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:YuQRtpLP10I&dimension=qrur9Dvnyt5:EQ:50&hierarchyMeta=true

The default response JSON format will look similar to this:

```json
{
  "headers": [
    {
      "name": "psi",
      "column": "Event",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ps",
      "column": "Program stage",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "eventdate",
      "column": "Event date",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdated",
      "column": "Last Updated",
      "valueType": "DATE",
      "type": "java.time.LocalDate",
      "hidden": false,
      "meta": true
    },
    {
      "name": "createdbydisplayname",
      "column": "Created by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdatedbydisplayname",
      "column": "Last updated by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "coordinates",
      "column": "Coordinates",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "qrur9Dvnyt5": "Age",
      "eBAyeGv0exc": "Inpatient morbidity and mortality",
      "ImspTQPwCqd": "Sierra Leone",
      "O6uvpzGd5pu": "Bo",
      "YuQRtpLP10I": "Badjia",
      "oZg33kd9taw": "Gender"
    },
    "ouHierarchy": {
      "YuQRtpLP10I": "/ImspTQPwCqd/O6uvpzGd5pu"
    }
  },
  "width": 8,
  "height": 4,
  "rows": [
    [
      "yx9IDINf82o",
      "Zj7UnCAulEk",
      "2016-08-05",
      "system",
      "2018-08-07",
      "[5.12, 1.23]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "IPNa7AsCyFt",
      "Zj7UnCAulEk",
      "2016-06-12",
      "system",
      "2018-08-07",
      "[5.22, 1.43]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "ZY9JL9dkhD2",
      "Zj7UnCAulEk",
      "2016-06-15",
      "system",
      "2018-08-07",
      "[5.42, 1.33]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "MYvh4WAUdWt",
      "Zj7UnCAulEk",
      "2016-06-16",
      "system",
      "2018-08-07",
      "[5.32, 1.53]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ]
  ]
}
```

The *headers* section of the response describes the content of the query
result. The event unique identifier, the program stage identifier, the
event date, the organisation unit name, the organisation unit code and
the organisation unit identifier appear as the first six dimensions in
the response and will always be present. Next comes the data elements,
person attributes and person identifiers which were specified as
dimensions in the request, in this case, the "Gender" and "Age" data
element dimensions. The header section contains the identifier of the
dimension item in the "name" property and a readable dimension
description in the "column" property.

The *metaData* section, *ou* object contains the identifiers of all
organisation units present in the response mapped to a string
representing the hierarchy. This hierarchy string lists the identifiers
of the ancestors (parents) of the organisation unit starting from the
root. The *names* object contains the identifiers of all items in the
response mapped to their names.

The *rows* section contains the events produced by the query. Each row
represents exactly one event.

In order to have the event analytics resource generate the data in the
shape of a ready-made table, you can provide *rows* and *columns*
parameters with requested dimension identifiers separated by semi-colons
as values to indicate which ones to use as table columns and rows.
Instead of generating a plain, normalized data source, the event
analytics resource will now generate the data in table layout. The
column and rows dimensions must be present as a data dimension in the
query (not a filter). Such a request can look like this:

    /api/33/analytics.html+css?dimension=dx:cYeuwXTCPkU;fbfJHSPpUQD&dimension=pe:WEEKS_THIS_YEAR
      &filter=ou:ImspTQPwCqd&displayProperty=SHORTNAME&columns=dx&rows=pe

### Event aggregate analytics { #webapi_event_aggregate_analytics } 

The `/analytics/events/aggregate` resource lets you retrieve *aggregated
numbers* of events captured in DHIS2. This resource lets you retrieve
aggregate data based on a program and optionally a program stage, and
lets you filter on any event dimension.

    /api/33/analytics/events/aggregate

The events aggregate resource does not return the event information
itself, rather the aggregate numbers of events matching the request
query. Event dimensions include data elements, person attributes, person
identifiers, periods and organisation units. Aggregate event queries
should be on the format described below.

    /api/33/analytics/events/aggregate/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve aggregate numbers for events from the
"Inpatient morbidity and mortality" program between January and October
2016, where the "Gender" and "Age" data elements are included, the "Age"
dimension item is filtered on "18" and the "Gender" item is filtered on
"Female", you can use the following query:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=oZg33kd9taw:EQ:Female&dimension=qrur9Dvnyt5:GT:50

To retrieve data for fixed and relative periods instead of start and end
date, in this case, May 2016 and last 12 months, and the organisation
unit associated with the current user, you can use the following query:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:201605;LAST_12_MONTHS
      &dimension=ou:USER_ORGUNIT;fdc6uOvgo7ji&dimension=oZg33kd9taw

In order to specify "Female" as a filter for "Gender" for the data
response, meaning "Gender" will not be part of the response but will
filter the aggregate numbers in it, you can use the following syntax:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:2016;
      &dimension=ou:O6uvpzGd5pu&filter=oZg33kd9taw:EQ:Female

To specify the "Bo" organisation unit and the period "2016" as filters,
and the "Mode of discharge" and Gender" as dimensions, where "Gender" is
filtered on the "Male" item, you can use a query like this:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&dimension=oZg33kd9taw:EQ:Male

To create a "Top 3 report" for _Mode of discharge_ you can use the limit
and sortOrder query parameters similar to this:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&limit=3&sortOrder=DESC

To specify a value dimension with a corresponding aggregation type you
can use the value and aggregationType query parameters. Specifying a
value dimension will make the analytics engine return aggregate values
for the values of that dimension in the response as opposed to counts of
events.

    /api/33/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &dimension=ou:ImspTQPwCqd&dimension=pe:LAST_12_MONTHS&dimension=fWIAEtYVEGk
      &value=qrur9Dvnyt5&aggregationType=AVERAGE

To base event analytics aggregation on a specific data element or attribute
of value type date or date time you can use the `timeField` parameter:

    /api/33/analytics/events/aggregate/IpHINAT79UW.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:LAST_12_MONTHS&dimension=cejWyOfXge6&stage=A03MvHHogjR
      &timeField=ENROLLMENT_DATE

To base event analytics aggregation on a specific data element or attribute
of value type organisation unit you can use the `orgUnitField` parameter:

    /api/33/analytics/events/aggregate/eBAyeGv0exc.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:THIS_YEAR&dimension=oZg33kd9taw&stage=Zj7UnCAulEk
      &orgUnitField=S33cRBsnXPo

#### Ranges / legend sets { #ranges-legend-sets } 

For aggregate queries, you can specify a range / legend set for numeric
data element and attribute dimensions. The purpose is to group the
numeric values into ranges. As an example, instead of generating data
for an "Age" data element for distinct years, you can group the
information into age groups. To achieve this, the data element or
attribute must be associated with the legend set. The format is
described below:

    ?dimension=<item-id>-<legend-set-id>

Voici donc un exemple :

    /api/33/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &dimension=qrur9Dvnyt5-Yf6UHoPkdS6&dimension=ou:ImspTQPwCqd&dimension=pe:LAST_MONTH

#### Response formats { #response-formats } 

The default response representation format is JSON. The requests must be
using the HTTP *GET* method. The response will look similar to this:

```json
{
  "headers": [
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "pe",
      "column": "Period",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "value",
      "column": "Value",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "eBAyeGv0exc": "Inpatient morbidity and mortality"
    }
  },
  "width": 5,
  "height": 39,
  "rows": [
    [
      "Female",
      "95",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "63",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "67",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "71",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "75",
      "201605",
      "O6uvpzGd5pu",
      "14"
    ],
    [
      "Female",
      "73",
      "201605",
      "O6uvpzGd5pu",
      "5"
    ]
  ]
}
```

Note that the max limit for rows to return in a single response is 10 000.
If the query produces more than the max limit, a *409 Conflict* status code
will be returned.

### Event clustering analytics { #webapi_event_clustering_analytics } 

The *analytics/events/cluster* resource provides clustered geospatial
event data. A request looks like this:

    /api/33/analytics/events/cluster/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:LEVEL-2&clusterSize=100000
      &bbox=-13.2682125,7.3721619,-10.4261178,9.904012&includeClusterPoints=false

The cluster response provides the count of underlying points, the center
point and extent of each cluster. If the `includeClusterPoints` query
parameter is set to true, a comma-separated string with the identifiers
of the underlying events is included. A sample response looks like this:

```json
{
  "headers": [
    {
      "name": "count",
      "column": "Count",
      "type": "java.lang.Long",
      "meta": false
    },
    {
      "name": "center",
      "column": "Center",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "extent",
      "column": "Extent",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "points",
      "column": "Points",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "width": 3,
  "height": 4,
  "rows": [
    [
      "3",
      "POINT(-13.15818 8.47567)",
      "BOX(-13.26821 8.4St7215,-13.08711 8.47807)",
      ""
    ],
    [
      "9",
      "POINT(-13.11184 8.66424)",
      "BOX(-13.24982 8.51961,-13.05816 8.87696)",
      ""
    ],
    [
      "1",
      "POINT(-12.46144 7.50597)",
      "BOX(-12.46144 7.50597,-12.46144 7.50597)",
      ""
    ],
    [
      "7",
      "POINT(-12.47964 8.21533)",
      "BOX(-12.91769 7.66775,-12.21011 8.49713)",
      ""
    ]
  ]
}
```

### Event count and extent analytics { #webapi_event_count_extent_analytics } 

The *analytics/events/count* resource is suitable for geometry-related
requests for retrieving the count and extent (bounding box) of events
for a specific query. The query syntax is equal to the *events/query*
resource. A request looks like
    this:

    /api/33/analytics/events/count/eBAyeGv0exc?startDate=2016-01-01
      &endDate=2016-10-31&dimension=ou:O6uvpzGd5pu

The response will provide the count and extent in JSON format:

```json
{
  extent: "BOX(-13.2682125910096 7.38679562779441,-10.4261178860988 9.90401290212795)",
  count: 59
}
```

### Constraints and validation { #webapi_event_analytics_constraints } 

There are several constraints to the input parameters you can provide to the
event analytics resource. If any of the constraints are violated, the API will
return a *409 Conflict* response and a response message looking similar to this:

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "At least one organisation unit must be specified",
  "errorCode": "E7200"
}
```

The possible validation errors for the event analytics API are described
in the table below.

| Code d'erreur | Message |
| ---------- | ------- |
| E7200      | Au moins une unité d'organisation doit être spécifiée |
| E7201      | Dimensions cannot be specified more than once |
| E7202      | Query items cannot be specified more than once |
| E7203      | Value dimension cannot also be specified as an item or item filter |
| E7204      | Value dimension or aggregate data must be specified when aggregation type is specified |
| E7205      | Start and end date or at least one period must be specified |
| E7206      | Start date is after end date |
| E7207      | Page number must be a positive number |
| E7208      | Page size must be zero or a positive number |
| E7209      | Limit is larger than max limit |
| E7210      | Time field is invalid |
| E7211      | Org unit field is invalid |
| E7212      | Cluster size must be a positive number |
| E7213      | Bbox is invalid, must be on format: 'min-lng,min-lat,max-lng,max-lat' |
| E7214      | Cluster field must be specified when bbox or cluster size are specified |
| E7215      | Query item cannot specify both legend set and option set |
| E7216      | Query item must be aggregateable when used in aggregate query |
| E7217      | User is not allowed to view event analytics data |
| E7218      | Spatial database support is not enabled |
| E7219      | Data element must be of value type coordinate in order to be used as coordinate field |
| E7220      | Attribute must be of value type coordinate to in order to be used as coordinate field |
| E7221      | Coordinate field is invalid |
| E7222      | Query item or filter is invalid |
| E7223      | Value does not refer to a data element or attribute which are numeric and part of the program |
| E7224      | Item identifier does not reference any data element, attribute or indicator part of the program |
| E7225      | Program stage is mandatory for data element dimensions in enrollment analytics queries |
| E7226      | Dimension is not a valid query item |
| E7227      | Relationship entity type not supported |
| E7228      | Fallback coordinate field is invalid |
| E7229      | Operator does not allow missing value |

## Enrollment analytics { #webapi_enrollment_analytics } 

The enrollment analytics API lets you access aggregated event data and query *enrollments with their event data* captured in DHIS2. This resource lets you retrieve data for a program based on program stages and data elements - in addition to tracked entity attributes. When querying event data for a specific programstages within each enrollment, the data element values for each program stage will be returned as one row in the response from the api. If querying a data element in a program stage that is repeatable, the newest data element value will be used for that data element in the api response.

### Dimensions and items { #webapi_enrollment_analytics_dimensions } 

Enrollment dimensions include data elements, attributes, organisation units and periods. The query analytics resource will simply return enrollments matching a set of criteria and does not perform any aggregation.



Table: Enrollment dimensions

| Dimension | Identifiant de la dimension | Description |
|---|---|---|
| Data elements in program stages | <program stage id\>.<data element id\> | Data element identifiers must include the program stage when querying data for enrollments.      dimension=edqlbukwRfQ.vANAXwtLwcT |
| Attributs | <id\> | Attribute identifiers |
| Périodes | pe | Périodes ISO et périodes relatives, voir "format de date et de période" |
| Unités d’organisation | ou | Organisation unit identifiers and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |

### Enrollment query analytics { #webapi_enrollment_query_analytics } 

The *analytics/enrollments/query* resource lets you query for captured enrollments. This resource does not perform any aggregation, rather it lets you query and filter for information about enrollments.

    /api/33/analytics/enrollments/query

You can specify any number of dimensions and any number of filters in a query. Dimension item identifiers can refer to any of the data elements in program stages, tracked entity attributes, fixed and relative periods and organisation units. Dimensions can optionally have a query operator and a filter. Enrollment queries should be on the format described below.

    /api/33/analytics/enrollments/query/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve enrollments in the from the "Antenatal care" program from January 2019, where the "First name" is picked up from attributes, "Chronic conditions" and "Smoking" data elements are included from the first program stage, and "Hemoglobin value" from the following program stage, and only women that have "Cronic conditions" would be included, you can use the following query:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=w75KJ2mc4zz&dimension=WZbXY0S00lP.de0FEHSIoxh:eq:1&dimension=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=edqlbukwRfQ.vANAXwtLwcT
      &startDate=2019-01-01&endDate=2019-01-31

To retrieve enrollments in the from the "Antenatal care" program from last month (relative to the point in time the query is executed), where the "Chronic conditions" and "Smoking" data elements are included from the first program stage, and "Hemoglobin value" from the followup program stage, only including smoking women with hemoglobin less than 20:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&dimension=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD:eq:1&dimension=edqlbukwRfQ.vANAXwtLwcT:lt:20
      &dimension=pe:LAST_MONTH

Sorting can be applied to the query for the enrollment and incident dates of the enrollment:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &columns=w75KJ2mc4zz&dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=pe:LAST_MONTH
      &stage=WZbXY0S00lP&pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

Paging can be applied to the query by specifying the page number and the page size parameters. If page number is specified but page size is not, a page size of 50 will be used. If page size is specified but page number is not, a page number of 1 will be used. To get the second page of the response with a page size of 10 you can use a query like this:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&dimension=w75KJ2mc4zz&dimension=pe:LAST_MONTH
      &dimension=WZbXY0S00lP.sWoqcoByYmD&pageSize=10&page=2

#### Filtering { #filtering } 

Filters can be applied to data elements, person attributes and person identifiers. The filtering is done through the query parameter value on the following format:

    &dimension=<item-id>:<operator>:<filter-value>

As an example, you can filter the "Weight" data element for values greater than 2000 and lower than 4000 like this:

    &dimension=WZbXY0S00lP.UXz7xuGCEhU:GT:2000&dimension=WZbXY0S00lP.UXz7xuGCEhU:LT:4000

You can filter the "Age" attribute for multiple, specific ages using the IN operator like this:

    &dimension=qrur9Dvnyt5:IN:18;19;20

You can specify multiple filters for a given item by repeating the operator and filter components, all separated with semi-colons:

    &dimension=qrur9Dvnyt5:GT:5:LT:15

#### Time Field Filtering { #time-field-filtering } 

By default, the `query` endpoints filter periods based on `enrollmentDate`.
However, it is possible to filter entries based on `lastUpdated` instead, by using the `timeField` query parameter.

    &timeField=LAST_UPDATED

##### NV keyword { #nv-keyword } 
A special keyword `NV` can be used to filter by `null` values

Filter by AGE is null

    &dimension=qrur9Dvnyt5:EQ:NV

Filter by AGE is not null

    &dimension=qrur9Dvnyt5:NE:NV

Filter by AGE is 18, 19 or is null

    &dimension=qrur9Dvnyt5:IN:18;19;NV

`NV` can be used with `EQ`, `NE` and `IN` operators

##### Operators { #operators } 

The available operators are listed below.

Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Like (free text match) |
| IN | Equal to one of multiple values separated by ";" |

### Request query parameters { #webapi_enrollment_analytics_query_parameters } 

The analytics enrollment query API lets you specify a range of query parameters.



Table: Query parameters for enrollment query endpoint

| Paramètre de requête | Obligatoire | Description | Options (par défaut en premier) |
|---|---|---|---|
| de paludisme) ». | Oui | Program identifier. | Any program identifier |
| date de début | Non | Start date for enrollments. | Date in yyyy-MM-dd format |
| date de fin | Non | End date for enrollments. | Date in yyyy-MM-dd format |
| dimension | Oui | Dimension identifier including data elements, attributes, program indicators, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. | Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN |
| filtre | Non | Dimension identifier including data elements, attributes, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. ||
| programStatus | Non | Specify enrollment status of enrollments to include. | ACTIVE &#124; COMPLETED &#124; CANCELLED |
| relativePeriodDate (Date de la période relative) | string | Non | Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |
| ou Mode | Non | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. More details [here].(https://docs.dhis2.org/en/develop/using-the-api/dhis-core-version-master/tracker.html#webapi_nti_ou_scope) | DESCENDANTS, CHILDREN, SELECTED |
| asc | Non | Dimensions to be sorted ascending, can reference enrollment date, incident date, org unit name and code. | `ouname` &#124; `programstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| desc | Non | Dimensions to be sorted descending, can reference enrollment date, incident date, org unit name and code. | `ouname` &#124; `programstatus` &#124; `createdbydisplayname` &#124; `lastupdatedbydisplayname` &#124; `enrollmentdate` &#124; `incidentdate` &#124; `lastupdated` &#124; item identifier |
| coordinatesOnly | Non | Whether to only return enrollments which have coordinates. | faux &#124; vrai |
| headers | Non | The name of the headers to be returned as part of the response. | One or more headers name separated by comma |
| page | Non | The page number. Default page is 1. | Numeric positive value |
| taille de la page | Non | The page size. Default size is 50 items per page. | Numeric zero or positive value |

#### Response formats { #response-formats } 

The default response representation format is JSON. The requests must be using the HTTP *GET* method. The following response formats are supported.

  - json (application/json)
  - xml (application/xml)
  - xls (application/vnd.ms-excel)
  - csv  (application/csv)
  - html (text/html)
  - html+css (text/html)

As an example, to get a response in Excel format you can use a file extension in the request URL like this:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&columns=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=pe:LAST_MONTH&stage=WZbXY0S00lP
      &pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

The default response JSON format will look similar to this:

```json
{
  "headers": [
    {
      "name": "pi",
      "column": "Enrollment",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "tei",
      "column": "Tracked entity instance",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "enrollmentdate",
      "column": "Enrollment date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "incidentdate",
      "column": "Incident date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdated",
      "column": "Last Updated",
      "valueType": "DATE",
      "type": "java.time.LocalDate",
      "hidden": false,
      "meta": true
    },
    {
      "name": "storedby",
      "column": "Stored by",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "createdbydisplayname",
      "column": "Created by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "lastupdatedbydisplayname",
      "column": "Last updated by (display name)",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "geometry",
      "column": "Geometry",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "longitude",
      "column": "Longitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "latitude",
      "column": "Latitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "de0FEHSIoxh",
      "column": "WHOMCH Chronic conditions",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    },
    {
      "name": "sWoqcoByYmD",
      "column": "WHOMCH Smoking",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    }
  ],
  "metaData": {
    "pager": {
      "page": 2,
      "total": 163,
      "pageSize": 4,
      "pageCount": 41
    },
    "items": {
      "ImspTQPwCqd": {
        "name": "Sierra Leone"
      },
      "PFDfvmGpsR3": {
        "name": "Care at birth"
      },
      "bbKtnxRZKEP": {
        "name": "Postpartum care visit"
      },
      "ou": {
        "name": "Organisation unit"
      },
      "PUZaKR0Jh2k": {
        "name": "Previous deliveries"
      },
      "edqlbukwRfQ": {
        "name": "Antenatal care visit"
      },
      "WZbXY0S00lP": {
        "name": "First antenatal care visit"
      },
      "sWoqcoByYmD": {
        "name": "WHOMCH Smoking"
      },
      "WSGAb5XwJ3Y": {
        "name": "WHO RMNCH Tracker"
      },
      "de0FEHSIoxh": {
        "name": "WHOMCH Chronic conditions"
      }
    },
    "dimensions": {
      "pe": [],
      "ou": [
        "ImspTQPwCqd"
      ],
      "sWoqcoByYmD": [],
      "de0FEHSIoxh": []
    }
  },
  "width": 12,
  "rows": [
    [
      "A0cP533hIQv",
      "to8G9jAprnx",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Tonkomba MCHP",
      "OU_193264",
      "xIMxph4NMP1",
      "0",
      "1"
    ],
    [
      "ZqiUn2uXmBi",
      "SJtv0WzoYki",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Mawoma MCHP",
      "OU_254973",
      "Srnpwq8jKbp",
      "0",
      "0"
    ],
    [
      "lE747mUAtbz",
      "PGzTv2A1xzn",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Kunsho CHP",
      "OU_193254",
      "tdhB1JXYBx2",
      "",
      "0"
    ],
    [
      "nmcqu9QF8ow",
      "pav3tGLjYuq",
      "2019-02-03 12:05:00.0",
      "2019-02-03 12:05:00.0",
      "system",
      "2020-08-06 21:20:52.0",
      "",
      "0.0",
      "0.0",
      "Korbu MCHP",
      "OU_678893",
      "m73lWmo5BDG",
      "",
      "1"
    ]
  ],
  "height": 4
}
```

The *headers* section of the response describes the content of the query result. The enrollment unique identifier, the tracked entity instance identifier, the enrollment date, the incident date, geometry, latitude, longitude, the organisation unit name and the organisation unit code appear as the first dimensions in the response and will always be present. Next comes the data elements, and tracked entity attributes which were specified as dimensions in the request, in this case, the "WHOMCH Chronic conditions" and "WHOMCH smoking" data element dimensions. The header section contains the identifier of the dimension item in the "name" property and a readable dimension description in the "column" property.

The *metaData* section, *ou* object contains the identifiers of all organisation units present in the response mapped to a string representing the hierarchy. This hierarchy string lists the identifiers of the ancestors (parents) of the organisation unit starting from the root. The *names* object contains the identifiers of all items in the response mapped to their names.

The *rows* section contains the enrollments produced by the query. Each row represents exactly one enrollment.

### Analytics across TEI relationships with program indicators { #analytics-across-tei-relationships-with-program-indicators } 

The non-aggregation enrollment analytics API also supports linking Program Indicators to Relationship Types, in order to show the result of a calculation of a specific Program Indicator applied to the related entities of the listed Tracked Entity Instance.

![](resources/images/enrollments/enrollments-pi-relationship.jpg)

For the Program Indicator/Relationship Type link to work, the `/api/33/analytics/enrollments/query` API requires an additional dimension which must include the chosen Relationship Type UID and the chosen Program Indicator UID:

    /api/33/analytics/enrollments/query/<program-id>
      ?dimension=<relationshiptype-id>.<programindicator-id>

For example, to retrieve a list of enrollments from the "WHO RMNCH Tracker" program for January 2019 and display the count of Malaria Cases linked to that Enrollment by "Malaria case linked to person" type of relationship, you can use the following query

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=mxZDvSZYxlw.nFICjJluo74
      &startDate=2019-01-01&endDate=2019-01-31    

The API supports using program indicators which are not associated to the "main" program (that is the program ID specified after `/query/`).

## Dimensions { #webapi_dimensions }

Four resources allow to easily retrieve data dimensions:

- [Event Query data dimensions](#webapi_event_query_analytics_dimension)`/analytics/events/query/dimensions` 
- [Event Aggregate data dimensions](#webapi_event_aggregate_analytics_dimension) `/analytics/events/aggregate/dimensions`
- [Enrollment Query data dimensions](#webapi_enrollment_query_analytics_dimension) `/analytics/enrollments/query/dimensions`
- [Enrollment Aggregate data dimensions](#webapi_enrollment_aggregate_analytics_dimension) `/analytics/enrollments/aggregate/dimensions`

Resources mentioned above share the following request parameter:

| Paramètre de requête | required                                         | Description                                                                                       | Options                                                                                                                                              |
|-----------------|--------------------------------------------------|---------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------|
| filtre          | no                                               | Allows field value filtering on the format: <br/> `filter=field:OP:value&filter=field:OP:value&...` | See [dimension filters section].(#webapi_analytics_dimension_filters)                                                                                |
| fields          | no                                               | Allows field filtering                                                  |
| page            | no | Page number                                                                                       | Defaults to 1 (first page)                                                                                                                           |
| taille de la page        | no | Page size                                                                                         | Defaults to 50 elements per page                                                                                                                     |
| paging          | no | Disables pagination when `false`                                                                  | `true` or `false`, defaults to `true`                                                                                                                |
| Ordre           | no | Allows sorting on the format: `order=field:direction`                                                                   | Sortable fields: `created` (default), `lastUpdated`, `code`, `uid`, `id`, `name`, `displayName`, `dimensionType`<br/><br/> Direction can be `ASC` (default) or `DESC` |

#### Dimension filters { #webapi_analytics_dimension_filters }

Dimensions endpoints support filtering the output to narrow down the response to desired elements.
Filters are in the format `filter=field:op:value&filter=field:op:value&...&filter=field:op:value`.

Supported `field` values are:

- **id**/**uid** - dimension id
- **code** - dimension code
- **valueType** - dimension value type
- **name** - the name of the dimension
- **dimensionType** - the type of the dimension 
    - `DATA_ELEMENT`
    - `PROGRAM_INDICATOR`
    - `PROGRAM_ATTRIBUTE`
    - `CATEGORY`
    - `CATEGORY_OPTION_GROUP_SET`
- **displayName** - displayName of the dimension
- **displayShortName** - displayShortName of the dimension

Supported `op`values are:

- `startsWith` - field starts with
- `!startsWith` - field does not start with
- `endsWith` - field ends with
- `!endsWith` - field does not end with- 
- `eq` - equals
- `ieq` - equals ignoring case
- `ne` - not equals
- `like` - contains
- `!like` - does not contain
- `ilike` - contains ignoring case
- `!ilike` - does not contain ignoring case

### Event analytics dimensions { #event-analytics-dimensions } 
#### Event query analytics dimensions { #webapi_event_query_analytics_dimension }

The `/analytics/events/query/dimensions?programStageId=...` resource accepts a mandatory tracker program stage and returns the following data dimensions:

- **Program indicators** associated with the program (derived from programStageId)
- **Data elements** of *supported types* in the program stage
- **Tracked entity attributes** of *supported types* associated with the program (derived from programStageId)
- **Categories** in category combo associated with the program (derived from programStageId)
- **Category option group sets** of type `ATTRIBUTE`

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

#### Event aggregate dimensions { #webapi_event_aggregate_analytics_dimension }

The `/analytics/events/aggregate/dimensions?programStageId=...` resource accepts a mandatory `programStageId` parameter and returns the following data dimensions:

- **Data elements** of *supported types* in the program stage
- **Tracked entity attributes** of *supported types* associated with the program (derived from programStageId)
- **Categories** in category combo associated with the program (derived from programStageId)
- **Category option group sets** of type `ATTRIBUTE` associated with program (derived from programStageId)

Data elements and tracked entity attributes are considered *supported types* if their value type is one of the following:

- `NUMBER`
- `UNIT_INTERVAL`
- `PERCENTAGE`
- `INTEGER`
- `INTEGER_POSITIVE`
- `INTEGER_NEGATIVE`
- `INTEGER_ZERO_OR_POSITIVE`
- `BOOLEAN`
- `TRUE_ONLY`

### Enrollment analytics dimensions { #enrollment-analytics-dimensions } 

#### Enrollment query analytics dimensions { #webapi_enrollment_query_analytics_dimension }

The `/analytics/enrollments/query/dimensions?programId=...` resource accepts a mandatory id of a tracker program and returns the following data dimensions:

- **Program indicators** connected to the program
- **Data elements** of *supported types* in the program, with program stage for each data element
- **Tracked entity attributes** of *supported types* associated with the program that are not confidential

All value types for data elements and tracked entity attributes are considered *supported types*, except `IMAGE`, `FILE_RESOURCE` and `TRACKER_ASSOCIATE`.

#### Enrollment aggregate dimensions { #webapi_enrollment_aggregate_analytics_dimension }

The `/analytics/enrollments/aggregate/dimensions?programId=...` resource accepts a mandatory id of a tracker program, referring to a program with registration, and returns the following data dimensions:

- **Data elements** of *supported types* in the program, with program stage for each data element
- **Tracked entity attributes** of *supported types* associated with the program that are not confidential

Data elements and tracked entity attributes are considered *supported types* if their value type is one of the following:

- `NUMBER`
- `UNIT_INTERVAL`
- `PERCENTAGE`
- `INTEGER`
- `INTEGER_POSITIVE`
- `INTEGER_NEGATIVE`
- `INTEGER_ZERO_OR_POSITIVE`
- `BOOLEAN`
- `TRUE_ONLY`

### Sample request and response { #sample-request-and-response } 

    GET /api/analytics/events/query/dimensions?programStageId=A03MvHHogjR&order=code&filter=name:ilike:weight

```json
{
   "page":1,
   "total":5,
   "pageSize":50,
   "dimensions":[
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-08-06T22:49:20.128",
         "lastUpdated":"2015-08-06T22:51:19.787",
         "name":"Measles + Yellow fever doses low infant weight",
         "displayName":"Measles + Yellow fever doses low infant weight",
         "id":"tt54DiKuQ9c",
         "uid":"tt54DiKuQ9c",
         "displayShortName":"Measles + Yellow fever doses low infant weight"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2017-01-20T10:32:26.388",
         "lastUpdated":"2017-01-20T10:32:26.388",
         "name":"Weight gain(in g) between birth and last postnatal",
         "displayName":"Weight gain(in g) between birth and last postnatal",
         "id":"qhTkqwAJLMv",
         "uid":"qhTkqwAJLMv",
         "displayShortName":"Weight gain(g)"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-09-14T20:25:55.543",
         "lastUpdated":"2018-08-28T12:22:47.857",
         "name":"Average weight (g)",
         "displayName":"Average weight (g)",
         "id":"GxdhnY5wmHq",
         "uid":"GxdhnY5wmHq",
         "displayShortName":"Average weight (g)"
      },
      {
         "dimensionType":"PROGRAM_INDICATOR",
         "created":"2015-08-06T22:35:40.391",
         "lastUpdated":"2015-08-06T22:35:40.391",
         "name":"BCG doses low birth weight",
         "displayName":"BCG doses low birth weight",
         "id":"hCYU0G5Ti2T",
         "uid":"hCYU0G5Ti2T",
         "displayShortName":"BCG doses low birth weight"
      },
      {
         "valueType":"NUMBER",
         "dimensionType":"DATA_ELEMENT",
         "created":"2012-09-20T17:37:45.474",
         "lastUpdated":"2014-11-11T21:56:05.418",
         "name":"MCH Weight (g)",
         "displayName":"MCH Weight (g)",
         "id":"A03MvHHogjR.UXz7xuGCEhU",
         "uid":"UXz7xuGCEhU",
         "code":"DE_2005736",
         "displayShortName":"Weight (g)"
      }
   ]
}
```

## Org unit analytics { #webapi_org_unit_analytics } 

The org unit analytics API provides statistics on org units classified by org unit group sets, i.e. counts of org units per org unit group within org unit group sets.

    GET /api/orgUnitAnalytics?ou=<org-unit-id>&ougs=<org-unit-group-set-id>

The API requires at least one organisation unit and at least one organisation unit group set. Multiple org units and group sets can be provided separated by a semicolon.

### Paramètres de requête{ #request-query-parameters }

The org unit analytics resource lets you specify a range of query parameters:



Table: Org unit analytics query parameters

| Propriété | Description | Obligatoire |
|---|---|---|
| ou | Org unit identifiers, potentially separated by a semicolon. | Oui |
| ougs | Org unit group set identifiers, potentially separated by a semicolon. | Oui |
| colonnes | Org unit group set identifiers, potentially separated by a semicolon. Defines which group sets are rendered as columns in a table layout. | Non |

The response will contain a column for the parent org unit, columns for each org unit group set part of the request and a column for the count. The statistics include the count of org units which are part of the sub-hierarchy of the org units specified in the request. The response contains a metadata section which specifies the name of each org unit and org unit group part of the response referenced by their identifiers.

The default response is normalized with a single `count` column. The response can be rendered in a table layout by specifying at least one org unit group set using the `columns` query parameter.

### Response formats { #response-formats } 

The org unit analytics endpoint supports the following representation formats:

- json (application/json)
- csv (application/csv)
- xls (application/vnd.ms-excel)
- pdf (application/pdf)

### Exemples { #examples }

To fetch org unit analytics for an org unit and org unit group set:

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw&ougs=J5jldMd8OHv

To fetch org unit analytics data for two org units and two org unit group sets:

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw;PMa2VCrupOd&ougs=J5jldMd8OHv;Bpx0589u8y0

To fetch org unit analytics data in table mode with one group set rendered as columns:

    GET /api/orgUnitAnalytics?ou=fdc6uOvgoji;jUb8gELQApl;lc3eMKXaEfw;PMa2VCrupOd
      &ougs=J5jldMd8OHv&columns=J5jldMd8OHv

### Contraintes et validation { #constraints-and-validation }

The possible validation errors specifically for the org unit analytics API are described in the table below. Some errors specified for the aggregate analytics API are also relevant.

| Code d'erreur | Message |
| ---------- | ------- |
| E7300      | Au moins une unité d'organisation doit être spécifiée |
| E7301      | At least one organisation unit group set must be specified |

## Data set report { #webapi_data_set_report } 

Data set reports can be generated through the web api using the
`/dataSetReport` resource. This resource generates reports on data set
and returns the result in the form of an HTML table.

    /api/33/dataSetReport

### Paramètres de requête{ #request-query-parameters }

The request supports the following parameters:



Table: Data set report query parameters

| Paramètre | Description | Type | Obligatoire |
|---|---|---|---|
| ds | Data set to create the report from. | Data set UID | Oui |
| pe | Period(s) to create the report from. May be a comma-separated list. | ISO String | Oui |
| ou | Organisation unit to create the report from. | Organisation unit UID | Oui |
| filtre | Filters to be used as filters for the report. Can be repeated any number of times. Follows the analytics API syntax. | One or more UIDs | Non |
| selectedUnitOnly | Whether to use captured data only or aggregated data. | Booléen | Non |

The data set report resource accepts `GET` requests only. The response content type is `application/json` and returns data in a grid. This endpoint works for all types of data sets, including default, section and custom forms.

An example request to retrieve a report for a monthly data set and org unit for October 2018 looks like this:

    GET /api/33/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd&selectedUnitOnly=false

An example request to retrieve a report for a monthly data set and org unit for October, November, and December 2018 looks like this:

    GET /api/33/dataSetReport?ds=BfMAe6Itzgt&pe=201810,201811,201812&ou=ImspTQPwCqd&selectedUnitOnly=false

To get a data set report with a filter you can use the `filter` parameter. In this case, the filter is based on an org unit group set and two org unit groups:

    GET /api/33/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd
      &filter=J5jldMd8OHv:RXL3lPSK8oG;tDZVQ1WtwpA

### Response formats { #response-formats } 

The data set report endpoint supports output in the following formats. You can retrieve a specific endpoint using the file extension or `Accept` HTTP header.

- json (application/json)
- pdf (application/pdf)
- xls (application/vnd.ms-excel)

### Custom forms { #custom-forms } 

A dedicated endpoint is available for data sets with custom HTML forms. This endpoint returns the HTML form content with content type `text/html` with data inserted into it. Note that you can use the general data set report endpoint also for data sets with custom forms; however, that will return the report in JSON format as a grid. This endpoint only works for data sets with custom HTML forms.

    GET /api/33/dataSetReport/custom

The syntax for this endpoint is otherwise equal to the general data set report endpoint. To retrieve a custom HTML data set report you can issue a request like this:

    GET /api/33/dataSetReport/custom?ds=lyLU2wR22tC&pe=201810&ou=ImspTQPwCqd


## Push Analysis { #webapi_push_analysis } 

The push analysis API includes endpoints for previewing a push analysis
report for the logged in user and manually triggering the system to
generate and send push analysis reports, in addition to the normal CRUD
operations. When using the create and update endpoints for push
analysis, the push analysis will be scheduled to run based on the
properties of the push analysis. When deleting or updating a
push analysis to be disabled, the job will also be stopped from running
in the future.

To get an HTML preview of an existing push analysis, you can do a GET
request to the following endpoint:

    /api/33/pushAnalysis/<id>/render

To manually trigger a push analysis job, you can do a POST request to
this endpoint:

    /api/33/pushAnalysis/<id>/run

A push analysis consists of the following properties, where some are
required to automatically run push analysis jobs:



Table: Push analysis properties

| Propriété | Description | Type | Obligatoire |
|---|---|---|---|
| dashboard | Dashboard on which reports are based | Dashboard UID | Oui |
| message | Appears after title in reports | Chaîne | Non |
| recipientUserGroups | A set of user groups who should receive the reports | One or more user Group UID | No. Scheduled jobs without any recipient will be skipped. |
| activé | Indicated whether this push analysis should be scheduled or not. False by default. | Booléen | Yes. Must be true to be scheduled. |
| schedulingFrequency | The frequency of which reports should be scheduled. | "DAILY", "WEEKLY", "MONTHLY" | No. Push analysis without a frequency will not be scheduled |
| schedulingDayOfFrequency | The day in the frequency the job should be scheduled. | Integer. Any value when frequency is "DAILY". 0-7 when frequency is "WEEKLY". 1-31 when frequency is "MONTHLY" | No. Push analysis without a valid day of frequency for the frequency set will not be scheduled. |

## Data usage analytics { #webapi_usage_analytics } 

The usage analytics API lets you access information about how people are
using DHIS2 based on data analysis. When users access favorites, an
event is recorded. The event consists of the user name, the UID of the
favorite, when the event took place, and the type of event. The
different types of events are listed in the table.

    /api/33/dataStatistics

The usage analytics API lets you retrieve aggregated snapshots of usage
analytics based on time intervals. The API captures user views (for
example the number of times a chart or pivot table has been viewed by a
user) and saved analysis favorites (for example favorite charts and
pivot tables). DHIS2 will capture nightly snapshots which are then
aggregated at request.

### Request query parameters { #webapi_usage_analytics_request_query_parameters } 

The usage analytics (data statistics) API supports two operations:

  - *POST:* creates a view event

  - *GET:* retrieves aggregated statistics

### Create view events (POST) { #webapi_usage_analytics_create_view_events } 

The usage analytics API lets you create event views. The
dataStatisticsEventType parameter describes what type of item was
viewed. The favorite parameter indicates the identifier of the relevant
favorite.

URL that creates a new event view of
    charts:

    POST /api/33/dataStatistics?eventType=CHART_VIEW&favorite=LW0O27b7TdD

A successful save operation returns an HTTP status code 201. The table
below shows the supported types of events.



Table: Supported event types

| Clé | Description |
|---|---|
| VISUALIZATION_VIEW | Visualization view |
| MAP_VIEW | Map view (GIS) |
| EVENT_REPORT_VIEW | Event report view |
| EVENT_CHART_VIEW | Event chart view |
| EVENT_VISUALIZATION_VIEW | Event visualization view |
| DASHBOARD_VIEW | Dashboard view |
| PASSIVE_DASHBOARD_VIEW | Dashboard view (when not explicitly selecting the dashboard) |
| DATA_SET_REPORT_VIEW | Data set report view |

### Retrieve aggregated usage analytics report (GET) { #webapi_aggregated_usage_analytics } 

The usage analytics (data statistics) API lets you specify certain query
parameters when asking for an aggregated report.



Table: Query parameters for aggregated usage analytics (data statistics)

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| date de début | Oui | Start date for period | Date in yyyy-MM-dd format |
| date de fin | Oui | End date for period | Date in yyyy-MM-dd format |
| interval | Oui | Type of interval to be aggregated | DAY, WEEK, MONTH, YEAR |

The startDate and endDate parameters specify the period for which
snapshots are to be used in the aggregation. You must format the dates
as shown above. If no snapshots are saved in the specified period, an
empty list is sent back. The parameter called interval specifies what
type of aggregation will be done.

API query that creates a query for a monthly
    aggregation:

    GET /api/33/dataStatistics?startDate=2014-01-02&endDate=2016-01-01&interval=MONTH

### Retrieve top favorites { #webapi_usage_analytics_top_favorites } 

The usage analytics API lets you retrieve the top favorites used in
DHIS2, and by user.



Table: Query parameters for top favorites

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| eventType | Oui | The data statistics event type | See above table |
| taille de la page | Non | Size of the list returned | For example 5, 10, 25. Default is 25 |
| sortOrder | Non | Descending or ascending | ASC or DESC. Default is DESC. |
| Nom d'utilisateur | Non | If specified, the response will only contain favorites by this user. | For example 'admin' |

The API query can be used without a username, and will then find the top
favorites of the system.

    /api/33/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25&sortOrder=ASC

If the username is specified, the response will only contain the top favorites of that user.

    /api/33/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25
      &sortOrder=ASC&username=admin

### Response format { #webapi_usage_analytics_response_format } 

You can return the aggregated data in a usage analytics response in
several representation formats. The default format is JSON. The
available formats and content types are:

  - json (application/json)

  - xml (application/xml)

  - html (text/html)

API query that requests a usage analytics response in XML
    format:

    /api/33/dataStatistics.xml?startDate=2014-01-01&endDate=2016-01-01&interval=WEEK

You must retrieve the aggregated usage analytics response with the HTTP
GET method. This allows you to link directly from Web pages and other
HTTP-enabled clients to usage analytics responses. To do functional
testing use the cURL library.

To get an usage analytics response in JSON format:

    /api/33/dataStatistics?startDate=2016-02-01&endDate=2016-02-14&interval=WEEK

The JSON response looks like this:

```json
[
  {
    "year": 2016,
    "week": 5,
    "mapViews": 2181,
    "chartViews": 2227,
    "reportTableViews": 5633,
    "eventReportViews": 6757,
    "eventChartViews": 9860,
    "eventVisualizationViews": 2387,
    "dashboardViews": 10082,
    "passiveDashboardViews": 0,
    "totalViews": 46346,
    "averageViews": 468,
    "averageMapViews": 22,
    "averageChartViews": 22,
    "averageReportTableViews": 56,
    "averageEventReportViews": 68,
    "averageEventChartViews": 99,
    "averageEventVisualizationViews": 10,
    "averageDashboardViews": 101,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1805,
    "savedCharts": 2205,
    "savedReportTables": 1995,
    "savedEventReports": 1679,
    "savedEventCharts": 1613,
    "savedEventVisualizations": 1231,
    "savedDashboards": 0,
    "savedIndicators": 1831,
    "activeUsers": 99,
    "users": 969
  },
  {
    "year": 2016,
    "week": 6,
    "mapViews": 2018,
    "chartViews": 2267,
    "reportTableViews": 4714,
    "eventReportViews": 6697,
    "eventChartViews": 9511,
    "dashboardViews": 12181,
    "passiveDashboardViews": 0,
    "totalViews": 47746,
    "averageViews": 497,
    "averageMapViews": 21,
    "averageChartViews": 23,
    "averageReportTableViews": 49,
    "averageEventReportViews": 69,
    "averageEventChartViews": 99,
    "averageDashboardViews": 126,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1643,
    "savedCharts": 1935,
    "savedReportTables": 1867,
    "savedEventReports": 1977,
    "savedEventCharts": 1714,
    "savedDashboards": 0,
    "savedIndicators": 1646,
    "activeUsers": 96,
    "users": 953
  }
]
```

### Retrieve statistics for a favorite { #webapi_usage_analytics_retrieve_favorite_statistics } 

You can retrieve the number of view for a specific favorite by using the
*favorites* resource, where *{favorite-id}* should be substituted with
the identifier of the favorite of interest:

    /api/33/dataStatistics/favorites/{favorite-id}.json

The response will contain the number of views for the given favorite and
look like this:

```json
{
  "views": 3
}
```

## Geospatial features { #webapi_geospatial_features } 

The *geoFeatures* resource lets you retrieve geospatial information from
DHIS2. Geospatial features are stored together with organisation units.
The syntax for retrieving features is identical to the syntax used for
the organisation unit dimension for the analytics resource. It is
recommended to read up on the analytics api resource before continuing
to read this section. You must use the GET request type, and only JSON
response format is supported.

As an example, to retrieve geo features for all organisation units at
level 3 in the organisation unit hierarchy you can use a GET request
with the following URL:

    /api/33/geoFeatures.json?ou=ou:LEVEL-3

To retrieve geo features for organisation units at a level within the
boundary of an organisation unit (e.g. at level 2) you can use this URL:

    /api/33/geoFeatures.json?ou=ou:LEVEL-4;O6uvpzGd5pu

The response coordinates value can be read from two properties which is decided by the parameter `coordinateField`.
  - The `geometry` property of the OrganisationUnit: this is the default behaviour which is applied when parameter `coordinateField` is not provided.
  - The OrgansationUnit attribute of value type GeoJSON: the api will use the provided `coordinateField={attributeId}` to get the GeoJSON coordinates from this attribute value.

For example, to retrieve geo features for all organisation units at level 3 as above but get the coordinates from OrganisationUnit attribute `tJqtSV4quLb`

    /api/33/geoFeatures.json?ou=ou:LEVEL-3&coordinateField=tJqtSV4quLb

The semantics of the response properties are described in the following
table.

Table: Geo features response

| Propriété | Description |
|---|---|
| identifiant | Organisation unit / geo feature identifier |
| na | Organisation unit / geo feature name |
| hcd | Has coordinates down, indicating whether one or more children organisation units exist with coordinates (below in the hierarchy) |
| hcu | Has coordinates up, indicating whether the parent organisation unit has coordinates (above in the hierarchy) |
| le | Level of this organisation unit / geo feature. |
| pg | Parent graph, the graph of parent organisation unit identifiers up to the root in the hierarchy |
| pi | Parent identifier, the identifier of the parent of this organisation unit |
| pn | Parent name, the name of the parent of this organisation unit |
| ty | Geo feature type, 1 = point and 2 = polygon or multi-polygon |
| co | Coordinates of this geo feature |


### GeoJSON { #geojson } 

To export GeoJSON, you can simply add *.geosjon* as an extension to the
endpoint */api/organisationUnits*, or you can use the *Accept* header
*application/json+geojson*.

Two parameters are supported: `level` (default is 1) and `parent` (default is root organisation units). Both can be included multiple times. Some examples:

Get all features at level 2 and 4:

    /api/organisationUnits.geojson?level=2&level=4

Get all features at level 3 with a boundary organisation unit:

    /api/organisationUnits.geojson?parent=fdc6uOvgoji&level=3

## Analytics table hooks { #webapi_analytics_table_hooks } 

Analytics table hooks provide a mechanism for invoking SQL scripts
during different phases of the analytics table generation process. This
is useful for customizing data in resource and analytics tables, e.g. in
order to achieve specific logic for calculations and aggregation.
Analytics table hooks can be manipulated at the following API endpoint:

    /api/analyticsTableHooks

The analytics table hooks API supports the standard HTTP CRUD operations
for creating (POST), updating (PUT), retrieving (GET) and deleting
(DELETE) entities.

### Hook fields { #webapi_analytics_table_hook_fields } 

Analytics table hooks have the following fields:



Table: Analytics table hook fields

| Champ | Options | Description |
|---|---|---|
| nom | Texte | Name of the hook. |
| phase | RESOURCE_TABLE_POPULATED, ANALYTICS_TABLE_POPULATED | The phase for when the SQL script should be invoked. |
| resourceTableType | See column "Table type" in table "Phases, table types and temporary tables" below | The type of resource table for which to invoke the SQL script. Applies only for hooks defined with the RESOURCE_TABLE_POPULATED phase. |
| analyticsTableType | See column "Table type" in table "Phases, table types and temporary tables" below | The type of analytics table for which to invoke the SQL script. Applies only for hooks defined with the ANALYTICS_TABLE_POPULATED phase. |
| sql | Texte | The SQL script to invoke. |

The *ANALYTICS_TABLE_POPULATED* phase takes place after the analytics
table has been populated, but before indexes have been created and the
temp table has been swapped with the main table. As a result, the SQL
script should refer to the analytics temp table, e.g. *analytics_temp*,
*analytics_completeness_temp*, *analytics_event_temp_ebayegv0exc*.

This applies also to the *RESOURCE_TABLE_POPULATED* phase, which takes
place after the resource table has been populated, but before indexes
have been created and the temp table has been swapped with the main
table. As a result, the SQL script should refer to the resource temp
table, e.g. *_orgunitstructure_temp*, *_categorystructure_temp*.

You should define only one of the *resourceTableType* and
*analyticsTableType* fields, depending on which *phase* is defined.

You can refer to the temporary database table which matches the
specified hook table type only (other temporary tables will not be
available). As an example, if you specify *ORG_UNIT_STRUCTURE* as the
resource table type, you can refer to the *_orgunitstructure_temp*
temporary database table only.

The following table shows the valid combinations of phases, table types
and temporary tables.



Table: Phases, table types and temporary tables

| Phase | Table type | Temporary table |
|---|---|---|
| RESOURCE_TABLE_POPULATED | ORG_UNIT_STRUCTURE | \_orgunitstructure\_temp |
|| DATA_SET_ORG_UNIT_CATEGORY |\_datasetorgunitcategory\_temp |
|| CATEGORY_OPTION_COMBO_NAME | \_categoryoptioncomboname\_temp |
|| DATA_ELEMENT_GROUP_SET_STRUCTURE | \_dataelementgroupsetstructure\_temp |
|| INDICATOR_GROUP_SET_STRUCTURE |\_indicatorgroupsetstructure\_temp |
|| ORG_UNIT_GROUP_SET_STRUCTURE | \_organisationunitgroupsetstructure\_temp |
|| CATEGORY_STRUCTURE | \_categorystructure\_temp |
|| DATA_ELEMENT_STRUCTURE | \_dataelementstructure\_temp |
|| PERIOD_STRUCTURE | \_periodstructure\_temp |
|| DATE_PERIOD_STRUCTURE | \_dateperiodstructure\_temp |
|| DATA_ELEMENT_CATEGORY_OPTION_COMBO | \_dataelementcategoryoptioncombo\_temp |
|| DATA_APPROVAL_MIN_LEVEL | \_dataapprovalminlevel\_temp |
| ANALYTICS_TABLE_POPULATED | DATA_VALUE | analytics\_temp |
|| COMPLETENESS | analytics\_completeness\_temp |
|| COMPLETENESS_TARGET | analytics\_completenesstarget\_temp |
|| ORG_UNIT_TARGET | analytics\_orgunittarget\_temp |
|| ÉVÉNEMENT | analytics\_event\_temp\_{program-uid} |
|| INSCRIPTION | analytics\_enrollment\_temp\_{program-uid} |
|| VALIDATION_RESULT | analytics\_validationresult\_temp |

### Creating hooks { #webapi_create_analytics_table_hook } 

To create a hook which should run after the resource tables have been populated you can do a *POST* request like this using *JSON* format:

```bash
curl -d @hooks.json "localhost/api/analyticsTableHooks" -H "Content-Type:application/json" -u admin:district
```

```json
{
  "name": "Update 'Area' in org unit group set resource table",
  "phase": "RESOURCE_TABLE_POPULATED",
  "resourceTableType": "ORG_UNIT_GROUP_SET_STRUCTURE",
  "sql": "update _organisationunitgroupsetstructure_temp set \"uIuxlbV1vRT\" = 'b0EsAxm8Nge'"
}
```

To create a hook which should run after the data value analytics table has been populated you can do a *POST* request like this using *JSON* format:

```json
{
  "name": "Update 'Currently on treatment' data in analytics table",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "DATA_VALUE",
  "sql": "update analytics_temp set monthly = '200212' where monthly in ('200210', '200211')"
}
```

To create a hook which should run after the event analytics tables are populated you can do a *POST* request like this using *JSON* format:

```json
{
  "name": "Delete data for a data element",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "EVENT",
  "sql": "delete from analytics_event_temp_lxaq7zs9vyr where dx = 'uDX9LKGRwaH'"
}
```



## SVG conversion { #webapi_svg_conversion } 

The Web API provides a resource which can be used to convert SVG content
into more widely used formats such as PNG and PDF. Ideally this
conversion should happen on the client side, but not all client side
technologies are capable of performing this task. Currently PNG and PDF
output formats are supported. The SVG content itself should be passed with
a *svg* query parameter, and an optional query parameter *filename* can
be used to specify the filename of the response attachment file. Note
that the file extension should be omitted. For PNG you can send a *POST*
request to the following URL with Content-type
`application/x-www-form-urlencoded`, identical to a regular HTML form
submission.

    api/svg.png

For PDF you can send a *POST* request to the following URL with
content-type `application/x-www-form-urlencoded`.

    api/svg.pdf



Tableau : Paramètres de requête

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| svg | Oui | The SVG content |
| filename | Non | The file name for the returned attachment without file extension |

## Analytics query execution plan and costs including execution time estimation { #analytics-query-execution-plan-and-costs-including-execution-time-estimation } 
The Web Api provides entry point for the investigation of analytics database issues. 
It is implemented as a part of all analytics controllers:
- analytics/explain
- analytics/event/explain
- analytics/enrollment/explain

**Example**

Request:

http://localhost:8080/dhis/api/29/analytics/explain?displayProperty=NAME&dimension=dx:Uvn6LCg7dVU;sB79w2hiLp8,ou:USER_ORGUNIT&filter=pe:THIS_YEAR&includeNumDen=false&skipMeta=false&skipData=true&includeMetadataDetails=true

Response:

```
{
    "headers": [
        {
            "name": "dx",
            "column": "Data",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": true
        },
        {
            "name": "ou",
            "column": "Organisation unit",
            "valueType": "TEXT",
            "type": "java.lang.String",
            "hidden": false,
            "meta": true
        },
        {
            "name": "value",
            "column": "Value",
            "valueType": "NUMBER",
            "type": "java.lang.Double",
            "hidden": false,
            "meta": false
        }
    ],
    "metaData": {
        "items": {
            "ImspTQPwCqd": {
                "uid": "ImspTQPwCqd",
                "code": "OU_525",
                "name": "Sierra Leone",
                "dimensionItemType": "ORGANISATION_UNIT",
                "valueType": "NUMBER",
                "totalAggregationType": "SUM"
            },
            "sB79w2hiLp8": {
                "uid": "sB79w2hiLp8",
                "name": "ANC 3 Coverage",
                "description": "Total 3rd ANC visits (Fixed and outreach) by expected number of pregnant women.",
                "legendSet": "fqs276KXCXi",
                "dimensionItemType": "INDICATOR",
                "valueType": "NUMBER",
                "totalAggregationType": "AVERAGE",
                "indicatorType": {
                    "name": "Per cent",
                    "displayName": "Per cent",
                    "factor": 100,
                    "number": false
                }
            },
            "dx": {
                "uid": "dx",
                "name": "Data",
                "dimensionType": "DATA_X"
            },
            "pe": {
                "uid": "pe",
                "name": "Period",
                "dimensionType": "PERIOD"
            },
            "ou": {
                "uid": "ou",
                "name": "Organisation unit",
                "dimensionType": "ORGANISATION_UNIT"
            },
            "Uvn6LCg7dVU": {
                "uid": "Uvn6LCg7dVU",
                "code": "IN_52486",
                "name": "ANC 1 Coverage",
                "description": "Total 1st ANC visits (Fixed and outreach) by expected number of pregnant women.",
                "legendSet": "fqs276KXCXi",
                "dimensionItemType": "INDICATOR",
                "valueType": "NUMBER",
                "totalAggregationType": "AVERAGE",
                "indicatorType": {
                    "name": "Per cent",
                    "displayName": "Per cent",
                    "factor": 100,
                    "number": false
                }
            },
            "THIS_YEAR": {
                "name": "This year"
            },
            "2022": {
                "uid": "2022",
                "code": "2022",
                "name": "2022",
                "dimensionItemType": "PERIOD",
                "valueType": "NUMBER",
                "totalAggregationType": "SUM",
                "startDate": "2022-01-01T00:00:00.000",
                "endDate": "2022-12-31T00:00:00.000"
            }
        },
        "dimensions": {
            "dx": [
                "Uvn6LCg7dVU",
                "sB79w2hiLp8"
            ],
            "pe": [
                "2022"
            ],
            "ou": [
                "ImspTQPwCqd"
            ],
            "co": []
        }
    },
    "performanceMetrics": {
        "totalTimeInMillis": 90.894,
        "executionPlans": [
            {
                "timeInMillis": 12.314,
                "planningTime": 6.801,
                "executionTime": 5.513,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(daysxvalue) / 365 as value from analytics_2022 as ax where ax.\"dx\" in ('h0xKKjijTdI') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 20.21,
                    "Total Cost": 5602.98,
                    "Plan Rows": 260,
                    "Plan Width": 32,
                    "Actual Startup Time": 5.448,
                    "Actual Total Time": 5.449,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 20.21,
                            "Total Cost": 5588.33,
                            "Plan Rows": 1520,
                            "Plan Width": 32,
                            "Actual Startup Time": 0.446,
                            "Actual Total Time": 5.003,
                            "Actual Rows": 1032,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'h0xKKjijTdI'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 46,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ao_ax_2022_MClNI",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 19.83,
                                    "Plan Rows": 1520,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 0.406,
                                    "Actual Total Time": 0.407,
                                    "Actual Rows": 1032,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'h0xKKjijTdI'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            },
            {
                "timeInMillis": 38.35,
                "planningTime": 0.627,
                "executionTime": 37.723,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(value) as value from analytics_2022 as ax where ax.\"dx\" in ('Jtf34kNZhzP') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 193.57,
                    "Total Cost": 47322.83,
                    "Plan Rows": 261,
                    "Plan Width": 32,
                    "Actual Startup Time": 37.685,
                    "Actual Total Time": 37.685,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 193.57,
                            "Total Cost": 47191.38,
                            "Plan Rows": 17179,
                            "Plan Width": 32,
                            "Actual Startup Time": 1.981,
                            "Actual Total Time": 32.332,
                            "Actual Rows": 17462,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'Jtf34kNZhzP'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 1165,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ax_2022_Eb64F",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 189.27,
                                    "Plan Rows": 17179,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 1.765,
                                    "Actual Total Time": 1.765,
                                    "Actual Rows": 17462,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'Jtf34kNZhzP'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            },
            {
                "timeInMillis": 40.23,
                "planningTime": 5.153,
                "executionTime": 35.077,
                "query": "select ax.\"dx\",ax.\"uidlevel1\", sum(value) as value from analytics_2022 as ax where ax.\"dx\" in ('fbfJHSPpUQD') and ax.\"uidlevel1\" in ('ImspTQPwCqd') and ( ax.\"yearly\" in ('2022') ) and ax.\"year\" in (2022) group by ax.\"dx\",ax.\"uidlevel1\"",
                "plan": {
                    "Node Type": "Aggregate",
                    "Strategy": "Sorted",
                    "Partial Mode": "Simple",
                    "Parallel Aware": false,
                    "Async Capable": false,
                    "Startup Cost": 207.21,
                    "Total Cost": 49892.62,
                    "Plan Rows": 261,
                    "Plan Width": 32,
                    "Actual Startup Time": 35.034,
                    "Actual Total Time": 35.034,
                    "Actual Rows": 1,
                    "Actual Loops": 1,
                    "Group Key": [
                        "dx",
                        "uidlevel1"
                    ],
                    "Plans": [
                        {
                            "Node Type": "Bitmap Heap Scan",
                            "Parent Relationship": "Outer",
                            "Parallel Aware": false,
                            "Async Capable": false,
                            "Relation Name": "analytics_2022",
                            "Alias": "ax",
                            "Startup Cost": 207.21,
                            "Total Cost": 49751.83,
                            "Plan Rows": 18423,
                            "Plan Width": 32,
                            "Actual Startup Time": 1.688,
                            "Actual Total Time": 30.32,
                            "Actual Rows": 18542,
                            "Actual Loops": 1,
                            "Recheck Cond": "(dx = 'fbfJHSPpUQD'::bpchar)",
                            "Rows Removed by Index Recheck": 0,
                            "Filter": "((uidlevel1 = 'ImspTQPwCqd'::bpchar) AND (yearly = '2022'::text) AND (year = 2022))",
                            "Rows Removed by Filter": 0,
                            "Exact Heap Blocks": 1239,
                            "Lossy Heap Blocks": 0,
                            "Plans": [
                                {
                                    "Node Type": "Bitmap Index Scan",
                                    "Parent Relationship": "Outer",
                                    "Parallel Aware": false,
                                    "Async Capable": false,
                                    "Index Name": "in_dx_ax_2022_Eb64F",
                                    "Startup Cost": 0.0,
                                    "Total Cost": 202.6,
                                    "Plan Rows": 18423,
                                    "Plan Width": 0,
                                    "Actual Startup Time": 1.324,
                                    "Actual Total Time": 1.325,
                                    "Actual Rows": 18542,
                                    "Actual Loops": 1,
                                    "Index Cond": "(dx = 'fbfJHSPpUQD'::bpchar)"
                                }
                            ]
                        }
                    ]
                }
            }
        ]
    },
    "width": 0,
    "rows": [],
    "height": 0,
    "headerWidth": 3
}
```

This response displays the execution plan that the PostgreSQL planner generates for the supplied statement. The execution plan shows how the table(s) referenced by the statement will be scanned — by plain sequential scan, index scan, etc. — and if multiple tables are referenced, what join algorithms will be used to bring together the required rows from each input table.

The most critical part of the display is the estimated statement execution cost, which is the planner's guess at how long it will take to run the statement.

All entry points are secured by authorization. The user has to be in  **ALL** or **F_PERFORM_ANALYTICS_EXPLAIN** role.

## Analytics explain { #webapi_analytics_explain }
**Entry points:**
- analytics/explain
## Event analytics explain { #webapi_event_analytics_explain }
**Entry points:**
- analytics/event/aggregate/{program}/explain
- analytics/event/query/{program}/explain
## Enrollment analytics explain { #webapi_enrollment_analytics_explain }
**Entry points:**
- analytics/enrollment/query/{program}/explain


# Maintenance { #maintenance } 

## Resource and analytics tables { #webapi_generating_resource_analytics_tables } 

DHIS2 features a set of generated database tables which are used as
a basis for various system functionality. These tables can be executed
immediately or scheduled to be executed at regular intervals through the
user interface. They can also be generated through the Web API as
explained in this section. This task is typically one for a system
administrator and not consuming clients.

The resource tables are used internally by the DHIS2 application for
various analysis functions. These tables are also valuable for users
writing advanced SQL reports. They can be generated with a POST or PUT
request to the following URL:

    /api/33/resourceTables

The analytics tables are optimized for data aggregation and used
currently in DHIS2 for the pivot table module. The analytics tables can
be generated with a POST or PUT request to:

    /api/33/resourceTables/analytics



Table: Analytics tables optional query parameters

| Paramètre de requête | Options | Description |
|---|---|---|
| skipResourceTables | faux &#124; vrai | Ignorer la génération des tableaux de ressources |
| skipAggregate | faux &#124; vrai | Skip generation of aggregate data and completeness data |
| skipEvents | faux &#124; vrai | Skip generation of event data |
| skipEnrollment | faux &#124; vrai | Skip generation of enrollment data |
| lastYears | entier | Number of last years of data to include |

"Data Quality" and "Data Surveillance" can be run through the monitoring
task, triggered with the following endpoint:

    /api/33/resourceTables/monitoring

This task will analyse your validation rules, find any violations and
persist them as validation results.

These requests will return immediately and initiate a server-side
process.

## Maintenance { #webapi_maintenance } 

To perform maintenance you can interact with the *maintenance* resource. You should use *POST* or *PUT* as a method for requests. The following methods are available.

Analytics tables clear will drop all analytics tables.

    POST PUT /api/maintenance/analyticsTablesClear

Analytics table analyze will collects statistics about the contents of analytics tables in the database.

    POST PUT /api/maintenance/analyticsTablesAnalyze

Expired invitations clear will remove all user account invitations which
have expired.

    POST PUT /api/maintenance/expiredInvitationsClear

Period pruning will remove periods which are not linked to any data
values.

    POST PUT /api/maintenance/periodPruning

Zero data value removal will delete zero data values linked to data
elements where zero data is defined as not significant:

    POST PUT /api/maintenance/zeroDataValueRemoval

Soft deleted data value removal will permanently delete soft deleted data values.

    POST PUT /api/maintenance/softDeletedDataValueRemoval

Soft deleted program stage instance removal will permanently delete soft deleted events.

    POST PUT /api/maintenance/softDeletedProgramStageInstanceRemoval

Soft deleted program instance removal will permanently delete soft deleted enrollments.

    POST PUT /api/maintenance/softDeletedProgramInstanceRemoval

Soft deleted tracked entity instance removal will permanently delete soft deleted tracked entity instances.

    POST PUT /api/maintenance/softDeletedTrackedEntityInstanceRemoval

Drop SQL views will drop all SQL views in the database. Note that it will not delete the DHIS2 SQL view entities.

    POST PUT /api/maintenance/sqlViewsDrop

Create SQL views will recreate all SQL views in the database.

    POST PUT /api/maintenance/sqlViewsCreate

Category option combo update will remove obsolete and generate missing category option combos for all category combinations.

    POST PUT /api/maintenance/categoryOptionComboUpdate

It is also possible to update category option combos for a single category combo using the following endpoint.

    POST PUT /api/maintenance/categoryOptionComboUpdate/categoryCombo/<category-combo-uid>

Cache clearing will clear the application Hibernate cache and the analytics partition caches.

    POST PUT /api/maintenance/cacheClear

Org unit paths update will re-generate the organisation unit path property. This can be useful e.g. if you imported org units with SQL.

    POST PUT /api/maintenance/ouPathsUpdate

Data pruning will remove complete data set registrations, data approvals, data value audits and data values, in this case for an organisation unit.

    POST PUT /api/maintenance/dataPruning/organisationUnits/<org-unit-id>

Data pruning for data elements, which will remove data value audits and data values.

    POST PUT /api/maintenance/dataPruning/dataElement/<data-element-uid>

Metadata validation will apply all metadata validation rules and return the result of the operation.

    POST PUT /api/metadataValidation

App reload will refresh the DHIS2 managed cache of installed apps by reading from the file system.

    POST PUT /api/appReload

Maintenance operations are supported in a batch style with a POST request to the api/maintenance resource where the operations are supplied as query parameters:

    POST PUT /api/maintenance?analyticsTablesClear=true&expiredInvitationsClear=true
      &periodPruning=true&zeroDataValueRemoval=true&sqlViewsDrop=true&sqlViewsCreate=true
      &categoryOptionComboUpdate=true&cacheClear=true&ouPathsUpdate=true

## System info { #webapi_system_resource } 

The system resource provides you with convenient information and
functions. The system resource can be found at */api/system*.

### Generate identifiers { #webapi_system_resource_generate_identifiers } 

To generate valid, random DHIS2 identifiers you can do a GET request to
this resource:

    /api/33/system/id?limit=3

The *limit* query parameter is optional and indicates how many
identifiers you want to be returned with the response. The default is to
return one identifier. The response will contain a JSON object with an
array named codes, similar to this:

```json
{
  "codes": [
    "Y0moqFplrX4",
    "WI0VHXuWQuV",
    "BRJNBBpu4ki"
  ]
}
```

The DHIS2 UID format has these requirements:

  - 11 characters long.

  - Alphanumeric characters only, ie. alphabetic or numeric characters
    (A-Za-z0-9).

  - Start with an alphabetic character (A-Za-z).

### View system information { #webapi_system_resource_view_system_information } 

To get information about the current system you can do a GET request to
this URL:

    /api/33/system/info

JSON and JSONP response formats are supported. The system info response
currently includes the below properties.

```json
{
  "contextPath": "http://yourdomain.com",
  "userAgent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/29.0.1547.62",
  "calendar": "iso8601",
  "dateFormat": "yyyy-mm-dd",
  "serverDate": "2021-01-05T09:16:03.548",
  "serverTimeZoneId": "Etc/UTC",
  "serverTimeZoneDisplayName": "Coordinated Universal Time",
  "version": "2.13-SNAPSHOT",
  "revision": "11852",
  "buildTime": "2013-09-01T21:36:21.000+0000",
  "serverDate": "2013-09-02T12:35:54.311+0000",
  "environmentVariable": "DHIS2_HOME",
  "javaVersion": "1.7.0_06",
  "javaVendor": "Oracle Corporation",
  "javaIoTmpDir": "/tmp",
  "javaOpts": "-Xms600m -Xmx1500m -XX:PermSize=400m -XX:MaxPermSize=500m",
  "osName": "Linux",
  "osArchitecture": "amd64",
  "osVersion": "3.2.0-52-generic",
  "externalDirectory": "/home/dhis/config/dhis2",
  "databaseInfo": {
    "type": "PostgreSQL",
    "name": "dhis2",
    "user": "dhis",
    "spatialSupport": false
  },
  "memoryInfo": "Mem Total in JVM: 848 Free in JVM: 581 Max Limit: 1333",
  "cpuCores": 8
}
```

> **Note**
>
> If the user requesting this resource does not have full authority then only properties which are not considered sensitive will be included.

To get information about the system context only, i.e. `contextPath` and
`userAgent`, you can make a GET request to the below URL. JSON and
JSONP response formats are supported:

    /api/33/system/context

### Check if username and password combination is correct { #webapi_system_resource_check_username_password } 

To check if some user credentials (a username and password combination)
is correct you can make a *GET* request to the following resource using
*basic authentication*:

    /api/33/system/ping

You can detect the outcome of the authentication by inspecting the *HTTP
status code* of the response header. The meanings of the possible status
codes are listed below. Note that this applies to Web API requests in
general.



Table: HTTP Status codes

| HTTP Status code | Description | Résultat |
|---|---|---|
| 200 | OK | Authentication was successful |
| 302 | Found | No credentials were supplied with the request - no authentication took place |
| 401 | Unauthorized | The username and password combination was incorrect - authentication failed |

### View asynchronous task status { #webapi_system_resource_view_async_task_status } 

Tasks which often take a long time to complete can be performed
asynchronously. After initiating an async task you can poll the status
through the `system/tasks` resource by supplying the task category and
the task identifier of interest.

When polling for the task status you need to authenticate as the same
user which initiated the task. The following task categories are
supported:



Table: Task categories

| Identificateur | Description |
|---|---|
| ANALYTICS_TABLE | Generation of the analytics tables. |
| RESOURCE_TABLE | Generation of the resource tables. |
| MONITORING | Processing of data surveillance/monitoring validation rules. |
| DATAVALUE_IMPORT | Import of data values. |
| EVENT_IMPORT | Import of events. |
| ENROLLMENT_IMPORT | Import of enrollments. |
| TEI_IMPORT | Import of tracked entity instances. |
| METADATA_IMPORT | Import of metadata. |
| DATA_INTEGRITY | Processing of data integrity checks. |

Each asynchronous task is automatically assigned an identifier which can
be used to monitor the status of the task. This task identifier is
returned by the API when you initiate an async task through the various
async-enabled endpoints.

#### Monitoring a task { #monitoring-a-task } 

You can poll the task status through a GET request to the system tasks
resource like this:

    /api/33/system/tasks/{task-category-id}/{task-id}

An example request may look like this:

    /api/33/system/tasks/DATAVALUE_IMPORT/j8Ki6TgreFw

The response will provide information about the status, such as the
notification level, category, time and status. The *completed* property
indicates whether the process is considered to be complete.

```json
[{
  "uid": "hpiaeMy7wFX",
  "level": "INFO",
  "category": "DATAVALUE_IMPORT",
  "time": "2015-09-02T07:43:14.595+0000",
  "message": "Import done",
  "completed": true
}]
```

#### Monitoring all tasks for a category { #monitoring-all-tasks-for-a-category } 

You can poll all tasks for a specific category through a GET request to
the system tasks resource:

    /api/33/system/tasks/{task-category-id}

An example request to poll for the status of data value import tasks
looks like this:

    /api/33/system/tasks/DATAVALUE_IMPORT

#### Monitor all tasks { #monitor-all-tasks } 

You can request a list of all currently running tasks in the system with
a GET request to the system tasks resource:

    /api/33/system/tasks

The response will look similar to this:

```json
[{
  "EVENT_IMPORT": {},
  "DATA_STATISTICS": {},
  "RESOURCE_TABLE": {},
  "FILE_RESOURCE_CLEANUP": {},
  "METADATA_IMPORT": {},
  "CREDENTIALS_EXPIRY_ALERT": {},
  "SMS_SEND": {},
  "MOCK": {},
  "ANALYTICSTABLE_UPDATE": {},
  "COMPLETE_DATA_SET_REGISTRATION_IMPORT": {},
  "DATAVALUE_IMPORT": {},
  "DATA_SET_NOTIFICATION": {},
  "DATA_INTEGRITY": {
    "OB1qGRlCzap": [{
      "uid": "LdHQK0PXZyF",
      "level": "INFO",
      "category": "DATA_INTEGRITY",
      "time": "2018-03-26T15:02:32.171",
      "message": "Data integrity checks completed in 38.31 seconds.",
      "completed": true
    }]
  },
  "PUSH_ANALYSIS": {},
  "MONITORING": {},
  "VALIDATION_RESULTS_NOTIFICATION": {},
  "REMOVE_EXPIRED_RESERVED_VALUES": {},
  "DATA_SYNC": {},
  "SEND_SCHEDULED_MESSAGE": {},
  "DATAVALUE_IMPORT_INTERNAL": {},
  "PROGRAM_NOTIFICATIONS": {},
  "META_DATA_SYNC": {},
  "ANALYTICS_TABLE": {},
  "PREDICTOR": {}
}]
```

### View asynchronous task summaries { #view-asynchronous-task-summaries } 

The task summaries resource allows you to retrieve a summary of an
asynchronous task invocation. You need to specify the category and
optionally the identifier of the task. The task identifier can be
retrieved from the response of the API request which initiated the
asynchronous task.

To retrieve the summary of a specific task you can issue a request to:

    /api/33/system/taskSummaries/{task-category-id}/{task-id}

An example request might look like this:

    /api/33/system/taskSummaries/DATAVALUE_IMPORT/k72jHfF13J1

The response will look similar to this:

```json
{
  "responseType": "ImportSummary",
  "status": "SUCCESS",
  "importOptions": {
    "idSchemes": {},
    "dryRun": false,
    "async": true,
    "importStrategy": "CREATE_AND_UPDATE",
    "mergeMode": "REPLACE",
    "reportMode": "FULL",
    "skipExistingCheck": false,
    "sharing": false,
    "skipNotifications": false,
    "datasetAllowsPeriods": false,
    "strictPeriods": false,
    "strictCategoryOptionCombos": false,
    "strictAttributeOptionCombos": false,
    "strictOrganisationUnits": false,
    "requireCategoryOptionCombo": false,
    "requireAttributeOptionCombo": false,
    "skipPatternValidation": false
  },
  "description": "Import process completed successfully",
  "importCount": {
    "imported": 0,
    "updated": 431,
    "ignored": 0,
    "deleted": 0
  },
  "dataSetComplete": "false"
}
```

You might also retrieve import summaries for multiple tasks of a
specific category with a request like
this:

    /api/33/system/taskSummaries/{task-category-id}

### Get appearance information { #webapi_system_resource_get_appearance_information } 

You can retrieve the available flag icons in JSON format with a GET
request:

    /api/33/system/flags

You can retrieve the available UI styles in JSON format with a GET
request:

    /api/33/system/styles

## Cluster info { #cluster-info } 

When DHIS 2 is set up in a cluster configuration, it is useful to know which node in the cluster acts as the leader of the cluster. The following API can be used to get the details of the leader node instance. The API supports both JSON and XML formats.

```
GET /api/36/cluster/leader
```

A sample JSON response looks like this:

```json
{
  "leaderNodeId": "play-dhis2-org-dev",
  "leaderNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "currentNodeId": "play-dhis2-org-dev",
  "currentNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "leader": true
}
```

## Min-max data elements { #webapi_min_max_data_elements } 

The min-max data elements resource allows you to set minimum and maximum
value ranges for data elements. It is unique by the combination of
organisation unit, data element and category option combo.

    /api/minMaxDataElements



Table: Min-max data element data structure

| Élément | Description | Type de données |
|---|---|---|
| source | Identifiant de l'unité d'organisation | Chaîne |
| élément de données | Identifiant de l'élément de données | Chaîne |
| optionCombo | Data element category option combo identifier | Chaîne |
| min | Valeur minimale | Entier |
| max | Valeur maximum | Entier |
| generated | Indicates whether this object is generated by the system (and not set manually). | Booléen |

You can retrieve a list of all min-max data elements from the following
resource:

    GET /api/minMaxDataElements.json

You can filter the response like this:

    GET /api/minMaxDataElements.json?filter=dataElement.id:eq:UOlfIjgN8X6

    GET /api/minMaxDataElements.json?filter=dataElement.id:in:[UOlfIjgN8X6,xc8gmAKfO95]

The filter parameter for min-max data elements supports two operators:
eq and in. You can also use the `fields` query parameter.

    GET /api/minMaxDataElements.json?fields=:all,dataElement[id,name]

### Add/update min-max data element { #webapi_add_update_min_max_data_element } 

To add a new min-max data element, use POST request to:

    POST /api/minMaxDataElements.json

The JSON content format looks like this:

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

If the combination of data element, organisation unit and category
option combo exists, the min-max value will be updated.

### Delete min-max data element { #webapi_delete_min_max_data_element } 

To delete a min-max data element, send a request with DELETE method:

    DELETE /api/minMaxDataElements.json

The JSON content is in similar format as above:

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

## Exceptions de verrouillage { #webapi_lock_exceptions } 

The lock exceptions resource allows you to open otherwise locked data
sets for data entry for a specific data set, period and organisation
unit. You can read lock exceptions from the following resource:

    /api/lockExceptions

To create a new lock exception you can use a POST request and specify
the data set, period and organisation unit:

    POST /api/lockExceptions?ds=BfMAe6Itzgt&pe=201709&ou=DiszpKrYNg8

To delete a lock exception you can use a similar request syntax with a
DELETE request:

    DELETE /api/lockExceptions?ds=BfMAe6Itzgt&pe=201709&ou=DiszpKrYNg8




# I18n { #i18n } 

## Locales { #webapi_locales } 

DHIS2 supports translations both for the user interface and for database
content.

### UI locales { #ui-locales } 

You can retrieve the available locales for the user interface through
the following resource with a GET request. XML and JSON resource
representations are supported.

    /api/33/locales/ui

### Database content locales { #database-content-locales } 

You can retrieve and create locales for the database content with GET and POST requests through the `dbLocales` resource. XML and JSON resource representations are supported. To POST data, there are two required parameters: `country` and `language`. 

    /api/locales/dbLocales?country=US&language=en

## Les traductions { #webapi_translations } 

DHIS2 allows for translations of database content. 
If a metadata is translatable, then it will have a `translations` property.

That means you can retrieve and update translations using metadata class resources such as `api/dataElements`, `api/organisationUnits`, `api/dataSets`, etc.

### Get translations { #get-translations } 

You can get translations for a metadata object such as DataElement by sending a GET request to `api/dataElements/{dataElementUID}`

The response contains full details of the DataElement which also includes the `translations` property as below

```json
{
  "id": "fbfJHSPpUQD",
  "href": "https://play.dhis2.org/dev/api/29/dataElements/fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```
You can also get only the `translations` property of an object by sending a GET request to 
`api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

### Create a translations { #create-a-translations } 

You can create a translation by sending a PUT request with same JSON format to `api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "DESCRIPTION",
      "locale": "fr",
      "value": "description in french"
    },
    {
      "property": "FORM_NAME",
      "locale": "fr",
      "value": "name in french"
    }
  ]
}
```

Alternatively, you can also just update the object with payload including the `translations` property.

Send PUT request to `api/dataElements/{dataElementUID}` with full object payload as below:

```json
{
  "id": "fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

The common properties which support translations are listed in the table below.

Table: Property names

| Property name | Description |
|---|---|
| nom | Object name |
| nomAbrégé | Object short name |
| Description | Object description |

The classes which support translations are listed in the table below.

Table: Class names

| Class name | Description | Other translatable Properties |
|---|---|---|
| DataElementCategoryOption | Option de catégorie | |
| DataElementCategory | Catégorie | |
| DataElementCategoryCombo | La combinaison de catégories | |
| Élément de données | Élément de données | |
| DataElementGroup | Groupe d'éléments de données | |
| DataElementGroupSet | Ensemble de groupes d'éléments de donnée | |
| Indicateur | Indicateur | numeratorDescription, denominatorDescription |
| IndicatorType | Type d'indicateur | |
| IndicatorGroup | Groupe d’indicateurs | |
| IndicatorGroupSet | Ensemble de groupes d'indicateurs | |
| OrganisationUnit | Unité d’organisation | |
| OrganisationUnitGroup | Groupe d'unités d'organisation | |
| OrganisationUnitGroupSet | Ensemble de groupes d'unités d'organisation | |
| Ensemble de données | Ensemble de données | |
| Section | Data set section | |
| ValidationRule | Règle de validation | instruction |
| ValidationRuleGroup | Groupe de règles de validation | |
| Programme | Programme | enrollmentDateLabel, incidentDateLabel |
| Étape du programme | Étape du programme | executionDateLabel, dueDateLabel |
| TrackedEntityAttribute | Attribut d’entité suivie | |
| TrackedEntity | Tracked entity | |
| Type de relation | Relationship type for tracked entity instances | fromToName, toFromName |
| Ensemble d'options | Ensemble d'options | |
| Attribut | Attribute for metadata | |
| ProgramNotificationTemplate | Program Notification template | subjectTemplate, messageTemplate |
| ValidationNotificationTemplate | Validation Notification template | subjectTemplate, messageTemplate |
| DataSetNotificationTemplate | DataSet Notification template | subjectTemplate, messageTemplate |
| Visualization | Visualization | title, subtitle, rangeAxisLabel, baseLineLabel, targetLineLabel, domainAxisLabel |
| ProgramRuleAction | Program Rule Actions | content |
| Prédicteur | Prédicteur | Name, ShortName, Description, Generator Description  |
| ValidationRule | ValidationRule | Name, Description, Instruction, Leftside expression, Rightside expression |

## Internationalization { #webapi_i18n } 

In order to retrieve key-value pairs for translated strings you can use
the *i18n* resource.

    /api/33/i18n

The endpoint is located at */api/i18n* and the request format is a simple
array of the key-value pairs:

```json
[
  "access_denied",
  "uploading_data_notification"
]
```

The request must be of type *POST* and use *application/json* as
content-type. An example using curl, assuming the request data is saved
as a file `keys.json`:

```bash
curl -d @keys.json "play.dhis2.org/demo/api/33/i18n" -X POST
  -H "Content-Type: application/json" -u admin:district
```

The result will look like this:

```json
{
  "access_denied":"Access denied",
  "uploading_data_notification":"Uploading locally stored data to the server"
}
```





# SMS { #sms } 

## Service de messages courts (SMS) { #webapi_sms } 

Cette section porte sur l'API Web SMS, qui permet d'envoyer et de recevoir des messages 
texte courts.

### Service de SMS sortant { #outbound-sms-service } 

L'API Web prend en charge l'envoi de SMS sortants à l'aide de la méthode POST. Les SMS peuvent 
être envoyés à un ou plusieurs destinataires. Une ou plusieurs passerelles doivent 
être configurées avant d'utiliser le service. Un SMS ne sera pas envoyé si 
aucune passerelle n'est configurée. Il nécessite un ensemble de destinataires et 
un texte de message au format JSON, comme indiqué ci-dessous.

    /api/sms/sortant

```json
{
  "message":"Texte du Sms",
  "destinataires": [
    "004712341234",
    "004712341235"
  ]
}
```

> **Remarque**
>
> La liste des destinataires sera divisée si la taille dépasse la limite `DESTINATAIRES_MAXIMUM_AUTORISÉS` de 200.

L'API Web prend également en charge une version de paramètre de requête, mais 
l'API paramétrée ne peut être utilisée que pour envoyer des SMS à un seul 
destinataire.

    /api/sms/outbound?message=text&recipient=004712341234

Les messages sortants peuvent être récupérés à l'aide de la ressource GET.

    GET /api/sms/outbound
    GET /api/sms/outbound?filter=status:eq:SENT
    GET /api/sms/outbound?filter=status:eq:SENT&fields=*

Les messages sortants peuvent être supprimés à l'aide de la ressource SUPPRIMER.

    SUPPRIMER/api/sms/outbound/{uid}
    SUPPRIMER /api/sms/outbound?ids=uid1,uid2

#### Codes de réponse de la passerelle { #gateway-response-codes } 

La passerelle peut répondre avec les codes de réponse suivants.



Tableau : Codes de réponse de la passerelle

| Code de la réponse | Message de réponse | Description détaillée |
|---|---|---|
| CODE DU_RÉSULTAT_0 | succès | Le message a été envoyé avec succès |
| CODE DU_RÉSULTAT_1 | programmé | Le message a été programmé avec succès |
| CODE DU_RÉSULTAT_22 | erreur fatale interne | erreur fatale interne |
| CODE DU_RÉSULTAT_23 | échec de l'authentification | Les données de l'authentification sont incorrectes |
| CODE DU_RÉSULTAT_24 | échec de la validation des données | Les paramètres fournis dans la demande sont incorrects |
| CODE DU_RÉSULTAT_25 | crédits insuffisants | Le crédit est insuffisant pour envoyer un message |
| CODE DU_RÉSULTAT_26 | montant du crédit non disponible | Montant du crédit non disponible |
| CODE DU_RÉSULTAT_27 | vous avez dépassé votre quota journalier | vous avez dépassé votre quota journalier |
| CODE DU_RÉSULTAT_40 | temporairement indisponible | Le service est temporairement interrompu |
| CODE DU_RÉSULTAT_201 | taille maximale du lot dépassée | Taille maximale du lot dépassée |
| CODE DU_RÉSULTAT_200 | succès | La demande a été traitée avec succès |
| CODE DU_RÉSULTAT_202 | accepté | Le(s) message(s) sera(ont) traité(s) |
| CODE DU_RÉSULTAT_207 | multi-statut | Plus d'un message a été soumis à l'API ; cependant, tous les messages n'ont pas le même statut. |
| CODE DU_RÉSULTAT_400 | mauvaise requête | Échec de validation (paramètres ou en-têtes manquants/invalides) |
| CODE DU_RÉSULTAT_401 | Non-autorisé | Échec de l'authentification. Ce problème peut également être causé par des paramètres de verrouillage de l'IP. |
| CODE DU_RÉSULTAT_402 | paiement requis | Crédit insuffisant pour envoyer un message |
| CODE DU_RÉSULTAT_404 | pas trouvé | La ressource n'existe pas |
| CODE DU_RÉSULTAT_405 | méthode non autorisée | La méthode Http n'est pas supportée par la ressource |
| CODE DU_RÉSULTAT_410 | parti | Le numéro du téléphone portable est bloqué |
| CODE DU_RÉSULTAT_429 | trop de requêtes | Erreur générique de limitation du taux |
| CODE DU_RÉSULTAT_503 | Service indisponible | Une erreur temporaire s'est produite sur notre plateforme - veuillez réessayer |

### Service de SMS entrants { #inbound-sms-service } 

L'API Web prend en charge la collecte des messages SMS entrants à l'aide de la méthode 
POST. Les messages entrants acheminés vers l'API Web DHIS2 peuvent être 
reçus à l'aide de cette API. L'API collecte les messages SMS entrants et 
les fournit aux auditeurs pour qu'ils les analysent, en fonction du contenu du SMS (commande SMS). Un exemple de charge utile au format JSON est donné ci-dessous. Le 
texte, l'expéditeur, la date de réception et la date d'envoi sont des paramètres obligatoires. 
Les autres sont facultatifs, mais le système utilisera la valeur par défaut pour ces 
paramètres.

    /api/sms/entrant

```json
{
  "texte" : "texte de l'échantillon",
  "auteur": "004712341234",
  "iddelapasserelle " : " inconnu",
  "date de réception": "2016-05-01",
  "date d'envoi":"2016-05-01",
  "codage sms": "1",
  "statut sms":"1"
}
```

Les messages entrants peuvent être récupérés à l'aide de la ressource GET.

    GET /api/sms/inbound
    GET /api/sms/inbound?fields=*&filter=smsstatus=INCOMING

Les messages entrants peuvent être supprimés à l'aide de la ressource SUPPRIMER.

    SUPPRIMER /api/sms/inbound/{uid}
    SUPPRIMER /api/sms/inbound?ids=uid1,uid2

Pour importer tous les messages non traités

    POST /api/sms/entrant/importer



Tableau : Paramètres de requête de l'utilisateur

| Paramètre | Type | Description |
|---|---|---|
| message | Chaîne | Il s'agit d'un paramètre obligatoire qui contient le message textuel proprement dit. |
| auteur | Chaîne | Il s'agit d'un paramètre obligatoire qui indique de qui provient le message. |
| passerelle | Chaîne | Il s'agit d'un paramètre facultatif qui indique l'identifiant de la passerelle. S'il n'est pas présent, le texte par défaut " INCONNU " sera stocké |
| heure de réception | Date | Ce paramètre est facultatif. Il indique l'heure à laquelle le message a été reçu par la passerelle. |

### Administration du service de la passerelle { #gateway-service-administration } 

L'API Web expose des ressources qui permettent de configurer et 
de mettre à jour les configurations de la passerelle SMS.

La liste des différentes passerelles configurées peut être obtenue à l'aide de la méthode 
GET

    GET /api/33/gateways

Les configurations peuvent également être récupérées pour un type de passerelle spécifique à l'aide de la
méthode GET.

    GET /api/33/gateways/{uid}

De nouvelles configurations de passerelles peuvent être ajoutées à l'aide de POST. L'api POST nécessite un paramètre de requête de type et actuellement sa valeur peut être *http,bulksms,clickatell,smpp*. La première passerelle ajoutée sera définie par défaut. Une seule passerelle peut être définie par défaut à la fois. La passerelle par défaut ne peut être modifiée que par l'intermédiaire de son interface utilisateur. Si la passerelle par défaut est supprimée, la suivante dans la liste deviendra automatiquement la passerelle par défaut.

    POST /api/33/gateways

La configuration peut être mise à jour en fournissant l'uid et la configuration de la passerelle comme indiqué ci-dessous

    PUT /api/33/gateways/{uids}

Les configurations peuvent être supprimées pour un type de passerelle spécifique à l'aide de la méthode 
SUPPRIMER

    DELETE /api/33/gateways/{uid}

La passerelle par défaut peut être récupérée et mise à jour.

    GET /api/33/gateways/default

Default gateway can be set using the PUT method.

    PUT /api/33/gateways/default/{uid}

### Configuration de la passerelle { #gateway-configuration } 

L'API Web vous permet de créer et de mettre à jour les configurations de la passerelle. Pour chaque
type de passerelle, les paramètres de la charge utile JSON sont différents.
Des exemples de charges utiles JSON pour chaque passerelle sont donnés ci-dessous. POST est utilisé pour
créer et PUT pour mettre à jour les configurations. Le paramètre En-tête peut être utilisé dans
le cas de "GenericHttpGateway" pour envoyer un ou plusieurs paramètres en tant qu'en-tête http.

#### Clickatell { #clickatell } 

```json
{
  "type" : "clickatell",
  "nom" : "clickatell",
  "nom d'utilisateur": "utilisateur de clickatell",
  "authToken": "XXXXXXXXXXXXXXXXXXXX",
  "modèle d'url": "https://platform.clickatell.com/messages"
}
```

#### Bulksms { #bulksms } 

```json
{
  "type": "bulksms",
  "nom": "bulkSMS",
  "nom d'utilisateur": "utilisateur bulk",
  "mot de passe": "abc123"
}
```

#### Passerelle SMPP { #smpp-gateway } 

```json
{
  "type": "smpp",
  "nom": "smpp gateway2",
  "systemId": "smppclient1",
  "hôte" : " hôte local",
  "type de système": "cp",
  "Indicateur de plan de numérotation": "INCONNU",
  "typeDeNombre": "INCONNU",
  "type de lien": "BIND_TX",
  "port": 2775,
  "mot de passe" : "mot de passe",
  "compressé" : faux
}
```

#### Générique HTTP { #generic-http } 

```json
{
  "type": "http",
  "nom": "Générique",
  "modèle de configuration": "nom d'utilisateur=${nom d'utilisateur}&mot de passe=${mot de passe}&to=${destinataires}&code pays=880&message=${text$}&identifiant du message=0",
  "useGet": faux,
  "paramètres d'envoi d'URL":faux,
  "type de contenu": "APPLICATION_JSON",
  "modèle d'url":"https://samplegateway.com/messages",
  "paramètres": [
    {
      "en-tête": vrai,
      "code": faux,
      "clé": "nom d'utilisateur",
      "valeur": "utilisateur_uio",
      "confidentiel": vrai
    },
    {
      "en-tête": vrai,
      "code": faux,
      "clé": "mot de passe",
      "valeur": "123abcxyz",
      "confidentiel": vrai
    },
    {
      "en-tête": faux,
      "code": faux,
      "clé": "rapport de diffusion",
      "valeur": "oui",
      "confidentiel": faux
    }
  ],
  "estParDéfaut": faux
}
```

Dans une passerelle générique http, il est possible d'ajouter un nombre illimité de paramètres.



Tableau : Paramètres génériques de la passerelle SMS

| Paramètre | Type | Description |
|---|---|---|
| nom | Chaîne | nom de la passerelle |
| modèle de configuration | Chaîne | Le modèle de configuration qui est rempli avec les valeurs des paramètres. Par exemple, le modèle de configuration donné ci-dessus sera rempli comme suit : { "to" : "+27001234567", "body" : "Hello World !"} |
| useGet | Booléen | La méthode Http POST est utilisée par défaut. Pour la remplacer par Http GET, l'utilisateur peut attribuer la valeur "true" au paramètre "useGet". |
| type de contenu | Chaîne | Le type de contenu spécifie le type de données envoyées. Les types pris en charge sont l'APPLICATION_JSON, l'APPLICATION_XML, le FORMULAIRE_URL_CODE, TEXTE_CLAIR |
| modèle d'url | Chaîne | modèle d'url |
| En-tête | Booléen | Si le paramètre doit être envoyé dans les en-têtes Http |
| coder | Booléen | Si le paramètre doit être codé |
| clé | Chaîne | clé de paramètre |
| valeur | Chaîne | valeur du paramètre |
| confidentiel | Booléen | Si le paramètre est confidentiel. Ce paramètre ne sera pas exposé à travers l'API |
| Paramètres d'envoi d'Url | Booléen | Si cette option est cochée, le modèle d'url peut être ajouté aux paramètres de la requête. Ceci est utile si l'API de la passerelle ne prend en charge que le HTTP GET. Un exemple de modèle d'url ressemble à ceci `"urlTemplate" : "https://samplegateway.com/messages?apiKey={apiKey}&to={recipients},content={text},deliveryreport={dp}"`. |

HTTP.OK sera renvoyé si les configurations sont sauvegardées avec succès, sinon *Erreur*

## Les commandes SMS { #webapi_sms_commands } 

Les commandes SMS sont utilisées pour collecter des données par SMS. Ces commandes 
appartiennent à un type d'analyseur spécifique. Chaque analyseur a des fonctionnalités différentes.

La liste des commandes peut être récupérée à l'aide de la fonction GET.

    GET /api/smsCommands

Une commande particulière peut être récupérée à l'aide de GET.

    GET /api/smsCommands/uid

Une commande particulière peut être mise à jour à l'aide de PUT.

    PUT /api/smsCommands/uid

La commande peut être créée en utilisant POST.

    POST /api/smsCommands

Une commande particulière peut être supprimée à l'aide de la commande SUPPRIMER.

    DELETE /api/smsCommands/uid

#### Types de commande SMS { #sms-command-types } 

| Type | Utilisation |
|---|---|
|ANALYSEUR_CLÉ_DE VALEUR | Pour la collecte de données agrégées.|
|ANALYSEUR_D'ALERTES | Pour envoyer des messages d'alerte.|
|ANALYSEUR_NON ENREGISTRÉ | Pour la surveillance des maladies et la notification des cas.|
|ANALYSEUR_D'ENREGISTREMENT_D'ENTITÉS_SUIVIES | Pour l'enregistrement de l'entité du tracker.|
|ANALYSEUR_DE SAISIE DE DONNÉES_DE L'ÉTAPE_DU PROGRAMME | Collecte de données pour l'étape du programme. ( L'IES est identifié sur la base du numéro de téléphone )|
|ANALYSEUR_D'ENREGISTREMENT_D'ÉVÉNEMENTS | Enregistrement d'un événement unique. Elle est utilisée pour les programmes d'événements.|

#### Types de commandes SMS pour Android { #sms-command-types-for-android } 

Ces types de commandes peuvent être utilisés par l'application Android pour l'envoi de données par SMS lorsque la connexion internet n'est pas disponible. Le SMS est composé par l'application Android.

| Type | Utilisation |
|---|---|
|ENSEMBLE DE DONNÉES_AGRÉGÉ | Pour la collecte de données agrégées.|
|INSCRIPTION | Pour l'enregistrement de l'entité du tracker.|
|ÉVÉNEMENT_TRACKER | Inscription à un événement pour les programmes tracker.|
|ÉVÉNEMENT_SIMPLE | Inscription aux programmes d'événements.|
|RELATION | Pour créer des relations.|
|SUPPRIMER | Supprimer un événement.|



# Utilisateurs { #users } 

## Utilisateurs { #webapi_users } 

Cette section couvre les méthodes de ressources de l'utilisateur.

    /api/users

### Requête de l'utilisateur { #webapi_users_query } 

La ressource *utilisateurs* offre des paramètres de requête supplémentaires en plus des
paramètres standard (par exemple, la pagination). Pour rechercher des utilisateurs 
dans la ressource vous pouvez utiliser les paramètres suivants.

Tableau : Paramètres de requête de l'utilisateur

| Paramètre | Type | Description |
|---|---|---|
| requête | Texte | Valeur de la requête pour le prénom, le nom de famille, le nom d'utilisateur et l'adresse électronique, sensible à la casse. |
| Numéro de Téléphone | Texte | Requête pour un numéro de téléphone. |
| peutGérer | faux &#124; vrai | Filtre permettant de déterminer si l'utilisateur actuel peut gérer les utilisateurs renvoyés à travers les relations de groupe d'utilisateurs gérés. |
| authSubset | faux &#124; vrai | Filtre permettant de déterminer si les utilisateurs renvoyés ont un sous-ensemble des autorisations de l'utilisateur actuel. |
| dernière connexion | Date | Filtre les utilisateurs qui se sont connectés après la date indiquée. |
| mois inactifs | Nombre | Filtre les utilisateurs qui ne se sont pas connectés pendant le nombre de mois indiqué. |
| inactif Depuis | Date | Filtre les utilisateurs qui ne se sont pas connectés après la date indiquée. |
| auto-inscrit | faux &#124; vrai | Filtre les utilisateurs qui se sont auto-inscrits sur leur compte d'utilisateur. |
| statut de l'invitation | aucun &#124; all &#124; expiré | Filtre les invitations des utilisateurs, notamment toutes les invitations ou les invitations expirées. |
| ou | Identificateur | Filtre les utilisateurs associés à l'unité d'organisation dont l'identifiant est indiqué. |
| unités d'organisation des utilisateurs | faux &#124; vrai | Filtre les utilisateurs qui sont associés aux unités d'organisation liées à l'utilisateur actuellement connecté. |
| Inclut les enfants | faux &#124; vrai | Inclut les utilisateurs de toutes les unités d'organisation subordonnées du paramètre de l'uo. |
| page | Nombre | Le nombre de la page. |
| taille de la page | Nombre | La taille de la page |

Une requête pour un maximum de 10 utilisateurs avec "konan" comme prénom ou nom de famille (sensible 
à la casse) qui ont un sous-ensemble d'autorisations par rapport à l'utilisateur 
actuel :

    /api/users?query=konan&authSubset=true&pageSize=10

Récupérer tous les comptes d'utilisateurs qui ont été initialement auto-inscrits :

```
/api/users?selfRegistered=true
```

#### Requête de l'utilisateur par identifiant { #user-query-by-identifier } 

La syntaxe suivante permet d'obtenir des informations complètes sur un utilisateur ayant un identifiant particulier.

```
/api/users/{id}
```

Voici un exemple d'identifiant particulier :

```
/api/users/OYLGMiazHtW
```

### Recherche d'utilisateurs { #user-lookup } 

L'API de recherche d'utilisateurs propose un système de récupération des utilisateurs lorsque la 
réponse comporte un minimum d'informations. Aucune autorité spécifique 
n'est requise et elle permet aux clients de rechercher des informations 
telles que le prénom et le nom de famille de l'utilisateur, sans pour autant révéler des informations 
potentiellement sensibles.

```
/api/userLookup
```

Le système de recherche de l'utilisateur comporte deux méthodes.

#### Recherche des utilisateurs par identifiant { #user-lookup-by-identifier } 

Vous pouvez effectuer une recherche d'utilisateur par identifiant en utilisant la requête API suivante :

```
GET /api/userLookup/{id}
```

L'`ID` de l'utilisateur sera recherché par rapport aux propriétés d'utilisateur 
suivantes dans l'ordre indiqué :

- UID
- UUID
- Nom d'utilisateur

Voici donc un exemple de requête :

```
/api/userLookup/QqvaU7JjkUV
```

La réponse comportera un minimum d'informations relatives à l'utilisateur.

```json
{
  "id": "QqvaU7JjkUV",
  "nom d'utilisateur": "nkono",
  "prénom": "Thomas",
  "nom de famille": "Nkono",
  "nom affiché": "Thomas Nkono"
}
```

#### Requête de recherche d'utilisateurs { #user-lookup-query } 

Vous pouvez réaliser une requête des utilisateurs à partir de la requête API suivante :

```
GET /api/userLookup?query={string}
```

Le paramètre de requête `query` est obligatoire. La chaîne de requête `query` sera comparée 
aux propriétés utilisateur suivantes :

- Prénom
- Nom
- Adresses électronique
- Nom d'utilisateur

Voici donc un exemple de requête :

```
/api/userLookup?query=John
```

La réponse comportera des informations relatives aux utilisateurs et correspondants à la requête.

```json
{
  "utilisateurs": [
    {
      "id": "DXyJmlo9rge",
      "nom d'utilisateur": "jbarnes",
      "prénom": "John",
      "nom de famille": "Barnes",
      "nom affiché": "John Barnes"
    },
    {
      "id": "N3PZBUlN8vq",
      "nom d'utilisateur": "jkamara",
      "prénom": "John",
      "nom de famille": "Kamara",
      "nom affiché": "John Kamara"
    }
  ]
}
```

### Créer et mettre à jour un compte utilisateur { #webapi_users_create_update } 

La création et la mise à jour des utilisateurs sont prises en charge par l'API. Une charge utile
de base pour créer un utilisateur ressemble à l'exemple ci-dessous. Notez que le mot de passe
sera envoyé en texte clair, n'oubliez donc pas d'activer SSL/HTTPS pour le transport réseau.

```json
{
  "identifiant": "Mj8balLULKp",
  "Prénom": "John",
  "nom ": "Doe",
  "email": "johndoe@mail.com",
  "informations d'identification de l'utilisateur": {
    "identifiant": "lWCkJ4etppc",
    "infoUtilisateur": {
    "identifiant": "Mj8balLULKp"
  },
  "nom d'utilisateur": "johndoe123",
  "mot de passe": "Your-password-123",
  "skype": "john.doe",
  "telegram": "joh.doe",
  "whatsApp": "+1-541-754-3010",
  "facebookMessenger": "john.doe",
  "avatar": {
    "identifiant": "<fileResource id>"
  },
  "rôles d'utilisateur": [
    {
      "identifiant": "Ufph3mGRmMo"
    }
  ]
  },
  "unités d'organisation": [
    {
      "identifiant": "Rp268JB6Ne4"
    }
  ],
  "groupes d'utilisateurs": [
    {
      "identifiant": "wl5cDMuUhmF"
    }
  ]
}
```

```bash
curl -X POST -d @u.json "http://server/api/33/users" -u user:pass
  -H "Content-Type: application/json"
```

Dans la charge utile de création d'utilisateurs, les groupes d'utilisateurs ne sont pris en charge que lors de l'importation 
ou du *POSTing* d'un seul utilisateur à la fois. Si vous tentez de créer plus d'un 
utilisateur tout en spécifiant des groupes d'utilisateurs, vous ne recevrez pas d'erreur et les 
utilisateurs seront créés, mais aucun groupe d'utilisateurs ne sera affecté. Ceci est prévu et 
limité en raison de la relation de plusieurs à plusieurs entre les utilisateurs et les 
groupes d'utilisateurs, les groupes d'utilisateurs étant propriétaires de la relation. Pour mettre à jour 
ou créer plusieurs utilisateurs et leurs groupes d'utilisateurs, envisagez un programme pour *POSTER* 
un à la fois, ou *POSTER* tous les utilisateurs suivi d'une autre action pour mettre à jour 
leurs groupes d'utilisateurs tout en spécifiant les identifiants du nouvel utilisateur.

Après la création de l'utilisateur, une entête *Location* est renvoyée avec l'identifiant 
nouvellement généré (vous pouvez également fournir le vôtre en utilisant le point d'extrémité 
`/api/system/id`). La même charge utile peut alors être utilisée pour faire des mises à jour, mais n'oubliez pas 
d'utiliser *PUT* au lieu de *POST* et le point d'extrémité est désormais `/api/users/ID`.

```bash
curl -X PUT -d @u.json "http://server/api/33/users/ID" -u user:pass
  -H "Content-Type: application/json"
```

Pour plus d'informations sur l'ensemble des données disponibles, voir `/api/schemas/user`.

Pour plus d'informations sur le téléchargement et la récupération des avatars des utilisateurs, veuillez consulter le 
point d'extrémité `/fileResources`.

### Invitations pour les comptes d'utilisateurs { #webapi_user_invitations } 

L'API Web permet d'inviter des personnes à créer des comptes d'utilisateur par le biais de la ressource
`invite`. Pour créer une invitation, vous devez POSTER un utilisateur au format XML
ou JSON à la ressource "invite". Un nom d'utilisateur spécifique peut être imposé
en définissant le nom d'utilisateur dans l'entité postée. En omettant le nom d'utilisateur,
la personne pourra le spécifier elle-même. Le système enverra
une invitation par courrier électronique. Il faut pour cela que les paramètres de messagerie soient
correctement configurés.

La ressource "invite" est utile pour permettre en toute sécurité
à des personnes de créer des comptes sans que personne d'autre ne connaisse le mot de passe
ou en transférant le mot de passe en texte clair. La charge utile à utiliser pour
l'invitation est la même que pour la création d'utilisateurs. Un exemple de charge utile en JSON
ressemble à ceci :

```json
{
  "prénom": "John",
  "nom": "Doe",
  "email": "johndoe@mail.com",
  "informations d'identification de l'utilisateur": {
    "nom d'utilisateur": "johndoe",
    "roles d'utilisateur": [{
      "id": "Euq3XfEIEbx"
    }]
  },
  "unités d'organisation": [ {
    "id": "ImspTQPwCqd"
  } ],
  "groupes d'utilisateurs": [ {
    "id": "vAvEltyXGbD"
  }]
}
```

L'entité d'invitation de l'utilisateur peut être affichée comme suit :

```bash
curl -d @invite.json "localhost/api/33/users/invite" -u admin:district
  -H "Content-Type:application/json"
```

Pour envoyer des invitations à plusieurs utilisateurs en même temps, vous devez utiliser un 
format légèrement différent. Pour JSON :

```json
{
  "utilisateurs": [ {
    "prénom": "John",
    "nom": "Doe",
    "email": "johndoe@mail.com",
    "informations d'identification de l'utilisateur": {
      "nom d'utilisateur": "johndoe",
      "rôles d'utilisateur": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "unités d'organisation": [ {
      "id": "ImspTQPwCqd"
      } ]
    }, {
    "prénom": "Tom",
    "nom": "Johnson",
    "email": "tomj@mail.com",
    "informations d'identification de l'utilisateur": {
      "rôles d'utilisateur": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "unités d'organisation": [ {
      "id": "ImspTQPwCqd"
      } ]
    }
  ]
}
```

Pour créer plusieurs invitations, vous pouvez envoyer la charge utile à la ressource
api/users/invites comme ceci :

```bash
curl -d @invites.json "localhost/api/33/users/invites" -u admin:district
  -H "Content-Type:application/json"
```

Certaines conditions doivent être remplies pour que les invitations à ouvrir un compte d'utilisateur soient 
envoyées :

  - Le serveur SMTP doit être configuré correctement sur le serveur.

  - L'utilisateur à inviter doit avoir indiqué un e-mail valide.

  - Si le nom d'utilisateur est spécifié, il ne doit pas être déjà pris par un autre
    utilisateur existant.

Si l'une de ces conditions n'est pas remplie, la ressource invitée renvoie 
un code d'état *409 Conflict* accompagné d'un message descriptif.

### Réplication de l'utilisateur { #webapi_user_replication } 

Pour répliquer un utilisateur, vous pouvez utiliser la ressource *replica*. Répliquer un
utilisateur peut être utile pour déboguer ou reproduire des problèmes signalés par un
particulier. Vous devez fournir un nouveau nom d'utilisateur et un nouveau mot de passe à l'utilisateur 
répliqué, que vous allez utiliser pour vous authentifier ultérieurement. Notez que vous
avez besoin de l'autorisation ALL pour effectuer cette action. Pour répliquer un utilisateur, vous
vous pouvez envoyer une charge utile JSON comme ci-dessous :

```json
{
  "nom d'utilisateur" : " utilisateur_replica",
  "mot de passe" : " Motdepassesecret "
}
```

Cette charge utile peut être envoyée à la ressource réplique, où vous fournissez
l'identifiant de l'utilisateur à répliquer dans l'URL :

    /api/33/users/<uid>/replica

Voici un exemple de reproduction d'un utilisateur à l'aide de curl :

```bash
curl -d @replica.json "localhost/api/33/users/N3PZBUlN8vq/replica"
  -H "Content-Type:application/json" -u admin:district
```

### Réinitialiser le mot de passe de l'utilisateur { #webapi_user_reset }

Les administrateurs utilisateurs (disposant des droits appropriés) peuvent réinitialiser le compte 
d'un autre utilisateur en déclenchant la récupération du mot de passe. Une fois l'opération déclenchée, un e-mail contenant un lien de récupération 
est envoyé à l'utilisateur. Les utilisateurs qui suivent le lien accèdent à un formulaire qui leur 
permet de définir un nouveau mot de passe.

Pour déclencher ce flux de travail pour l'utilisateur `tH7WIiIJ0O3`, utilisez :

    POST /api/37/users/tH7WIiIJ0O3/reset

### Désactiver et activer des comptes d'utilisateurs { #webapi_user_disable } 

Les comptes d'utilisateurs peuvent être marqués comme désactivés.
Un utilisateur désactivé ne peut plus se connecter.

Pour marquer un utilisateur avec l'UID `tH7WIiIJ0O3` comme désactivé (nécessite un utilisateur avec les droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/disabled

Pour permettre à un utilisateur désactivé d'utiliser à nouveau l'outil en question (l'utilisateur doit disposer des droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/enabled

### Expiration de l'utilisateur { #webapi_user_expiration } 

Une date d'expiration peut être définie pour un compte d'utilisateur.
Elle marque le moment à partir duquel le compte d'utilisateur a expiré 
et ne peut plus être utilisé. L'utilisateur dont le compte a expiré ne peut plus se connecter.

Pour mettre à jour la date d'expiration de l'utilisateur avec l'UID `tH7WIiIJ0O3` 
et la mettre à la date `2021-01-01` (nécessite un utilisateur avec les droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/expired?date=2021-01-01

Pour désactiver la date d'expiration afin que le compte n'expire jamais 
utiliser en conséquence (nécessite un utilisateur disposant des droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/unexpired

### Flux de travail pour l'approbation des données des utilisateurs { #user-data-approval-workflows } 

Pour connaître les flux de travail et les niveaux d'approbation des données auxquels un utilisateur peut accéder, 
vous pouvez utiliser la ressource *dataApprovalWorkflows* comme suit :

```
GET /api/users/{id}/dataApprovalWorkflows
```

## Informations sur l'utilisateur actuel { #webapi_current_user_information } 

Pour obtenir des informations sur l'utilisateur actuellement authentifié et ses associations 
avec d'autres ressources, vous pouvez utiliser la ressource *me* 
(vous pouvez également l'appeler par son ancien nom *currentUser*). Les 
ressources liées à l'utilisateur actuel fournissent des informations utiles lors 
de la création de clients, par exemple pour la saisie de données et la gestion des utilisateurs. Les 
paragraphes suivants décrivent ces ressources et leur objectif.

Fournit des informations de base sur l'utilisateur sous lequel vous êtes actuellement connecté.
en tant qu'utilisateur, y compris le nom d'utilisateur, les informations d'identification de l'utilisateur, les unités d'organisation 
affectées:

    /api/me

Donne des informations sur les messages non lus et les interprétations :

    /api/me/tableau de bord

Pour modifier le mot de passe, ce point d'extrémité peut être utilisé pour valider le mot de passe nouvellement saisi.
le nouveau mot de passe. La validation du mot de passe sera effectuée sur la base des
PasswordValidationRules configurées dans le système. Ce point d'extrémité prend en charge
POST et la chaîne du mot de passe doit être envoyée dans le corps de POST.

    /api/me/valider le mot de passe

Lors d'un changement de mot de passe, ce point final (support POST) peut être utilisé pour
vérifier l'ancien mot de passe. La chaîne du mot de passe doit être envoyée dans le corps du POST.

    /api/me/verifier le mot de passe

Renvoie l'ensemble des autorisations accordées à l'utilisateur actuel :

    /api/me/authorisation

Renvoie vrai ou faux, indiquant si l'utilisateur actuel a 
reçu l'autorisation `<auth>` donnée:

    /api/me/authorisation/<auth>

Indique les niveaux d'approbation des données correspondant à l'utilisateur actuel :

    /api/me/Niveaux d'approbation des données

Indique les flux de travail d'approbation des données accessibles à l'utilisateur actuel.
Pour chaque flux de travail, indique les niveaux d'approbation des données que l'utilisateur peut voir, et
les autorisations dont il dispose à chaque niveau :

    /api/me/dataApprovalWorkflows



# Paramètres et configuration { #settings-and-configuration } 

## Paramètres du système { #webapi_system_settings } 

Vous pouvez manipuler les paramètres du système en interagissant avec la ressource
*systemSettings*. Un paramètre système est une simple paire clé-valeur,
où la clé et la valeur sont des chaînes de texte en clair. Pour enregistrer ou
mettre à jour un paramètre système, vous pouvez envoyer une requête *POST* à l'URL suivante :

    /api/33/systemSettings/my-key?value=my-val

Vous pouvez également soumettre la valeur du paramètre dans le corps de la requête,
où le type de contenu est défini sur "texte/clair". Par exemple, vous pouvez utiliser
curl comme suit :

```bash
curl "play.dhis2.org/demo/api/33/systemSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

Pour définir les paramètres du système en bloc, vous pouvez envoyer un objet JSON avec une 
propriété et une valeur pour chaque paire clé-valeur de paramètre du système à l'aide d'une requête POST :

```json
{
  "notification de l'application clé" : "Bienvenue",
  "intro de l'application clé": "DHIS2",
  "pied de page de l'application clé" : "En savoir plus sur dhis2.org"
}
```

Les traductions pour les clés de paramétrage traduisibles peuvent être définies en spécifiant  le paramètre local  comme 
paramètre de requête et la valeur traduite qui peut être spécifiée 
soit comme paramètre de requête, soit dans la charge utile du corps. Voir un exemple d'URL :

    /api/33/systemSettings/<my-key>?locale=<my-locale>&value=<my-translated-value>

Vous devez remplacer my-key par votre clé réelle et my-val par votre valeur 
réelle. Pour récupérer la valeur d'une clé donnée (en JSON ou en texte brut)
vous pouvez envoyer une requête *GET* à l'URL suivante :

    /api/33/systemSettings/my-key

Alternativement, vous pouvez spécifier la clé en tant que paramètre de requête :

    /api/33/systemSettings?key=my-key

Vous pouvez récupérer des paramètres système spécifiques sous forme de JSON en répétant la clé
paramètre de la requête :

```bash
curl "play.dhis2.org/demo/api/33/systemSettings?key=keyApplicationNotification&key=keyApplicationIntro"
  -u admin:district
```

Vous pouvez récupérer tous les paramètres du système à l'aide d'une requête GET :

    /api/33/systemSettings

Pour récupérer une traduction spécifique pour une clé traduisible donnée, vous pouvez spécifier
un paramètre local comme paramètre de requête :

    /api/33/systemSettings/<my-key>?locale=<my-locale>

Si elle est présente, la traduction pour le paramètre local donné est renvoyée. Sinon, une valeur
est renvoyée. Si aucun paramètre local n'est spécifié pour la clé traduisible, le paramètre local par défaut de 
l'interface utilisateur est utilisé pour obtenir la traduction correcte. Si la traduction donnée n'est pas
présente, la valeur par défaut est renvoyée.

La priorité pour les clés traduisibles est la suivante :

 locale spécifiée > UI local par défaut de l'utilisateur > valeur par défaut

Pour supprimer un paramètre du système, vous pouvez envoyer une requête *DELETE* à l'URL
similaire à celle utilisée ci-dessus pour la récupération. Si une clé traduisible est
utilisée, toutes les traductions présentes seront également supprimées.

Pour supprimer uniquement une traduction spécifique d'une clé traduisible, il convient d'utiliser la même URL
que pour l'ajout d'une traduction et la valeur vide doit être
fournie :

    /api/33/systemSettings/<my-key>?locale=<my-locale>&value=

Les paramètres système disponibles sont énumérés ci-dessous.

Tableau : Paramètres du système

| Clé | Description | Traduisible |
|---|---|---|
| cléUiLocale | Paramètre local pour l'interface utilisateur | Non |
| cléDbLocale | Paramètre local de la base de données | Non |
| Propriété d'affichage de l'analyse clé | La propriété à afficher dans l'analyse. Par défaut : " nom " | Non |
| Séparateur de groupes de chiffres de l'analyse clé | Le séparateur utilisé pour séparer les groupes de chiffres | Non |
| type clé du domaine actuel | Pas encore en service | Non |
| présentation du tableau de bord clé du tracker | Utilisé par la saisie tracker | Non |
| titre de l'application | Titre de l'application. Par défaut : « DHIS2 » | Oui |
| clé Introduction de l'application | La présentation de l'application | Oui |
| Notification clé de l'application | Notification de l'application | Oui |
| clé Pied de page de l'application | Pied de page gauche de l'application | Oui |
| clé pied de page droit de l'application | pied de page droit de l'application | Oui |
| clé Drapeau | Drapeau de l'application | Non |
| clé Image du drapeau | Drapeau utilisé dans le menu tableau de bord | Non |
| module démarrer | La page de démarrage de l'application. Par défaut :  " Intégration du-tableau de bord-de dhis-web  " | Non |
| Module Démarrer Activer Faible poids | L'application de la page de départ pour le rendu d'une page de destination légère. Par défaut : " faux " | Non |
| facteur Écart  | Facteur d'écart-type de l'analyse des données. Par défaut :"2d" | Non |
| clé Nom de l'hôte de l'email | Nom d'hôte du serveur e-mail | Non |
| clé Port Email | Port du serveur email | Non |
| clé Tls de l'email | Utiliser TLS. Par défaut : « vrai » | Non |
| clé Expéditeur de l'e-mail | Expéditeur de l'e-mail | Non |
| clé Nom d'utilisateur de l'e-mail  | Nom d'utilisateur du serveur de l'email | Non |
| clé Mot de passe de l'e-mail  | Mot de passe du serveur de l'email | Non |
| Longueur minimale du mot de passe | Longueur minimale du mot de passe | Non |
| Longueur maximale du mot de passe | Longueur maximale du mot de passe | Non |
| clé Paramètre des Sms | Configuration de SMS | Non |
| clé Stratégie de mise en cache | Stratégie de mise en cache. Par défaut : " MIS EN CACHE_6H_DEMAIN " | Non |
| clé Mise en cache | PUBLIC ou PRIVÉ. Détermine si les serveurs proxy sont autorisés à mettre des données en cache ou non. | Non |
| Code régional du numéro de téléphone | Code régional du numéro de téléphone | Non |
| Formulaires des unités d'organisation multiples | Permet d'activer les formulaires d'unités multi-organisations. Par défaut :  " faux  " | Non |
| clé Configuration || Non |
| Clé Récupération de compte | Active la récupération des comptes d'utilisateurs. Par défaut : " faux " | Non |
| Clé Verrouillage des touches en cas d'échecs multiples de connexion | Active le verrouillage de l'accès après plusieurs échecs de connexion | Non |
| Analyse de Google UA | Clé d'analyse Google UA pour le suivi de l'utilisation du site | Non |
| Informations d'identification Expirés | Demande de modification du mot de passe du compte utilisateur. Par défaut : « 0 » (jamais) | Non |
| Alerte d'expiration des informations d'identification | Activer l'alerte lorsque les informations d'identification sont proches de la date d'expiration | Non |
| alerte d'expiration du compte | Envoi un e-mail d'alerte aux utilisateurs dont le compte est sur le point d'expirer en raison d'une date d'expiration définie. Par défaut : " faux " | Non |
| expiration du compte en jours | Nombre de jours pendant lesquels l'alerte d'expiration du compte doit être envoyée avant l'expiration réelle. Par défaut : 7 | Non |
| clé Auto inscription, pas de recaptcha | Ne pas exiger de recaptcha pour l'auto-inscription. Par défaut : " faux " | Non |
| secret de recaptcha | Secret de recaptcha de l'API Google. Par défaut : l'API secret de l'instance de jeu dhis2, mais cela ne fonctionnera que sur votre instance locale et pas en production. | Non |
| site de recaptcha | Site de recaptcha de l'API Google. Par défaut : l'API du site de l'instance de jeu dhis2, mais cela ne fonctionnera que sur votre instance locale et pas en production. | Non |
| clé Peut accorder des groupes d'autorisation à ses propres utilisateurs | Permet aux utilisateurs d'attribuer leurs propres rôles. Par défaut : " faux " | Non |
| clé limite maximale de vue Sql | Limite maximale pour la vue SQL | Non |
| clé Respecter les dates de début et de fin des métadonnées dans l'exportation des tableaux analytiques | Lorsque cette option est " vraie ", l'outil d'analyse ignore les données qui ne sont pas comprises dans les dates de début et de fin de l'option de catégorie. Par défaut : " faux " | Non |
| clé Sauter la validation du type de données dans l'exportation de tableaux analytiques | Ne pas valider le type de données dans l'exportation de tableaux analytiques | Non |
| clé Logo personnalisé de la page de connexion | Logo pour la page de connexion personnalisée | Non |
| clé Logo du menu supérieur personnalisé | Logo pour le menu supérieur personnalisé | Non |
| clé Seuil de l'année des données du Cache analytique | Les données analytiques plus anciennes que cette valeur (en années) seront toujours mises en cache. La valeur « 0 » désactive ce paramètre. Par défaut : 0 | Non |
| Analyse du début de l'exercice financier | Définir le début de l'exercice financier. Par défaut : octobre | Non |
| clé Ignorer le seuil de l'année d'approbation de l'analyse | « 0 » vérifie l'approbation de toutes les données. « -1 » désactive le contrôle de l'approbation. « 1 » ou plus vérifie l'approbation de toutes les données qui sont plus récentes que « 1 » année. | Non |
| clé Limite Maximale Analytique | Nombre maximal d'enregistrements analytiques. Par défaut : « 50000 » | Non |
| keyAnalyticsMaintenanceMode | Put analytics in maintenance mode. Default: "false" | Non |
| clé Période d'analyse des Années de compensation | Définit le décalage des années à utiliser dans le processus d'exportation des données analytiques. Si l'année d'une date donnée est en dehors du décalage, le système renvoie un message d'avertissement au cours du processus. À ce stade, l'étape de génération de la période est ignorée. Par exemple : supposons que l'utilisateur du système définisse la valeur du décalage à `5`, et que nous soyons en l'an 2023. Cela signifie que l'analyse acceptera d'exporter des dates allant de 2018 (inclus) à 2028 (inclus). Ce qui se traduit par : [2018, 2019, 2020, 2021, 2022, 2023, 2024, 2025, 2026, 2027, 2028]. REMARQUE : Le décalage aura une influence significative sur l'utilisation des ressources. Des valeurs plus élevées entraîneront une utilisation plus importante de la mémoire RAM/HEAP et de l'unité centrale. La définition de nombres négatifs pour cette clé désactivera tout type de validation (ce qui signifie qu'il n'y aura pas d'avertissement) et la plage interne d'années sera utilisée (1970 à l'année en cours plus 10) Par défaut : 22 | Non |
| clé Unités centrales du serveur de la base de données | Nombre d'unités centrales du serveur de base de données. Par défaut : « 0 » (Automatique) | Non |
| clé Dernière exécution réussie des tableaux d'analyse | Conserve l'horodatage de la dernière exécution réussie des tables d'analyse. | Non |
| keyLastSuccessfulLatestAnalyticsPartitionRuntime | Conserve l'horodatage de la dernière exécution réussie de la partition analytique | Non |
| clé Dernière Exécution de la Surveillance | Conserve l'horodatage de la dernière exécution de la surveillance | Non |
| clé Dernière Syncronisation de Données Réussie | Conserve l'horodatage de la dernière synchronisation réussie des valeurs de données | Non |
| clé Dernière synchronisation réussie d'événements de données | Conserve l'horodatage de la dernière synchronisation réussie des données des programmes d'événements. | Non |
| keyLastCompleteDataSetRegistrationSyncSuccess | Conserve l'horodatage de la dernière synchronisation réussie de l'exhaustivité | Non |
| sync Sauter la synchronisation pour les données modifiées avant | Spécifie l'horodatage utilisé pour ignorer la synchronisation de toutes les données modifiées avant ce point dans le temps | Non |
| Dernière mise à jour réussie des tableaux d'analyse | Conserve l'horodatage de la dernière mise à jour réussie des tableaux d'analyse | Non |
| clé Dernière mise à jour réussie de la partition analytique | Conserve l'horodatage de la dernière mise à jour réussie de la partition analytique | Non |
| clé  Dernière mise à jour réussie des tableaux de ressources | Conserve l'horodatage de la dernière mise à jour réussie des tableaux de ressources | Non |
| keyLastSuccessfulSystemMonitoringPush | Conserve l'horodatage de du dernier push réussi de la surveillance du système | Non |
| keyLastSuccessfulMonitoring | Conserve l'horodatage de la dernière surveillance réussie | Non |
| keyNextAnalyticsTableUpdate | Conserve l'horodatage de la prochaine mise à jour du tableau d'analyse | Non |
| Lien de la page d'aide | Lien vers la page d'aide. Par défaut : "[https://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html](http://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html) | Non |
| keyAcceptanceRequiredForApproval | L'acceptation est requise avant la validation. Par défaut "faux" | Non |
| clé Notifications Email du Système | Où envoyer les notifications du système par e-mail | Non |
| clé Analyse de la Période Relative | Période relative par défaut pour l'analyse. Par défaut : « 12_DERNIERS_MOIS ». | Non |
| keyRequireAddToView | Autorisation requise pour l'ajout de listes d'objets à visualiser. Par défaut : « faux » | Non |
| keyAllowObjectAssignment | Autoriser l'affectation d'un objet à des objets apparentés lors d'un ajout ou d'une mise à jour. Par défaut "faux" | Non |
| keyUseCustomLogoFront | Permet l'utilisation d'un logo personnalisé sur la page d'accueil. Par défaut : « faux » | Non |
| keyUseCustomLogoBanner | Permet l'utilisation d'une bannière personnalisée sur le site web. Par défaut : « faux » | Non |
| keyDataImportStrictPeriods || Non |
| keyDataImportStrictPeriods | Exige que les périodes correspondent au type de période de l'ensemble de données. Par défaut : « faux » | Non |
| keyDataImportStrictDataElements | Exiger que les éléments de données fassent partie de l'ensemble de données. Par défaut : « faux » | Non |
| keyDataImportStrictCategoryOptionCombos | Nécessite que les combinaisons d'options de catégorie correspondent à la combinaison de catégories de l'élément de données. Par défaut : « faux » | Non |
| keyDataImportStrictOrganisationUnits | Nécessite que les unités d'organisation correspondent à l'affectation de l'ensemble de données. Valeur par défaut : « faux » | Non |
| keyDataImportStrictAttributeOptionsCombos | Nécessite que l'option d'attribut combis corresponde à la catégorie combo de l'ensemble de données. Valeur par défaut : « faux » | Non |
| keyDataImportRequireCategoryOptionCombo | Exige que la combinaison d'options de catégorie soit spécifiée. Valeur par défaut : « faux » | Non |
| keyDataImportRequireAttributeOptionCombo | Exige que la combinaison d'options d'attributs soit spécifiée. Par défaut : « faux » | Non |
| keyCustomJs | JavaScript personnalisé à utiliser sur le site web | Non |
| keyCustomCss | CSS personnalisé à utiliser sur le site web | Non |
| clé calendrier | Le type de calendrier. Par défaut : « iso8601 ». | Non |
| keyDateFormat | Format dans lequel les dates doivent être affichées. Valeur par défaut : « aaaa-MM-jj ». | Non |
| cléStyle | Style utilisé sur les pages web de DHIS2. Valeur par défaut : « light_blue/light_blue.css ». | Non |
| keyRemoteInstanceUrl | Url utilisée pour se connecter à l'instance distante | Non |
| keyRemoteInstanceUsername | Nom d'utilisateur utilisé pour se connecter à l'instance DHIS2 distante | Non |
| keyRemoteInstancePassword | Mot de passe utilisé pour se connecter à l'instance DHIS2 distante | Non |
| keyGoogleMapsApiKey | Google Maps API key | Non |
| keyGoogleCloudApiKey | Clé de l'API Google Cloud | Non |
| keyLastMetaDataSyncSuccess | Conserve l'horodatage de la dernière synchronisation réussie des métadonnées. | Non |
| keyVersionEnabled | Permet le versionnage des métadonnées | Non |
| keyMetadataFailedVersion | Conserve les détails de l'échec de la version de synchronisation des métadonnées | Non |
| keyMetadataLastFailedTime | Conserve l'horodatage du dernier échec de synchronisation des métadonnées | Non |
| keyLastSuccessfulScheduledProgramNotifications || Non |
| keyLastSuccessfulScheduledDataSetNotifications || Non |
| keyRemoteMetadataVersion | Détails sur la version des métadonnées de l'instance distante | Non |
| keySystemMetadataVersion | Détails sur la version des métadonnées du système | Non |
| keyStopMetadataSync | Drapeau pour arrêter la synchronisation des métadonnées | Non |
| keyFileResourceRetentionStrategy | Détermine la durée de conservation des ressources du fichier associées aux valeurs supprimées ou mises à jour. AUCUNE, TROIS_MOIS, UNE_ANNÉE ou INDÉFINIMENT. | Non |
| syncMaxRemoteServerAvailabilityCheckAttempts | Specifies how many times the availability of remote server will be checked before synchronization jobs fail. | Non |
| syncMaxAttempts | Spécifie le nombre maximum de tentatives pour les tâches de synchronisation | Non |
| syncDelayBetweenRemoteServerAvailabilityCheckAttempts | Délai entre les contrôles de disponibilité du serveur distant | Non |
| lastSuccessfulDataStatistics | Conserve l'horodatage de la dernière analyse de données réussie | Non |
| keyHideDailyPeriods | Pas en cours d'utilisation | Non |
| keyHideWeeklyPeriods || Non |
| keyHideBiWeeklyPeriods | Indicateur booléen utilisé pour masquer/afficher les périodes bihebdomadaires | Non |
| keyHideMonthlyPeriods || Non |
| keyHideBiMonthlyPeriods || Non |
| keyGatherAnalyticalObjectStatisticsInDashboardViews | Si l'on souhaite recueillir des statistiques analytiques sur les objets lorsqu'ils sont visualisés dans un tableau de bord. | Non |
| keyCountPassiveDashboardViewsInUsageAnalytics | Comptabilise les consultations « passives » des tableaux de bord (sans sélection d'un tableau de bord particulier) dans l'analyse de l'utilisation. | Non |
| keyDashboardContextMenuItemSwitchViewType | Permet aux utilisateurs de changer le type d'affichage des favoris du tableau de bord | Oui |
| keyDashboardContextMenuItemOpenInRelevantApp | Permet aux utilisateurs d'ouvrir les favoris du tableau de bord dans les applications pertinentes. | Oui |
| keyDashboardContextMenuItemShowInterpretationsAndDetails | Permet aux utilisateurs d'afficher les interprétations et les détails des favoris du tableau de bord | Oui |
| keyDashboardContextMenuItemViewFullscreen | Permet aux utilisateurs d'afficher les favoris du tableau de bord en plein écran | Oui |
| clé Tâches parallèles dans l'exportation de tableaux analytiques | Renvoie le nombre de tâches parallèles à utiliser pour traiter les tableaux analytiques. Il est prioritaire sur « keyDatabaseServerCpus ». Par défaut : -1 | Non |

## Paramètres de l'utilisateur { #webapi_user_settings } 

Vous pouvez manipuler les paramètres de l'utilisateur en interagissant avec la ressource *userSettings*. Un paramètre utilisateur est une simple paire clé-valeur, où la clé et la valeur sont des chaînes de texte en clair. Le paramètre utilisateur sera lié à l'utilisateur authentifié pour la requête de l'API Web. Pour obtenir une liste de tous les paramètres utilisateur, vous pouvez envoyer une requête *GET* à l'URL suivante :

    /api/33/userSettings

Les paramètres non définis par l'utilisateur seront remplacés par les paramètres équivalents 
du système. Pour ne renvoyer que les valeurs définies explicitement par l'utilisateur, 
vous pouvez ajouter ?useFallback=false à l'URL ci-dessus, comme ceci :

    /api/33/userSettings?useFallback=false

Pour enregistrer ou mettre à jour un paramètre pour l'utilisateur actuellement authentifié, vous pouvez
envoyer une requête *POST* à l'URL suivante :

    /api/33/userSettings/my-key?value=my-val

Vous pouvez spécifier explicitement l'utilisateur pour lequel le paramètre doit être sauvegardé en utilisant 
cette syntaxe :

    /api/33/userSettings/my-key?user=username&value=my-val

Vous pouvez également soumettre la valeur du paramètre dans le corps de la requête,
où le type de contenu est défini sur "texte/clair". Par exemple, vous pouvez utiliser
curl comme suit :

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

Par exemple, pour définir les paramètres linguistiques de l'interface utilisateur de l'utilisateur actuel en français, vous 
pouvez utiliser la commande suivante.

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/keyUiLocale?value=fr"
  -X POST -u admin:district
```

Vous devez remplacer my-key par votre véritable clé et my-val par votre valeur 
réelle. Pour récupérer la valeur d'une clé donnée en texte brut, vous pouvez envoyer une 
requête *GET* à l'URL suivante :

    /api/33/userSettings/my-key

Pour supprimer un paramètre utilisateur, vous pouvez envoyer une requête *DELETE* à l'URL
similaire à celle utilisée ci-dessus pour la récupération.

Les paramètres système disponibles sont énumérés ci-dessous.



Tableau : Paramètres de l'utilisateur

| Clé | Options | Description |
|---|---|---|
| cléStyle | light_blue/light_blue.css &#124; green/green.css &#124; vietnam/vietnam.css | Feuille de style de l'interface utilisateur. |
| Clé Message de notification par Email | faux &#124; vrai | Envoi ou non de notifications par email. |
|  clé Notification par message Sms | faux &#124; vrai | Envoi ou non de notifications SMS |
| cléUiLocale | Valeur locale | Locale de l'interface utilisateur. |
| cléDbLocale | Valeur locale | Locale du contenu de la base de données. |
| Propriété d'affichage de l'analyse clé | nom &#124; Nom court | Propriété à afficher pour les métadonnées dans les applications d'analyse. |
| type clé du domaine actuel | tous &#124 ; agrégat &#124 ; tracker | Type de domaine de l'élément de données à afficher dans les listes. |
| clé Sauvegarde automatique du formulaire de saisie de cas | faux &#124; vrai | Sauvegarder périodiquement les formulaires de saisie de cas. |
| clé Formulaire d'enregistrement automatique des entités suivies | faux &#124; vrai | Sauvegarder périodiquement les formulaires d'inscription des personnes. |
| clé Sauvegarde automatique du formulaire de saisie des données | faux &#124; vrai | Sauvegarder périodiquement les formulaires de saisie de données agrégées. |
| présentation du tableau de bord clé du tracker | faux &#124; vrai | Présentation du tableau de bord du tracker. |

## Configuration { #webapi_configuration } 

Pour accéder à la configuration, vous pouvez interagir avec la ressource 
*configuration*. Vous pouvez obtenir des réponses XML et JSON via l'en-tête *Accepter* 
ou en utilisant les extensions .json ou .xml. Vous pouvez *OBTENIR* toutes les propriétés 
de la configuration depuis : 

    /api/33/configuration

Vous pouvez envoyer des requêtes *GET* et *POST* aux ressources spécifiques 
suivantes :

    GET /api/33/configuration/systemId

    GET POST DELETE /api/configuration/feedbackRecipients

    GET POST DELETE /api/configuration/offlineOrganisationUnitLevel

    GET POST /api/configuration/infrastructuralDataElements

    GET POST /api/configuration/infrastructuralIndicators

    GET POST /api/configuration/infrastructuralPeriodType

    GET POST DELETE /api/configuration/selfRegistrationRole

    GET POST DELETE /api/configuration/selfRegistrationOrgUnit

    GET POST /api/facilityOrgUnitGroupSet

    GET POST /api/facilityOrgUnitLevel

Pour la configuration de la liste blanche CORS, vous pouvez effectuer une requête POST avec  
une série  d'URL à inscrire sur la liste blanche comme charge utile en utilisant « application/json » comme 
type de contenu, par exemple :

```json
["www.google.com", "www.dhis2.org", "www.who.int"]
```

    GET POST /api/33/configuration/corsWhitelist

Pour les requêtes POST, la valeur de configuration doit être envoyée sous forme de texte 
dans la charge utile de la requête. Le tableau suivant indique les valeurs de configuration 
appropriées pour chaque propriété.



Tableau : Valeurs de configuration

| Propriété de la configuration | Valeur |
|---|---|
| Bénéficiaires du retour d'information | Identifiant du Groupe d’utilisateurs |
| niveau de l'unité d'organisation hors ligne | Identifiant du niveau de l'unité d'organisation |
| éléments de données infrastructurelles | Identifiant du groupe d'éléments de données |
| Indicateurs infrastructurels | Identifiant du groupe d'indicateurs |
| Type de période infrastructurelle | Nom du type de période (par exemple « Mensuel ») |
| rôle d'auto-inscription | Identifiant du rôle d'utilisateur |
| Unité d'organisation d'auto-inscription | Identifiant de l'unité d'organisation |
| Mot de passe smtp | Mot de passe du serveur email SMTP |
| Url du serveur distant | Url au serveur distant |
| Nom d'utilisateur du serveur distant | Nom d'utilisateur pour l'authentification du serveur distant |
| mot de passe du serveur distant | Mot de passe pour l'authentification du serveur distant |
| corsWhitelist | Liste JSON des URL |

Par exemple, pour définir le groupe d'utilisateurs des destinataires du retour d'information, vous pouvez invoquer 
la commande curl suivante :

```bash
curl "localhost/api/33/configuration/feedbackRecipients" -d "wl5cDMuUhmF"
  -H "Content-Type:text/plain"-u admin:district
```

## Configuration en lecture uniquement { #webapi_readonly_configuration_interface } 

Pour accéder à tous les paramètres et propriétés de configuration, vous pouvez utiliser le point d'extrémité de configuration en lecture uniquement. Cela permet l'accès en lecture uniquement aux *Paramètres de l'utilisateur, Paramètres du système et aux paramètres de configuration du serveur DHIS2*. Vous pouvez obtenir des réponses XML et JSON grâce à l'en-tête *Accept*. Vous pouvez *OBTENIR* tous les paramètres à partir de :

    /api/33/configuration/settings

Vous pouvez obtenir des paramètres filtrés en fonction du type de paramètre :

    GET /api/33/configuration/settings/filter?type=USER_SETTING

    GET /api/33/configuration/settings/filter?type=CONFIGURATION

Plus d'un type peut être fourni :

    GET /api/33/configuration/settings/filter?type=USER_SETTING&type=SYSTEM_SETTING



Tableau : Paramètres du type de valeurs

| Valeur | Description |
|---|---|
| PARAMÈTRES DE_L'UTILISATEUR | Pour obtenir les paramètres d'utilisateur |
| PARAMÈTRES DU_SYSTÈME | Pour obtenir les paramètres du système |
| CONFIGURATION | Obtenir les paramètres du serveur DHIS |

> **Remarque**
>
> Les champs confidentiels seront fournis dans le résultat, mais sans valeur.

## Jetons { #webapi_tokens } 

La ressource *tokens* fournit des jetons d'accès à différents services.

### Compte Google Service { #webapi_tokens_google_service_account } 

Vous pouvez récupérer un jeton d'accès OAuth 2.0 du compte de service Google à l'aide 
d'une requête GET vers la ressource suivante.

    GET /api/tokens/google

Le jeton est valable pendant un certain temps, après quoi 
un autre jeton doit être demandé à cette ressource. La réponse 
contient un en-tête de contrôle de cache qui correspond à l'expiration du jeton. La 
réponse contiendra les propriétés suivantes au format JSON.



Tableau : Réponse du jeton

| Propriété | Description |
|---|---|
| jeton_d'accès | The OAuth 2.0 access token to be used when authentication against Google services. |
| expire_dans | Nombre de secondes avant l'expiration du jeton d'accès, généralement 3600 secondes (1 heure). |
| identifiant_du client | L'identifiant du client du compte du service Google. |

Cela suppose qu'un compte de service Google a été créé et configuré pour DHIS2. Veuillez consulter le guide d'installation pour plus d'informations.

## Contenu statique { #webapi_static_content } 

La ressource *staticContent* vous permet de télécharger et d'extraire des logos 
personnalisés utilisés dans DHIS2. La ressource permet à l'utilisateur de télécharger un fichier avec une 
clé associée, qui peut ensuite être extraite à l'aide de la clé. Seuls les fichiers PNG 
sont pris en charge et ne peuvent être téléchargés que vers les clés `logo_banner` et 
`logo_front`.

    /api/33/staticContent



Tableau : Clés de contenu statique

| Clé | Description |
|---|---|
| logo_bannière | Logo dans le menu supérieur de l'application sur le côté gauche. |
| façade_du logo | Logo sur la page de connexion au-dessus du formulaire de connexion. |

Pour télécharger un fichier, envoyez-le avec une requête *POST* à :

    POST /api/33/staticContent/<key>

Exemple de requête pour télécharger logo.png dans la clé `logo_front` :

```bash
curl -F "file=@logo.png;type=image/png" "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -X POST -H "Content-Type: multipart/form-data" -u admin:district
```

Le téléchargement de plusieurs fichiers avec la même clé écrasera le fichier 
existant. Ainsi, la recherche d'un fichier pour une clé donnée ne renverra que 
le dernier fichier téléchargé.

To retrieve a logo, you can *GET* the following:

    GET /api/33/staticContent/<key>

Exemple de requêtes pour récupérer le fichier stocké pour `logo_front` :

* Ajout de « Accept : text/html » à l'en-tête HTTP.*__ Dans ce cas, le point d'extrémité renverra une image par défaut si rien n'est défini. Il renvoie un flux d'images lorsqu'une image personnalisée ou par défaut est trouvée.

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -H "Accept: text/html" -L -u admin:district
```

* Ajout de « Accepter : application/json » à l'en-tête HTTP.*__ Avec ce paramètre, le point d'extrémité ne renverra jamais d'image par défaut si le logo personnalisé n'est pas trouvé. Au lieu de cela, un message d'erreur sera renvoyé. Lorsque l'image personnalisée est trouvée, ce point d'extrémité renvoie une réponse JSON contenant le chemin/URL de l'image correspondante.

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -H "Accept: application/json" -L -u admin:district
```

Les messages de succès et d'erreur se présentent comme suit :

```json
{
  "images": {
    "png": "http://localhost:8080/dhis/api/staticContent/logo_front"
  }
}
```

```json
{
  "httpStatus": "Non trouvé",
  "httpStatusCode": 404,
  "statut": "ERREUR",
  "message": "Aucun fichier personnalisé n'a été trouvé."
}
```

Pour utiliser des logos personnalisés, vous devez activer les paramètres système 
correspondants en leur attribuant la valeur *vrai*. Si le paramètre correspondant est faux, 
le logo par défaut sera utilisé.

## Personnalisation de l'IU { #webapi_ui_customization } 

Pour personnaliser l'interface utilisateur de l'application DHIS2, vous pouvez insérer des styles JavaScript et CSS personnalisés via la ressource *files*.

```
POST GET DELETE /api/33/files/script
POST GET DELETE /api/33/files/style
```

Le contenu JavaScript et CSS inséré par le biais de cette ressource sera chargé par 
l'application web DHIS2. Cela peut être particulièrement utile dans certaines situations :

  - Remplacer les styles CSS de l'application DHIS2, tels que la balise
    page de connexion ou la page principale.

  - Définir des fonctions JavaScript communes à plusieurs formulaires de saisie de données 
    personnalisés et à des rapports basés sur HTML.

  - Y compris les styles CSS utilisés dans les formulaires de saisie de données personnalisés et 
    les rapports basés sur HTML.

### Javascript { #webapi_customization_javascript } 

Pour insérer Javascript à partir d'un fichier appelé *script.js*, vous pouvez interagir 
avec la ressource *files/script* à l'aide d'une requête POST :

```bash
curl --data-binary @script.js "localhost/api/33/files/script"
  -H "Content-Type:application/javascript" -u admin:district
```

Notez que nous utilisons l'option `--data-binary` pour préserver le formatage du 
contenu du fichier. Vous pouvez récupérer le contenu du JavaScript à l'aide d'une requête GET :

    /api/33/files/script

Pour supprimer le contenu JavaScript, vous pouvez utiliser une requête de type SUPPRIMER (DELETE).

### CSS { #webapi_customization_css } 

Pour insérer une feuille de style CSS à partir d'un fichier appelé *style.css*, vous pouvez interagir avec la ressource
*files/style* en utilisant une requête POST :

```bash
curl --data-binary @style.css "localhost/api/33/files/style"
  -H "Content-Type:text/css" -u admin:district
```

Vous pouvez récupérer le contenu CSS à l'aide d'une requête GET :

    /api/33/files/style

Pour supprimer le contenu JavaScript, vous pouvez utiliser une requête de type SUPPRIMER (DELETE).


# Tracker { #tracker } 

## Tracker Web API { #webapi_tracker_api }

Tracker Web API consists of 3 endpoints that have full CRUD (create,
read, update, delete) support. The 3 endpoints are
`/api/trackedEntityInstances`, `/api/enrollments` and
`/api/events` and they are responsible for tracked entity instance,
enrollment and event items.

### Tracked entity instance management { #webapi_tracked_entity_instance_management }

Tracked entity instances have full CRUD support in the API. Together
with the API for enrollment most operations needed for working with
tracked entity instances and programs are supported.

    /api/33/trackedEntityInstances

#### Creating a new tracked entity instance { #webapi_creating_tei }

For creating a new person in the system, you will be working with the
*trackedEntityInstances* resource. A template payload can be seen below:

```json
{
  "trackedEntity": "tracked-entity-id",
  "orgUnit": "org-unit-id",
  "geometry": "<Geo JSON>",
  "attributes": [{
    "attribute": "attribute-id",
    "value": "attribute-value"
  }]
}
```

The field "geometry" accepts a GeoJson object, where the type of the
GeoJson have to match the featureType of the TrackedEntityType
definition. An example GeoJson object looks like this:

```json
{
  "type": "Point",
  "coordinates": [1, 1]
}
```

The "coordinates" field was introduced in 2.29, and accepts a coordinate
or a polygon as a value.

For getting the IDs for `relationship` and `attributes` you can have a look
at the respective resources `relationshipTypes`, `trackedEntityAttributes`.
To create a tracked entity instance you must use the HTTP *POST* method.
You can post the payload the following URL:

    /api/trackedEntityInstances

For example, let us create a new instance of a person tracked entity and
specify its first name and last name attributes:

```json
{
  "trackedEntity": "nEenWmSyUEp",
  "orgUnit": "DiszpKrYNg8",
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "value": "Joe"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "value": "Smith"
    }
  ]
}
```

To push this to the server you can use the cURL command like this:

```bash
curl -d @tei.json "https://play.dhis2.org/demo/api/trackedEntityInstances" -X POST
  -H "Content-Type: application/json" -u admin:district
```

To create multiple instances in one request you can wrap the payload in
an outer array like this and POST to the same resource as above:[]()

```json
{
  "trackedEntityInstances": [
    {
      "trackedEntity": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": "Joe"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "value": "Smith"
        }
      ]
    },
    {
      "trackedEntity": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": "Jennifer"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "value": "Johnson"
        }
      ]
    }
  ]
}
```

The system does not allow the creation of a tracked entity instance
(as well as enrollment and event) with a UID that was already used in
the system. That means that UIDs cannot be reused.

#### Updating a tracked entity instance { #webapi_updating_tei }

For updating a tracked entity instance, the payload is equal to the
previous section. The difference is that you must use the HTTP *PUT*
method for the request when sending the payload. You will also need to
append the person identifier to the *trackedEntityInstances* resource in
the URL like this, where `<tracked-entity-instance-identifier>` should
be replaced by the identifier of the tracked entity instance:

    /api/trackedEntityInstances/<tracked-entity-instance-id>

The payload has to contain all, even non-modified, attributes and
relationships. Attributes or relationships that were present before and
are not present in the current payload any more will be removed from the
system. This means that if attributes/relationships are empty in the
current payload, all existing attributes/relationships will be deleted
from the system. From 2.31, it is possible to ignore empty
attributes/relationships in the current payload. A request parameter of
`ignoreEmptyCollection` set to `true` can be used in case you do not
wish to send in any attributes/relationships and also do not want them
to be deleted from the system.

It is not allowed to update an already deleted tracked entity instance.
Also, it is not allowed to mark a tracked entity instance as deleted via
an update request. The same rules apply to enrollments and events.

#### Deleting a tracked entity instance { #webapi_deleting_tei }

In order to delete a tracked entity instance, make a request to the URL
identifying the tracked entity instance with the *DELETE*
method. The URL is equal to the one above used for update.

#### Create and enroll tracked entity instances { #webapi_create_enroll_tei }

It is also possible to both create (and update) a tracked entity
instance and at the same time enroll into a program.

```json
{
  "trackedEntity": "tracked-entity-id",
  "orgUnit": "org-unit-id",
  "attributes": [{
    "attribute": "attribute-id",
    "value": "attribute-value"
  }],
  "enrollments": [{
    "orgUnit": "org-unit-id",
    "program": "program-id",
    "enrollmentDate": "2013-09-17",
    "incidentDate": "2013-09-17"
   }, {
    "orgUnit": "org-unit-id",
    "program": "program-id",
    "enrollmentDate": "2013-09-17",
    "incidentDate": "2013-09-17"
   }]
}
```

You would send this to the server as you would normally when creating or
updating a new tracked entity instance.

```bash
curl -X POST -d @tei.json -H "Content-Type: application/json"
  -u user:pass "http://server/api/33/trackedEntityInstances"
```

#### Complete example of payload including: tracked entity instance, enrollment and event { #webapi_create_enroll_tei_create_event }

It is also possible to create (and update) a tracked entity instance, at
the same time enroll into a program and create an event.

```json
{
  "trackedEntityType": "nEenWmSyUEp",
  "orgUnit": "DiszpKrYNg8",
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "value": "Joe"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "value": "Rufus"
    },
    {
     "attribute":"cejWyOfXge6",
     "value":"Male"
    }
  ],
  "enrollments":[
    {
      "orgUnit":"DiszpKrYNg8",
      "program":"ur1Edk5Oe2n",
      "enrollmentDate":"2017-09-15",
      "incidentDate":"2017-09-15",
      "events":[
        {
          "program":"ur1Edk5Oe2n",
          "orgUnit":"DiszpKrYNg8",
          "eventDate":"2017-10-17",
          "status":"COMPLETED",
          "storedBy":"admin",
          "programStage":"EPEcjy3FWmI",
          "coordinate": {
            "latitude":"59.8",
            "longitude":"10.9"
          },
          "dataValues": [
            {
              "dataElement":"qrur9Dvnyt5",
              "value":"22"
            },
            {
              "dataElement":"oZg33kd9taw",
              "value":"Male"
            }
         ]
      },
      {
         "program":"ur1Edk5Oe2n",
         "orgUnit":"DiszpKrYNg8",
         "eventDate":"2017-10-17",
         "status":"COMPLETED",
         "storedBy":"admin",
         "programStage":"EPEcjy3FWmI",
         "coordinate": {
           "latitude":"59.8",
           "longitude":"10.9"
         },
         "dataValues":[
           {
             "dataElement":"qrur9Dvnyt5",
             "value":"26"
           },
           {
             "dataElement":"oZg33kd9taw",
             "value":"Female"
           }
         ]
       }
     ]
    }
  ]  
}
```

You would send this to the server as you would normally when creating or
updating a new tracked entity instance.

```bash
curl -X POST -d @tei.json -H "Content-Type: application/json"
  -u user:pass "http://server/api/33/trackedEntityInstances"
```

#### Generated tracked entity instance attributes { #webapi_generate_tei_attributes }

Tracked entity instance attributes that are using automatic generation of
unique values have three endpoints that are used by apps. The endpoints
are all used for generating and reserving values.

In 2.29 we introduced TextPattern for defining and generating these
patterns. All existing patterns will be converted to a valid TextPattern
when upgrading to 2.29.

> **Note**
>
> As of 2.29, all these endpoints will require you to include any
> variables reported by the `requiredValues` endpoint listed as
> required. Existing patterns, consisting of only `#`, will be upgraded
> to the new TextPattern syntax `RANDOM(<old-pattern>)`. The RANDOM
> segment of the TextPattern is not a required variable, so this
> endpoint will work as before for patterns defined before 2.29.

##### Finding required values { #finding-required-values } 

A TextPattern can contain variables that change based on different
factors. Some of these factors will be unknown to the server, so the
values for these variables have to be supplied when generating and
reserving values.

This endpoint will return a map of required and optional values, that
the server will inject into the TextPattern when generating new values.
Required variables have to be supplied for the generation, but optional
variables should only be supplied if you know what you are doing.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/requiredValues

```json
{
  "REQUIRED": [
    "ORG_UNIT_CODE"
  ],
  "OPTIONAL": [
    "RANDOM"
  ]
}
```

##### Generate value endpoint { #webapi_generate_values }

Online web apps and other clients that want to generate a value that
will be used right away can use the simple generate endpoint. This
endpoint will generate a value that is guaranteed to be unique at the
time of generation. The value is also guaranteed not to be reserved. As
of 2.29, this endpoint will also reserve the value generated for 3 days.

If your TextPattern includes required values, you can pass them as
parameters like the example below:

The expiration time can also be overridden at the time of generation, by
adding the `?expiration=<number-of-days>` to the request.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generate?ORG_UNIT_CODE=OSLO

```json
{
  "ownerObject": "TRACKEDENTITYATTRIBUTE",
  "ownerUid": "Gs1ICEQTPlG",
  "key": "RANDOM(X)-OSL",
  "value": "C-OSL",
  "created": "2018-03-02T12:01:36.680",
  "expiryDate": "2018-03-05T12:01:36.678"
}
```

##### Generate and reserve value endpoint { #webapi_generate_reserve_values }

The generate and reserve endpoint is used by offline clients that need
to be able to register tracked entities with unique ids. They will
reserve a number of unique ids that this device will then use when
registering new tracked entity instances. The endpoint is called to
retrieve a number of tracked entity instance reserved values. An
optional parameter numberToReserve specifies how many ids to generate
(default is 1).

If your TextPattern includes required values, you can pass them as
parameters like the example below:

Similar to the /generate endpoint, this endpoint can also specify the
expiration time in the same way. By adding the `?expiration=<number-of-days>`
you can override the default 60 days.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generateAndReserve?numberToReserve=3&ORG_UNIT_CODE=OSLO

```json
[
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "B-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "Q-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "S-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  }
]
```

##### Reserved values { #reserved-values } 

Reserved values are currently not accessible through the api, however, they
are returned by the `generate` and `generateAndReserve` endpoints. The
following table explains the properties of the reserved value object:

#####



Table: Reserved values

| Propriété | Description |
|---|---|
| ownerObject | The metadata type referenced when generating and reserving the value. Currently only TRACKEDENTITYATTRIBUTE is supported. |
| ownerUid | The uid of the metadata object referenced when generating and reserving the value. |
| clé | A partially generated value where generated segments are not yet added. |
| valeur | The fully resolved value reserved. This is the value you send to the server when storing data. |
| créé | The timestamp when the reservation was made |
| expiryDate | The timestamp when the reservation will no longer be reserved |

Expired reservations are removed daily. If a pattern changes, values
that were already reserved will be accepted when storing data, even if
they don't match the new pattern, as long as the reservation has not
expired.

#### Image attributes { #image-attributes } 

Working with image attributes is a lot like working with file data
values. The value of an attribute with the image value type is the id of
the associated file resource. A GET request to the
`/api/trackedEntityInstances/<entityId>/<attributeId>/image`
endpoint will return the actual image. The optional height and width
parameters can be used to specify the dimensions of the image.

```bash
curl "http://server/api/33/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/image?height=200&width=200"
  > image.jpg
```

The API also supports a *dimension* parameter. It can take three possible values (please note capital letters): `SMALL` (254x254), `MEDIUM` (512x512), `LARGE` (1024x1024) or `ORIGINAL`. Image type attributes will be stored in pre-generated sizes
and will be furnished upon request based on the value of the `dimension` parameter.

```bash
curl "http://server/api/33/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/image?dimension=MEDIUM"
```

#### Tracked entity instance query { #webapi_tracked_entity_instance_query }

To query for tracked entity instances you can interact with the
`/api/trackedEntityInstances` resource.

    /api/33/trackedEntityInstances

##### Request syntax { #webapi_tei_query_request_syntax }



Table: Tracked entity instances query parameters

| Paramètre de requête | Description |
|---|---|
| filtre | Attributes to use as a filter for the query. Param can be repeated any number of times. Filters can be applied to a dimension on the format <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>]. Filter values are case-insensitive and can be repeated together with operator any number of times. Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN. |
| ou | Organisation unit identifiers, separated by ";". |
| ou Mode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; CAPTURE &#124; ALL. Default is SELECTED, which refers to the selected selected organisation units only. See table below for explanations. |
| de paludisme) ». | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| suivi | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| Entité suivie | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| page | The page number. Default page is 1. |
| taille de la page | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| lastUpdatedStartDate | Filter for teis which were updated after this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedEndDate | Filter for teis which were updated up until this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedDuration (durée de la dernière mise à jour) | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). Cannot be used together with *lastUpdatedStartDate* and/or *lastUpdatedEndDate*. |
| Mode utilisateur attribué | Restricts result to tei with events assigned based on the assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. See table below "Assigned user modes" for explanations. |
| assignedUser (Utilisateur assigné) | Filter the result down to a limited set of teis with events that are assigned to the given user IDs by using *assignedUser=id1;id2*.This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |
| trackedEntityInstance | Filter the result down to a limited set of teis using explicit uids of the tracked entity instances by using *trackedEntityInstance=id1;id2*. This parameter will at the very least create the outer boundary of the results, forming the list of all teis using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary. |
| includeDeleted | Indicates whether to include soft deleted teis or not. It is false by default. |
| potentialDuplicate | Il est possible de filtrer le résultat en supposant qu'une TEI soit un doublon potentiel. true: renvoie les TEI marqués comme doublons potentiels. false: renvoie les TEI NON marqués comme doublons potentiels. En cas d'omission, nous ne vérifions pas si une TEI est un doublon potentiel ou pas.|

The available organisation unit selection modes are explained in the following table.

Table: Organisation unit selection modes

| Mode | Description |
|---|---|
| SELECTED | Unités d'organisation définies dans la requête. |
| CHILDREN | The selected organisation units and the immediate children, i.e. the organisation units at the level below. |
| DESCENDANTS | The selected organisation units and all children, i.e. all organisation units in the sub-hierarchy. |
| ACCESSIBLE | The data view organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| CAPTURE | The data capture organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. |
| ALL | Il s'agit de toutes les unités d'organisation du système. L'utilisateur doit disposer de l'autorité `TOUS` pour pouvoir l'utiliser. |


Les modes 'utilisateur attribué' disponibles sont expliqués dans le tableau suivant.

Tableau : Modes d'utilisateur assigné

| Mode | Description |
|---|---|
| ACTUEL | Inclut les événements attribués à l’utilisateur actuellement connecté. |
| FOURNI | Inclut les événements attribués à l’utilisateur fourni dans la requête. |
| AUCUNE | Inclut uniquement les événements non attribués. |
| TOUT | Inclut tous les événements attribués, peu importe à qui ils sont attribués. |



La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

  - At least one organisation unit must be specified using the *ou*
    (un ou plusieurs), ou *ouMode=ALL* doit être spécifié.

  - Un seul des paramètres *program* et *trackedEntity* peut être
    spécifié (zéro ou un).

  - If *programStatus* is specified then *program* must also be
    spécifiés.

  - If *followUp* is specified then *program* must also be specified.

  - If *programStartDate* or *programEndDate* is specified then
    *program* must also be specified.

  - Les éléments du filtre ne peuvent être spécifiés qu'une seule fois.

Une requête pour toutes les instances associées à une unité d'organisation spécifique peut ressembler à ceci :

    /api/33/trackedEntityInstances.json?ou=DiszpKrYNg8

Pour lancer une requête pour des instances à l'aide d'un attribut avec filtre et d'un attribut sans filtre, avec une unité d'organisation en utilisant le mode de requête de l'unité d'organisation subordonnée, utilisez ceci :

    /api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A
      &filter=AMpUYgxuCaE&ou=DiszpKrYNg8;yMCshbaVExv

A query for instances where one attribute is included in the response
and one attribute is used as a filter:

    /api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A
      &filter=AMpUYgxuCaE:LIKE:Road&ou=DiszpKrYNg8

Une requête dans laquelle plusieurs opérandes et filtres sont spécifiés pour un élément de filtre :

    api/33/trackedEntityInstances.json?ou=DiszpKrYNg8&program=ur1Edk5Oe2n
      &filter=lw1SqmMlnfh:GT:150:LT:190

Pour lancer une requête sur un attribut en utilisant plusieurs valeurs dans un filtre *IN* :

    api/33/trackedEntityInstances.json?ou=DiszpKrYNg8
      &filter=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

Pour limiter la réponse aux instances qui font partie d'un programme spécifique, vous pouvez inclure un paramètre de requête de programme :

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &ouMode=DESCENDANTS&program=ur1Edk5Oe2n

Pour spécifier les dates d'inscription au programme dans la requête :

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &program=ur1Edk5Oe2n&programStartDate=2013-01-01&programEndDate=2013-09-01

Pour limiter la réponse aux instances d'une entité suivie spécifique, vous pouvez inclure un paramètre de requête d'entité suivie :

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

Par défaut, les instances sont renvoyées dans des pages de taille 50. Pour modifier cela, vous pouvez utiliser les paramètres de requête de page et de taille de page (pageSize) :

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &ouMode=DESCENDANTS&page=2&pageSize=3

Vous pouvez utiliser une gamme d'opérateurs pour le filtrage :



Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Free text match (Contains) |
| SW | Starts with |
| EW | Ends with |
| IN | Equal to one of multiple values separated by ";" |

##### Response format { #webapi_tei_query_response_format }

This resource supports JSON, JSONP, XLS and CSV resource
representations.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

The response in JSON/XML is in object format and can look like the
following. Please note that field filtering is supported, so if you want
a full view, you might want to add `fields=*` to the query:

```json
{
  "trackedEntityInstances": [
    {
      "lastUpdated": "2014-03-28 12:27:52.399",
      "trackedEntity": "cyl5vuJ5ETQ",
      "created": "2014-03-26 15:40:19.997",
      "orgUnit": "ueuQlqb8ccl",
      "trackedEntityInstance": "tphfdyIiVL6",
      "relationships": [],
      "attributes": [
        {
          "displayName": "Address",
          "attribute": "AMpUYgxuCaE",
          "type": "string",
          "value": "2033 Akasia St"
        },
        {
          "displayName": "TB number",
          "attribute": "ruQQnf6rswq",
          "type": "string",
          "value": "1Z 989 408 56 9356 521 9"
        },
        {
          "displayName": "Weight in kg",
          "attribute": "OvY4VVhSDeJ",
          "type": "number",
          "value": "68.1"
        },
        {
          "displayName": "Email",
          "attribute": "NDXw0cluzSw",
          "type": "string",
          "value": "LiyaEfrem@armyspy.com"
        },
        {
          "displayName": "Gender",
          "attribute": "cejWyOfXge6",
          "type": "optionSet",
          "value": "Female"
        },
        {
          "displayName": "Phone number",
          "attribute": "P2cwLGskgxn",
          "type": "phoneNumber",
          "value": "085 813 9447"
        },
        {
          "displayName": "First name",
          "attribute": "dv3nChNSIxy",
          "type": "string",
          "value": "Liya"
        },
        {
          "displayName": "Last name",
          "attribute": "hwlRTFIFSUq",
          "type": "string",
          "value": "Efrem"
        },
        {
          "code": "Height in cm",
          "displayName": "Height in cm",
          "attribute": "lw1SqmMlnfh",
          "type": "number",
          "value": "164"
        },
        {
          "code": "City",
          "displayName": "City",
          "attribute": "VUvgVao8Y5z",
          "type": "string",
          "value": "Kranskop"
        },
        {
          "code": "State",
          "displayName": "State",
          "attribute": "GUOBQt5K2WI",
          "type": "number",
          "value": "KwaZulu-Natal"
        },
        {
          "code": "Zip code",
          "displayName": "Zip code",
          "attribute": "n9nUvfpTsxQ",
          "type": "number",
          "value": "3282"
        },
        {
          "code": "National identifier",
          "displayName": "National identifier",
          "attribute": "AuPLng5hLbE",
          "type": "string",
          "value": "465700042"
        },
        {
          "code": "Blood type",
          "displayName": "Blood type",
          "attribute": "H9IlTX2X6SL",
          "type": "string",
          "value": "B-"
        },
        {
          "code": "Latitude",
          "displayName": "Latitude",
          "attribute": "Qo571yj6Zcn",
          "type": "string",
          "value": "-30.659626"
        },
        {
          "code": "Longitude",
          "displayName": "Longitude",
          "attribute": "RG7uGl4w5Jq",
          "type": "string",
          "value": "26.916172"
        }
      ]
    }
  ]
}
```

#### Tracked entity instance grid query { #webapi_tracked_entity_instance_grid_query }

To query for tracked entity instances you can interact with the
*/api/trackedEntityInstances/grid* resource. There are two types of
queries: One where a *query* query parameter and optionally *attribute*
parameters are defined, and one where *attribute* and *filter*
parameters are defined. This endpoint uses a more compact "grid" format,
and is an alternative to the query in the previous section.

    /api/33/trackedEntityInstances/query

##### Request syntax { #webapi_tei_grid_query_request_syntax }



Table: Tracked entity instances query parameters

| Paramètre de requête | Description |
|---|---|
| requête | Query string. Attribute query parameter can be used to define which attributes to include in the response. If no attributes but a program is defined, the attributes from the program will be used. If no program is defined, all attributes will be used. There are two formats. The first is a plan query string. The second is on the format <operator\>:<query\>. Operators can be EQ &#124; LIKE. EQ implies exact matches on words, LIKE implies partial matches on words. The query will be split on space, where each word will form a logical AND query. |
| attribut | Attributes to be included in the response. Can also be used as a filter for the query. Param can be repeated any number of times. Filters can be applied to a dimension on the format <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>]. Filter values are case-insensitive and can be repeated together with operator any number of times. Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN. Filters can be omitted in order to simply include the attribute in the response without any constraints. |
| filtre | Attributes to use as a filter for the query. Param can be repeated any number of times. Filters can be applied to a dimension on the format <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>]. Filter values are case-insensitive and can be repeated together with operator any number of times. Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN. |
| ou | Organisation unit identifiers, separated by ";". |
| ou Mode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; ALL. Default is SELECTED, which refers to the selected organisation units only. See table below for explanations. |
| de paludisme) ». | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| suivi | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| Entité suivie | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| eventStatus | Status of any event associated with the given program and the tracked entity instance. Can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULED &#124; OVERDUE &#124; SKIPPED. |
| eventStartDate | Start date of event associated with the given program and event status. |
| eventEndDate | End date of event associated with the given program and event status. |
| Étape du programme | The programStage for which the event related filters should be applied to. If not provided all stages will be considered. |
| skipMeta (ignorer les métadonnées) | Indicates whether meta data for the response should be included. |
| page | The page number. Default page is 1. |
| taille de la page | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| Mode utilisateur attribué | Restricts result to tei with events assigned based on the assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser (Utilisateur assigné) | Filter the result down to a limited set of teis with events that are assigned to the given user IDs by using *assignedUser=id1;id2*.This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |
| trackedEntityInstance | Filter the result down to a limited set of teis using explicit uids of the tracked entity instances by using *trackedEntityInstance=id1;id2*. This parameter will at the very least create the outer boundary of the results, forming the list of all teis using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary. |
| potentialDuplicate | Il est possible de filtrer le résultat en supposant qu'une TEI soit un doublon potentiel. true: renvoie les TEI marqués comme doublons potentiels. false: renvoie les TEI NON marqués comme doublons potentiels. En cas d'omission, nous ne vérifions pas si une TEI est un doublon potentiel ou pas.|

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.



Table: Organisation unit selection modes

| Mode | Description |
|---|---|
| SELECTED | Unités d'organisation définies dans la requête. |
| CHILDREN | Immediate children, i.e. only the first level below, of the organisation units defined in the request. |
| DESCENDANTS | All children, i.e. at only levels below, e.g. including children of children, of the organisation units defined in the request. |
| ACCESSIBLE | All descendants of the data view organisation units associated with the current user. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| CAPTURE | The data capture organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. |
| ALL | All organisation units in the system. Requires authority. |

Note that you can specify "attribute" with filters or directly using the "filter" params for constraining the
instances to return.

Certain rules apply to which attributes are returned.

  - If "query" is specified without any attributes or program, then all attributes that
    are marked as "Display in List without Program" is included in the response.

  - If program is specified,  all the attributes linked to the program will
    be included in the response.

  - If tracked entity type is specified, then all tracked entity type attributes
    will be included in the response.

You can specify queries with words separated by space - in that
situation the system will query for each word independently and return
records where each word is contained in any attribute. A query item can
be specified once as an attribute and once as a filter if needed. The
query is case insensitive. The following rules apply to the query
parameters.

  - At least one organisation unit must be specified using the *ou*
    (un ou plusieurs), ou *ouMode=ALL* doit être spécifié.

  - Un seul des paramètres *program* et *trackedEntity* peut être
    spécifié (zéro ou un).

  - If *programStatus* is specified then *program* must also be
    spécifiés.

  - If *followUp* is specified then *program* must also be specified.

  - If *programStartDate* or *programEndDate* is specified then
    *program* must also be specified.

  - If *eventStatus* is specified then *eventStartDate* and
    *eventEndDate* must also be specified.

  - A query cannot be specified together with filters.

  - Attribute items can only be specified once.

  - Les éléments du filtre ne peuvent être spécifiés qu'une seule fois.

Une requête pour toutes les instances associées à une unité d'organisation spécifique peut ressembler à ceci :

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8

A query on all attributes for a specific value and organisation unit,
using an exact word match:

    /api/33/trackedEntityInstances/query.json?query=scott&ou=DiszpKrYNg8

A query on all attributes for a specific value, using a partial word
match:

    /api/33/trackedEntityInstances/query.json?query=LIKE:scott&ou=DiszpKrYNg8

You can query on multiple words separated by the URL character for
space which is %20, will use a logical AND query for each
    word:

    /api/33/trackedEntityInstances/query.json?query=isabel%20may&ou=DiszpKrYNg8

A query where the attributes to include in the response are specified:

    /api/33/trackedEntityInstances/query.json?query=isabel
      &attribute=dv3nChNSIxy&attribute=AMpUYgxuCaE&ou=DiszpKrYNg8

To query for instances using one attribute with a filter and one
attribute without a filter, with one organisation unit using the
descendants organisation unit query mode:

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &attribute=AMpUYgxuCaE&ou=DiszpKrYNg8;yMCshbaVExv

A query for instances where one attribute is included in the response
and one attribute is used as a
    filter:

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &filter=AMpUYgxuCaE:LIKE:Road&ou=DiszpKrYNg8

Une requête dans laquelle plusieurs opérandes et filtres sont spécifiés pour un élément de filtre :

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8&program=ur1Edk5Oe2n
      &filter=lw1SqmMlnfh:GT:150:LT:190

To query on an attribute using multiple values in an IN
    filter:

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8
      &attribute=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

Pour limiter la réponse aux instances qui font partie d'un programme spécifique, vous pouvez inclure un paramètre de requête de programme :

    /api/33/trackedEntityInstances/query.json?filter=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

Pour spécifier les dates d'inscription au programme dans la requête :

    /api/33/trackedEntityInstances/query.json?filter=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&program=ur1Edk5Oe2n&programStartDate=2013-01-01
      &programEndDate=2013-09-01

Pour limiter la réponse aux instances d'une entité suivie spécifique, vous pouvez inclure un paramètre de requête d'entité suivie :

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

Par défaut, les instances sont renvoyées dans des pages de taille 50. Pour modifier cela, vous pouvez utiliser les paramètres de requête de page et de taille de page (pageSize) :

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&ouMode=DESCENDANTS&page=2&pageSize=3

To query for instances which have events of a given status within a
given time span:

    /api/33/trackedEntityInstances/query.json?ou=O6uvpzGd5pu
      &program=ur1Edk5Oe2n&eventStatus=LATE_VISIT
      &eventStartDate=2014-01-01&eventEndDate=2014-09-01

Vous pouvez utiliser une gamme d'opérateurs pour le filtrage :



Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Free text match (Contains) |
| SW | Starts with |
| EW | Ends with |
| IN | Equal to one of multiple values separated by ";" |

##### Response format { #webapi_tei_grid_query_response_format }

This resource supports JSON, JSONP, XLS and CSV resource
representations.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

  - csv (application/csv)

  - xls (application/vnd.ms-excel)

The response in JSON comes is in a tabular format and can look like the
following. The *headers* section describes the content of each column.
The instance, created, last updated, org unit and tracked entity columns
are always present. The following columns correspond to attributes
specified in the query. The *rows* section contains one row per
instance.

```json
{
  "headers": [{
    "name": "instance",
    "column": "Instance",
    "type": "java.lang.String"
  }, {
    "name": "created",
    "column": "Created",
    "type": "java.lang.String"
  }, {
    "name": "lastupdated",
    "column": "Last updated",
    "type": "java.lang.String"
  }, {
    "name": "ou",
    "column": "Org unit",
    "type": "java.lang.String"
  }, {
    "name": "te",
    "column": "Tracked entity",
    "type": "java.lang.String"
  }, {
    "name": "zHXD5Ve1Efw",
    "column": "Date of birth type",
    "type": "java.lang.String"
  }, {
    "name": "AMpUYgxuCaE",
    "column": "Address",
    "type": "java.lang.String"
  }],
  "metaData": {
    "names": {
      "cyl5vuJ5ETQ": "Person"
    }
  },
  "width": 7,
  "height": 7,
  "rows": [
    ["yNCtJ6vhRJu", "2013-09-08 21:40:28.0", "2014-01-09 19:39:32.19", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "21 Kenyatta Road"],
    ["fSofnQR6lAU", "2013-09-08 21:40:28.0", "2014-01-09 19:40:19.62", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "56 Upper Road"],
    ["X5wZwS5lgm2", "2013-09-08 21:40:28.0", "2014-01-09 19:40:31.11", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "56 Main Road"],
    ["pCbogmlIXga", "2013-09-08 21:40:28.0", "2014-01-09 19:40:45.02", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "12 Lower Main Road"],
    ["WnUXrY4XBMM", "2013-09-08 21:40:28.0", "2014-01-09 19:41:06.97", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "13 Main Road"],
    ["xLNXbDs9uDF", "2013-09-08 21:40:28.0", "2014-01-09 19:42:25.66", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "14 Mombasa Road"],
    ["foc5zag6gbE", "2013-09-08 21:40:28.0", "2014-01-09 19:42:36.93", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "15 Upper Hill"]
  ]
}
```

#### Tracked entity instance filters { #webapi_tei_filters }

To create, read, update and delete tracked entity instance filters you
can interact with the */api/trackedEntityInstanceFilters* resource. Tracked entity instance filters are shareable and follows the same pattern of sharing as any other metadata object. When using the */api/sharing* the type parameter will be *trackedEntityInstanceFilter*.

    /api/33/trackedEntityInstanceFilters

##### Create and update a tracked entity instance filter definition { #create-and-update-a-tracked-entity-instance-filter-definition } 

For creating and updating a tracked entity instance filter in the
system, you will be working with the *trackedEntityInstanceFilters*
resource. The tracked entity instance filter definitions are used in the
Tracker Capture app to display relevant predefined "Working lists" in
the tracker user interface.



Tableau : Charge utile

| Valeurs de charge utile | Description | Exemple |
|---|---|---|
| nom | Name of the filter. Required. ||
| Description | A description of the filter. ||
| sortOrder | The sort order of the filter. Used in Tracker Capture to order the filters in the program dashboard. ||
| style | Object containing css style. | ( "color": "blue", "icon": "fa fa-calendar"} |
| de paludisme) ». | Objet contenant l'identifiant du programme. Obligatoire. | { "id" : "uy2gU8kTjF"} |
| entityQueryCriteria | An object representing various possible filtering values. See *Entity Query Criteria* definition table below.
| eventFilters | A list of eventFilters. See *Event filters* definition table below. | [{"programStage": "eaDH9089uMp", "eventStatus": "OVERDUE", "eventCreatedPeriod": {"periodFrom": -15, "periodTo": 15}}] |

Table: Entity Query Criteria definition

||||
|---|---|---|
| Filtres de valeurs d'attributs | A list of attributeValueFilters. This is used to specify filters for attribute values when listing tracked entity instances | "attributeValueFilters"=[{       "attribute": "abcAttributeUid",       "le": "20",       "ge": "10",       "lt": "20",       "gt": "10",       "in": ["India", "Norway"],       "like": "abc",       "sw": "abc",       "ew": "abc",       "dateFilter": {         "startDate": "2014-05-01",         "endDate": "2019-03-20",         "startBuffer": -5,         "endBuffer": 5,         "period": "LAST_WEEK",         "type": "RELATIVE"       }     }] |
| Statut de l'inscription | The TEIs enrollment status. Can be none(any enrollmentstatus) or ACTIVE&#124;COMPLETED&#124;CANCELED ||
| followup | When this parameter is true, the filter only returns TEIs that have an enrollment with status followup. ||
| organisationUnit | To specify the uid of the organisation unit | "organisationUnit": "a3kGcGDCuk7" |
| ou Mode | To specify the OU selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL | "ouMode": "SELECTED" |
| Mode utilisateur attribué | To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUser (Utilisateur assigné) | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |
| Afficher l'ordre des colonnes | To specify the output ordering of columns | "displayOrderColumns": ["enrollmentDate", "program"] |
| Ordre | To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "orderDimension:direction". | "order"="a3kGcGDCuk6:desc,eventDate:asc" |
| eventStatus | Any valid EventStatus | "eventStatus": "COMPLETED" |
| Étape du programme | To specify a programStage uid to filter on. TEIs will be filtered based on presence of enrollment in the specified program stage.| "programStage"="a3kGcGDCuk6" |
| TrackedEntityType (Type d'entité suivie) | To specify a trackedEntityType filter TEIs on. | "trackedEntityType"="a3kGcGDCuk6" |
| trackedEntityInstances | To specify a list of trackedEntityInstances to use when querying TEIs. | "trackedEntityInstances"=["a3kGcGDCuk6","b4jGcGDCuk7"] |
| enrollmentIncidentDate | DateFilterPeriod object date filtering based on enrollment incident date. | "enrollmentIncidentDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| eventDate | DateFilterPeriod object date filtering based on event date. | "eventDate": {     "startBuffer": -5,     "endBuffer": 5,     "type": "RELATIVE"   } |
| enrollmentCreatedDate | DateFilterPeriod object date filtering based on enrollment created date. | "enrollmentCreatedDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| lastUpdatedDate | DateFilterPeriod object date filtering based on last updated date. | "lastUpdatedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   } |

Table: Event filters definition

||||
|---|---|---|
| Étape du programme | Which programStage the TEI needs an event in to be returned. | "eaDH9089uMp" |
| eventStatus | The events status. Can be none(any event status) or ACTIVE&#124;COMPLETED&#124;SCHEDULED&#124;OVERDUE | ACTIVE |
| eventCreatedPeriod | Period object containing a period in which the event must be created. See *Period* definition below. | { "periodFrom": -15, "periodTo": 15} |
| Mode utilisateur attribué | To specify the assigned user selection mode for events. Possible values are CURRENT (events assigned to current user)&#124; PROVIDED (events assigned to users provided in "assignedUsers" list) &#124; NONE (events assigned to no one) &#124; ANY (events assigned to anyone). If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUser (Utilisateur assigné) | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |


Table: DateFilterPeriod object definition

||||
|---|---|---|
| type | Specify whether the date period type is ABSOLUTE &#124; RELATIVE | "type" : "RELATIVE" |
| période | Specify if a relative system defined period is to be used. Applicable only when "type" is RELATIVE. (see [Relative Periods](#webapi_date_relative_period_values) for supported relative periods) | "period" : "THIS_WEEK" |
| date de début | Absolute start date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| date de fin | Absolute end date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| startBuffer | Relative custom start date. Applicable only when "type" is RELATIVE | "startBuffer":-10 |
| endBuffer | Relative custom end date. Applicable only when "type" is RELATIVE | "startDate":+10 |

Table: Period definition

||||
|---|---|---|
| periodFrom | Number of days from current day. Can be positive or negative integer. | -15 |
| periodTo | Number of days from current day. Must be bigger than periodFrom. Can be positive or negative integer. | 15 |

##### Tracked entity instance filters query { #tracked-entity-instance-filters-query } 

To query for tracked entity instance filters in the system, you can
interact with the */api/trackedEntityInstanceFilters* resource.



Table: Tracked entity instance filters query parameters

| Paramètre de requête | Description |
|---|---|
| de paludisme) ». | Program identifier. Restricts filters to the given program. |

### Enrollment management { #webapi_enrollment_management }

Enrollments have full CRUD support in the API. Together with the API
for tracked entity instances most operations needed for working with
tracked entity instances and programs are supported.

    /api/33/enrollments

#### Enrolling a tracked entity instance into a program { #webapi_enrolling_tei }

For enrolling persons into a program, you will need to first get the
identifier of the person from the *trackedEntityInstances* resource.
Then, you will need to get the program identifier from the *programs*
resource. A template payload can be seen below:

```json
{
  "trackedEntityInstance": "ZRyCnJ1qUXS",
  "orgUnit": "ImspTQPwCqd",
  "program": "S8uo8AlvYMz",
  "enrollmentDate": "2013-09-17",
  "incidentDate": "2013-09-17"
}
```

This payload should be used in a *POST* request to the enrollments
resource identified by the following URL:

    /api/33/enrollments

For cancelling or completing an enrollment, you can make a *PUT*
request to the `enrollments` resource, including the identifier and the
action you want to perform. For cancelling an enrollment for a tracked
entity instance:

    /api/33/enrollments/<enrollment-id>/cancelled

For completing an enrollment for a tracked entity instance you can make a
*PUT* request to the following URL:

    /api/33/enrollments/<enrollment-id>/completed

For deleting an enrollment, you can make a *DELETE* request to the
following URL:

    /api/33/enrollments/<enrollment-id>

#### Enrollment instance query { #webapi_enrollment_instance_query }

To query for enrollments you can interact with the */api/enrollments*
resource.

    /api/33/enrollments

##### Request syntax { #webapi_enrollment_query_request_syntax }



Table: Enrollment query parameters

| Paramètre de requête | Description |
|---|---|
| ou | Organisation unit identifiers, separated by ";". |
| ou Mode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; CAPTURE &#124; ALL. Default is SELECTED, which refers to the selected organisation units only. See table below for explanations. |
| de paludisme) ». | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| suivi | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| lastUpdatedDuration (durée de la dernière mise à jour) | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). |
| Entité suivie | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| trackedEntityInstance | Tracked entity instance identifier. Should not be used together with trackedEntity. |
| page | The page number. Default page is 1. |
| taille de la page | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| includeDeleted | Indicates whether to include soft deleted enrollments or not. It is false by default. |
| Ordre | Comma-delimited list in the form of `propName:sortDirection`.<br>Available properties are: `completedAt`, `createdAt`, `createdAtClient`, `enrolledAt`, `updatedAt` and `updatedAtClient`.<br> Example: `createdAt:desc`<br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive. `sortDirection` defaults to `asc` when non provided.|

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.



Table: Organisation unit selection modes

| Mode | Description |
|---|---|
| SELECTED | Organisation units defined in the request (default). |
| CHILDREN | Immediate children, i.e. only the first level below, of the organisation units defined in the request. |
| DESCENDANTS | All children, i.e. at only levels below, e.g. including children of children, of the organisation units defined in the request. |
| ACCESSIBLE | All descendants of the data view organisation units associated with the current user. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| ALL | All organisation units in the system. Requires authority. |

La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

  - At least one organisation unit must be specified using the *ou*
    (un ou plusieurs), ou *ouMode=ALL* doit être spécifié.

  - Un seul des paramètres *program* et *trackedEntity* peut être
    spécifié (zéro ou un).

  - If *programStatus* is specified then *program* must also be
    spécifiés.

  - If *followUp* is specified then *program* must also be specified.

  - If *programStartDate* or *programEndDate* is specified then
    *program* must also be specified.

Une requête pour toutes les inscriptions associées à une unité d'organisation spécifique peut ressembler à ceci :

    /api/33/enrollments.json?ou=DiszpKrYNg8

To constrain the response to enrollments which are part of a specific
program you can include a program query
    parameter:

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

To specify program enrollment dates as part of the
    query:

    /api/33/enrollments.json?&ou=O6uvpzGd5pu&program=ur1Edk5Oe2n
      &programStartDate=2013-01-01&programEndDate=2013-09-01

To constrain the response to enrollments of a specific tracked entity
you can include a tracked entity query
    parameter:

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

To constrain the response to enrollments of a specific tracked entity
instance you can include a tracked entity instance query parameter, in
this case we have restricted it to available enrollments viewable for
current
    user:

    /api/33/enrollments.json?ouMode=ACCESSIBLE&trackedEntityInstance=tphfdyIiVL6

By default the enrollments are returned in pages of size 50, to change
this you can use the page and pageSize query
    parameters:

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&page=2&pageSize=3

##### Response format { #webapi_enrollment_query_response_format }

This resource supports JSON, JSONP, XLS and CSV resource
representations.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

The response in JSON/XML is in object format and can look like the
following. Please note that field filtering is supported, so if you want
a full view, you might want to add `fields=*` to the query:

```json
{
  "enrollments": [
    {
      "lastUpdated": "2014-03-28T05:27:48.512+0000",
      "trackedEntity": "cyl5vuJ5ETQ",
      "created": "2014-03-28T05:27:48.500+0000",
      "orgUnit": "DiszpKrYNg8",
      "program": "ur1Edk5Oe2n",
      "enrollment": "HLFOK0XThjr",
      "trackedEntityInstance": "qv0j4JBXQX0",
      "followup": false,
      "enrollmentDate": "2013-05-23T05:27:48.490+0000",
      "incidentDate": "2013-05-10T05:27:48.490+0000",
      "status": "ACTIVE"
    }
  ]
}
```

### Événements { #webapi_events }

This section is about sending and reading events.

    /api/33/events

#### Sending events { #webapi_sending_events }

DHIS2 supports three kinds of events: single events with no registration
(also referred to as anonymous events), single event with registration
and multiple events with registration. Registration implies that the
data is linked to a tracked entity instance which is identified using
some sort of identifier.

To send events to DHIS2 you must interact with the *events* resource.
The approach to sending events is similar to sending aggregate data
values. You will need a *program* which can be looked up using the
*programs* resource, an *orgUnit* which can be looked up using the
*organisationUnits* resource, and a list of valid data element
identifiers which can be looked up using the *dataElements* resource.
For events with registration, a *tracked entity instance* identifier is
required, read about how to get this in the section about the
*trackedEntityInstances* resource. For sending events to programs with
multiple stages, you will need to also include the *programStage*
identifier, the identifiers for programStages can be found in the
*programStages* resource.

A simple single event with no registration example payload in XML format
where we send events from the "Inpatient morbidity and mortality"
program for the "Ngelehun CHC" facility in the demo database can be seen
below:

```xml
<?xml version="1.0" encoding="utf-8"?>
<event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
  eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
  <coordinate latitude="59.8" longitude="10.9" />
  <dataValues>
    <dataValue dataElement="qrur9Dvnyt5" value="22" />
    <dataValue dataElement="oZg33kd9taw" value="Male" />
    <dataValue dataElement="msodh3rEMJa" value="2013-05-18" />
  </dataValues>
</event>
```

To perform some testing we can save the XML payload as a file
called*event.xml* and send it as a POST request to the events resource
in the API using curl with the following command:

```bash
curl -d @event.xml "https://play.dhis2.org/demo/api/33/events"
  -H "Content-Type:application/xml" -u admin:district
```

The same payload in JSON format looks like this:

```json
{
  "program": "eBAyeGv0exc",
  "orgUnit": "DiszpKrYNg8",
  "eventDate": "2013-05-17",
  "status": "COMPLETED",
  "completedDate": "2013-05-18",
  "storedBy": "admin",
  "coordinate": {
    "latitude": 59.8,
    "longitude": 10.9
  },
  "dataValues": [
    {
      "dataElement": "qrur9Dvnyt5",
      "value": "22"
    },
    {
      "dataElement": "oZg33kd9taw",
      "value": "Male"
    },
    {
      "dataElement": "msodh3rEMJa",
      "value": "2013-05-18"
    }
  ]
}
```

To send this you can save it to a file called *event.json* and use curl
like this:

```bash
curl -d @event.json "localhost/api/33/events" -H "Content-Type:application/json"
  -u admin:district
```

We also support sending multiple events at the same time. A payload in
XML format might look like this:

```xml
<?xml version="1.0" encoding="utf-8"?>
<events>
  <event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
    eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
    <coordinate latitude="59.8" longitude="10.9" />
    <dataValues>
      <dataValue dataElement="qrur9Dvnyt5" value="22" />
      <dataValue dataElement="oZg33kd9taw" value="Male" />
    </dataValues>
  </event>
  <event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
    eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
    <coordinate latitude="59.8" longitude="10.9" />
    <dataValues>
      <dataValue dataElement="qrur9Dvnyt5" value="26" />
      <dataValue dataElement="oZg33kd9taw" value="Female" />
    </dataValues>
  </event>
</events>
```

You will receive an import summary with the response which can be
inspected in order to get information about the outcome of the request,
like how many values were imported successfully. The payload in JSON
format looks like this:

```json
{
  "events": [
  {
    "program": "eBAyeGv0exc",
    "orgUnit": "DiszpKrYNg8",
    "eventDate": "2013-05-17",
    "status": "COMPLETED",
    "storedBy": "admin",
    "coordinate": {
      "latitude": "59.8",
      "longitude": "10.9"
    },
    "dataValues": [
      {
        "dataElement": "qrur9Dvnyt5",
        "value": "22"
      },
      {
        "dataElement": "oZg33kd9taw",
        "value": "Male"
      }
    ]
  },
  {
    "program": "eBAyeGv0exc",
    "orgUnit": "DiszpKrYNg8",
    "eventDate": "2013-05-17",
    "status": "COMPLETED",
    "storedBy": "admin",
    "coordinate": {
      "latitude": "59.8",
      "longitude": "10.9"
    },
    "dataValues": [
      {
        "dataElement": "qrur9Dvnyt5",
        "value": "26"
      },
      {
        "dataElement": "oZg33kd9taw",
        "value": "Female"
      }
    ]
  } ]
}
```

You can also use GeoJson to store any kind of geometry on your event. An example payload using GeoJson instead of the former latitude and longitude properties can be seen here:

```json
{
  "program": "eBAyeGv0exc",
  "orgUnit": "DiszpKrYNg8",
  "eventDate": "2013-05-17",
  "status": "COMPLETED",
  "storedBy": "admin",
  "geometry": {
    "type": "POINT",
    "coordinates": [59.8, 10.9]
  },
  "dataValues": [
    {
      "dataElement": "qrur9Dvnyt5",
      "value": "22"
    },
    {
      "dataElement": "oZg33kd9taw",
      "value": "Male"
    },
    {
      "dataElement": "msodh3rEMJa",
      "value": "2013-05-18"
    }
  ]
}
```

As part of the import summary you will also get the identifier
*reference* to the event you just sent, together with a *href* element
which points to the server location of this event. The table below
describes the meaning of each element.



Table: Events resource format

| Paramètre | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| de paludisme) ». | string | vrai || Identifier of the single event with no registration program |
| orgUnit (Unité d'organisation) | string | vrai || Identifier of the organisation unit where the event took place |
| eventDate | date | vrai || The date of when the event occurred |
| completedDate | date | faux || The date of when the event is completed. If not provided, the current date is selected as the event completed date |
| statut | enum | faux | ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED | Whether the event is complete or not |
| Stocké par | string | faux | Defaults to current user | Who stored this event (can be username, system-name, etc) |
| coordinate | double | faux || Refers to where the event took place geographically (latitude and longitude) |
| élément de données | string | vrai || Identifier of data element |
| valeur | string | vrai || Data value or measure for this event |

##### OrgUnit matching { #orgunit-matching } 

By default the orgUnit parameter will match on the
ID, you can also select the orgUnit id matching scheme by using the
parameter orgUnitIdScheme=SCHEME, where the options are: *ID*, *UID*,
*UUID*, *CODE*, and *NAME*. There is also the *ATTRIBUTE:* scheme, which
matches on a *unique* metadata attribute value.

#### Updating events { #webapi_updating_events }

To update an existing event, the format of the payload is the same, but
the URL you are posting to must add the identifier to the end of the URL
string and the request must be PUT.

The payload has to contain all, even non-modified, attributes.
Attributes that were present before and are not present in the current
payload any more will be removed by the system.

It is not allowed to update an already deleted event. The same applies
to tracked entity instance and enrollment.

```bash
curl -X PUT -d @updated_event.xml "localhost/api/33/events/ID"
  -H "Content-Type: application/xml" -u admin:district
```

```bash
curl -X PUT -d @updated_event.json "localhost/api/33/events/ID"
  -H "Content-Type: application/json" -u admin:district
```

#### Deleting events { #webapi_deleting_events }

To delete an existing event, all you need is to send a DELETE request
with an identifier reference to the server you are using.

```bash
curl -X DELETE "localhost/api/33/events/ID" -u admin:district
```

#### Assigning user to events { #webapi_user_assign_event }

A user can be assigned to an event. This can be done by including the appropriate property in the payload when updating or creating the event.

      "assignedUser": "<id>"

The id refers to the if of the user. Only one user can be assigned to an event at a time.

User assignment must be enabled in the program stage before users can be assigned to events.
#### Getting events { #webapi_getting_events }

To get an existing event you can issue a GET request including the
identifier like this:

```bash
curl "http://localhost/api/33/events/ID" -H "Content-Type: application/xml" -u admin:district
```

#### Querying and reading events { #webapi_querying_reading_events }

This section explains how to read out the events that have been stored
in the DHIS2 instance. For more advanced uses of the event data, please
see the section on event analytics. The output format from the
`/api/events` endpoint will match the format that is used to send events
to it (which the analytics event api does not support). Both XML and
JSON are supported, either through adding .json/.xml or by setting the
appropriate *Accept* header. The query is paged by default and the
default page size is 50 events, *field* filtering works as it does for
metadata, add the *fields* parameter and include your wanted properties,
i.e. *?fields=program,status*.



Table: Events resource query parameters

| Clé | Type | Obligatoire | Description |
|---|---|---|---|
| de paludisme) ». | identifier | true (if not programStage is provided) | Identifiant du programme |
| Étape du programme | identifier | faux | Identifiant de l'étape de programme |
| programStatus | enum | faux | Status of event in program, ca be ACTIVE &#124; COMPLETED &#124; CANCELLED |
| Suivi | booléen | faux | Whether event is considered for follow up in program, can be true &#124; false or omitted. |
| trackedEntityInstance | identifier | faux | Identifiant de l'instance d'entité suivie |
| orgUnit (Unité d'organisation) | identifier | vrai | Identifiant de l'unité d'organisation |
| ou Mode | enum | faux | Org unit selection mode, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS |
| date de début | date | faux | Only events newer than this date |
| date de fin | date | faux | Only events older than this date |
| statut | enum | faux | Status of event, can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULED &#124; OVERDUE &#124; SKIPPED |
| lastUpdatedStartDate | date | faux | Filter for events which were updated after this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedEndDate | date | faux | Filter for events which were updated up until this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedDuration (durée de la dernière mise à jour) | string | faux | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). Cannot be used together with *lastUpdatedStartDate* and/or *lastUpdatedEndDate*. |
| skipMeta (ignorer les métadonnées) | booléen | faux | Exclut la partie métadonnées de la réponse (améliore les performances) |
| page | entier | faux | Page number |
| taille de la page | entier | faux | Number of items in each page |
| totalPages | booléen | faux | Indicates whether to include the total number of pages in the paging response. |
| skipPaging | booléen | faux | Indicates whether to skip paging in the query and return all events. |
| dataElementIdScheme (Schéma de l'identifiant de l'élément de données) | string | faux | Data element ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | string | faux | Category Option Combo ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | string | faux | Organisation Unit ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| programIdScheme (Schéma d'identification du programme) | string | faux | Program ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| programmeStageIdScheme (Schéma d'identification de l'étape de programme) | string | faux | Program Stage ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| idScheme (schéma d'identifiants) | string | faux | Permet de définir le schéma d'identification  à la fois pour l'élément de données, la combinaison d'options de catégorie, l'unité d'organisation, le programme et l'étape de programme. |
| Ordre | string | faux | The order of which to retrieve the events from the API. Usage: order=<property\>:asc/desc - Ascending order is default. <br>Properties: event &#124; program &#124; programStage &#124; enrollment &#124; enrollmentStatus &#124; orgUnit &#124; orgUnitName &#124; trackedEntityInstance &#124; eventDate &#124; followup &#124; status &#124; dueDate &#124; storedBy &#124; created &#124; lastUpdated &#124; completedBy &#124; completedDate<br> order=orgUnitName:DESC order=lastUpdated:ASC |
| événement | comma delimited string | faux | Filter the result down to a limited set of IDs by using *event=id1;id2*. |
| skipEventId | booléen | faux | Ignore les identifiants d'événement dans la réponse |
| attributeCc (\*\*) | string | faux | Attribute category combo identifier (must be combined with *attributeCos*) |
| attributeCos (\*\*) | string | faux | Attribute category option identifiers, separated with ; (must be combined with *attributeCc*) |
| async | faux &#124; vrai | faux | Indicates whether the import should be done asynchronous or synchronous. |
| includeDeleted | booléen | faux | S'il est défini sur "vrai", les événements supprimés mais pas définitivement seront inclus dans le résultat de votre requête. |
| Mode utilisateur attribué | enum | faux | Assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser (Utilisateur assigné) | comma delimited strings | faux | Filter the result down to a limited set of events that are assigned to the given user IDs by using *assignedUser=id1;id2*. This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |

> **Note**
>
> If the query contains neither `attributeCC` nor `attributeCos`, the server returns events for all attribute option combos where the user has read access.

##### Exemples { #examples }

Query for all events with children of a certain organisation unit:

    /api/29/events.json?orgUnit=YuQRtpLP10I&ouMode=CHILDREN

Query for all events with all descendants of a certain organisation
unit, implying all organisation units in the sub-hierarchy:

    /api/33/events.json?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS

La requête pour tous les événements disposant d'un programme et d'une unité d'organisation :

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

Query for all events with a certain program and organisation unit,
sorting by due date
    ascending:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=dueDate

La requête pour les 10 événements avec la date d'événement la plus récente dans un programme et une unité d'organisation - par pagination et ordonnés par date d'échéance en ordre décroissant :

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &order=eventDate:desc&pageSize=10&page=1

La requête pour tous les événements avec un programme et une unité d'organisation pour une instance d'entité suivie donnée :

    /api/33/events.json?orgUnit=DiszpKrYNg8
      &program=eBAyeGv0exc&trackedEntityInstance=gfVxE3ALA9m

Query for all events with a certain program and organisation unit older
or equal to
    2014-02-03:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&endDate=2014-02-03

La requête pour tous les événements avec une étape de programme, une unité d'organisation et une instance d'entité suivie de l'an 2014 :

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &trackedEntityInstance=gfVxE3ALA9m&startDate=2014-01-01&endDate=2014-12-31

Query files associated with event data values. In the specific case of fetching an image file an
additional parameter can be provided to fetch the image with different dimensions. If dimension is
not provided, the system will return the original image. The parameter will be ignored in case of
fetching non-image files e.g pdf. Possible dimension values are *small(254 x 254),
medium(512 x 512), large(1024 x 1024) or original*. Any value other than those mentioned will be
discarded and the original image will be returned.

    /api/33/events/files?eventUid=hcmcWlYkg9u&dataElementUid=C0W4aFuVm4P&dimension=small

Retrieve events with specified Organisation unit and Program, and use _Attribute:Gq0oWTf2DtN_ as
identifier scheme

    /api/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN

Retrieve events with specified Organisation unit and Program, and use UID as identifier scheme for
orgUnits, Code as identifier scheme for Program stages, and _Attribute:Gq0oWTf2DtN_ as identifier
scheme for the rest of the metadata with assigned attribute.

    api/events.json?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN
      &orgUnitIdScheme=UID&programStageIdScheme=Code

#### Event grid query { #event-grid-query } 

In addition to the above event query end point, there is an event grid
query end point where a more compact "grid" format of events are
returned. This is possible by interacting with
/api/events/query.json|xml|xls|csv endpoint.

    /api/33/events/query

Most of the query parameters mentioned in event querying and reading
section above are valid here. However, since the grid to be returned
comes with specific set of columns that apply to all rows (events), it
is mandatory to specify a program stage. It is not possible to mix
events from different programs or program stages in the return.

Returning events from a single program stage, also opens up for new
functionality - for example sorting and searching events based on their
data element values. api/events/query has support for this. Below are
some examples

A query to return an event grid containing only selected data elements
for a program stage

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &dataElement=qrur9Dvnyt5,fWIAEtYVEGk,K6uUAvq500H&order=lastUpdated:desc
      &pageSize=50&page=1&totalPages=true

A query to return an event grid containing all data elements of a
program
    stage

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &includeAllDataElements=true

A query to filter events based on data element
    value

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &filter=qrur9Dvnyt5:GT:20:LT:50

In addition to the filtering, the above example also illustrates one
thing: the fact that there are no data elements mentioned to be returned
in the grid. When this happens, the system defaults back to return only
those data elements marked "Display in report" under program stage
configuration.

We can also extend the above query to return us a grid sorted (asc|desc)
based on data element
    value

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &filter=qrur9Dvnyt5:GT:20:LT:50&order=qrur9Dvnyt5:desc

#### Event filters { #webapi_event_filters }

To create, read, update and delete event filters you
can interact with the `/api/eventFilters` resource.

    /api/33/eventFilters

##### Create and update an event filter definition { #create-and-update-an-event-filter-definition } 

For creating and updating an event filter in the
system, you will be working with the *eventFilters*
resource. *POST* is used to create and *PUT* method is used to update. The event filter definitions are used in the
Tracker Capture app to display relevant predefined "Working lists" in
the tracker user interface.



Table: Request Payload

| Request Property | Description | Exemple |
|---|---|---|
| nom | Name of the filter. | "name":"My working list" |
| Description | A description of the filter. | "description":"for listing all events assigned to me". |
| de paludisme) ». | The uid of the program. | "program" : "a3kGcGDCuk6" |
| Étape du programme | The uid of the program stage. | "programStage" : "a3kGcGDCuk6" |
| eventQueryCriteria | Object containing parameters for querying, sorting and filtering events. | "eventQueryCriteria": {     "organisationUnit":"a3kGcGDCuk6",     "status": "COMPLETED",     "createdDate": {       "from": "2014-05-01",       "to": "2019-03-20"     },     "dataElements": ["a3kGcGDCuk6:EQ:1", "a3kGcGDCuk6"],     "filters": ["a3kGcGDCuk6:EQ:1"],     "programStatus": "ACTIVE",     "ouMode": "SELECTED",     "assignedUserMode": "PROVIDED",     "assignedUsers" : ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "followUp": false,     "trackedEntityInstance": "a3kGcGDCuk6",     "events": ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "fields": "eventDate,dueDate",     "order": "dueDate:asc,createdDate:desc"   } |



Table: Event Query Criteria definition

||||
|---|---|---|
| Suivi | Used to filter events based on enrollment followUp flag. Possible values are true&#124;false. | "followUp": true |
| organisationUnit | To specify the uid of the organisation unit | "organisationUnit": "a3kGcGDCuk7" |
| ou Mode | To specify the OU selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL | "ouMode": "SELECTED" |
| Mode utilisateur attribué | To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUser (Utilisateur assigné) | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |
| displayOrderColumns | To specify the output ordering of columns | "displayOrderColumns": ["eventDate", "dueDate", "program"] |
| Ordre | To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "dataItem:direction". | "order"="a3kGcGDCuk6:desc,eventDate:asc" |
| Filtres de données | To specify filters to be applied when listing events | "dataFilters"=[{       "dataItem": "abcDataElementUid",       "le": "20",       "ge": "10",       "lt": "20",       "gt": "10",       "in": ["India", "Norway"],       "like": "abc",       "dateFilter": {         "startDate": "2014-05-01",         "endDate": "2019-03-20",         "startBuffer": -5,         "endBuffer": 5,         "period": "LAST_WEEK",         "type": "RELATIVE"       }     }] |
| statut | Any valid EventStatus | "eventStatus": "COMPLETED" |
| événements | To specify list of events | "events"=["a3kGcGDCuk6"] |
| completedDate | DateFilterPeriod object date filtering based on completed date. | "completedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| eventDate | DateFilterPeriod object date filtering based on event date. | "eventDate": {     "startBuffer": -5,     "endBuffer": 5,     "type": "RELATIVE"   } |
| dueDate | DateFilterPeriod object date filtering based on due date. | "dueDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| lastUpdatedDate | DateFilterPeriod object date filtering based on last updated date. | "lastUpdatedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   } |



Table: DateFilterPeriod object definition

||||
|---|---|---|
| type | Specify whether the date period type is ABSOLUTE &#124; RELATIVE | "type" : "RELATIVE" |
| période | Specify if a relative system defined period is to be used. Applicable only when "type" is RELATIVE. (see [Relative Periods](#webapi_date_relative_period_values) for supported relative periods) | "period" : "THIS_WEEK" |
| date de début | Absolute start date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| date de fin | Absolute end date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| startBuffer | Relative custom start date. Applicable only when "type" is RELATIVE | "startBuffer":-10 |
| endBuffer | Relative custom end date. Applicable only when "type" is RELATIVE | "startDate":+10 |

The available assigned user selection modes are explained in the
following table.



Table: Assigned user selection modes (event assignment)

| Mode | Description |
|---|---|
| ACTUEL | Assigned to the current logged in user |
| FOURNI | Assigned to the users provided in the "assignedUser" parameter |
| AUCUNE | Assigned to no users. |
| TOUT | Assigned to any users. |

A sample payload that can be used to create/update an eventFilter is shown below.

```json
{
  "program": "ur1Edk5Oe2n",
  "description": "Simple Filter for TB events",
  "name": "TB events",
  "eventQueryCriteria": {
    "organisationUnit":"DiszpKrYNg8",
    "eventStatus": "COMPLETED",
    "eventDate": {
      "startDate": "2014-05-01",
      "endDate": "2019-03-20",
      "startBuffer": -5,
      "endBuffer": 5,
      "period": "LAST_WEEK",
      "type": "RELATIVE"
    },
    "dataFilters": [{
      "dataItem": "abcDataElementUid",
      "le": "20",
      "ge": "10",
      "lt": "20",
      "gt": "10",
      "in": ["India", "Norway"],
      "like": "abc"
    },
    {
      "dataItem": "dateDataElementUid",
      "dateFilter": {
        "startDate": "2014-05-01",
        "endDate": "2019-03-20",
        "type": "ABSOLUTE"
      }
    },
    {
      "dataItem": "anotherDateDataElementUid",
      "dateFilter": {
        "startBuffer": -5,
        "endBuffer": 5,
        "type": "RELATIVE"
      }
    },
    {
      "dataItem": "yetAnotherDateDataElementUid",
      "dateFilter": {
        "period": "LAST_WEEK",
        "type": "RELATIVE"
      }
    }],
    "programStatus": "ACTIVE"
  }
}
```


##### Retrieving and deleting event filters { #retrieving-and-deleting-event-filters } 

A specific event filter can be retrieved by using the following api

    GET /api/33/eventFilters/{uid}

All event filters can be retrieved by using the following api.

    GET /api/33/eventFilters?fields=*

All event filters for a specific program can be retrieved by using the following api

    GET /api/33/eventFilters?filter=program:eq:IpHINAT79UW

An event filter can be deleted by using the following api

    DELETE /api/33/eventFilters/{uid}

### Relationships { #relationships } 
Relationships are links between two entities in tracker. These entities can be tracked entity instances, enrollments and events.

There are multiple endpoints that allow you to see, create, delete and update relationships. The most common is the /api/trackedEntityInstances endpoint, where you can include relationships in the payload to create, update or deleting them if you omit them - Similar to how you work with enrollments and events in the same endpoint. All the tracker endpoints, /api/trackedEntityInstances, /api/enrollments and /api/events also list their relationships if requested in the field filter.

The standard endpoint for relationships is, however, /api/relationships. This endpoint provides all the normal CRUD operations for relationships.

List all relationships require you to provide the UID of the trackedEntityInstance, Enrollment or event that you want to list all the relationships for:  

    GET /api/relationships?tei=ABCDEF12345
    GET /api/relationships?enrollment=ABCDEF12345
    GET /api/relationships?event=ABCDEF12345

This request will return a list of any relationship you have access to see that includes the trackedEntityInstance, enrollment or event you specified. Each relationship is represented with the following JSON:

```json
{
  "relationshipType": "dDrh5UyCyvQ",
  "relationshipName": "Mother-Child",
  "relationship": "t0HIBrc65Rm",
  "bidirectional": false,
  "from": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "vOxUH373fy5"
    }
  },
  "to": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "pybd813kIWx"
    }
  },
  "created": "2019-04-26T09:30:56.267",
  "lastUpdated": "2019-04-26T09:30:56.267"
}
```

You can also view specified relationships using the following endpoint:

    GET /api/relationships/<id>

To create or update a relationship, you can use the following endpoints:

    POST /api/relationships
    PUT /api/relationships

And use the following payload structure:

```json
{
  "relationshipType": "dDrh5UyCyvQ",
  "from": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "vOxUH373fy5"
    }
  },
  "to": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "pybd813kIWx"
    }
  }
}
```

To delete a relationship, you can use this endpoint:

      DELETE /api/relationships/<id>

In our example payloads, we use a relationship between trackedEntityInstances. Because of this, the "from" and "to" properties of our payloads include "trackedEntityInstance" objects. If your relationship includes other entities, you can use the following properties:

```json
{
  "enrollment": {
    "enrollment": "<id>"
  }
}
```

```json
{
  "event": {
    "event": "<id>"
  }
}
```

### Update strategies { #webapi_tei_update_strategies }

Two update strategies for all 3 tracker endpoints are supported:
enrollment and event creation. This is useful when you have generated an
identifier on the client side and are not sure if it was created or not
on the server.



Table: Available tracker strategies

| Paramètre | Description |
|---|---|
| CRÉER | Create only, this is the default behavior. |
| CREATE_AND_UPDATE | Try and match the ID, if it exist then update, if not create. |

To change the parameter, please use the strategy parameter:

    POST /api/33/trackedEntityInstances?strategy=CREATE_AND_UPDATE

### Tracker bulk deletion { #webapi_tracker_bulk_deletion }

Bulk deletion of tracker objects work in a similar fashion to adding and
updating tracker objects, the only difference is that the
`importStrategy` is *DELETE*.

*Example: Bulk deletion of tracked entity instances:*

```json
{
  "trackedEntityInstances": [
    {
      "trackedEntityInstance": "ID1"
    }, {
      "trackedEntityInstance": "ID2"
    }, {
      "trackedEntityInstance": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/trackedEntityInstances?strategy=DELETE"
```

*Example: Bulk deletion of enrollments:*

```json
{
  "enrollments": [
    {
       "enrollment": "ID1"
    }, {
      "enrollment": "ID2"
    }, {
      "enrollment": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/enrollments?strategy=DELETE"
```

*Example: Bulk deletion of events:*

```json
{
  "events": [
    {
      "event": "ID1"
    }, {
      "event": "ID2"
    }, {
      "event": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/events?strategy=DELETE"
```

### Identifier reuse and item deletion via POST and PUT methods { #webapi_updating_and_deleting_items }

Tracker endpoints */trackedEntityInstances*, */enrollments*, */events*
support CRUD operations. The system keeps track of used identifiers.
Therefore, an item which has been created and then deleted (e.g. events,
enrollments) cannot be created or updated again. If attempting to delete
an already deleted item, the system returns a success response as
deletion of an already deleted item implies no change.

The system does not allow to delete an item via an update (*PUT*) or
create (*POST*) method. Therefore, an attribute *deleted* is ignored in
both *PUT* and *POST* methods, and in *POST* method it is by default set
to *false*.

### Import parameters { #webapi_import_parameters }

Le processus d'importation peut être personnalisé à l'aide d'un ensemble de paramètres d'importation :



Tableau : Paramètres d'importation

| Paramètre | Valeurs (par défaut en premier) | Description |
|---|---|---|
| dataElementIdScheme (Schéma de l'identifiant de l'élément de données) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'élément de données à utiliser pour faire correspondre les données. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'unité d'organisation à utiliser pour faire correspondre les données. |
| idScheme (schéma d'identifiants) | id &#124; name &#124; code&#124; attribute:ID | Property of all objects including data elements, org units and category option combos, to use to map the data values. |
| dryRun (essai) | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| strategy | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipNotifications | true &#124; false | Indicates whether to send notifications for completed events. |
| skipFirst | true &#124; false | Relevant for CSV import only. Indicates whether CSV file contains a header row which should be skipped. |
| importReportMode | FULL, ERRORS, DEBUG | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |

#### CSV Import / Export { #webapi_events_csv_import_export }

In addition to XML and JSON for event import/export, in DHIS2.17 we
introduced support for the CSV format. Support for this format builds on
what was described in the last section, so here we will only write about
what the CSV specific parts are.

To use the CSV format you must either use the `/api/events.csv`
endpoint, or add *content-type: text/csv* for import, and *accept:
text/csv* for export when using the `/api/events` endpoint.

The order of column in the CSV which are used for both export and import
is as follows:



Table: CSV column

| Index | Clé | Type | Description |
|---|---|---|---|
| 1 | événement | identifier | Identifier of event |
| 2 | statut | enum | Status of event, can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULED &#124; OVERDUE &#124; SKIPPED |
| 3 | de paludisme) ». | identifier | Identifiant du programme |
| 4 | Étape du programme | identifier | Identifiant de l'étape de programme |
| 5 | inscription | identifier | Identifier of enrollment (program instance) |
| 6 | orgUnit (Unité d'organisation) | identifier | Identifiant de l'unité d'organisation |
| 7 | eventDate | date | Date de l'événement |
| 8 | dueDate | date | Due Date |
| 9 | latitude | double | Latitude where event happened |
| 10 | longitude | double | Longitude where event happened |
| 11 | élément de données | identifier | Identifier of data element |
| 12 | valeur | string | Value / measure of event |
| 13 | Stocké par | string | Event was stored by (defaults to current user) |
| 14 | Fourni ailleurs | booléen | Was this value collected somewhere else |
| 14 | completedDate | date | Completed date of event |
| 14 | completedBy (terminé par) | string | Username of user who completed event |

*Example of 2 events with 2 different data value
    each:*

```csv
EJNxP3WreNP,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,1,,
EJNxP3WreNP,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,2,,
qPEdI1xn7k0,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,3,,
qPEdI1xn7k0,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,4,,
```

#### Import strategy: SYNC { #webapi_sync_import_strategy }

The import strategy SYNC should be used only by internal synchronization
task and not for regular import. The SYNC strategy allows all 3
operations: CREATE, UPDATE, DELETE to be present in the payload at the
same time.

### Tracker Ownership Management { #webapi_tracker_ownership_management }

A new concept called Tracker Ownership is introduced from 2.30. There
will now be one owner organisation unit for a tracked entity instance in
the context of a program. Programs that are configured with an access
level of *PROTECTED* or *CLOSED* will adhere to the ownership
privileges. Only those users belonging to the owning org unit for a
tracked entity-program combination will be able to access the data
related to that program for that tracked entity.

#### Tracker Ownership Override : Break the Glass { #webapi_tracker_ownership_override_api }

It is possible to temporarily override this ownership privilege for a
program that is configured with an access level of *PROTECTED*. Any user
will be able to temporarily gain access to the program related data, if
the user specifies a reason for accessing the tracked entity-program
data. This act of temporarily gaining access is termed as *breaking the
glass*. Currently, the temporary access is granted for 3 hours. DHIS2
audits breaking the glass along with the reason specified by the user.
It is not possible to gain temporary access to a program that has been
configured with an access level of *CLOSED*. To break the glass for a
tracked entity program combination, you can issue a POST request as
shown:

    /api/33/tracker/ownership/override?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&reason=patient+showed+up+for+emergency+care

#### Tracker Ownership Transfer { #webapi_tracker_ownership_transfer_api }

It is possible to transfer the ownership of a tracked entity-program
from one org unit to another. This will be useful in case of patient
referrals or migrations. Only an owner (or users who have broken the
glass) can transfer the ownership. To transfer ownership of a tracked
entity-program to another organisation unit, you can issue a PUT request
as shown:

    /api/33/tracker/ownership/transfer?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&ou=EJNxP3WreNP


## Potential Duplicates   { #potential-duplicates } 

Potential duplicates are records we work with in the data deduplication feature. Due to the nature of the deduplication feature, this API endpoint is somewhat restricted.

A potential duplicate represents a pair of records which are suspected to be a duplicate.

The payload of a potential duplicate looks like this:

```json
{
  "teiA": "<id>",
  "teiB": "<id>",
  "status": "OPEN|INVALID|MERGED"
}
```

You can retrieve a list of potential duplicates using the following endpoint:

    GET /api/potentialDuplicates

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| teis | List of tracked entity instances | List of string (separated by comma)| existing tracked entity instance id |
| statut | Potential duplicate status | string | `OPEN <default>`, `INVALID`, `MERGED`, `ALL` |

| Status code | Description
|---|---|
| 400 | Invalid input status

You can inspect individual potential duplicate records:

    GET /api/potentialDuplicates/<id>

| Status code | Description
|---|---|
| 404 | Potential duplicate not found

You can also filter potential duplicates by Tracked Entity Instance (referred as tei) :

    GET /api/potentialDuplicates/tei/<tei>

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| statut | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED`, `ALL <default>` |

| Status code | Description
|---|---|
| 400 | Invalid input status
| 403 | User do not have access to read tei
| 404 | Tei not found

To create a new potential duplicate, you can use this endpoint:

    POST /api/potentialDuplicates

The payload you provide must include both teiA and teiB

```json
{
  "teiA": "<id>",
  "teiB": "<id>"
}
```

| Status code | Description
|---|---|
| 400 | Input teiA or teiB is null or has invalid id
| 403 | User do not have access to read teiA or teiB
| 404 | Tei not found
| 409 | Pair of teiA and teiB already existing

To update a potential duplicate status:

    PUT /api/potentialDuplicates/<id>

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| statut | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED` |

| Status code | Description
|---|---|
| 400 | You can't update a potential duplicate to MERGED as this is possible only by a merging request
| 400 | You can't update a potential duplicate that is already in a MERGED status

## Flag Tracked Entity Instance as Potential Duplicate { #flag-tracked-entity-instance-as-potential-duplicate } 

To flag as potential duplicate a Tracked Entity Instance (referred as tei)

 `PUT /api/trackedEntityInstances/{tei}/potentialDuplicate`

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| flag | either flag or unflag a tei as potential duplicate | string | `true`, `false` |


| Status code | Description
|---|---|
| 400 | Invalid flag must be true of false
| 403 | User do not have access to update tei
| 404 | Tei not found

## Merging Tracked Entity Instances { #merging-tracked-entity-instances } 
Tracked entity instances can now be merged together if they are viable. To initiate a merge, the first step is to define two tracked entity instances as a Potential Duplicate. The merge endpoint
will move data from the duplicate tracked entity instance to the original tracked entity instance, and delete the remaining data of the duplicate.

To merge a Potential Duplicate, or the two tracked entity instances the Potential Duplicate represents, the following endpoint can be used:

    POST /potentialDuplicates/<id>/merge

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| mergeStrategy | Strategy to use for merging the potentialDuplicate | enum | AUTO(default) or MANUAL |

The endpoint accepts a single parameter, "mergeStrategy", which decides which strategy to use when merging. For the AUTO strategy, the server will attempt to merge the two tracked entities
automatically, without any input from the user. This strategy only allows merging tracked entities without conflicting data (See examples below). The other strategy, MANUAL, requires the
user to send in a payload describing how the merge should be done. For examples and rules for each strategy, see their respective sections below.

### Merge Strategy AUTO { #merge-strategy-auto } 
The automatic merge will evaluate the mergability of the two tracked entity instances, and merge them if they are deemed mergable. The mergability is based on whether the two tracked entity instances
has any conflicts or not. Conflicts refers to data which cannot be merged together automatically. Examples of possible conflicts are:
- The same attribute has different values in each tracked entity instance
- Both tracked entity instances are enrolled in the same program
- Tracked entity instances have different types

If any conflict is encountered, an errormessage is returned to the user.

When no conflicts are found, all data in the duplicate that is not already in the original will be moved over to the original. This includes attribute values, enrollments (Including events) and relationships.
After the merge completes, the duplicate is deleted and the potentialDuplicate is marked as MERGED.

When requesting an automatic merge like this, a payload is not required and will be ignored.

### Merge Strategy MANUAL { #merge-strategy-manual } 
The manual merge is suitable when the merge has resolvable conflicts, or when not all the data is required to be moved over during a merge. For example, if an attribute has different values in both tracked
entity instances, the user can specify whether to keep the original value, or move over the duplicate's value. Since the manual merge is the user explicitly requesting to move data, there are some different
checks being done here:
- Relationship cannot be between the original and the duplicate (This results in an invalid self-referencing relationship)
- Relationship cannot be of the same type and to the same object in both tracked entity instances (IE. between original and other, and duplicate and other; This would result in a duplicate relationship)

There are two ways to do a manual merge: With and without a payload.

When a manual merge is requested without a payload, we are telling the API to merge the two tracked entity instances without moving any data. In other words, we are just removing the duplicate and marking the
potentialDuplicate MERGED. This might be valid in a lot of cases where the tracked entity instance was just created, but not enrolled for example.

Otherwise, if a manual merge is requested with a payload, the payload refers to what data should be moved from the duplicate to the original. The payload looks like this:
```json
{
  "trackedEntityAttributes": ["B58KFJ45L9D"],
  "enrollments": ["F61SJ2DhINO"],
  "relationships": ["ETkkZVSNSVw"]
}
```

This payload contains three lists, one for each of the types of data that can be moved. `trackedEntityAttributes` is a list of uids for tracked entity attributes, `enrollments` is a list of uids for enrollments and `relationships`
a list of uids for relationships. The uids in this payload have to refer to data that actually exists on the duplicate. There is no way to add new data or change data using the merge endpoint - Only moving data.


### Additional information about merging { #additional-information-about-merging } 
Currently it is not possible to merge tracked entity instances that are enrolled in the same program, due to the added complexity. A workaround is to manually remove the enrollments from one of the tracked entity
instances before starting the merge.

All merging is based on data already persisted in the database, which means the current merging service is not validating that data again. This means if data was already invalid, it will not be reported during the merge.
The only validation done in the service relates to relationships, as mentioned in the previous section.



## Program Notification Template { #program-notification-template } 

Program Notification Template lets you create message templates which can be sent as a result of different type of events.
Message and Subject templates will be translated into actual values and can be sent to the configured destination. Each program notification template will be
transformed to either MessageConversation object or ProgramMessage object based on external or internal notificationRecipient. These intermediate objects will
only contain translated message and subject text.
There are multiple configuraiton parameters in Program Notification Tempalte which are critical for correct working of notifications.
All those are explained in the table below.

    POST /api/programNotificationTemplates

```json
{
    "name": "Case notification",
    "notificationTrigger": "ENROLLMENT",
    "subjectTemplate": "Case notification V{org_unit_name}",
    "displaySubjectTemplate": "Case notification V{org_unit_name}",
    "notifyUsersInHierarchyOnly": false,
    "sendRepeatable": false,
    "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
    "notifyParentOrganisationUnitOnly": false,
    "displayMessageTemplate": "Case notification A{h5FuguPFF2j}",
    "messageTemplate": "Case notification A{h5FuguPFF2j}",
    "deliveryChannels": [
        "EMAIL"
    ]
}
```

The fields are explained in the following table.


Table: Program Notification Template payload

| Champ | Obligatoire | Description | Valeurs |
|---|---|---|---|
| nom | Oui | name of Program Notification Tempalte | case-notification-alert |
| notificationTrigger | Oui | When notification should be triggered. Possible values are ENROLLMENT, COMPLETION, PROGRAM_RULE, SCHEDULED_DAYS_DUE_DATE| INSCRIPTION |
| subjectTemplate | Non | Subject template string | Case notification V{org_unit_name} |
| messageTemplate | Oui | Message template string | Case notification A{h5FuguPFF2j} |
| notificationRecipient | OUI | Who is going to receive notification. Possible values are USER_GROUP, ORGANISATION_UNIT_CONTACT, TRACKED_ENTITY_INSTANCE, USERS_AT_ORGANISATION_UNIT, DATA_ELEMENT, PROGRAM_ATTRIBUTE, WEB_HOOK  | USER_GROUP |
| deliveryChannels | Non | Which channel should be used for this notification. It can be either SMS, EMAIL or HTTP | SMS |
| sendRepeatable | Non | Whether notification should be sent multiple times | faux |

NOTE: WEB_HOOK notificationRecipient is used only to POST http request to an external system. Make sure to choose HTTP delivery channel when using WEB_HOOK.

### Retrieving and deleting Program Notification Template { #retrieving-and-deleting-program-notification-template } 

The list of Program Notification Templates can be retrieved using GET.

    GET /api/programNotificationTemplates

For one particular Program Notification Template.

    GET /api/33/programNotificationTemplates/{uid}

To get filtered list of Program Notification Templates

    GET /api/programNotificationTemplates/filter?program=<uid>
    GET /api/programNotificationTemplates/filter?programStage=<uid>

Program Notification Template can be deleted using DELETE.

    DELETE /api/33/programNotificationTemplates/{uid}


## Program Messages { #program-messages } 

Program message lets you send messages to tracked entity instances,
contact addresses associated with organisation units, phone numbers and
email addresses. You can send messages through the `messages` resource.

    /api/33/messages

### Sending program messages { #sending-program-messages } 

Program messages can be sent using two delivery channels:

  - SMS (SMS)

  - Email address (EMAIL)

Program messages can be sent to various recipients:

  - Tracked entity instance: The system will look up attributes of value
    type PHONE_NUMBER or EMAIL (depending on the specified delivery
    channels) and use the corresponding attribute values.

  - Organisation unit: The system will use the phone number or email
    information registered for the organisation unit.

  - List of phone numbers: The system will use the explicitly defined
    phone numbers.

  - List of email addresses: The system will use the explicitly defined
    email addresses.

Below is a sample JSON payload for sending messages using POST requests.
Note that message resource accepts a wrapper object named
`programMessages` which can contain any number of program messages.

    POST /api/33/messages

```json
{
  "programMessages": [{
    "recipients": {
      "trackedEntityInstance": {
        "id": "UN810PwyVYO"
      },
      "organisationUnit": {
        "id": "Rp268JB6Ne4"
      },
      "phoneNumbers": [
        "55512345",
        "55545678"
      ],
      "emailAddresses": [
        "johndoe@mail.com",
        "markdoe@mail.com"
      ]
    },
    "programInstance": {
      "id": "f3rg8gFag8j"
    },
    "programStageInstance": {
      "id": "pSllsjpfLH2"
    },
    "deliveryChannels": [
      "SMS", "EMAIL"
    ],
    "notificationTemplate": "Zp268JB6Ne5",
    "subject": "Outbreak alert",
    "text": "An outbreak has been detected",
    "storeCopy": false
  }]
}
```

The fields are explained in the following table.



Table: Program message payload

| Champ | Obligatoire | Description | Valeurs |
|---|---|---|---|
| recipients | Oui | Recipients of the program message. At least one recipient must be specified. Any number of recipients / types can be specified for a message. | Can be trackedEntityInstance, organisationUnit, an array of phoneNumbers or an array of emailAddresses. |
| programInstance | Either this or programStageInstance required | The program instance / enrollment. | Enrollment ID. |
| programStageInstance | Either this or programInstance required | The program stage instance / event. | Event ID. |
| deliveryChannels | Oui | Array of delivery channels. | SMS &#124; EMAIL |
| subject | Non | The message subject. Not applicable for SMS delivery channel. | Text. |
| texte | Oui | The message text. | Text. |
| storeCopy | Non | Whether to store a copy of the program message in DHIS2. | false (default) &#124; true |

A minimalistic example for sending a message over SMS to a tracked
entity instance looks like this:

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messages"
  -H "Content-Type:application/json" -u admin:district
```

```json
{
  "programMessages": [{
    "recipients": {
      "trackedEntityInstance": {
        "id": "PQfMcpmXeFE"
      }
    },
    "programInstance": {
      "id": "JMgRZyeLWOo"
    },
    "deliveryChannels": [
      "SMS"
    ],
    "text": "Please make a visit on Thursday"
  }]
}
```

### Retrieving and deleting program messages { #retrieving-and-deleting-program-messages } 

The list of messages can be retrieved using GET.

    GET /api/33/messages

To get the list of sent tracker messages, the below endpoint can be used. ProgramInstance or ProgramStageInstance uid has to be provided.

    GET /api/33/messages/scheduled/sent?programInstance={uid}
    GET /api/33/messages/scheduled/sent?programStageInstance={uid}

To get the list of all scheduled message

    GET /api/33/messages/scheduled
    GET /api/33/messages/scheduled?scheduledAt=2020-12-12

One particular message can also be retrieved using GET.

    GET /api/33/messages/{uid}

Message can be deleted using DELETE.

    DELETE /api/33/messages/{uid}


### Querying program messages { #querying-program-messages } 

The program message API supports program message queries based on
request parameters. Messages can be filtered based on below mentioned
query parameters. All requests should use the GET HTTP verb for
retrieving information.



Table: Query program messages API

| Paramètre | URL |
|---|---|
| programInstance | /api/33/messages?programInstance=6yWDMa0LP7 |
| programStageInstance | /api/33/messages?programStageInstance=SllsjpfLH2 |
| trackedEntityInstance | /api/33/messages?trackedEntityInstance=xdfejpfLH2 |
| organisationUnit | /api/33/messages?ou=Sllsjdhoe3 |
| processedDate | /api/33/messages?processedDate=2016-02-01 |


# New Tracker { #new-tracker } 

Version 2.36 of DHIS2 introduced a set of new tracker endpoints dedicated to importing and querying tracker objects (Including tracked entities, enrollments, events, and relationships).
These new endpoints set a discontinuity with earlier implementations. Re-engineering the endpoints allowed developers to improve, redesign, and formalize the API's behavior to improve the Tracker services.

The newly introduced endpoints consist of:

* `POST /api/tracker`
* `GET /api/tracker/enrollments`
* `GET /api/tracker/events`
* `GET /api/tracker/trackedEntities`
* `GET /api/tracker/relationships`

> **NOTE**
>
> - The old endpoints are marked as deprecated but still work as before.
> - Some functionality is not yet ready in the new endpoints, but they support their primary use-cases.

## Changes in the API { #changes-in-the-api } 

Property names used in the API have changed to use consistent naming across all the new endpoints.

### Tracker Import changelog (`POST`) { #tracker-import-changelog-post } 

The following table highlights the differences between the previous tracker import endpoints (/api/trackedEntityInstance, /api/enrollments, /api/events and /api/relatiosnhips) and the new endpoint (/api/tracker). All endpoints are still currently available.

|Tracker Object|Previously|Now|
|---|---|---|
|**Attribute**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**DataValue**|`created`<br>`lastUpdated`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`|`createdAt`<br>`updatedAt`<br>`createdBy`<br>`updatedBy`|
|**Enrollment**|`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`trackedEntityInstance`<br>`enrollmentDate`<br>`incidentDate`<br>`completedDate`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`|`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`trackedEntity`<br>`enrolledAt`<br>`occurredAt`<br>`completedAt`<br>`createdBy`<br>`updatedBy`|
|**Manifestation**|`trackedEntityInstance`<br>`eventDate`<br>`dueDate`<br>`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`completedDate`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`<br>`assignedUser`*|`trackedEntity`<br>`occurredAt`<br>`scheduledAt`<br>`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`completedAt`<br>`createdBy`<br>`updatedBy`<br>`assignedUser`*|
|**Remarque**|`storedDate`<br>`lastUpdatedBy`|`storedAt`<br>`createdBy`|
|**ProgramOwner**|`ownerOrgUnit`<br>`trackedEntityInstance`|`orgUnit`<br>`trackedEntity`|
|**RelationshipItem**|`trackedEntityInstance.trackedEntityInstance`<br>`enrollment.enrollment`<br>`event.event`|`trackedEntity`<br>`enrollment`<br>`event`|
|**Relationship**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**TrackedEntity**|`trackedEntityInstance`<br>`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`createByUserInfo`<br>`lastUpdatedByUserInfo`|`trackedEntity`<br>`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`createdBy`<br>`updatedBy`|

> **Note**
>
>Field `assignedUser` was a String before, now it is of type User:
>```json
>{
>   "assignedUser": {
>     "uid": "ABCDEF12345",
>     "username": "username",
>     "firstName": "John",
>     "surname": "Doe"
>   }
>}
>```

### Tracker Export changelog (`GET`) { #tracker-export-changelog-get } 

The `GET` endpoints all conform to the same naming conventions reported in the previous paragraph. Additionally, we made some changes regarding the request parameters to respect the same naming conventions here as well.

These tables highlight the old endpoint differences in request parameters for `GET` endpoints compared to the new

#### Request parameter changes for `GET /api/tracker/enrollments` { #request-parameter-changes-for-get-apitrackerenrollments } 
|Previously|Now|
|---|---|
|`ou`|`orgUnit` (unité d'organisation)|
|`lastUpdated`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedWithin`|
|`programStartDate`<br>`programEndDate`|`enrolledAfter`<br>`enrolledBefore`|
|`trackedEntityInstance`|`trackedEntity` (entité suivie)|

#### Request parameter changes for `GET /api/tracker/events` { #request-parameter-changes-for-get-apitrackerevents } 
|Previously|Now|
|---|---|
|`trackedEntityInstance`|`trackedEntity` (entité suivie)|
|`startDate`<br>`endDate`|`occurredAfter`<br>`occurredBefore`|
|`dueDateStart`<br>`dueDateEnd`|`scheduledAfter`<br>`scheduledBefore`|
|`dernière mise à jour`|Removed - obsolete, see: <br><ul><li>`updatedAfter`</li><li>`updatedBefore`</li></ul>|
|`lastUpdatedStartDate`<br>`lastUpdateEndDate`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedBefore`<br>`updatedWithin`|

#### Request parameter changes for `GET /api/tracker/trackedEntities` { #request-parameter-changes-for-get-apitrackertrackedentities } 
|Previously|Now|
|---|---|
|`trackedEntityInstance`|`trackedEntity` (entité suivie)|
|`ou`|`orgUnit` (unité d'organisation)|
|`programStartDate`<br>`programEndDate`|Removed - obsolete, see <br><ul><li>`enrollmentEnrolledAfter`</li><li>`enrollmentEnrolledBefore`</li></ul>|
|`programEnrollmentStartDate`<br>`programEnrollmentEndDate`|`enrollmentEnrolledAfter`<br>`enrollmentEnrolledBefore`|
|`programIncidentStartDate`<br>`programIncidentEndDate`|`enrollmentOccurredAfter`<br>`enrollmentOccurredBefore`|
|`eventStartDate`<br>`eventEndDate`|`eventOccurredAfter`<br>`eventOccurredBefore`|
|`lastUpdatedStartDate`<br>`lastUpdateEndDate`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedBefore`<br>`updatedWithin`|


## Objets Tracker { #webapi_nti_tracker_objects }

Tracker est constitué de différents types d'objets interconnectés destinés à représenter les données. Dans cette section, nous montrerons et décrirons chacun des objets utilisés dans l'API du Tracker.

### Entité suivie { #tracked-entity }

Les `entités suivies` constituent la base du modèle Tracker.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| Entité suivie | L’identifiant de l’entité suivie. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| TrackedEntityType (Type d'entité suivie) | Le type d’entité suivie. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| créé à | Date à laquelle l'utilisateur a créé l'entité suivie. Elle est définie sur le serveur. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| crééAtClient (Création au niveau du client) | Date à laquelle l'utilisateur a créé l'entité suivie au niveau du client. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de l'objet. Elle est définie sur le serveur. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAtClient (mise à jour au niveau du client) | Date de la dernière mise à jour de l'objet au niveau du client. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| orgUnit (Unité d'organisation) | L'unité d'organisation dans laquelle l'utilisateur a créé l'entité suivie. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| inactif | Indique si l'entité suivie est inactive ou non. | Non | Oui | Booléen | Par défaut : Faux, Vrai |
| supprimé | Indique si l'entité suivie a été supprimée. Ne peut être modifié qu'au moment de la suppression. | Non | Non | Booléen | Faux jusqu'à suppression |
| géométrie | Il s'agit d'une représentation géographique de l'entité suivie. Elle est basée sur le « type de fonctionnalité » du type d'entité suivie. | Non | Oui | GeoJson | {<br>"type": "POINT",<br>"coordonnées": [123.0, 123.0]<br>} |
| Stocké par | Référence client indiquant celui a stocké/créé l’entité suivie. | Non | Oui | Chaîne : Toute | John Doe |
| createdBy (créé par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a créé l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| updatedBy (mis à jour par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a mis à jour l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| les attributs | Une liste de valeurs d'attributs d'entité suivie appartenant à l'entité suivie. | Non | Oui | Liste des valeurs d'attributs d'entités suivies | Voir l'attribut |
| inscriptions | Une liste des inscriptions appartenant à l’entité suivie. | Non | Oui | Liste des inscriptions | Voir les inscriptions |
| relations | Une liste de relations connectées à l'entité suivie. | Non | Oui | Liste des relations | Voir les relations |
| Propriétaires du programme | Liste des unités d'organisation qui ont accès via des programmes spécifiques à cette entité suivie. Voir « Propriété du programme » pour en savoir plus. | Non | Oui | Liste des propriétaires du programme | Voir la section « Propriété du programme » |

> **Remarque**
>
> Les `entités suivies` "possèdent" toutes les `Valeurs d'attribut d'entités suivies` (ou les "attributs" décrits dans le tableau précédent). Cependant, les `attributs d'entités suivies` sont soit connectés à une `entité suivie` via son `type d'entité suivie` soit à un `programme`. Nous désignons souvent cette séparation par `Attributs de type d'entité suivi` et `Attributs de programme d'entité suivi`. L'importance de cette distinction est liée au contrôle d'accès et à la limitation des informations que l'utilisateur peut voir.
>
> Les "attributs" mentionnés dans `Entité suivie` sont des `Attributs de type d'entité suivie`.


### Inscription { #enrollment } 
Les `Entités suivies` peuvent s'inscrire aux `Programmes` pour lesquels elles sont éligibles. Les entités suivies sont éligibles tant que le programme est configuré avec le même `Type d'entité suivie` que l'entité suivie. Nous représentons l'inscription avec l'objet `Inscription`, que nous décrivons dans cette section.


| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| inscription | L’identifiant de l'inscription. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| de paludisme) ». | Le programme que représente l’inscription. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| Entité suivie | Une référence à l’entité suivie inscrite. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| TrackedEntityType (Type d'entité suivie) | Uniquement pour lire les données. Il s'agit du type de l'entité suivie inscrite | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| statut | Statut de l'inscription. Il est ACTIF au cas où n'est pas fourni. | Non | Non | Énumération | ACTIF, TERMINÉ, ANNULÉ |
| orgUnit (Unité d'organisation) | L'unité d'organisation dans laquelle l'utilisateur a inscrit l'entité suivie. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| orgUnitName (nom de l'unité d'organisation) | Uniquement pour lire les données. Il s'agit du nom de l'unité d'organisation où l'inscription a eu lieu. | Non | Non | Chaîne : Toute | Sierra Leone |
| créé à | Date à laquelle l'utilisateur a créé l'objet. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| crééAtClient (Création au niveau du client) | Date à laquelle l'utilisateur a créé l'objet au nibveau du client | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de l'objet. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAtClient (mise à jour au niveau du client) | Date de la dernière mise à jour de l'objet au niveau du client. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| enrolledAt (inscrit à) | Date à laquelle l'utilisateur a inscrit l'entité suivie. | Oui | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| occurredAt (s'est produit à) | Date à laquelle l'inscription a eu lieu. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedAt (terminé à) | Date à laquelle l'utilisateur a terminé l'inscription. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedBy (terminé par) | Fait référence à la personne qui a effectué l'inscription | Non | Non | Chaîne : Toute | John Doe |
| Suivi | Indique si l'inscription nécessite un suivi. La valeur est "Faux" si rien n'est fourni | Non | Non | Booléen | Par défaut : Faux, Vrai |
| supprimé | Indique si l'inscription a été supprimée. Ne peut être modifié qu'au moment de la suppression. | Non | Oui | Booléen | Faux jusqu'à suppression |
| géométrie | Il s'agit d'une représentation géographique de l'inscription. Elle se base sur le « type de fonctionnalité » du programme. | Non | Non | GeoJson | {<br>"type": "POINT",<br>"coordonnées": [123.0, 123.0]<br>} |
| Stocké par | Référence client indiquant celui a stocké/créé l'inscription. | Non | Non | Chaîne : Toute | John Doe |
| createdBy (créé par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a créé l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| updatedBy (mis à jour par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a mis à jour l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| les attributs | Une liste de valeurs d'attributs d'entité suivie associées à l'inscription. | Non | Non | Liste des valeurs d'attributs d'entités suivies | Voir l'attribut |
| événements | Une liste des événements appartenant à l'inscription. | Non | Non | Liste des événements | Voir les évènements |
| relations | Une liste des relations liées à l'inscription. | Non | Non | Liste des relations | Voir les relations |
| notes | Notes liées à l'inscription. Elles ne peuvent qu'être créées. | Non | Oui | Liste des notes | Voir les notes |

> **Remarque**
>
> Les `entités suivies` "possèdent" toutes les `Valeurs d'attribut d'entités suivies` (ou les "attributs" décrits dans le tableau précédent). Cependant, les `attributs d'entités suivies` sont soit connectés à une `entité suivie` via son `type d'entité suivie` soit à un `programme`. Nous désignons souvent cette séparation par `Attributs de type d'entité suivi` et `Attributs de programme d'entité suivi`. L'importance de cette distinction est liée au contrôle d'accès et à la limitation des informations que l'utilisateur peut voir.
>
> Les "attributs" mentionnés dans `Inscription` sont des `Attributs de programmes d'entités suivies`.


### Événements { #events } 
Les `Événements` font partie d'un `PROGRAMME D'ÉVÉNEMENT` ou d'un `PROGRAMME TRACKER`. Pour le `PROGRAMME TRACKER`, les événements appartiennent à une `Inscription`, laquelle appartient à une `Entité suivie`. D'un autre côté, `PROGRAMME D'ÉVÉNEMENT` concerne les `Événements` non rattachées à une `Inscription` ou à une `Entité suivie` spécifique. La différence réside dans le fait que nous effectuons ou non un suivi pour une `Entité suivie` spécifique. Nous désignons parfois les événements `PROGRAMME D'ÉVÉNEMENT` "événements anonymes "ou "événements uniques" puisqu'ils ne se représentent qu'eux-mêmes et non une autre `Entité suivie`.

Dans l'API, la différence majeure est que tous les événements sont soit rattachés à la même inscription (`PROGRAMME D'ÉVÈNEMENT`), soit à des inscriptions différentes (`PROGRAMME TRACKER`). Le tableau ci-dessous signalera les cas exceptionnels entre ces deux.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| événement | L'identifiant de l'événement. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| Étape du programme | L'étape du programme que représente l'événement. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| inscription | Il s'agit d'une référence à l’inscription qui à laquelle appartient l’événement. Ceci ***ne s'applique pas au `PROGRAMME D'ÉVÉNEMENT`*** | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| de paludisme) ». | Uniquement pour lire les données. Il s'agit du type de programme de l'inscription qui possède l'événement. | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| Entité suivie | Uniquement pour lire les données. Il s'agit de l'entité suivie propriétaire de l'événement. Ceci ***ne s'applique pas au `PROGRAMME D'ÉVÉNEMENT`*** | Non | Non | Chaîne : Uid | ABCDEF12345 |
| statut | Statut de l'évènement. Il est ACTIF au cas où n'est pas fourni. | Non | Non | Énumération | ACTIF, EFFECTUÉ, VISITÉ, HORAIRE, EN RETARD, SAUTÉ |
| Statut de l'inscription | Uniquement pour lire les données. Il s'agit du statut de l'inscription propriétaire de l'événement. Ceci ***ne s'applique pas au `PROGRAMME D'ÉVÉNEMENT`*** | Non | Non | Énumération | ACTIF, TERMINÉ, ANNULÉ |
| orgUnit (Unité d'organisation) | Il s'agit de l'unité d'organisation dans laquelle l'utilisateur a enregistré l'événement. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| orgUnitName (nom de l'unité d'organisation) | Uniquement pour lire les données. Il s'agit du nom de l'unité d'organisation où l'utilisateur a enregistré l'évènement. | Non | Non | Chaîne : Toute | Sierra Leone |
| créé à | Date à laquelle l'utilisateur a créé l'évènement. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| crééAtClient (Création au niveau du client) | Date à laquelle l'utilisateur a créé l'évènement au niveau du client | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de l'évènement. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAtClient (mise à jour au niveau du client) | Date de la dernière mise à jour de l'évènement au niveau du client. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| scheduledAt (programmé à) | Date à laquelle l'évènement a été programmée. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| occurredAt (s'est produit à) | Date à laquelle quelque chose se passe. | Oui | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedAt (terminé à) | Date à laquelle l'utilisateur a effectué l'évènement. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedBy (terminé par) | Fait référence à la personne qui a effectué l'évènement | Non | Non | Chaîne : Toute | John Doe |
| Suivi | Indique si l'événement a été marqué pour un suivi. Faux si non fourni | Non | Non | Booléen | Par défaut : Faux, Vrai |
| supprimé | Indique si l'évènement a été supprimée. Ne peut être modifié qu'au moment de la suppression. | Non | Oui | Booléen | Faux jusqu'à suppression |
| géométrie | Il s'agit d'une représentation géographique de l'évènement. Elle se base sur le « type de fonctionnalité » de l'étape de programme. | Non | Non | GeoJson | {<br>"type": "POINT",<br>"coordonnées": [123.0, 123.0]<br>} |
| Stocké par | Référence client indiquant celui a stocké/créé l'évènement. | Non | Non | Chaîne : Toute | John Doe |
| createdBy (créé par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a créé l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| updatedBy (mis à jour par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a mis à jour l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| attributeOptionCombo (combinaison d'options d'attribut) | Combinaison d'options d'attribut pour l'événement. Utiliser l'option par défaut s’il n’est pas fourni ou configuré. | Non | Non | Chaîne : Uid | ABCDEF12345
| attributeCategoryOptions (options de catégorie d'attribut) | Il s'agit de l'option de catégorie d'attribut pour l'événement. Utiliser l'option par défaut si rien n’est fourni ou configuré. | Non | Non | Chaîne : Uid | ABCDEF12345
| assignedUser (Utilisateur assigné) | Fait référence à un utilisateur qui a été assigné à l'événement. | Non | Non | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| dataValues (Valeurs de données) | Liste des valeurs de données liées à l'événement. | Non | Non | Liste des valeurs d'attributs d'entités suivies | Voir l'attribut |
| relations | Liste des relations liées à l'évènement. | Non | Non | Liste des relations | Voir les relations |
| notes | Notes liées à l'évènement. Elles ne peuvent qu'être créées. | Non | Oui | Liste des notes | Voir les notes |

### Relation { #relationship }

Les `Relations` sont des objets qui relient deux autres objets Tracker. Les contraintes auxquelles chaque côté de la relation doit se conformer sont basées sur le `Type de relation` de la `Relation`.


| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| relation | L'identifiant de la relation. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| type de relation | Il s'agit du type de relation. Il détermine quels objets peuvent être reliés dans une relation. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| Nom de la relation | Uniquement pour lire les données. Il s'agit du nom du type de relation de cette relation | Non | Non | Chaîne : Toute | Sibling |
| créé à | Date à laquelle l'utilisateur a créé la relation. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de la relation. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| bidirectionnel | Uniquement pour lire les données. Indique si le type de relation est bidirectionnel ou non. | Non | Non | Booléen | Vrai ou faux |
| de, à | Fait référence à chaque côté de la relation. Doit être conforme aux contraintes définies dans le type de relation | Oui | Oui | Élément de la relation | {"trackedEntity": {"trackedEntity": "ABCEF12345"}}, {"enrollment": {"enrollment": "ABCDEF12345"}} or {"event": {"event": "ABCDEF12345" }} |

> **Remarque**
>
>Un `Élément de relation` représente un lien vers un objet. Étant donné qu'il peut y avoir une `relation` entre n'importe quel objet Tracker tel qu'une `entité suivie`, une `inscription` et un `évènement`, la valeur dépend du `type de relation`. Par exemple, si le `type de relation` relie un `événement` et une `entité suivie`, le format est strict :
>```json
>{
> "de": {
> "événement": { "événement": "ABCDEF12345" }
> },
> "à": {
> "trackedEntity": { "trackedEntity": "FEDCBA12345" }
> }
>}
>```

### Attribut { #attribute } 
Les `Attributs` sont les valeurs qui décrivent les `entités suivies`. Ils peuvent être reliés via un `type d'entité suivi` ou un `programme`. Implicitement, cela signifie que les `attributs` peuvent faire partie à la fois d'une `entité suivie` et d'une `inscription`.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| attribut | Fait référence à l’attribut d’entité suivi représenté. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| code | Uniquement pour lire les données. Il s'agit du code de l'attribut de l'entité suivie | Non | Non | Chaîne : Toute | ABC |
| Nom d'affichage | Uniquement pour lire les données. Il s'agit du nom d'affichage de l'attribut de l'entité suivie | Non | Non | Chaîne : Toute | Nom |
| créé à | Date à laquelle la valeur a été ajoutée. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de la valeur. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| Stocké par | Référence client indiquant celui a stocké/créé la valeur. | Non | Non | Chaîne : Toute | John Doe |
| Type de valeur | Uniquement pour lire les données. Il s'agit du type de valeur que l'attribut représente. | Non | Non | Énumération | TEXTE, ENTIER et plus |
| valeur | La valeur de l'attribut d'entité suivi. | Non | Non | Chaîne : Toute | John Doe |

> **Remarque**
>
> Pour les `attributs`, seules les propriétés "attribut" et "valeur" sont requises lors de l'ajout des données. Une "valeur" peut être nulle, ce qui suppose que l'utilisateur doit la supprimer.
>
> Dans le contexte des objets Tracker, nous considérons les `Attributs d'entité suivie` et les `Valeurs d'attribut d'entité suivie` comme des "attributs". Cependant, les attributs sont également des éléments distincts, liés aux métadonnées. Il est donc essentiel de séparer les attributs Tracker et les attributs de métadonnées. Dans l'API du Tracker, il est possible de référencer les attributs des métadonnées lors de la spécification du `Schéma d'identification` (voir les paramètres de requête pour plus d'informations).

### Valeurs de données { #data-values }
Alors que les `Attributs` décrivent une `entité suivie` ou une `inscription`, les `valeurs de données` décrivent un `évènement`. La différence majeure est que les `attributs ` ne peuvent avoir qu'une seule valeur pour une `entité suivie` donnée. En revanche, les `valeurs de données` peuvent avoir plusieurs valeurs différentes selon les `événements` - même si les `événements` appartiennent tous à la même `inscription` ou à la même `entité suivie`.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| élément de données | L'élément de données que cette valeur représente. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| valeur | La valeur de la valeur des données. | Non | Non | Chaîne : Toute | 123 |
| Fourni ailleurs | Indique si l'utilisateur a fourni la valeur ailleurs ou non. Faux si la valeur n'a pas été fournie. | Non | Non | Booléen | Faux ou vrai |
| créé à | Date à laquelle l'utilisateur a ajouté la valeur. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de la valeur. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| Stocké par | Référence client indiquant celui a stocké/créé la valeur. | Non | Non | Chaîne : Toute | John Doe |
| createdBy (créé par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a créé l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |
| updatedBy (mis à jour par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a mis à jour l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |


> **Remarque**
>
> Pour les `éléments de données`, seules les propriétés "élément de données" et "valeur" sont requises lors de l'ajout des données. Une "valeur" peut être nulle, et dans ce cas l'utilisateur doit la supprimer.

### Notes Tracker { #tracker-notes }

Le Tracker de DHIS2 permet de recueillir des données à l'aide d'éléments de données et d'attributs d'entités suivies. Cependant, il est parfois nécessaire d'enregistrer des informations supplémentaires ou des commentaires sur le sujet en question. Ces informations supplémentaires peuvent être saisies à l'aide de notes Tracker. Les notes Tracker correspondent aux commentaires sur les valeurs de données dans DHIS2 Agrégé.

Il existe deux types de notes Tracker : les notes enregistrées au niveau de l'événement et celles enregistrées au niveau de l'inscription. Une inscription peut comporter un ou plusieurs événements. Des commentaires sur chaque événement - par exemple, pourquoi un événement a été manqué, reprogrammé, ou pourquoi seuls quelques éléments de données ont été renseignés et ainsi de suite - peuvent être documentés à l'aide de notes d'événements. Chaque événement d'une inscription peut avoir son propre récit ou ses propres notes. Il est alors possible d'enregistrer, par exemple, une observation générale de ces événements à l'aide de la note d'inscription racine. Les notes d'inscription permettent également de documenter, par exemple, les raisons pour lesquelles une inscription est annulée. C'est à l'utilisateur de faire preuve d'imagination et de déterminer quand et comment utiliser les notes.

L'inscription et l'événement peuvent avoir autant de notes que nécessaire - il n'y a pas de limite. Toutefois, ces notes ne peuvent ni être supprimées ni être mises à jour. Elles servent en quelque sorte de journal de bord. Pour modifier une note, il faut en créer une autre. La seule façon de supprimer une note est de supprimer l'objet racine, à savoir l'événement ou l'inscription. 

Les notes Tracker n'ont pas de point d'extrémité qui leur soit dédié. Elles sont échangées dans le cadre de la charge utile de l'événement racine et/ou de l'inscription. Vous trouverez ci-dessous un exemple de charge utile.

```json
{
  "trackedEntityInstance": "oi3PMIGYJH8",
  <entity_details>,
  ],
  "enrollments": [
    {
      "enrollment": "EbRsJr8LSSO",
      <enrollment_details>
      "notes": [
        {
          "note": "vxmCvYcPdaW",
          "value": "Enrollment note 2.",
        },
        {
          "value": "Enrollment note 1",
        }
      ],

      "events": [
        {
          "event": "zfzS9WeO0uM",
          <event_details>,
          "notes": [
            {
              "note": "MAQFb7fAggS",
              "value": "Event Note 1.",
            },
            {
              "value": "Event Note 2.",
            }
          ],
        },
        {
          ...
        }
      ]
    }
  ]
}
```


| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| note | La référence de la note. Elle est générée si rien n'est fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| valeur | Le contenu de la note. | Oui | Oui | Chaîne : Toute | Ceci est une note |
| Stocké à | Date à laquelle l'utilisateur a ajouté la note. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| Stocké par | Référence client indiquant celui a stocké/créé la note. | Non | Non | Chaîne : Toute | John Doe |
| createdBy (créé par) | Uniquement pour lire des données. Il s'agit de l'utilisateur qui a créé l'objet. Défini sur le serveur | Non | Oui | Utilisateur | {<br>"uid": "ABCDEF12345",<br>"Nom d'utilisateur": "Nom d'utilisateur",<br>"Prénom": "John",<br>"Nom de famille": "Doe"<br>} |

### Utilisateur { #user } 

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| uid | L'identifiant de l'utilisateur. | Oui* | Oui | Chaîne : Uid | ABCDEF12345 |
| Nom d'utilisateur | Le nom d'utilisateur utilisé par l'utilisateur. | Oui* | Oui | Chaîne : Toute | 123 |
| Prénom | Uniquement pour lire les données. Il s'agit du prénom de l'utilisateur. | Non | Oui | Chaîne : Toute | John |
| Nom de famille | Uniquement pour lire les données. Il s'agit du nom de famille de l'utilisateur. | Non | Oui | Chaîne : Toute | Doe |

> L'`uid` ou le `nom d'utilisateur` doit être fourni. Si les deux sont fournis, seul le nom d’utilisateur est pris en compte.


## Importation Tracker (`POST /api/tracker`) { #webapi_nti_import }

Le point d'extrémité `POST /api/tracker` permet aux clients d'importer les objets Tracker suivants dans DHIS2 :

* **Entités suivies**
* **Inscriptions**
* **Événements**
* **Relations**
* Données intégrées dans d'autres [objets Tracker](#webapi_nti_tracker_objects)

Les principaux changements à noter par rapport aux autres points d'extrémité dédiés à l'importation Tracker sont :

1. La charge utile d'importation peut être ***imbriquée*** ou ***plate***
2. L'appel peut être ***synchrone*** ou ***asynchrone***
3. Importation de la charge utile des événements ***CSV***

### Paramètres de requête { #request-parameters }

Actuellement, le point d'extrémité de l'importation Tracker prend en charge les paramètres suivants :

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| async | Indique si l’importation doit avoir lieu de manière asynchrone ou synchrone. | Booléen | `VRAI`, `FAUX` |
| Mode de rapport | Uniquement lors d'une importation synchrone. Voir le "Récapitulatif de l'importation" pour plus d’informations. | Énumération | `COMPLET`, `ERREURS`, `AVERTISSEMENTS` |
| Mode d'importation  | Indicates the mode of import. Can either be validation only or commit (Default) | Énumération | `VALIDATION`, `COMMIT` |
| idScheme (schéma d'identifiants) | Indique le 'schéma d'identification' global à utiliser pour les références de métadonnées lors de l'importation. La valeur par défaut est UID. Elle peut être remplacée pour des métadonnées spécifiques (voir la liste ci-dessous). | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| dataElementIdScheme (Schéma de l'identifiant de l'élément de données) | Indique le schéma d'identification à utiliser pour les éléments de données lors de l'importation. | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Indique le schéma d'identification à utiliser pour les unités d'organisation lors de l'importation. | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| programIdScheme (Schéma d'identification du programme) | Indique le schéma d'identification à utiliser pour les programmes lors de l'importation. | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| programmeStageIdScheme (Schéma d'identification de l'étape de programme) | Indique le schéma d'identification à utiliser pour les étapes de programme lors de l'importation. | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Indique le schéma d'identification à utiliser pour les combinaisons d'options de catégorie lors de l'importation. | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| categoryOptionIdScheme (Schéma de l'identifiant d'option de catégorie) | Indique le schéma d'identification à utiliser pour les options de catégorie lors de l'importation. | Énumération | `UID`, `CODE`, `NOM`, `ATTRIBUT` |
| importStrategy (stratégie d'importation) | Indique l'effet que l'importation doit avoir. Les différentes possibilités sont `CRÉER`, `METTRE À JOUR`, `CRÉER_ET_METTRE À JOUR` et `SUPPRIMER`. Respectivement, elles permettent d'importer de nouvelles données, d'importer des modifications à des données existantes, d'importer de nouvelles données ou des mises à jour à des données existantes et, enfin, de supprimer des données. | Énumération | `CRÉER`, `METTRE À JOUR`, `CRÉER_ET_METTRE À JOUR` et `SUPPRIMER` |
| Mode atomique | Indique comment l'importation répond aux erreurs de validation. S'il est défini sur `TOUS`, toutes les données importées doivent être valides avant que chaque donnée ne soit commitée. Par contre s'il est défini sur `OBJET`, seules les données commitées doivent être valides, tandis que d'autres données peuvent être invalides. | Énumération | `TOUS`, `OBJET` |
| flushMode | Indique la fréquence de vidange. Il s'agit de la fréquence à laquelle les données sont introduites dans la base de données au cours de l'importation. Il est principalement utilisé à des fins de débogage et ne doit pas être modifié dans un environnement de production. | Énumération | `AUTO`, `OBJET` |
| Mode de validation | Indique l'intégralité de l'étape de validation. Il peut être ignoré, configuré pour échouer rapidement (retour à la première erreur) ou complet (par défaut), ce qui renverra toutes les erreurs trouvées. | Énumération | `COMPLET`, `ÉCHOUER_RAPIDEMENT`, `IGNORER` |
| Validation du modèle de saut | S'il est défini sur 'vrai', la validation du modèle des attributs générés sera sautée. | Booléen | `VRAI`, `FAUX` |
| Sauter les effets secondaires | Si défini sur 'vrai', les effets secondaires de l'importation seront ignorés. | Booléen | `VRAI`, `FAUX` |
| Sauter les règles | Si défini sur 'vrai', l'exécution des règles de programme pour l'importation sera ignorée. | Booléen | `VRAI`, `FAUX` |

**REMARQUE** : Le schéma d'identification (idScheme) et ses paramètres spécifiques aux métadonnées comme 'schéma d'unité d'organisation' (orgUnitIdScheme), 'schéma d'identification de programme' (programIdScheme), etc. permettaient d'autoriser et d'utiliser le paramètre par défaut `AUTO`. `AUTO` a été supprimé. `UID` est déjà le schéma d'identification par défaut. Toutes les requêtes envoyées avec le schéma d'identification `AUTO` se comporteront de la même manière qu'auparavant, c'est à dire que la correspondance sera faite en utilisant `UID`.

### Charges utiles plates et imbriquées { #flat-and-nested-payloads }

L'importateur prend en charge les charges utiles plates et imbriquées. La principale différence réside dans la manière dont le client exige que ses données soient structurées.

**Charge utile plate**
: La charge utile de type plate est simple. Elle peut contenir des collections pour chacun des principaux objets Tracker dont nous disposons. Cela fonctionne de manière transparente avec les données existantes, auxquelles des UID sont déjà attribués. Cependant, pour les nouvelles données, le client devra fournir de nouveaux UID pour toute référence entre objets. Par exemple, si vous importez une nouvelle entité suivie avec une nouvelle inscription, l'entité suivie demande au client de fournir un UID afin que l'inscription puisse être rattachée à cet UID.

**Charge utile imbriqué**
: Les charges utiles imbriquées sont la structure la plus couramment utilisée. Ici, les objets Tracker sont intégrés dans leur objet racine - par exemple, une inscription dans une entité suivie. L'avantage avec cette structure est que le client n'a pas besoin de fournir d'UID pour toutes ces connexions puisqu'il se verra attribuer la connexion au cours du processus d'importation, étant donné qu'elles sont imbriquées les unes aux autres.

> **REMARQUE**
>
> Même si les charges utiles imbriquées peuvent s'avérer plus simples à gérer pour les clients, elles seront toujours aplaties avant l'importation. Cela signifie que pour les importations volumineuses, le fait de fournir une charge utile plate permettra non seulement d'avoir plus de contrôle mais aussi moins de surcharge sur le processus d'importation.

Ci-dessous, des exemples de versions **PLATES** et **IMBRIQUÉES** de la charge utile. Les mêmes données sont utilisées dans les deux cas.

#### Charge utile ***PLATE*** { #flat-payload }

```json
{
  "trackedEntities": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "Q9GufDoplCL"
    }
  ],
  "enrollments": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "program": "f1AyMswryyQ",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "trackedEntityType": "Q9GufDoplCL",
      "enrolledAt": "2019-08-19T00:00:00.000",
      "deleted": false,
      "occurredAt": "2019-08-19T00:00:00.000",
      "status": "ACTIVE",
      "notes": [],
      "attributes": [],
    }
  ],
  "events": [
    {
      "scheduledAt": "2019-08-19T13:59:13.688",
      "program": "f1AyMswryyQ",
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "status": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "attributeCategoryOptions": "xYerKDKCefk",
      "deleted": false,
      "attributeOptionCombo": "HllvX50cXC0",
      "dataValues": [
        {
          "updatedAt": "2019-08-19T13:58:37.477",
          "storedBy": "admin",
          "dataElement": "BuZ5LGNfGEU",
          "value": "20",
          "providedElsewhere": false
        },
        {
          "updatedAt": "2019-08-19T13:58:40.031",
          "storedBy": "admin",
          "dataElement": "ZrqtjjveTFc",
          "value": "Male",
          "providedElsewhere": false
        },
        {
          "updatedAt": "2019-08-19T13:59:13.691",
          "storedBy": "admin",
          "dataElement": "mB2QHw1tU96",
          "value": "[-11.566044,9.477801]",
          "providedElsewhere": false
        }
      ],
      "notes": []
    },
    {
      "scheduledAt": "2019-08-19T13:59:13.688",
      "program": "f1AyMswryyQ",
      "event": "XwwuwNp6gVE",
      "programStage": "PaOOjwLVW23",
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "status": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "attributeCategoryOptions": "xYerKDKCefk",
      "deleted": false,
      "attributeOptionCombo": "HllvX50cXC0",
      "notes": []
    }
  ],
  "relationships": [
    {
      "relationshipType": "Udhj3bsdHeT",
      "from": {
        "trackedEntity": { "trackedEntity": "Kj6vYde4LHh" }
      },
      "to": {
        "trackedEntity": { "trackedEntity": "Gjaiu3ea38E" }
      }
    }
  ]
}
```

#### Charge utile ***IMBRIQUÉES*** { #nested-payload }

```json
{
  "trackedEntities": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "Q9GufDoplCL",
      "relationships": [
        {
          "relationshipType": "Udhj3bsdHeT",
          "from": {
            "trackedEntity": { "trackedEntity": "Kj6vYde4LHh" }
          },
          "to": {
            "trackedEntity": { "trackedEntity": "Gjaiu3ea38E" }
          }
        }
      ],
      "enrollments": [
        {
          "orgUnit": "O6uvpzGd5pu",
          "program": "f1AyMswryyQ",
          "trackedEntity": "Kj6vYde4LHh",
          "enrollment": "MNWZ6hnuhSw",
          "trackedEntityType": "Q9GufDoplCL",
          "enrolledAt": "2019-08-19T00:00:00.000",
          "deleted": false,
          "occurredAt": "2019-08-19T00:00:00.000",
          "status": "ACTIVE",
          "notes": [],
          "relationships": [],
          "attributes": [],
          "events": [
            {
              "scheduledAt": "2019-08-19T13:59:13.688",
              "program": "f1AyMswryyQ",
              "event": "ZwwuwNp6gVd",
              "programStage": "nlXNK4b7LVr",
              "orgUnit": "O6uvpzGd5pu",
              "trackedEntity": "Kj6vYde4LHh",
              "enrollment": "MNWZ6hnuhSw",
              "enrollmentStatus": "ACTIVE",
              "status": "ACTIVE",
              "occurredAt": "2019-08-01T00:00:00.000",
              "attributeCategoryOptions": "xYerKDKCefk",
              "deleted": false,
              "attributeOptionCombo": "HllvX50cXC0",
              "dataValues": [
                {
                  "updatedAt": "2019-08-19T13:58:37.477",
                  "storedBy": "admin",
                  "dataElement": "BuZ5LGNfGEU",
                  "value": "20",
                  "providedElsewhere": false
                },
                {
                  "updatedAt": "2019-08-19T13:58:40.031",
                  "storedBy": "admin",
                  "dataElement": "ZrqtjjveTFc",
                  "value": "Male",
                  "providedElsewhere": false
                },
                {
                  "updatedAt": "2019-08-19T13:59:13.691",
                  "storedBy": "admin",
                  "dataElement": "mB2QHw1tU96",
                  "value": "[-11.566044,9.477801]",
                  "providedElsewhere": false
                }
              ],
              "notes": [],
              "relationships": []
            },
            {
              "scheduledAt": "2019-08-19T13:59:13.688",
              "program": "f1AyMswryyQ",
              "event": "XwwuwNp6gVE",
              "programStage": "PaOOjwLVW23",
              "orgUnit": "O6uvpzGd5pu",
              "trackedEntity": "Kj6vYde4LHh",
              "enrollment": "MNWZ6hnuhSw",
              "enrollmentStatus": "ACTIVE",
              "status": "ACTIVE",
              "occurredAt": "2019-08-01T00:00:00.000",
              "attributeCategoryOptions": "xYerKDKCefk",
              "deleted": false,
              "attributeOptionCombo": "HllvX50cXC0",
              "notes": [],
              "relationships": []
            }
          ]
        }
      ]
    }
  ]
}
```

### SYNC et ASYNC { #sync-and-async }
Pour l'utilisateur, la principale différence entre une importation synchrone et une importation asynchrone est la réponse immédiate de l'API. Dans le cas d'une importation synchrone, la réponse sera renvoyée avec le récapitulatif de l'importation (importSummary) dès que l'importation sera terminée. En revanche, pour les importations asynchrones, la réponse sera immédiate et contiendra une référence à travers laquelle le client pourra demander des mises à jour de l'importation.

Dles importations importantes, il peut être avantageux pour le client d'utiliser l'importation asynchrone pour éviter d'attendre trop longtemps une réponse.


Des exemples de réponse **ASYNC** sont présentés ci-dessous. Pour la réponse **SYNC**, consultez la [section importSummary](#webapi_nti_import_summary).

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "message": "Tracker job added",
    "response": {
        "responseType": "TrackerJob",
        "id": "LkXBUdIgbe3",
        "location": "https://play.dhis2.org/dev/api/tracker/jobs/LkXBUdIgbe3"
    }
}
```

### Charge utile des événements CSV { #csv-events-payload }

Afin de maintenir la compatibilité avec les anciennes versions du Tracker, l'API permet d'importer des événements en utilisant le format CSV.
Étant donné que ce format ne permet pas d'utiliser une liste comme champ, chaque ligne de la charge utile CSV représente un événement et une valeur de données.
Ainsi, pour les événements comportant plusieurs valeurs de données, le fichier CSV comportera `x` lignes par événement où `x` est le nombre de valeurs de données dans cet événement.
Les autres champs présentés sous forme de listes tels que comme ***relations*** et ***notes*** ne sont pas pris en charge.
Pour importer un fichier CSV, le contenu de la requête doit être de type ***application/csv*** ou ***texte/csv***.

#### *** Exemple de charge utile CSV *** { #csv-payload-example }

|événement|statut|de paludisme) ».|Étape du programme|inscription|orgUnit (Unité d'organisation)|occurredAt (s'est produit à)|scheduledAt (programmé à)|élément de données|valeur|Stocké par|Fourni ailleurs
|---|---|---|---|---|---|---|---|---|---|---|---|
|V1CerIi3sdL|EFFECTUÉ|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|a3kGcGDCuk6|11|administrateur|faux
|V1CerIi3sdL|EFFECTUÉ|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|mB2QHw1tU96|[-11.566044,9.477801]|administrateur|faux

### Récapitulatif des importations { #webapi_nti_import_summary }

L'API du Tracker dispose de deux points d'extrémité de base qui permettent aux consommateurs d'obtenir des commentaires sur leurs importations. Ces points d'extrémité concernent plus les tâches d'importation asynchrone, mais ils sont également disponibles pour les importations synchrones. Ces points d'extrémité renverront soit le journal de l'importation, soit le récapitulatif de l'importation lui-même.

> **Remarque**
>
> Ces points d'extrémité s'appuient sur des informations stockées dans la mémoire de l'application. Cela signifie que les informations seront indisponibles après certaines situations, telle qu'un redémarrage de l'application ou après un grand nombre de requêtes d'importation qui commencent après celle-ci.

Après avoir soumis une requête d'importation Tracker, nous pouvons accéder aux points d'extrémité suivants afin de surveiller la progression de la tâche en fonction des journaux :

`GET /tracker/jobs/{uid}`

| Paramètre|Description|Exemple
|---|---|---|
|`{uid}`| L'UID d'une tâche d'importation Tracker existante | ABCDEF12345

#### exemple de ***REQUÊTE*** { #request-example }

`GET /tracker/jobs/mEfEaFSCKCC`

#### Exemple de ***RÉPONSE*** { #response-example }

```json
[
  {
    "uid": "mEfEaFSCKCC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:06.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) finished in 6.00000 sec. Import:Done",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:05.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) commit completed in 1.00000 sec. Import:commit",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:04.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) programruleValidation completed in 1.00000 sec. Import:programruleValidation",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:03.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) programrule completed in 1.00000 sec. Import:programrule",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:02.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) validation completed in 1.00000 sec. Import:validation",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:01.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) preheat completed in 1.00000 sec. Import:preheat",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:00.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) started by admin ( xE7jOejl9FI ) Import:Start",
    "completed": true,
    "id": "mEfEaFSCKCC"
  }
]
```

De plus, le point d'extrémité suivant renverra le récapitulatif de la tâche d’importation. Ce récapitulatif ne sera disponible qu'une fois l'importation terminée :

`GET /tracker/jobs/{uid}/report`

| Paramètre|Description|Exemple
|---|---|---|
|path `/{uid}`| L'UID d'une tâche d'importation Tracker existante | ABCDEF12345
|`reportMode` (Mode de rapport)| Le niveau du rapport à renvoyer | `FULL`&#124;`ERRORS`&#124;`WARNINGS`|

#### exemple de ***REQUÊTE*** { #request-example }

`GET /tracker/jobs/mEfEaFSCKCC/report`

#### Exemple de ***RÉPONSE*** { #response-example }

La [charge utile de la réponse](#sample-responses) est la même que celle renvoyée après une requête d'importation synchrone.

> **Remarque**
>
> Les deux points d'extrémité sont principalement utilisés pour l'importation asynchrone. Cependant, `GET /tracker/jobs/{uid}` devrait également fonctionner pour les demandes synchrones car au final il utilise le même processus d'importation et la même journalisation que les demandes asynchrones.

### Structure du récapitulatif d'importation { #import-summary-structure }

La structure globale des récapitulatifs d'importation se présente comme suit, en fonction du `mode de rapport` faisant l'objet de la requête :
```json
{
  "status": "...",
  "validationReport": { },
  "stats": { },
  "timingsStats": { },
  "bundleReport": { },
  "message" : { }
}
```

***statut***

La propriété `statut` du récapitulatif d'importation indique l'état global de l'importation. Si aucune erreur ou avertissement n'est signalé(e) lors de l'importation, le `statut` est `OK`. Par contre, si une erreur ou un avertissement est signalé(e) lors de l'importation, le statut devient `ERREUR` ou `AVERTISSEMENT`.

Le `statut` dépend du `Rapport de validation` le plus important. `ERREUR` est le plus important, suivi de `AVERTISSEMENT` et enfin `OK`. Cela implique que `ERREUR` est signalé si une seule erreur a été détectée lors de l'importation, quel que soit le nombre d'avertissements.

> **Remarque**
>
> Si l'importation est faite selon le mode atomique "OBJET", où les données sont importées sans erreurs de validation, le statut sera toujours `ERREUR` si des erreurs sont détectées.

***Rapport de validation***

Le `Rapport de validation` peut inclure des `Rapports d'erreur` et des `Rapports d'avertissement` si des erreurs ou des avertissements étaient présents lors de l'importation. Lorsqu'ils sont présents, ils fournissent une liste détaillée des erreurs ou avertissements rencontrés.

Ci-dessous, un exemple d'erreur de validation lors de l'importation d'une `ENTIÉE_SUIVIE` :
```json
{
  "validationReport": {
    "errorReports": [
      {
        "message": "Could not find TrackedEntityType: `Q9GufDoplCL`.",
        "errorCode": "E1005",
        "trackerType": "TRACKED_ENTITY",
        "uid": "Kj6vYde4LHh"
      },
      ...
    ],
    "warningReports" : [ ... ]
  }
}
```

Le rapport contient un message et un code décrivant l'erreur (voir la section [codes d'erreur] (#error-codes) pour plus d'informations sur les erreurs). Il contient également le `type de tracker` et l'`uid`, lesquels permettent d'identifier l'emplacement de l'erreur dans les données. Dans ce cas, il y avait une `ENTITÉ_SUIVIE` avec l'uid `Kj6vYde4LHh` qui renvoyait à un type d'entité suivi qui n'a pas été trouvé.

> **Remarque**
>
> Les `uid` des objets trackers servent de noms à ces objets dans la charge utile. Par exemple, l'`uid` d'une entité suivie dans la charge utile serait "trackedEntity". La même chose s'applique aux inscriptions, aux événements et aux relations qui portent respectivement les noms "enrollment", "event" et "relationship".
>
> Si aucun uid n'est fourni dans la charge utile, le processus d'importation générera de nouveaux uids. Cela signifie que le rapport d'erreur peut faire référence à un uid qui n'existe pas dans votre charge utile.
>
> Les erreurs signalent des problèmes avec la charge utile que l'importateur ne peut pas contourner. Toute erreur empêchera l'importation de ces données. Les avertissements, en revanche, sont des problèmes qui peuvent être contournés en toute sécurité, mais dont l'utilisateur doit être informé. Les avertissements ne bloquent pas l'importation des données.

***Statistiques***

Les statistiques donnent un aperçu rapide de l'importation. Une fois l'importation terminée, ces statistiques indiqueront la quantité de données créées, mises à jour, supprimées ou ignorées.

Exemple:
```json
{
  "stats": {
    "created": 2,
    "updated": 2,
    "deleted": 1,
    "ignored": 5,
    "total": 10
  }
}
```
`cre` fait référence au nombre de nouveaux objets créés. En général, les objets sans UID existant dans la charge utile seront traités comme de nouveaux objets.

`updated` fait référence au nombre d'objets mis à jour. Si un objet a un UID défini dans la charge utile, il sera considéré comme étant à jour tant que ce même UID se trouve dans la base de données.

`deleted` fait référence au nombre d'objets supprimés lors de l'importation. La suppression ne se produit que lorsque l'importation est configurée pour supprimer des données et uniquement lorsque les objets présents dans la charge utile ont des UID existants définis.

`ignored` fait référence aux objets qui n'ont pas été conservés. Les objets peuvent être ignorés pour plusieurs raisons, par exemple pour éviter de créer un objet qui existe déjà. Ignorer des objets ne pose pas de réels problèmes, car si un objet est ignoré, c'est parce que sa création n'était pas nécessaire ou cela lié à la configuration de l'importation.

***timingStats*** (Statistiques de temps)

`timingStats` représente le temps écoulé dans les différentes étapes de l'importation. Ces statistiques ne donnent pas le temps total exact de l'importation, mais plutôt le temps passé dans le code pour les différentes étapes.

Les `timingStats` servent principalement à déboguer les importations qui posent des problèmes afin de voir quelle partie de l'importation rencontre des problèmes.
```json
{
  "timingsStats": {
    "timers": {
      "preheat": "0.234086 sec.",
      "preprocess": "0.000058 sec.",
      ...
      "totalImport": "0.236810 sec.",
      "validation": "0.001533 sec."
    }
  }
}
```

***bundleRapport*** (Rapport d'ensemble)

Une fois l'importation terminée, le `bundleReport` contient tous les [objets tracker](#tracker-objects) importés.

Prenons en exemple l'`ENTITÉ_SUIVIE` :
```json
{
  "bundleReport": {
    "status": "OK",
    "typeReportMap": {
      "TRACKED_ENTITY": {
        "trackerType": "TRACKED_ENTITY",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "TRACKED_ENTITY",
            "uid": "FkxTQC4EAKK",
            "index": 0,
            "errorReports": []
          }
        ]
      },
      ...
    }
  }
}
```
Comme nous l'avons vu, chaque type d'objet Tracker sera rapporté, et chacun a ses propres statistiques et `objectReports`(rapports d'objets). Ces `rapports d'objets` fourniront des détails sur chaque objet importé, notamment leur type, leur UID et tout rapport d'erreur ou d'avertissement qui les concerne.

***message***

Si l'importation se termine brusquement, le `message`  va contenir des informations supplémentaires sur ce qui s'est passé.

### Niveau du rapport récapitulatif de l'importation { #import-summary-report-level }

Comme indiqué précédemment, `GET /tracker/jobs/{uid}/report` peut être récupéré à l'aide d'un paramètre `reportMode` spécifique. Par défaut, le point d'extrémité renverra un `importSummary` avec `pour reportMode` `ERROR`.

| Paramètre | Description |
|---|---|
| `COMPLET` | Renvoie tout à partir de `AVERTISSEMENTS`, en plus des `timingsStats` |
| `AVERTISSEMENTS` | Renvoie tout à partir de `ERREURS`, en plus de `warningReports` (rapports d'avertissement) dans `validationReports` (rapports de validation) |
| `ERREURS` (par défaut) | Renvoie uniquement `errorReports` (rapports d'erreurs) dans `validationReports` |

De plus, tous les `reportModes` (modes de rapports) renverront `statut`, `statistiques`, `bundleReport` et `message` le cas échéant.

### Codes d'erreur { #webapi_nti_error_codes }

Il existe plusieurs codes d'erreur pour différents scénarios d'erreur. Le tableau suivant contient la liste des codes d'erreur générés par la nouvelle API du Tracker, ainsi que les messages d'erreur et quelques descriptions supplémentaires. Les espaces réservés dans les messages d'erreur (`{0}`, `{1}`, `{2}`..) sont généralement des uids, sauf indication contraire.

| Code d'erreur | Message d'erreur | Description |
|:--|:----|:----|
| E1000 | Utilisateur : `{0}`, n'a pas d'accès en écriture à l'unité d'organisation : `{1}`. | Cela signifie que l'unité d'organisation `{1}` ne fait pas partie du champ de saisie de l'utilisateur `{0}` pour que l'opération d'écriture soit autorisée. |
| E1001 | L'utilisateur : `{0}`, n'a pas d'accès en écriture de données sur le type d'entité suivie : `{1}`. | L'erreur se produit lorsque l'utilisateur n'est pas autorisé à créer ou à modifier les données du Type d'entité suivie `{1}`
| E1002 | L'instance d'entité suivie `{0}` existe déjà. | Cette erreur se produit lorsque l'on essaie de créer une nouvelle entité suivie avec un uid déjà existant. Veillez à utiliser un nouvel uid lors de l'ajout d'une nouvelle entité suivie. |
| E1005 | Impossible de trouver le Type d'entité suivie : `{0}`. | L'erreur se produit lorsque l'on essaie de récupérer un Type d'entité suivie non existant avec l'uid `{0}` . Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture au Type d'entité suivie. |
| E1006 | L'attribut : `{0}` n'existe pas. | L'erreur se produit lorsque le système n'a pas pu trouver un attribut d'entité suivie correspondant avec l'uid `{0}`. Cela peut également signifier que l'utilisateur n'a pas accès à l'attribut d'entité suivie. |
| E1007 | Erreur de validation du type de valeur d'attribut : `{0}` ; Erreur : `{1}`. | Incompatibilité entre le type de valeur d'un attribut d'entité suivie et la valeur d'attribut qui lui est fournie. L'erreur de validation réelle sera affichée dans `{1}`. |
| E1009 | Le ressource de fichier : `{0}` a déjà été attribuée à un autre objet. | L'uid de ressource de fichier `{0}` est déjà attribué à un autre objet du système. |
| E1010 | Impossible de trouver le programme : `{0}` lié à l'événement. | Le système n'a pas pu trouver un programme avec l'uid `{0}` spécifié dans la charge utile Événement. Cela peut également signifier que le programme spécifique n'est pas accessible par l'utilisateur connecté. |
| E1011 | Impossible de trouver l'unité d'organisation : `{0}` lié à l'événement. | Le système n'a pas pu trouver une unité d'organisation avec l'uid `{0}` spécifié dans la charge utile de l'événement.  |
| E1012 | La géométrie n'est pas conforme au FeatureType (type de fonctionnalité) : `{0}`. | Le type de fonctionnalité fourni est soit NONE (aucun), soit il est incompatible pour la valeur géométrique fournie. |
| E1013 | Impossible de trouver le ProgramStage (étape de programme) : `{0}`, lié à l'événement. | Le système n'a pas pu trouver une étape de programme avec l'uid `{0}` spécifié dans la charge utile de l'événement. Cela peut également signifier que l'étape de programme n'est pas accessible à l'utilisateur connecté.  |
| E1014 | Un programme identifié `{0}` est un programme sans enregistrement. Aucune inscription ne peut être faite dans un programme sans enregistrement. | Les inscriptions ne peuvent être créées que pour les programmes avec des enregistrements. |
| E1015 | L'instance d'entité suivie : `{0}` a déjà une inscription active dans le programme `{1}`. | Il est impossible de s'inscrire à un programme si une autre inscription active existe déjà pour le programme. L’inscription active devra au moins être terminée au préalable. |
| E1016 | L'instance d'entité suivie : `{0}` a déjà une inscription active dans le programme : `{1}`, et ce programme n'autorise qu'une seule inscription . | Conformément à la configuration du programme `{1}`, une entité suivie ne peut être inscrite qu'une seule fois à ce programme. Il semble que l'entité suivie `{0}` ait déjà une inscription ACTIVE ou TERMINÉE dans ce programme. Une autre inscription ne peut donc pas être ajoutée. |
| E1018 | L'attribut : `{0}` est obligatoire dans le programme `{1}` mais il n'est pas déclaré dans l'inscription `{2}`. | La valeur de l'attribut est manquante dans la charge utile, pour un attribut défini comme obligatoire pour un programme. Assurez-vous que les valeurs des attributs obligatoires sont fournies dans la charge utile.  |
| E1019 | Only Program attributes is allowed for enrollment; Non valid attribute: `{0}`. | L'uid d'attribut `{0}` spécifié dans la charge utile d'inscription n'est pas associé au programme.  |
| E1020 | La date d'inscription : `{0}` ne peut pas être une date ultérieure.` | Il est impossible de créer une inscription à une date ultérieure à moins que le Programme ne le permette dans sa configuration. |
| E1021 | La date d'incidence identifiée `{0}` ne peut pas être une date ultérieure.` | La date d'incidence ne peut pas être une date ultérieure à moins que le Programme ne le permette dans sa configuration. |
| E1022 | L'instance d'entité suivie `{0}` doit avoir le même type d'entité suivie que le programme `{1}`. | Le programme est configuré pour accepter un UID de type d'entité suivie différent de celui fourni dans la charge utile d’inscription. |
| E1023 | La DisplayIncidentDate (date d'affichage de l'incident) est vraie mais la propriété occurredAt (survenu à) est nulle ou a un format invalide : `{0}`. | Le programme est configuré avec la date d'affichage de l'incident mais sa date est nulle ou invalide dans la charge utile. |
| E1025 | La propriété enrolledAt (inscrit à) est nulle ou a un format non valide : `{0}`. | La date d'inscription est obligatoire pour une inscription. Assurez-vous qu'il ne soit pas nul et qu'il ait un format de date valide. |
| E1029 | L'unité d'organisation Évènement identifiée `{0}` et le Programme `{1}` ne correspondent pas. | La charge utile de l'événement utilise un programme `{1}` qui n'est pas configuré pour être accessible par l'unité d'organisation `{0}`. |
| E1030 | L'Événement `{0}` existe déjà. | Cette erreur se produit lorsque l'on essaie d'ajouter un nouvel événement avec un uid déjà existant. Veillez à utiliser un nouvel uid lors de l'ajout d'un nouvel événement. |
| E1031 | La date à laquelle l'événement est survenu (OccurredAt) est manquante. | La propriété OccuredAt (est survenue) est nulle ou a un format de date invalide dans la charge utile. |
| E1032 | L'Événement `{0}` n'existe pas. | |
| E1033 | La valeur d'inscription de l'Événement `{0}`  est NULLE. | |
| E1035 | La valeur d'inscription de l'Étape de programme `{0}`  est NULLE. | |
| E1036 | L'instance d'entité suivie de l'Événement `{0}` ne pointe pas vers un objet existant. | Le système n'a pas pu trouver une entité suivie avec l'UID spécifié dans la charge utile de l'événement. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à l'entité suivie. |
| E1039 | L'Étape de programme `{0}` n'est pas répétable et un événement existe déjà. | Un événement existe déjà pour l'étape de programme de l’inscription. Étant donné que l'étape de programme est configuré pour être non répétable, un autre événement ne peut pas être ajouté pour la même étape de programme.  |
| E1041 | L'unité d'organisation Inscription `{0}` et le Programme `{1}` ne correspondent pas. | La charge utile de l'inscription contient un programme `{1}` qui n'est pas configuré pour être accessible par l'unité d'organisation `{0}`. |
| E1042 | L'Événement `{0}` doit avoir une date de fin. | Si le programme est configuré pour avoir des completeExpiryDays (dates d'expiration complètes), alors la date de fin est obligatoire pour la charge utile d'un événement TERMINÉ. La propriété "completedDate" d'un événement dont le statut est "COMPLETED" (TERMINÉ) doit être non nulle et correspondre à un format de date valide. |
| E1048 | Object: `{0}`, uid: `{1}`, has an invalid uid format. | Un uid valide comporte 11 caractères. Le premier caractère doit être une lettre de l'alphabet (a-z ou A-Z) et les 10 caractères restants peuvent être alphanumériques (a-z ou A-Z ou 0-9). |
| E1049 | Could not find OrganisationUnit: `{0}`, linked to Tracked Entity. | The system could not find an OrganisationUnit with uid `{0}`. |
| E1050 | La date à laquelle l'événement est programmé (ScheduledAt) est manquante. | La propriété "ScheduledAt" dans la charge utile de l'événement est soit manquante, soit son format de date est invalide. |
| E1055 | La combinaison d'options d'attribut (AttributeOptionCombo) par défaut n'est pas autorisée car le programme n'a pas de combinaison de catégories (CategoryCombo) par défaut. | Le programme est configuré pour contenir une combinaison de catégories différente de celle par défaut, mais la requête utilise la combinaison d'options d'attribut par défaut. |
| E1056 | La date d'événement : `{0}`, est antérieure à la date de début : `{1}`, pour l'option d'attribut (AttributeOption) : `{2}`. | L'option de catégorie a une date de début configurée ; la date de l'événement dans la charge utile ne peut pas être antérieure à cette date de début. |
| E1057 | La date d'événement : `{0}`, est postérieure à la date de début : `{1}`, pour l'option d'attribut (AttributeOption) : `{2}`. | L'option de catégorie a une date de fin configurée ; la date de l'événement dans la charge utile ne peut pas être postérieure à cette date de fin.  |
| E1063 | L'instance d'entité suivie `{0}` n'existe pas. | L'erreur se produit lorsque l'on essaie de récupérer une Entité suivie qui n'existe pas avec l'uid `{0}`. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à l'Entité suivie. |
| E1064 | Valeur d'attribut non unique `{0}` pour l'attribut `{1}` | La valeur de l'attribut doit être unique dans le champ d'application défini. L'erreur indique que la valeur de l'attribut existe déjà pour une autre Entité suivie. |
| E1068 | Impossible de trouver l'Instance d'entité suivie : `{0}`, lié à l'inscription. | Le système n'a pas pu trouver l'entité suivie spécifiée dans la charge utile d'inscription. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à cette entité suivie. |
| E1069 | Impossible de trouver le programme : `{0}` lié à l'inscription. | Le système n'a pas pu trouver le programme spécifié dans la charge utile d'inscription. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à cet programme . |
| E1070 | Impossible de trouver l'unité d'organisation : `{0}` lié à l'inscription. | Le système n'a pas pu trouver l'unité d'organisation spécifiée dans la charge utile d'inscription. |
| E1074 | FeatureType (Type de fonctionnalité) est manquant. | |
| E1075 | L'attribut : `{0}`, n'a pas d'uid. | |
| E1076 | `{0}` `{1}` est obligatoire et ne peut pas être nul | |
| E1077 | La valeur du texte de l'attribut : `{0}`, dépasse la longueur maximale autorisée : `{0}`. | |
| E1080 | L'Inscription `{0}` existe déjà. | Cette erreur se produit lorsque l'on essaie de créer une nouvelle inscription avec un uid déjà existant. Veillez à utiliser un nouvel uid pour une nouvelle inscription. |
| E1081 | L'Inscription `{0}` n'existe pas. | L'erreur se produit lorsque l'on essaie de récupérer une Inscription qui n'existe pas avec l'uid `{0}`. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à cette Inscription. |
| E1082 | L'Événement : `{0}`, est déjà supprimé et ne peut pas être modifié. | Si l’événement est supprimé mais pas définitivement (soft delete), aucune modification n’est autorisée sur cet événement. |
| E1083 | L'Utilisateur : `{0}`, n'est pas autorisé à modifier les événements terminés. | Seul un super utilisateur ou un utilisateur disposant de l'autorité "F_UNCOMPLETE_EVENT" peut modifier les événements terminés. Les événements terminés sont les événements dont le statut est "TERMINÉ". |
| E1084 | La référence de la ressource de fichier : `{0}`, est introuvable. | |
| E1085 | La valeur de l'Attribut : `{0}`, ne correspond pas au type de valeur : `{1}`. | Incompatibilité entre le type de valeur d'un attribut et la valeur d'attribut fournie. |
| E1089 | L'Événement : `{0}`, fait référence à une Étape de programme `{1}` qui n'appartient pas au Programme `{2}`. | L’uid de l'Étape de programme et l’uid de Programme présent dans la charge utile de l’Événement sont incompatibles. |
| E1090 | L'attribut : `{0}` est obligatoire dans le type d'entité suivie `{1}` mais il n'est pas déclaré dans l'entité suivie `{2}`. | Des valeurs manquent dans la charge utile pour les attributs de type d'entité suivie obligatoires. |
| E1091 | L'utilisateur : `{0}` n'a pas d'accès en écriture de données sur le Programme : `{1}`. | La configuration du partage du Programme est telle que l'utilisateur n'a pas d'accès en écriture pour ce programme. |
| E1095 | L'utilisateur : `{0}` n'a pas d'accès en écriture de données sur l'Étape de programme : `{1}`. | La configuration du partage de l'Étape de programme est telle que l'utilisateur n'a pas d'accès en écriture pour cette Étape de programme.  |
| E1096 | L'utilisateur : `{0}` n'a pas d'accès en lecture de données sur le Programme : `{1}`. | La configuration du partage du Programme est telle que l'utilisateur n'a pas d'accès en lecture pour ce programme. |
| E1099 | L'utilisateur : `{0}` n'a pas d'accès en écriture sur l'Option de catégorie : `{1}`. | La configuration du partage de l'Option de catégorie est telle que l'utilisateur n'a pas d'accès en écriture pour cette Option de catégorie. |
| E1100 | L'Utilisateur : `{0}`, ne dispose pas de l'autorité 'F_TEI_CASCADE_DELETE' pour supprimer l'Instance d'entité suivie : `{1}`. | Certaines Inscriptions n'ont pas été supprimées pour cette Entité suivie. Si l'utilisateur ne dispose pas de l'autorité "F_TEI_CASCADE_DELETE", ces inscriptions devront d'abord être supprimées explicitement avant qu'il puisse supprimer l'Entité suivie. |
| E1102 | L'Utilisateur : `{0}`, n'a pas accès à la combinaison de l'Entité suivie : `{1}` et du Programme : `{2}`. | Cette erreur se produit lorsque l'unité d'organisation de l'utilisateur ne possède pas cette entité suivie, pour ce programme spécifique. L'unité d'organisation propriétaire de la combinaison Entité Suivie-Programme (TrackedEntity-Program) doit se trouver dans le champ de saisie (dans certains cas, dans le champ de recherche) de l'utilisateur. |
| E1103 | L'Utilisateur : `{0}`, ne dispose pas de l'autorité 'F_ENROLLMENT_CASCADE_DELETE' pour supprimer l'Inscription : `{1}`. | Certains Événements n'ont pas été supprimées pour cette Inscription. Si l'utilisateur ne dispose pas de l'autorité 'F_ENROLLMENT_CASCADE_DELETE', ces Événements devront d'abord être supprimées explicitement avant qu'il puisse supprimer l'Inscription. |
| E1104 | L'utilisateur : `{0}` n'a pas d'accès en lecture de données sur le programme : `{1}` et le type d'entité suivie : `{2}`. | La configuration du partage du Type d'entité suivie associé au Programme est telle que l'utilisateur n'a pas d'accès en lecture de données pour ce type d'entité suivie. |
| E1112 | La Valeur d'attribut : `{0}`, est définie sur 'confidentiel' mais le système n'est pas correctement configuré pour crypter les données. | Soit les fichiers JCE sont manquants, soit la propriété de configuration `encryption.password` peut être manquante dans `dhis.conf`. |
| E1113 | L'Inscription : `{0}`, est déjà supprimée et ne peut plus être modifiée. | Si l'inscription est supprimée mais pas définitivement (soft delete), aucune modification n’est autorisée sur cette inscription. |
| E1114 | L'Entité suivie : `{0}`, est déjà supprimée et ne peut donc plus être modifiée. | Si l'entité suivie est supprimée mais pas définitivement (soft delete), aucune modification n’est autorisée sur cette entité suivie. |
| E1115 | Impossible de trouver la combinaison d'options de catégorie : `{0}`. | |
| E1116 | Impossible de trouver la l'Option de catégorie : `{0}`. | Cela peut également signifier que l'utilisateur n'a pas accès à cette option de catégorie.|
| E1117 | La Combinaison d'options de catégorie n'existe pas pour la combinaison de catégories et les options de catégorie fournies : `{0}`. | |
| E1118 | L'utilisateur attribué `{0}` n'est pas un uid valide. | |
| E1119 | Une note de Tracker avec l'uid `{0}` existe déjà. | |
| E1120 | L'Étape de programme `{0}` n'autorise pas l'attribution d'utilisateurs | La charge utile d'événement a attribué un identifiant d'utilisateur (uid) mais l'étape de programme n’est pas configurée pour autoriser l'attribution d’utilisateurs. |
| E1121 | Propriété d'entité suivie obligatoire manquante : `{0}`. | |
| E1122 | La propriété d'inscription requise est manquante : `{0}`. | |
| E1123 | La propriété d'événement requise est manquante : `{0}`. | |
| E1124 | La propriété de relation requise est manquante : `{0}`. | |
| E1125 | La valeur `{0}` n'est pas une option valide pour `{1}` `{2}` dans l'ensemble d'options `{3}` | |
| E1017 | L'attribut : `{0}` n'existe pas. | |
| E1093 | L'utilisateur : `{0}` n'a pas d'accès en écriture sur l'unité d'organisation : `{1}`. | |
| E1094 | Il n'est pas permis de mettre à jour l'Inscription : `{0}`, Programme existant `{1}`. | La charge utile d’inscription pour inscription existante a un uid de programme différent de celui avec lequel l'inscription a été initialement faite. |
| E1110 | Il n'est pas permis de mettre à jour l'Événement : `{0}`, Programme existant `{1}`. | La charge utile d'Événement pour un Événement existant a un uid de programme différent de celui avec lequel il a été initialement créé.  |
| E1111 | Nous avons un attribut généré : `{0}`, mais aucun modèle. | |
| E1043 | La date de fin de l'événement : `{0}`, a expiré ; il n'est donc  plus possible d'apporter des modifications à cet événement. | A user without 'F_EDIT_EXPIRED' autthority cannot update an Event that has passed its expiry days as configured in its Program. |
| E1046 | L'Événement : `{0}`, doit avoir au moins une date (d'événement ou de programmation). | La propriété occuredAt (survenu à) ou selectedAt (sélectionné à) doit être présente dans la charge utile de l’événement. |
| E1047 | La date de l'événement : `{0}`, appartient à une période expirée. Un tel événement ne peut être créé. | Les propriétés occuredAt et scheduledAt de l'événement ont une valeur antérieure à la date de début du type de période (PeriodType).  |
| E1300 | Généré par la règle du programme (`{0}`) - `{1}` | |
| E1302 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` n'est pas valide : `{2}` | |
| E1303 | Généré par la règle de programme (`{0}`) - L'élément de données obligatoire `{1}` n'est pas présent | |
| E1304 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` n'est pas valide | |
| E1305 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` ne fait pas partie de l'étape de programme `{2}` | |
| E1306 | Généré par la règle de programme (`{0}`) - L'attribut obligatoire `{1}` n'est pas présent | |
| E1307 | Généré par la règle de programme (`{0}`) - Impossible d'attribuer une valeur à l'élément de données `{1}`. La valeur fournie doit être vide ou correspondre à la valeur calculée `{2}` | |
| E1308 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` est remplacé dans l'événement `{2}` | |
| E1309 | Généré par la règle de programme (`{0}`) - Impossible d'attribuer une valeur à l'attribut `{1}`. La valeur fournie doit être vide ou correspondre à la valeur calculée `{2}` | |
| E1310 | Généré par la règle de programme (`{0}`) - L'attribut `{1}` est remplacé dans l'instance d'entité suivie `{2}` | |
| E4000 | La relation : `{0}` ne peut pas être reliée à elle-même | |
| E4001 | L'élément de relation `{0}` n'est pas valide pour la relation `{1}`  : un élément ne peut être relié qu'à une seule entité Tracker. | |
| E4006 | Impossible de trouver le Type de relation : `{0}`. | |
| E4009 | Le Type de relation `{0}` n'est pas valide. | |
| E4010 | La contrainte du type de relation `{0}` nécessite un {1} mais un {2} a été trouvé . | |
| E4011 | Relationship: `{0}` cannot be persisted because {1} {2} referenced by this relationship is not valid. | |
| E4012 | Impossible de trouver `{0}` : `{1}`, liés à la relation. | |
| E4013 | La contrainte du type de relation `{0}` est manquante {1}. | |
| E4014 | La contrainte du type de relation `{0}` nécessite une entité suivie de type `{1}` mais c'est un type `{2} ` qui a été trouvé. | |
| E9999 | N/A | Message d'erreur non défini. |

### Validation { #webapi_nti_validation }

Lors de l'importation de données à l'aide de l'importateur du Tracker, une série de validations est effectuée pour garantir la validité des données. Cette section décrit certains des différents types de validation effectués afin d'avoir une meilleure compréhension si la validation échoue pour votre importation.

#### Propriétés requises { #required-properties }

Chaque objet Tracker possède quelques propriétés qui doivent être présentes lors de l'importation des données. Pour obtenir une liste exhaustive des propriétés requises, consultez la [section sur les objets Tracker] (#webapi_nti_tracker_objects).

Lors de la validation des propriétés requises, nous parlons généralement de références à d'autres données ou métadonnées. Dans ces cas, on note trois critères principaux :

1. La référence est présente et non nulle dans la charge utile.
2. La référence pointe vers le bon type de données et existe dans la base de données
3. L'utilisateur est autorisé à voir la référence

Si la première condition n'est pas remplie, l'importation échouera et un message indiquant une référence manquante sera généré. Cependant, si la référence indique un objet qui n'existe pas ou auquel l'utilisateur n'a pas accès, le message généré indiquera que la référence n'a pas été trouvée.

#### Formats { #formats }

Certaines propriétés des objets Tracker requièrent un format spécifique. Lors de l'importation des données, chacune de ces propriétés est validée au regard du format attendu et renvoie des erreurs en fonction de la propriété dont le format est incorrect. Voici quelques exemples de propriétés validées de cette manière :

- UID (Ceux-ci couvrent toutes les références à d’autres données ou métadonnées dans DHIS2.)
- Dates
- Géométrie (Les coordonnées doivent correspondre au format spécifié par son type)

#### Accès des utilisateurs { #user-access }
Toutes les données importées seront validées en fonction des métadonnées ([Partage](#webapi_nti_metadata_sharing)) et des unités d'organisation ([Champs d'application des unités d'organisation](#webapi_nti_ou_scope)) référencées dans les données. Vous pourrez trouver plus d’informations sur les champs d'application du partage et des unités d’organisation dans les sections suivantes.

Le partage est validé en même temps que la recherche des références dans la base de données. Les métadonnées auxquelles l'utilisateur n'a pas accès seront traitées comme si elles n'existaient pas. L'importation validera toutes les métadonnées référencées dans les données.

Les unités d'organisation, quant à elles, servent un double objectif. D'une part, elles permettent de s'assurer que les données ne soient importées que pour une unité d'organisation figurant dans le "champ de saisie" de l'utilisateur. D'autre part, elles sont également utilisées pour restreindre les programmes disponibles. Cela signifie que si vous essayez d'importer des données pour une unité d'organisation qui n'a pas accès au programme que vous importez, l'importation ne sera pas valide.

Les utilisateurs disposant de l'autorité `TOUS` ne sont pas affectés par les limites des champs d'application de partage et d'unité d'organisation lorsqu'ils importent des données. Cependant, ils ne peuvent pas importer d'inscriptions dans des unités d'organisation qui n'ont pas accès au programme d'inscription.

#### Valeurs d'attribut et de données { #attribute-and-data-values }

Les attributs et les valeurs de données font partie respectivement d'une entité suivie et d'un événement. Cependant, les attributs peuvent être liés à une entité suivie soit par son type (TrackedEntityType), soit par son programme (Program). Les attributs peuvent également être uniques.

La première validation effectuée lors de l'importation consiste à s'assurer que la valeur fournie pour un attribut ou un élément de données est conforme au type de valeur attendu. Par exemple, supposons que vous importiez une valeur pour un élément de données de type numérique. Dans ce cas, la valeur doit être numérique. Toute erreur liée à une non-concordance entre un type et une valeur se traduira par le même code d'erreur, mais avec un message spécifique lié au type de violation.

Les attributs et les valeurs de données obligatoires sont également vérifiés. Actuellement, la suppression des attributs obligatoires n'est pas autorisée. Dans certains cas d'utilisation, les valeurs doivent être envoyées séparément, tandis que dans d'autres, toutes les valeurs doivent être envoyées en une seule fois. Les programmes peuvent être configurés pour valider les attributs obligatoires `ON_COMPLETE` (complet ou `ON_UPDATE_AND_INSERT` pour s'adapter à ces cas d'utilisation.

Les attributs uniques sont validés au moment de l'importation. Cela signifie que tant que la valeur fournie est unique pour l'attribut et ce dans tout le système, l'importation sera acceptée. Cependant, si la valeur unique est utilisée par une autre entité suivie que celle qui est importée, l'importation échouera.

#### Configuration { #configuration }

Les dernières validations dans l'importateur sont des validations basées sur la configuration des métadonnées pertinentes par l'utilisateur. Pour plus d'informations sur chaque configuration, consultez les sections correspondantes. Trouvez ci-après quelques exemples de validations configurables :
- Type de fonctionnalité (pour la géométrie)
- Événements attribuables à l'utilisateur
- Autoriser les dates futures
- Inscrire une fois
- Et plus.

Ces configurations apporteront des modifications supplémentaires à la manière dont la validation est effectuée lors de l'importation.

### Règles de programme { #webapi_nti_program_rules }

Les utilisateurs peuvent configurer des [Règles de programme](#webapi_program_rules), qui vont ajouter un fonctionnement conditionnel aux formulaires du Tracker. En plus d'exécuter ces règles dans les applications du Tracker, l'importateur du Tracker va également procéder à une sélection de ces règles. Puisque l'importateur exécute également ces règles, nous pouvons garantir un niveau de validation supplémentaire.

Toutes les actions de règles de programme ne sont pas prises en charge, car elles ne sont adaptées qu'à une présentation de type « frontend ». Une liste complète des actions de règles de programme prises en charge est présentée ci-dessous.

  |Action de règle de programme|Pris en charge|
  |---|:---:|
  |**DISPLAYTEXT** (afficher le texte)| |
  |**DISPLAYKEYVALUEPAIR** (afficher la paire clé-valeur)| |
  |**HIDEFIELD** (cacher le champ)||
  |**HIDESECTION** (cacher la section)||
  |**ASSIGN** (attribuer )|**X**|
  |**SHOWWARNING** (afficher un avertissement)|**X**|
  |**SHOWERROR** (afficher l'erreur)|**X**|
  |**WARNINGONCOMPLETION** (avertissement à la fin)|**X**|
  |**ERRORONCOMPLETION** (erreur à la fin)|**X**|
  |**CREATEEVENT** (créer un événement)||
  |**SETMANDATORYFIELD** (définir un champ obligatoire)|**X**|
  |**SENDMESSAGE** (envoyer un message)|**X**|
  |**SCHEDULEMESSAGE** (planifier un message)|**X**|

Les règles de programme sont évaluées dans l'importateur de la même manière que dans les applications du Tracker. En résumé, les conditions suivantes sont prises en compte lors de l'application des règles de programme :

* La règle de programme doit être liée aux données importées ; par exemple, une étape de programme ou un élément de données.
* La condition de la règle de programme doit être évaluée comme étant vraie

Les résultats des règles de programme dépendent des actions définies dans ces règles :

* Les actions des règles de programme peuvent aboutir à 2 résultats différents : avertissements ou erreurs.
  * Les erreurs feront échouer la validation, tandis que les avertissements seront rapportés sous forme de message dans le récapitulatif de l'importation.
    * Les actions SHOWWARNING (afficher l'avertissement) et WARNINGONCOMPLETION (avertissement à la fin) ne peuvent générer que des avertissements.
    * Les actions SHOWERROR (afficher l'erreur), ERRORONCOMPLETION (erreur à la fin), et SETMANDATORYFIELD (définir un champ obligatoire) ne peuvent générer que des erreurs.
    * L'action ASSIGN (attribuer) peut générer à la fois des avertissements et des erreurs.
      * Lorsque l'action attribue une valeur à un attribut/élément de données vide, un avertissement est généré.
      * Lorsque l'action attribue une valeur à un attribut/élément de données qui a déjà la même valeur à attribuer, un avertissement est généré.
      * Lorsque l'action attribue une valeur à un attribut/élément de données qui a déjà une valeur et que la valeur à attribuer est différente, une erreur est générée à moins que le paramètre système `RULE_ENGINE_ASSIGN_OVERWRITE` soit défini sur "vrai".

Les règles de programme peuvent également entraîner des actions non voulues, telles que l'envoi et la planification de messages. Pour plus d’informations sur les actions non voulues, veuillez consulter la section suivante.

> **REMARQUE**
>
> Les règles de programme peuvent être ignorées lors de l'importation à l'aide du paramètre `skipProgramRules` (ignorer les règles de programme).

### Actions non voulues { #webapi_nti_side_effects }

Une fois qu'une importation est terminée, des tâches spécifiques peuvent être déclenchées du fait de cette importation. Ces tâches sont ce que nous appelons des « effets secondaires ». Ces tâches exécutent des opérations qui n'affectent pas l'importation elle-même.

Les effets secondaires sont des tâches qui s'exécutent séparément de l'importation, mais qui sont toujours déclenchées par une importation. Étant donné que les effets secondaires sont dissociés de l'importation, ils peuvent échouer même si l'importation réussit. De plus, les effets secondaires ne sont exécutés que lorsque l'importation réussit ; ils ne peuvent donc pas échouer dans l'autre sens.

Voici donc les effets secondaires actuellement pris en charge :

  |Effets secondaires|Pris en charge|Description|
  |---|:---:|---|
  |**Notification de Tracker**|**X**| Les mises à jour peuvent déclencher des notifications. Celles qui déclenchent des notifications sont **inscription**, **mise à jour d'événement**, **achèvement d'événement ou d'inscription**. |
  |**Notification de règle de programme**|**X**| Les règles de programme peuvent déclencher des notifications. Notez que ces notifications font partie des effets des règles de programme qui sont générés via le moteur de règles de DHIS2.|

  > **REMARQUE**
  >
  > Certaines configurations peuvent contrôler l'exécution des effets secondaires. La fonction `skipSideEffects` (ignorer les effets secondaires) peut être activée lors de l'importation pour ignorer complètement les effets secondaires. Par exemple, vous pouvez utiliser ce paramètre lors de l'importation d'un objet pour lequel vous ne voulez pas déclencher de notifications.

### Attribuer un utilisateur à des événements { #webapi_nti_user_event_assignment }

Certains processus bénéficient du fait que des événements soient traités comme des tâches, et pour cette raison, vous pouvez attribuer un utilisateur à un événement.

L'attribution d'un utilisateur à un événement ne modifie pas l'accès ou les autorisations des utilisateurs, mais crée un lien entre l'événement et l'utilisateur.
Lorsqu'un utilisateur est attribué à un événement, vous pouvez lancer des requêtes sur les événements à partir de l'API en utilisant le champ `assignedUser` (utilisateur attribué) en tant que paramètre.

Lorsque vous voulez attribuer un utilisateur à un événement, fournissez simplement l'UID de cet utilisateur dans le champ `assignedUser`. Voir l'exemple suivant :

```json
{
  ...
  "events": [
    {
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "enrollment": "MNWZ6hnuhSw",
      "assignedUser" : "M0fCOxtkURr"
    }
  ],
  ...
}
```

Dans cet exemple, l'utilisateur avec l'uid `M0fCOxtkURr` sera attribué à l'événement avec l'uid `ZwwuwNp6gVd`. Un seul utilisateur peut être attribué à un événement unique.

Pour utiliser cette fonctionnalité, l'attribution d'utilisateurs doit être activée pour l'étape de programme concernée et l'uid fourni pour l'utilisateur doit renvoyer à un utilisateur existant et valide.

## Exportation Tracker  { #webapi_nti_export }

Tracker export endpoints are a set of services that allow clients to query and retrieve objects stored using the import endpoint.

Besides differences highlighted in **[Changes in the API](#Changes-in-the-API)**, request parameters for these endpoints match older ones.

These endpoints are still being developed and are subject to change. However, 
the `request` and `response` interfaces will most likely not undergo significant changes.

Tracker export endpoints deal with the following Tracker objects:

- **Tracked Entities**
- **Événements**
- **Inscriptions**
- **Relations**

> **NOTE**
>
> - All these endpoints currently support `JSON`, `CSV` is only supported by Tracked Entities and Events.
>
> - These endpoints adopt the new naming convention documented in **[Changes in the API](#Changes-in-the-API)**

### Paramètres de requête courants { #common-request-parameters }

Le point d'extrémité suivant prend en charge les paramètres normalisés pour la pagination.

- **Entités suivies** `GET /api/tracker/trackedEntities`
- **Évènements** `GET /api/tracker/events`
- **Inscriptions** `GET /api/tracker/enrollments`
- **Relations** `GET /api/tracker/relationships`

#### Paramètres de requête pour la pagination { #request-parameters-for-pagination }

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`page`|`Entier`| Tout entier positif |Numéro de page à renvoyer. La valeur par défaut est 1 si rien n'est fourni.|
|`taille de la page`|`Entier`| Tout entier positif |Taille de la page. La valeur par défaut est 50. |
|`totalPages` (pages totales)|`Booléen`| `vrai`, `faux` |Indique s'il faut renvoyer le nombre total de pages dans la réponse |
|`skipPaging` (ignorer la pagination)|`Booléen`| `vrai`, `faux` |Indique si la pagination doit être ignorée et si toutes les lignes doivent être renvoyées. La valeur par défaut est `faux`, ce qui signifie que par défaut toutes les requêtes sont paginées, sauf si `skipPaging=true` (c'est-à-dire si le paramètre "ignorer la pagination" est définie sur "vrai")|
|`ordre`|`Chaîne`|comma-delimited list of `OrderCriteria` in the form of `propName:sortDirection`.<br><br> Example: `createdAt:desc`<br><br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive|Sort the response based on given `OrderCriteria`|

> **Attention**
>
> Sachez que les performances sont directement liées à la quantité de données qui fait l'objet de la requête. Le renvoi des pages plus volumineuses prendra plus de temps.

#### Paramètres de requête pour le mode de sélection de l'unité d'organisation{ #request-parameters-for-organisational-unit-selection-mode }

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.

|Mode|Description|
|---|---|
|`SÉLECTIONNÉ`|  Unités d'organisation définies dans la requête.|
|`SUBORDONNÉES`|  Les unités d'organisation sélectionnées et leurs subordonnées directs, c'est-à-dire les unités d'organisation au niveau inférieur.|
|`DESCENDANTS`| Les unités d'organisation sélectionnées et tous leurs subordonnées, c'est-à-dire toutes les unités d'organisation de niveau inférieur dans la hiérarchie.|
|`ACCESSIBLE`|  Il s'agit des unités d'organisation de visualisation de données associées à l'utilisateur actuel et toutes leurs subordonnées, c'est-à-dire toutes les unités d'organisation qui leur sont inférieures dans la hiérarchie. Les unités d'organisation de saisie de données associées à l'utilisateur actuel seront utilisées si celles dédiées à la visualisation ne sont pas définies.|
|`SAISIE`| Il s'agit des unités d'organisation de saisie de données associées à l'utilisateur actuel et toutes leurs subordonnées, c'est-à-dire toutes les unités d'organisation qui leur sont inférieures dans la hiérarchie.|
|`TOUS`| Il s'agit de toutes les unités d'organisation du système. L'utilisateur doit disposer de l'autorité `TOUS` pour pouvoir l'utiliser.|

#### Paramètre de requête pour filtrer les réponses { #webapi_nti_field_filter }

Tous les points d'extrémité d'exportation acceptent un paramètre `fields` (champs) qui contrôle les champs qui seront renvoyés dans la réponse JSON. Le paramètre `fields` accepte une liste de noms de champs ou de modèles séparés par des virgules. Quelques filtres `fields` possibles sont présentés ci-dessous. Consultez la section [filtre de champ de métadonnées (#webapi_metadata_field_filter)] pour obtenir un guide plus complet sur l'utilisation du paramètre `fields`.

##### Exemples { #examples }

|Exemple de paramètre|Signification|
|:---|:---|
|`champs=*`|renvoie tous les champs|
|`fields=createdAt,uid` (champs=créés à, uid)|renvoie uniquement les champs `createdAt` et `uid`|
|`fields=inscriptions[*,!uid]` (champs=inscriptions, uid)|renvoie tous les champs des `inscriptions` sauf les `uid`|
|`fields=enrollments[uid]`|renvoie uniquement l'`uid` du champ `inscriptions`|
|`fields=enrollments[uid,enrolledAt]`|renvoie uniquement l'`uid` des champs `inscriptions` et `enrolledAt` (inscrit à)|

### Entités suivies (`GET /api/tracker/trackedEntities`) { #tracked-entities-get-apitrackertrackedentities }

Deux points d'extrémité sont dédiés aux entités suivies :

- `GET /api/tracker/trackedEntities`
  - récupère les entités suivies correspondant aux critères donnés
- `GET /api/tracker/trackedEntities/{id}`
  - récupère une entité suivie en fonction de l'identifiant fourni

#### Point d'extrémité de la collection d'entités suivies `GET /api/tracker/trackedEntities` { #tracked-entities-collection-endpoint-get-apitrackertrackedentities }

Le but de ce point d'extrémité est de récupérer les entités suivies correspondant aux critères fournis par le client.

Le point d'extrémité renvoie une liste d'entités suivies qui correspondent aux paramètres de la requête.

##### Syntaxe de la requête { #request-syntax }

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`requête`|`Chaîne`|`{operator}:{filter-value}`|Crée un filtre sur les attributs d'entité suivie. Seule la valeur du filtre est obligatoire. L'opérateur `EQ` est utilisé si l'`opérateur` n'est pas spécifié.|
|`attribut`|`Chaîne`|Comma separated values of attribute `UID` | Pour chaque entité suivie dans la réponse, renvoie uniquement les attributs spécifiés |
|`filtre`|`Chaîne`|Comma separated values of filters|Filter is properties or attributes with operator and value.<br>Example: `filter=updatedAfter:lt:2000-01-01`<br>Multiple filters are allowed. User needs access to attribute to being able to have a filter on it|
|`orgUnit` (unité d'organisation)|`Chaîne`|semicolon-delimited list of organisational unit `UID`|Renvoie uniquement les instances d'entités suivies appartenant aux unités d'organisation fournies|
|Pour plus d'informations sur le `ouMode` (mode d'unité d'organisation) voir [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`Chaîne`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|Le mode de sélection des unités d'organisation peut l'être. La valeur par défaut est `SÉLECTIONNÉ`, qui fait uniquement référence aux unités d'organisation sélectionnées.|
|`programme`|`Chaîne`|`UID` de programme| un `UID` de programme dans lequel les instances présentes dans la réponse doivent être inscrites|
|`statut du programme`|`Chaîne`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|Le statut du programme de l’instance d’entité suivie dans le programme donné|
|`programStage` (étape de programme)|`Chaîne`|`UID`|un `UID` d'étape de programme pour lequel les instances présentes dans la réponse doivent avoir des événements|
|`followUp` (suivi)|`Booléen`|`vrai`, `faux`|Indique si l'instance d'entité suivie est marquée pour le suivi du programme spécifié.|
|`updatedAfter` (mis à jour après)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Date de début de la dernière mise à jour|
|`updatedBefore` (mis à jour avant)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Date de fin de la dernière mise à jour|
|`updatedWithin`|`Durée`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) | Renvoie les TEI qui ne dépassent pas la durée spécifiée|
|`enrollmentEnrolledAfter` (Inscription après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de début de l'incident dans le programme donné|
|`enrollmentEnrolledBefore` (Inscription avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de fin de l'incident dans le programme donné|
|`enrollmentOccurredAfter` (Inscription survenue après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de début de l'incident dans le programme donné|
|`enrollmentOccurredBefore` (inscription survenue avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de fin de l'incident dans le programme donné|
|`TrackedEntityType` (Type d'entité suivie)|`Chaîne`|UID du type d'entité suivi|Renvoie uniquement les instances d'entité suivies d'un type donné|
|`trackedEntity` (entité suivie)|`Chaîne`|semicolon-delimited list of tracked entity instance `UID`|Filtrez le résultat de manière à obtenir un ensemble limité d'entités suivies qui utilisent les uids explicites des instances d'entités suivies. Faites-le en utilisant le paramètre `trackedEntity=id1;id2`. Ce paramètre créera, au minimum, la limite externe des résultats, en constituant la liste de toutes les entités suivies à l'aide des uids fournis. Si d'autres paramètres/filtres de ce tableau sont utilisés, ils limiteront davantage les résultats à partir de la limite externe explicite.|
|`assignedUserMode` (mode utilisateur attribué)|`Chaîne`|`CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`|Restreint le résultat aux entités suivies avec des événements attribués en fonction du mode de sélection de l'utilisateur attribué. Voir le tableau ci-dessous "Modes utilisateur attribué" pour les explications. |
|`assignedUser` (utilisateur attribué)|`Chaîne`|Semicolon-delimited list of user UIDs to filter based on events assigned to the users.|Il est possible de filtrer le résultat pour obtenir un ensemble limité d'entités suivies avec des événements attribués aux UID donnés, à l'aide du paramètre `assignedUser=id1;id2`. Ce paramètre ne sera pris en compte que si le "mode utilisateur assigné" est `FOURNI` ou `nul`. L'API va générer une erreur si, par exemple, `assignedUserMode=CURRENT` et `assignedUser=someId`|
|`eventStatus` (statut d'événement)|`Chaîne`|`ACTIVE`&#124;`COMPLETED`&#124;`VISITED`&#124;`SCHEDULE`&#124;`OVERDUE`&#124;`SKIPPED`|Il s'agit du statut de tous les événements présents dans le programme spécifié|
|`eventOccurredAfter` (événement survenu après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de début de l'événement pour le programme donné|
|`eventOccurredBefore` (événement survenu avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de fin de l'événement pour le programme donné|
|`skipMeta`|`Booléen`|`vrai`, `faux`|Indique s’il convient de ne pas inclure les métadonnées dans la réponse.|
|`includeDeleted` (inclure les éléments supprimés)|`Booléen`|`vrai`, `faux`|Indique s’il faut inclure les éléments supprimés mais pas définitivement (soft delete)|
|`includeAllAttributes` (inclure tous les attributs)|`Booléen`|`vrai`, `faux`|Indique s'il faut inclure tous les attributs TEI|
|`attachment`|`Chaîne`| |Il s'agit du nom du fichier en cas d'exportation sous forme de fichier|
|`potentialDuplicate` (doublon potentiel)|`Booléen`|`vrai`, `faux`| Filter the result based on the fact that a tei is a Potential Duplicate. true: return teis flagged as Potential Duplicates. false: return teis NOT flagged as Potential Duplicates. If omitted, we don't check whether a tei is a Potential Duplicate or not. |
|`ordre`|`Chaîne`|Les champs pris en charge sont : `assignedUser, assignedUserDisplayName, attributeOptionCombo, completedAt, completedBy, createdAt, createdBy, deleted, enrolledAt, enrollment, enrollmentStatus, event, followup, occurredAt, orgUnit, orgUnitName, program, programStage, scheduleAt, status, storedBy, trackedEntity, updatedAt, updatedBy`.|Comma-delimited list of property name, attribute or data element UID and sort direction pairs in format `propName:sortDirection`.<br><br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive. |

Les modes 'utilisateur attribué' disponibles sont expliqués dans le tableau suivant.



Tableau : Modes d'utilisateur assigné

| Mode | Description |
|---|---|
| ACTUEL | Inclut les événements attribués à l’utilisateur actuellement connecté. |
| FOURNI | Inclut les événements attribués à l’utilisateur fourni dans la requête. |
| AUCUNE | Inclut uniquement les événements non attribués. |
| TOUT | Inclut tous les événements attribués, peu importe à qui ils sont attribués. |

La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

- Au moins une unité d'organisation doit être spécifiée avec le paramètre `orgUnit`
  (un ou plusieurs), ou `ouMode=ALL` doit être spécifié.

- Un seul des paramètres `program` et `trackedEntity` peut être
  spécifié (zéro ou un).

- Si `programStatus` est spécifié, alors `program` doit également être
  spécifiés.

- Si `followUp` est spécifié, alors `program` doit également être spécifié.

- Si `enrollmentEnrolledAfter` ou `enrollmentEnrolledBefore` est spécifié, alors
  `program` doit également être spécifié.

- Les éléments du filtre ne peuvent être spécifiés qu'une seule fois.

##### Exemples de requêtes { #example-requests }

Une requête pour toutes les instances associées à une unité d'organisation spécifique peut ressembler à ceci :

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8

Pour lancer une requête pour des instances à l'aide d'un attribut avec filtre et d'un attribut sans filtre, avec une unité d'organisation en utilisant le mode de requête de l'unité d'organisation subordonnée, utilisez ceci :

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &attribure=AMpUYgxuCaE&orgUnit=DiszpKrYNg8;yMCshbaVExv

Une requête pour les instances où les attributs sont inclus dans la réponse et où un attribut est utilisé comme filtre :

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &filter=AMpUYgxuCaE:LIKE:Road
        &orgUnit=DiszpKrYNg8

Une requête dans laquelle plusieurs opérandes et filtres sont spécifiés pour un élément de filtre :

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &program=ur1Edk5Oe2n
        &filter=lw1SqmMlnfh:GT:150
        &filter=lw1SqmMlnfh:LT:190

Pour lancer une requête sur un attribut en utilisant plusieurs valeurs dans un filtre *IN* :

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &filter=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

Pour limiter la réponse aux instances qui font partie d'un programme spécifique, vous pouvez inclure un paramètre de requête de programme :

    GET GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS
        &program=ur1Edk5Oe2n

Pour spécifier les dates d'inscription au programme dans la requête :

    GET /API/tracker/trackedEntities?
        &orgUnit=O6uvpzGd5pu&program=ur1Edk5Oe2n
        &enrollmentEnrolledAfter=2013-01-01
        &enrollmentEnrolledBefore=2013-09-01

Pour limiter la réponse aux instances d'une entité suivie spécifique, vous pouvez inclure un paramètre de requête d'entité suivie :

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu
        &ouMode=DESCENDANTS
        &trackedEntity=cyl5vuJ5ETQ

Par défaut, les instances sont renvoyées dans des pages de taille 50. Pour modifier cela, vous pouvez utiliser les paramètres de requête de page et de taille de page (pageSize) :

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu
        &ouMode=DESCENDANTS
        &page=2&pageSize=3

Vous pouvez utiliser une gamme d'opérateurs pour le filtrage :

|Opérateur|  Description|
|---|---|
|`EQ`|  Egale à|
|`GT`|  Supérieure à|
|`GE`|  Supérieure ou égal à|
|`LT`|  Inférieur à|
|`LE`|  inférieure ou égale à|
|`NE`|  Pas égale à|
|`LIKE`|  Like (free text match)|
|`IN`|  Égal à l'une des multiples valeurs séparées par ";"|

##### Format de réponse { #response-format }

La réponse `JSON` peut ressembler à ceci :

Les réponses peuvent être filtrées en fonction des champs recherchés ; voir [Paramètre de requête pour filtrer les réponses](#webapi_nti_field_filter)

```json
{
  "instances": [
    {
      "trackedEntity": "IzHblRD2sDH",
      "trackedEntityType": "nEenWmSyUEp",
      "createdAt": "2014-03-26T15:40:36.669",
      "createdAtClient": "2014-03-26T15:40:36.669",
      "updatedAt": "2014-03-28T12:28:17.544",
      "orgUnit": "g8upMTyEZGZ",
      "inactive": false,
      "deleted": false,
      "relationships": [],
      "attributes": [
        {
          "attribute": "VqEFza8wbwA",
          "code": "MMD_PER_ADR1",
          "displayName": "Address",
          "createdAt": "2016-01-12T00:00:00.000",
          "updatedAt": "2016-01-12T00:00:00.000",
          "valueType": "TEXT",
          "value": "1061 Marconi St"
        },
        {
          "attribute": "RG7uGl4w5Jq",
          "code": "Longitude",
          "displayName": "Longitude",
          "createdAt": "2016-01-12T00:00:00.000",
          "updatedAt": "2016-01-12T00:00:00.000",
          "valueType": "TEXT",
          "value": "27.866613"
        },
        ...,
        ...,
      ],
      "enrollments": [],
      "programOwners": []
    }
  ],
  "page": 1,
  "total": 39,
  "pageSize": 1
}
```

#### Point d'extrémité d'objet unique des entités suivies `GET /api/tracker/trackedEntities/{uid}`

Le but de ce point d'extrémité est de récupérer une entité suivie en se basant sur son UID.

##### Syntaxe de la requête { #request-syntax }

`GET /api/tracker/trackedEntities/{uid}?program={programUid}&fields={fields}`

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`uid`|`Chaîne`|`uid`|Renvoie l'instance d'entité suivie disposant de l'`uid` spécifié|
|`programme`|`Chaîne`|`uid`| Inclut les attributs du programme dans la réponse (seuls ceux auxquels l'utilisateur a accès) |
|`champs`|`Chaîne`| Tout filtre de champ valide (par défaut `*,!relationships,!enrollments,!events,!programOwners`) |Inclut les sous-objets spécifiés dans la réponse| 

##### Exemples de requêtes { #example-requests }

Une requête pour une instance d'entité suivie :

    GET /api/tracker/trackedEntities/IzHblRD2sDH?program=ur1Edk5Oe2n&fields=*

##### Format de réponse { #response-format }

Ce point d'extrémité permet de renvoyer des sous-objets lorsque le paramètre de requête `fields` (champs) est transmis après que le format json soit demandé. Dans le cas du format csv, le paramètre de requête `fields` n'a pas d'effet et la réponse contiendra toujours les mêmes champs, qui sont :
  - trackedEntity (Identifiant)
  - trackedEntityType (identifiant)
  - createdAt (Date et heure)
  - createdAtClient (Date et heure)
  - updatedAt (Date et heure)
  - updatedAtClient (Date et heure)
  - orgUnit (Identifiant)
  - inactif (booléen)
  - supprimé (booléen)
  - potentialDuplicate (booléen)
  - géométrie (WKT, https://en.wikipedia.org/wiki/Well-known_text_representation_of_geometry)
  - stockéBy (Chaîne)
  - createdBy (Nom d'utilisateur de l'utilisateur)
  - updatedBy (Nom d'utilisateur de l'utilisateur)
  - attributs (tout attribut valide répertorié dans une autre colonne)

Exemple de réponse json :
```json
{
    "trackedEntity": "IzHblRD2sDH",
    "trackedEntityType": "nEenWmSyUEp",
    "createdAt": "2014-03-26T15:40:36.669",
    "updatedAt": "2014-03-28T12:28:17.544",
    "orgUnit": "g8upMTyEZGZ",
    "inactive": false,
    "deleted": false,
    "relationships": [],
    "attributes": [
        {
            "attribute": "w75KJ2mc4zz",
            "code": "MMD_PER_NAM",
            "displayName": "First name",
            "createdAt": "2016-01-12T09:10:26.986",
            "updatedAt": "2016-01-12T09:10:35.884",
            "valueType": "TEXT",
            "value": "Wegahta"
        },
        {
            "attribute": "zDhUuAYrxNC",
            "displayName": "Last name",
            "createdAt": "2016-01-12T09:10:26.986",
            "updatedAt": "2016-01-12T09:10:35.884",
            "valueType": "TEXT",
            "value": "Goytiom"
        }
    ],
    "enrollments": [
        {
            "enrollment": "uT5ZysTES7j",
            "createdAt": "2017-03-28T12:28:17.539",
            "createdAtClient": "2016-03-28T12:28:17.539",
            "updatedAt": "2017-03-28T12:28:17.544",
            "trackedEntity": "IzHblRD2sDH",
            "trackedEntityType": "nEenWmSyUEp",
            "program": "ur1Edk5Oe2n",
            "status": "ACTIVE",
            "orgUnit": "g8upMTyEZGZ",
            "orgUnitName": "Njandama MCHP",
            "enrolledAt": "2020-11-10T12:28:17.532",
            "occurredAt": "2020-10-12T12:28:17.532",
            "followUp": false,
            "deleted": false,
            "events": [
                {
                    "event": "ixDYEGrNQeH",
                    "status": "ACTIVE",
                    "program": "ur1Edk5Oe2n",
                    "programStage": "ZkbAXlQUYJG",
                    "enrollment": "uT5ZysTES7j",
                    "enrollmentStatus": "ACTIVE",
                    "trackedEntity": "IzHblRD2sDH",
                    "relationships": [],
                    "scheduledAt": "2019-10-12T12:28:17.532",
                    "followup": false,
                    "deleted": false,
                    "createdAt": "2017-03-28T12:28:17.542",
                    "createdAtClient": "2016-03-28T12:28:17.542",
                    "updatedAt": "2017-03-28T12:28:17.542",
                    "attributeOptionCombo": "HllvX50cXC0",
                    "attributeCategoryOptions": "xYerKDKCefk",
                    "dataValues": [],
                    "notes": []
                }
            ],
            "relationships": [],
            "attributes": [],
            "notes": []
        }
    ],
    "programOwners": [
        {
            "orgUnit": "g8upMTyEZGZ",
            "trackedEntity": "IzHblRD2sDH",
            "program": "ur1Edk5Oe2n"
        }
    ]
}
```

### Événements (`GET /api/tracker/events`) { #events-get-apitrackerevents }

Deux points d'extrémité sont dédiés aux événements :

- `GET /api/tracker/events`
    - récupère les événements correspondant aux critères donnés
- `GET /api/tracker/events/{id}`
    - récupère un événement en fonction de l'identifiant fourni

#### Point d'extrémité de la collecte d'événements `GET /api/tracker/events` { #events-collection-endpoint-get-apitrackerevents }

Renvoie une liste d'événements en fonction des filtres fournis.

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`programme`|`Chaîne`|`uid`| Identifiant du programme|
|`programStage` (étape de programme)|`Chaîne`|`uid`| Identifiant de l'étape de programme|
|`statut du programme`|`énumération`| `ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`| Statut de l'événement dans le programme | 
|`followUp` (suivi)|`booléen`| `vrai`, `faux` | Détermine si l'événement est pris en compte pour un suivi dans le programme. La valeur par défaut est `vrai`|
|`trackedEntityInstance`|`Chaîne`|`uid`| Identifiant de l'instance d'entité suivie|
|`orgUnit` (unité d'organisation)|`Chaîne`|`uid`| Identifiant de l'unité d'organisation|
|Pour plus d'informations sur le `ouMode` (mode d'unité d'organisation) voir [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`Chaîne`| `SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`|  Mode de sélection de l'unité d'organisation| 
|`occurredAfter` (survenu après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only events newer than this date|
|`occurredBefore` (survenu avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only events older than this date|
|`statut`|`Chaîne`|`COMPLETED`&#124;`VISITED`&#124;`SCHEDULED`&#124;`OVERDUE`&#124;`SKIPPED` | Statut de l'événement|
|`occurredAfter` (survenu après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were occurred after this date.|
|`occurredBefore` (survenu avant)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were occurred up until this date.|
|`scheduledAfter` (programmé après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filtre pour les événements programmés après cette date.|
|`scheduledBefore` (programmé av|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were scheduled up until this date.|
|`updatedAfter` (mis à jour après)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filtre pour les événements qui ont été mis à jour après cette date. Ne peut pas être utilisé avec `updatedWithin`.|
|`updatedBefore` (mis à jour avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filtre pour les événements qui ont été mis à jour jusqu'à cette date. Ne peut pas être utilisé avec `updatedWithin`.|
|`updatedWithin`|`Durée`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations)| Incluez uniquement les éléments mis à jour pendant la durée indiquée.<br><br> Le format est [ISO-8601#Duration](https : //en.wikipedia.org/wiki/ISO_8601#Durations)|
|`skipMeta`|`Booléen`| `vrai`, `faux` | Exclut la partie métadonnées de la réponse (améliore les performances)|
|`dataElementIdScheme` (Schéma d'identification de l'élément de données)|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Schéma d’identification de l'élément de données à utiliser pour l’exportation.|
|categoryOptionComboIdScheme (`Schéma d'identification de la combinaison d'options de catégorie`)|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Schéma d'identification de la combinaison d'options de catégorie à utiliser pour l'exportation|
|`orgUnitIdScheme` (Schéma d'identification de l'unité d'organisation)|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Schéma d'ID de l'unité d'organisation à utiliser pour l'exportation|
|`programIdScheme` (Schéma d'identification du programme)|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Schéma d’identification de programme à utiliser pour l’exportation.|
|`programStageIdScheme` (Schéma d'identification d'étape de programme)|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Schéma d’identification d'étape de programme à utiliser pour l’exportation.|
|`idScheme` (Schéma d'identification)|`chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Permet de définir le schéma d'identification  à la fois pour l'élément de données, la combinaison d'options de catégorie, l'unité d'organisation, le programme et l'étape de programme.|
|`ordre`|`Chaîne`|comma-delimited list of `OrderCriteria` in the form of `propName:sortDirection`.<br><br> Example: `createdAt:desc`<br><br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive|Sort the response based on given `OrderCriteria`|
|`événement`|`Chaîne`|liste d'`uid` délimités par des virgules| Filtre le résultat pour obtenir un ensemble limité d’identifiants en utilisant event=id1;id2.|
|`skipEventId` (ignorer l'identifiant de l'élément)|`Booléen`| | Ignore les identifiants d'événement dans la réponse|
|`attributeCc` (voir la note)|`Chaîne`| Identifiant de la combinaison de catégories d'attribut (doit être combiné aux options de catégorie d'attribut (attributCos))|
|`attributeCos` (voir la note)|`Chaîne`| Identifiants d'options de catégorie d'attribut, séparés par ";"(doit être combiné à la combinaison de catégories d'attribut (attributeCc))|
|`includeDeleted` (inclure les éléments supprimés)|`Booléen`| |  S'il est défini sur "vrai", les événements supprimés mais pas définitivement seront inclus dans le résultat de votre requête.|
|`assignedUserMode` (mode utilisateur attribué)|`Chaîne`| `CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`| Mode de sélection de l'utilisateur assigné|
|`assignedUser` (utilisateur attribué)|`Chaîne`|liste d'`uid` délimités par des virgules| Il est possible de filtrer le résultat pour obtenir un ensemble limité d'événements qui sont attribués aux UID donnés, à l'aide du paramètre `assignedUser=id1;id2`. <br><br>Ce paramètre ne sera pris en compte que si le "mode d'utilisateur assigné" est `FOURNI` ou `nul`. <br><br>L'API va générer une erreur si, par exemple, `assignedUserMode=CURRENT` et `assignedUser=someId`|

> **Remarque**
>
> Si la requête ne contient ni `attributeCC` ni `attributeCos`,
> le serveur renvoie des événements pour toutes les combinaisons d'options d'attribut pour lesquelles l'utilisateur a un accès en lecture.

##### Exemples de requêtes { #example-requests }

La requête pour tous les événements ayant des subordonnées d'une unité d'organisation particulière :

    GET /api/tracker/events?orgUnit=YuQRtpLP10I&ouMode=CHILDREN

La requête pour tous les événements contenant tous les descendants d'une unité d'organisation donnée, c'est-à-dire toutes les unités d'organisation qui lui sont inférieurs dans la hiérarchie :

    GET /api/tracker/events?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS

La requête pour tous les événements disposant d'un programme et d'une unité d'organisation :

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

La requête pour tous les événements disposant d'un programme et d'une unité d'organisation, triés par date d'échéance en ordre croissant :

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=dueDate

La requête pour les 10 événements avec la date d'événement la plus récente dans un programme et une unité d'organisation - par pagination et ordonnés par date d'échéance en ordre décroissant :

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &order=eventDate:desc&pageSize=10&page=1

La requête pour tous les événements avec un programme et une unité d'organisation pour une instance d'entité suivie donnée :

    GET /api/tracker/events?orgUnit=DiszpKrYNg8
      &program=eBAyeGv0exc&trackedEntityInstance=gfVxE3ALA9m

La requête pour tous les événements avec un programme et une unité d'organisation plus ancien(ne) ou égal(e) au 03/02/2014 :

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&endDate=2014-02-03

La requête pour tous les événements avec une étape de programme, une unité d'organisation et une instance d'entité suivie de l'an 2014 :

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &trackedEntityInstance=gfVxE3ALA9m&occurredAfter=2014-01-01&occurredBefore=2014-12-31

Pour récupérer les événements avec l'unité d'organisation et le programme spécifiés, et utiliser l'`Attribut : Gq0oWTf2DtN` comme schéma d'identification

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN

Pour récupérer les événements avec l'unité d'organisation et le programme spécifiés, et utiliser l'UID comme schéma d'identification pour les unités d'organisation, le code comme schéma d'identification pour les étapes du programme, et _Attribute:Gq0oWTf2DtN_ comme schéma d'identification pour le reste des métadonnées avec les attributs assignés.

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN
      &orgUnitIdScheme=UID&programStageIdScheme=Code

##### Format de réponse { #response-format }

La réponse `JSON` peut ressembler à ceci :

```json
{
    "instances": [
        {
            "event": "rgWr86qs0sI",
            "status": "ACTIVE",
            "program": "kla3mAPgvCH",
            "programStage": "aNLq9ZYoy9W",
            "orgUnit": "DiszpKrYNg8",
            "orgUnitName": "Ngelehun CHC",
            "relationships": [],
            "occurredAt": "2021-10-12T00:00:00.000",
            "followup": false,
            "deleted": false,
            "createdAt": "2018-10-20T12:09:19.492",
            "updatedAt": "2018-10-20T12:09:19.492",
            "attributeOptionCombo": "amw2rQP6r6M",
            "attributeCategoryOptions": "RkbOhHwiOgW",
            "dataValues": [
                {
                    "createdAt": "2015-10-20T12:09:19.640",
                    "updatedAt": "2015-10-20T12:09:19.640",
                    "storedBy": "system",
                    "providedElsewhere": false,
                    "dataElement": "HyJL2Lt37jN",
                    "value": "12"
                },
              ...
            ],
            "notes": []
        }
    ],
    "page": 1,
    "pageSize": 1
}
```

La réponse `CSV` peut ressembler à ceci :

```
|event|status|program|programStage|enrollment|orgUnit|occurredAt|scheduledAt|dataElement|value|storedBy|providedElsewhere
|---|---|---|---|---|---|---|---|---|---|---|---|
|V1CerIi3sdL|COMPLETED|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|a3kGcGDCuk6|11|admin|false
|V1CerIi3sdL|COMPLETED|IpHINAT79UW|A03MvHHogjR|CCBLMntFuzb|DiszpKrYNg8|2020-02-26T23:00:00Z|2020-02-27T23:00:00Z|mB2QHw1tU96|[-11.566044,9.477801]|admin|false
```

#### Point d'extrémité d'objet unique d'événements `GET /api/tracker/events/{uid}`

Le but de ce point d'extrémité est de récupérer un événement en se basant sur son UID.

##### Syntaxe de la requête { #request-syntax }

`GET /api/tracker/events/{uid}?fields={fields}`

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`uid`|`Chaîne`|`uid`|Renvoie l'événement disposant de l'`uid` spécifié|
|`champs`|`Chaîne`| Tout filtre de champ valide (par défaut `*,!relationships`) |Inclut les sous-objets spécifiés dans la réponse| 

##### Exemples de requêtes { #example-requests }

Une requête pour un événement :

    GET /api/tracker/events/rgWr86qs0sI

##### Format de réponse { #response-format }

```json
{
  "event": "rgWr86qs0sI",
  "status": "ACTIVE",
  "program": "kla3mAPgvCH",
  "programStage": "aNLq9ZYoy9W",
  "enrollment": "Lo3SHzCnMSm",
  "enrollmentStatus": "ACTIVE",
  "orgUnit": "DiszpKrYNg8",
  "orgUnitName": "Ngelehun CHC",
  "relationships": [],
  "occurredAt": "2021-10-12T00:00:00.000",
  "followup": false,
  "deleted": false,
  "createdAt": "2018-10-20T12:09:19.492",
  "createdAtClient": "2017-10-20T12:09:19.492",
  "updatedAt": "2018-10-20T12:09:19.492",
  "attributeOptionCombo": "amw2rQP6r6M",
  "attributeCategoryOptions": "RkbOhHwiOgW",
  "dataValues": [
    {
      "createdAt": "2015-10-20T12:09:19.640",
      "updatedAt": "2015-10-20T12:09:19.640",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HyJL2Lt37jN",
      "value": "12"
    },
    {
      "createdAt": "2015-10-20T12:09:19.514",
      "updatedAt": "2015-10-20T12:09:19.514",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "b6dOUjAarHD",
      "value": "213"
    },
    {
      "createdAt": "2015-10-20T12:09:19.626",
      "updatedAt": "2015-10-20T12:09:19.626",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "UwCXONyUtGs",
      "value": "3"
    },
    {
      "createdAt": "2015-10-20T12:09:19.542",
      "updatedAt": "2015-10-20T12:09:19.542",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "fqnXmRYo5Cz",
      "value": "123"
    },
    {
      "createdAt": "2015-10-20T12:09:19.614",
      "updatedAt": "2015-10-20T12:09:19.614",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "Qz3kfeKgLgL",
      "value": "23"
    },
    {
      "createdAt": "2015-10-20T12:09:19.528",
      "updatedAt": "2015-10-20T12:09:19.528",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "W7aC8jLASW8",
      "value": "12"
    },
    {
      "createdAt": "2015-10-20T12:09:19.599",
      "updatedAt": "2015-10-20T12:09:19.599",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HrJmqlBqTFG",
      "value": "3"
    }
  ],
  "notes": []
}
```

### Inscriptions (`GET /api/tracker/enrollments`) { #enrollments-get-apitrackerenrollments }

Deux points d'extrémité sont dédiés aux inscriptions :

- `GET /api/tracker/enrollments`
    - récupère les inscriptions correspondant aux critères donnés
- `GET /api/tracker/enrollments/{id}`
    - récupère une inscription en fonction de l'identifiant fourni

#### Point d'extrémité de la collecte d'inscriptions `GET /api/tracker/enrollments` { #enrollment-collection-endpoint-get-apitrackerenrollments }

Renvoie une liste d'événements en fonction des filtres.

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`orgUnit` (unité d'organisation)|`Chaîne`|`uid`| Identifiant de l'unité d'organisation|
|Pour plus d'informations sur le `ouMode` (mode d'unité d'organisation) voir [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`Chaîne`| `SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL| Mode de sélection de l'unité d'organisation| 
|`programme`|`Chaîne`|`uid`| Identifiant du programme|
|`statut du programme`|`énumération`| `ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`| Statut du programme |
|`followUp` (suivi)|`booléen`| `vrai`, `faux` | Statut du suivi de l'instance du programme donné. Peut être `vrai`, `faux` ou omis.|
|`updatedAfter` (mis à jour après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Seules les inscriptions mises à jour après cette date|
|`updatedWithin`|`Durée`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Seules les inscriptions mises à jour depuis une durée donnée |
|`enrolledAfter` (inscrit après)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|  Seules les inscriptions plus récentes que cette date|
|`enrolledBefore` (inscrit avant)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Seules les inscriptions antérieures à cette date|
|`TrackedEntityType` (Type d'entité suivie)|`Chaîne`|`uid`| Identifiant du type d'entité suivie|
|`trackedEntity` (entité suivie)|`Chaîne`|`uid`| Identifiant de l'instance d'entité suivie|
|`inscription`|`Chaîne`|Liste d'`uid` délimités par des virgules| Filtre le résultat pour obtenir un ensemble limité d’identifiants en utilisant enrollement=id1;id2.|
|`includeDeleted` (inclure les éléments supprimés)|`Booléen`| |  S'il est défini sur "vrai", les événements supprimés mais pas définitivement seront inclus dans le résultat de votre requête.|

La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

- Au moins une unité d'organisation doit être spécifiée avec le paramètre `orgUnit`
  (un ou plusieurs), ou *ouMode=ALL* doit être spécifié.

- Un seul des paramètres *program* et *trackedEntity* peut être
  spécifié (zéro ou un).

- Si *programStatus* est spécifié, alors *program* doit également être
  spécifiés.

- Si *followUp* est spécifié, alors *program* doit également être spécifié.

- Si *enrolledAfter* ou *enrolledBefore* est spécifié, alors *program* doit également être spécifié.

##### Exemples de requêtes { #example-requests }

Une requête pour toutes les inscriptions associées à une unité d'organisation spécifique peut ressembler à ceci :

    GET /api/tracker/enrollments?orgUnit=DiszpKrYNg8

Pour limiter la réponse aux inscriptions qui font partie d'un programme spécifique, vous pouvez inclure un paramètre de requête de programme :

    GET /api/tracker/enrollments?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

Pour spécifier les dates d'inscription au programme dans la requête :

    GET /api/tracker/enrollments?&orgUnit=O6uvpzGd5pu&program=ur1Edk5Oe2n
      &enrolledAfter=2013-01-01&enrolledBefore=2013-09-01

Pour limiter la réponse aux inscriptions d'une entité suivie spécifique, vous pouvez inclure un paramètre de requête d'entité suivie :

    GET /api/tracker/enrollments?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

Pour limiter la réponse aux inscriptions d'une entité suivie spécifique, vous pouvez inclure un paramètre de requête d'instance d'entité suivie. Dans ce cas, nous avons limité la réponse aux inscriptions disponibles pour l'utilisateur actuel :

    GET /API/tracker/enrollments?ouMode=ACCESSIBLE&trackedEntity=tphfdyIiVL6

##### Format de réponse { #response-format }

La réponse `JSON` peut ressembler à ceci :

```json
{
  "instances": [
    {
      "enrollment": "iKaBMOyq7QQ",
      "createdAt": "2017-03-28T12:28:19.812",
      "createdAtClient": "2016-03-28T12:28:19.812",
      "updatedAt": "2017-03-28T12:28:19.817",
      "trackedEntity": "PpqV8ytvW5i",
      "trackedEntityType": "nEenWmSyUEp",
      "program": "ur1Edk5Oe2n",
      "status": "ACTIVE",
      "orgUnit": "NnQpISrLYWZ",
      "orgUnitName": "Govt. Hosp. Bonthe",
      "enrolledAt": "2020-10-23T12:28:19.805",
      "occurredAt": "2020-10-07T12:28:19.805",
      "followUp": false,
      "deleted": false,
      "events": [],
      "relationships": [],
      "attributes": [],
      "notes": []
    }
  ],
  "page": 1,
  "total": 1,
  "pageSize": 5
}
```

#### Point d'extrémité d'objet unique d'inscriptions `GET /api/tracker/enrollments/{uid}`

Le but de ce point d'extrémité est de récupérer une inscription en se basant sur son UID.

##### Syntaxe de la requête { #request-syntax }

`GET /api/tracker/enrollment/{uid}`

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`uid`|`Chaîne`|`uid`|Renvoie l'inscription disposant de l'`uid` spécifié|
|`champs`|`Chaîne`| Tout filtre de champ valide (par défaut `*,!relationships,!events,!attributes`) |Inclut les sous-objets spécifiés dans la réponse| 

##### Exemples de requêtes { #example-requests }

Une requête pour une inscription :

    GET /api/tracker/enrollments/iKaBMOyq7QQ

##### Format de réponse { #response-format }

```json
{
  "enrollment": "iKaBMOyq7QQ",
  "createdAt": "2017-03-28T12:28:19.812",
  "createdAtClient": "2016-03-28T12:28:19.812",
  "updatedAt": "2017-03-28T12:28:19.817",
  "trackedEntity": "PpqV8ytvW5i",
  "trackedEntityType": "nEenWmSyUEp",
  "program": "ur1Edk5Oe2n",
  "status": "ACTIVE",
  "orgUnit": "NnQpISrLYWZ",
  "orgUnitName": "Govt. Hosp. Bonthe",
  "enrolledAt": "2020-10-23T12:28:19.805",
  "occurredAt": "2020-10-07T12:28:19.805",
  "followUp": false,
  "deleted": false,
  "events": [],
  "relationships": [],
  "attributes": [],
  "notes": []
}
```

### Relations (`GET /api/tracker/relationships`) { #relationships-get-apitrackerrelationships }

Les relations sont des liens entre deux entités dans le Tracker.
Ces entités peuvent être des instances d'entités suivies, des inscriptions et des événements.

Le but de ce point d'extrémité est de récupérer les relations entre les objets.

Contrairement aux autres points d'extrémité d'objets suivis, les relations n'exposent qu'un seul point d'extrémité :

- `GET /api/tracker/relationships?[trackedEntity={trackedEntityUid}|enrollment={enrollmentUid}|event={eventUid}]&fields=[fields]`

#### Paramètres de requête { #request-parameters }

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`trackedEntity` (entité suivie)|`Chaîne`|`uid`| Identifiant d'une instance d'entité suivie|
|`inscription`|`Chaîne`|`uid`| Identifiant d'une inscription |
|`événement`|`Chaîne`|`uid`| Identifiant d'un événement|
|`champs`|`Chaîne`| Tout filtre de champ valide (par défaut `relationship,relationshipType,from[trackedEntity[trackedEntity],enrollment[enrollment],event[event]],to[trackedEntity[trackedEntity],enrollment[enrollment],event[event]]`) |Inclut les sous-objets spécifiés dans la réponse| 
|`ordre`|`Chaîne`|comma-delimited list of property name and sort direction pairs in format `propName:sortDirection`.|Champs pris en charge : `createdAt`.|

Les règles suivantes s'appliquent aux paramètres de requête.

- un seul paramètre parmi `trackedEntity`, `enrollment` et `event` peut être transmis

> **REMARQUE**
>
> L'utilisation des paramètres "tracked entity", "Enrollment" ou "Event" renverra toute relation à laquelle fait partie l'entité suivie, l'inscription ou l'événement (que ce soit 'à partir de' ou 'vers'), à condition que l'utilisateur y ait accès. 
> >

#### Exemple de réponse { #example-response }

```json
{
  "instances": [
    {
      "relationship": "SSfIicJKbh5",
      "relationshipType": "Mv8R4MPcNcX",
      "from": {
        "trackedEntity": {
          "trackedEntity": "neR4cmMY22o"
        }
      },
      "to": {
        "trackedEntity": {
          "trackedEntity": "rEYUGH97Ssd"
        }
      }
    },
    {
      "relationship": "S9kZGYPKk3x",
      "relationshipType": "Mv8R4MPcNcX",
      "from": {
        "trackedEntity": {
          "trackedEntity": "neR4cmMY22o"
        }
      },
      "to": {
        "trackedEntity": {
          "trackedEntity": "k8TU70vWtnP"
        }
      }
    }
  ],
  "page": 1,
  "pageSize": 2
}
```

## Contrôle de l'accès au Tracker { #webapi_nti_access_control }

Le Tracker a quelques concepts différents en ce qui concerne le contrôle d'accès, tels que le partage, les champs d'application des unités d'organisation, la propriété et les niveaux d'accès. Les sections suivantes fournissent une brève introduction aux différents sujets.

### Partage de métadonnées { #webapi_nti_metadata_sharing }


Le paramètre de partage est une fonctionnalité standard de DHIS2 qui s'applique aux métadonnées/données du Tracker et de l'Agrégé, ainsi qu'aux tableaux de bord et aux éléments de visualisation. Au cœur du partage se trouve la possibilité de définir qui peut voir/faire quoi. En général, il existe cinq configurations de partage possibles : aucun accès, lecture des métadonnées, écriture des métadonnées, lecture des données et écriture des données. Ces configurations d'accès peuvent être accordées au niveau de l'utilisateur et/ou du groupe d'utilisateurs (pour plus de flexibilité). En ce qui concerne le Tracker, les métadonnées suivantes et leur configuration de partage sont d'une importance particulière : Élément de données, option de catégorie, programme, étape de programme, type d'entité suivie, attribut d'entité suivie, ainsi que les tableaux de bord et les éléments de tableau de bord liés au Tracker.

Le fonctionnement des paramètres de partage est simple : les paramètres sont appliqués lors des processus d'importation/exportation des données Tracker. Pour lire des valeurs, il faut disposer d'un accès en lecture aux données. Un utilisateur qui souhaite modifier des données doit disposer d'un accès en écriture. De même, un utilisateur qui souhaite modifier des métadonnées doit disposer d'un accès en écriture aux métadonnées.

Un point essentiel concernant les données Tracker est la nécessité d'adopter une approche holistique.
Par exemple, un utilisateur ne pourra pas voir la valeur de l'élément de données s'il n'a accès qu'à l'élément de données en lecture. L'utilisateur doit disposer d'un accès en lecture aux données pour accéder au stade du programme parent et au programme auquel l'élément de données appartient. Il en va de même pour la combinaison d'options de catégorie. Dans Tracker, l'événement est lié à AttributeOptionCombo, qui se compose d'une combinaison d'options de catégorie. Par conséquent, pour qu'un utilisateur puisse lire les données d'un événement, il doit avoir un accès en lecture à toutes les options de catégorie et aux catégories correspondantes qui constituent la combinaison d'options d'attributs de l'événement en question. Si un utilisateur n'a pas accès à une seule option de catégorie ou à une seule catégorie, il n'a pas accès à l'ensemble de l'événement.

Lorsqu'il s'agit d'accéder aux données d'inscription, il est essentiel d'avoir d'abord accès à l'entité suivie. L'accès à une entité suivie est contrôlé par le partage des paramètres du programme, du type d'entité suivie et de l'attribut d'entité suivie. Une fois que l'on a accédé à l'inscription, il est possible d'accéder aux données d'événement, là encore en fonction de l'étape du programme et des paramètres de partage des éléments de données.

Un autre point essentiel à prendre en considération est la manière de définir l'accès aux différentes étapes d'un programme. Il peut arriver que nous devions accorder l'accès à une étape spécifique - par exemple, « Résultat de laboratoire » - à un groupe d'utilisateurs spécifique (techniciens de laboratoire). Dans ce cas, nous pouvons accorder un accès en écriture aux données de l'étape « Résultat du laboratoire », probablement un accès en lecture à une ou plusieurs étapes au cas où nous voudrions que les techniciens de laboratoire lisent d'autres résultats médicaux, ou aucun accès si nous pensons qu'il n'est pas nécessaire qu'ils consultent des données autres que celles relatives au laboratoire.

En résumé, DHIS2 dispose d'un paramètre de partage très précis que nous pouvons utiliser pour implémenter les mécanismes de contrôle d'accès au niveau des données et des métadonnées. Ces paramètres de partage peuvent être appliqués directement au niveau de l'utilisateur ou du groupe d'utilisateurs. Le paramètre de partage à appliquer dépend du cas d'utilisation.

Pour plus d'informations sur le partage de données, consultez [Partage de données](https://docs.dhis2.org/en/use/user-guides/dhis-core-version-master/configuring-the-system/about-sharing -of-objects.html#data-sharing-for-event-based-programs).

### Champs d'application des unités d'organisation { #webapi_nti_ou_scope }

Les unités d'organisation font partie des objets les plus fondamentaux de DHIS2. Elles définissent un univers dans lequel un utilisateur est autorisé à enregistrer et/ou à lire des données. Trois types d'unités d'organisation peuvent être attribués à un utilisateur. Il s'agit de la saisie de données, de la consultation de données et de la recherche Tracker. Comme leur nom l'indique, ces unités d'organisation définissent un champ d'application dans lequel un utilisateur est autorisé à effectuer les opérations requises.

Cependant, pour mieux affiner le champ d'application, DHIS2 Tracker introduit un concept que nous appelons **OrganisationUnitSelectionMode** (mode de sélection de l'unité d'organisation). Ce mode est souvent utilisé lors de l'exportation d'objets Tracker. Par exemple, si un utilisateur dispose d'un champ de recherche particulier, cela signifie-t-il que nous devons utiliser ce champ chaque fois que l'utilisateur tente de rechercher un objet Tracker, d'inscription ou d'événement ? Ou bien l'utilisateur souhaite-t-il limiter la recherche à l'unité d'organisation sélectionnée, ou à l'ensemble de l'unité d'organisation de saisie, etc.

Les utilisateurs peuvent affiner un champ d'application en transmettant une valeur spécifique de ouMode (mode d'unité d'organisation) dans leur requête API :

*api/tracker/trackedEntities?orgUnit=UID&ouMode=specific_organisation_unit_selection_mode*

Actuellement, six modes de sélection sont disponibles : *SÉLECTIONNÉ, SUBORDONNÉES, DESCENDANTS, SAISIE, ACCESSIBLE et TOUS*.

1. **SÉLECTIONNÉ** : comme son nom l'indique, toutes les opérations prévues par l'API qui fait la requête se limitent à l'unité d'organisation sélectionnée.
2. **SUBORDONNÉES** : dans ce mode, le champ d'application de l'unité d'organisation sera construite avec l'unité d'organisation sélectionnée et ses subordonnés immédiats.
3. **DESCENDANTS** : ici, il s'agit de l'unité d'organisation sélectionnée et toutes les unités qui se trouvent en dessous de celle-ci, pas seulement les subordonnés immédiats.
4. **SAISIE** : comme le nom l'indique, il s'agit ici des unités d'organisation destinées à la saisie des données. Il convient de noter que, parmi les trois unités d'organisation pouvant être attribuées à un utilisateur, celle de la saisie de données est obligatoire. Si un utilisateur ne dispose pas d'unités d'organisation pour la visualisation des données et pour la recherche Tracker, le système reviendra à la saisie des données. De cette manière, nous sommes toujours sûrs que l'utilisateur possède au moins un univers.
5. **ACCESSIBLE** : techniquement, il s'agit du même champ d'application que les unités d'organisation de recherche Tracker de l'utilisateur.
6. **TOUS** : "TOUS" s'applique parfaitement aux superutilisateurs. Pour ces derniers, ce champ d'application désigne toutes les unités d’organisation disponibles dans le système. Cependant, pour les non-superutilisateurs, TOUS se limite aux unités d'organisation ACCESSIBLES.

Il n'est pas judicieux de transmettre ces modes lors des opérations d'importation du Tracker. En effet, lors de l'écriture des données Tracker, chaque objet doit être rattaché à une unité d'organisation spécifique. Le système vérifiera alors si chacune des unités d'organisation mentionnées relève du champ d'application de la SAISIE. Si ce n'est pas le cas, le système rejettera simplement l'opération d'écriture.

Notez qu'il existe quatre types d'associations d'unités d'organisation pour les objets Tracker. Une entité suivie a une unité d'organisation, communément appelée unité d'organisation d'enregistrement. Les inscriptions ont une unité d'organisation qui leur est associée, pareil pour les événements. Pour finir, il existe également une unité d'organisation "propriétaire" pour une combinaison Entité Suivie-Programme. 

Lors de la récupération des objets Tracker, selon le contexte, le champ d'application de l'unité d'organisation est appliquée à l'une des quatre associations d'unités d'organisation ci-dessus.

Par exemple, lors de la récupération d'entités suivies en dehors d'un programme, le champ d'application de l'unité d'organisation est appliquée à l'unité d'organisation d'enregistrement de l'entité suivie. Par contre, lors de la récupération d'entités suivies, en plus de données de programme spécifiques, le champ d'application de l'unité d'organisation est appliquée à l'unité d'organisation "propriétaire".

  * **Explique leur lien avec la propriété - Lien vers la propriété du programme**

### Propriété du programme Tracker { #webapi_nti_ownership }

Un nouveau concept appelé Propriété du Tracker est introduit depuis la version 2.30. Il s'agit d'une nouvelle association d'unités d'organisation pour une combinaison Entité Suivie - Programme.
Nous l'appelons l'Unité d'Organisation Propriétaire d'une Entité Suivie dans le cadre d'un Programme.
L'unité d'organisation Propriétaire est utilisée pour définir les accès lors de la lecture et de l'écriture des données Tracker associées à un programme.
Cette unité d'organisation, conjointement avec la configuration [Niveau d'accès](#webapi_nti_access_level) du programme, décide de l'accès aux données liées au programme (inscriptions et événements). 
Un utilisateur peut accéder aux données du programme d'une entité suivie si l'unité d'organisation propriétaire correspondante pour cette combinaison 'Entité suivie-Programme' se trouve dans le champ d'application de l'unité d'organisation de l'utilisateur (Recherche/Saisie). Pour les programmes configurés avec le niveau d'accès *OUVERT* ou *AUDITÉ*, l'unité d'organisation propriétaire doit se trouver dans le champ d'application de recherche de l'utilisateur.
Pour les programmes configurés avec le niveau d'accès *PROTÉGÉ* ou * FERMÉ*, l'unité d'organisation propriétaire doit se trouver dans le champ d'application de saisie de l'utilisateur pour que ce dernier puisse accéder aux données de programme correspondantes pour l'entité suivie en question.

#### Remplacement de la propriété du Tracker : briser le verre { #webapi_nti_tracker_ownership_override }

Il est possible d'annuler temporairement ce privilège de propriété pour un programme configuré avec un niveau d'accès *PROTÉGÉ*. Tout utilisateur sera en mesure d'obtenir temporairement l'accès aux données relatives au programme si l'utilisateur fournit une raison d'accéder aux données de la combinaison Entité suivie - Programme. Ce fait d'obtenir temporairement l'accès est appelé *briser le verre*. Actuellement, l'accès temporaire est accordé pour une durée de trois heures. DHIS2 vérifie l'aspect "briser le verre" ainsi que la raison fournie par l'utilisateur. Il n'est pas possible d'obtenir un accès temporaire à un programme qui a été configuré avec un niveau d'accès *Fermé*. Pour briser le verre d'une combinaison Entité suivie - Programme, la requête POST suivante peut être utilisée :

    /API/33/tracker/ownership/override?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&reason=patient+showed+up+for+emergency+care

#### Transfert de la propriété du Tracker { #webapi_nti_tracker_ownership_transfer }

Il est possible de transférer la propriété d'une combinaison Entité suivie - Programme d'une unité d'organisation à une autre. Cela peut s'avérer utile en cas de transfert de patients ou de migration. Seul un utilisateur disposant d'un accès à la propriété (ou d'un accès temporaire en brisant la glace) peut transférer la propriété. Pour transférer la propriété d'une combinaison Entité suivie - Programme à une autre unité d'organisation, la requête "PUT" suivante peut être utilisée :

    /API/33/tracker/ownership/transfer?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&ou=EJNxP3WreNP


### Niveau d'accès { #webapi_nti_access_level }

DHIS2 traite les données Tracker avec un niveau de protection supplémentaire. En plus de la protection standard des métadonnées et des données via les paramètres de partage, les données Tracker sont protégées par des mécanismes supplémentaires en matière de niveau d'accès. Actuellement, quatre niveaux d'accès peuvent être configurés pour un programme : Ouvert, Audité, Protégé et Fermé.

Ces niveaux d'accès ne sont déclenchés que lorsque les utilisateurs tentent d'interagir avec les données du programme, c'est-à-dire les données relatives aux inscriptions et aux événements. La configuration des différents niveaux d'accès du programme correspond à un degré d'ouverture (ou de fermeture) des données du programme. Notez que tous les autres paramètres de partage sont toujours respectés et que le niveau d'accès n'est qu'une couche supplémentaire de contrôle d'accès. Voici une brève description des quatre niveaux d'accès qui peuvent être configurés pour un programme. 

1. Ouvert : Ce niveau d'accès est le moins restrictif des niveaux d'accès. Les utilisateurs peuvent accéder aux données d'un programme OUVERT et les modifier si l'unité d'organisation propriétaire fait partie du champ de recherche de l'utilisateur. Avec ce niveau d'accès, il est possible d'accéder à des données qui se trouvent hors du champ de saisie et de les modifier sans justification ni conséquence. 
2.  Audité : Il s'agit du même niveau d'accès que le niveau Ouvert. La différence est que le système ajoutera automatiquement une entrée dans le journal d'audit sur les données auxquelles l'utilisateur accède.
3.  Protégé : Ce niveau d'accès est légèrement plus restreint. Les données contenues dans un programme PROTÉGÉ ne peuvent être consultées par les utilisateurs que si l'unité d'organisation propriétaire fait partie du champ de saisie de l'utilisateur donnée. Cependant, un utilisateur qui n'a que l'unité d'organisation propriétaire dans son champ de recherche peut en obtenir la propriété temporaire en [brisant la glace] (#webapi_nti_tracker_ownership_override). L'utilisateur doit fournir une justificla raison pour laquelle il accède aux données en question. Le système enregistre alors la justification et l'audit d'accès et accorde à l'utilisateur un accès temporaire de 3 heures. Notez que si le concept "briser la glace" est appliqué, l'unité d'organisation propriétaire reste inchangée et seul l'utilisateur qui a brisé la glace bénéficie de l'accès temporaire. 
4.  Fermé : Il s'agit du niveau d'accès le plus restreint. Les données enregistrées pour le compte de programmes configurés avec le niveau d'accès FERMÉ ne seront pas accessibles si l'unité d'organisation propriétaire n'est pas dans le champ de saisie de l'utilisateur. Il est également impossible de briser la vitre ou d'obtenir une propriété temporaire dans cette configuration. Notez qu'il est toujours possible de transférer la propriété à une autre unité d'organisation. Seul un utilisateur ayant accès à ces données peut transférer la propriété d'une combinaison Entité Suivie - Programme à une autre unité d'organisation. Si la propriété est transférée, l'unité d'organisation propriétaire est mise à jour.


# Adresses électronique { #email } 

## Adresses électronique { #webapi_email } 

The Web API features a resource for sending emails. For emails to be
sent it is required that the SMTP configuration has been properly set up
and that a system notification email address for the DHIS2 instance has
been defined. You can set SMTP settings from the email settings screen
and system notification email address from the general settings screen
in DHIS2.

    /api/33/email

### System notification { #webapi_email_system_notification } 

The *notification* resource lets you send system email notifications
with a given subject and text in JSON or XML. The email will be sent to
the notification email address as defined in the DHIS2 general system
settings:

```json
{
  "subject": "Integrity check summary",
  "text": "All checks ran successfully"
}
```

You can send a system email notification by posting to the notification
resource like this:

```bash
curl -d @email.json "localhost/api/33/email/notification" -X POST
  -H "Content-Type:application/json" -u admin:district
```

### Outbound emails { #outbound-emails } 

You can also send a general email notification by posting to the
notification resource as mentioned below. `F_SEND_EMAIL` or `ALL`
authority has to be in the system to make use of this api. Subject
parameter is optional. "DHIS 2" string will be sent as default subject
if it is not provided in url. Url should be encoded in order to use this
API.

```bash
curl "localhost/api/33/email/notification?recipients=xyz%40abc.com&message=sample%20email&subject=Test%20Email"
  -X POST -u admin:district
```

### Test message { #webapi_email_test_message } 

To test whether the SMTP setup is correct by sending a test email to
yourself you can interact with the *test* resource. To send test emails
it is required that your DHIS2 user account has a valid email address
associated with it. You can send a test email like this:

```bash
curl "localhost/api/33/email/test" -X POST -H "Content-Type:application/json" -u admin:district
```






# Data store { #data-store } 

## Data store { #webapi_data_store } 

Using the *dataStore* resource, developers can store arbitrary data for
their apps. Access to a datastore's key is based on its sharing settings.
By default all keys created are publicly accessible (read and write).
Additionally,  access to a datastore's namespace is limited to the user's
access to the corresponding app, if the app has reserved the namespace.
For example a user with access to the "sampleApp" application will also
be able to use the sampleApp namespace in the datastore. If a namespace
is not reserved, no specific access is required to use it.

    /api/33/dataStore

Note that there are reserved namespaces used by the system that require 
special authority to be able to read or write entries. 
For example the namespace for the android settings app `ANDROID_SETTINGS_APP`
will require `F_METADATA_MANAGE` authority.

### Data store structure { #webapi_data_store_structure } 

Data store entries consist of a namespace, key and value. The
combination of namespace and key is unique. The value data type is JSON.

Table: Data store structure

| Élément | Description | Type de données |
|---|---|---|
| Espace de noms | Namespace for organization of entries. | Chaîne |
| Clé | Key for identification of values. | Chaîne |
| Valeur | Value holding the information for the entry. | JSON |
| Encrypted | Indicates whether the value of the given key should be encrypted | Booléen |

### Get keys and namespaces { #webapi_data_store_get_keys_and_namespaces } 

For a list of all existing namespaces:

    GET /api/33/dataStore

Example curl request for listing:

```bash
curl "play.dhis2.org/demo/api/33/dataStore" -u admin:district
```

Example response:

```json
[
  "foo",
  "bar"
]
```

For a list of all keys in a namespace:

    GET /api/33/dataStore/<namespace>

Example curl request for listing:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -u admin:district
```

Example response:

```json
[
  "key_1",
  "key_2"
]
```

To retrieve a value for an existing key from a namespace:

    GET /api/33/dataStore/<namespace>/<key>

Example curl request for retrieval:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1"-u admin:district
```

Example response:

```json
{
  "foo":"bar"
}
```

To retrieve meta-data for an existing key from a namespace:

    GET /api/33/dataStore/<namespace>/<key>/metaData

Example curl request for retrieval:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1/metaData" -u admin:district
```

Example response:

```json
{
  "id": "dsKeyUid001", 
  "created": "...",
  "user": {...},
  "namespace": "foo",
  "key": "key_1"
}
```


### Query API { #query-api } 
The query API is allows you to query and filter values over all keys in a namespace. The `fields` parameter is used to specify the query. This is useful for retrieving specific values of keys across a namespace in a single request. 

    GET /api/dataStore/<namespace>?fields=

The list of `fields` can be:

* empty: returns just the entry keys
* `.`: return the root value as stored
* comma separated list of paths: `<path>[,<path>]`; each `<path>` can be a simple property name (like `age`) or a nested path (like `person.age`) 

Furthermore, entries can be filtered using one or more `filter` parameters 
and sorted using the `order` parameter. 

Multiple filters can be combined using `rootJunction=OR` (default) or `rootJunction=AND`. 

All details on the `fields`, `filter` and `order` parameters are given in the following sections.

#### Paging { #paging } 
By default, results use paging. Use `pageSize` and `page` to adjust size and offset. 
The parameter `paging=false` can be used to opt-out and always return all matches. 
This should be used with caution as there could be many entries in a namespace. The default page size is 50.

    GET /api/dataStore/<namespace>?fields=.&page=2&pageSize=10

When paging is turned off, entries are returned as plain result array as the root JSON structure. The same effect can be achieved while having paged results by using `headless=true`.

```json
{
  "pager": { ... },
  "entries": [...]
}
```
vs.
```json
[...]
```

#### Value extraction { #value-extraction } 
The data store allows extracting entire simple or complex values 
as well as the extraction of parts of complex JSON values.

> **Note**
> 
> For clarity of the examples the responses shown mostly omit the outermost object with the `pager` information
> and the `entries` array that the examples show.

To filter a certain set of fields add a `fields` parameter to the namespace 
query:

    GET /api/dataStore/<namespace>?fields=name,description

This returns a list of all entries having a non-null `name` and/or a 
`description` field like in the following example:

```json
[
  {"key": "key1", "name": "name1", "description": "description1"},
  {"key": "key2", "name": "name2", "description": "description2"}
]
```

If for some reason we even want entries where none of the extracted fields 
is non-null contained in the result list the `includeAll` parameter can be 
added:

    GET /api/dataStore/<namespace>?fields=name,description&includeAll=true

The response now might look like this:

```json
[
  {"key": "key1", "name": "name1", "description": "description1"},
  {"key": "key2", "name": "name2", "description": "description2"},
  {"key": "key3", "name": null, "description": null},
  {"key": "key4", "name": null, "description": null}
]
```

The extraction is not limited to simple root level members but can pick 
nested members as well by using square brackets after a members name:

    GET /api/dataStore/<namespace>?fields=name,root[child1,child2]

The example response could look like this:

```json
[
  { "key": "key1", "name": "name1", "root": {"child1": 1, "child2": []}},
  { "key": "key2", "name": "name2", "root": {"child1": 2, "child2": []}}
]
```

The same syntax works for nested members:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3]]]

Example response here:

```json
[
  { "key": "key1", "root": {"level1": {"level2": {"level3": 42}}}},
  { "key": "key1", "root": {"level1": {"level2": {"level3": 13}}}}
]
```

When such deeply nested values are extracted we might not want to keep the 
structure but extract the leaf member to a top level member in the response.
Aliases can be used to make this happen. An alias can be placed anywhere 
after a member name using round brackets containing the alias name like so:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3(my-prop)]]]

The response now would look like this:

```json
[
  { "key": "key1", "my-prop": 42},
  { "key": "key2", "my-prop": 13}
]
```

If the full path should be kept while giving an alias to a nested member the 
parent path needs to be repeated using dot-syntax to indicate the nesting.
This can also be used to restructure a response in a new different structure 
like so:

    GET /api/dataStore/<namespace>?fields=root[level1[level2[level3(my-root.my-prop)]]]

The newly structured response now looks like this:

```json
[
  { "key": "key1", "my-root": {"my-prop": 42}},
  { "key": "key2", "my-root": {"my-prop": 13}}
]
```

OBS! An alias cannot be used to rename an intermediate level. However, an alias
could be used to resolve a name collision with the `key` member.

    GET /api/dataStore/<namespace>?fields=id,key(value-key)

```json
[
  { "key": "key1", "id": 1, "value-key": "my-key1"},
  { "key": "key2", "id": 2, "value-key": "my-key2"}
]
```

### Sorting results { #sorting-results } 
Results can be sored by a single property using the `order=<path>[:direction]` parameter.
This can be any valid value `<path>` or the entry key (use `_` as path).

By default, sorting is alphanumeric assuming the value at the path is a string of mixed type.

For example to extract the name property and also sort the result by it use:

    GET /api/dataStore/<namespace>?fields=name&order=name

To switch to descending order use `:desc`:

    GET /api/dataStore/<namespace>?fields=name&order=name:desc

Sometimes the property sorted by is numeric so alphanumeric interpretation would be confusing.
In such cases special ordering types `:nasc` and `:ndesc` can be used.

In summary, order can be one of the following:

* `asc`: alphanumeric ascending order
* `desc:`: alphanumeric descending order
* `nasc`: numeric ascending order
* `ndesc`: numeric descending order

> **OBS!**
> 
> When using numeric order all matches must have a numeric value for the property at the provided `<path>`.

### Filtering entries { #filtering-entries } 
To filter entries within the query API context add one or more `filter` parameters
while also using the `fields` parameter.

Each `filter` parameter has the following form:

* unary operators: `<path>:<operator>`
* binary operators: `<path>:<operator>:<value>`
* set operators: `<path>:<operator>:[<value>,<value>,...]`

Unary operators are:

| Opérateur | Description |
| -------- | ----------- |
| `nul`   | value is JSON `null` |
| `!nul`  | value is defined but different to JSON `null` |
| `vide`  | value is an empty object, empty array or JSON string of length zero |
| `!vide` | value is different to an empty object, empty array or zero length string |

Binary operators are:

| Opérateur | Description |
| -------- | ----------- |
| `eq`     | value is equal to the given boolean, number or string |
| `!eq`, `ne`, `neq` | value is not equal to the given boolean, number or string |
| `lt`     | value is numerically or alphabetically less than the given number or string |
| `le`     | value is numerically or alphabetically less than or equal to the given number or string |
| `gt`     | value is numerically or alphabetically greater than the given number or string |
| `ge`     | value is numerically or alphabetically greater than or equal to the given number or string |

Text pattern matching binary operators are:

| Opérateur | Case Insensitive |  Description |
| -------- | ---------------- | ----------- |
| `like`   | `ilike`          | value matches the text pattern given |
| `!like`  | `!ilike`         | value does not match the text pattern given |
| `$like`  | `$ilike`, `startswith`   | value starts with the text pattern given |
| `!$like` | `!$ilike`, `!startswith` | value does not start with the text pattern given |
| `like$`  | `ilike$`, `endswith`     | value ends with the text pattern given |
| `!like$` | `!ilike$`, `!endswith`   | value does not end with the text pattern given |

For operators that work for multiple JSON node types the semantic is determined from the provided value.
If the value is `true` or `false` the filter matches boolean JSON values.
If the value is a number the filter matches number JSON values.
Otherwise, the value matches string JSON values or mixed types of values.

> **Tip**
>
> To force text comparison for a value that is numeric quote the value in single quotes.
> For example, the value `'13'` is the text 13 while `13` is the number 13.  

Set operators are:

| Opérateur | Description |
| -------- | ----------- |
| `in`     | entry value is textually equal to one of the given values (is in set) |
| `!in`    | entry value is not textually equal to any of the given values (is not in set) |

The `<path>` can be:

* `_`: the entry key is
* `.`: the entry root value is
* `<member>`: the member of the root value is
* `<member>.<member>`: the member at the path is (up to 5 levels deep)

A `<member>` path expression can be a member name or in case of arrays an array index.
In case of an array the index can also be given in the form: `[<index>]`.
For example, the path `addresses[0].street` would be identical to `addresses.0.street`.

Some example queries are found below.

Name (of root object) is "Luke":

    GET /api/dataStore/<namespace>?fields=.&filter=name:eq:Luke

Age (of root object) is greater than 42 (numeric):

    GET /api/dataStore/<namespace>?fields=.&filter=age:gt:42

Root value is a number greater than 42 (numeric matching inferred from the value):

    GET /api/dataStore/<namespace>?fields=.&filter=.:gt:42

Enabled (of root object) is true (boolean matching inferred from the value):

    GET /api/dataStore/<namespace>?fields=.&filter=enabled:eq:true

Root object has name containing "Pet" and has an age greater than 20:

    GET /api/dataStore/<namespace>?fields=.&filter=name:like:Pet&filter=age:gt:20

Root object is either flagged as minor or has an age less than 18:

    GET /api/dataStore/<namespace>?fields=.&filter=minor:eq:true&filter=age:lt:18&rootJunction=or

### Create values { #webapi_data_store_create_values } 

To create a new key and value for a namespace:

    POST /api/33/dataStore/<namespace>/<key>

Example curl request for create, assuming a valid JSON payload:

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X POST
  -H "Content-Type: application/json" -d "{\"foo\":\"bar\"}" -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'key_1' created."
}
```

If you require the data you store to be encrypted (for example user
credentials or similar) you can append a query to the url like this:

    GET /api/33/dataStore/<namespace>/<key>?encrypt=true

### Update values { #webapi_data_store_update_values } 

To update a key that exists in a namespace:

    PUT /api/33/dataStore/<namespace>/<key>

Example curl request for update, assuming valid JSON payload:

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X PUT -d "[1, 2, 3]"
  -H "Content-Type: application/json" -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' updated."
}
```

### Delete keys { #webapi_data_store_delete_keys } 

To delete an existing key from a namespace:

    DELETE /api/33/dataStore/<namespace>/<key>

Example curl request for delete:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X DELETE -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' deleted from namespace 'foo'."
}
```

To delete all keys in a namespace:

    DELETE /api/33/dataStore/<namespace>

Example curl request for delete:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -X DELETE -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Namespace 'foo' deleted."
}
```

### Sharing data store keys { #webapi_data_store_sharing } 

Sharing of data store keys follows the same principle as for other metadata sharing (see
[Sharing](#webapi_sharing)).

To get sharing settings for a specific data store key:

    GET /api/33/sharing?type=dataStore&id=<uid>

Where the id for the data store key comes from the `/metaData` endpoint for that key:

    GET /api/33/dataStore/<namespace>/<key>/metaData

To modify sharing settings for a specific data store key:

    POST /api/33/sharing?type=dataStore&id=<uid>

with the following request:

```json
{
  "object": {
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userAccesses": [],
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

## User data store { #webapi_user_data_store } 

In addition to the *dataStore* which is shared between all users of the
system, a user-based data store is also available. Data stored to the
*userDataStore* is associated with individual users, so that each user
can have different data on the same namespace and key combination. All
calls against the *userDataStore* will be associated with the logged in
user. This means one can only see, change, remove and add values
associated with the currently logged in user.

    /api/33/userDataStore

### User data store structure { #webapi_user_data_store_structure } 

*userDataStore* consists of a user, a namespace, keys and associated
values. The combination of user, namespace and key is unique.

Table: User data store structure

| Élément | Description | Data Type |
|---|---|---|
| Utilisateur | The user this data is associated with | Chaîne |
| Espace de noms | The namespace the key belongs to | Chaîne |
| Clé | The key a value is stored on | Chaîne |
| Valeur | The value stored | JSON |
| Encrypted | Indicates whether the value should be encrypted | Booléen |

### Get namespaces { #webapi_user_data_store_get_namespaces } 

Returns an array of all existing namespaces

    GET /api/33/userDataStore

Example
    request:

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore"
```

```json
[
  "foo",
  "bar"
]
```

### Get keys { #webapi_user_data_store_get_keys } 

Returns an array of all existing keys in a given namespace

    GET /api/userDataStore/<namespace>

Example request:

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
[
  "key_1",
  "key_2"
]
```

### Get values { #webapi_user_data_store_get_values } 

Returns the value for a given namespace and key

    GET /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "some": "value"
}
```

### Create value { #webapi_user_data_store_create_values } 

Adds a new value to a given key in a given namespace.

    POST /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -X POST -H "Content-Type: application/json" -u admin:district -d "['some value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'bar' in namespace 'foo' created."
}
```

If you require the value to be encrypted (For example user credentials
and such) you can append a query to the url like this:

    GET /api/33/userDataStore/<namespace>/<key>?encrypt=true

### Update values { #webapi_user_data_store_update_values } 

Updates an existing value

    PUT /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -X PUT -H "Content-Type: application/json" -u admin:district -d "['new value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"Created",
  "httpStatusCode":201,
  "status":"OK",
  "message":"Key 'bar' in namespace 'foo' updated."
}
```

### Delete key { #webapi_user_data_store_delete_key } 

Delete a key

    DELETE /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"Key 'bar' deleted from the namespace 'foo."
}
```

### Delete namespace { #webapi_user_data_store_delete_namespace } 

Delete all keys in the given namespace

    DELETE /api/33/userDataStore/<namespace>

Example request:

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"All keys from namespace 'foo' deleted."
}
```






# Organisation unit profile { #org_unit_profile }

The organisation unit profile resource allows you to define and retrieve an information profile for organisation units in DHIS 2.

```
/api/organisationUnitProfile
```

A single organisation unit profile can be created and applies to all organisation units.

The information part of the organisation unit profile includes:

- Name, short name, description, parent organisation unit, level, opening date, closed date, URL.
- Contact person, address, email, phone number (if exists).
- Location (longitude/latitude).
- Metadata attributes (configurable).
- Organisation unit group sets and groups (configurable).
- Aggregate data for data elements, indicators, reporting rates, program indicators (configurable).

## Create organisation unit profile { #create-organisation-unit-profile } 

To define the organisation unit profile you can use a `POST` request:

```
POST /api/organisationUnitProfile
```

The payload in JSON format looks like this, where `attributes` refers to metadata attributes,  `groupSets` refer to organisation unit group sets and `dataItems` refers to data elements, indicators, data sets and program indicators:

```json
{
  "attributes": [
    "xqWyz9jNCA5",
    "n2xYlNbsfko"
  ],
  "groupSets": [
    "Bpx0589u8y0",
    "J5jldMd8OHv"
  ],
  "dataItems": [
    "WUg3MYWQ7pt",
    "vg6pdjObxsm",
    "DTVRnCGamkV",
    "Uvn6LCg7dVU",
    "eTDtyyaSA7f"
  ]
}
```

The `F_ORG_UNIT_PROFILE_ADD` authority is required to define the profile.

## Get organisation unit profile { #get-organisation-unit-profile } 

To retrieve the organisation unit profile definition you can use a `GET` request:

```
GET /api/organisationUnitProfile
```

The response will be in JSON format.

## Get organisation unit profile data { #get-organisation-unit-profile-data } 

To retrieve the organisation unit profile data you can use a `GET` request:

```
GET /api/organisationUnitProfile/{org-unit-id}/data?period={iso-period}
```

The organisation unit profile data endpoint will combine the profile definition with the associated information/data values. 

* The `org-unit-id` path variable is required and refers to the ID of the organisation unit to provide aggregated data for.
* The `iso-period` query parameter is optional and refers to the ISO period ID for the period to provide aggregated data for the data items. If none is specified, the _this year_ relative period will be used as fallback.

The response will include the following sections:

* `info`: Fixed information about the organisation unit.
* `attributes`: Metadata attributes with corresponding attribute values.
* `groupSets`: Organisation unit group sets with the corresponding organisation unit group which the organisation unit is a member of.
* `dataItems`: Data items with the corresponding aggregated data value.

Note that access control checks are performed and metadata items which are not accessible to the current user will be omitted.

Voici donc un exemple de requête :

```
GET /api/organisationUnitProfile/DiszpKrYNg8/data?period=2021
```

The profile data response payload in JSON format will look like this, where the `id` and `label` fields refer to the metadata item, and the `value` field refers to the associated value:

```json
{
  "info": {
    "id": "DiszpKrYNg8",
    "code": "OU_559",
    "name": "Ngelehun CHC",
    "shortName": "Ngelehun CHC",
    "parentName": "Badjia",
    "level": 4,
    "levelName": "Facility",
    "openingDate": "1970-01-01T00:00:00.000",
    "longitude": -11.4197,
    "latitude": 8.1039
  },
  "attributes": [
    {
      "id": "n2xYlNbsfko",
      "label": "NGO ID",
      "value": "GHE51"
    },
    {
      "id": "xqWyz9jNCA5",
      "label": "TZ code",
      "value": "NGE54"
    }
  ],
  "groupSets": [
    {
      "id": "Bpx0589u8y0",
      "label": "Facility Ownership",
      "value": "Public facilities"
    },
    {
      "id": "J5jldMd8OHv",
      "label": "Facility Type",
      "value": "CHC"
    }
  ],
  "dataItems": [
    {
      "id": "WUg3MYWQ7pt",
      "label": "Total Population",
      "value": 3503
    },
    {
      "id": "DTVRnCGamkV",
      "label": "Total population < 1 year",
      "value": 140
    },
    {
      "id": "vg6pdjObxsm",
      "label": "Population of women of child bearing age (WRA)",
      "value": 716
    },
    {
      "id": "Uvn6LCg7dVU",
      "label": "ANC 1 Coverage",
      "value": 368.2
    },
    {
      "id": "eTDtyyaSA7f",
      "label": "FIC <1y",
      "value": 291.4
    }
  ]
}
```

## Upload image for organisation unit { #upload-image-for-organisation-unit } 

To upload an image for an organisation unit you can use the `fileResources` endpoint.

```
/api/fileResources
```

The `fileResource` endpoint accepts a raw file as the request body. The `JPG`, `JPEG` and `PNG` formats are supported for organisation unit images. The domain for organisation unit images is `ORG_UNIT`.

Please consult *File resources* in the *Metadata* section for details about the `fileResources` endpoint. 

To upload an image you can send a `POST` request with `ORG_UNIT` as domain query parameter together with the image as the request payload. The `Content-Type` header should match the type of file being uploaded.

```
POST /api/fileResources?domain=ORG_UNIT
```

The `id ` property of the `response` > `fileResource` object in the JSON response will contain a reference to the identifier of the file resource.

The organisation unit entity has an `image` property which refers to the file resource image. To set the file resource reference on an organisation unit you can send a `PATCH` request to the organisation unit with a JSON payload:

```
PATCH /api/organisationUnits/{id}
```

```json
{ 
  "image": "{file-resource-id}" 
}
```

Alternatively, you can use a `PUT` request with the full organisation unit payload (fields omitted for brevity):

```
PUT /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-iid}"
  }
}
```

## Get image for organisation unit { #get-image-for-organisation-unit } 

The organisation unit entity has an `image` object which refers to a file resource by identifier. You can get the organisation unit information from the `organisationUnits` endpoint. If set, the JSON format looks like this:

```
GET /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-id}"
  }
}
```

The image file resource identifier can be used to make a request to the `fileResources` endpoint to retrieve the file content:

```
GET /api/fileResources/{id}/data
```

The `Content-Type` header will reflect the type of file being retrieved.



# Applications { #apps } 

## Applications { #webapi_apps } 

The `/api/apps` endpoint can be used for installing, deleting and
listing apps. The app key is based on the app name, but with all
non-alphanumerical characters removed, and spaces replaced with a dash.
*My app!* will return the key *My-app*.

> **Note**
>
> Previous to 2.28, the app key was derived from the name of the ZIP
> archive, excluding the file extension. URLs using the old format
> should still return the correct app in the api.

    /api/33/apps

### Get apps { #webapi_get_apps } 

> **Note**
>
> Previous to 2.28 the app property folderName referred to the actual
> path of the installed app. With the ability to store apps on cloud
> services, folderName's purpose changed, and will now refer to the app
> key.

You can read the keys for apps by listing all apps from the apps
resource and look for the *key* property. To list all installed apps in
JSON:

```bash
curl -u user:pass -H "Accept: application/json" "http://server.com/api/33/apps"
```

You can also simply point your web browser to the resource URL:

    http://server.com/api/33/apps

The apps list can also be filtered by app type and by name, by appending
one or more *filter* parameters to the URL:

    http://server.com/api/33/apps?filter=appType:eq:DASHBOARD_APP&filter=name:ilike:youtube

App names support the *eq* and *ilike* filter operators, while *appType*
supports *eq* only.

### Install an app { #webapi_install_app } 

To install an app, the following command can be issued:

```bash
curl -X POST -u user:pass -F file=@app.zip "http://server.com/api/33/apps"
```

### Delete an app { #webapi_delete_app } 

To delete an app, you can issue the following command:

```bash
curl -X DELETE -u user:pass "http://server.com/api/33/apps/<app-key>"
```

### Reload apps { #webapi_reload_apps } 

To force a reload of currently installed apps, you can issue the
following command. This is useful if you added a file manually directly
to the file system, instead of uploading through the DHIS2 user
interface.

```bash
curl -X PUT -u user:pass "http://server.com/api/33/apps"
```

### Share apps between instances { #webapi_share_apps_between_instances } 

If the DHIS2 instance has been configured to use cloud storage, apps
will now be installed and stored on the cloud service. This will enable
multiple instances share the same versions on installed apps, instead of
installing the same apps on each individual instance.

> **Note**
>
> Previous to 2.28, installed apps would only be stored on the instance's
> local filesystem. Apps installed before 2.28 will still be available on the
> instance it was installed, but it will not be shared with other
> instances, as it's still located on the instances local filesystem.

## App store { #webapi_app_store } 

The Web API exposes the content of the DHIS2 App Store as a JSON
representation which can found at the `/api/appHub` resource.

    /api/33/appHub

### Get apps { #webapi_get_app_store_apps } 

You can retrieve apps with a GET request:

    GET /api/33/appHub

A sample JSON response is described below.

```json
{
  [
    {
      "name": "Tabular Tracker Capture",
      "description": "Tabular Tracker Capture is an app that makes you more effective.",
      "sourceUrl": "https://github.com/dhis2/App-repository",
      "appType": "DASHBOARD_WIDGET",
      "status": "PENDING",
      "id": "NSD06BVoV21",
      "developer": {
        "name": "DHIS",
        "organisation": "Uio",
        "address": "Oslo",
        "email": "dhis@abc.com",
      },
      "versions": [
        {
          "id": "upAPqrVgwK6",
          "version": "1.2",
          "minDhisVersion": "2.17",
          "maxDhisVersion": "2.20",
          "downloadUrl": "https://dhis2.org/download/appstore/tabular-capture-12.zip",
          "demoUrl": "http://play.dhis2.org/demo"
        }
      ],
      "images": [
        {
          "id": "upAPqrVgwK6",
          "logo": "true",
          "imageUrl": "https://dhis2.org/download/appstore/tabular-capture-12.png",
          "description": "added feature snapshot",
          "caption": "dialog",
        }
      ]
    }
  ]
}
```

### Install apps { #webapi_install_app_store_apps } 

You can install apps on your instance of DHIS2 assuming you have the
appropriate permissions. An app is referred to using the `id` property
of the relevant version of the app. An app is installed with a POST
request with the version id to the following resource:

    POST /api/33/appHub/{app-version-id}

