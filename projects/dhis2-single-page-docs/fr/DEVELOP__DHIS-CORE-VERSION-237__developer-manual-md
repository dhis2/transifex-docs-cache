---
revision_date: '2023-01-13'
tags:
- Développement
- DHIS core version 2.37
template: single.html
---

# Aperçu { #webapi } 

The Web API is a component which makes it possible for external systems
to access and manipulate data stored in an instance of DHIS2. More
precisely, it provides a programmatic interface to a wide range of
exposed data and service methods for applications such as third-party
software clients, web portals and internal DHIS2 modules.

## Introduction { #webapi_introduction } 

The Web API adheres to many of the principles behind the REST
architectural style. To mention some few and important ones:

1.  The fundamental building blocks are referred to as *resources*. A
    resource can be anything exposed to the Web, from a document to a
    business process - anything a client might want to interact with.
    The information aspects of a resource can be retrieved or exchanged
    through resource *representations*. A representation is a view of a
    resource's state at any given time. For instance, the *reportTable*
    resource in DHIS2 represents a tabular report of aggregated data for
    a certain set of parameters. This resource can be retrieved in a
    variety of representation formats including HTML, PDF, and MS Excel.

2.  All resources can be uniquely identified by a *URI* (also referred
    to as *URL*). All resources have a default representation. You can
    indicate that you are interested in a specific representation by
    supplying an *Accept* HTTP header, a file extension or a *format*
    query parameter. So in order to retrieve the PDF representation of a
    report table you can supply an *Accept: application/pdf* header or
    append *.pdf* or *?format=pdf* to your request URL.

3.  Interactions with the API requires the correct use of HTTP *methods* or
    *verbs*. This implies that for a resource you must issue a *GET*
    request when you want to retrieve it, *POST* request when you want
    to create one, *PUT* when you want to update it and *DELETE* when
    you want to remove it. So if you want to retrieve the default
    representation of a report table you can send a GET request to e.g.
    */reportTable/iu8j/hYgF6t*, where the last part is the report table
    identifier.

4.  Resource representations are *linkable*, meaning that
    representations advertise other resources which are relevant to the
    current one by embedding links into itself (please be aware that you
    need to request *href* in your field filter to have this working.
    This feature greatly improves the usability and robustness of the
    API as we will see later. For instance, you can easily navigate to
    the indicators which are associated with a report table from the
    *reportTable* resource through the embedded links using your
    preferred representation format.

While all of this might sound complicated, the Web API is actually very
simple to use. We will proceed with a few practical examples in a
minute.

## Authentication { #webapi_authentication } 

The DHIS2 Web API supports three protocols for authentication: 

- [Basic Authentication](#webapi_basic_authentication)
- [Personal Access Tokens (PAT)](#webapi_pat_authentication)
- [OAuth 2](#webapi_oauth2)

You can verify and get information about the currently authenticated 
user by making a GET request to the following URL:

    /api/33/me

And more information about authorities (and if a user has a certain
authority) by using the endpoints:

    /api/33/me/authorities
    /api/33/me/authorities/ALL

## Basic Authentication { #webapi_basic_authentication } 

The DHIS2 Web API supports *Basic authentication*. Basic authentication
is a technique for clients to send login credentials over HTTP to a web
server. Technically speaking, the username is appended with a colon and
the password, Base64-encoded, prefixed Basic and supplied as the value
of the *Authorization* HTTP header. More formally that is:

    Authorization: Basic base64encode(username:password)

Most network-aware development environments provide support for Basic
authentication, such as *Apache HttpClient* and *Spring RestTemplate*.
An important note is that this authentication scheme provides no security
since the username and password are sent in plain text and can be easily
observed by an attacker. Using Basic is recommended only if the server is
using SSL/TLS (HTTPS) to encrypt communication with clients. Consider this
a hard requirement in order to provide secure interactions with the Web
API.

## Two-factor authentication { #webapi_2fa } 

DHIS2 supports two-factor authentication. This can be enabled per user.
When enabled, users will be asked to enter a 2FA code when logging in. You
can read more about 2FA [here](https://www.google.com/landing/2step/).

## Personal Access Token { #webapi_pat_authentication }
Les jetons d'accès personnels (PAT) sont une alternative à l'utilisation de mots de passe lors 
de l'authentification au système DHIS2 lorsque l'on utilise l'API.

PATs can be a more secure alternative to HTTP Basic Authentication,
and should be your preferred choice when creating a new app/script etc. 

HTTP Basic Authentication is considered insecure because, among other things, 
it sends your username and password in clear text. It may be deprecated in 
future DHIS2 versions or made opt-in, meaning that basic authentication would 
need to be explicitly enabled in the configuration.

#### Problèmes de sécurité majeurs ! { #important-security-concerns } 

Vos jetons hériteront automatiquement de toutes les permissions et autorisations dont dispose votre utilisateur. Il est donc extrêmement important de limiter l'accès que vous accordez à votre jeton en fonction de l'utilisation que vous comptez en faire, voir **Configurer votre jeton**.

**If you only want the token to have access to a narrow and specific part of the
server, it is advised to rather create a new special user that you assign only
the roles/authorities you want it to have access to.**


### Creating a token { #creating-a-token } 
To create a new PAT, you have two choices:
* A. Create a token in the UI on your account's profile page.
* B. Create a token via the API

### A. Creating a token on the account's page { #a-creating-a-token-on-the-accounts-page } 
Log in with your username and password, go to your profile page
(Click top right corner, and chose "Edit profile" from the dropdown).
On your user profile page, choose "Manage personal access tokens" from the
left side menu.
You should now be on the "Manage personal access tokens" page and see the
text: "You don't have any active personal access tokens".
Click "Generate new token" to make a new token.
A "Generate new token" popup will be shown and present you with two choices:

#### 1. Server/script context: { #1-serverscript-context } 
_"This type is used for integrations and scripts that won't be accessed by a browser"._

If you plan to use the token in an application, a script or similar, this
type should be your choice.

#### 2. Browser context: { #2-browser-context } 
_"This type us used for applications, like public portals, that will be accessed with a web browser"._

If you need to link to DHIS2 on a webpage, or e.g. embed in an iframe,
this is probably the type of token you want.


### Configuring your token { #configuring-your-token } 

After choosing what token type you want, you can configure different access constraints on
your token. By constraint, we mean how to limit and narrow down how your token can be used.
This can be of crucial importance if you plan on using the token in a public environment,
e.g. on a public dashboard on another site, embedded in an iframe.
Since tokens always have the same access/authorities that your user currently has, taking special 
care is needed if you intend to use it in any environment you don't have 100% control over.

**NB**: If anyone else gets their hands on your token, they can do anything your user can do. 
It is not possible to distinguish between actions performed using the token and other actions
performed by your user.

**Important**: It is strongly advised that you create a separate unique user with only the roles/authorities
you want the token to have if you plan on using PAT tokens in a non-secure and/or public environment,
e.g. on a PC or server, you don't have 100% control over, or "embedded" in a webpage on another server.

#### The different constraint types are as follows: { #the-different-constraint-types-are-as-follows } 
* Expiry time
* Allowed UP addresses
* Allowed HTTP methods
* Allowed HTTP referrers

##### Expiry time { #expiry-time } 
Expiry time simply sets for how long you want your token to be usable, the default is 30
days. After the expiry time, the token will simply return a 401 (Unauthorized) message.
You can set any expiry time you want, but it is strongly advised that you set an expiry time 
that is reasonable for your use case.

#### Allowed IP addresses { #allowed-ip-addresses } 
This is a comma-separated list of IP addresses you want to limit where the token requests can come from.

**Important**: IP address validation relies on the X-Forwarded-For header, which can be spoofed.
For security, make sure a load balancer or reverse proxy overwrites this header.

#### Allowed HTTP methods { #allowed-http-methods } 
A comma-separated list of HTTP methods you want your token to be able to use.
If you only need your token to view data, not modify or delete, selecting only the GET HTTP method 
makes sense.

#### Allowed HTTP referrers { #allowed-http-referrers } 
HTTP referer is a header added to the request, when you click on a link, this says which site/page 
you were on when you clicked the link. 
Read more about the HTTP referer header here: https://en.wikipedia.org/wiki/HTTP_referer

This can be used to limit the use of a "public" token embedded on another page on another site. 
Making sure that the referer header match the site hostname in should come from, can
help avoid abuse of the token, e.g. if someone posts it on a public forum.

**Important**: this is not a security feature. The `referer` header can easily be spoofed.
This setting is intended to discourage unauthorized third-party developers from connecting
to public access instances.

#### Saving your token: { #saving-your-token } 
When you are done configuring your token, you can save it by clicking the "Generate new token"
button, on the bottom right of the pop-up.
When doing so the token will be saved and a secret token key will be generated on the server.
The new secret token key will be shown on the bottom of the PAT token list with a green background,
and the text "Newly created token".
The secret token key will look similar to this:
```
d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```
**Important**: This generated secret token key will only be shown once, so it is important 
that you copy the token key now and save it in a secure place for use later. 
The secret token key will be securely hashed on the server, and only the hash of this secret token 
key will be saved to the database. This is done to minimize the security impact if someone gets 
unauthorized access to the database, similar to the way passwords are handled.

### B. Creating a token via the API { #b-creating-a-token-via-the-api } 

Example of how to create a new Personal Access Token with the API:

```
POST https://play.dhis2.org/dev/api/apiToken
Content-Type: application/json
Authorization: Basic admin district

{}
```
**NB**: Remember the empty JSON body (`{}`) in the payload! 

This will return a response containing a token similar to this:
```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "response": {
     "responseType": "ApiTokenCreationResponse",
     "key": "d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092",
     "uid": "jJYrtIVP7qU",
     "klass": "org.hisp.dhis.security.apikey.ApiToken",
     "errorReports": []
  }
}
```

**Important**: The token key will only be shown once here in this response.
You need to copy and save this is in a secure place for use later!

The token itself consists of three parts:
1. Prefix: (`d2pat_`) indicates what type of token this is.
2. Random bytes Base64 encoded: (`5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ`)
3. CRC32 checksum: (`1151814092`) the checksum part is padded with 0 so that it always stays ten characters long.


#### Configure your token via the API: { #configure-your-token-via-the-api } 
To change any of the constraints on your token, you can issue the following HTTP API request.

**NB**: Only the constraints are possible to modify after the token is created! 

```
PUT https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: Basic admin district
```

```json
{
  "version": 1,
  "type": "PERSONAL_ACCESS_TOKEN",
  "expire": 163465349603200,
  "attributes": [
      {
        "type": "IpAllowedList",
        "allowedIps": ["192.168.0.1"]
      },
      {
        "type": "MethodAllowedList",
        "allowedMethods": ["GET"]
      }
  ]
}
```

### Using your Personal Access Token { #using-your-personal-access-token } 

To issue a request with your newly created token, use the Authorization header
accordingly.
The Authorization header format is:
```
Autorisation : ApiToken [YOUR_SECRET_API_TOKEN_KEY]
```
**Example**:
```
GET https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


### Deleting your Personal Access Token { #deleting-your-personal-access-token } 
You can delete your PATs either in the UI on your profile page where you created it,
or via the API like this:
```
DELETE https://play.dhis2.org/dev/api/apiToken/jJYrtIVP7qU
Content-Type: application/json
Authorization: ApiToken d2pat_5xVA12xyUbWNedQxy4ohH77WlxRGVvZZ1151814092
```


## OAuth2 { #webapi_oauth2 } 

DHIS2 supports the *OAuth2* authentication protocol. OAuth2 is an open
standard for authorization which allows third-party clients to
connect on behalf of a DHIS2 user and get a reusable *bearer token* for
subsequent requests to the Web API. DHIS2 does not support fine-grained
OAuth2 roles but rather provides applications access based on user roles
of the DHIS2 user.

Each client for which you want to allow OAuth 2 authentication must be
registered in DHIS2. To add a new OAuth2 client go to `Apps > Settings > OAuth2 Clients`
in the user interface, click *Add new* and enter the desired client name and the grant types.

#### Adding a client using the Web API { #adding-a-client-using-the-web-api } 

An OAuth2 client can be added through the Web API. As an example, we can
send a payload like this:

```json
{
  "name": "OAuth2 Demo Client",
  "cid": "demo",
  "secret": "1e6db50c-0fee-11e5-98d0-3c15c2c6caf6",
  "grantTypes": [
    "password",
    "refresh_token",
    "authorization_code"
  ],
  "redirectUris": [
    "http://www.example.org"
  ]
}
```

The payload can be sent with the following command:

```bash
SERVER="https://play.dhis2.org/dev"
curl -X POST -H "Content-Type: application/json" -d @client.json
  -u admin:district "$SERVER/api/oAuth2Clients"
```

We will use this client as the basis for our next grant type examples.

#### Grant type password { #webapi_oauth2_password } 

The simplest of all grant types is the *password* grant type. This
grant type is similar to basic authentication in the sense that it
requires the client to collect the user's username and password. As an
example we can use our demo server:

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d grant_type=password -d username=admin -d password=district
```

This will give you a response similar to this:

```json
{
  "expires_in": 43175,
  "scope": "ALL",
  "access_token": "07fc551c-806c-41a4-9a8c-10658bd15435",
  "refresh_token": "a4e4de45-4743-481d-9345-2cfe34732fcc",
  "token_type": "bearer"
}
```

For now, we will concentrate on the `access_token`, which is what we
will use as our authentication (bearer) token. As an example, we will get
all data elements using our token:

```bash
SERVER="https://play.dhis2.org/dev"
curl -H "Authorization: Bearer 07fc551c-806c-41a4-9a8c-10658bd15435" "$SERVER/api/33/dataElements.json"
```

#### Grant type refresh\_token { #webapi_refresh_token } 

In general the access tokens have limited validity. You can have a look
at the `expires_in` property of the response in the previous example
to understand when a token expires. To get a fresh `access_token` you
can make another round trip to the server and use `refresh_token`
which allows you to get an updated token without needing to ask for the
user credentials one more time.

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"
REFRESH_TOKEN="a4e4de45-4743-481d-9345-2cfe34732fcc"

curl -X POST -H "Accept: application/json" -u demo:$SECRET "$SERVER/uaa/oauth/token"
  -d "grant_type=refresh_token" -d "refresh_token=$REFRESH_TOKEN"
```

The response will be exactly the same as when you get a token to start with.

#### Grant type authorization_code { #webapi_authorization_code } 

Authorized code grant type is the recommended approach if you don't want
to store the user credentials externally. It allows DHIS2 to collect the
username/password directly from the user instead of the client
collecting them and then authenticating on behalf of the user. Please be
aware that this approach uses the `redirectUris` part of the client
payload.

Step 1: Visit the following URL using a web browser. If you have more than one
redirect URIs, you might want to add `&redirect_uri=http://www.example.org`
to the URL:

```bash
SERVER="https://play.dhis2.org/dev"
$SERVER/uaa/oauth/authorize?client_id=demo&response_type=code
```

Step 2: After the user has successfully logged in and accepted your
client access, it will redirect back to your redirect uri like this:

    http://www.example.org/?code=XYZ

Step 3: This step is similar to what we did in the password grant type,
using the given code, we will now ask for an access token:

```bash
SERVER="https://play.dhis2.org/dev"
SECRET="1e6db50c-0fee-11e5-98d0-3c15c2c6caf6"

curl -X POST -u demo:$SECRET -H "Accept: application/json" $SERVER/uaa/oauth/token
-d "grant_type=authorization_code" -d "code=XYZ"
```

## Error and info messages { #webapi_error_info_messages } 

The Web API uses a consistent format for all error/warning and
informational messages:

```json
{
  "httpStatus": "Forbidden",
  "message": "Vous n'avez pas la permission de lire ce type d'objet.",
  "httpStatusCode": 403,
  "status": "ERROR"
}
```

Here we can see from the message that the user tried to access a
resource I did not have access to. It uses the http status code 403, the
http status message *forbidden* and a descriptive message.



Table: WebMessage properties

| Nom | Description |
|---|---|
| httpStatus | HTTP Status message for this response, see RFC 2616 (Section 10) for more information. |
| httpStatusCode | HTTP Status code for this response, see RFC 2616 (Section 10) for more information. |
| statut | DHIS2 status, possible values are *OK* &#124; *WARNING* &#124; *ERROR*, where `OK` means everything was successful, `ERROR` means that operation did not complete and `WARNING` means the operation was partially successful, if the message contains a `response` property, please look there for more information. |
| message | A user-friendly message telling whether the operation was a success or not. |
| devMessage | A more technical, developer-friendly message (not currently in use). |
| response | Extension point for future extension to the WebMessage format. This will be documented when it starts being used. |

## Date and period format { #webapi_date_perid_format } 

Throughout the Web API, we refer to dates and periods. The date format
is:

    yyyy-MM-dd

For instance, if you want to express March 20, 2014, you must use
*2014-03-20*.

The period format is described in the following table (also available on
the API endpoint `/api/periodTypes`)



Table: Period format

| Interval | Format | Exemple | Description |
|---|---|---|---|
| Day | yyyyMMdd | 20040315 | March 15, 2004 |
| Week | yyyyWn | 2004W10 | Week 10 2004 |
| Week Wednesday | yyyyWedWn | 2015WedW5 | Week 5 with start Wednesday |
| Week Thursday | yyyyThuWn | 2015ThuW6 | Week 6 with start Thursday |
| Week Saturday | yyyySatWn | 2015SatW7 | Week 7 with start Saturday |
| Week Sunday | yyyySunWn | 2015SunW8 | Week 8 with start Sunday |
| Bi-week | yyyyBiWn | 2015BiW1 | Week 1-2 20015 |
| Month | yyyyMM | 200403 | March 2004 |
| Bi-month | yyyyMMB | 200401B | January-February 2004 |
| Quarter | yyyyQn | 2004Q1 | January-March 2004 |
| Six-month | yyyySn | 2004S1 | January-June 2004 |
| Six-month April | yyyyAprilSn | 2004AprilS1 | April-September 2004 |
| Year | yyyy | 2004 | 2004 |
| Financial Year April | yyyyApril | 2004April | Apr 2004-Mar 2005 |
| Financial Year July | yyyyJuly | 2004July | July 2004-June 2005 |
| Financial Year Oct | yyyyOct | 2004Oct | Oct 2004-Sep 2005 |


### Relative Periods { #webapi_date_relative_period_values } 


In some parts of the API, like for the analytics resource, you can
utilize relative periods in addition to fixed periods (defined above).
The relative periods are relative to the current date and allow e.g.
for creating dynamic reports. The available relative period values are:

    THIS_WEEK, LAST_WEEK, LAST_4_WEEKS, LAST_12_WEEKS, LAST_52_WEEKS,
    THIS_MONTH, LAST_MONTH, THIS_BIMONTH, LAST_BIMONTH, THIS_QUARTER, LAST_QUARTER,
    THIS_SIX_MONTH, LAST_SIX_MONTH, MONTHS_THIS_YEAR, QUARTERS_THIS_YEAR,
    THIS_YEAR, MONTHS_LAST_YEAR, QUARTERS_LAST_YEAR, LAST_YEAR, LAST_5_YEARS, LAST_10_YEARS, LAST_10_FINANCIAL_YEARS, LAST_12_MONTHS, 
    LAST_3_MONTHS, LAST_6_BIMONTHS, LAST_4_QUARTERS, LAST_2_SIXMONTHS, THIS_FINANCIAL_YEAR,
    LAST_FINANCIAL_YEAR, LAST_5_FINANCIAL_YEARS


## Authorities { #authorities } 
System authority ids and names can be listed using:

    /api/authorities

It returns the following format:
```json
{
  "systemAuthorities": [
    {
      "id": "ALL",
      "name": "ALL"
    },
    {
      "id": "F_ACCEPT_DATA_LOWER_LEVELS",
      "name": "Accept data at lower levels"
    }
    //...
  ]
}
```



# Métadonnées { #metadata } 

## Identifier schemes { #webapi_identifier_schemes } 

This section provides an explanation of the identifier scheme concept.
Identifier schemes are used to map metadata objects to other metadata
during import, and to render metadata as part of exports. Please note
that not all schemes work for all API calls, and not all
schemes can be used for both input and output. This is outlined in the
sections explaining the various Web APIs.

The full set of identifier scheme object types available are listed
below, using the name of the property to use in queries:

  - idScheme

  - dataElementIdScheme (Schéma d'identifiant d'élément de données)

  - categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie)

  - orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation)

  - programIdScheme (Schéma d'identification du programme)

  - programmeStageIdScheme (Schéma d'identification de l'étape de programme)

  - trackedEntityIdScheme

  - trackedEntityAttributeIdScheme

The general idScheme applies to all types of objects. It can be
overridden by specific object types.

The default scheme for all parameters is UID (stable DHIS2
identifiers). The supported identifier schemes are described in the
table below.

Table: Scheme Values

| Schéma | Description |
|---|---|
| ID, UID | Correspondre avec l'identifiant permanent DHIS2. il s'agit du schéma d'identification par défaut. |
| CODE | Correspondre avec le code DHIS2, principalement utilisé pour échanger des données avec un système externe. |
| NOM | Match on DHIS2 Name, please note that this uses what is available as *object.name*, and not the translated name. Also note that names are not always unique, and in that case, they can not be used. |
| ATTRIBUT:ID | Match on metadata attribute, this attribute needs to be assigned to the type you are matching on, and also that the unique property is set to *true*. The main usage of this is also to exchange data with external systems, it has some advantages over *CODE* since multiple attributes can be added, so it can be used to synchronize with more than one system. |

Note that identifier schemes is not an independent feature but needs to
be used in combination with resources such as data value import and metadata import.

As an example, to specify CODE as the general id scheme and override
with UID for organisation unit id scheme you can use these query
parameters:

    ?idScheme=CODE&orgUnitIdScheme=UID

As another example, to specify an attribute for the organisation unit id
scheme, code for the data element id scheme and use the default UID id
scheme for all other objects you can use these parameters:

    ?orgUnitIdScheme=ATTRIBUTE:j38fk2dKFsG&dataElementIdScheme=CODE

## Browsing the Web API { #webapi_browsing_the_web_api } 

The entry point for browsing the Web API is `/api`. This resource
provides links to all available resources. Four resource representation
formats are consistently available for all resources: HTML, XML, JSON,
and JSONP. Some resources will have other formats available, like MS
Excel, PDF, CSV, and PNG. To explore the API from a web browser, navigate
to the `/api` entry point and follow the links to your desired
resource, for instance `/api/dataElements`. For all resources which
return a list of elements certain query parameters can be used to modify
the response:

Table: Query parameters

| Param | Option values | Default option | Description |
|---|---|---|---|
| paging | true &#124; false | vrai | Indicates whether to return lists of elements in pages. |
| page | number | 1 | Defines which page number to return. |
| taille de la page | number | 50 | Defines the number of elements to return for each page. |
| Ordre | property:asc/iasc/desc/idesc || Order the output using a specified order, only properties that are both persisted and simple (no collections, idObjects etc) are supported. iasc and idesc are case insensitive sorting. |

An example of how these parameters can be used to get a full list of
data element groups in XML response format is:

    /api/dataElementGroups.xml?links=false&paging=false

You can query for elements on the name property instead of returning
a full list of elements using the *query* query variable. In this example
we query for all data elements with the word "anaemia" in the name:

    /api/dataElements?query=anaemia

You can get specific pages and page sizes of objects like this:

    /api/dataElements.json?page=2&pageSize=20

You can completely disable paging like this:

    /api/indicatorGroups.json?paging=false

To order the result based on a specific property:

    /api/indicators.json?order=shortName:desc

You can find an object based on its ID across all object types through
the *identifiableObjects* resource:

    /api/identifiableObjects/<id>

### Translation { #webapi_translation } 

DHIS2 supports translations of database content, such as data elements,
indicators, and programs. All metadata objects in the Web API have
properties meant to be used for display / UI purposes, which include
*displayName*, *displayShortName*, *displayDescription* and
*displayFormName* (for data elements and tracked entity attributes).

Table: Translate options

| Paramètre | Valeurs | Description |
|---|---|---|
| translate | true &#124; false | Translate display\* properties in metadata output (displayName, displayShortName, displayDescription, and displayFormName for data elements and tracked entity attributes). Default value is true. |
| locale | Locale to use | Translate metadata output using a specified locale (requires translate=true). |

### Translation API { #webapi_translation_api } 

The translations for an object is rendered as part of the object itself
in the *translations* array. Note that the *translations* array in the
JSON/XML payloads is normally pre-filtered for you, which means they
can not directly be used to import/export translations (as that would
normally overwrite locales other than current users).

Example of data element with translation array filtered on user locale:

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute French",
  "translations": [
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    }
  ]
}
```

Example of data element with translations turned off:

```json
{
  "id": "FTRrcoaog83",
  "displayName": "Accute Flaccid Paralysis (Deaths < 5 yrs)",
  "translations": [
    {
      "property": "FORM_NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "Accute Flaccid Paral"
    },
    {
      "property": "SHORT_NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Accute French"
    },
    {
      "property": "NAME",
      "locale": "en_FK",
      "value": "aa"
    },
    {
      "property": "DESCRIPTION",
      "locale": "en_FK",
      "value": "aa"
    }
  ]
}
```

Note that even if you get the unfiltered result, and are using the
appropriate type endpoint i..e `/api/dataElements` we do not allow
updates, as it would be too easy to make mistakes and overwrite the
other available locales.

To read and update translations you can use the special translations
endpoint for each object resource. These can be accessed by *GET* or
*PUT* on the appropriate `/api/<object-type>/<object-id>/translations` endpoint.

As an example, for a data element with identifier `FTRrcoaog83`, you could use
`/api/dataElements/FTRrcoaog83/translations` to get and update
translations. The fields available are `property` with options *NAME*,
*SHORT_NAME*, *FORM_NAME*, *DESCRIPTION*, `locale` which supports any valid
locale ID and the translated property `value`.

Example of NAME property for French locale:

```json
{
  "property": "NAME",
  "locale": "fr",
  "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
}
```

This payload would then be added to a translation array, and sent back
to the appropriate endpoint:

```json
{
  "translations": [
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Paralysie Flasque Aiguë (Décès <5 ans)"
    }
  ]
}
```

For a data element with ID *FTRrcoaog83* you can *PUT* this to
`/api/dataElements/FTRrcoaog83/translations`. Make sure to send all
translations for the specific object and not just for a single locale
(if not you will potentially overwrite existing locales for other
locales).

### Web API versions { #webapi_api_versions } 

The Web API is versioned starting from DHIS 2.25. The API versioning
follows the DHIS2 major version numbering. As an example, the API
version for DHIS 2.33 is `33`.

You can access a specific API version by including the version number
after the `/api` component, as an example like this:

    /api/33/dataElements

If you omit the version part of the URL, the system will use the current
API version. As an example, for DHIS 2.25, when omitting the API part,
the system will use API version 25. When developing API clients it is
recommended to use explicit API versions (rather than omitting the API
version), as this will protect the client from unforeseen API changes.

The last three API versions will be supported. As an example, DHIS
version 2.27 will support API version 27, 26 and 25.

Note that the metadata model is not versioned and that you might
experience changes e.g. in associations between objects. These changes
will be documented in the DHIS2 major version release notes.

## Metadata object filter { #webapi_metadata_object_filter } 

To filter the metadata there are several filter operations that can be
applied to the returned list of metadata. The format of the filter
itself is straight-forward and follows the pattern
*property:operator:value*, where *property* is the property on the
metadata you want to filter on, *operator* is the comparison operator
you want to perform and *value* is the value to check against (not all
operators require value). Please see the *schema* section to discover
which properties are available. Recursive filtering, ie. filtering on
associated objects or collection of objects, is supported as well.

Table: Available Operators

| Opérateur | Types | Value required | Description |
|---|---|---|---|
| eq | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | vrai | Equality |
| !eq | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | vrai | Inequality |
| ne | string &#124; boolean &#124; integer &#124; float &#124; enum &#124; collection (checks for size) &#124; date | vrai | Inequality |
| like | string | vrai | Case sensitive string, match anywhere |
| !like | string | vrai | Case sensitive string, not match anywhere |
| $like | string | vrai | Case sensitive string, match start |
| !$like | string | vrai | Case sensitive string, not match start |
| like$ | string | vrai | Case sensitive string, match end |
| !like$ | string | vrai | Case sensitive string, not match end |
| ilike | string | vrai | Case insensitive string, match anywhere |
| !ilike | string | vrai | Case insensitive string, not match anywhere |
| $ilike | string | vrai | Case insensitive string, match start |
| !$ilike | string | vrai | Case insensitive string, not match start |
| ilike$ | string | vrai | Case insensitive string, match end |
| !ilike$ | string | vrai | Case insensitive string, not match end |
| gt | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Supérieure à |
| ge | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Greater than or equal |
| lt | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Inférieur à |
| le | string &#124; boolean &#124; integer &#124; float &#124; collection (checks for size) &#124; date | vrai | Less than or equal |
| nulle | all | faux | Property is null |
| !null | all | faux | Property is not null |
| empty | collection | faux | Collection is empty |
| token | string | vrai | Match on multiple tokens in search property |
| !token | string | vrai | Not match on multiple tokens in search property |
| recherche | string &#124; boolean &#124; integer &#124; float &#124; date | vrai | Find objects matching 1 or more values |
| !in | string &#124; boolean &#124; integer &#124; float &#124; date | vrai | Find objects not matching 1 or more values |

Operators will be applied as logical *and* query, if you need a *or*
query, you can have a look at our *in* filter (also have a look at the
section below). The filtering mechanism allows for recursion. See below
for some examples.

Get data elements with id property ID1 or ID2:

    /api/dataElements?filter=id:eq:ID1&filter=id:eq:ID2

Get all data elements which have the dataSet with id ID1:

    /api/dataElements?filter=dataSetElements.dataSet.id:eq:ID1

Get all data elements with aggregation operator "sum" and value type
"int":

    /api/dataElements.json?filter=aggregationOperator:eq:sum&filter=type:eq:int

You can do filtering within collections, e.g. to get data elements which
are members of the "ANC" data element group you can use the following
query using the id property of the associated data element groups:

    /api/dataElements.json?filter=dataElementGroups.id:eq:qfxEYY9xAl6

Since all operators are *and* by default, you can't find a data
element matching more than one id, for that purpose you can use the *in*
operator.

    /api/dataElements.json?filter=id:in:[fbfJHSPpUQD,cYeuwXTCPkU]

### Logical operators { #webapi_metadata_logical_operator } 

As mentioned in the section before, the default logical operator applied
to the filters is *AND* which means that all object filters must be
matched. There are however cases where you want to match on one of
several filters (maybe id and code field) and in those cases, it is
possible to switch the root logical operator from *AND* to *OR*
using the *rootJunction* parameter.

Example: Normal filtering where both id and code must match to have a
result returned

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1

Example: Filtering where the logical operator has been switched to OR
and now only one of the filters must match to have a result
    returned

    /api/dataElements.json?filter=id:in:[id1,id2]&filter=code:eq:code1&rootJunction=OR

### Identifiable token filter { #identifiable-token-filter } 

In addition to the specific property based filtering mentioned above,
we also have *token* based *AND* filtering across a set of
properties: id, code, and name (also shortName if available). These
properties are commonly referred to as *identifiable*. The idea is to
filter metadata whose id, name, code or short name containing something.

Example: Filter all data elements containing *2nd* in any of the
following: id,name,code, shortName

    /api/dataElements.json?filter=identifiable:token:2nd

It is also possible to specify multiple filtering values.

Example: Get all data elements where *ANC visit* is found in any of the *identifiable* properties. The system returns all data elements where both tokens (ANC and visit) are found anywhere in identifiable properties.

    /api/dataElements.json?filter=identifiable:token:ANC visit

It is also possible to combine the identifiable filter with property-based filter and expect the *rootJunction* to be applied.

    /api/dataElements.json?filter=identifiable:token:ANC visit&filter=displayName:ilike:tt1

    /api/dataElements.json?filter=identifiable:token:ANC visit
      &filter=displayName:ilike:tt1&rootJunction=OR

## Metadata field filter { #webapi_metadata_field_filter } 

In many situations, the default views of the metadata can be too
verbose. A client might only need a few fields from each object and want
to remove unnecessary fields from the response. To discover which fields
are available for each object please see the *schema* section.

The format for include/exclude allows for infinite recursion. To filter
at the "root" level you can just use the name of the field,
i.e. `?fields=id,name` which would only display the `id` and
`name` fields for every object. For objects that are either collections or
complex objects with properties on their own, you can use the format
`?fields=id,name,dataSets[id,name]` which would return `id`, `name` of
the root, and the `id` and `name` of every data set on that object.
Negation can be done with the exclamation operator, and we have a set of
presets of field select. Both XML and JSON are supported.

**Example**: Get `id` and `name` on the indicators resource:

    /api/indicators?fields=id,name

**Example**: Get `id` and `name` from dataElements, and `id` and `name`
from the dataSets on dataElements:

    /api/dataElements?fields=id,name,dataSets[id,name]

To exclude a field from the output you can use the exclamation `!`
operator. This is allowed anywhere in the query and will simply not
include that property as it might have been inserted in some of the
presets.

A few presets (selected fields groups) are available and can be applied
using the `:` operator.

Table: Property operators

| Opérateur | Description |
|---|---|
| <field-name\> | Include property with name, if it exists. |
| <object\>[<field-name\>, ...] | Includes a field within either a collection (will be applied to every object in that collection), or just on a single object. |
| !<field-name\>, <object\>[!<field-name\> | Do not include this field name, it also works inside objects/collections. Useful when you use a preset to include fields. |
| \*, <object\>[\*] | Include all fields on a certain object, if applied to a collection, it will include all fields on all objects on that collection. |
| :<preset\> | Alias to select multiple fields. Three presets are currently available, see the table below for descriptions. |

Table: Field presets

| Preset | Description |
|---|---|
| all | All fields of the object |
| \* | Alias for all |
| identifiable | Includes id, name, code, created and lastUpdated fields |
| nameable | Includes id, name, shortName, code, description, created and lastUpdated fields |
| persisted | Returns all persisted property on an object, does not take into consideration if the object is the owner of the relation. |
| owner | Returns all persisted property on an object where the object is the owner of all properties, this payload can be used to update through the API. |

**Example**: Include all fields from dataSets except organisationUnits:

    /api/dataSets?fields=:all,!organisationUnits

**Example**: Include only id, name and the collection of organisation units from a data set, but exclude the id from organisation units:

    /api/dataSets/BfMAe6Itzgt?fields=id,name,organisationUnits[:all,!id]

**Example**: Include nameable properties from all indicators:

    /api/indicators.json?fields=:nameable

### Field transformers { #webapi_field_transformers } 

In DHIS2.17 we introduced field transformers, the idea is to allow
further customization of the properties on the server-side.

    /api/dataElements/ID?fields=id~rename(i),name~rename(n)

This will rename the *id* property to *i* and *name* property to *n*.

Multiple transformers can be used by repeating the transformer syntax:

    /api/dataElementGroups.json?fields=id,displayName,dataElements~isNotEmpty~rename(haveDataElements)

Table: Available Transformers

| Nom | Arguments | Description |
|---|---|---|
| size || Gives sizes of strings (length) and collections |
| isEmpty || Is string or collection empty |
| isNotEmpty || Is string or collection not empty |
| rename | Arg1: name | Renames the property name |
| paging | Arg1: page,Arg2: pageSize | Pages a collection, default pageSize is 50. |
| pluck | Optional Arg1: fieldName | Converts an array of objects to an array of a selected field of that object. By default, the first field that is returned by the collection is used (normally the ID). |

#### Examples { #webapi_field_transformers_examples } 

Examples of transformer usage.

```
/api/dataElements?fields=dataSets~size

/api/dataElements?fields=dataSets~isEmpty

/api/dataElements?fields=dataSets~isNotEmpty

/api/dataElements/ID?fields=id~rename(i),name~rename(n)

/api/dataElementGroups?fields=id,displayName,dataElements~paging(1;20)

# Include array with IDs of organisation units:
/api/categoryOptions.json?fields=id,organisationUnits~pluck

# Include array with names of organisation units (collection only returns field name):
/api/categoryOptions.json?fields=id,organisationUnits~pluck[name]
```

## Metadata create, read, update, delete, validate { #webapi_metadata_crud } 

All metadata entities in DHIS2 have their own API endpoint which supports
*CRUD* operations (create, read, update and delete). The endpoint URLs
follows this format:

    /api/<entityName>

The _entityName_ uses the camel-case notation. As an example, the endpoint
for _data elements_ is:

    /api/dataElements

### Create / update parameters { #webapi_metadata_create_update } 

The following request query parameters are available across all metadata endpoints.

Table: Available Query Filters

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| preheatCache | boolean | faux | true &#124; false | Turn cache-map preheating on/off. This is on by default, turning this off will make initial load time for importer much shorter (but will make the import itself slower). This is mostly used for cases where you have a small XML/JSON file you want to import, and don't want to wait for cache-map preheating. |
| importStrategy (stratégie d'importation) | enum | faux | CREATE_AND_UPDATE &#124; CREATE &#124; UPDATE &#124; DELETE | Import strategy to use, see below for more information. |
| mergeMode | enum | faux | REPLACE, MERGE | Strategy for merging of objects when doing updates. REPLACE will just overwrite the property with the new value provided, MERGE will only set the property if it is not null (only if the property was provided). |

### Creating and updating objects { #webapi_creating_updating_objects } 

For creating new objects you will need to know the endpoint, the type
format, and make sure that you have the required authorities. As an
example, we will create and update a *constant*. To figure out the
format, we can use the new *schema* endpoint for getting format
description. So we will start with getting that info:

    http://<server>/api/schemas/constant.json

From the output, you can see that the required authorities for create
are `F_CONSTANT_ADD`, and the important properties are: *name* and
*value*. From this, we can create a JSON payload and save it as a file
called constant.json:

```json
{
  "name": "PI",
  "value": "3.14159265359"
}
```

The same content as an XML payload:

```xml
<constant name="PI" xmlns="http://dhis2.org/schema/dxf/2.0">
  <value>3.14159265359</value>
</constant>
```

We are now ready to create the new *constant* by sending a POST request to
the `constants` endpoint with the JSON payload using curl:

```bash
curl -d @constant.json "http://server/api/constants" -X POST
  -H "Content-Type: application/json" -u user:password
```

A specific example of posting the constant to the demo server:

```bash
curl -d @constant.json "https://play.dhis2.org/api/constants" -X POST
  -H "Content-Type: application/json" -u admin:district
```

If everything went well, you should see an output similar to:

```json
{
  "status": "SUCCESS",
  "importCount": {
    "imported": 1,
    "updated": 0,
    "ignored": 0,
    "deleted": 0
  },
  "type": "Constant"
}
```

The process will be exactly the same for updating, you make your changes
to the JSON/XML payload, find out the *ID* of the constant, and then
send a PUT request to the endpoint including ID:

```bash
curl -X PUT -d @pi.json -H "Content-Type: application/json"
  -u user:password "http://server/api/constants/ID"
```

### Deleting objects { #webapi_deleting_objects } 

Deleting objects is very straight forward, you will need to know the
*ID* and the endpoint of the type you want to delete, let's continue our
example from the last section and use a *constant*. Let's assume that
the id is *abc123*, then all you need to do is the send the DELETE
request to the endpoint + id:

```bash
curl -X DELETE -u user:password "http://server/api/constants/ID"
```

A successful delete should return HTTP status 204 (no content).

### Adding and removing objects in collections { #webapi_adding_removing_objects_collections } 

The collections resource lets you modify collections of
objects.

#### Adding or removing single objects { #webapi_collections_adding_removing_single_objects } 

In order to add or remove objects to or from a collection of objects you
can use the following
    pattern:

    /api/{collection-object}/{collection-object-id}/{collection-name}/{object-id}

You should use the POST method to add, and the DELETE method to remove
an object. When there is a many-to-many relationship between objects,
you must first determine which object owns the relationship. If it isn't
clear which object this is, try the call both ways to see which works.

The components of the pattern are:

  - collection object: The type of objects that owns the collection you
    want to modify.

  - collection object id: The identifier of the object that owns the
    collection you want to modify.

  - collection name: The name of the collection you want to modify.

  - object id: The identifier of the object you want to add or remove
    from the collection.

As an example, in order to remove a data element with identifier IDB
from a data element group with identifier IDA you can do a DELETE
request:

    DELETE /api/dataElementGroups/IDA/dataElements/IDB

To add a category option with identifier IDB to a category with
identifier IDA you can do a POST
request:

    POST /api/categories/IDA/categoryOptions/IDB

#### Adding or removing multiple objects { #webapi_collections_adding_removing_multiple_objects } 

You can add or remove multiple objects from a collection in one request
with a payload like this:

```json
{
  "identifiableObjects": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ]
}
```

Using this payload you can add, replace or delete items:

*Adding Items:*

    POST /api/categories/IDA/categoryOptions

*Replacing Items:*

    PUT /api/categories/IDA/categoryOptions

*Delete
Items:*

    DELETE /api/categories/IDA/categoryOptions

#### Adding and removing objects in a single request { #webapi_collections_adding_removing_objects_single_request } 

You can both add and remove objects from a collection in a single POST
request to the following URL:

    POST /api/categories/IDA/categoryOptions

The payload format is:

```json
{
  "additions": [{
      "id": "IDA"
    }, {
      "id": "IDB"
    }, {
      "id": "IDC"
    }
  ],
  "deletions": [{
      "id": "IDD"
    }, {
      "id": "IDE"
    }, {
      "id": "IDF"
    }
  ]
}
```

### Validating payloads { #webapi_validating_payloads } 

DHIS 2 supports system wide validation of metadata payloads, which means
that create and update operations on the API endpoints will be checked for
valid payload before allowing changes to be made. To find out what validations
are in place for a specific endpoint, have a look at the `/api/schemas`
endpoint, i.e. to figure out which constraints a data element have, you
would go to `/api/schemas/dataElement`.

You can also validate your payload manually by sending it to the proper
schema endpoint. If you wanted to validate the constant from the create
section before, you would send it like this:

    POST /api/schemas/constant

A simple (non-validating) example would be:

```bash
curl -X POST -d "{\"name\": \"some name\"}" -H "Content-Type: application/json"
  -u admin:district "https://play.dhis2.org/dev/api/schemas/dataElement"
```

Which will yield the result:

```json
[
   {
      "message" : "Required property missing.",
      "property" : "type"
   },
   {
      "property" : "aggregationOperator",
      "message" : "Required property missing."
   },
   {
      "property" : "domainType",
      "message" : "Required property missing."
   },
   {
      "property" : "shortName",
      "message" : "Required property missing."
   }
]
```

### Partial updates { #webapi_partial_updates } 

For our web api endpoints that deal with metadata, we support partial updates (PATCH) using the JSON Patch [standard](https://tools.ietf.org/html/rfc6902). The payload basically outlines a set of operation you want applied to a existing metadata object. For examples of JSON patch please see [jsonpatch.com](http://jsonpatch.com/), we support 3 operators: `add`, `remove` and `replace`.

Below is a few examples relevant to dhis2, please note that any update to a payload should be thought of as a HTTP PUT (i.e. any mutation must result in a valid PUT metadata payload).

The default `importReportMode` for JSON Patch is `ERRORS_NOT_OWNER` which means that if you try and update any property that is not owned by that particular object (for example trying to add a indicator group directly to an indicator) you will get an error.

As per the JSON Patch specification you must always use the mimetype `application/json-patch+json` when sending patches.

#### Exemples { #examples }

##### Update name and value type of data element { #update-name-and-value-type-of-data-element } 

```
PATCH /api/dataElements/{id}
```

```json
[
  {"op": "add", "path": "/name", "value": "New Name"},
  {"op": "add", "path": "/valueType", "value": "INTEGER"}
] 
```

##### Add new data element to a data element group { #add-new-data-element-to-a-data-element-group } 

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "add", "path": "/dataElements/-", "value": {"id": "data-element-id"}}
]
```

##### Remove all data element associations from a data element group { #remove-all-data-element-associations-from-a-data-element-group } 

```
PATCH /api/dataElementGroups/{id}
```

```json
[
  {"op": "remove", "path": "/dataElements"}
]
```

##### Change domain and value type of a data element { #change-domain-and-value-type-of-a-data-element } 

```
PATCH /api/dataElements/{id}
```

```json
[
    {"op": "add", "path": "/domainType", "value": "TRACKER"},
    {"op": "add", "path": "/valueType", "value": "INTEGER"}
]
```

##### Remove a specific orgUnit from an orgUnit group { #remove-a-specific-orgunit-from-an-orgunit-group } 

```
PATCH /api/organisationUnitGroups/{id}
```

```json
[
  {"op": "remove", "path": "/organisationUnits/1"}
]
```


## Metadata export { #webapi_metadata_export } 

This section explains the metatada API which is available at
`/api/metadata`. XML and JSON resource representations are supported.

    /api/metadata

The most common parameters are described below in the "Export Parameter"
table. You can also apply this to all available types by using
`type:fields=<filter>` and `type:filter=<filter>`. You can also
enable/disable the export of certain types by setting `type=true|false`.

Table: Export Parameter

| Nom | Options | Description |
|---|---|---|
| fields | Same as metadata field filter | Default field filter to apply for all types, default is `:owner`. |
| filter | Same as metadata object filter | Default object filter to apply for all types, default is `none`. |
| Ordre | Same as metadata order | Default order to apply to all types, default is `name` if available, or `created` if not. |
| translate | false/true | Enable translations. Be aware that this is turned off by default (in other endpoints this is on by default). |
| locale | <locale\> | Change from user locale, to your own custom locale. |
| defaults | INCLUDE/EXCLUDE | Should auto-generated category object be included or not in the payload. If you are moving metadata between 2 non-synced instances, it might make sense to set this to EXCLUDE to ease the handling of these generated objects. |
| skipSharing | false/true | Enabling this will strip the sharing properties from the exported objects. This includes *user*, *publicAccess*, *userGroupAccesses*, *userAccesses*, and *externalAccess*. |
| download | false/true | Enabling this will add HTTP header Content-Disposition that specifies that the data should be handled as an attachment and will be offered by web browsers as a download. |

### Metadata export examples { #webapi_metadata_export_examples } 

Export all metadata. Be careful as the response might be very large depending
on your metadata configuration:

    /api/metadata

Export all metadata ordered by lastUpdated descending:

    /api/metadata?defaultOrder=lastUpdated:desc

Export metadata only including indicators and indicator groups:

    /api/metadata?indicators=true&indicatorGroups=true

Export id and displayName for all data elements, ordered by displayName:

    /api/metadata?dataElements:fields=id,name&dataElements:order=displayName:desc

Export data elements and indicators where name starts with "ANC":

    /api/metadata?filter=name:^like:ANC&dataElements=true&indicators=true

### Metadata export with dependencies { #webapi_dataset_program_export_dependencies } 

When you want to exchange metadata for a data set, program, category combo,
dashboard, option set or data element group
from one DHIS2 instance to another instance there are six dedicated endpoints available:

```
/api/dataSets/{id}/metadata.json

/api/programs/{id}/metadata.json

/api/categoryCombos/{id}/metadata.json

/api/dashboards/{id}/metadata.json

/api/optionSets/{id}/metadata.json

/api/dataElementGroups/{id}/metadata.json
```

These exports can then be imported using `/api/metadata`.

These endpoints also support the following parameters:

Table: Export Parameter

| Nom | Options | Description |
|---|---|---|
| skipSharing | false/true | Enabling this will strip the sharing properties from the exported objects. This includes *user*, *publicAccess*, *userGroupAccesses*, *userAccesses*, and *externalAccess*. |
| download | false/true | Enabling this will add HTTP header Content-Disposition that specifies that the data should be handled as an attachment and will be offered by web browsers as a download. |

## Metadata import { #webapi_metadata_import } 

This section explains the metadata import API. XML and JSON resource
representations are supported. Metadata can be imported using a *POST* request.

    /api/metadata

The importer allows you to import metadata payloads which may include many
different entities and any number of objects per entity. The metadata export
generated by the metadata export API can be imported directly.

The metadata import endpoint support a variety of parameters, which are
listed below.

Table: Import Parameter

| Nom | Options (first is default) | Description |
|---|---|---|
| Mode d'importation  | COMMIT, VALIDATE | Sets overall import mode, decides whether or not to only `VALIDATE` or also `COMMIT` the metadata, this has similar functionality as our old dryRun flag. |
| identifier | UID, CODE, AUTO | Sets the identifier scheme to use for reference matching. `AUTO` means try `UID` first, then `CODE`. |
| importReportMode | ERRORS, FULL, DEBUG | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |
| preheatMode | REFERENCE, ALL, NONE | Sets the preheater mode, used to signal if preheating should be done for `ALL` (as it was before with *preheatCache=true*) or do a more intelligent scan of the objects to see what to preheat (now the default), setting this to `NONE` is not recommended. |
| importStrategy (stratégie d'importation) | CREATE_AND_UPDATE, CREATE, UPDATE, DELETE | Sets import strategy, `CREATE_AND_UPDATE` will try and match on identifier, if it doesn't exist, it will create the object. |
| Mode atomique | ALL, NONE | Sets atomic mode, in the old importer we always did a *best effort* import, which means that even if some references did not exist, we would still import (i.e. missing data elements on a data element group import). Default for new importer is to not allow this, and similar reject any validation errors. Setting the `NONE` mode emulated the old behavior. |
| ~~mergeMode~~ | ~~REPLACE, MERGE~~ | ~~Sets the merge mode, when doing updates we have two ways of merging the old object with the new one, `MERGE` mode will only overwrite the old property if the new one is not-null, for `REPLACE` mode all properties are overwritten regardless of null or not.~~ (*) |
| flushMode | AUTO, OBJECT | Sets the flush mode, which controls when to flush the internal cache. It is *strongly* recommended to keep this to `AUTO` (which is the default). Only use `OBJECT` for debugging purposes, where you are seeing hibernate exceptions and want to pinpoint the exact place where the stack happens (hibernate will only throw when flushing, so it can be hard to know which object had issues). | 
| skipSharing | false, true | Skip sharing properties, does not merge sharing when doing updates, and does not add user group access when creating new objects. |
| skipValidation | false, true | Skip validation for import. `NOT RECOMMENDED`. |
| async | false, true | Asynchronous import, returns immediately with a *Location* header pointing to the location of the *importReport*. The payload also contains a json object of the job created. |
| inclusionStrategy | NON_NULL, ALWAYS, NON_EMPTY | *NON_NULL* includes properties which are not null, *ALWAYS* include all properties, *NON_EMPTY* includes non empty properties (will not include strings of 0 length, collections of size 0, etc.) |
| userOverrideMode | NONE, CURRENT, SELECTED | Allows you to override the user property of every object you are importing, the options are NONE (do nothing), CURRENT (use import user), SELECTED (select a specific user using overrideUser=X) |
| overrideUser | User ID | If userOverrideMode is SELECTED, use this parameter to select the user you want override with. |

> (*) Currently the `mergeMode=MERGE` option of the import service has limitations and doesn't support all objects. It doesn't work with some object types such as Embedded objects, or objects which are saved as JSONB format in database ( sharing, attributeValues, etc...). Fixing those issues are complicated and would just cause new issues. Therefore, this `mergedMode=MERGE` is deprecated and currently is not recommended to use. The update mode should always be mergedMode=REPLACE. We have developed a new [JSON Patch API](#webapi_partial_updates) which can be used as an alternative approach. This feature is introduced in 2.37 release.


An example of a metadata payload to be imported looks like this. Note how
each entity type have their own property with an array of objects:

```json
{
  "dataElements": [
    {
      "name": "EPI - IPV 3 doses given",
      "shortName": "EPI - IPV 3 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    },
    {
      "name": "EPI - IPV 4 doses given",
      "shortName": "EPI - IPV 4 doses given",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "valueType": "INTEGER_ZERO_OR_POSITIVE"
    }
  ],
  "indicators": [
    {
      "name": "EPI - ADS stock used",
      "shortName": "ADS stock used",
      "numerator": "#{LTb8XeeqeqI}+#{Fs28ZQJET6V}-#{A3mHIZd2tPg}",
      "numeratorDescription": "ADS 0.05 ml used",
      "denominator": "1",
      "denominatorDescription": "1",
      "annualized": false,
      "indicatorType": {
        "id": "kHy61PbChXr"
      }
    }
  ]
}
```

When posting this payload to the metadata endpoint, the response will contain
information about the parameters used during the import and a summary per
entity type including how many objects were created, updated, deleted and
ignored:

```json
{
  "importParams": {
    "userOverrideMode": "NONE",
    "importMode": "COMMIT",
    "identifier": "UID",
    "preheatMode": "REFERENCE",
    "importStrategy": "CREATE_AND_UPDATE",
    "atomicMode": "ALL",
    "mergeMode": "REPLACE",
    "flushMode": "AUTO",
    "skipSharing": false,
    "skipTranslation": false,
    "skipValidation": false,
    "metadataSyncImport": false,
    "firstRowIsHeader": true,
    "username": "UNICEF_admin"
  },
  "status": "OK",
  "typeReports": [
    {
      "klass": "org.hisp.dhis.dataelement.DataElement",
      "stats": {
        "created": 2,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 2
      }
    },
    {
      "klass": "org.hisp.dhis.indicator.Indicator",
      "stats": {
        "created": 1,
        "updated": 0,
        "deleted": 0,
        "ignored": 0,
        "total": 1
      }
    }
  ],
  "stats": {
    "created": 3,
    "updated": 0,
    "deleted": 0,
    "ignored": 0,
    "total": 3
  }
}
```


## Schema { #webapi_schema } 

A resource which can be used to introspect all available DXF 2 objects
can be found on `/api/schemas`. For specific resources you can have a
look at `/api/schemas/<type>`.

To get all available schemas in XML:

    GET /api/schemas.xml

To get all available schemas in JSON:

    GET /api/schemas.json

To get JSON schema for a specific class:

    GET /api/schemas/dataElement.json


## Icons { #webapi_icons } 

DHIS2 includes a collection of icons that can be used to give visual
context to metadata. These icons can be accessed through the icons
resource.

    GET /api/icons

This endpoint returns a list of information about the available icons.
Each entry contains information about the icon, and a reference to the
actual icon.

```json
{
  key: "mosquito_outline",
  description: "Mosquito outline",
  keywords: [
    "malaria",
    "mosquito",
    "dengue"
  ],
  href: "<dhis server>/api/icons/mosquito_outline/icon.svg"
}
```

The keywords can be used to filter which icons to return. Passing a list
of keywords with the request will only return icons that match all the
keywords:

    GET /api/icons?keywords=shape,small

A list of all unique keywords can be found at the keywords resource:

    GET /api/icons/keywords

## Render type { #webapi_render_type } 

Some metadata types have a property named *renderType*. The render type
property is a map between a *device* and a *renderingType*. Applications
can use this information as a hint on how the object should be rendered
on a specific device. For example, a mobile device might want to render
a data element differently than a desktop computer.

There is currently two different kinds of renderingTypes available:

1.  Value type rendering

2.  Program stage section rendering

There is also 2 device types available:

1.  MOBILE

2.  DESKTOP

The following table lists the metadata and rendering types available.
The value type rendering has addition constraints based on the metadata
configuration, which will be shown in a second table.

Table: Metadata and RenderingType overview

| Metadata type | Available RenderingTypes |
|---|---|
| Program Stage Section | * LISTING (default)<br> * SEQUENTIAL<br> * MATRIX |
| Élément de données | * DEFAULT<br> * DROPDOWN<br> * VERTICAL_RADIOBUTTONS<br> * HORIZONTAL_RADIOBUTTONS<br> * VERTICAL_CHECKBOXES<br> * HORIZONTAL_CHECKBOXES<br> * SHARED_HEADER_RADIOBUTTONS<br> * ICONS_AS_BUTTONS<br> * SPINNER<br> * ICON<br> * TOGGLE<br> * VALUE<br> * SLIDER<br> * LINEAR_SCALE |

Since handling the default rendering of data elements and tracked entity
attributes are depending on the value type of the object, there is also
a DEFAULT type to tell the client it should be handled as normal.
Program Stage Section is LISTING as default.

Table: RenderingTypes allowed based on value types

| Type de valeur | Is object an optionset? | RenderingTypes allowed |
|---|---|---|
| TRUE_ONLY | Non | DEFAULT, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, TOGGLE |
| BOOLÉEN | Non ||
| - | Oui | DEFAULT, DROPDOWN, VERTICAL_RADIOBUTTONS, HORIZONTAL_RADIOBUTTONS, VERTICAL_CHECKBOXES, HORIZONTAL_CHECKBOXES, SHARED_HEADER_RADIOBUTTONS, ICONS_AS_BUTTONS, SPINNER, ICON |
| INTEGER | Non | DEFAULT, VALUE, SLIDER, LINEAR_SCALE, SPINNER |
| INTEGER_POSITIVE | Non ||
| INTEGER_NEGATIVE | Non ||
| INTEGER_ZERO_OR_POSITIVE | Non ||
| NUMBER | Non ||
| UNIT_INTERVAL | Non ||
| PERCENTAGE | Non ||

A complete reference of the previous table can also be retrieved using
the following endpoint:

    GET /api/staticConfiguration/renderingOptions

Value type rendering also has some additional properties that can be
set, which is usually needed when rendering some of the specific types:

Table: renderType object properties

| Propriété | Description | Type |
|---|---|---|
| type | The RenderingType of the object, as seen in the first table. This property is the same for both value type and program stage section, but is the only property available for program stage section. | Enum (See list in the Metadata and Rendering Type table) |
| min | Only for value type rendering. Represents the minimum value this field can have. | Entier |
| max | Only for value type rendering. Represents the maximum value this field can have. | Entier |
| step | Only for value type rendering. Represents the size of the steps the value should increase, for example for SLIDER og LINEAR_SCALE | Entier |
| decimalPoints | Only for value type rendering. Represents the number of decimal points the value should use. | Entier |

The *renderingType* can be set when creating or updating the metadata listed in the first table. An example payload for the rendering type for program stage section looks like this:

```json
{
  "renderingType": {
    "type": "MATRIX"
  }
}
```

For data element and tracked entity attribute:

```json
{
  "renderingType": {
    "type": "SLIDER",
    "min": 0,
    "max": 1000,
    "step": 50,
    "decimalPoints": 0
  }
}
```

## Object Style { #webapi_object_style } 

Most metadata have a property names "style". This property can be used
by clients to represent the object in a certain way. The properties
currently supported by style is as follows:

Table: Style properties

| Propriété | Description | Type |
|---|---|---|
| color | A color, represented by a hexadecimal. | String (#000000) |
| icon | An icon, represented by a icon-name. | Chaîne |

Currently, there is no official list or support for icon-libraries, so
this is currently up to the client to provide. The following list shows
all objects that support style:

  - Élément de données

  - Data element category option

  - Ensemble de données

  - Indicateur

  - Option

  - Programme

  - Indicateur du programme

  - Program Section

  - Étape du programme

  - Program Stage Section

  - Relationship (Tracker)

  - Attribut d’entité suivie

  - Type d'entité suivie

When creating or updating any of these objects, you can include the
following payload to change the style:

```json
{
  "style": {
    "color": "#ffffff",
    "icon": "my-beautiful-icon"
  }
}
```

## Indicateurs { #webapi_indicators } 

This section describes indicators and indicator expressions.

### Aggregate indicators { #webapi_aggregate_indicators } 

To retrieve indicators you can make a GET request to the indicators
resource like this:

    /api/indicators

Indicators represent expressions which can be calculated and presented
as a result. The indicator expressions are split into a numerator and
denominator. The numerators and denominators are mathematical
expressions which can contain references to data elements, other indicators, constants and
organisation unit groups. The variables will be substituted with data
values when used e.g. in reports. Variables which are allowed in
expressions are described in the following table.

Table: Indicator variables

| Variable | Objet | Description |
|---|---|---|
| #{<data-element-id\>.<category-option-combo-id\>.<attribute-option-combo-id\>} | Data element operand | Refers to a combination of an aggregate data element and a category option combination. Both category and attribute option combo ids are optional, and a wildcard "\*" symbol can be used to indicate any value. |
| #{<dataelement-id\>.<category-option-group-id\>.<attribute-option-combo-id\>} | Category Option Group | Refers to an aggregate data element and a category option group, containing multiple category option combinations. |
| #{<data-element-id\>} | Aggregate data element | Refers to the total value of an aggregate data element across all category option combinations. |
| D{<program-id\>.<data-element-id\>} | Program data element | Refers to the value of a tracker data element within a program. |
| A{<program-id\>.<attribute-id\>} | Program tracked entity attribute | Refers to the value of a tracked entity attribute within a program. |
| I{<program-indicator-id\>} | Indicateur de programme | Refers to the value of a program indicator. |
| R{<dataset-id\>.<metric\>} | Taux de déclaration | Refers to a reporting rate metric. The metric can be REPORTING_RATE, REPORTING_RATE_ON_TIME, ACTUAL_REPORTS, ACTUAL_REPORTS_ON_TIME, EXPECTED_REPORTS. |
| C{<constant-id\>} | Constante | Refers to a constant value. |
| N{<indicator-id\>} | Indicateur | Refers to an existing Indicator. |
| OUG{<orgunitgroup-id\>} | Groupe d'unités d'organisation | Refers to the count of organisation units within an organisation unit group. |

Within a Data element operand or an Aggregate data element, the following substitutions may be made:

| Élément | Valeur | Description |
|---|---|---|
| data-element-id | data-element-id | An aggregate data element |
| data-element-id | deGroup:data-element-group-id | All the aggregate data elements in a data element group |
| category-option-combo-id | category-option-combo-id | A category option combination |
| category-option-combo-id | co:category-option-id | All the category option combinations in a category option |
| category-option-combo-id | coGroup:category-option-group-id | All the category option combinations in a category option group |
| category-option-combo-id | coGroup:co-group-id1&co-group-id2... | All the category option combinations that are members of multiple category option groups |

The syntax looks like
    this:

    #{<dataelement-id>.<catoptcombo-id>} + C{<constant-id>} + OUG{<orgunitgroup-id>}

A corresponding example looks like this:

    #{P3jJH5Tu5VC.S34ULMcHMca} + C{Gfd3ppDfq8E} + OUG{CXw2yu5fodb}

Note that for data element variables the category option combo
identifier can be omitted. The variable will then represent the total
for the data element, e.g. across all category option combos. Example:

    #{P3jJH5Tu5VC} + 2

Data element operands can include any of category option combination and
attribute option combination, and use wildcards to indicate any
    value:

    #{P3jJH5Tu5VC.S34ULMcHMca} + #{P3jJH5Tu5VC.*.j8vBiBqGf6O} + #{P3jJH5Tu5VC.S34ULMcHMca.*}

An example using a data element group:

    #{deGroup:oDkJh5Ddh7d} + #{deGroup:GBHN1a1Jddh.j8vBiBqGf6O}

An example using a category option, data element group, and a category option group:

    #{P3jJH5Tu5VC.co:FbLZS3ueWbQ} + #{deGroup:GBHN1a1Jddh.coGroup:OK2Nr4wdfrZ.j8vBiBqGf6O}

An example using multiple category option groups:

    #{P3jJH5Tu5VC.coGroup:OK2Nr4wdfrZ&j3C417uW6J7&ddAo6zmIHOk}

An example using a program data element and a program attribute:

    ( D{eBAyeGv0exc.vV9UWAZohSf} * A{IpHINAT79UW.cejWyOfXge6} ) / D{eBAyeGv0exc.GieVkTxp4HH}

An example combining program indicators and aggregate indicators:

    I{EMOt6Fwhs1n} * 1000 / #{WUg3MYWQ7pt}

An example using a reporting rate:

    R{BfMAe6Itzgt.REPORTING_RATE} * #{P3jJH5Tu5VC.S34ULMcHMca}

Another reporting rate example using actual data set reports and expected reports:

    R{BfMAe6Itzgt.ACTUAL_REPORTS} / R{BfMAe6Itzgt.EXPECTED_REPORTS}

An example using an existing indicator:

    N{Rigf2d2Zbjp} * #{P3jJH5Tu5VC.S34ULMcHMca}

Expressions can be any kind of valid mathematical expression, as an
example:

    ( 2 * #{P3jJH5Tu5VC.S34ULMcHMca} ) / ( #{FQ2o8UBlcrS.S34ULMcHMca} - 200 ) * 25

### ![](resources/images/pivot_table/table_layout.png) { #webapi_program_indicators } 

To retrieve program indicators you can make a GET request to the program
indicators resource like this:

    /api/programIndicators

Program indicators can contain information collected in a program.
Indicators have an expression which can contain references to data
elements, attributes, constants and program variables. Variables which
are allowed in expressions are described in the following table.



Table: Program indicator variables

| Variable | Description |
|---|---|
| #{<programstage-id\>.<dataelement-id\>} | Refers to a combination of program stage and data element id. |
| A{<attribute-id\>} | Refers to a tracked entity attribute. |
| V{<variable-id\>} | Refers to a program variable. |
| C{<constant-id\>} | Refers to a constant. |

The syntax looks like
    this:

    #{<programstage-id>.<dataelement-id>} + #{<attribute-id>} + V{<varible-id>} + C{<constant-id>}

A corresponding example looks like
    this:

    #{A03MvHHogjR.a3kGcGDCuk6} + A{OvY4VVhSDeJ} + V{incident_date} + C{bCqvfPR02Im}

### Expressions { #webapi_expressions } 

Expressions are mathematical formulas which can contain references to
data elements, constants and organisation unit groups. To validate and
get the textual description of an expression, you can make a GET request
to the expressions resource:

    /api/expressions/description?expression=<expression-string>

The response follows the standard JSON web message format. The *status*
property indicates the outcome of the validation and will be "OK" if
successful and "ERROR" if failed. The *message* property will be "Valid"
if successful and provide a textual description of the reason why the
validation failed if not. The *description* provides a textual
description of the expression.

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Valid",
  "description": "Acute Flaccid Paralysis"
}
```

## Les unités d’organisation { #webapi_organisation_units } 

The *organisationUnits* resource follows the standard conventions as
other metadata resources in DHIS2. This resource supports some
additional query parameters.

### Get list of organisation units { #webapi_list_of_organisation_units } 

To get a list of organisation units you can use the following resource.

    /api/33/organisationUnits

Table: Organisation units query parameters

| Paramètre de requête | Options | Description |
|---|---|---|
| userOnly | faux &#124; vrai | Data capture organisation units associated with current user only. |
| userDataViewOnly | faux &#124; vrai | Data view organisation units associated with current user only. |
| userDataViewFallback | faux &#124; vrai | Data view organisation units associated with current user only with fallback to data capture organisation units. |
| requête | string | Query against the name, code and ID properties. |
| District | entier | Organisation units at the given level in the hierarchy. |
| maxLevel | entier | Organisation units at the given max level or levels higher up in the hierarchy. |
| withinUserHierarchy | faux &#124; vrai | Limits search and retrieval to organisation units that are within the users data capture scope. |
| withinUserSearchHierarchy | faux &#124; vrai | Limits search and retrieval to organisation units that are within the current users search scope. Note: "withinUserHierarchy", if true, takes higher precedence. |
| memberCollection | string | For displaying count of members within a collection, refers to the name of the collection associated with organisation units. |
| memberObject | UID | For displaying count of members within a collection, refers to the identifier of the object member of the collection. |

### Get organisation unit with sub-hierarchy { #webapi_organisation_units_with_sub_hierarchy } 

To get an organisation unit including organisation units in its sub-hierarchy you can use the following resource.

    /api/33/organisationUnits/{id}

Table: Organisation unit parameters

| Paramètre de requête | Options | Description |
|---|---|---|
| Inclut les enfants | faux &#124; vrai | Include immediate children of the specified organisation unit, i.e. the units at the immediate level below in the subhierarchy. |
| includeDescendants | faux &#124; vrai | Include all children of the specified organisation unit, i.e. all units in the sub-hierarchy. |
| includeAncestors | faux &#124; vrai | Include all parents of the specified organisation unit. |
| District | entier | Include children of the specified organisation unit at the given level of the sub-hierarchy. This is relative to the organisation unit, starting on 1 for the level immediately below the org unit. |

### Get organisation units by category option  { #webapi_organisation_units_by_category_options }

Purpose-built endpoint to retrieve associations between category options and organisation units. This endpoint is the preferred way to retrieve program organisation unit associations.

    /api/33/categoryOptions/orgUnits?categoryOptions={categoryOptionIdA},{categoryOptionIdB}

responses will have the following format:

```json
{
  "<categoryOptionIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<categoryOptionIdC>": []
}
```

Category options that are accessible by all organisation units are returned with an empty array (`[]`) of organisation units.

### Get organisation units by programs { #webapi_organisation_units_by_programs } 

Purpose-built endpoint to retrieve associations between programs and organisation units. This endpoint is the preferred way to retrieve program organisation unit associations.

    /api/33/programs/orgUnits?programs={programIdA},{programIdB}

responses will have the following format:

```json
{
  "<programIdA>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdB>": [
    "<orgUnitUid>",
    "<orgUnitUid>"
  ],
  "<programIdC>": []
}
```

Programs which are accessible by all organisation units are returned with an empty array (`[]`) of organisation units.

### Split organisation unit { #webapi_organisation_unit_split }

The organisation unit split endpoint allows you to split organisation units into a number of target organisation units. 

#### Request { #request } 

Split organisation units with a POST request:

```
POST /api/organisationUnits/split
```

The payload in JSON format looks like the following:

```json
{
  "source": "rspjJHg4WY1",
  "targets": [
    "HT0w9YLMLyn",
    "rEpnzuNpRKM"
  ],
  "primaryTarget": "HT0w9YLMLyn",
  "deleteSource": true
}
```

The JSON properties are described in the following table.

Table: Split payload fields

| Champ         | Obligatoire | Valeur |
| ------------- | -------- |------ |
| source        | Oui      | Identifier of the organisation unit to split (the source organisation unit). |
| targets       | Oui      | Array of identifiers of the organisation units to split the source into (the target organisation units). |
| primaryTarget | Non       | Identifier of the organisation unit to transfer the aggregate data, events and tracked entities associated with the source over to. If not specified, the first target will be used. |
| deleteSource  | Non       | Whether to delete the source organisation unit after the operation. Default is `true`. |

The split operation will split the source org unit into the target org units. It is recommended to first create new target org units before performing the split, and at a minimum ensure that no aggregate data exists for the target org units. Any number of target org units can be specified.

The split operation will transfer all of the metadata associations of the source org unit over to the target org units. This includes data sets, programs, org unit groups, category options, users, visualizations, maps and event reports.

The operation will transfer all data records of the source org unit over to the org unit specified as the primary target, or if not specified, the first specified target org unit. This includes aggregate data values, data approval records, events, tracked entities and more.

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| Code d'erreur | Description                                     |
| ---------- | ----------------------------------------------- |
| E1510      | Source org unit must be specified               |
| E1511      | At least two target org units must be specified |
| E1512      | Source org unit cannot be a target org unit     |
| E1513      | Primary target must be specified                |
| E1514      | Primary target must be a target org unit        |
| E1515      | Target org unit does not exist                  |

### Merge organisation units { #webapi_organisation_unit_merge}

The organisation unit merge endpoint allows you to merge a number of organisation units into a target organisation unit.

#### Request { #request } 

Merge organisation units with a POST request:

```
POST /api/organisationUnits/merge
```

The payload in JSON format looks like the following:

```json
{
  "sources": [
    "jNb63DIHuwU",
    "WAjjFMDJKcx"
  ],
  "target": "V9rfpjwHbYg",
  "dataValueMergeStrategy": "LAST_UPDATED",
  "dataApprovalMergeStrategy": "LAST_UPDATED",
  "deleteSources": true
}
```

The JSON properties are described in the following table.

Table: Merge payload fields

| Champ                     | Obligatoire | Valeur |
| ------------------------- | -------- | ----- |
| sources                   | Oui      | Array of identifiers of the organisation units to merge (the source organisation units). |
| target                    | Oui      | Identifier of the organisation unit to merge the sources into (the target organisation unit). |
| dataValueMergeStrategy    | Non       | Strategy for merging data values. Options: `LAST_UPDATED` (default), `DISCARD`. |
| dataApprovalMergeStrategy | Non       | Strategy for merging data approval records. Options: `LAST_UPDATED` (default), `DISCARD`. |
| deleteSources             | Non       | Whether to delete the source organisation units after the operation. Default is true. |

The merge operation will merge the source org units into the target org unit. It is recommended to first create a new target org unit before performing the merge, and at a minimum ensure that no aggregate data exists for the target org unit. Any number of source org units can be specified.

The merge operation will transfer all of the metadata associations of the source org units over to the target org unit. This includes data sets, programs, org unit groups, category options, users, visualizations, maps and event reports. The operation will also transfer all event and tracker data, such as events, enrollments, ownership history, program ownership and tracked entities, over to the target org unit.

The specified data value merge strategy defines how data values are handled. For strategy `LAST_UPDATED`, data values for all source org units are transferred over to the target org unit, and in situation where data values exist for the same parameters, the last updated or created data value will be used. This is done to avoid duplication of data. For strategy `DISCARD`, data values are not transferred over to the target org unit, and simply deleted. The specified data approval merge strategy defines how data approval records are handled, and follows the same logic as data values.

#### Validation { #validation } 

The following constraints and error codes apply.

Table: Constraints and error codes

| Code d'erreur | Description                                     |
| ---------- | ----------------------------------------------- |
| E1500      | At least two source orgs unit must be specified |
| E1501      | Target org unit must be specified               |
| E1502      | Target org unit cannot be a source org unit     |
| E1503      | Source org unit does not exist                  |

## Ensembles de données { #webapi_data_sets } 

The *dataSets* resource follows the standard conventions as other
metadata resources in DHIS2. This resource supports some additional
query parameters.

    /api/33/dataSets

To retrieve the version of a data set you can issue a GET request:

    GET /api/33/dataSets/<uid>/version

To bump (increase by one) the version of a data set you can issue a POST
request:

    POST /api/33/dataSets/<uid>/version

### Data set notification template { #webapi_dataset_notifications } 

The *dataset notification templates* resource follows the standard
conventions as other metadata resources in DHIS2.

    GET /api/33/dataSetNotficationTemplates

To retrieve data set notification template you can issue a GET request:

    GET /api/33/dataSetNotficationTemplates/<uid>

To add data set notification template you can issue a POST request:

    POST /api/33/dataSetNotficationTemplates

To delete data set notification template you can issue a DELETE request:

    DELETE /api/33/dataSetNotficationTemplates/<uid>

JSON payload sample is given below:

```json
{
  "name": "dataSetNotificationTemplate1",
  "notificationTrigger": "COMPLETION",
  "relativeScheduledDays": 0,
  "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
  "dataSets": [{
    "id": "eZDhcZi6FLP"
  }],
  "deliveryChannels": ["SMS"],
  "subjectTemplate": "V{data_name}",
  "messageTemplate": "V{data_name}V{complete_registration_period}",
  "sendStrategy": "SINGLE_NOTIFICATION"
}

```

## Filled organisation unit levels { #webapi_filled_organisation_unit_levels } 

The *filledOrganisationUnitLevels* resource provides an ordered list of
organisation unit levels, where generated levels are injected into the
list to fill positions for which it does not exist a persisted level.

    GET /api/33/filledOrganisationUnitLevels

To set the organisation unit levels you can issue a POST request with a
JSON payload and content type `application/json` looking like this:

```json
{
  "organisationUnitLevels": [{
    "name": "National",
    "level": 1,
    "offlineLevels": 3
  }, {
    "name": "District",
    "level": 2
  }, {
    "name": "Chiefdom",
    "level": 3
  }, {
    "name": "Facility",
    "level": 4
  }]
}
```

## Les prédicteurs { #webapi_predictors } 

A predictor allows you to generate data values based on an expression.
This can be used for example to generate targets, thresholds,
or estimated values.

To retrieve predictors you can make a GET request to the predictors
resource like this:

    /api/predictors

### Creating a predictor { #webapi_create_predictor } 

You can create a predictor with a POST request to the predictors
resource:

    POST /api/predictors

A sample payload looks like this:

```json
{
  "id": "AG10KUJCrRk",
  "name": "Malaria Outbreak Threshold Predictor",
  "shortName": "Malaria Outbreak Predictor",
  "description": "Computes the threshold for potential malaria outbreaks based on the mean plus 1.5x the std dev",
  "output": {
    "id": "nXJJZNVAy0Y"
  },
  "generator": {
    "expression": "AVG(#{r6nrJANOqMw})+1.5*STDDEV(#{r6nrJANOqMw})",
    "description": "Maximum normal malaria case count",
    "missingValueStrategy": "NEVER_SKIP",
    "slidingWindow": false
  },
  "periodType": "Monthly",
  "sequentialSampleCount": 4,
  "sequentialSkipCount": 1,
  "annualSampleCount": 3,
  "organisationUnitLevels": [4]
}
```

The output element refers to the identifier of the data element for
which to saved predicted data values. The generator element refers to the
expression to use when calculating the predicted values.

### Predictor expressions { #webapi_predictor_expressions } 

A predictor always has a generator expression that describes how the
predicted value is calculated. A predictor may also have a skip test
expression returning a boolean value. When the skip test expression is
present, it is evaluated in each of the sampled periods to tell whether
values from that period should be skipped.

The following variables may be used in either a generator expression
or a skip test expression:

| Variable    | Objet     | Description |
| ----------- | ---------- | ----------- |
| #{<dataelement-id>} | Aggregate data element | Refers to the total value of an aggregate data element across all category option combinations. |
| #{<dataelement-id>.<categoryoptcombo-id> | Data element operand | Refers to a combination of an aggregate data element and a category option combination. |
| D{<program-id>.<dataelement-id>} | Program data element | Refers to the value of a tracker data element within a program. |
| A{<program-id>.<attribute-id>} | Program tracked entity attribute | Refers to the value of a tracked entity attribute within a program. |
| I{<program-indicator-id>} | Indicateur de programme | Refers to the value of a program indicator. |
| R{<dataset-id>.<metric>} | Taux de déclaration | Refers to a reporting rate metric. The metric can be REPORTING_RATE, REPORTING_RATE_ON_TIME, ACTUAL_REPORTS, ACTUAL_REPORTS_ON_TIME, EXPECTED_REPORTS. |
| C{<constant-id>} | Constante | Refers to a constant value. |
| OUG{<orgunitgroup-id>} | Groupe d'unités d'organisation | Refers to the count of organisation units within an organisation unit group. |
| [days] | Number of days | The number of days in the current period. |

### Generating predicted values { #webapi_generating_predicted_values } 

To run all predictors (generating predicted values) you can make a POST
request to the run resource:

    POST /api/predictors/run

To run a single predictor you can make a POST request to the run
resource for a predictor:

    POST /api/predictors/AG10KUJCrRk/run

## Règles du programme { #webapi_program_rules } 

This section is about sending and reading program rules, and explains
the program rules data model. The program rules give functionality to
configure dynamic behaviour in the programs in DHIS2.

### Program rule model { #webapi_program_rule_model } 

The program rules data model consists of programRuleVariables,
programRules and programRuleActions. The programRule contains an
expression - when this expression is true, the child programRuleActions
is triggered. The programRuleVariables is used to address data elements,
tracked entity data values and other data values needed to run the
expressions. All programRules in a program share the same library of
programRuleVariables, and one programRuleVariable can be used in several
programRules' expressions.

![](resources/images/program_rules/program-rule-model.jpg)

#### Program rule model details { #program-rule-model-details } 

The following table gives a detailed overview over the programRule
model.

Table: programRule

| nom | Description | Compulsory |
|---|---|---|
| de paludisme) ». | The program of which the programRule is executed in. | Compulsory |
| nom | The name with which the program rule will be displayed to dhis2 configurators. Not visible to the end user of the program. | Compulsory |
| Description | The description of the program rule, can be used by configurators to describe the rule. Not visible to the end user of the program. | Compulsory |
| Étape du programme | If a programStage is set for a program rule, the rule will only be evaluated inside the specified program stage. | optional |
| condition | The expression that needs to be evaluated to true in order for the program rule to trigger its child actions. The expression is written using operators, function calls, hard coded values, constants and program rule variables. `d2:hasValue('hemoglobin') && #{hemoglobin} <= 7 `| Compulsory |
| priorité | The priority to run the rule in cases where the order of the rules matters. In most cases the rules does not depend on being run before or after other rules, and in these cases the priority can be omitted. If no priority is set, the rule will be run after any rules that has a priority defined. If a priority(integer) is set, the rule with the lowest priority will be run before rules with higher priority. | optional |

#### Program rule action model details { #program-rule-action-model-details } 

The following table gives a detailed overview over the programRuleAction
model.

Table: programRuleAction

| nom | Description | Compulsory |
|---|---|---|
| programRule | The programRule that is the parent of this action. | Compulsory |
| programRule- ActionType | The type of action that is to be performed.<br>  * `DISPLAYTEXT` - Displays a text in a given widget.<br> * `DISPLAYKEYVALUEPAIR` - Displays a key and value pair(like a program indicator) in a given widget.<br> * `HIDEFIELD` - Hide a specified dataElement or trackedEntityAttribute.<br>    -         *content* - if defined, the text in *content* will be displayed to the end user in the instance where a value is previously entered into a field that is now about to be hidden (and therefore blanked). If *content* is not defined, a standard message will be shown to the user in this instance.<br>   -         *dataElement* - if defined, the HIDEFIELD action will hide this dataElement when the rule is effective.<br>   -         *trackedEntityDataValue* - if defined, the HIDEFIELD action will hide this trackedEntityDataValue when the rule is effective.<br>  * `HIDESECTION` - Hide a specified section.<br>    -         *programStageSection* - must be defined. This is the programStageSection that will be hidden in case the parent rule is effective.<br>  * `ASSIGN` - Assign a dataElement a value(help the user calculate something or fill in an obvious value somewhere)<br>    -         *content* - if defined, the value in *data* is assigned to this variable. If content id defined, and thus a variable is assigned for use in other rules, it is important to also assign a *programRule.priority* to make sure the rule with an ASSIGN action runs before the rule that will in turn evaluate the assigned variable.<br>   -         *data* - must be defined, data forms an expression that is evaluated and assigned to either a variable(#{myVariable}), a dataElement, or both.<br>   -         *dataElement* - if defined, the value in *data* is assigned to this data element.<br>  Either the content or dataElement must be defined for the ASSIGN action to be effective.<br> * `SHOWWARNING` - Show a warning to the user, not blocking the user from completing the event or registration.<br>    -         *content* - if defined, content is a static part that is displayed at the end of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the warning message.<br>   -         *dataElement* - if defined, the warning message is displayed next to this data element.<br>   -         *trackedEntityAttribute* - if defined, the warning message is displayed next to this tracked entity attribute.<br>  Either dataElement or trackedEntityAttribute must be specified.<br> * `SHOWERROR` - Show an error to the user, blocking the user from completing the event or registration.<br>    -         *content* - if defined, content is a static part that is displayed in the start of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the error message.<br>   -         *dataElement* - if defined, the error message is linked to this data element.<br>   -         *trackedEntityAttribute* - if defined, the error message is linked to this tracked entity attribute.<br>  Either dataElement or trackedEntityAttribute must be specified.<br> * `WARNINGONCOMPLETE` - Show a warning to the user on the "Complete form" dialog, but allowing the user to complete the event.<br>    -         *content* - if defined, content is a static part that is displayed at the end of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the warning message.<br>   -         *dataElement* - if defined, the warning message prefixed with the name/formName of the data element.<br>  * `ERRORONCOMPLETE` - Show an error to the user on in a modal window when the user tries to complete the event. The user is prevented from completing the event.<br>    -         *content* - if defined, content is a static part that is displayed in the start of the error message.<br>   -         *data* - if defined, data forms an expression that is evaluated and added to the end of the error message.<br>   -         *dataElement* - if defined, the error message is linked to this data element.<br>  * `CREATEEVENT` - Create an event within the same enrollment.<br>    -         *content*<br>   -         *data* - if defined, contains data values to assign the created event. The format is <uid\>:<data value\>. Where several values is specified, these are separated with comma.<br> AcMrnleqHqc:100,AqK1IHqCkEE:'Polyhydramnios'   -         *programStage* - must be defined, and designates the program stage that the rule shall create an event of.<br>  * `SETMANDATORYFIELD` - Set a field to be mandatory.<br>    -         *dataElement* - if defined, this data element will be set to be mandatory in the data entry form.<br>   -         *trackedEntityAttribute* - if defined, this tracked entity attribute will be set to mandatory in the registration form or profile.<br>  * `SENDMESSAGE` - To send message at completion of event/enrollment or at data value update.<br>    -         *messageTemplate* - if defined, this template will be delivered either as SMS or EMAIL depending upon DeliveryChannel value in message template.<br>  * `SCHEDULEMESSAGE` - To schedule message at completion of event/enrollment or at data value update.<br>    -         *messageTemplate* - if defined, this template will be delivered either as SMS or EMAIL depending upon DeliveryChannel value in message template.<br>   -         *Date to send message* - Expression which is going to be used for evaluation of scheduled date. This expression should result in Date, any other resultant will be discarded and notification will not get scheduled. | Compulsory |
| location | Used for actionType DISPLAYKEYVALUEPAIR and DISPLAYTEXT to designate which widget to display the text or keyvaluepair in. Compulsory for DISPLAYKEYVALUEPAIR and DISPLAYTEXT. | See description |
| content | Used for user messages in the different actions. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, DISPLAYTEXT and DISPLAYKEYVALUEPAIR. Optional for HIDEFIELD and ASSIGN. | See description |
| données | Used for expressions in the different actions. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for ASSIGN. Optional for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, DISPLAYTEXT, CREATEEVENT and DISPLAYKEYVALUEPAIR | See description |
| élément de données | Used for linking rule actions to dataElements. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for SHOWWARNING, SHOWERROR, WARNINGONCOMPLETE, ERRORONCOMPLETE, ASSIGN and HIDEFIELD | See description |
| trackedEntity- Attribute | Used for linking rule actions to trackedEntityAttributes. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for SHOWWARNING, SHOWERROR and HIDEFIELD. | See description |
| option | Used for linking rule actions to options. See the actionType overview for a detailed explanation for how it is used in each of the action types. Optional for HIDEOPTION | See description |
| optionGroup | Used for linking rule actions to optionGroups. See the actionType overview for a detailed explanation for how it is used in each of the action types. Compulsory for SHOWOPTIONGROUP, HIDEOPTIONGROUP. | See description |
| Étape du programme | Only used for CREATEEVENT rule actions. Compulsory for CREATEEEVENT. | See description |
| programStage- Section | Only used for HIDESECTION rule actions. Compulsory for HIDESECTION | See description |

##### ProgramRuleAction Validation { #programruleaction-validation } 
There are certain validations added to ProgramRuleAction model in 2.37. Main purpose was to keep user from creating erroneous ProgramRules in order to keep the database consistent. These validations depends on program rule action type. Each action type has its own respective validation. 

Table: ProgramRuleAction Validations

| nom | validation check for id existence |
|---|---|
|SENDMESSAGE| Notification template id |
|SCHEDULEMESSAGE| Notification template id |
|HIDESECTION| ProgramStage section id |
|HIDEPROGRAMSTAGE| ProgramStage id |
|HIDEFIELD| DataElement or TrackedEntityAttribute id |
|HIDEOPTION| Option id |
|HIDEOPTIONGROUP| Option group id |
|SHOWOPTIONGROUP| Option group id |
|SETMANDATORYFIELD| DataElement or TrackedEntityAttribute id |
|SHOWERROR| Always valid |
|SHOWWARNING| Always valid |
|DISPLAYTEXT| DataElement or TrackedEntityAttribute id |
|DISPLAYKEYVALUEPAIR||
|ASSIGN| DataElement or TrackedEntityAttribute id |
|WARNINGONCOMPLETE| DataElement or TrackedEntityAttribute id |
|ERRORONCOMPLETE| DataElement or TrackedEntityAttribute id |

Apart from above validations, `data` field in program rule action which normally contains expression can also be evaluated using below api endpoint.

    POST /api/programRuleActions/data/expression/description?programId=<uid>


```json
{
  "condition": "1 + 1"
}
```

#### Program rule variable model details { #program-rule-variable-model-details } 

The following table gives a detailed overview over the
programRuleVariable model.

Table: programRuleVariable

| nom | Description | Compulsory |
|---|---|---|
| nom | the name for the programRuleVariable - this name is used in expressions. #{myVariable} \> 5 | Compulsory |
| sourceType | Defines how this variable is populated with data from the enrollment and events. <br> * DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE - In tracker capture, gets the newest value that exists for a data element, within the events of a given program stage in the current enrollment. In event capture, gets the newest value among the 10 newest events on the organisation unit.<br> * DATAELEMENT_NEWEST_EVENT_PROGRAM - In tracker capture, get the newest value that exists for a data element across the whole enrollment. In event capture, gets the newest value among the 10 newest events on the organisation unit.<br> * DATAELEMENT_CURRENT_EVENT - Gets the value of the given data element in the current event only.<br> * DATAELEMENT_PREVIOUS_EVENT - In tracker capture, gets the newest value that exists among events in the program that precedes the current event. In event capture, gets the newvest value among the 10 preceeding events registered on the organisation unit.<br> * CALCULATED_VALUE - Used to reserve a variable name that will be assigned by a ASSIGN program rule action<br> * TEI_ATTRIBUTE - Gets the value of a given tracked entity attribute | Compulsory |
| élément de données | Used for linking the programRuleVariable to a dataElement. Compulsory for all sourceTypes that starts with DATAELEMENT_. | See description |
| trackedEntity- Attribute | Used for linking the programRuleVariable to a trackedEntityAttribute. Compulsory for sourceType TEI_ATTRIBUTE. | See description |
| useCodeFor- OptionSet | If checked, the variable will be populated with the code - not the name - from any linked option set. Default is unchecked, meaning that the name of the option is populated. ||
| Étape du programme | Used for specifying a specific program stage to retreive the programRuleVariable value from. Compulsory for DATAELEMENT_NEWEST_EVENT_PROGRAM_STAGE. | See description |

### Creating program rules { #webapi_creating_program_rules } 

- To perform crud operations, `programRules` resource is available in API.

To retrieve list of programRules you can do a GET request like this:

    /api/programRules

To retrieve single programRule you can do a GET request like this:

    /api/programRules/<program_rule_uid>

To save/add single programRule you can do a POST request like this:

    /api/programRules/<program_rule_uid>

To update single programRule you can do a PUT request like this:

    /api/programRules/<program_rule_uid>

To delete single programRule you can do a DELETE request like this:

    /api/programRules/<program_rule_uid>

To retrieve description of programRule condition you can use POST and provide condition string in the POST body.

    /api/programRules/condition/description?<program_rule_uid>

## Forms { #webapi_forms } 

To retrieve information about a form (which corresponds to a data set
and its sections) you can interact with the `form` resource. The form
response is accessible as XML and JSON and will provide information
about each section (group) in the form as well as each field in the
sections, including labels and identifiers. By supplying period and
organisation unit identifiers the form response will be populated with
data values.

Table: Form query parameters

| Paramètre | Option | Description |
|---|---|---|
| pe | ISO period | Period for which to populate form data values. |
| ou | UID | Organisation unit for which to populate form data values. |
| metaData | faux &#124; vrai | Whether to include metadata about each data element of form sections. |

To retrieve the form for a data set you can do a GET request like this:

    /api/dataSets/<dataset-id>/form.json

To retrieve the form for the data set with identifier "BfMAe6Itzgt" in
XML:

    /api/dataSets/BfMAe6Itzgt/form

To retrieve the form including metadata in JSON:

    /api/dataSets/BfMAe6Itzgt/form.json?metaData=true

To retrieve the form filled with data values for a specific period and
organisation unit in XML:

    /api/dataSets/BfMAe6Itzgt/form.xml?ou=DiszpKrYNg8&pe=201401

When it comes to custom data entry forms, this resource also allows for
creating such forms directly for a data set. This can be done through a
POST or PUT request with content type text/html where the payload is the
custom form markup such as:

```bash
curl -d @form.html "localhost/api/dataSets/BfMAe6Itzgt/form"
  -H "Content-Type:text/html" -u admin:district -X PUT
```

## Documents { #webapi_documents } 

References to files can be stored with the document resource.



Table: Document fields

| Field name | Description |
|---|---|
| nom | unique name of document |
| external | flag identifying the location of the document. TRUE for external files, FALSE for internal ones |
| url | the location of the file. URL for external files. File resource id for internal ones (see [File resources](#webapi_file_resources)) |

A GET request to the documents endpoint will return all documents:

    /api/documents

A POST request to the documents endpoint will create a new document:

```bash
curl -X POST -d @document.json -H "Content-type: application/json"
  "http://dhis.domain/api/documents"
```

```json
{
  "name": "dhis home",
  "external": true,
  "url": "https://www.dhis2.org"
}
```

A GET request with the id of a document appended will return information
about the document. A PUT request to the same endpoint will update the
fields of the document:

    /api/documents/<documentId>

Appending */data* to the GET request will return the actual file content
of the document:

    /api/documents/<documentId>/data

## CSV metadata import { #webapi_csv_metadata_import } 

DHIS2 supports import of metadata in the CSV format, such as data elements, organisation units and validation rules. Properties for the various metadata objects are identified based on the column order/column index (see below for details). You can omit non-required object properties/columns, but since the column order is significant, an empty column must be included. In other words, if you would like to specify properties/columns which appear late in the column order but not specify certain columns which appear early in the order you can include empty/blank columns for them.

The first row of the CSV file is considered to be a header and is ignored during import. The _comma_ character should be used as a text delimiter. Text which contains commas must be enclosed in _double quotes_.

To upload metadata in CSV format you can make a POST request to the metadata endpoint:

    POST /api/metadata?classKey=CLASS-KEY

The following object types are supported. The `classKey` query parameter is mandatory and can be found next to each object type in the table below.

Table: Object types and keys

| Type d'objet | Class key |
|---|---|
| Des éléments de données | DATA_ELEMENT |
| Groupes d'éléments de données | DATA_ELEMENT_GROUP |
| Les options de catégorie | CATEGORY_OPTION |
| Category option groups | CATEGORY_OPTION_GROUP |
| Unités d’organisation | ORGANISATION_UNIT |
| Groupes d'unités d'organisation | ORGANISATION_UNIT_GROUP |
| Règles de validation | VALIDATION_RULE |
| Option sets | OPTION_SET |
| Les traductions | TRANSLATION |

> **Tip**
>
> If using *curl*, the `--data-binary` option should be used as it preserves line breaks and newlines, which is essential for CSV data.

As an example, to upload a file of data elements in CSV format with `curl` you can use the following command:

```bash
curl --data-binary @data_elements.csv "http://localhost/api/metadata?classKey=DATA_ELEMENT"
  -H "Content-Type:application/csv" -u admin:district
```

The formats for the currently supported object types for CSV import are listed in the following sections.

### Eléments de données { #webapi_csv_data_elements } 

Table: Data Element CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 char. Unique. |
| 2 | UID | Non | UID | Stable identifier. Exactly 11 alpha-numeric characters, beginning with a letter. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 char. |
| 4 | Nom abrégé | Non | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 char. Unique. |
| 5 | Description | Non || Free text description. |
| 6 | Nom du formulaire | Non || Max 230 char. |
| 7 | Type de domaine | Non | AGGREGATE &#124; TRACKER | Domain type for data element, can be aggregate or tracker. Max 16 char. |
| 8 | Type de valeur | Non | INTEGER &#124; NUMBER &#124; UNIT_INTERVAL &#124; PERCENTAGE &#124; INTEGER_POSITIVE &#124; INTEGER_NEGATIVE &#124; INTEGER_ZERO_OR_POSITIVE &#124; FILE_RESOURCE &#124; COORDINATE &#124;TEXT &#124; LONG_TEXT &#124; LETTER &#124; PHONE_NUMBER &#124; EMAIL &#124; BOOLEAN &#124; TRUE_ONLY &#124; DATE &#124; DATETIME | Value type. Max 16 char. |
| 9 | Type d'agrégation | Non | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX &#124; NONE | Aggregation type indicating how to aggregate data in various dimensions. Max 16 char. |
| 10 | La combinaison de catégories | Non | UID | UID of category combination. Will default to default category combination if not specified. |
| 11 | Url | Non || URL to data element resource. Max 255 char. |
| 12 | Zero is significant | Non | faux &#124; vrai | Indicates whether zero values will be stored for this data element. |
| 13 | Ensemble d'options | Non | UID | UID of option set to use for data. |
| 14 | Comment option set | Non | UID | UID of option set to use for comments. |

An example of a CSV file for data elements can be seen below. The first
row will always be ignored. Note how you can skip columns and rely on
default values to be used by the system. You can also skip columns which
you do not use which appear to the right of the ones

```csv
name,uid,code,shortname,description
"Women participated skill development training",,"D0001","Women participated in training"
"Women participated community organizations",,"D0002","Women participated in organizations"
```

### Les unités d’organisation { #webapi_csv_org_units } 

Table: Organisation Unit CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 characters. Unique. |
| 2 | UID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 char. |
| 4 | Parent | Non | UID | UID of parent organisation unit. |
| 5 | Nom abrégé | Non | 50 first char of name | Will fall back to first 50 characters of name if unspecified. Max 50 characters. Unique. |
| 6 | Description | Non || Free text description. |
| 7 | Date d'ouverture | Non | 1970-01-01 | Opening date of organisation unit in YYYY-MM-DD format. |
| 8 | Closed date | Non || Closed date of organisation unit in YYYY-MM-DD format, skip if currently open. |
| 9 | Commentaire | Non || Free text comment for organisation unit. |
| 10 | Feature type | Non | NONE &#124; MULTI_POLYGON &#124; POLYGON &#124; POINT &#124; SYMBOL | Geospatial feature type. |
| 11 | Coordinates | Non || Coordinates used for geospatial analysis in Geo JSON format. |
| 12 | URL | Non || URL to organisation unit resource. Max 255 char. |
| 13 | Personne de contact | Non || Contact person for organisation unit. Max 255 char. |
| 14 | Addresse | Non || Address for organisation unit. Max 255 char. |
| 15 | Adresses électronique | Non || Email for organisation unit. Max 150 char. |
| 16 | Numéro de téléphone | Non || Phone number for organisation unit. Max 150 char. |

A minimal example for importing organisation units with a parent unit
looks like this:

```csv
name,uid,code,parent
"West province",,"WESTP","ImspTQPwCqd"
"East province",,"EASTP","ImspTQPwCqd"
```

### Règles de validation { #webapi_csv_validation_rules } 

Table: Validation Rule CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 characters. Unique. |
| 2 | UID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 |
| 4 | Description | Non || Free text description. |
| 5 | Instruction | Non || Free text instruction. |
| 6 | Importance | Non | MEDIUM &#124; HIGH &#124; LOW | Importance of validation rule. |
| 7 | Rule type (ignored) | Non | VALIDATION &#124; SURVEILLANCE | Type of validation rule. |
| 8 | Opérateur | Non | equal_to &#124; not_equal_to &#124; greater_than &#124; greater_than_or_equal_to &#124; less_than &#124; less_than_or_equal_to &#124; compulsory_pair &#124; exclusive_pair | Expression operator. |
| 9 | Type de période | Non | Monthly &#124; Daily &#124; Weekly &#124; Quarterly &#124; SixMontly &#124; Yearly | Period type. |
| 10 | Left side expression | Oui || Mathematical formula based on data element and option combo UIDs. |
| 11 | Left side expression description | Oui || Free text. |
| 12 | Left side missing value strategy | Non | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124; NEVER_SKIP | Behavior in case of missing values in left side expression. |
| 13 | Right side expression | Oui || Mathematical formula based on data element and option combo UIDs. |
| 14 | Right side expression description | Oui || Free text. |
| 15 | Right side missing value strategy | Non | SKIP_IF_ANY_VALUE_MISSING &#124; SKIP_IF_ALL_VALUES_MISSING &#124; NEVER_SKIP | Behavior in case of missing values in right side expression. |

### Option sets { #webapi_csv_option_sets } 

Table: Option Set CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | OptionSetName | Oui || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionSetUID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionSetCode | Non || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionName | Oui || Option name. Max 230 characters. |
| 5 | OptionUID | Non | UID | Stable identifier. Max 11 char. Will be generated by system if not specified. |
| 6 | OptionCode | Oui || Stable code. Max 50 char. |

The format for option sets is special. The three first values represent
an option set. The three last values represent an option. The first
three values representing the option set should be repeated for each
option.

```csv
optionsetname,optionsetuid,optionsetcode,optionname,optionuid,optioncode
"Color",,"COLOR","Blue",,"BLUE"
"Color",,"COLOR","Green",,"GREEN"
"Color",,"COLOR","Yellow",,"YELLOW"
"Sex",,,"Male",,"MALE"
"Sex",,,"Female",,"FEMALE"
"Sex",,,"Unknown",,"UNKNOWN"
"Result",,,"High",,"HIGH"
"Result",,,"Medium",,"MEDIUM"
"Result",,,"Low",,"LOW"
"Impact","cJ82jd8sd32","IMPACT","Great",,"GREAT"
"Impact","cJ82jd8sd32","IMPACT","Medium",,"MEDIUM"
"Impact","cJ82jd8sd32","IMPACT","Poor",,"POOR"
```

### Option group { #option-group } 

Table: Option Group CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | OptionGroupName | Oui || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionGroupUid | Non || Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionGroupCode | Non || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionGroupShortName | Oui || Short Name. Max 50 characters. Unique. Should be repeated for each option. |
| 5 | OptionSetUid | Oui || Stable identifier. Max 11 char. Should be repeated for each option. |
| 6 | OptionUid | Non || Stable identifier. Max 11 char. |
| 7 | OptionCode | Non || Stable code. Max 50 char. |

Sample OptionGroup CSV payload

```csv
optionGroupName,optionGroupUid,optionGroupCode,optionGroupShortName,optionSetUid,optionUid,optionCode
optionGroupA,,,groupA,xmRubJIhmaK,,OptionA
optionGroupA,,,groupA,xmRubJIhmaK,,OptionB
optionGroupB,,,groupB,QYDAByFgTr1,,OptionC
```
### Option Group Set { #option-group-set } 



Table: Option Group Set CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | OptionGroupSetName | Oui || Name. Max 230 characters. Unique. Should be repeated for each option. |
| 2 | OptionGroupSetUid | Non || Stable identifier. Max 11 char. Will be generated by system if not specified. Should be repeated for each option. |
| 3 | OptionGroupSetCode | Non || Stable code. Max 50 char. Should be repeated for each option. |
| 4 | OptionGroupSetDescription | Non || Description. Should be repeated for each option. |
| 5 | DataDimension | Non || TRUE, FALSE |
| 6 | OptionSetUid | Non || OptionSet UID. Stable identifier. Max 11 char. |

Sample OptionGroupSet CSV payload

```csv
name,uid,code,description,datadimension,optionsetuid
optiongroupsetA,,,,,xmRubJIhmaK
optiongroupsetB,,,,false,QYDAByFgTr1
```
To add OptionGroups to an imported OptionGroupSet, follow the steps as importing collection membership

### Collection membership { #collection-membership } 

In addition to importing objects, you can also choose to only import the
group-member relationship between an object and a group. Currently, the
following group and object pairs are supported

  - Organisation Unit Group - Organisation Unit

  - Data Element Group - Data Element

  - Indicator Group - Indicator

  - Option Group Set - Option Group

The CSV format for these imports are the same



Table: Collection membership CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | UID | Oui | UID | The UID of the collection to add an object to |
| 2 | UID | Oui | UID | The UID of the object to add to the collection |

### Other objects { #webapi_csv_other_objects } 



Table: Data Element Group, Category Option, Category Option Group, Organisation Unit Group CSV Format

| Index | Colonne | Obligatoire | Valeur (par défaut en premier) | Description |
|---|---|---|---|---|
| 1 | Nom | Oui || Name. Max 230 characters. Unique. |
| 2 | UID | Non | UID | Stable identifier. Max 11 chars. Will be generated by system if not specified. |
| 3 | Code | Non || Stable code. Max 50 char. |
| 4 | Nom abrégé | Non || Short name. Max 50 characters. |

An example of category options looks like this:

```csv
name,uid,code,shortname
"Male",,"MALE"
"Female",,"FEMALE"
```

## Deleted objects { #webapi_deleted_objects } 

The deleted objects resource provides a log of metadata objects being
deleted.

    /api/deletedObjects

Whenever an object of type metadata is deleted, a log is being kept of
the uid, code, the type and the time of when it was deleted. This API is
available at `/api/deletedObjects` field filtering and object filtering
works similarly to other metadata resources.

Get deleted objects of type data elements:

    GET /api/deletedObjects.json?klass=DataElement

Get deleted object of type indicator which was deleted in 2015 and
forward:

    GET /api/deletedObjects.json?klass=Indicator&deletedAt=2015-01-01

## Favorites { #webapi_favorites } 

Certain types of metadata objects can be marked as favorites for the
currently logged in user. This applies currently for dashboards.

    /api/dashboards/<uid>/favorite

To make a dashboard a favorite you can make a *POST* request (no content
type required) to a URL like this:

    /api/dashboards/iMnYyBfSxmM/favorite

To remove a dashboard as a favorite you can make a *DELETE* request
using the same URL as above.

The favorite status will appear as a boolean *favorite* field on the
object (e.g. the dashboard) in the metadata response.

## Subscriptions { #webapi_subscription } 

A logged user can subscribe to certain types of objects. Currently
subscribable objects are those of type Chart, EventChart, EventReport,
Map, ReportTable and Visualization.

> **Note**
>
> The Chart and ReportTable objects are deprecated. Use Visualization instead.

To get the subscribers of an object (return an array of user IDs) you
can make a *GET* request:

    /api/<object-type>/<object-id>/subscribers

See example as follows:

    /api/charts/DkPKc1EUmC2/subscribers

To check whether the current user is subscribed to an object (returns a
boolean) you can perform a *GET* call:

    /api/<object-type>/<object-id>/subscribed

See example as follows:

    /api/charts/DkPKc1EUmC2/subscribed

To subscribe/de-subscribe to an object you perform a *POST/DELETE*
request (no content type required):

    /api/<object-type>/<object-id>/subscriber

## File resources { #webapi_file_resources } 

*File resources* are objects used to represent and store binary content.
The *FileResource* object itself contains the file meta-data (name,
Content-Type, size, etc.) as well as a key allowing retrieval of the
contents from a database-external file store. The *FileResource* object
is stored in the database like any other but the content (file) is
stored elsewhere and is retrievable using the contained reference
*(storageKey)*.

    /api/fileResources

The contents of file resources are not directly accessible but are
referenced from other objects (such as data values) to store binary
content of virtually unlimited size.

To create a file resource that does not require a corresponding data value,
POST to the endpoint `/api/fileResources` with a multipart upload:

```bash
curl "https://server/api/fileResources" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

To create both a file resource and a data value that references the file,
POST to the `/api/dataValues/file` endpoint in DHIS 2.36 or later:

```bash
curl "https://server/api/dataValues/file?de=xPTAT98T2Jd
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s" -X POST
  -F "file=@/path/to/file/name-of-file.png"
```

For the `api/fileResources` endpoint, the only form parameter required is
*file*, which is the file to upload. For the `api/dataValues/file`
endpoint, the parameters required are the same as for a post to
`api/dataValues`, with the addition of *file*.

The filename and content-type should also be included in the request but
will be replaced with defaults when not supplied.

On successfully creating a file resource the returned data will contain
a `response` field which in turn contains the `fileResource` like this:

```json
{
  "httpStatus": "Accepted",
  "httpStatusCode": 202,
  "status": "OK",
  "response": {
    "responseType": "FileResource",
    "fileResource": {
      "name": "name-of-file.png",
      "created": "2015-10-16T16:34:20.654+0000",
      "lastUpdated": "2015-10-16T16:34:20.667+0000",
      "externalAccess": false,
      "publicAccess": "--------",
      "user": { ... },
      "displayName": "name-of-file.png",
      "contentType": "image/png",
      "contentLength": 512571,
      "contentMd5": "4e1fc1c3f999e5aa3228d531e4adde58",
      "storageStatus": "PENDING",
      "id": "xm4JwRwke0i"
    }
  }
}
```

Note that the response is a *202 Accepted*, indicating that the returned
resource has been submitted for background processing (persisting to the
external file store in this case). Also, note the `storageStatus` field
which indicates whether the contents have been stored or not. At this
point, the persistence to the external store is not yet finished (it is
likely being uploaded to a cloud-based store somewhere) as seen by the
`PENDING` status.

Even though the content has not been fully stored yet the file resource
can now be used, for example as referenced content in a data value (see
[Working with file data values](#datavalue_file)). If we need to check
the updated *storageStatus* or otherwise retrieve the metadata of the
file, the `fileResources` endpoint can be queried.

```bash
curl "https://server/api/fileResources/xm4JwRwke0i" -H "Accept: application/json"
```

This request will return the `FileResource` object as seen in the
response of the above example.

### File resource constraints { #webapi_file_resources_constraints } 

  - File resources *must* be referenced (assigned) from another object
    in order to be persisted in the long term. A file resource which is
    created but not referenced by another object such as a data value is
    considered to be in *staging*. Any file resources which are in this
    state and are older than *two hours* will be marked for deletion
    and will eventually be purged from the system.

  - The ID returned by the initial creation of the file resource is not
    retrievable from any other location unless the file resource has
    been referenced (in which the ID will be stored as the reference),
    so losing it will require the POST request to be repeated and a new
    object to be created. The *orphaned* file resource will be cleaned
    up automatically.

  - File resource objects are *immutable*, meaning modification is not
    allowed and requires creating a completely new resource instead.

### File resource blocklist { #file-resource-blocklist } 

Certain types of files are blocked from being uploaded for security reasons.

The following content types are blocked.

| Content type | Content type |
| ------------------------------------- | ---- |
| text/html                             | application/x-ms-dos-executable |
| text/css                              | application/vnd.microsoft.portable-executable |
| text/javascript                       | application/vnd.apple.installer+xml |
| font/otf                              | application/vnd.mozilla.xul+xml |
| application/x-shockwave-flash         | application/x-httpd-php  |
| application/vnd.debian.binary-package | application/x-sh |
| application/x-rpm                     | application/x-csh |
| application/java-archive              |  |

The following file extensions are blocked.

| File extension | File extension | File extension |
| ---- | ---- | ---- |
| html | deb  | xul  |
| htm  | rpm  | php  |
| css  | jar  | bin  |
| js   | jsp  | sh   |
| mjs  | exe  | csh  |
| otf  | msi  | bat  |
| swf  | mpkg |      |

## Metadata versioning { #webapi_metadata_versioning } 

This section explains the metadata versioning APIs.

  - `/api/metadata/version`: This endpoint will return the current metadata
    version of the system on which it is invoked.



Table: Query Parameters

| Nom | Obligatoire | Description |
|---|---|---|
| versionName | faux | If this parameter is not specified, it will return the current version of the system or otherwise it will return the details of the versionName passed as parameter. (versionName is of the syntax "Version_<id\>" |

### Get metadata version examples { #webapi_metadata_versioning_examples } 

**Example:** Get the current metadata version of this system

Request:

```
/api/metadata/version
```

Response:

```json
{
  "name": "Version_4",
  "created": "2016-06-30T06:01:28.684+0000",
  "lastUpdated": "2016-06-30T06:01:28.685+0000",
  "externalAccess": false,
  "displayName": "Version_4",
  "type": "BEST_EFFORT",
  "hashCode": "848bf6edbaf4faeb7d1a1169445357b0",
  "id": "Ayz2AEMB6ry"
}
```

**Example:** Get the details of version with name "Version_2"

Request:

```
/api/metadata/version?versionName=Version_2
```

Response:

```json
{
  "name": "Version_2",
  "created": "2016-06-30T05:59:33.238+0000",
  "lastUpdated": "2016-06-30T05:59:33.239+0000",
  "externalAccess": false,
  "displayName": "Version_2",
  "type": "BEST_EFFORT",
  "hashCode": "8050fb1a604e29d5566675c86d02d10b",
  "id": "SaNyhusVxBG"
}
```

  - `/api/metadata/version/history`: This endpoint will return the list of all
    metadata versions of the system on which it is invoked.



Table: Query Parameters

| Nom | Obligatoire | Description |
|---|---|---|
| baseline | faux | If this parameter is not specified, it will return list of all metadata versions. Otherwise we need to pass a versionName parameter of the form "Version_<id\>". It will then return the list of versions present in the system which were created after the version name supplied as the query parameter. |

### Get the list of all metadata versions { #webapi_get_list_of_metadata_versions } 

**Example:** Get the list of all versions in this system

Request:

```
/api/metadata/version/history
```

Response:

```json
{
  "metadataversions": [{
    "name": "Version_1",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:54:41.139+0000",
    "id": "SjnhUp6r4hG",
    "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798"
  }, {
    "name": "Version_2",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T05:59:33.238+0000",
    "id": "SaNyhusVxBG",
    "hashCode": "8050fb1a604e29d5566675c86d02d10b"
  }, {
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }]
}
```

**Example:** Get the list of all versions in this system created after "Version_2"

Request:

```
/api/metadata/version/history?baseline=Version_2
```

Response:

```json
{
  "metadataversions": [{
    "name": "Version_3",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:23.680+0000",
    "id": "FVkGzSjAAYg",
    "hashCode": "70b779ea448b0da23d8ae0bd59af6333"
  }, {
    "name": "Version_4",
    "type": "BEST_EFFORT",
    "created": "2016-06-30T06:01:28.684+0000",
    "id": "Ayz2AEMB6ry",
    "hashCode": "848bf6edbaf4faeb7d1a1169445357b0"
  }]
 }
```

  - `/api/metadata/version/create`: This endpoint will create the metadata
    version for the version type as specified in the parameter.



Table: Query Parameters

| Nom | Obligatoire | Description |
|---|---|---|
| type | vrai | The type of metadata version which needs to be created.<br>  * BEST_EFFORT<br> * ATOMIC |

Users can select the type of metadata which needs to be created.
Metadata Version type governs how the importer should treat the given
version. This type will be used while importing the metadata. There are
two types of metadata.

  - *BEST_EFFORT*: This type suggests that missing references can be
    ignored and the importer can continue importing the metadata (e.g.
    missing data elements on a data element group import).

  - *ATOMIC*: This type ensures a strict type checking of the metadata
    references and the metadata import will fail if any of the references
    do not exist.

> **Note**
>
> It's recommended to have an ATOMIC type of versions to ensure that all
> systems (central and local) have the same metadata. Any missing
> reference is caught in the validation phase itself. Please see the
> importer details for a full explanation.

### Create metadata version { #webapi_create_metadata_version } 

**Example:** Create metadata version of type `BEST_EFFORT`

Request:

```bash
curl -X POST -u admin:district "https://play.dhis2.org/dev/api/metadata/version/create?type=BEST_EFFORT"
```

Response:

```json
{
  "name": "Version_1",
  "created": "2016-06-30T05:54:41.139+0000",
  "lastUpdated": "2016-06-30T05:54:41.333+0000",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407+0000",
    "lastUpdated": "2016-04-06T00:06:06.571+0000",
    "externalAccess": false,
    "displayName": "John Traore",
    "id": "xE7jOejl9FI"
  },
  "displayName": "Version_1",
  "type": "BEST_EFFORT",
  "hashCode": "fd1398ff7ec9fcfd5b59d523c8680798",
  "id": "SjnhUp6r4hG"
}
```

  - `/api/metadata/version/{versionName}/data`: This endpoint will download
    the actual metadata specific to the version name passed as path
    parameter.

  - `/api/metadata/version/{versionName}/data.gz`: This endpoint will download
    the actual metadata specific to the version name passed as path
    parameter in a compressed format (gzipped).



Table: Path parameters

| Nom | Obligatoire | Description |
|---|---|---|
| versionName | vrai | Path parameter of the form "Version_<id\>" so that the API downloads the specific version |

### Download version metadata { #webapi_download_version_metadata } 

**Example:** Get the actual metadata for "Version 5"

Request:

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/version/Version_5/data"
```

Response:

```json
{
  "date": "2016-06-30T06:10:23.120+0000",
  "dataElements": [
    {
      "code": "ANC 5th Visit",
      "created": "2016-06-30T06:10:09.870+0000",
      "lastUpdated": "2016-06-30T06:10:09.870+0000",
      "name": "ANC 5th Visit",
      "id": "sCuZKDsix7Y",
      "shortName": "ANC 5th Visit ",
      "aggregationType": "SUM",
      "domainType": "AGGREGATE",
      "zeroIsSignificant": false,
      "valueType": "NUMBER",
      "categoryCombo": {
        "id": "p0KPaWEg3cf"
      },
      "user": {
        "id": "xE7jOejl9FI"
      }
    }
  ]
}
```

## Metadata Synchronization { #webapi_metadata_synchronization } 

This section explains the Metadata Synchronization API available
starting 2.24

  - `/api/metadata/sync`: This endpoint performs metadata sync of the
    version name passed in the query parameter by downloading and
    importing the specified version from the remote server as defined in
    the settings app.



Table: Query parameters

| Nom | Obligatoire | Description |
|---|---|---|
| versionName | vrai | versionName query parameter of the form "Version_<id\>" . The api downloads this version from the remote server and imports it in the local system. |

  - This API should be used with utmost care. Please note that there is
    an alternate way to achieve sync in a completely automated manner by
    leveraging the Metadata Sync Task from the "Data Administration"
    app. See Chapter 22, Section 22.17 of User Manual for more details
    regarding Metadata Sync Task.

  - This sync API can alternatively be used to sync metadata for the
    versions which have failed from the metadata sync scheduler. Due to
    its dependence on the given metadata version number, care should be
    taken for the order in which this gets invoked. E.g. If this api is
    used to sync some higher version from the central instance, then the
    sync might fail as the metadata dependencies are not present in the
    local instance.

  - Assume the local instance is at `Version_12` and if this endpoint is used
    to sync `Version_15` (of type `BEST_EFFORT`) from the central
    instance, the scheduler will start syncing metadata from
    `Version_16`. So the local instance will not have the metadata
    versions between `Version_12` and `Version_15`. You need to manually
    sync the missing versions using these endpoints only.

### Sync metadata version { #webapi_metadata_synchronization_version } 

**Example:** Sync Version_6 from central system to this system

Request:

```bash
curl -u admin:district "https://play.dhis2.org/dev/api/metadata/sync?versionName=Version_6"
```

## Metadata repository { #webapi_metadata_repository } 

DHIS2 provides a metadata repository containing metadata packages with
various content. A metadata package is a DHIS2-compliant JSON document
which describes a set of metadata objects.

To retrieve an index over available metadata packages you can issue a
GET request to the *metadataRepo* resource:

    GET /api/synchronization/metadataRepo

A metadata package entry contains information about the package and a
URL to the relevant package. An index could look like this:

```json
{
  "packages": [
    {
      "id": "sierre-leone-demo",
      "name": "Sierra Leone demo",
      "description": "Sierra Leone demo database",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/sierra-leone-demo/metadata.json"
    },
    {
      "id": "trainingland-org-units",
      "name": "Trainingland organisation units",
      "description": "Trainingland organisation units with four levels",
      "version": "0.1",
      "href": "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
    }
  ]
}
```

A client can follow the URLs and install a metadata package through a
POST request with content type *text/plain* with the metadata package
URL as the payload to the *metadataPull* resource:

    POST /api/synchronization/metadataPull

An example curl command looks like this:

```bash
curl "localhost:8080/api/synchronization/metadataPull" -X POST
  -d "https://dhis2.org/metadata-repo/221/trainingland-org-units/metadata.json"
  -H "Content-Type:text/plain" -u admin:district
```

## Reference to createdBy User { #reference-to-createdby-user } 

Each object created in DHIS2 will have a property named `user` which is linked to `User` who created the object.

From version 2.36 we have changed the name of this property to `createdBy` to avoid confusion.

However, in order to keep the backwards compability, the legacy `user` property is still included in the payload and works normally as before.

```json
{
  "createdBy": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  },
  "user": {
      "displayName": "John Kamara",
      "name": "John Kamara",
      "id": "N3PZBUlN8vq",
      "username": "district"
  }
}
```

## Metadata Proposal Workflow { #webapi_metadata_proposal_workflow }

The metadata proposal workflow endpoint allows for a workflow of proposing and accepting changes to metadata.

```
/api/metadata/proposals
```

### Propose a metadata change { #webapi_metadata_proposal_propose }

A proposal always targets a single metadata object using:

    POST /api/metadata/proposals

Depending on the payload the proposal could:

* Add a new metadata object.
* Update an existing metadata object references by ID.
* Remove an existing metadata object referenced by ID.

To propose adding a new metadata object send a JSON payload like the following:

```json
{
  "type": "ADD",
  "target": "ORGANISATION_UNIT",
  "change": {"name":"My Unit", "shortName":"MyOU", "openingDate": "2020-01-01"}
}
```
The `change` property contains the same JSON object that could directly be posted to the corresponding endpoint to create the object.

To propose updating an existing metadata object send a JSON payload like in the below example:

```json
{
  "type": "UPDATE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>",
  "change": [
    { "op": "replace", "path": "/name", "value": "New name" }
  ]
}
```
The `targetId` refers to the object by its ID which should be updated. The `change` property here contains a JSON patch payload. This is the same
patch payload that could be posted to the corresponding endpoint to directly apply the update.

To propose the removal of an existing object send a payload like in the last example:

```json
{
  "type": "REMOVE",
  "target": "ORGANISATION_UNIT",
  "targetId": "<id>"
}
```
The `targetId` refers to the object  by its ID which should be removed. A free text `comment` can be added to any type of comment.

Only `target` type `ORGANISATION_UNIT` is supported currently.

### Accept a metadata change proposal { #webapi_metadata_proposal_accept }
To accept an open proposal use `POST` on the proposal resource

    POST /api/metadata/proposals/<uid>

When successful the status of the proposal changes to status `ACCEPTED`. Once accepted the proposal can no longer be rejected.

Should a proposal fail to apply it changes to status `NEEDS_UPDATE`. The `reason` field contains a summary of the failures when this information is 
available.

### Oppose a metadata change proposal { #webapi_metadata_proposal_oppose }
If a proposal isn't quite right and needs adjustment this can be indicated by opposing the proposal by sending a `PATCH` for the proposal resource

    PATCH /api/metadata/proposals/<uid>

Optionally a plain text body can be added to this to give a `reason` why the proposal got opposed.

A opposed proposal must be in state `PROPOSED` and will change to state `NEEDS_UPDATE`.

### Adjust a metadata change proposal { #webapi_metadata_proposal_adjust }
A proposal in state `NEEDS_UPDATE` needs to be adjusted before it can be accepted. To adjust the proposal a `PUT` request is made for the proposal's 
resource

    PUT /api/metadata/proposals/<uid>

Such an adjustment can either be made without a body or with a JSON body containing an object with the updated `change` and `targetId` for the 
adjustment:

```json
{
  "targetId": "<id>",
  "change": ...
}
```
The JSON type of the `change` value depends on the proposal `type` analogous to when a proposal is initially made.

### Reject a metadata change proposal { #webapi_metadata_proposal_reject }
To reject an open proposal use `DELETE` on the proposal resource

    DELETE /api/metadata/proposals/<uid>

This changes the status of the proposal conclusively to `REJECTED`. No further changes can be made to this proposal. It is kept as a documentation of the events.

### List metadata change proposals { #webapi_metadata_proposal_list }
All proposals can be listed:

    GET /api/metadata/proposals/

The result list can be filtered using the `filter` parameter.
For example, to list only accepted proposals use:

    GET /api/metadata/proposals?filter=status=ACCEPTED

Similarly to only show open proposals use:

    GET /api/metadata/proposals?filter=status=PROPOSED

Filters can also be applied to any field except `change`. Supported filter operators are those described in the Gist Metadata API. This also includes property transformers described for Gist API.

List of available fields are:

| Champ       | Description |
| ----------- | -------------------------------------------------------------- |
| identifiant          | unique identifier of the proposal |
| type        | `ADD` a new object, `UPDATE` an existing object, `REMOVE` an existing object |
| statut      | `PROPOSED` (open proposal), `ACCEPTED` (successful), `NEEDS_UPDATE` (accepting caused error or opposed), `REJECTED` |
| target      | type of metadata object to add/update/remove; currently only `ORGANISATION_UNIT` |
| targetId    | UID of the updated or removed object, not defined for `ADD` |
| createdBy (créé par)   | the user that created the proposal |
| créé     | the date time when the proposal was created |
| finalisedBy | the user that accepted or rejected the proposal |
| finalised   | the date time when the proposal changed to a conclusive state of either accepted or rejected |
| commentaire     | optional plain text comment given for the initial proposal |
| raison      | optional plain text given when the proposal was opposed or the errors occurring when accepting a proposal failed | 
| change      | JSON object for `ADD` proposal, JSON array for `UPDATE` proposal, nothing for `REMOVE` proposal |

### Viewing metadata change proposals { #webapi_metadata_proposal_show }
Individual change proposals can be viewed using 

    GET /api/metadata/proposals/<uid>

The `fields` parameter can be used to narrow the fields included for the shown object. For example:

    GET /api/metadata/proposals/<uid>?fields=id,type,status,change


# Métadonnées Gist API { #gist_api } 
<!--DHIS2-SECTION-ID:gist_api-->

L'API Gist des métadonnées est une API JSON RESTful en lecture uniquement qui permet de récupérer et de parcourir 
des métadonnées. Les éléments de cette API contiennent la gist du même élément dans l'API Métadonnées.

L'API est spécifiquement conçue pour éviter :

* Les charges utiles des réponses volumineuses en raison de l'inclusion d'objets partiels imbriqués
  imbriqués.
* Traitement des demandes en mémoire, à forte intensité de ressources 
  (par exemple, le filtrage en mémoire ou la navigation dans le graphe d'objets).
* _n + 1_ requêtes de base de données à la suite de la navigation dans le graphe d'objets lors de la restitution de 
  la réponse.

## Comparaison avec l'API des métadonnées { #gist_vs_metadata_api } 
<!--DHIS2-SECTION-ID:gist_vs_metadata_api-->

L'API standard des métadonnées est une API flexible et puissante, conçue pour répondre à 
tous les cas d'utilisation. 
L'inconvénient est que toutes les fonctionnalités et combinaisons ne peuvent pas être mises à l'échelle tout en 
conservant de bonnes performances en présence d'un grand nombre d'éléments. 
En particulier, les listes d'éléments où chaque élément possède une propriété qui est une 
grande collection d'objets complexes se sont avérées problématiques car elles font 
rapidement référence à une grande partie du graphe d'objets entier.

L'API `/gist` a été ajoutée pour fournir une API de métadonnées où la mise à l'échelle est 
notre première priorité. L'inconvénient est qu'il y a des limites plus distinctes à ce qui est 
techniquement raisonnable, ce qui signifie que toutes les fonctionnalités de l'API standard 
de métadonnées n'existent pas pour l'API Gist.

L'API Gist utilise une stratégie de division et de conquête pour éviter les réponses avec de grands 
graphes d'objets partiels. Au lieu d'inclure des objets ou des listes imbriqués, elle fournit
un URI de point de terminaison `/gist` où cet objet ou cette liste peut être visualisé de manière isolée.

**L'API `/gist` se réfère aux données imbriquées en utilisant les URI plutôt que de les inclure.** 
Cela signifie que si un client est intéressé par ces informations imbriquées, il faudra plus de 
requêtes, mais chacune d'entre elles reste raisonnablement petite et s'adaptera 
bien dans le contexte d'un grand nombre d'éléments potentiels.

Les différences connues :

* les éléments n'incluent que les champs des objets identifiables référencés si ceux-ci n'ont 
  pas de point de terminaison propre 
* ils n'incluent jamais directement les collections d'objets identifiables 
* les éléments par défaut n'incluent pas tous les champs disponibles, mais un sous-ensemble qui dépend 
  du contexte et des paramètres 
* les listes ne peuvent pas être utilisées sans pagination (il n'y a donc pas de paramètre `pagination`) 
* les champs avec les collections ne sont pas paginés en utilisant le transformateur `pagination` mais à travers 
  un point de terminaison API paginé pour la propriété particulière de la collection 
* les éléments d'une liste, la taille d'une propriété de collection ou le résultat 
  toujours en compte le partage d'objets (l'ensemble des éléments pris en compte est toujours l'ensemble 
  visible par l'utilisateur)
* Gist propose les transformateurs de champs de collection  `membre(<id>)` et  `non-membre(<id>)`
* Gist propose un filtre de vérification d'accès de type `peutLire` et `peuModifier` au lieu de filtrer 
  selon la propriété `accès`
* La Gist propose d'utiliser les UID des attributs comme noms de champs et de propriétés de filtrage pour permettre 
  l'établissement de listes ou le filtrage en fonction de valeurs d'attributs personnalisées

Les limites connues :

* only persisted or synthetic fields (those based on persisted fields) can be included
* les filtres ne peuvent être appliqués qu'aux champs persistants
* les commandes ne peuvent être appliquées qu'aux champs persistants
* like-filters are always case-insensitive
* les filtres de jeton ne sont pas disponibles
* l'ordre est toujours sensible à la casse
* Le transformateur `pluck` limité aux propriétés de texte
* Les champs contenant des collections d'éléments simples (non identifiables) ne peuvent pas toujours 
  être inclus en fonction de la manière dont ils sont stockés

Lorsque cela est possible, l'utilisation de l'API `/gist` doit être considérée comme la meilleure façon 
d'obtenir des informations sur les métadonnées.


## Points de terminaison { #gist_endpoints } 
<!--DHIS2-SECTION-ID:gist_Points de terminaison-->

L'API `/gist` a 3 types de points de terminaison :

* <code>/api/&lt;object-type><b>/gist </b></code>: liste paginée de tous les objets connus et visibles du type (implicite `auto=S`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;<b>/gist</b></code> : affichage d'un seul objet par identifiant (implicite `auto=L`)
* <code>/api/&lt;object-type&gt;/&lt;object-id&gt;/&lt;field-name&gt;<b>/gist</b></code> : liste paginée de tous les éléments connus et visibles dans la collection du champ de l'objet propriétaire (implicite `auto=M` ; dans le cas d'un champ simple, juste la valeur du champ).

Ces points de terminaison correspondent aux points de terminaison de l'API standard de métadonnées sans 
le suffixe `/gist` et partagent la majorité des paramètres et de leurs options avec 
cette API.


## Données de navigation { #gist_browse } 
<!--DHIS2-SECTION-ID:gist_browse-->

Puisque l'API `/gist` évite les structures de données profondément intégrées dans la réponse, les 
détails des objets complexes ou des listes d'objets référencés sont plutôt fournis 
sous la forme d'un URI vers le point de terminaison gist qui renvoie uniquement l'objet complexe ou 
la liste d'objets. Ces URI sont fournies par le champ `pointsdeterminaisonsdel'api` d'un élément qui est 
automatiquement ajouté à un élément lorsque de telles références existent. 
La propriété item elle-même peut contenir un résultat de transformation sur l'objet 
ou la collection tel que sa taille, sa contenance, sa non contenance, son (ses) identifiant(s) 
ou une propriété extraite telle que son nom.

Pour parcourir manuellement les données, il peut être pratique d'utiliser le paramètre `absoluteUrls=true`. 
Les liens entre les parties de la liste peuvent maintenant être suivis directement dans les navigateurs qui 
affichent les réponses JSON.


## Paramètres { #gist_parameters } 
<!--DHIS2-SECTION-ID:gist_paramètres-->

Tous les points de terminaison de l'API `/gist` acceptent le même ensemble de paramètres.
Les paramètres et leurs options qui n'ont pas de sens dans le contexte du point de terminaison sont 
ignorés.


### Aperçu { #overview } 
Les paramètres par ordre alphabétique :

| Paramètre      | Options               |  Par défaut     | Description          |
| -------------- | --------------------- | ------------ | ---------------------|
| `Urls absolus` | `vrai` or `faux`     | `faux`      | `vrai` utilise les chemins relatifs dans les liens, `faux` utilise les URL absolues dans les liens |
| `automatique`         | `XS`, `S`, `M`, `L`, `XL` | (en fonction du contexte) | étendue des champs sélectionnés par `*` le sélecteur de champ  |
| `champs`       | (en fonction du point de terminaison) | `*`          | liste de champs ou de préréglages séparés par des virgules à inclure |
| `filtre`       | `<field>:<operator>` ou `<field>:<operator>:<value>` |   | liste de filtres de champs de requête séparés par des virgules (peut être utilisée plus d'une fois) |
| `sans titre`     | `vrai` or `faux`     | `faux`      | `true` skip wrapping result in a pager (ignores `total`), `false` use a pager wrapper object around the result list |
| `inversé`      | `vrai` or `faux`     | `faux`      | La valeur `vrai` renvoie les éléments **pas** dans la liste, la valeur `faux` renvoie les éléments dans la liste. |
| `locale`       |                       | (langue configurée du compte utilisateur) | remplacement de la langue de traduction |
| `ordre`        | `<field>` or  `<field>:asc` or `<field>:desc` | `:asc` | comma separated list of query order fields (can be used more than once) |
| `page`         | 1-n                   | 1            | numéro de page |
| `taille de la page`     | 1-1000                | 50           | nombre d'éléments sur une page |
| `jonction de racines` | `ET` or `OU`         | `ET`        | combinaison logique de `filtres`, `ET`= tous doivent correspondre, `OU`= au moins un doit correspondre |
| `total`        | `vrai` or `faux`     | `faux`      | `vrai` ajoute le nombre total de correspondances à la pagination, `faux` ne compte pas le nombre total de correspondances |
| `traduire`    | `vrai` or `faux`     | `vrai`       | `vrai` traduit toutes les propriétés traduisibles, `faux` saute la traduction des propriétés traduisibles (pas d'effet sur les noms d'affichage synthétiques) |


### Le paramètre `absoluteUrls` { #gist_parameters_absoluteUrls } 
<!--DHIS2-SECTION-ID:gist_les paramètres_absoluteUrls-->

Par défaut, les URIs dans les `points de terminaison api`, `href` et les membres `précedent` et `suivant` de la`pagination` 
sont relatifs, et commencent par le chemin `/<object-type>/`.

Les URI peuvent être changés en URL absolues en utilisant le paramètre `absoluteUrls`.

Par exemple, `/api/users/rWLrZL8rP3K/gist?fields=id,href` renvoie :

```json
{
  "id": "rWLrZL8rP3K",
  "href": "/users/rWLrZL8rP3K/gist"
}
```

tandis que `/api/users/rWLrZL8rP3K/gist?fields=id,href&absoluteUrls=true` 
renvoie :

```json
{
  "id": "rWLrZL8rP3K",
  "href": "http://localhost:8080/api/users/rWLrZL8rP3K/gist?absoluteUrls=true"
}
```

Comme le montre l'exemple, le paramètre `absoluteUrls` est également transmis ou reporté 
dans les URLs incluses, ce qui permet de parcourir les réponses en suivant les 
URLs fournies.


### Le Paramètre `auto` { #the-auto-parameter } 
Chaque point d'accès définit implicitement une valeur par défaut pour l'étendue des champs correspondant 
au sélecteur de champs`*` / `:tout` :

* `/api/<object-type>/gist` : implique que `auto=S`
* `/api/<object-type>/<object-id>/gist`: implique que `auto=L`
* `/api/<object-type>/<object-id>/<field-name>/gist`: implique que `auto=M`

Le paramètre `auto` est utilisé pour surcharger manuellement la valeur par défaut afin que les éléments 
de la liste incluent plus ou moins de champs. Ce paramètre agit à nouveau comme une valeur par défaut qui peut 
être modifiée pour chaque champ à l'aide d'une transformation explicite.

Les options possibles pour `auto` sont (" les tailles de t-shirt ") :

* `XS` : inclut uniquement les identifiants et les propriétés textuelles
* `S` : exclut les propriétés complexes (objets), les collections sont uniquement liées (non comptabilisées)
* `M` : complexe inclus en tant qu'URL de référence, les références et les collections en tant qu'URL de comptage et de référence
* `L` : comme `M` mais les références et les collections sont incluses en tant qu'identifiants (OBS ! non consolidé en taille)
* `XL` : comme `L` mais les références et les collections sont incluses en tant qu'objets de l'identifiant : `{ "id" : <id>}`

Par exemple, `/api/users/gist` listerait les éléments avec les champs `identifiant`, `nom`, 
`prénom`, `numéro de téléphone`, `email`, `dernière mise à jour` alors que 
`/api/users/gist?auto=XS` ne liste que l' `identifiant`, le `nom`,
le `prénom`, le `numéro de téléphone`, l'`email`. L'utilisation de `/api/users/gist?auto=L` inclurait également `unités d'organisation`, `unités d'organisation de visualisation des données`, 
`Unités d'organisation de recherche d'instances d'entités suivis` et `groupes d'utilisateurs`, chacun avec la liste des identifiants des
membres des listes/ensembles.


### Le paramètre `champs` { #gist_parameters_fields } 
<!--DHIS2-SECTION-ID:gist_les paramètres_champs-->

Spécifie la liste des champs à inclure pour chaque élément de la liste.

Les champs sont inclus dans les résultats des objets JSON pour un élément dans l'ordre indiqué. 
Un preset dans la liste des champs est étendu aux champs qu'il contient en fonction de la 
position qu'il occupe dans la liste `fields`. 
Les champs de la présélection sont classés de simple à complexe.

Si aucun paramètre `fields` n'est fourni, `fields=*` est pris en compte.
Notez que les champs du `*`preset dépendent également du paramètre `auto`.

Pour supprimer un champ, utilisez `!<name>` ou `-<name>` dans la liste des champs.
Par exemple, pour supprimer les groupes d'utilisateurs d'un utilisateur, utilisez :

    /api/users/gist?fields=*,!groupes d'utilisateurs

Le même principe peut être utilisé pour spécifier le transformateur à utiliser pour un 
champ. Par exemple, pour inclure les identifiants des groupes d'utilisateurs de l'utilisateur, utilisez :

    /api/users/gist?fields=*,groupes d'utilisateurs::identifiants

Le paramètre `champs` permet de lister les champs des objets imbriqués. 
Par exemple, pour ajouter `références de l'utilisateur` avec `identifiant` et `nom` d'un utilisateur, utilisez :

    /api/users/gist?fields=*,références de l'utilisateur[identifiant,Nom d'utilisateur]

Cela crée des éléments du genre :

```json
{
  ...
  "références de l'utilisateur": {
    "identifiant": "Z9oOHPi3FHB",
    "Nom d'utilisateur": "invité"
  }
}
```

Lors de l'inclusion de champs imbriqués de collections, le champ imbriqué doit être une 
propriété textuelle.

Par exemple pour inclure tous les `nom`s des `groupes d'utilisateurs` d'un utilisateur par :

    /api/users/gist?fields=*,groupes d'utilisateurs[nom]

La liste des `groupes d'utilisateurs` est la suivante:

```json
{
  "groupes d'utilisateurs ": {
    "nom": [
      "_PROGRAMME_Programme pour les patients hospitalisés",
      "_PROGRAMME_Programme TB",
      "_ENSEMBLE DE DONNÉES_Superutilisateur",
      "_PROGRAMME_Superutilisateur",
      "_ENSEMBLE DE DONNÉES_Agent de saisie des données",
      "_ENSEMBLE DE DONNÉES_Agent M et E"
    ]
  }
}
```
Ce qui précède est fonctionnellement identique à :

    /api/users/gist?fields=*,groupe d'utilisateurs::pluck( nom)~renommer(groupe d'utilisateurs.nom)

Lorsque l'on demande un seul champ, comme `/api/users/gist?fields=nom`, la réponse est une liste (toujours paginée) de valeurs simples :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50
  },
  "utilisateurs": [
    "Kamara",
    "Wakiki",
    "Nana",
    "Malai",
    ...
  ]
}
```

Lorsque l'on demande un champ unique de l'objet d'un propriétaire spécifique qui a une valeur simple 
(sans collection), comme par exemple 
`/api/users/rWLrZL8rP3K/gist fields=surname`, la réponse comprend uniquement la valeur 
JSON simple:

```json
"Wakiki"
```

Pour plus de détails sur les préréglages de champs, voir la section [Champs](#gist_fields).

### Le paramètre `filtre` { #gist_parameters_filter } 
<!--DHIS2-SECTION-ID:gist_paramètres_filtre-->

Pour filtrer la liste des éléments renvoyés, ajoutez un ou plusieurs paramètres `filtre`.

Plusieurs filtres peuvent être spécifiés sous la forme d'une liste séparée par des virgules d'un seul paramètre 
ou comme de multiples paramètres `filtre`, chacun avec un seul `filtre`.

Il existe deux types de filtres :

* unitaire: `<field>:<operator>`
* binaire: `<field>:<operator>:<value>`

Un champ peut être : 

* un champ persistant du type d'élément énuméré
* un champ maintenu d'un objet directement référencé (relation 1:1)
* l'UID d'un attribut

Les opérateurs unitaires disponibles sont les suivants :

| Opérateur unitaire | Description                                                 |
| -------- | ----------------------------------------------------------------- |
| `nul`   | le champ est _nul_ (non défini)                                       |
| `!nul`  | le champ est _non nul_ (défini)                                     |
| `vide`  | Le champ est une collection ou une chaîne _vide_                           |
| `!vide` | le champ est une collection ou une chaîne de caractères _non vide_                       |

Les opérateurs binaires disponibles sont les suivants :

| Opérateur binaire   | Description                                              |
| ----------------- | -------------------------------------------------------- |
| `eq`              | champ _égal_ valeur                                     |
| `!eq`, `neq`, `ne`| champ _non égal_ valeur                               |
| `lt`              | champ _inférieur à_ valeur                               |
| `le`, `lte`       | champ _inférieur ou égal à_ valeur                   |
| `gt`              | champ _supérieur à_ valeur                            |
| `ge`, `gte`       | champ _supérieur ou égal à_ valeur                |
| `in`              | le champ est une collection et la valeur est un élément _contenu dans_ la collection |
| `!in`             | le champ est une collection et la valeur est un élément _non contenu dans_ la collection |

Si la `<value>` d'un filtre `in` ou `!in` est une liste, il est donné sous la forme suivante
`[valeur1,valeur2,...]`, par exemple: `groupes d'utilisateurs:dans:[fbfJHSPpUQD,cYeuwXTCPkU]`.

Toute comparaison `>`, `>=`, `<` `<=`, `==` ou `!=` appliquée à un champ de collection 
avec une valeur numérique comparera la taille de la collection à la valeur, par 
exemple : `groupes d'utilisateurs:gt:0`.

Les opérateurs de recherche de motifs binaires disponibles sont les suivants :

| Opérateur binaire                   | Description                              |
| --------------------------------- | ---------------------------------------- |
| `like`, `ilike`                   | champ _contient_ `<value>` ou champ _correspond_ au motif `<value>` (lorsque les caractères génériques `*` ou `?` sont présents dans la valeur) |
| `!like`, `!ilike`                 | le champ ne _contient pas_ `<value>` ou le champ ne _correspond pas_ au motif `<value>` (lorsque les caractères génériques `*` ou `?` sont présents dans la valeur) |
| `$like`, `$ilike`, `démarreAvec`   | le champ _commence avec_ `<value>`            |
| `!$like`, `!$ilike`, `!démarreAvec`| le champ ne_commence pas avec_ `<value>`    |
| `like$`, `ilike$`, `se termine avec`     | le champ _se termine par_ `<value>`              |
| `!like$`, `!ilike$`, `!se termine avec`  | le champ ne_se termine pas par_ `<value>`      |

Les opérateurs `like` et `!like` peuvent être utilisés soit en fournissant un terme de recherche, 
et dans ce cas la correspondance est toute valeur où le terme apparaît à tout endroit, soit 
en fournissant le motif de recherche en utilisant `*` comme _nombre quelconque de caractères_ 
et `?` comme _caractère unique_.

Notez que les filtres sur les valeurs d'attributs utilisent une comparaison basée sur le texte, ce qui signifie que 
tous les filtres textuels sont pris en charge.

Operators have multiple aliases to be backwards compatible with the 
standard metadata API. For the gist API any like is always case-insensitive. 

Par exemple, pour ne répertorier que les organisations de deuxième niveau, utilisez

    /api/organisationUnits/gist?filter=level:eq:2

De même, lorsqu'il s'agit de lister les `enfants` d'une unité d'organisation particulière, la 
collection peut être filtrée. Pour ne lister que les enfants qui sont connectés à
à un programme, on peut utiliser:

    /api/organisationUnits/rZxk3S0qN63/children/gist?filter=programs:gt:0

Opérateurs binaires pour le filtrage basé sur l'accès (le partage) :

| Opérateur binaire   | Description                                              |
| ----------------- | -------------------------------------------------------- |
| `peutLire`         | L'utilisateur `<value>` de métadonnées a t'il le droit de consulter l'objet |
| `peutModifier`        | L'utilisateur `<value>` de métadonnées a t-il le droit de modifier l'objet ? |
| `peut Lire les données`     | L'utilisateur `<value>` des données a t'il le droit de consulter l'objet    |
| `peutModifier les données`    | L'utilisateur `<value>` des données a t-il le droit de modifier l'objet ?   |
| `peutAccéder`       | L'utilisateur a t'il la `<value0>` permission `<value1>` d'accéder à l'objet   |

Lorsque l'identifiant de l'utilisateur `<value>` est omis, la vérification est effectuée pour 
l'utilisateur actuellement connecté. De même, si `<value0>` est omis pour le filtre `peutAccéder`, 
la vérification est effectuée pour l'utilisateur actuellement connecté.

Lorsqu'il est appliqué à une propriété de valeur simple, ici `code`, le filtre limite la réponse à 
ces  éléments de données (propriétaire de l'objet) que l'utilisateur peut lire/modifier :

    /api/dataElements/gist?filter=code:canWrite:OYLGMiazHtW

Lorsqu'il est appliqué à une propriété de référence, ici `combinaison de catégories`, le filtre limite la réponse 
à ces éléments de données ayant une combinaison de catégories que l'utilisateur peut lire/modifier:

    /api/dataElements/gist?filter=categoryCombo:canWrite:OYLGMiazHtW

Lorsqu'il est appliqué à une propriété de collection de référence, ici `groupe d'éléments de données`, le 
filtre limite la réponse à ces éléments de données pour lesquels un groupe d'éléments de données existe dans la 
propriété de collection et que l'utilisateur peut lire/modifier :

    /api/dataElements/gist?filter=dataElementGroups:canWrite:OYLGMiazHtW

La fonction `peutAccéder` demande deux arguments, le premier est l'identifiant de l'utilisateur, le second le modèle d'accès,
par exemple, pour vérifier l'accès en lecture et en modification des métadonnées, le motif est `rw%` :

    /api/dataElements/gist?filter=code:canAccess:[OYLGMiazHtW,rw%]

### Le paramètre `sans titre` { #gist_parameters_headless } 
<!--DHIS2-SECTION-ID:gist_paramètres_sans titre-->

Les points d'extrémité qui renvoient une liste enveloppent par défaut les éléments dans une enveloppe contenant 
le `pager` et la liste, qui est nommée en fonction du type d'objet listé.

Par exemple, l'option `/api/organisationUnits/gist` renvoie :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50,
    "page suivante": "/organisationUnits/gist?page=2"
  },
  "unités d'organisation": [
    ...
  ]
}
```

Avec `headless=true`, la réponse à `/api/organisationUnits/gist?headless=true` 
est juste la partie de la liste `[...]` de l'exemple ci-dessus.


### Le Paramètre `inverse`  { #the-inverse-parameter } 
Le `inverse` peut être utilisé dans le contexte d'un champ de collection gist de la forme 
`/api/<object-type>/<object-id>/<field-name>/gist` pour ne pas lister tous les éléments qui
sont contenus dans la collection membre mais tous les éléments qui ne sont **pas** contenus 
dans la collection membre.

Par exemple, alors que 

    /api/organisationUnits/rZxk3S0qN63/children/gist

listerait toutes les unités d'organisation qui sont des enfants de `rZxk3S0qN63` l'inverse

    /api/organisationUnits/rZxk3S0qN63/children/gist?inverse=true

listerait toutes les unités d'organisation qui ne sont pas des enfants de `rZxk3S0qN63`. 
Cela pourrait par exemple être utilisé pour composer une liste de toutes les unités qui peuvent devenir des enfants 
d'une unité particulière.

Les filtres et les commandes s'appliquent normalement, c'est-à-dire qu'ils filtrent ou commandent les éléments
non contenus dans la collection de membres.


### Le paramètre `local`  { #gist_parameters_locale } 
<!--DHIS2-SECTION-ID:gist_paramètres_local-->
Le paramètre `locale` est généralement utilisé à des fins de test pour changer 
de manière ad-hoc la langue de traduction des noms d'affichage. 

Si elle n'est pas spécifiée, la langue de traduction est celle configurée dans les paramètres 
du compte de l'utilisateur.

Exemples:

    /api/organisationUnits/gist?locale=en
    /api/organisationUnits/gist?locale=en_GB

### Le paramètre `ordre`  { #gist_parameters_order } 
<!--DHIS2-SECTION-ID:gist_paramètres_ordre-->

Pour trier la liste des éléments, une ou plusieurs expressions d'ordre peuvent être données.

Une expression d'ordre est soit un simple nom de champ persistant, soit un nom de champ 
suivi de `:asc` (ordre croissant - par défaut) ou de `:desc` 
(ordre décroissant).

Par exemple, pour trier les unités d'organisation par ordre alphabétique de nom, utilisez :

    /api/organisationUnits/gist?order=name

L'ordre alphabétique inverse serait utilisé :

    /api/organisationUnits/gist?order=name:desc

Pour trier les unités d'organisation en premier lieu par niveau, puis par nom, utilisez :

    /api/organisationUnits/gist?order=level,name

On commencera par la (les) racine(s) au niveau 1. Pour commencer avec les unités foliaires, utilisez :

    /api/organisationUnits/gist?order=level:desc,name

Si aucun ordre n'est spécifié, la liste des résultats aura un ordre stable basé sur 
l'organisation interne des données.


### Le paramètre `page`  { #gist_parameters_page } 
<!--DHIS2-SECTION-ID:gist_paramètres_page-->

Fait référence à la page consultée dans la liste des pages, en commençant par `1` pour la première page.

Si le paramètre `page` n'est pas présent, il est égal à `page=1`.

La `page` est toujours en relation avec la `taille de la page`.
Si une `page` est indiquée au-delà du nombre de correspondances existantes, une liste d'éléments vide 
est renvoyée.


### Le paramètre `taille de la page` { #gist_parameters_pageSize } 
<!--DHIS2-SECTION-ID:gist_paramètres_taille de la page-->

Indique le nombre d'éléments d'une `page`. Le maximum est de 1000 éléments.

Si le paramètre `taille de la page` n'est pas présent, il est égal à `taille de la page=50`.


### Le paramètre `jonction de racines`  { #gist_parameters_rootJunction } 
<!--DHIS2-SECTION-ID:gist_paramètres_jonction de racines-->

Le paramètre `jonction de racines` peut être utilisé pour définir explicitement la jonction logique 
utilisée entre les filtres. Les possibilités sont les suivantes :

* `ET` : tous les filtres doivent correspondre à une donnée pour qu'elle soit incluse dans les résultats
* `OU` : l'un des filtres correspond à une donnée pour qu'elle soit incluse dans les résultats

La valeur par défaut est `ET`


### Le paramètre  `total` { #gist_parameters_total } 
<!--DHIS2-SECTION-ID:gist_paramètres_total-->

Par défaut, une requête gist ne comptera **pas** le nombre total de correspondances si celles-
ci dépassent la limite `taille de la page`. Au lieu de cela, nous acceptons les coûts supplémentaires 
que le comptage total implique.

Si l'on ne compte pas le nombre total de correspondances (`Total=faux`), la réponse `pager`
suppose qu'il y a une page `suivante` dans le cas où des éléments `taille de la page` ont été trouvés. Ceci
pourrait cependant s'avérer faux lorsque l'on navigue sur la page. De plus, le champ `total`
indiquant le nombre de correspondances totales n'est pas inclus dans le `pager`.

Par exemple, `/api/organisationUnits/gist` renvoie un `pager` :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50,
    "page suivante": "/organisationUnits/gist?page=2"
  }
}
```

Lorsque l'on compte le nombre total de correspondances (`Total=vrai`), la réponse `pager` 
contiendra le champ `total` avec le nombre réel de correspondances totales au prix 
d'une opération supplémentaire sur la base de données.

La réponse à `/api/organisationUnits/gist?total=true` renvoie maintenant ce `pager` :

```json
{
  "pager": {
    "page": 1,
    "taille de la page": 50,
    "total": 1332,
    "page suivante": "/organisationUnits/gist?total=true&page=2",
    "nombre de pages": 27
  }
}
```


### Le paramètre `traduire`  { #gist_parameters_translate } 
<!--DHIS2-SECTION-ID:gist_paramètres_traduire-->

Les champs tels que `nom` ou `Nomcourt` peuvent être traduits (internationalisés).

Par défaut, tout champ traduisible ayant une traduction est renvoyé traduit
à condition que la langue de l'interface soit configurée par l'utilisateur qui demande la gist.

Pour retourner le champ non traduit, utilisez `traduit=faux`.

Par exemple, `/api/organisationUnits/gist` renvoie des éléments comme suit :

```json
{
  "nom": "Un nom traduit",
  ...
}
```

Alors que `/api/organisationUnits/gist?translate=false` renverrait des éléments comme :

```json
{
  "nom"
  "Nom du champ brut",
  ...
}
```

Notez que les champs synthétiques `Afficher le nom` et `Afficher le nom court` renvoient toujours
la valeur traduite, indépendamment du paramètre `traduire`.


## Champs  { #gist_fields } 
<!--DHIS2-SECTION-ID:gist_champs -->

Les champs inclus par défaut (sans le paramètre `champs`) correspondent à 
`champs=*`. 
Cela signifie que la liste des champs affichés dépend du type d'objet, du contexte du point d'extrémité 
ainsi que du paramètre `auto`. 

Notez que l'API `/gist` exclut toujours certains champs qui ne sont généralement pas 
importants pour les clients, comme par exemple les champs `traductions` ou `partage`. 
Ceux-ci peuvent être ajoutés explicitement.

Lorsqu'elle n'est pas explicitement fournie par un nom dans les paramètres `champs`, la liste 
des champs est calculée à partir d'un préréglage.
Un préréglage peut être utilisé dans la liste des champs comme un nom de champ. 
Il se développe en zéro, un ou plusieurs champs en fonction du type d'objet, du point 
d'extrémité utilisé et du sélecteur.


### Préréglages des champs { #field-presets } 

* `*` / `:tous`: les champs par défaut dépendent du contexte et du paramètre `auto`
* `:identifiable` : tous les champs maintenus de l'interface `Objet identifiable` 
* `:propriétaire` : tous les champs maintenus pour lesquels le type listé est le propriétaire
* `:nommable` : tous les champs maintenus de l'interface `ObjetNommable`
* `:maintenus` : littéralement tous les champs maintenus 


### Transformateurs de champ { #field-transformers } 
Un transformateur ou une transformation peut être appliqué à un champ en ajoutant 
l'un des indicateurs `::`, `~` ou `@` suivi de l'expression du transformateur.

Les expressions de transformateur disponibles sont les suivantes :

| Transformateur        | Type de résultat JSON    | Description                       |
| ------------------ | ------------------- | --------------------------------- |
| `renommer(<name>)`   | -                   | renomme le champ dans la réponse en `<name>` |
| `taille`             | `nombre`            | nombre d'éléments dans le champ de la collection |
| `estVide`          | `booléen`           | vide d'un champ de collecte   |
| `n'estPasvide`       | `booléen`           | non-emptiness of a collection field |
| `identifiants`              | `chaîne` or `[chaîne]` | Identifiant d'un objet ou identifiant d'éléments d'une collecte |
| `Identifiant - Objets`       | `[{ "identifiant": <id> }]`  | Identifiants des éléments de la collecte en tant qu'objet |
| `membre(<id>)`     | `booléen`           | a un membre avec `<id>` pour le champ de collecte |
| `pas-membre(<id>)` | `booléen`           | n'a pas de membre avec `<id>` pour le champ de collecte |
| `pluck(<field>)`   | `chaîne` or `[chaîne]` | extrait une seule propriété de texte de l'objet ou de chaque élément de la collecte |

Un champ peut recevoir à la fois le transformateur `renommer` et l'un des autres 
transformateurs, par exemple :

    /api/organisationUnits/gist?fields=*,children::size~rename(child-count)

Les éléments renvoyés n'ont plus de membre `enfants` mais un membre `nombre-d'enfants`
à la place. Notez que `renommer` affecte aussi le nom du membre de la référence de l'URI
donnée dans `l'apidespointsd'Extrémités`


## Champs synthétiques { #gist_syntheticFields } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques-->

L'API `/gist` est étroitement liée aux propriétés qui existent dans la base de données.
Cela signifie que les propriétés qui ne sont pas stockées dans la base de données ne sont généralement pas 
disponibles.
L'exception à cette règle sont les propriétés "synthétiques" qui sont dynamiquement 
calculées sur la base d'une ou plusieurs propriétés stockées dans la base de données.

Les propriétés synthétiques sont disponibles pour tous les points d'extrémité où existent 
les propriétés maintenues nécessaires au calcul de la propriété synthétique.

A l'exception de la propriété `points d'extrémité de l'api` qui est automatiquement ajoutée si nécessaire 
toutes les autres propriétés synthétiques ne sont pas incluses par défaut et doivent faire 
l'objet d'une demande explicite dans la liste des `champs`. 


### Aperçu { #overview } 
Champs synthétiques par ordre alphabétique :

| Champ              | Description                                             |
| ------------------ | ------------------------------------------------------- |
| `points d'extrémité de l'api`     | contient des liens permettant de parcourir des objets ou des collections complexes imbriqués |
| `href`             | lien vers l'élément de la liste elle-même ( affichage d'un seul élément)         |
| `Nom d'affichage`      | `nom` traduit (toujours traduit)                   |
| `afficherNomCourt` | translated `displayName` (always translated)            |
| `accès`           | résumé sur la capacité de l'utilisateur actuel à lire/saisir/modifier les données |


### Le Champ `href` { #gist_syntheticFields_href } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques_href-->

Chaque élément d'une réponse `/gist` peut avoir un lien vers lui-même. Ce lien est donné 
dans la propriété `href`.

Pour ajouter le champ `href`, utilisez (par exemple) :

    /api/<object-type>/gist?fields=*,href

### Le champ `afficherNom` et `afficherNomCourt` { #gist_syntheticFields_displayName } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques_afficherNom-->

Par définition, le `afficherNom` est le `nom` traduit et le `afficherNomCourt` est le `nom court` traduit. 

Pour ajouter `afficherNom` ou `afficherNomCourt` à la liste, utilisez (par exemple) :

    /api/<object-type>/gist?fields=*,afficherNom
    /api/<object-type>/gist?fields=*,afficherNomCourt

Notez que par défaut, toutes les propriétés traduisibles comme `nom` et `nomCourt` 
seront également traduites. Lorsque `traduire=faux` est utilisé pour désactiver cela, 
`afficherNom` et `afficherNomCourt` restent traduits. 


### Le Champ `points d'extrémité de l'api`  { #gist_syntheticFields_apiEndpoints } 
<!--DHIS2-SECTION-ID:gist_Champs synthétiques_points d'extrémité de l'api-->

Cette propriété permet de parcourir des objets complexes ou des listes 
d'éléments qui sont inclus dans la réponse `/gist` sous la forme d'une valeur simple 
transformée comme un nombre d'éléments.

L'objet `points d'extrémité de l'api` aura un membre du même nom pour chaque membre 
de l'élément qui a été transformé en valeur simple.

Par exemple, 

    /api/users/gist?fields=id,userGroups::size,organisationUnits::size 

renvoie les éléments du formulaire :

```json
{
  "identifiant": "rWLrZL8rP3K",
  "groupes d'utilisateurs": 0,
  "unités d'organisation": 1,
  "points d'extrémité de l'api": {
    "unités d'organisation": "/utilisateurs/rWLrZL8rP3K/unités d'organisation/gist",
    "groupes d'utilisateurs": "/utilisateurs/rWLrZL8rP3K/groupes d'utilisateurs/gist"
  }
}
```

La liste des `groupes d'utilisateurs` et des `unités d'organisation` est incluse dans leur `taille`. 
Chacun a un membre correspondant dans `points d'extrémité de l'api` avec un chemin pour parcourir la
liste.

Les chemins peuvent être transformés en URL en utilisant le paramètre `Urls absolus`. 

    /api/users/gist?fields=id,userGroups::size,organisationUnits::size&absoluteUrls=true

renvoie les éléments du formulaire :

```json
{
  "identifiant": "rWLrZL8rP3K",
  "groupes d'utilisateurs": 0,
  "unités d'organisation": 1,
  "points d'extrémité de l'api": {
    "unités d'organisation":"http://{host}/api/users/rWLrZL8rP3K/organisationUnits/gist?absoluteUrls=true",
    "groupes d'utilisateurs": http://{host}/api/users/rWLrZL8rP3K/userGroups/gist?absoluteUrls=true"
  }
}
```

### Le Champ `accès` { #the-access-field } 
Le résumé `accès` est basé sur le `partage` et l'utilisateur actuel.
Cela signifie qu'il n'est applicable qu'aux objets ayant une propriété `partage`.

Par exemple, lors de l'établissement d'une liste d'éléments de données avec le champ `accès`

    /api/dataElements/gist?fields=*,access

les éléments de données renvoyés contiennent un membre `"accès"` comme ci-dessous :

```json
"accès": {
  "gérer": faux,
  "externaliser": faux,
  "modifier": faux,
  "lire": vrai,
  "mettre à jour": faux,
  "supprimer": faux
}
```

### Attributs comme Champs { #gist_attributeFields }
DHIS2 permet de créer et d'ajouter des attributs personnalisés aux objets de métadonnées. 
Leurs valeurs sont contenues dans la propriété `valeurs d'attributs` d'un objet de métadonnées 
sous la forme d'une carte dont la clé est l'UID de l'attribut.

Pour lister directement une ou plusieurs valeurs d'attributs spécifiques de cette carte comme s'il 
s'agissait de champs habituels de l'objet de métadonnées, l'UID de l'attribut peut être utilisé comme s'il 
s'agissait du nom d'un champ habituel.

Par exemple, pour inclure la valeur de l'attribut avec l'UID `Y1LUDU8sWBR` en tant que 
la propriété `unité de mesure` dans la liste, utilisez :

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(unit-of-measure)

Il en résulte des éléments de liste du type
```json
{
  "identifiant": "qrur9Dvnyt5",
  "nom": "Âge en années",
  "unité de mesure" : "années"
}
```

Par défaut, les valeurs sont récupérées au format JSON et extraites de la carte des 
valeurs d'attributs. Cela signifie que la liste contiendra le type JSON approprié pour
le type de valeur d'attribut. Cela implique un surcoût lié à la récupération de toutes 
les valeurs d'attributs. Pour isoler la valeur dans la base de données, la transformation `PLUCK` 
peut être utilisée.

    /api/dataElements/gist?fields=id,name,Y1LUDU8sWBR::rename(unit-of-measure)~pluck

Le résultat sera le même, mais la valeur est désormais extraite sous forme de texte dans la 
base de données, ce qui transforme toute valeur JSON en une chaîne de caractères dans le résultat de la propriété. 

## Exemples { #gist_examples } 
<!--DHIS2-SECTION-ID:gist_exemples-->
Quelques exemples partant de simples listes et allant jusqu'à des cas d'utilisation très spécifiques. 

Il est préférable de toujours fournir une liste explicite de `champs` pour que cette section 
le fasse.

Liste des unités d'organisation avec leur identifiant et leur nom :

    /api/organisationUnits/gist?fields=id,name

Liste des unités d'organisation avec leur identifiant, leur nom et leur nombre total :

    /api/organisationUnits/gist?fields=id,name&total=true

Liste des utilisateurs avec l'identifiant et le nom d'utilisateur :

    /api/users/gist?fields=id,userCredentials.username

Liste des utilisateurs avec l'identifiant, le nom d'utilisateur et la date de la dernière connexion :

    /api/users/gist?fields=id,userCredentials[username,lastLogin]

Ne listez que les unités d'organisation au deuxième niveau avec l'identifiant, le nom et le niveau :

    /api/organisationUnits/gist?fields=id,name,level&filter=level:eq:2

Listez uniquement les unités d'organisation qui ont plus d'un enfant avec l'identifiant, le nom et 
le nombre d'enfants :

    /api/organisationUnits/gist?fields=id,name,children::size&filter=children:gt:1

Listez uniquement les unités d'organisation qui ne sont pas encore enfants d'une autre unité
`zFDYIgyGmXG` :

    /api/organisationUnits/zFDYIgyGmXG/children/gist?fields=id,name&inverse=true

Listez les utilisateurs et indiquez s'ils sont membres d'un groupe d'utilisateurs spécifique. 
`NTC8Gj7p8P` et nommer ce champ `est-membre` dans la réponse :

    /api/users/gist?fields=id,userCredentials.username,userGroups::member(NTC8GjJ7p8P)~rename(is-member)

Listez les liens vers tous les utilisateurs dans des pages de 10 éléments :

    /api/users/gist?fields=href&absoluteUrls&pageSize=10




# Données { #data }

## Valeurs des données { #webapi_data_values }

Cette section traite de l'envoi et de la lecture des données.

    /api/33/dataValueSets

### Envoi de données { #webapi_sending_data_values }

Un cas d'utilisation courant pour l'intégration des systèmes est la nécessité d'envoyer un ensemble de valeurs de données d'un système tiers vers DHIS. Dans cet exemple, nous utiliserons la démonstration DHIS2 sur `http://play.dhis2.org/demo`. Supposons que nous avons collecté des données basées sur les cas à l'aide d'un simple logiciel client installé sur des téléphones portables pour l'ensemble de données *Mortalité <5 ans* dans la communauté du *Ngelehun CHC* (dans la chefferie *Badjia*, district *Bo*) pour le mois de janvier 2014. Nous avons maintenant agrégé nos données dans un rapport statistique et nous voulons envoyer ces données à l'instance DHIS2. L'URL de base de l'API de démonstration est `http://play.dhis2.org/demo/api`. Les liens suivants sont associés à l'URL de base.


La ressource la plus appropriée pour notre objectif d'envoi de valeurs de données est `/api/dataValueSets`. Un ensemble de valeurs de données représente des données qui ont une relation, généralement parce qu'elles ont été saisies dans le même formulaire. Le format ressemble à ceci :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="dataSetID"
  completeDate="date" period="période" orgUnit="orgUnitID" attributOptionCombo="aocID">
  <dataValue dataElement="dataElementID"
    categoryOptionCombo="cocID" value="1" comment="comment1"/>
  <dataValue dataElement="dataElementID"
    categoryOptionCombo="cocID" value="2" comment="comment2"/>
  <dataValue dataElement="dataElementID"
    categoryOptionCombo="cocID" value="3" comment="comment3"/>
</dataValueSet>
```

JSON est pris en charge dans ce format :

```json
{
  "dataSet": "dataSetID",
  "completeDate": "date",
  "période": "période",
  "orgUnit": "orgUnitID",
  "attributeOptionCombo": "aocID",
  "valeurs de données": [
    {
      "dataElement": "dataElementID",
      "categoryOptionCombo": "cocID",
      "valeur": "1",
      "commentaire": "commentaire1"
    },
    {
      "dataElement": "dataElementID",
      "categoryOptionCombo": "cocID",
      "valeur": "2",
      "commentaire": "commentaire2"
    },
    {
      "dataElement": "dataElementID",
      "categoryOptionCombo": "cocID",
      "valeur": "3",
      "commentaire": "commentaire3"
    }
  ]
}
```

CSV est pris en charge dans ce format :

```csv
"élément de données", "période", "orgunit", "catoptcombo", "attroptcombo", "valeur", "strby", "lstupd", "cmt"
"dataElementID", "période", "orgUnitID", "cocID", "aocID", "1", "nom d'utilisateur", "2015-04-01", "comment1"
"dataElementID", "période", "orgUnitID", "cocID", "aocID", "2", "nom d'utilisateur", "2015-04-01", "comment2"
"dataElementID", "période", "orgUnitID", "cocID", "aocID", "3", "nom d'utilisateur", "2015-04-01", "comment3"
```

> **Remarque**
>
> Veuillez vous référer à la section date et période ci-dessus pour les formats d'heure.

À partir de l'exemple, nous l'importance d'identifier la période, l'ensemble de données, l'unité d'organisation (établissement) et les éléments de données qui nécessite des rapports.

Pour obtenir l'identifiant de l'ensemble de données, nous adressons une requête à la ressource `/api/dataSets`. De là, nous trouverons le lien vers l'ensemble de données *Mortalité < 5 ans* qui nous conduit à `/api/dataSets/pBOMPrpg1QX`.
La ressource de l'ensemble de données *Mortalité < 5 ans* fournit des liens vers les éléments de données qu'elle abrite. D'ici nous pouvons suivre ces liens et obtenir les identifiants des données éléments. Par souci de concision, nous allons déclarer des données pour seulement trois éléments de données : *Rougeole* avec l'identifiant `f7n9E0hX8qk`, *Dysenterie* avec l'identifiant `Ix2HsbDMLea` et *Choléra* avec l'identifiant `eY5ehpbEsB7`.

Il ne nous reste que l'identifiant de l'organisation unité. L'*ensemble de données* fournit un lien vers les unités d'organisation qui produisent des rapports dessus. Nous recherchons donc *Ngelehun CHC* et suivons le lien vers la représentation HTML dans `/api/organisationUnits/DiszpKrYNg8`, qui nous indique que l'identifiant de cette unité d'organisation est `DiszpKrYNg8`.

À partir de nos données basées sur les cas, nous supposons que nous avons 12 cas de rougeole, 14 cas de dysenterie et 16 cas de choléra. Nous avons maintenant assez d'informations pour pouvoir composer le message XML de l'ensemble de valeurs des données :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-02-03" period="201401" orgUnit="DiszpKrYNg8">
  <dataValue dataElement="f7n9E0hX8qk" value="12"/>
  <dataValue dataElement="Ix2HsbDMLea" value="14"/>
  <dataValue dataElement="eY5ehpbEsB7" value="16"/>
</dataValueSet>
```

Au format JSON :

```json
{
  "ensembleDeDonnées": "pBOMPrpg1QX",
  "date": "03/02/2014",
  "période": "201401",
  "unitéD'organisation": "DiszpKrYNg8",
  "valeursDeDonnées": [
    {
      "élémentDeDonnées": "f7n9E0hX8qk",
      "valeur": "1"
    },
    {
      "élémentDeDonnées": "Ix2HsbDMLea",
      "valeur": "2"
    },
    {
      "élémentDeDonnées": "eY5ehpbEsB7",
      "valeur": "3"
    }
  ]
}
```

Pour effectuer des tests fonctionnels, nous utiliserons l'outil _curl_ qui permet de transférer facilement des données à l'aide du protocole HTTP. Tout d'abord, nous sauvegardons le contenu XML de l'ensemble de données dans un fichier appelé `datavalueset.xml`. Dans le répertoire où se trouve ce fichier, nous invoquons ce qui suit à partir de la ligne de commande :

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/33/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

Pour envoyer du contenu JSON, vous devez définir l'en-tête "type de contenu" comme suit :

```bash
curl -d @datavalueset.json "https://play.dhis2.org/demo/api/33/dataValueSets"
  -H "Content-Type:application/json" -u admin:district
```

La commande enverra une requête à l'API Web de démonstration, définissez `application/xml` comme type de contenu et authentifiez-vous en utilisant `admin`/`district` comme nom d'utilisateur/mot de passe. Si tout se passe bien, le code d'état HTTP `200 OK` sera renvoyé. Vous pouvez vérifier la réception des données en ouvrant le module de saisie de données dans DHIS2 et en sélectionnant l'unité d'organisation, l'ensemble de données et la période utilisés dans cet exemple.

L'API suit la sémantique normale pour la gestion des erreurs et les codes d'état HTTP. Si vous fournissez un nom d'utilisateur ou un mot de passe invalide, `401 Non autorisé` est renvoyé. Si vous fournissez un type de contenu autre que `application/xml`, `415 Type de média non pris en charge` est renvoyé. Si le contenu XML n'est pas valide selon l'espace de noms DXF, `400 Mauvaise requête` est renvoyé. Si vous fournissez un identifiant invalide dans le contenu XML, `409 Conflit` est renvoyé avec un message descriptif.

### Envoi de données en masse { #webapi_sending_bulks_data_values }

L'exemple précédent nous a montré comment envoyer un ensemble de données associées qui partagent la même période et la même unité d’organisation. L'exemple suivant nous montrera comment envoyer de grandes quantités de données qui ne sont pas nécessairement associés.

Encore une fois, nous interagirons avec la ressource `/api/dataValueSets`. Cette fois nous n'allons pas spécifier les attributs `dataSet` et `completeDate`. De plus, nous allons spécifiez les attributs `period` et `orgUnit` comme éléments de données individuelles et non élément d’ensemble de données externes. Cela nous permettra d'envoyer des données pour différentes périodes et unités d'organisation :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0">
  <dataValue dataElement="f7n9E0hX8qk"
    period="201401" orgUnit="DiszpKrYNg8" value="12"/>
  <dataValue dataElement="f7n9E0hX8qk"
    period="201401" orgUnit="FNnj3jKGS7i" value="14"/>
  <dataValue dataElement="f7n9E0hX8qk"
    period="201402" orgUnit="DiszpKrYNg8" value="16"/>
  <dataValue dataElement="f7n9E0hX8qk"
    period="201402" orgUnit="Jkhdsf8sdf4" value="18"/>
</dataValueSet>
```

Au format JSON :

```json
{
  "dataValues": [
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201401",
      "orgUnit": "DiszpKrYNg8",
      "valeur": "12"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201401",
      "orgUnit": "FNnj3jKGS7i",
      "valeur": "14"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201402",
      "orgUnit": "DiszpKrYNg8",
      "valeur": "16"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "période": "201402",
      "orgUnit": "Jkhdsf8sdf4",
      "valeur": "18"
    }
  ]
}
```

Au format CSV :

```csv
"dataelement","period","orgunit","categoryoptioncombo","attributeoptioncombo","value"
"f7n9E0hX8qk","201401","DiszpKrYNg8","bRowv6yZOF2","bRowv6yZOF2","1"
"Ix2HsbDMLea","201401","DiszpKrYNg8","bRowv6yZOF2","bRowv6yZOF2","2"
"eY5ehpbEsB7","201401","DiszpKrYNg8","bRowv6yZOF2","bRowv6yZOF2","3"
```

Nous effectuons les tests en utilisant "curl" pour envoyer les données au format XML :

```bash
curl -d @datavalueset.xml "https://play.dhis2.org/demo/api/33/dataValueSets"
  -H "Content-Type:application/xml" -u admin:district
```

Notez que lorsque vous utilisez le format CSV, vous devez utiliser l'option de données binaires pour conserver le retour-à-la-ligne dans le fichier CSV :

```bash
curl --data-binary @datavalueset.csv "https://play.dhis2.org/demo/24/api/dataValueSets"
  -H "Content-Type:application/csv" -u admin:district
```

La ressource ensemble de valeurs de données fournit une réponse XML qui est utile lorsque vous voulez vérifier l'impact de votre requête. La première fois que nous envoyons la requête " ensemble de données " ci-dessus, le serveur répondra avec le résumé d'importation suivant :

```xml
<importSummary>
  <dataValueCount imported="2" updated="1" ignored="1"/>
  <dataSetComplete>faux</dataSetComplete>
</importSummary>
```

Ce message nous indique que 3 données ont été importées, 1 donnée a été mise à jour et 0 donnée a été ignorée. La seule mise à jour résulte de l'envoi de cette donnée dans l'exemple précédent. Une donnée sera ignorée si elle fait référence à un élément de données, une période, une unité d'organisation ou un ensemble de données qui n'existent pas. Dans notre cas, cette valeur unique ignorée est due au fait que la dernière donnée faisait référence à une unité d'organisation non valide. L'élément complet de l'ensemble de données affichera la date à laquelle l'ensemble de données a été achevé, ou " faux " si aucun attribut d'élément de données n'a été fourni.

### Paramètres d'importation { #webapi_data_values_import_parameters }

Le processus d'importation peut être personnalisé à l'aide d'un ensemble de paramètres d'importation :



Tableau : Paramètres d'importation

| Paramètre | Valeurs (par défaut en premier) | Description |
|---|---|---|
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | uide &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'élément de données à utiliser pour faire correspondre les données. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | uide &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'unité d'organisation à utiliser pour faire correspondre les données. |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | uide &#124; nom &#124; code &#124; attribut:ID | Propriété des objets de combinaisons d’options de catégorie et d’options d’attribut à utiliser pour faire correspondre les valeurs de données. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'objet d'ensemble de données à utiliser pour faire correspondre les données. |
| categoryIdScheme (Schéma de l'identifiant de catégorie) | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'objet de catégorie à utiliser pour faire correspondre les données (ADX uniquement). |
| categoryOptionIdScheme (Schéma de l'identifiant d'option de catégorie) | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'objet d'option catégorie à utiliser pour faire correspondre les données (ADX uniquement). |
| idScheme | uide &#124; nom &#124; code&#124; attribut:ID | Propriété de l'un des objets ci-dessus s'ils ne sont pas spécifiés, à utiliser pour faire correspondre les données. |
| preheatCache | faux &#124; vrai | Indique s'il faut précharger les caches de métadonnées avant de commencer l'importation des données. Ceci permettra d'accélérer l'importation de grandes quantités de métadonnées. |
| dryRun | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| importStrategy (stratégie d'importation) | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipExistingCheck (ignorer les contrôles existants) | faux &#124; vrai | Ne contrôle pas les données existantes. Améliore les performances. À utiliser uniquement pour les bases de données vides ou lorsque les données à importer n'existent pas encore. |
| skipAudit (ignorer l'audit) | faux &#124; vrai | "Ignorer l'audit" signifie que les valeurs d'audit ne seront pas générées. Améliore les performances au détriment de la capacité à auditer les modifications. Nécessite l'autorité "F_SKIP_DATA_IMPORT_AUDIT". |
| async | faux &#124; vrai | Indique si l'importation doit être effectuée de manière asynchrone ou synchrone. La première option (asynchrone) est adapté aux importations très volumineuses car il garantit que la requête n’expire pas, bien qu’il entraîne une surcharge de performances. La deuxième (synchrone) est plus rapide mais nécessite que la connexion soit maintenue jusqu'à la fin du processus. |
| force | faux &#124; vrai | Indique si l'importation doit être forcée. L'importation de données peut être rejetée pour diverses raisons liées au verrouillage de l'ensemble des données, par exemple en raison de l'approbation, de la période de saisie des données, des jours d'expiration, etc. Pour passer outre ces verrouillages et forcer la saisie des données, il est possible d'utiliser l'importation de données en définissant force=true. Cependant, il faut être un \*superutilisateur\* pour que ce paramètre fonctionne. |

Tous les paramètres sont facultatifs et peuvent être fournis en tant que paramètres de requête dans l'URL de la requête comme ceci :

    /api/33/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=name
      &dryRun=true&importStrategy=CREATE

Ils peuvent également être fournis en tant qu'attributs XML sur l'élément " ensemble de valeurs de données ", tel qu'indiqué ci-dessous. Les attributs XML remplacent les paramètres de la chaîne de requête.

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataElementIdScheme="code"
  orgUnitIdScheme="name" dryRun="true" importStrategy="CREATE">
</dataValueSet>
```

Notez que le paramètre `preheatCache` peut avoir un impact considérable sur les performances. Pour les petits fichiers d'importation, maintenir "faux" permettra de gagner en rapidité. Pour les gros fichiers d'importation qui contiennent un grand nombre d'éléments de données et d'unités d'organisation distincts, le définir sur "vrai" permettra de gagner en rapidité en termes d'ordre de grandeur.

#### Exigences en matière de valeur des données { #webapi_data_values_import_requirement }

L’importation de valeurs de données prend en charge un ensemble de types de valeurs. Chaque type de valeur a une exigence particulière. Le tableau suivant répertorie les cas extrêmes pour les types valeur.



Tableau : Exigences relatives au type de valeur

| Type de valeur | Exigences | Commentaire |
|---|---|---|
| BOOLÉEN | vrai &#124; C'est vrai &#124; VRAI &#124; faux &#124; Faux &#124; FAUX &#124; 1 &#124; 0 &#124; t &#124; f &#124; | Utilisé lorsque la valeur est booléenne, vraie ou fausse. Le service d'importation ne prête pas attention au fait que l'entrée commence par une lettre majuscule ou minuscule, ou qu'elle soit entièrement en lettres majuscules. |

#### Schémas d'identifiants { #webapi_data_values_identifier_schemes }

En ce qui concerne les schémas d'identifiants, les identifiants utilisés dans les messages XML utilisent par défaut les identifiants d'objets stables de DHIS2 appelés `UID`. Dans certaines situations d'interopérabilité, il se peut qu'un système externe détermine les identifiants des objets. Dans ce cas, nous pouvons utiliser la propriété `code` des unités d'organisation et d'autres objets pour définir des identifiants fixes. Lors de l'importation des valeurs de données, nous devons donc référencer la propriété "code" et non la propriété "identifiant" de ces objets de métadonnées. Les schémas d'identifiants peuvent être spécifiés dans le message XML ainsi que dans la requête en tant que paramètres de requête. Pour les spécifier dans la charge utile XML, vous pouvez procéder comme suit :

```xml
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0"
  dataElementIdScheme="CODE" orgUnitIdScheme="UID" idScheme="CODE">
</dataValueSet>
```

Le tableau des paramètres ci-dessus explique comment les schémas d'identifiants peuvent être spécifiés comme paramètres de requête. Les règles suivantes déterminent l'ordre de priorité :

  - Les schémas d'identifiants définis dans la charge utile XML ou JSON ont priorité sur
    les schémas d'identifiants définis comme paramètres de requête URL.

  - Les schémas d'identifiants spécifiques tels que dataElementIdScheme ou
    orgUnitIdScheme ont priorité sur le idScheme général.

  - Si aucun schéma d'identifiants explicite n'est défini, le schéma d'identifiants par défaut est `code`
    pour le format ADX et `uid` pour tous les autres formats.

Les schémas d'identifiants suivants sont disponibles.

  - uid

  - code

  - nom

  - attribut (suivi de l'UID de l'attribut)

L'option d'attribut est spéciale et fait référence aux attributs de métadonnées qui ont été marqués comme *uniques*. En utilisant cette option, l'`attribut` doit être immédiatement suivi de l'identifiant de l'attribut, par exemple "attribut : DnrLSdo4hMl".

#### Importation de valeurs de données asynchrones { #webapi_data_values_async_import }

Les valeurs de données peuvent être envoyées et importées de manière asynchrone à travers un paramètre de requête `async` défini sur *vrai* :

    /api/33/dataValueSets?async=true

Cela lancera une tâche d'importation asynchrone dont vous pourrez surveiller l'état grâce à l'API de résumés des tâches. La réponse de l'API indique l'identifiant unique de la tâche, du type de tâche et de l'URL que vous pouvez utiliser pour surveiller l’état de l'importation. La réponse ressemblera à ceci :

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Initiated dataValueImport",
  "response": {
    "name": "dataValueImport",
    "id": "YR1UxOUXmzT",
    "created": "2018-08-20T14:17:28.429",
    "jobType": "DATAVALUE_IMPORT",
    "relativeNotifierEndpoint": "/api/system/tasks/DATAVALUE_IMPORT/YR1UxOUXmzT"
  }
}
```

Veuillez lire la section sur *l'état des tâches asynchrones* pour en savoir plus.

### Format des valeurs de données CSV { #webapi_data_values_csv }

La section suivante décrit le format CSV utilisé dans DHIS2. La première ligne est supposée être une ligne d'en-tête et sera ignorée lors de l'importation.



Tableau : format CSV de DHIS2

||||
|---|---|---|
| Colonne | Obligatoire | Description |
| Élément de données | Oui | Fait référence à l'ID par défaut, peut également être un nom et un code basés sur le schéma d'identifiants sélectionné |
| Période | Oui | Au format ISO |
| Unité d'organisation | Oui | Fait référence à l'ID par défaut, peut également être un nom et un code basés sur le schéma d'identifiants sélectionné |
| Combinaison d'options de catégorie | Non | Fait référence à l'identifiant |
| Combinaison d'options d'attribut | Non | Fait référence à l'ID (à partir de la version 2.16) |
| Valeur | Non | Valeur de données |
| Stocké par | Non | Fait référence au nom d'utilisateur de l'utilisateur qui a saisi la valeur |
| Dernière mise à jour | Non | Date au format ISO |
| Commentaire | Non | Commentaire en texte libre |
| Suivi | Non | vrai ou faux |

Ci-dessous un exemple de fichier CSV pouvant être importé dans DHIS2 :

```csv
"dataelement","period","orgunit","catoptcombo","attroptcombo","value","storedby","timestamp"
"DUSpd8Jq3M7","201202","gP6hn503KUX","Prlt0C1RF0s",,"7","bombali","2010-04-17"
"DUSpd8Jq3M7","201202","gP6hn503KUX","V6L425pT3A0",,"10","bombali","2010-04-17"
"DUSpd8Jq3M7","201202","OjTS752GbZE","V6L425pT3A0",,"9","bombali","2010-04-06"
```

### Génération d'un modèle d'ensemble de valeurs de données { #webapi_data_values_template }

Pour générer un modèle d'ensemble de valeurs de données pour un ensemble de données spécifique, vous pouvez utiliser la ressource `/api/dataSets/<id>/dataValueSet`. les formats de réponse XML et JSON sont pris en charge. Exemple:

    /api/dataSets/BfMAe6Itzgt/dataValueSet.json

Ci-dessous les paramètres que vous pouvez utiliser pour ajuster davantage la sortie :



Tableau : Paramètres de requête de valeurs de données

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| période | Non | La période d'utilisation sera incluse sans aucun contrôle. |
| orgUnit (Unité d'organisation) | Non | L'unité d'organisation à utiliser ; prend en charge plusieurs unités d'organisation ; l'identifiant et le code peuvent être utilisés. |
| commentaire | Non | Sur la prise en compte des commentaires, par défaut : Oui. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Non | Schéma d'unités d'organisation à utiliser ; prend en charge l'identifiant &#124; code. |
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | Non | Schéma d'élément de données à utiliser ; prend en charge l'identifiant &#124; code. |

### Lecture des valeurs de données { #webapi_reading_data_values }

This section explains how to retrieve data values from the Web API by
interacting with the *dataValueSets* resource. Data values can be
retrieved in *XML*, *JSON*, *CSV*, and *ADX* format. Since we want to read data
we will use the *GET* HTTP verb. We will also specify that we are
interested in the XML resource representation by including an `Accept`
HTTP header with our request. The following query parameters are
accepted:


Tableau : Paramètres de requête d'ensemble de valeurs de données

| Paramètre | Description |
|---|---|
| dataSet (ensemble de données) | Identifiant de l'ensemble de données. Peut être répété plusieurs fois. |
| dataElementGroup (groupe d'éléments de données) | Identifiant du groupe d'éléments de données. Peut être répété autant de fois que vous le voulez (pas pris en charge pour le format ADX). |
| période | Identifiant de période au format ISO. Peut être répété plusieurs fois. |
| date de début | Date de début pour la période des valeurs à exporter. |
| date de fin | Date de fin pour la période des valeurs à exporter. |
| orgUnit (Unité d'organisation) | Identifiant de l’unité d’organisation. Peut être répété plusieurs fois. |
| subordonnées | Permet de spécifier s'il faut inclure les unités d’organisation subordonnées dans la hiérarchie des unités d'organisation. |
| orgUnitGroup (groupe d'unités d'organisation) | Identifiant du groupe d’unités d’organisation. Peut être répété plusieurs fois. |
| attributeOptionCombo (combinaison d'options d'attribut) | Identifiant de la combinaison d’options d’attribut. Peut être répété plusieurs fois. |
| includeDeleted | Permet de spécifier s'il faut inclure les valeurs de données supprimées. |
| lastUpdated (dernière mise à jour) | Inclut uniquement les valeurs de données mises à jour depuis l'horodatage donné. |
| lastUpdatedDuration (durée de la dernière mise à jour) | Inclut uniquement les valeurs de données mises à jour pendant la durée spécifique. Le format est <value\><time-unit\>, où les unités de temps prises en charge sont "j" (jours), "h" (heures), "m" (minutes) et "s" (secondes). |
| limite | Le nombre maximum de résultats dans la réponse. |
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | Propriété de l'objet d'élément de données à utiliser pour les valeurs de données dans la réponse. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Propriété de l'objet d'unité d'organisation à utiliser pour les valeurs de données dans la réponse. |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété de la combinaison d'options de catégorie à utiliser pour les valeurs de données dans la réponse. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété des objets de combinaison d'options d'attribut à utiliser pour les valeurs de données dans la réponse. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | Propriété de l'objet d'ensemble de données à utiliser dans la réponse. |
| categoryIdScheme (Schéma de l'identifiant de catégorie) | Propriété de l'objet catégorie à utiliser dans la réponse (ADX uniquement). |
| categoryOptionIdScheme (Schéma de l'identifiant d'option de catégorie) | Propriété de l'objet d'options de catégorie à utiliser dans la réponse (ADX uniquement). |
| idScheme | Propriété de l'un des objets ci-dessus, s'ils ne sont pas spécifiés, à utiliser dans la réponse. S’il n’est pas spécifié, l’idScheme par défaut pour le format ADX est "code" et pour tous les autres formats, c'est "uid". |
| inputOrgUnitIdScheme | Propriété d'identification utilisée pour les valeurs du paramètre `orgUnit` fournies ; `id` ou `code` |
| inputDataSetIdScheme | Propriété d'identification utilisée pour les valeurs du paramètre `dataSet` fournies ; `id` ou `code` |
| inputDataElementGroupIdScheme | Propriété d'identification utilisée pour les valeurs du paramètre `dataElementGroup` fournies ; `id` ou `code` |
| inputIdScheme | Propriété d'identification utilisée pour l'une des valeurs des paramètres `dataSet`, `dataElementGroup`, `orgUnit`, `orgUnitGroup`, `attributeOptionCombo` fournies, à moins que l'un des trois schémas ci-dessus ne remplace explicitement cette entrée par défaut ; `id` ou `code` |

Les paramètres suivants provenant de la liste ci-dessus sont requis :
- dataSet ou dataElementGroup (pour le format ADX, cela doit être dataSet)
- period, (startDate et endDate), lastUpdated, ou lastUpdatedDuration
- orgUnit ou orgUnitGroup

Les formats de réponse suivants sont pris en charge :

  - xml (application/xml)

  - json (application/json)

  - csv (application/csv)

  - adx (application/adx+xml)

En supposant que nous avons publié les valeurs de données dans DHIS2 conformément à la section précédente intitulée *Envoi de valeurs de données*, nous pouvons maintenant constituer notre requête pour un ensemble de valeurs de données unique et l'exécuter en utilisant l'URL :

```bash
curl "https://play.dhis2.org/demo/api/33/dataValueSets?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8"
  -H "Accept:application/xml" -u admin:district
```

Nous pouvons également utiliser les paramètres de requête "date de début" et "date de fin" pour demander un plus grand nombre de valeurs de données. En d'autres termes, vous pouvez également demander des valeurs de données pour plusieurs ensembles de données, unités d'organisation et périodes afin d'exporter de plus grandes quantités de données. Notez que le paramètre de requête "période" est prioritaire sur les paramètres "date de début" et "date de fin". Voici un exemple :

```bash
curl "https://play.dhis2.org/demo/api/33/dataValueSets?dataSet=pBOMPrpg1QX&dataSet=BfMAe6Itzgt
  &startDate=2013-01-01&endDate=2013-01-31&orgUnit=YuQRtpLP10I&orgUnit=vWbkYPRmKyS&children=true"
  -H "Accept:application/xml" -u admin:district
```

Pour récupérer les valeurs de données qui ont été créées ou mises à jour au cours des 10 derniers jours, vous pouvez effectuer la requête suivante :

    /api/dataValueSets?dataSet=pBOMPrpg1QX&orgUnit=DiszpKrYNg8&lastUpdatedDuration=10d

La réponse ressemblera à ceci :

```xml
<?xml version='1.0' encoding='UTF-8'?>
<dataValueSet xmlns="http://dhis2.org/schema/dxf/2.0" dataSet="pBOMPrpg1QX"
  completeDate="2014-01-02" period="201401" orgUnit="DiszpKrYNg8">
<dataValue dataElement="eY5ehpbEsB7" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10003"/>
<dataValue dataElement="Ix2HsbDMLea" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10002"/>
<dataValue dataElement="f7n9E0hX8qk" period="201401" orgUnit="DiszpKrYNg8"
  categoryOptionCombo="bRowv6yZOF2" value="10001"/>
</dataValueSet>
```

Vous pouvez demander à ce que les données soient rendues au format JSON de la manière suivante :

    /api/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401&orgUnit=DiszpKrYNg8

La réponse ressemblera à ceci :

```json
{
  "dataSet": "pBOMPrpg1QX",
  "completeDate": "2014-02-03",
  "period": "201401",
  "orgUnit": "DiszpKrYNg8",
  "dataValues": [
    {
      "dataElement": "eY5ehpbEsB7",
      "categoryOptionCombo": "bRowv6yZOF2",
      "period": "201401",
      "orgUnit": "DiszpKrYNg8",
      "value": "10003"
    },
    {
      "dataElement": "Ix2HsbDMLea",
      "categoryOptionCombo": "bRowv6yZOF2",
      "period": "201401",
      "orgUnit": "DiszpKrYNg8",
      "value": "10002"
    },
    {
      "dataElement": "f7n9E0hX8qk",
      "categoryOptionCombo": "bRowv6yZOF2",
      "period": "201401",
      "orgUnit": "DiszpKrYNg8",
      "value": "10001"
    }
  ]
}
```

Notez que les valeurs de données sont mises en corbeille, c'est-à-dire qu'une valeur supprimée a la propriété `supprimée` définie sur "vrai" et n'est pas supprimée de façon permanente. Ceci est utile lors de l'intégration de plusieurs systèmes afin de signaler les suppressions. Vous pouvez inclure les valeurs supprimées dans la réponse comme suit :

    /api/33/dataValueSets.json?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8&includeDeleted=true

Vous pouvez également demander à ce que les données soient rendues au format CSV de la manière suivante :

    /api/33/dataValueSets.csv?dataSet=pBOMPrpg1QX&period=201401
      &orgUnit=DiszpKrYNg8

La réponse ressemblera à ceci :

```csv
dataelement,period,orgunit,catoptcombo,attroptcombo,value,storedby,lastupdated,comment,flwup
f7n9E0hX8qk,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,12,system,2015-04-05T19:58:12.000,comment1,false
Ix2HsbDMLea,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,14,system,2015-04-05T19:58:12.000,comment2,false
eY5ehpbEsB7,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,16,system,2015-04-05T19:58:12.000,comment3,false
FTRrcoaog83,201401,DiszpKrYNg8,bRowv6yZOF2,bRowv6yZOF2,12,system,2014-03-02T21:45:05.519,comment4,false
```

Les contraintes suivantes s'appliquent à la ressource Ensembles de valeurs de données :

  - Au moins un ensemble de données doit être spécifié.

  - Soit au moins une période, soit une date de début et une date de fin doivent être
    spécifiés.

  - Au moins une unité d'organisation doit être spécifiée.

  - Les unités d'organisation doivent faire partie de la hiérarchie des unités d'organisation 
    de l’utilisateur authentifié.

  - La limite ne peut pas être inférieure à zéro.

### Envoi, lecture et suppression de valeurs de données individuelles { #webapi_sending_individual_data_values }

Cet exemple montrera comment envoyer des valeurs de données individuelles à enregistrer dans une requête. Ceci peut être réalisé par l'envoi d'une requête *POST* à la ressource `dataValues` :

    /api/dataValues

Les paramètres de requête suivants sont pris en charge pour cette ressource :



Tableau : Paramètres de requête de valeurs de données

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| de | Oui | Identifiant de l'élément de données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| co | Non | Identifiant de la combinaison d'options de catégorie, la valeur par défaut sera utilisée en cas d'omission |
| cc | Non (doit être combiné avec cp) | Identifiant de la combinaison de catégories d'attribut |
| cp | Non (doit être combiné avec CC) | Identifiants d'options de catégorie d'attribut, séparés par ; pour plusieurs valeurs |
| ds | Non | Ensemble de données, pour vérifier si la fonction POST or DELETE (publier ou effacer) est autorisée pour la période et l'unité d'organisation. S'il est spécifié, l'élément de données doit être affecté à cet ensemble de données. Dans le cas contraire, un ensemble de données contenant l'élément de données sera sélectionné pour vérifier si l'opération est autorisée. |
| valeur | Non | Valeur de données. Pour les valeurs booléennes, les éléments suivants seront acceptés : vrai &#124; Vrai &#124; VRAI &#124; faux &#124; Faux &#124; FAUX &#124; 1 &#124; 0 &#124; t &#124; f &#124; |
| commentaire | Non | Commentaire sur les données |
| suivi | Non | Le suivi de la valeur de données permet de faire basculer la valeur booléenne actuelle |

Si l'un des identifiants fournis n'est pas valide, si la valeur de données ou le commentaire n'est pas valide ou si les données sont verrouillées, la réponse contiendra le code d'état *409 Conflit* et un message texte descriptif. Si l'opération conduit à une valeur enregistrée ou mise à jour, *200 OK* sera renvoyé. Ci-après, un exemple de requête :

```bash
curl "https://play.dhis2.org/demo/api/33/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s&value=12"
  -X POST -u admin:district
```

Cette ressource permet également une syntaxe spéciale pour associer la valeur à une combinaison d'options d'attribut. Pour ce faire, il suffit d'envoyer l'identifiant de la combinaison de catégories d'attribut, ainsi que les identifiants des options de catégories d'attribut que la valeur représente au sein de la combinaison. La combinaison de catégories est spécifiée avec le paramètre `cc`, tandis que les options de catégorie sont spécifiées sous la forme d'une chaîne de caractères séparés par des points-virgules avec le paramètre `cp`. Il faut s'assurer que les options de catégorie font toutes partie de la combinaison de catégories. Voici un exemple :

```bash
curl "https://play.dhis2.org/demo/api/33/dataValues?de=s46m5MS0hxu&ou=DiszpKrYNg8
  &pe=201308&cc=dzjKKQq0cSO&cp=wbrDrL2aYEc;btOyqprQ9e8&value=26"
  -X POST -u admin:district
```

Vous pouvez récupérer une valeur de données avec une requête en utilisant la méthode *GET* (obtenir). Les paramètres de valeur, de commentaire et de suivi ne sont pas applicables ici :

```bash
curl "https://play.dhis2.org/demo/api/33/dataValues?de=s46m5MS0hxu
  &pe=201301&ou=DiszpKrYNg8&co=Prlt0C1RF0s"
  -u admin:district
```

Vous pouvez supprimer une valeur de données avec une requête en utilisant la méthode *DELETE*.

#### Utilisation des valeurs de données de fichiers { #datavalue_file }

Lorsqu'il s'agit de valeurs de données dont l'élément de données est de type *fichier*, la méthode décrite ci-dessus ne s'applique plus. Ces valeurs de données sont spéciales dans la mesure où le contenu de la valeur est une référence UID à un objet *Ressource de fichier* et non une constante autonome. Ces valeurs de données se comportent comme les autres valeurs de données qui stockent du contenu textuel, mais elles doivent être traitées différemment afin de produire des entrées et des sorties pertinentes.

There are two methods of storing FileResource data values.

**The Easy Way:** Upload the file to the `/api/dataValues/file` endpoint as
described in the file resource section.  This works on versions 2.36 and later.

**The Hard Way:** If you are writing code that needs to be compatible
with versions of DHIS2 before 2.36, then the process is:

1.  Téléchargez le fichier sur le point de terminaison `/api/fileResources` tel que décrit
    dans la section des ressources de fichiers.

2.  Retrieve the `id` property of the returned *FileResource*.

3.  Store the retrieved id *as the value* to the data value using any
    des méthodes décrites ci-dessus.

Seules les relations un à un entre les valeurs de données et les ressources de fichiers sont autorisées. Cette règle est appliquée en interne, de sorte que l'enregistrement de l'identifiant d'une ressource de fichier dans plusieurs valeurs de données ne soit pas possible et entraîne une erreur. La suppression de la valeur de données entraîne la suppression de la ressource de fichier référencée. La suppression directe des ressources de fichiers n'est pas possible.

La valeur de données peut maintenant être récupérée normalement, mais c'est l'UID de la ressource du fichier qui sera renvoyé. Afin de récupérer le vrai contenu (c'est-à-dire le fichier stocké dans la ressource associée à la valeur de données), vous devez effectuer une requête GET à `/api/dataValues/files` en reproduisant les paramètres de la requête comme pour la valeur de données elle-même. Le point de terminaison `/api/dataValues/files` ne prend en charge que les requêtes GET.

Il convient de noter qu'en raison du fonctionnement asynchrone du mécanisme de stockage sous-jacent, le contenu du fichier peut ne pas être immédiatement téléchargeable à partir du point de terminaison `/api/dataValues/files`. Ceci est particulièrement valable pour les fichiers volumineux qui peuvent nécessiter des téléchargements en arrière-plan vers un entrepôt de fichiers externe (en fonction de la configuration du système). Récupérer les métadonnées de la ressource du fichier à partir du point de terminaison `/api/fileResources/<id>` permet de vérifier le `storageStatus` (état du stockage) du contenu avant d'essayer de le télécharger.

## Format de données ADX { #webapi_adx_data_format }

Depuis la version 2.20, nous prenons en charge une norme internationale d'échange de données agrégées appelée ADX. ADX est développé et maintenu par le comité Quality, Research and Public Health (Qualité, Recherche et Santé Publique) de l'IHE (Integrating the HealthCare Enterprise). La page wiki décrivant les activités du comité QRPH se trouve à l'adresse [wiki.ihe.net](http://wiki.ihe.net/index.php?title=Quality,_Research_and_Public_Health#Current_Domain_Activities). ADX fait toujours l'objet d'un développement actif et a maintenant été publié pour une implémentation à titre expérimental. Notez qu'actuellement, c'est la fonctionnalité de lecture et d'écriture des données formatées ADX qui est implémentée dans DHIS2, c'est-à-dire ce qui est décrit comme acteurs Consommateur de Contenu et Producteur de Contenu dans le profil ADX.

La structure d'un message de données ADX est assez similaire à celle des données DXF 2 décrites précédemment et que vous connaissez probablement. Il existe quelques différences importantes. Nous les décrirons à l'aide d'un petit exemple :

```xml
<adx xmlns="urn:ihe:qrph:adx:2015" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
  xsi:schemaLocation="urn:ihe:qrph:adx:2015 ../schema/adx_loose.xsd"
  exported="2015-02-08T19:30:00Z">
  <group orgUnit="OU_559" period="2015-06-01/P1M"
    completeDate="2015-07-01" dataSet="(TB/HIV)VCCT">
    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE0-14" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE0-14" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE0-14" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="FMLE" HIV_AGE="AGE15-24" value="10"/>

    <dataValue dataElement="VCCT_0" GENDER="MLE" HIV_AGE="AGE15-24" value="32"/>
    <dataValue dataElement="VCCT_1" GENDER="MLE" HIV_AGE="AGE15-24" value="20"/>
    <dataValue dataElement="VCCT_2" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_0" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
    <dataValue dataElement="PLHIV_TB_1" GENDER="MLE" HIV_AGE="AGE15-24" value="10"/>
  </group>
</adx>
```

### L'élément racine ADX { #the-adx-root-element }

L'élément racine ADX n'a qu'un seul attribut obligatoire, qui est l'horodatage *exporté*. Comme d'autres éléments ADX, le schéma est extensible dans le sens où il ne restreint pas les attributs spécifiques d'applications supplémentaires.

### L'élément du groupe ADX { #the-adx-group-element }

Contrairement à dxf2, ADX exige que les valeurs de données soient regroupées par unité d'organisation, période et ensemble de données. L'exemple ci-dessus montre un rapport de données pour l'ensemble de données "( TB/VIH) VCCT" de la base de données de démonstration en ligne. Cet exemple utilise des codes comme identifiants et non des uids dhis2. Le code est la forme d'identifiant préférée lors de l'utilisation d'ADX.

Les attributs d'unité d'organisation, de période et d'ensemble de données sont obligatoires dans ADX. L'élément de groupe peut contenir des attributs supplémentaires. Dans notre implémentation de DHIS2, tout attribut supplémentaire est simplement transmis à l'importateur sous-jacent. Cela signifie que tous les attributs qui ont actuellement une signification dans dxf2 (comme completeDate dans l'exemple ci-dessus) peuvent continuer à être utilisés dans ADX et seront traités de la même manière.

Une différence importante entre ADX et dxf2 réside dans la manière dont les périodes sont encodées. ADX utilise strictement la norme ISO8601 et encode la période de déclaration sous la forme (date|heure) / (durée). Dans l'exemple ci-dessus, la période est donc une période d'un mois (P1M) qui commence le 01/06/2015. Il s'agit donc des données de juin 2015. La notation est un peu plus longue, mais elle est très souple et nous permet de prendre en charge tous les types de période existants dans DHIS2.

### Définitions des périodes ADX { #adx-period-definitions }

Les périodes commencent par la date à laquelle la durée commence, suivie d'un "/" et de la notation de la durée, comme indiqué dans le tableau. Le tableau suivant détaille tous les types de période dans DHIS2 et la manière dont ils sont représentés en ADX, ainsi que des exemples.

Tableau : Périodes ADX

| Type de période | Notation de durée | Exemples) | Durée(s) |
|---|---|---|---|
| Quotidien  | P1D | 2017-10-01/P1M | 01 octobre 2017 |
| Hebdomadaire | P7D | 2017-10-02/P7D | 02 oct 2017-08 oct 2017 |
| Hebdomadaire Mercredi | P7D | 04-10-2017/P7D | 04 octobre 2017-10 octobre 2017 |
| Hebdomadaire Jeudi | P7D | 05-10-2017/P7D | 05 octobre 2017-011 octobre 2017 |
| Hebdomadaire Samedi | P7D | 07-10-2017/P7D | 07 octobre 2017-13 octobre 2017 |
| Hebdomadaire Dimanche | P7D | 01-10-2017/P7D | 01 octobre 2017-07 octobre 2017 |
| Bihebdomadaire | P14D | 02-10-2017/P14D | 02 octobre 2017-15 octobre 2017 |
| Mensuel | P1M | 2017-10-01/P1M | 01 octobre 2017-31 octobre 2017 |
| Bimensuel | P2M | 01-11-2017/P2M | 01 novembre 2017-31 décembre 2017 |
| Trimestriel | P3M | 01-09-2017/P3M | 01 septembre 2017-31 décembre 2017 |
| Semestriel | P6M | 01-01-2017/P6M<br>01-07-2017/P6M | 1er janvier 2017-30 juin 2017<br>1er juillet 2017-31 décembre 2017 |
| Semestriel Avril | P6M | 01-04-2017/P6M<br>01-10-2017/P6M | 1er avril 2017-30 septembre 2017<br>1er octobre 2017-31 mars 2018 |
| Semestriel Novembre | P6M | 01-10-2017/P6M<br>01-05-2018/P6M | 1er novembre 2017-30 avril 2018<br>1er mai 2018-31 octobre 2018 |
| Annuel | P1Y | 01-01-2017/P1Y | 01 janvier 2017-31 décembre 2017 |
| Financière Avril | P1Y | 01-04-2017/P1Y | 1er avril 2017-31 mars 2018 |
| Financière Juillet | P1Y | 01-07-2017/P1Y | 1er juillet 2017-30 juin 2018 |
| Financière Octobre | P1Y | 01-10-2017/P1Y | 01 octobre 2017-30 septembre 2018 |
| Financière Novembre | P1Y | 01-11-2017/P1Y | 01 novembre 2017-31 octobre 2018 |

### Valeurs de données ADX { #adx-data-values }

L'élément "valeur de données" dans ADX est très similaire à son équivalent dans DXF. Les attributs obligatoires sont *élément de données* et *valeur*. Les attributs *unité d'organisation* et *période* n'apparaissent pas dans l'élément "valeur de données" car ils sont requis au niveau *groupe*.

La différence la plus significative est la manière dont la désagrégation est représentée. DXF utilise la combinaison d'options de catégorie pour représenter la désagrégation des données. Dans ADX, les désagrégations (par exemple GROUPE_D'ÂGE et SEXE) sont exprimées explicitement en tant qu'attributs. Si vous utilisez `code` comme schéma d'identification pour `catégorie`, vous devez attribuer un code à toutes les catégories utilisées pour les éléments de données de l'ensemble de données et, de plus, ce code doit pouvoir être utilisé en tant qu'attribut XML. La contrainte concernant un nom d'attribut XML est décrite dans la norme XML du W3C. En pratique, cela signifie qu'il n'y a pas d'espaces, pas de caractères non alphanumériques autres que "_" et que le nom ne peut pas commencer par une lettre. L'exemple ci-dessus montre des exemples de "bons" codes de catégorie ("GENRE" et "ÂGE_VIH"). Les mêmes restrictions s'appliquent si vous utilisez `nom` ou `attribut` comme schémas d'identification.

Dans ADX, seuls les identifiants de catégorie sont utilisés comme attributs XML ; les identifiants d'autres types de métadonnées ne doivent pas être utilisés comme attributs XML. Notez que cette syntaxe n'est pas appliquée par DHIS2 lorsque vous attribuez des noms, des codes ou des attributs DHIS2, mais vous obtiendrez un message d'erreur avec une explication si vous essayez d'importer des données ADX et que les identifiants de catégorie ne sont pas attribués ou ne conviennent pas.

Les principaux avantages de l’utilisation de dimensions explicites de données désagrégées sont les suivants :

  - Le système qui produit les données n'a pas besoin d'être synchronisé avec la
    combinaison d'options de catégorie dans DHIS2.

  - Le producteur et le consommateur peuvent faire correspondre leurs codes à une source tierce 
    qui fait autorité, telle qu'un service de terminologie. Notez que dans 
    l'exemple ci-dessus, les codes de genre et de groupe d'âge utilisent des listes de codes
    de l'[Observatoire mondial de la santé de l'OMS](http://apps.who.int/gho/data/node.resources.api).

Cette fonction peut être très utile, par exemple pour produire des données désagrégées à partir d'un système de DME, mais il peut arriver qu'un mapping de *combinaison d'options de catégorie* soit plus facile ou plus souhaitable. L'implémentation d'ADX dans DHIS2 permettra de vérifier l'existence d'un attribut de *combinaison d'options de catégorie* et, s'il existe, de l'utiliser au lieu des attributs de dimension éclatés. De même, un attribut de *combinaison d'options d'attributs* sur l'élément *groupe* sera traité de la même manière que les attributs existants. Sinon, la combinaison d'options d'attributs peut être utilisée comme catégories éclatées, comme pour la *valeur de données*.

Dans l'exemple simple ci-dessus, tous les éléments de données de l'ensemble de données ont la même dimensionnalité (combinaison de catégories), ce qui rend les données parfaitement rectangulaires. Les ensembles de données peuvent contenir des éléments de données ayant des combinaisons de catégories différentes, ce qui donne un message de données ADX *décalé vers la droite* (c'est-à-dire que les valeurs des différents éléments de données peuvent avoir des nombres de catégories différents).

### Importation de données ADX { #importing-adx-data }

DHIS2 expose un point de terminaison pour les données POST ADX dans `/api/dataValueSets` en utilisant *application/xml+adx* comme type de contenu. Ainsi, par exemple, la commande curl suivante peut être utilisée pour POST (publier) les exemples de données ci-dessus dans le serveur de démonstration DHIS2 :

```bash
curl -u admin:district -X POST -H "Content-Type: application/adx+xml"
  -d @data.xml "https://play.dhis2.org/demo/api/33/dataValueSets?dataElementIdScheme=code&orgUnitIdScheme=code"
```

Notez que les paramètres de requête sont les mêmes que ceux utilisés avec les données DXF. Le point de terminaison ADX doit interpréter tous les paramètres DXF existants avec la même sémantique que DXF.

### Exportation de données ADX { #exporting-adx-data }

DHIS2 expose un point de terminaison pour les ensembles de données GET ADX dans `/api/dataValueSets` en utilisant *application/xml+adx* comme type de contenu. Ainsi, par exemple, la commande curl suivante peut être utilisée pour récupérer les données ADX :

```bash
curl -u admin:district -H "Accept: application/adx+xml"
 "https://play.dhis2.org/demo/api/33/dataValueSets?dataValueSets?orgUnit=M_CLINIC&dataSet=MALARIA&period=201501"
```

Notez que les paramètres de requête sont les mêmes que ceux utilisés avec les données DXF. Une différence importante est que les identifiants d'ensemble de données et d'unité d'organisation peuvent être soit des uids, soit des codes.

## Suivi { #webapi_follow_up }

Cette section couvre les données de marquage pour le suivi.

### Suivi de la valeur de données { #data-value-follow-up }

Le point de terminaison de suivi des valeurs de données permet de marquer les valeurs de données pour le suivi.

```
PUT /api/36/dataValues/followup
```

La charge utile au format `JSON` ressemble à ceci :

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "categoryOptionCombo": "psbwp3CQEhs",
  "attributeOptionCombo": "HllvX50cXC0",
  "followup": true
}
```

Les champs `combinaison d'options de catégorie` et `combinaison d'options d'attributs` sont facultatifs. Une charge utile `JSON` minimale ressemble à ceci :

```json
{
  "dataElement": "s46m5MS0hxu",
  "period": "202005",
  "orgUnit": "DiszpKrYNg8",
  "followup": false
}
```

Le champ `suivi` doit être défini sur `vrai` pour marquer une valeur de données pour le suivi, et sur `faux` pour retirer le marquage.

Le code d'état de la réponse sera `200 OK` si l'opération réussit, et `409 Conflit` en cas d'erreur avec la requête.

Pour mettre à jour plusieurs valeurs de données à la fois pour le suivi :

    PUT /api/dataValues/followups

avec la charge utile `JSON` :

```json
{
  "values": [
    {
      "dataElement": "s46m5MS0hxu",
      "period": "202005",
      "orgUnit": "DiszpKrYNg8",
      "categoryOptionCombo": "psbwp3CQEhs",
      "attributeOptionCombo": "HllvX50cXC0",
      "followup": true
    }
  ]
}
```

Chaque élément de cette mise à jour comporte les mêmes champs et exigences que le point de terminaison de la mise à jour unique.

La mise à jour groupée renvoie également `200 OK` en cas de succès ou `409 Conflit` en cas d'erreurs dans la requête.



# Validation des données { #data-validation }

## Validation { #webapi_validation }

Pour générer un résumé de validation des données, vous pouvez interagir avec la ressource de validation. La ressource "ensemble de données" est optimisée pour les clients chargés de la saisie des données et de la validation d'un ensemble de données ou d'un formulaire. Elle est accessible de la manière suivante :

    GET /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

En plus de la validation des règles basées sur un ensemble de données, il existe deux méthodes supplémentaires de validation : validation personnalisée et validation programmée.

La première variable path (de chemin) est un identifiant qui fait référence à l'ensemble de données à valider. Les représentations XML et JSON des ressources sont prises en charge. La réponse contient les violations des règles de validation. Cette fonction sera étendue à d'autres types de validation dans les versions à venir.

Pour récupérer les règles de validation relatives à un ensemble de données spécifique, c'est-à-dire les règles de validation avec des formules où tous les éléments de données font partie de l'ensemble de données en question, vous pouvez lancer une requête GET à la ressource `validationRules` de la manière suivante :

    GET /api/validationRules?dataSet=<dataset-id>

Les règles de validation ont un côté gauche et un côté droit, dont la validité est comparée en fonction d'un opérateur. Les valeurs valides de l'opérateur sont indiquées dans le tableau ci-dessous.



Tableau : Opérateurs

| Valeur | Description |
|---|---|
| égal_à | Egale à |
| pas_égale_à | Pas égal à |
| supérieure_à | Supérieure à |
| supérieure_ou_égale_à_ | Supérieure ou égal à |
| inférieure_à | Inférieur à |
| inférieure_ou_égale_à_ | inférieur ou égal à |
| paire_obligatoire | Si l’un des côtés est présent, l’autre doit également l’être. |
| paire_exclusive | Si l’un des côtés est présent, l’autre ne doit pas être |

Les expressions du côté gauche et du côté droit sont des expressions mathématiques qui peuvent contenir des références à des éléments de données et à des combinaisons d'options de catégorie au format suivant :

    ${<dataelement-id>.<catoptcombo-id>}

Les expressions du côté gauche et du côté droit ont une *stratégie de valeur manquante*. Cette stratégie indique comment le système doit traiter les valeurs de données manquantes pour les références d'éléments de données ou de combinaisons d'options de catégorie dans la formule, en déterminant si la règle de validation doit être vérifiée ou ignorée. Les stratégies de valeurs manquantes valides sont présentées dans le tableau ci-dessous.



Tableau : Stratégies de valeur manquante

| Valeur | Description |
|---|---|
| IGNORER_SI_UNE_VALEUR_MANQUE | Ignore la règle de validation si une valeur de données est manquante |
| IGNORER_SI_TOUTES-LES_VALEURS_MANQUENT | Ignore la règle de validation si toutes les valeurs de données sont manquantes |
| NE-JAMAIS_IGNORER | N'ignore jamais la règle de validation, quelles que soient les valeurs de données manquantes |

## Résultats de la validation { #webapi_validation_results }

Les résultats de validation sont les résultats des violations constatées lors d'une analyse de validation. Si vous choisissez "conserver les résultats" lorsque vous lancez ou programmez une analyse de validation, toutes les violations constatées seront stockées dans la base de données. Lorsqu'un résultat est stocké dans la base de données, il est utilisé à trois fins :

1.  Générer des analyses basées sur les résultats stockés.

2.  Les résultats qui n'ont pas généré de notification le feront,
    une fois.

3.  Garder la trace des résultats qui ont généré ou non une
    notification.

4.  Ignorer les règles déjà vérifiées lors de
    l'analyse de validation.

Cela signifie que si vous ne conservez pas vos résultats, vous ne pourrez pas générer d'analyses pour les résultats de validation. Si cette option est sélectionnée, les résultats généreront des notifications à chaque fois qu'il y en aura et l'analyse de validation pourrait être plus lente.

### Résultats de la validation de la requête { #query-validation-results }

Les résultats de validation conservés peuvent être consultés au point d'extrémité suivant :

    GET /api/33/validationResults

Vous pouvez également inspecter un résultat individuel à l'aide de l'identifiant du résultat de validation dans ce point d'extrémité :

    GET /api/33/validationResults/<id>

Les résultats de validation peuvent également être filtrés par les propriétés suivantes :

* Unité organisationnelle : `ou=<UID>`
* Règle de validation : `vr=<UID>`
* Période : `pe=<ISO-expression>`

Chacune des propriétés de filtre ci-dessus peut apparaître plusieurs fois, par exemple :

    GET /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

Plusieurs valeurs pour le même filtre sont combinées avec OR, les résultats doivent correspondre à l'une des valeurs données.

Si plusieurs propriétés de filtre sont utilisées et qu'elles sont combinées avec AND, les résultats devront correspondre à l'une des valeurs de chacune des propriétés.

Pour le filtre de période, les résultats doivent se superposer à l'une des périodes spécifiées.

De plus, les résultats de validation peuvent également être filtrés en fonction de leur date de création :

    GET /api/36/validationResults?createdDate=<date>

Ce filtre peut être combiné avec n’importe quel autre filtre.

### Déclencher des notifications de résultats de validation { #trigger-validation-result-notifications }

Les résultats de la validation sont envoyés aux utilisateurs concernés une fois par jour. Ils peuvent également être déclenchés manuellement pour être exécutés sur demande, à l'aide du point d'extrémité de l'API suivant :

    POST /api/33/validation/sendNotifications

Seuls les résultats non envoyés sont envoyés via ce point d'extrémité.

### Supprimer les résultats de validation { #delete-validation-results }

Les résultats de validation peuvent être supprimés manuellement en utilisant l'ID,

    DELETE /api/36/validationResults/<id>

ou les filtres

    DELETE /api/36/validationResults?<filters>

Les paramètres de filtre pris en charge sont :

* `ou=<UID>` pour faire correspondre tous les résultats de validation d'une unité d'organisation. Plusieurs unités utilisent 'OU' lorsque le paramètre est fourni plus d'une fois
* `vr=<UID>` pour faire correspondre tous les résultats de validation d'une règle de validation. Plusieurs règles utilisent 'OU' lorsque le paramètre est fourni plus d'une fois
* `pe=<ISO-expression>` pour faire correspondre tous les résultats de validation liés à une période qui se superpose à la période spécifiée
* `created=<ISO-expression>` pour faire correspondre tous les résultats de validation créés au cours de la période fournie
* `notificationSent=<boolean>` pour faire correspondre uniquement les résultats de validation pour lesquels une notification a été ou n'a pas été envoyée

Si les filtres sont combinés, toutes les conditions doivent être vraies (AND logic (ET logique)).

Quelques exemples:

Pour supprimer tous les résultats de validation liés à l'unité d'organisation dont l'UID est `NqwvaQC1ni4` pour le premier trimestre (Q1) 2020, utilisez :

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

Pour supprimer tous les résultats de validation créés au cours de la semaine 1 de 2019 et pour lesquels une notification a été envoyée, utilisez :

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

Toute opération de suppression nécessitera l'autorité _Effectuer des tâches de maintenance_.


## Détection des valeurs atypiques { #outlier-detection }

Le point d'extrémité de détection des valeurs atypiques permet de détecter les valeurs atypiques dans les valeurs de données agrégées.

```
GET /api/36/outlierDetection
```

Ce point d'extrémité prend en charge deux algorithmes pour détecter les valeurs atypiques :

* **Z-score :** Le z-score est défini comme l'écart absolu entre le score et la moyenne divisé par l'écart type. Un paramètre de seuil faisant référence au nombre d'écarts types par rapport à la moyenne doit être spécifié avec l'algorithme z-score pour définir les limites supérieure et inférieure de ce qui est considéré comme une valeur atypique.
* **Z-score modifié :** Identique au z-score, à la différence qu'il utilise la médiane au lieu de la moyenne comme mesure de la tendance centrale. Les paramètres sont les mêmes que pour le Z-score.
* **Min-max :** Les valeurs des éléments de données min-max (minimales et maximales) font référence aux limites personnalisées qui peuvent être insérées dans DHIS 2 en fonction de la combinaison d'éléments de données, d'unités d'organisation et d'options de catégorie.

Les valeurs atypiques seront *classées selon leur importance*, par défaut selon l'écart absolu par rapport à la moyenne, avec la valeur la plus importante en premier. Ceci permet d'identifier rapidement les valeurs atypiques qui ont le plus grand impact sur la qualité et l’analyse des données.

### Paramètres de requête{ #request-query-parameters }

Les paramètres de requête suivants sont pris en charge.

| Paramètre de requête | Description                                                  | Obligatoire | Options (par défaut en premier)                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | Ensemble de données, peut être spécifié plusieurs fois.                   | No [*]    | Identifiant de l'ensemble de données.                      |
| de              | Élément de données, peut être spécifié plusieurs fois.               | No [*]    | Identifiant de l'élément de données.                  |
| date de début       | Date en début de l'intervalle pour contrôler les valeurs atypiques.               | Oui       | Date (aaaa-MM-jj).                        |
| date de fin         | Date en fin de l'intervalle pour vérifier les valeurs aberrantes.                 | Oui       | Date (aaaa-MM-jj).                        |
| ou              | Unité d'organisation, peut être spécifiée plusieurs fois.          | Oui       | Identifiant de l’unité d’organisation.             |
| algorithme       | Algorithme à utiliser pour la détection des valeurs atypiques.                      | Non        | `Z_SCORE`, `MIN_MAX`, `MOD_Z_SCORE`       |
| seuil       | Seuil pour les valeurs atypiques. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Numérique, supérieur à zéro. Par défaut : 3.0. |
| Date de début des données   | Date en début de l'intervalle pour le calcul de la moyenne et de l'écart type. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Date (aaaa-MM-jj). |
| Date de fin des données     | Date en fin de l'intervalle pour le calcul de la moyenne et de l'écart type. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Date (aaaa-MM-jj).   |
| orderBy         | Field to order by. `Z_SCORE` and `MOD_Z_SCORE`algorithm only.| Non        | `MEAN_ABS_DEV`, `Z_SCORE`                 |
| Résultats maximum      | Limite maximale pour la sortie.                                    | Non        | Entier, supérieur à zéro. Par défaut : 500. |

[*] Vous devez spécifier soit des ensembles de données avec le paramètre `ds`, qui inclura tous les éléments de données dans les ensembles de données, _ou_ spécifier des éléments de données avec le paramètre `de`.

Au moins un ensemble de données ou élément de données, une date de début et une date de fin, et au moins une unité d'organisation doivent être définis.

Les paramètres `Date de début` et `Date de fin` sont obligatoires et font référence à l'intervalle de temps dans lequel vous voulez détecter les valeurs atypiques. Les paramètres `Date de début des données` et `Date de fin des données` sont facultatifs et font référence à l'intervalle de temps à utiliser pour les données lors du calcul de la moyenne et de l'écart type. Ils sont utilisés pour calculer éventuellement le z-score.

### Utilisation et exemples { #usage-and-examples }

Obtenez les valeurs atypiques à l'aide de l'algorithme z-score par défaut :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
```

Obtenez des valeurs atypiques à l'aide d'un algorithme et d'un seuil spécifiques :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=Z_SCORE&threshold=2.5
```

Obtenez les valeurs atypiques classées par z-score :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &orderBy=Z_SCORE
```

Obtenez les 10 principales valeurs atypiques :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &maxResults=10
```

Obtenez des valeurs atypiques avec un intervalle défini pour les données à utiliser lors du calcul de la moyenne et de l'écart type :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &dataStartDate=2018-01-01&dataEndDate=2020-12-31
```

Obtenez les valeurs atypiques à l'aide de l'algorithme min-max :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=MIN_MAX
```

### Format de réponse { #response-format }

Les formats de réponse suivants sont pris en charge.

| Format | Format API                                                   |
| ------ | ------------------------------------------------------------ |
| JSON   | `/api/36/outlierDetection.json` or `Accept: application/json` (default format) |
| CSV    | `/api/36/outlierDetection.csv` or `Accept: application/csv`  |

La réponse contient les champs suivants :

| Champ      | Description                                                  |
| ---------- | ------------------------------------------------------------ |
| de         | Identifiant de l'élément de données.                                     |
| Nom de l'élément de données     | Nom de l'élément de données.                                           |
| pe         | Identifiant ISO de la période.                                       |
| ou         | Identifiant de l’unité d’organisation.                                |
| ouName     | Nom de l'unité d'organisation.                                      |
| coc        | Identifiant de la combinaison d’options de catégorie.                      |
| cocName    | Nom de la combinaison d’options de catégorie.                            |
| aoc        | Identifiant de la combinaison d’options d’attribut.                     |
| aocName    | Nom de la combinaison d’options d’attribut.                           |
| valeur      | Valeur de données.                                                  |
| moyenne       | Moyenne des valeurs de données dans la dimension de temps.                   |
| stdDev     | Écart-type.                                          |
| absDev     | Pour le z-score, il s'agit de l'écart absolu par rapport à la moyenne. Pour min-max, il s'agit de l'écart absolu par rapport à la limite min ou max. |
| zScore     | Le z-score. Algorithme du z-score uniquement.                         |
| lowerBound | La limite inférieure.                                          |
| upperBound | La limite supérieure.                                          |
| suivi   | Si la valeur de données est marquée pour le suivi.                  |

Les champs de `moyenne`, `écart type` et `z-score` ne sont présents que lorsque l'`algorithme` est `Z_SCORE`.

La réponse ressemblera à ceci. La section `métadonnées` contient des métadonnées de requête et de réponse. La section `Valeurs atypique` contient les valeurs atypiques.

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### Contraintes et validation { #constraints-and-validation }

Les contraintes suivantes s'appliquent lors de la validation de la requête. Chaque erreur de validation a un code d'erreur correspondant.

| Code d'erreur | Message                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | Au moins un élément de données doit être spécifié                  |
| E2201      | La date de début et la date de fin doivent être précisées                    |
| E2202      | La date de début doit être antérieure à la date de fin                           |
| E2203      | Au moins une unité d'organisation doit être spécifiée             |
| E2204      | Le seuil doit être un nombre positif                          |
| E2205      | Les résultats maximum doivent être exprimés en nombres positifs                        |
| E2206      | Le nombre maximum de résultats dépasse la limite autorisée : {d}               |
| E2207      | La date de début des données doit être antérieure à la date de fin des données                 |
| E2208      | Valeurs de données non numériques rencontrées lors de la détection des valeurs atypiques |

## Analyse des données { #webapi_data_analysis }

Plusieurs ressources permettant d'effectuer des analyses de données et de détecter les problèmes de qualité et de validation des données sont fournies.

**Remarque :** Ce point d'extrémité est obsolète et sera supprimé dans la version 2.38. Utilisez plutôt le point d'extrémité  `outlierAnalysis`.

### Analyse des règles de validation { #webapi_data_analysis_validation_rules } 

Pour exécuter des règles de validation et extraire les violations :

    GET /api/dataAnalysis/validationRules

Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'analyse des règles de validation

| Paramètre de requête | Description | Option |
|---|---|---|
| vrg | Groupe de règles de validation | Identifiant |
| ou | Unité d’organisation | Identifiant |
| date de début | Date de début de la période | Date |
| date de fin | Date de fin de la période | Date |
| conserver | S'il faut conserver les violations dans le système | faux &#124; vrai |
| notification | S'il faut envoyer des notifications sur les violations | faux &#124; vrai |

Exemple de sortie :
```json
[{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### Analyse des valeurs atypiques sur la base de l'écart type { #webapi_data_analysis_std_dev_outlier }

Pour identifier les valeurs atypiques parmi les données en fonction des écarts types de la valeur  moyenne :

    GET /api/dataAnalysis/stdDevOutlier

Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'analyse des valeurs atypiques de l'écart type

| Paramètre de requête | Description | Option |
|---|---|---|
| ou | Unité d’organisation | Identifiant |
| date de début | Date de début de la période | Date |
| date de fin | Date de fin de la période | Date |
| ds | Ensembles de données, le paramètre peut être répété | Identifiant |
| écart type | Nombre d'écarts types par rapport à la moyenne | Valeur numérique |

### Analyse des valeurs aberrantes basée sur les valeurs min/max { #webapi_data_analysis_min_max_outlier }

Pour identifier les valeurs atypiques sur la base des valeurs min/max :

    GET /api/dataAnalysis/minMaxOutlier

Les paramètres de requête pris en charge équivalent à la ressource *analyse des valeurs atypiques en fonction de l'écart type* décrite ci-dessus.

### Analyse des données de suivi { #follow-up-data-analysis }

Pour identifier les données marquées pour le suivi :

    GET /api/dataAnalysis/followup

Au moins un ensemble de données ou élément de données, une date ou période de début et de fin, et au moins une unité d'organisation doivent être définis.

Les paramètres de requête suivants sont pris en charge.

| Paramètre  | Description                                                  | Obligatoire | Options (par défaut en premier)                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ou         | Unité d'organisation, peut être spécifiée plusieurs fois.          | Oui       | Identifiant de l’unité d’organisation.             |
| ds         | Ensemble de données, peut être spécifié plusieurs fois.                   | No [*]    | Identifiant de l'ensemble de données.                      |
| de         | Élément de données, peut être spécifié plusieurs fois.               | No [*]    | Identifiant de l'élément de données.                  |
| date de début  | Date en début de l'intervalle pour contrôler les valeurs atypiques.               | No [*]    | Date (aaaa-MM-jj).                        |
| date de fin    | Date en fin de l'intervalle pour vérifier les valeurs aberrantes.                 | No [*]    | Date (aaaa-MM-jj).                        |
| pe         | ID de période ISO.                                               | No [*]    | ID ISO de la période.                        |
| peType     | Période ISO.                                                  | No [*]    | Chaîne ISO de la période.                        |
| coc        | Les combinaisons d’options de catégorie peuvent être spécifiées plusieurs fois.     | Non        | Identifiant de la combinaison d’options de catégorie.         |
| Résultats maximum | Limite maximale pour la sortie.                                    | Non        | Entier, supérieur à zéro. Par défaut : 50.  |

[*] Vous devez spécifier soit des ensembles de données avec le paramètre `ds`, qui intégrera tous les éléments de données dans les ensembles de données, _ou_ spécifier des éléments de données avec le paramètre `de`.
     De même, `Date de début` et `date de fin` _ou_ `période` doivent être spécifiés.

Les paramètres `Date de début` et `Date de fin` font référence à l'intervalle de temps au cours duquel vous voulez détecter les valeurs atypiques.
Si une période `pe` est fournie à la place, le début et la fin de l'intervalle sont également ceux de la période.

Si aucune combinaison d'options `coc` n'est fournie, tous les éléments de données de type valeur numérique seront pris en compte.


## Intégrité des données { #webapi_data_integrity } 

The data integrity capabilities of the data administration module are
available through the web API. This section describes how to run the
data integrity process as well as retrieving the result. The details of
the analysis performed are described in the user manual.

### Running data integrity { #webapi_data_integrity_run } 

The operation of measuring data integrity is a fairly resource (and
time) demanding task. It is therefore run as an asynchronous process and
only when explicitly requested. Starting the task is done by forming an
empty POST request to the *dataIntegrity* endpoint:

    POST /api/dataIntegrity

If successful the request will return HTTP 202 immediately. The location
header of the response points to the resource used to check the status
of the request. The payload also contains a json object of the job
created. Forming a GET request to the given location yields an empty
JSON response if the task has not yet completed and a JSON taskSummary
object when the task is done. Polling (conservatively) to this resource
can hence be used to wait for the task to finish.

### Fetching integrity summary { #webapi_data_integrity_fetch_results } 

Once data integrity is finished running the result can be fetched from
the `system/taskSummaries` resource like so:

    GET /api/system/taskSummaries/DATA_INTEGRITY

The returned object contains a summary for each point of analysis,
listing the names of the relevant integrity violations. As stated in the
leading paragraph for this section the details of the analysis (and the
resulting data) can be found in the user manual chapter on Data
Administration.

## Enregistrements des ensembles de données complets{ #webapi_complete_data_set_registrations }

Cette section traite de l'enregistrement d'ensembles de données complétés en tant qu'ensembles de données. Un enregistrement marque un ensemble de données comme étant complètement capturé.

### Compléter les ensembles de données { #webapi_completing_data_sets }

Cette section explique comment enregistrer des ensembles de données comme étant complets. Cela s'obtient en interagissant avec la ressource *completeDataSetRegistrations*:

    GET /api/33/completeDataSetRegistrations

Le point d'extrémité utilise la méthode *POST* pour enregistrer les ensembles de données complets. De façon pratique, ce point d'extrémité est très similaire à celui de *dataValueSets* (ensembles de valeurs de données), avec la possibilité d'importer des enregistrements complets en bloc.

L'importation de charges utiles au format *XML* et *JSON* est prise en charge. Le format de base de cette charge utile, donné en *XML* dans cet exemple, ressemble à ceci :

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

L'attribut *storedBy* (stocké par) est facultatif (car il peut être retiré de l'objet d'enregistrement complet). Vous pouvez également définir la propriété *date* (heure de l'enregistrement) en tant qu'attribut. Si l'heure n'est pas définie, l'heure actuelle sera utilisée.

Le processus d'importation prend en charge les paramètres de requête suivants :



Tableau : Paramètres de requête d'enregistrement d'ensembles de données complets

| Paramètre | Valeurs | Description |
|---|---|---|
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'ensemble de données permettant de mettre en correspondance les enregistrements complets. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'unité d'organisation permettant de mettre en correspondance les enregistrements complets. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de la combinaison d'options d'attribut permettant de mettre en correspondance les enregistrements complets. |
| idScheme | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de tous les objets, y compris les ensembles de données, les unités d'organisation et les combinaisons d'options d'attribut, qui permettent de mettre en correspondance enregistrements complets. |
| preheatCache | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| dryRun | faux &#124; vrai | Si l'enregistrement s'applique aux sous-unités |
| importStrategy (stratégie d'importation) | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipExistingCheck (ignorer les contrôles existants) | faux &#124; vrai | Ne contrôle pas les enregistrements complets existants. Améliore les performances. À utiliser uniquement pour les bases de données vides ou lorsque les enregistrements à importer n'existent pas encore. |
| async | faux &#124; vrai | Indique si l'importation doit être effectuée de manière asynchrone ou synchrone. La première option (asynchrone) est adapté aux importations très volumineuses car il garantit que la requête n’expire pas, bien qu’il entraîne une surcharge de performances. La deuxième (synchrone) est plus rapide mais nécessite que la connexion soit maintenue jusqu'à la fin du processus. |

Les éléments `idScheme` (schéma de l'identifiant), `dataSetIdScheme`  (schéma de l'identifiant de l'ensemble de données), `orgUnitIdScheme` (schéma de l'identifiant de l'unité d'organisation), `attributeOptionComboIdScheme` (schéma de l'identifiant de la combinaison d'options d'attribut),
`dryRun` (essai) et `strategy` (stratégie) (notez la dénomination différente du paramètre `importStrategy` (stratégie d'importation))
peuvent également être définis dans le cadre de la charge utile.
Avec XML, ce sont des attributs ; avec JSON, ce sont des éléments du nœud `completeDataSetRegistrations` (enregistrements des ensembles de données complets).

Par exemple :
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

Si le paramètre URL et la charge utile définissent un schéma, la charge utile est prioritaire.

### Lecture des enregistrements d'ensembles de données complets { #webapi_reading_complete_data_sets }

Cette section explique comment récupérer les enregistrements d'ensembles de données complets. Nous utiliserons la ressource *completeDataSetRegistrations*. Les paramètres de requête à utiliser sont les suivants :



Tableau : Paramètres de requête d'ensemble de valeurs de données

| Paramètre | Description |
|---|---|
| dataSet (ensemble de données) | Identifiant de l'ensemble de données, plusieurs ensembles de données sont autorisés |
| période | Identifiant de la période au format ISO. Plusieurs périodes sont autorisées. |
| date de début | Date de début de la période des valeurs à exporter |
| date de fin | Date de fin de la période des valeurs à exporter |
| créé | Inclut uniquement les enregistrements créées depuis l'horodatage donné |
| Durée de la création | Inclut uniquement les enregistrements créées pendant la durée indiquée. Le format est <value\><unité-de-temps\>, où les unités de temps prises en charge sont "d", "h", "m", "s " *(jours, heures, minutes, secondes).* L'unité de temps est liée à l'heure actuelle. |
| orgUnit (Unité d'organisation) | Identifiant de l'unité d'organisation ; peut être spécifié plusieurs fois. Non applicable si un groupe d'unités d'organisation est fourni. |
| orgUnitGroup (groupe d'unités d'organisation) | Identifiant du groupe d’unités d’organisation ; peut être spécifié plusieurs fois. Non applicable si une unité d'organisation est fournie. |
| subordonnées | Permet de spécifier s'il faut inclure les unités d’organisation subordonnées dans la hiérarchie des unités d'organisation |
| limite | Le nombre maximum d'enregistrements à inclure dans la réponse. |
| idScheme | Propriété d'identifiant utilisée pour les objets de métadonnées dans la réponse. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | Propriété d'identifiant utilisée pour les ensembles de données dans la réponse. Elle remplace le schéma de l'identifiant. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Propriété d'identifiant utilisée pour les unités d'organisation dans la réponse. Elle remplace le schéma de l'identifiant. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété d'identifiant utilisée pour les combinaisons d'options d'attribut dans la réponse. Elle remplace le schéma de l'identifiant. |
Les paramètres `ensemble de données` et `unité d'organisation` peuvent être répétés afin d'inclure plusieurs ensembles de données et unités d'organisation.

Les paramètres `période`, `date de début`, `date de fin`, `créé` et `durée de création` fournissent plusieurs façons de définir la dimension temporelle de la requête, donc un seul peut être utilisé. Par exemple, cela n'a pas de sens de définir à la fois la date de début/fin et les périodes.

Voici donc un exemple de requête :

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX&dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

Vous pouvez obtenir la réponse au format *xml* et *json*. Vous pouvez indiquer le format de réponse que vous préférez via l'en-tête HTTP *Accepter* comme dans l'exemple ci-dessus. Pour xml, utilisez *application/xml* ; pour json, utilisez *application/json*.

### Annuler la finalisation des ensembles de données { #webapi_uncompleting_data_sets }

Cette section explique comment annuler l'enregistrement de la complétude d'un ensemble de données. Pour annuler la finalisation d'un ensemble de données, vous interagirez avec la ressource completeDataSetRegistrations :

    GET /api/33/completeDataSetRegistrations

Cette ressource prend en charge la fonction *DELETE* pour annuler l'inscription. Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'enregistrement d'ensembles de données complets

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| ds | Oui | Identifiant de l'ensemble de données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| cc | Non (doit combiner avec cp) | Identifiant de la combinaison d'attributs (pour la vérification du verrouillage) |
| cp | Non (doit combiner avec cp) | Identifiants d'options d'attribut, séparés par ; pour plusieurs valeurs (pour le contrôle du verrouillage) |
| multiOu (unités d'organisation multiples) | Non (faux par défaut) | Si l'enregistrement s'applique aux sous-unités |



# Approbation des données { #data-approval } 

## Approbation des données { #webapi_data_approval } 

Cette section explique comment approuver, désapprouver et vérifier le statut 
d'approbation en utilisant la ressource *dataApprovals* (Approbation des données). L'approbation se fait par flux 
de travail d'approbation des données, par période, par unité d'organisation et par combinaison d'options d'attributs.

    /api/33/dataApprovals

Un processus d'approbation des données est associé à plusieurs entités :

* Un type de période qui définit la fréquence d'approbation
* Une combinaison de catégories facultative
* Un ou plusieurs niveaux d'approbation des données qui font partie du flux de travail
* Un ou plusieurs ensembles de données utilisés pour la collecte de données

### Obtenir le statut d'approbation { #webapi_data_approval_get_status } 

Pour obtenir des informations sur l'approbation d'un ensemble de données, vous pouvez envoyer une requête GET :

    /api/dataApprovals?wf=rIUL3hYOjJc&pe=201801&ou=YuQRtpLP10I



Tableau : Paramètres de requête pour l'approbation des données

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| wf | Oui | Identifiant du workflow d'approbation des données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| aoc | Non | Identifiant de combinaison d'options d'attributs |

> **Remarque**
>
> Pour des raisons de compatibilité en amont, le paramètre `ds` pour l'ensemble de données peut être donné à la place de `wf` pour le flux de travail dans cette demande d'approbation de données et dans d'autres, comme décrit ci-dessous. Si l'ensemble de données est donné, le flux de travail associé à cet ensemble de données sera utilisé.

Vous obtiendrez une réponse similaire à celle-ci :

```json
{
  "mayApprove": false,
  "mayUnapprove": false,
  "mayAccept": false,
  "mayUnaccept": false,
  "state": "UNAPPROVED_ELSEWHERE"
}
```

Les paramètres obtenus sont les suivants :



Tableau : Paramètres obtenus pour l'approbation des données

| Paramètre de retour | Description |
|---|---|
| peutApprouver | Si l'utilisateur actuel peut approuver cette sélection de données. |
| peutDésapprouver | Si l'utilisateur actuel peut désapprouver cette sélection de données. |
| peutAccepter | Si l'utilisateur actuel peut accepter cette sélection de données. |
| peutRefuser | Si l'utilisateur actuel peut refuser cette sélection de données. |
| État | L'un des états d'approbation des données est indiqué dans le tableau ci-dessous. |



Tableau : États d'approbation des données

| État | Description |
|---|---|
| NON APPROUVÉ | L'approbation des données ne s'applique pas à cette sélection. (Les données ne sont ni approuvées ni non approuvées). |
| NON APPROUVÉ_EN ATTENTE | Les données pourraient être approuvées pour cette sélection, mais elles attendent une approbation de niveau inférieur avant d'être prêtes à être approuvées. |
| NON APPROUVÉ_AUTRE PART | Les données ne sont pas approuvées et attendent d'être approuvées autre part (elles ne peuvent pas être approuvées ici). |
| NON APPROUVÉ_ PRÊT | Les données ne sont pas approuvées et sont prêtes à être approuvées pour cette sélection. |
| APPROUVÉ_ICI | Les données sont approuvées et ont été approuvées ici (elles pourraient donc être non approuvées ici). |
| APPROUVÉ_AUTRE PART | Les données sont approuvées, mais n'ont pas été approuvées ici (et ne peuvent donc pas être non approuvées ici) : <br>* Les données sont approuvées à un niveau supérieur.<br>* Les données sont approuvées pour un plus grand nombre d'options de catégories. <br>* Les données sont approuvées pour toutes les sous-périodes de la période sélectionnée. <br>Dans les deux premiers cas, il existe un seul objet d'approbation des données qui couvre la sélection. Dans le troisième cas, il n'y en a pas. |
| ACCEPTÉ_ICI | Les données sont approuvées et acceptées ici (elles pourraient donc être non approuvées ici). |
| ACCEPTÉ_AUTRE PART | Les données sont approuvées et acceptées, mais à un autre endroit. |

Notez que lorsque vous demandez l'état de l'approbation des données, vous pouvez spécifier
toute combinaison de paramètres d'interrogation. La combinaison que vous spécifiez
ne doit pas nécessairement décrire l'endroit où les données doivent être approuvées à l'un 
des niveaux d'approbation. Par exemple :

  - L'unité d'organisation peut ne pas être à un niveau d'approbation. Le
    statut d'approbation est déterminé par le fait que les données sont approuvées à un
    niveau d'approbation pour un ascendant de l'unité d'organisation.

  - Vous pouvez spécifier des options de catégories d'attributs individuelles. Le statut
    d'approbation est déterminé par le fait que les données sont approuvées pour une
    combinaison d'options de catégorie d'attributs qui comprend une ou plusieurs de ces
    options.

  - Vous pouvez spécifier une période plus longue que celle de
    l'ensemble de données, au cours de laquelle les données sont saisies et approuvées. Le statut 
    d'approbation est déterminé par l'approbation des données pour toutes les
    périodes de l'ensemble de données au cours de la période spécifiée.

Pour les ensembles de données associés à une combinaison de catégories, il est possible 
de récupérer les enregistrements d'approbation des données pour les combinaisons d'options d'attributs individuels 
à partir de la ressource suivante, au moyen d'une requête GET :

    /api/dataApprovals/categoryOptionCombos?wf=rIUL3hYOjJc&pe=201801&ou=YuQRtpLP10I

### Obtenir le statut d'approbation en bloc { #bulk-get-approval-status } 

Pour obtenir une liste de plusieurs statuts d'approbation, vous pouvez envoyer une requête GET similaire à celle-ci :

    /api/dataApprovals/approvals?wf=rIUL3hYOjJc&pe=201801,201802&ou=YuQRtpLP10I

Les paramètres `wf`, `pe`, `ou`, et `aoc` sont les mêmes que pour obtenir un statut d'approbation unique, sauf que vous pouvez fournir une liste séparée par des virgules d'une ou plusieurs valeurs pour chaque paramètre.

Vous obtiendrez une réponse contenant une liste de paramètres d'approbation et de statuts, comme suit :

```json
[
  {
    "aoc": "HllvX50cXC0",
    "pe": "201801",
    "level": "KaTJLhGmU95",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "mayApprove": false,
      "mayUnapprove": true,
      "mayAccept": true,
      "mayUnaccept": false,
      "mayReadData": true
    },
    "state": "APPROVED_HERE",
    "wf": "rIUL3hYOjJc"
  },
  {
    "aoc": "HllvX50cXC0",
    "pe": "201802",
    "ou": "YuQRtpLP10I",
    "permissions": {
      "mayApprove": true,
      "mayUnapprove": false,
      "mayAccept": false,
      "mayUnaccept": false,
      "mayReadData": true
    },
    "state": "UNAPPROVED_READY",
    "wf": "rIUL3hYOjJc"
  }
]
```

Les champs obtenus sont décrits dans le tableau ci-dessous.

| Champ       | Description |
| ----------- | ----------- |
| aoc         | Identifiant de combinaison d'options d'attributs |
| pe          | Identifiant de période |
| ou          | Identifiant d'unité d'organisation |
| autorisations | The permissions: 'mayApprove', 'mayUnapprove', 'mayAccept', 'mayUnaccept', and 'mayReadData' (same definitions as for get single approval status). |
| État       | Un des états d'approbation des données (comme pour obtenir un statut d'approbation unique.) |
| wf          | Identifiant du workflow d'approbation des données |

### Approuver les données { #webapi_data_approval_approve_data } 

Pour approuver des données, vous pouvez envoyer une demande *POST* à la ressource 
*dataApprovals*. Pour annuler l'approbation des données, vous pouvez envoyer une 
demande *SUPPRIMER* à la ressource dataApprovals.

    POST DELETE /api/33/dataApprovals

Pour accepter des données déjà approuvées, vous pouvez envoyer une demande 
*POSTER* à la ressource *Acceptationdesdonnées*. Pour annuler l'acceptation de données, 
vous pouvez envoyer une demande *SUPPRIMER* à la ressource *Acceptationdesdonnées*.

    POST DELETE /api/33/dataAcceptances

Ces demandes contiennent les paramètres suivants :



Tableau : Paramètres d'action pour l'approbation des données

| Paramètres d'action | Obligatoire | Description |
|---|---|---|
| wf | Oui | Identifiant du workflow d'approbation des données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| aoc | Non | Identifiant de combinaison d'options d'attributs |

Notez que, contrairement à la requête sur le statut d'approbation des données, vous devez 
spécifier des paramètres qui correspondent à une sélection de données susceptibles d'être 
approuvées. En particulier, les deux éléments suivants doivent être vrais :

  - Le niveau de l'unité d'organisation doit être spécifié par un niveau d'approbation 
    dans le flux de travail.

  - La période spécifiée doit correspondre au type de période du 
    flux de travail.

### Approuver les données en bloc { #webapi_data_approval_bulk_approve_data } 

Vous pouvez approuver un ensemble d'enregistrements de données en postant dans 
la ressource `/api/dataApprovals/approvals`.

    POST /api/33/dataApprovals/approvals

Vous pouvez approuver un bloc d'enregistrements de données en postant dans 
la ressource `/api/dataApprovals/approvals`.

    POST /api/33/dataApprovals/unapprovals

Vous pouvez accepter un grand nombre d'enregistrements en envoyant un message à la ressource
`/api/dataAcceptances/acceptances`.

    POST /api/33/dataAcceptances/acceptances

Vous pouvez refuser un bloc d'enregistrements en envoyant un message à la ressource
`/api/dataAcceptances/acceptances`.

    POST /api/33/dataAcceptances/unacceptances

La charge utile d'approbation est prise en charge en tant que JSON et ressemble à ceci :

```json
{
  "wf": [
    "pBOMPrpg1QX", "lyLU2wR22tC"
  ],
  "pe": [
    "201601", "201602"
  ],
  "approvals": [
    {
      "ou": "cDw53Ej8rju",
      "aoc": "ranftQIH5M9"
    },
    {
      "ou": "cDw53Ej8rju",
      "aoc": "fC3z1lcAW5x"
    }
  ]
}
```

### Obtenir les niveaux d'approbation des données { #get-data-approval-levels } 

Pour récupérer les flux de travail d'approbation des données et leurs niveaux d'approbation, 
vous pouvez effectuer une requête GET similaire à celle-ci :

/api/dataApprovalWorkflows ?
champs=identifiant, nom, type de période, niveau d'approbation des données [identifiant, nom, niveau, niveau de l'unité d'organisation]


### Responsables de l'approbation des données { #authorities-for-data-approval } 

- `F_FLUX DE TRAVAIL_ DE L' APPROBATION_DES DONNÉES` : permet à l'utilisateur d'ajouter/mettre à jour le flux de travail relatif à l'approbation des données.
-  `F_NIVEAU_D'APPROBATION DES_DONNÉES` : permet à l'utilisateur d'ajouter/mettre à jour le niveau d'approbation des données.


# Partage { #sharing } 

## Partage { #webapi_sharing } 

La solution de partage vous permet de partager la plupart des objets du système avec 
des groupes d'utilisateurs spécifiques et de définir si les objets doivent être accessibles 
au public ou privés. Pour obtenir et définir le statut de partage des objets, vous pouvez 
interagir avec la ressource de *partage*.

    /api/33/sharing

### Obtenir le statut de partage { #webapi_get_sharing_status } 

Pour demander le statut de partage d'un objet, faites une requête GET à :

    /api/33/sharing?type=dataElement&id=fbfJHSPpUQD

La réponse se présente comme suit.

```json
{
  "meta": {
    "autoriserl'accèspublic": vrai,
    "autoriserl'accèsexterne": faux
  },
  "objet": {
    "id": "fbfJHSPpUQD",
    "nom": "CPN 1ère visite",
    "accèspublic": "rw------",
    "accèsexterne": faux,
    "utilisateur": {},
    "accès au groupe d'utilisateurs": [
      {
        "id": "hj0nnsVsPLU",
        "accès": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "accès": "r-------"
      }
    ]
  }
}
```

### Définir le statut de partage { #webapi_set_sharing_status } 

Vous pouvez définir le statut de partage d'un objet en utilisant la même URL avec 
une requête POST, où la charge utile au format JSON ressemble à ceci :

```json
{
  "objet": {
    "accèspublic": "rw------",
    "accèsexterne": faux,
    "utilisateur": {},
    "accès au groupe d'utilisateurs": [
      {
        "id": "hj0nnsVsPLU",
        "accès": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "accès": "r-------"
      }
    ]
  }
}
```

Dans cet exemple, la charge utile définit l'objet comme ayant un accès public en lecture et 
en modification, aucun accès externe (sans connexion), un accès en lecture et en modification à 
un groupe d'utilisateurs et un accès en lecture uniquement à un autre groupe d'utilisateurs. Vous pouvez 
soumettre ceci à la ressource de partage en utilisant curl :

```bash
curl -d @sharing.json "localhost/api/33/sharing?type=dataElement&id=fbfJHSPpUQD"
  -H "Content-Type:application/json" -u admin:district
```
**Remarque**
> Il est possible de créer des combinaisons de partage surprenantes. Par
> exemple, si `accèsexterne` est défini à `vrai` mais que `accèspublic` est
> défini à `--------`, les utilisateurs n'auront accès à l'objet 
> que lorsqu'ils seront déconnectés.




## Nouvel objet de partage { #new-sharing-object } 
Depuis la version 2.36, une nouvelle propriété `partage` a été introduite afin de remplacer les anciennes propriétés de partage `accès utilisateur`, `accès groupe utilisateur`, `accès public`, `accès externe` dans toutes les classes de métadonnées pour lesquelles le partage est activé. Cet objet `Partage` est sauvegardé en tant que colonne JSONB dans la base de données. 
Cependant, afin de rendre le système compatible avec les anciennes versions, les anciens objets de partage continuent de fonctionner normalement, à la fois pour l'importation et l'exportation. Dans le backend, les données de partage seront sauvegardées dans la nouvelle colonne JSONb `Partage` au lieu des anciennes tables `*Accès`.

Le format est le suivant :
```json
{
  "nom": "CPN 1ère visite",
  "accès public": "rw------",
  "accès externe": faux,
  "accès aux groupes d'utilisateurs": [
      {
          "accès": "r-r-----",
          "groupe d'utilisateur Uid": "Rg8wusV7QYi",
          "nom d'affichage": "Coordinateurs du programme VIH",
          "id": "Rg8wusV7QYi"
      }
  ],
  "accès utilisateur": [],
  "utilisateur": {
      "nom d'affichage": "Tom Wakiki",
      "nom": "Tom Wakiki",
      "id": "GOLswS44mh8",
      "Nom d'utilisateur": "système"
  },
  "partage": {
      "propriétaire": "GOLswS44mh8",
      "externe": faux,
      "utilisateurs": {},
      "groupes d'utilisateurs": {
          "Rg8wusV7QYi": {
              "accès": "r-r-----",
              "id": "Rg8wusV7QYi"
          }
      },
      "public": "rw------"
  }
}
```

### Définir le statut de partage en utilisant la nouvelle Api JSON Patch { #webapi_set_sharing_status_using_json_patch_api } 
Vous pouvez utiliser [JSON Patch API](#webapi_partial_updates) pour mettre à jour le partage d'un objet en envoyant une requête `PATCH` à ce point de terminaison avec l'en-tête `Type de contenu : application/json-patch+json`
```
api/dataElements/fbfJHSPpUQD
```
Veuillez noter que cette fonction ***supporte uniquement*** le nouveau format `partage`. La charge utile au format JSON ressemble à ceci :
```json
[
  {
    "op": "remplacer",
    "chemin d'accès": "/partage/utilisateurs",
    "valeur": {
      "NOOF56dveaZ": {
        "accès": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "accès": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
Vous pouvez ajouter des utilisateurs à la propriété `partage` d'un objet comme suit
```json
[
  {
    "op": "ajouter",
    "chemin d'accès": "/partage/utilisateurs",
    "valeur": {
      "NOOF56dveaZ": {
        "accès": "rw------",
        "id": "NOOF56dveaZ"
      },
      "Kh68cDMwZsg": {
        "accès": "rw------",
        "id": "Kh68cDMwZsg"
      }
    }
  }
]
```
Vous pouvez ajouter un utilisateur à `partage` comme ceci
```json
[
  {
    "op": "ajouter",
    "chemin d'accès": "/partage/utilisateurs/NOOF56dveaZ",
    "valeur": {
      "accès": "rw------",
      "id": "NOOF56dveaZ"
    }
  }
]
```
Vous pouvez supprimer un utilisateur de `partage` comme suit
```json
[
  { 
    "op": "remove", 
    "path": "/sharing/users/N3PZBUlN8vq"
    }
]
```

## Partage en cascade du tableau de bord { #cascade-sharing-for-dashboard } 

### Aperçu { #overview } 

- The sharing solution supports cascade sharing for Dashboard. 
- This function will copy `userAccesses` and `userGroupAccesses` of a Dashboard to all of its DashboardItem's objects including `Map`, `EventReport`, `EventChart`, `Visualization`. 
- This function will ***NOT*** copy `METADATA_WRITE` access. The copied `UserAccess` and `UserGroupAccess` will **only** have `METADATA_READ` permission. 
- The `publicAccess` setting is currently ***NOT*** handled by this function. Means the `publicAccess` of the current `Dashboard` will not be copied to its `DashboardItems`'s objects.
- If target object has `publicAccess` enabled, then it will be ignored by this function. Means that no `UserAccesses` or `UserGroupAccesses` will be copied from `Dashboard`.
- Current `User` is required to have `METADATA_READ` sharing permission to all target objects, otherwise error `E5001` will be thrown. And to update target objects, `METADATA_WRITE` is required, otherwise error `E3001` will be thrown.
- Sample use case:

    - DashboardA is shared to userA with `METADATA_READ_WRITE` permission.

    - Le tableau de bord A a une visualisation A qui a un élément de données A.

    - VisualizationA, DataElementA have `publicAccess`  *disabled* and are *not shared* to userA.

    - Après avoir exécuté le partage en cascade pour le tableau de Bord A, l'utilisateur A aura un accès `LECTURE_DE METADONNEES` à la Visualisation A et à l'Élément de Données A.

### Point de terminaison de l'API  { #api-endpoint } 

- Envoyer une requête `POST` au point de terminaison 
```
api/dashboards/cascadeSharing/{dashboardUID}
```


### Paramètres de l'API { #api-parameters } 

| Nom | Par défaut | Description |
| --- | --- | -- |
| dryRun | faux | Si ce paramètre est fixé à `vrai`, la fonction de partage en cascade sera exécutée sans mettre à jour aucun objet. </br>La réponse comprendra les erreurs éventuelles et tous les objets qui seront mis à jour. </br>Cela permet à l'utilisateur de connaître le résultat avant d'exécuter la fonction de partage en cascade.
| atomic | faux | Si ce paramètre est fixé à `vrai`, alors la fonction de partage en cascade s'arrêtera et ne mettra à jour aucun objet s'il y a une erreur. </br>Sinon, si cette valeur est ` fausse `, la fonction essaiera de procéder avec le mode du best effort (meilleur effort).

Exemple de réponse : 

```json
{
  "rapports d'erreur": [
    {
      "message": "Pas d'objet correspondant à la référence. L'identificateur était s46m5MS0hxu, et l'objet était l'élément de données .",
      "mainKlass": "org.hisp.dhis.dataelement.DataElement",
      "code d'erreur": "E5001",
      "Propriétés de l'erreur": [
        "s46m5MS0hxu",
        "élément de données "
      ]
    }
  ],
  "countUpdatedDashBoardItems": 1,
  "mettre à jour les objets": {
    "élément de données ": [
      {
        "id": "YtbsuPPo010",
        "nom": "Dose de rougeole administrée"
      },
      {
        "id": "l6byfWFUGaP",
        "nom": "Doses de fièvre jaune administrées"
      }
    ]
  }
}
```

### Propriétés de la réponse : { #response-properties } 

- `Rapports d'erreurs` : inclut toutes les erreurs survenues au cours du processus de partage en cascade.
- `countUpdatedDashBoardItems` : Nombre `d'éléments du tableau de bord` qui seront ou ont été mis à jour, en fonction du mode `dryRun`.
- `updateObjects` (Mise à jour des objets): Liste de tous les objets qui seront ou ont été mis à jour en fonction du mode `dryRun`.


# Programmation { #webapi_scheduling } 

DHIS2 allows for scheduling of jobs of various types. Each type of job has different properties for configuration, giving you finer control over how jobs are run. In addition, you can configure the same job to run with different configurations and at different intervals if required.



Table: Main properties

| Propriété | Description | Type |
|---|---|---|
| nom | Name of the job. | Chaîne |
| cronExpression | The cron expression which defines the interval for when the job should run. | String (Cron expression) |
| jobType | The job type represent which task is run. In the next table, you can get an overview of existing job types. Each job type can have a specific set of parameters for job configuration. | String (Enum) |
| jobParameters | Job parameters, if applicable for job type. | (See list of job types) |
| enabled | A job can be added to the system without it being scheduled by setting `enabled` to false in the JSON payload. Use this if you want to temporarily stop scheduling for a job, or if a job configuration is not complete yet. | Booléen |



Table: Available job types

| Job type | Paramètres | Param(Type:Default) |
|---|---|---|
| DATA_INTEGRITY | AUCUNE ||
| ANALYTICS_TABLE | * lastYears: Number of years back to include<br> * skipTableTypes: Skip generation of tables<br>Possible values: DATA_VALUE, COMPLETENESS, COMPLETENESS_TARGET, ORG_UNIT_TARGET, EVENT, ENROLLMENT, VALIDATION_RESULT<br> * skipResourceTables: Skip generation of resource tables | * lastYears (int:0)<br> * skipTableTypes (Array of String (Enum):None )<br> * skipResourceTables (Boolean) |
| CONTINUOUS_ANALYTICS_TABLE | * fullUpdateHourOfDay: Hour of day for full update of analytics tables (0-23)<br> * lastYears: Number of years back to include<br> * skipTableTypes: Skip generation of tables<br>Possible values: DATA_VALUE, COMPLETENESS, COMPLETENESS_TARGET, ORG_UNIT_TARGET, EVENT, ENROLLMENT, VALIDATION_RESULT<br> * skipResourceTables: Skip generation of resource tables | * lastYears (int:0)<br> * skipTableTypes (Array of String (Enum):None )<br> * skipResourceTables (Boolean) |
| DATA_SYNC | AUCUNE ||
| META_DATA_SYNC | AUCUNE ||
| SEND_SCHEDULED_MESSAGE | AUCUNE ||
| PROGRAM_NOTIFICATIONS | AUCUNE ||
| MONITORING (Validation rule analysis) | * relativeStart: A number related to date of execution which resembles the start of the period to monitor<br> * relativeEnd: A number related to date of execution which resembles the end of the period to monitor<br> * validationRuleGroups: Validation rule groups(UIDs) to include in job<br> * sendNotification: Set "true" if job should send notifications based on validation rule groups<br> * persistsResults: Set "true" if job should persist validation results | * relativeStart (int:0)<br> * relativeEnd (int:0)<br> * validationRuleGroups (Array of String (UIDs):None )<br> * sendNotification (Boolean:false)<br> * persistsResults (Boolean:false) |
| PUSH_ANALYSIS | * pushAnalysis: The uid of the push analysis you want to run | * pushAnalysis (String:None) |
| PREDICTOR | * relativeStart: A number related to date of execution which resembles the start of the period to monitor<br> * relativeEnd: A number related to date of execution which resembles the start of the period to monitor<br> * predictors: Predictors(UIDs) to include in job | * relativeStart (int:0)<br> * relativeEnd (int:0)<br> * predictors (Array of String (UIDs):None ) |

### Get available job types { #get-available-job-types } 

To get a list of all available job types you can use the following endpoint:

    GET /api/jobConfigurations/jobTypes

The response contains information about each job type including name, job type, key, scheduling type and available parameters. The scheduling type can either be `CRON`, meaning jobs can be scheduled using a cron expression with the `cronExpression` field, or `FIXED_DELAY`, meaning jobs can be scheduled to run with a fixed delay in between with the `delay` field. The field delay is given in seconds.

A response will look similar to this:

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

### Create job { #create-job } 

To configure jobs you can do a POST request to the following resource:

    /api/jobConfigurations

A job without parameters in JSON format looks like this :

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

An example of an analytics table job with parameters in JSON format:

```json
{
  "name": "Analytics tables last two years",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * * ? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

As example of a push analysis job with parameters in JSON format:

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

An example of a job with scheduling type `FIXED_DELAY` and 120 seconds delay:

```json
{
  "name": "Continuous analytics table",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "delay": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
```

### Get jobs { #get-jobs } 

List all job configurations:

    GET /api/jobConfigurations

Retrieve a job:

    GET /api/jobConfigurations/{id}

The response payload looks like this:

```json
{
  "lastUpdated": "2018-02-22T15:15:34.067",
  "id": "KBcP6Qw37gT",
  "href": "http://localhost:8080/api/jobConfigurations/KBcP6Qw37gT",
  "created": "2018-02-22T15:15:34.067",
  "name": "analytics last two years",
  "jobStatus": "SCHEDULED",
  "displayName": "analytics last two years",
  "enabled": true,
  "externalAccess": false,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "2018-02-26T03:00:00.000",
  "cronExpression": "0 0 3 ? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorite": false,
  "configurable": true,
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "manage": true
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favorites": [],
  "translations": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
```

### Update job { #update-job } 

Update a job with parameters using the following endpoint and JSON payload format:

    PUT /api/jobConfiguration/{id}

```json
{
  "name": "analytics last two years",
  "enabled": true,
  "cronExpression": "0 0 3 ? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

### Delete job { #delete-job } 

Delete a job using:

    DELETE /api/jobConfiguration/{id}

Note that some jobs with custom configuration parameters may not be added if the
required system settings are not configured. An example of this is data
synchronization, which requires remote server configuration.

## Synchronization { #webapi_synchronization } 

This section covers pull and push of data and metadata.

### Data value push { #webapi_sync_data_push } 

To initiate a data value push to a remote server one must first configure the
URL and credentials for the relevant server from System settings >
Synchronization, then make a POST request to the following resource:

    /api/33/synchronization/dataPush

### Metadata pull { #webapi_sync_metadata_pull } 

To initiate a metadata pull from a remote JSON document you can make a
POST request with a *url* as request payload to the following resource:

    /api/33/synchronization/metadataPull

### Availability check { #webapi_sync_availability_check } 

To check the availability of the remote data server and verify user
credentials you can make a GET request to the following resource:

    /api/33/synchronization/availability


# Audit { #audit }

## Auditing { #webapi_auditing } 

DHIS2 does automatic auditing on all updates and deletions of aggregate
data values, tracked entity data values, tracked entity attribute
values, and data approvals. This section explains how to fetch this
data.

### Aggregate data value audits { #webapi_auditing_aggregate_audits } 

The endpoint for aggregate data value audits is located at
`/api/audits/dataValue`, and the available parameters are displayed in
the table below.



Table: Aggregate data value query parameters

| Paramètre | Option | Description |
|---|---|---|
| ds | Ensemble de données | One or more data set identifiers to get data elements from. |
| de | Élément de données | One or more data element identifiers. |
| pe | ISO Period | One or more period ISO identifiers. |
| ou | Unité d'organisation | One or more org unit identifiers. |
| auditType | UPDATE &#124; DELETE | Filter by audit type. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show |

Get all audits for data set with ID *lyLU2wR22tC*:

    /api/33/audits/dataValue?ds=lyLU2wR22tC

### Tracked entity data value audits { #webapi_tracked_entity_data_value_audits } 

The endpoint for tracked entity data value audits is located at
`/api/audits/trackedEntityDataValue`, and the available parameters are
displayed in the table below.



Table: Tracked entity data value query parameters

| Paramètre | Option | Description |
|---|---|---|
| de | Élément de données | One or more data element identifiers. |
| ps | Program Stage Entity | One or more program stage instance identifiers. |
| auditType | UPDATE &#124; DELETE | Filter by audit type. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show |

Get all audits which have data element ID eMyVanycQSC or qrur9Dvnyt5:

    /api/33/audits/trackedEntityDataValue?de=eMyVanycQSC&de=qrur9Dvnyt5

### Tracked entity attribute value audits { #webapi_tracked_entity_attribute_value_audits } 

The endpoint for tracked entity attribute value audits is located at
`/api/audits/trackedEntityAttributeValue`, and the available parameters
are displayed in the table below.



Table: Tracked entity attribute value query parameters

| Paramètre | Option | Description |
|---|---|---|
| tea | Tracked Entity Attributes | One or more tracked entity attribute identifiers. |
| te | Tracked Entity Instances | One or more tracked entity instance identifiers. |
| auditType | UPDATE &#124; DELETE | Filter by audit type. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show |

Get all audits which have attribute with ID VqEFza8wbwA:

    /api/33/audits/trackedEntityAttributeValue?tea=VqEFza8wbwA

### Tracked entity instance audits { #webapi_tracked_entity_instance_audits } 

Once auditing is enabled for tracked entity instances (by setting
allowAuditLog of tracked entity types to true), all read and search
operations are logged. The endpoint for accessing audit logs is
api/audits/trackedEntityInstance. Below are available parameters to
interact with this endpoint.



Table: Tracked entity instance audit query parameters

| Paramètre | Option | Description |
|---|---|---|
| tei | Instance d'entité suivie | One or more tracked entity instance identifiers |
| user | Utilisateur | One or more user identifiers |
| auditType | SEARCH &#124; READ | Audit type to filter for |
| date de début | Start date | Start date for audit filtering in yyyy-mm-dd format. |
| date de fin | End date | End date for audit filtering in yyyy-mm-dd format. |
| skipPaging | faux &#124; vrai | Turn paging on / off. |
| page | 1 (default) | Specific page to ask for. |
| taille de la page | 50 (default) | Page size. |

Get all tracked entity instance audits of type READ with
startDate=2018-03-01 and endDate=2018-04-24 in a page size of 5:

    /api/33/audits/trackedEntityInstance.json?startDate=2018-03-01
      &endDate=2018-04-24&auditType=READ&pageSize=5

### Enrollment audits { #webapi_enrollment_audits } 

Once auditing is enabled for enrollments (by setting allowAuditLog of
tracker programs to true), all read operations are logged. The
endpoint for accessing audit logs is api/audits/enrollment. Below are
available parameters to interact with this endpoint.



Table: Enrollment audit query parameters

| Paramètre | Option | Description |
|---|---|---|
| en | Inscription | One or more tracked entity instance identifiers |
| user | Utilisateur | One or more user identifiers |
| date de début | Start date | Start date for audit filtering in yyyy-mm-dd format. |
| date de fin | End date | End date for audit filtering in yyyy-mm-dd format. |
| skipPaging | faux &#124; vrai | Turn paging on / off. |
| page | 1 (default) | Specific page to ask for. |
| taille de la page | 50 (default) | Page size. |

Get all enrollment audits with startDate=2018-03-01 and
endDate=2018-04-24 in a page size of 5:

    /api/audits/enrollment.json?startDate=2018-03-01&endDate=2018-04-24&pageSize=5

Get all enrollment audits for user admin:

    /api/audits/enrollment.json?user=admin

### Data approval audits { #data-approval-audits } 

The endpoint for data approval audits is located at
/api/audits/dataApproval, and the available parameters are displayed in
the table below.



Tableau : Paramètres de requête pour l'approbation des données

| Paramètre | Option | Description |
|---|---|---|
| dal | Data Approval Level | One or more data approval level identifiers. |
| wf | Déroulement | One or more data approval workflow identifiers. |
| ou | Unité d'organisation | One or more organisation unit identifiers. |
| aoc | Attribute Option Combo | One or more attribute option combination identifiers. |
| date de début | Start Date | Starting Date for approvals in yyyy-mm-dd format. |
| date de fin | End Date | Ending Date for approvals in yyyy-mm-dd format. |
| skipPaging | faux &#124; vrai | Turn paging on / off |
| page | 1 (default) | If paging is enabled, this parameter decides which page to show. |

Get all audits for data approval workflow RwNpkAM7Hw7:

    /api/33/audits/dataApproval?wf=RwNpkAM7Hw7




# Messagerie { #messaging } 

## Message conversations { #webapi_message_conversations } 

DHIS2 features a mechanism for sending messages for purposes such as
user feedback, notifications, and general information to users. Messages
are grouped into conversations. To interact with message conversations
you can send POST and GET request to the *messageConversations*
resource.

    /api/33/messageConversations

Messages are delivered to the DHIS2 message inbox but can also be sent
to the user's email addresses and mobile phones as SMS. In this example,
we will see how we can utilize the Web API to send, read and manage
messages. We will pretend to be the *DHIS2 Administrator* user and send
a message to the *Mobile* user. We will then pretend to be the mobile
user and read our new message. Following this, we will manage the admin
user inbox by marking and removing messages.

### Writing and reading messages { #webapi_writing_messages } 

The resource we need to interact with when sending and reading messages
is the *messageConversations* resource. We start by visiting the Web API
entry point at <http://play.dhis2.org/demo/api> where we find and follow
the link to the *messageConversations* resource at
<http://play.dhis2.org/demo/api/messageConversations>. The description
tells us that we can use a POST request to create a new message using
the following XML format for sending to multiple users:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <users>
    <user id="user1ID" />
    <user id="user2ID" />
    <user id="user3ID" />
  </users>
</message>
```

For sending to all users contained in one or more user groups, we can
use:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <userGroups>
    <userGroup id="userGroup1ID" />
    <userGroup id="userGroup2ID" />
    <userGroup id="userGroup3ID" />
  </userGroups>
</message>
```

For sending to all users connected to one or more organisation units, we
can use:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>This is the subject</subject>
  <text>This is the text</text>
  <organisationUnits>
    <organisationUnit id="ou1ID" />
    <organisationUnit id="ou2ID" />
    <organisationUnit id="ou3ID" />
  </organisationUnits>
</message>
```

Since we want to send a message to our friend the mobile user we need to
look up her identifier. We do so by going to the Web API entry point and
follow the link to the *users* resource at `/api/users`. We continue by
following link to the mobile user at `/api/users/PhzytPW3g2J` where we learn
that her identifier is *PhzytPW3g2J*. We are now ready to put our XML
message together to form a message where we want to ask the mobile user
whether she has reported data for January 2014:

```xml
<message xmlns="http://dhis2.org/schema/dxf/2.0">
  <subject>Mortality data reporting</subject>
  <text>Have you reported data for the Mortality data set for January 2014?</text>
  <users>
    <user id="PhzytPW3g2J" />
  </users>
</message>
```

To test this we save the XML content into a file called *message.xml*.
We use cURL to dispatch the message the DHIS2 demo instance where we
indicate that the content-type is XML and authenticate as the *admin*
user:

```bash
curl -d @message.xml "https://play.dhis2.org/demo/api/messageConversations"
  -H "Content-Type:application/xml" -u admin:district -X POST
```

A corresponding payload in JSON and POST command looks like this:

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}
```

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Content-Type:application/json" -u admin:district -X POST
```

If all is well we receive a *201 Created* HTTP status code. Also, note
that we receive a *Location* HTTP header which value informs us of the
URL of the newly created message conversation resource - this can be
used by a consumer to perform further action.

We will now pretend to be the mobile user and read the message which was
just sent by dispatching a GET request to the *messageConversations*
resource. We supply an *Accept* header with *application/xml* as the
value to indicate that we are interested in the XML resource
representation and we authenticate as the *mobile* user:

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations"
  -H "Accept:application/xml" -u mobile:district
```

In response we get the following XML:

```xml
<messageConversations xmlns="http://dhis2.org/schema/dxf/2.0"
  link="https://play.dhis2.org/demo/api/messageConversations">
  <messageConversation name="Mortality data reporting" id="ZjHHSjyyeJ2"
    link="https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"/>
  <messageConversation name="DHIS2 version 2.7 is deployed" id="GDBqVfkmnp2"
    link="https://play.dhis2.org/demo/api/messageConversations/GDBqVfkmnp2"/>
</messageConversations>
```

From the response, we are able to read the identifier of the newly sent
message which is *ZjHHSjyyeJ2*. Note that the link to the specific
resource is embedded and can be followed in order to read the full
message. We can reply directly to an existing message conversation once we know
the URL by including the message text as the request payload. We
are now able to construct a URL for sending our reply:

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/messageConversations/ZjHHSjyyeJ2"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

If all went according to plan you will receive a *200 OK* status code.

In 2.30 we added an URL search parameter:

    queryString=?&queryOperator=?

The filter searches for matches in subject, text, and senders for message
conversations. The default query operator is *token*, however other operators
can be defined in the query.

### Managing messages { #webapi_managing_messages } 

As users receive and send messages, conversations will start to pile up
in their inboxes, eventually becoming laborious to track. We will now
have a look at managing a user's messages inbox by removing and marking
conversations through the Web-API. We will do so by performing some
maintenance in the inbox of the "DHIS Administrator" user.

First, let's have a look at removing a few messages from the inbox. Be
sure to note that all removal operations described here only remove the
relation between a user and a message conversation. In practical terms
this means that we are not deleting the messages themselves (or any
content for that matter) but are simply removing the message thread from
the user such that it is no longer listed in the
`/api/messageConversations` resource.

To remove a message conversation from a users inbox we need to issue a
*DELETE* request to the resource identified by the id of the message
conversation and the participating user. For example, to remove the user
with id `xE7jOejl9FI` from the conversation with id `jMe43trzrdi`:

```bash
curl "https://play.dhis2.org/demo/api/33/messageConversations/jMe43trzrdi
```

If the request was successful the server will reply with a *200 OK*. The
response body contains an XML or JSON object (according to the accept
header of the request) containing the id of the removed user.

```json
{
  "removed" : ["xE7jOejl9FI"]
}
```

On failure the returned object will contain a message payload which
describes the error.

```json
{
  "message" : "No user with uid: dMV6G0tPAEa"
}
```

The observant reader will already have noticed that the object returned
on success in our example is actually a list of ids (containing a single
entry). This is due to the endpoint also supporting batch removals. The
request is made to the same *messageConversations* resource but follows
slightly different semantics. For batch operations, the conversation ids
are given as query string parameters. The following example removes two
separate message conversations for the current user:

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm"
  -X DELETE -u admin:district
```

If you have sufficient permissions, conversations can be removed on
behalf of another user by giving an optional user id parameter.

```bash
curl "https://play.dhis2.org/demo/api/messageConversations?mc=WzMRrCosqc0&mc=lxCjiigqrJm&user=PhzytPW3g2J"
  -X DELETE -u admin:district
```

As indicated, batch removals will return the same message format as for
single operations. The list of removed objects will reflect successful
removals performed. Partially erroneous requests (i.e. non-existing id)
will therefore not cancel the entire batch operation.

Messages carry a boolean *read* property. This allows tracking whether a
user has seen (opened) a message or not. In a typical application
scenario (e.g. the DHIS2 web portal) a message will be marked read as
soon as the user opens it for the first time. However, users might want
to manage the read or unread status of their messages in order to keep
track of certain conversations.

Marking messages read or unread follows similar semantics as batch
removals, and also supports batch operations. To mark messages as read
we issue a *POST* to the `messageConversations/read` resource with a
request body containing one or more message ids. To mark messages as
unread we issue an identical request to the `messageConversations/unread`
resource. As is the case for removals, an optional *user* request parameter
can be given.

Let's mark a couple of messages as read by the current user:

```bash
curl "https://play.dhis2.org/dev/api/messageConversations/read"
  -d '["ZrKML5WiyFm","Gc03smoTm6q"]' -X POST
  -H "Content-Type: application/json" -u admin:district
```

The response is a *200 OK* with the following JSON body:

```json
{
  "markedRead": ["ZrKML5WiyFm", "Gc03smoTm6q"]
}
```

You can add recipients to an existing message conversation. The resource is located at:

    /api/33/messageConversations/id/recipients

The options for this resource is a list of users, user groups and
organisation units. The request should look like this:

```json
{
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ]
}

```

### Message Attachments { #webapi_message_attachments } 

Creating messages with attachments is done in two steps: uploading the
file to the *attachments* resource, and then including one or several of
the attachment IDs when creating a new message.

A POST request to the *attachments* resource will upload the file to the
server.

```
curl -F file=@attachment.png "https://play.dhis2.org/demo/api/messageConversations/attachments"
  -u admin:district
```

The request returns an object that represents the attachment. The id of
this object must be used when creating a message in order to link the
attachment with the message.

```json
{
  "created": "2018-07-20T16:54:18.210",
  "lastUpdated": "2018-07-20T16:54:18.212",
  "externalAccess": false,
  "publicAccess": "--------",
  "user": {
    "name": "John Traore",
    "created": "2013-04-18T17:15:08.407",
    "lastUpdated": "2018-03-09T23:06:54.512",
    "externalAccess": false,
    "displayName": "John Traore",
    "favorite": false,
    "id": "xE7jOejl9FI"
  },
  "lastUpdatedBy": {
    "id": "xE7jOejl9FI",
    "name": "John Traore"
  },
  "favorite": false,
  "id": "fTpI4GOmujz"
}
```

When creating a new message, the ids can be passed in the request body
to link the uploaded files to the message being created.

```json
{
  "subject": "Hey",
  "text": "How are you?",
  "users": [
    {
      "id": "OYLGMiazHtW"
    },
    {
      "id": "N3PZBUlN8vq"
    }
  ],
  "userGroups": [
    {
      "id": "ZoHNWQajIoe"
    }
  ],
  "organisationUnits": [
    {
      "id": "DiszpKrYNg8"
    }
  ],
  "attachments": [
    "fTpI4GOmujz",
    "h2ZsOxMFMfq"
  ]
}
```

When replying to a message, the ids can be passed as a request
parameter.

```bash
curl -d "Yes the Mortality data set has been reported"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?attachments=fTpI4GOmujz,h2ZsOxMFMfq"
  -H "Content-Type:text/plain" -u mobile:district -X POST
```

Once a message with an attachment has been created, the attached file
can be accessed with a GET request to the following URL:

    /api/messageConversations/<mcv-id>/<msg-id>/attachments/<attachment-id>

Where <mcv-id> is the *message conversation* ID, <msg-id> is the ID of
the *message* that contains the attachment and <attachment-id> is the
ID of the specific *message attachment*.

### Tickets and Validation Result Notifications { #webapi_messaging_tickets } 

You can use the "write feedback" tool to create tickets and messages.
The only difference between a ticket and a message is that you can give
a status and a priority to a ticket. To set the status:

    POST /api/messageConversations/<uid>/status

To set the priority:

    POST /api/messageConversations/<uid>/priority

In 2.29, messages generated by validation analysis now also be used in
the status and priority properties. By default, messages generated by
validation analysis will inherit the priority of the validation rule in
question, or the highest importance if the message contains multiple
rules.

In 2.30, validation rules can be assigned to any user while tickets
still need to be assigned to a user in the system's feedback recipient
group.



Table: A list of valid status and priority values

| Statut | Priority |
|---|---|
| OPEN | LOW |
| PENDING | MEDIUM |
| INVALID | HIGH |
| SOLVED ||

You can also add an internal message to a ticket, which can only be seen
by users who have "Manage tickets" permissions. To create an internal
reply, include the "internal" parameter, and set it to

```bash
curl -d "This is an internal message"
  "https://play.dhis2.org/demo/api/33/messageConversations/ZjHHSjyyeJ2?internal=true"
  -H "Content-Type:text/plain" -u admin:district -X POST
```




# Visualisations { #visualizations } 
## Tableaux de bord { #webapi_dashboard } 

The dashboard is designed to give you an overview of multiple analytical
items like maps, charts, pivot tables and reports which together can
provide a comprehensive overview of your data. Dashboards are available
in the Web API through the *dashboards* resource. A dashboard contains a
list of dashboard *items*. An item can represent a single resource, like
a chart, map or report table, or represent a list of links to analytical
resources, like reports, resources, tabular reports and users. A
dashboard item can contain up to eight links. Typically, a dashboard
client could choose to visualize the single-object items directly in a
user interface, while rendering the multi-object items as clickable
links.

    /api/dashboards

### Browsing dashboards { #webapi_browsing_dashboards } 

To get a list of your dashboards with basic information including
identifier, name and link in JSON format you can make a *GET* request to
the following URL:

    /api/dashboards.json

The dashboards resource will provide a list of dashboards. Remember that
the dashboard object is shared so the list will be affected by the
currently authenticated user. You can retrieve more information about a
specific dashboard by following its link, similar to this:

    /api/dashboards/vQFhmLJU5sK.json

A dashboard contains information like name and creation date and an
array of dashboard items. The response in JSON format will look similar
to this response (certain information has been removed for the sake of
brevity).

```json
{
  "lastUpdated" : "2013-10-15T18:17:34.084+0000",
  "id": "vQFhmLJU5sK",
  "created": "2013-09-08T20:55:58.060+0000",
  "name": "Mother and Child Health",
  "href": "https://play.dhis2.org/demo/api/dashboards/vQFhmLJU5sK",
  "publicAccess": "--------",
  "restrictFilters": false,
  "externalAccess": false,
  "itemCount": 17,
  "displayName": "Mother and Child Health",
  "access": {
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "read": true,
    "manage": true
  },
  "user": {
    "id": "xE7jOejl9FI",
    "name": "John Traore",
    "created": "2013-04-18T15:15:08.407+0000",
    "lastUpdated": "2014-12-05T03:50:04.148+0000",
    "href": "https://play.dhis2.org/demo/api/users/xE7jOejl9FI"
  },
  "dashboardItems": [{
    "id": "bu1IAnPFa9H",
    "created": "2013-09-09T12:12:58.095+0000",
    "lastUpdated": "2013-09-09T12:12:58.095+0000"
    }, {
    "id": "ppFEJmWWDa1",
    "created": "2013-09-10T13:57:02.480+0000",
    "lastUpdated": "2013-09-10T13:57:02.480+0000"
  }],
  "layout": {
    "spacing": {
      "column": 5,
      "row": 5
    },
    "columns": [{
      "index": 0,
      "span": 2
    }, {
      "index": 1,
      "span": 1
    }]
  },
  "userGroupAccesses": []
}
```

A more tailored response can be obtained by specifying specific fields
in the request. An example is provided below, which would return more
detailed information about each object on a users dashboard.

    /api/dashboards/vQFhmLJU5sK/?fields=:all,dashboardItems[:all]

### Searching dashboards { #webapi_searching_dasboards } 

When a user is building a dashboard it is convenient
to be able to search for various analytical resources using the
*/dashboards/q* resource. This resource lets you search for matches on
the name property of the following objects: visualizations, maps,
users, reports and resources. You can do a search by making a *GET*
request on the following resource URL pattern, where my-query should be
replaced by the preferred search query:

    /api/dashboards/q/my-query.json

For example, this query:

    /api/dashboards/q/ma?count=6&maxCount=20&max=REPORT&max=MAP

Will search for the following:

* Analytical object name contains the string "ma"
* Return up to 6 of each type
* For REPORT and MAP types, return up to 20 items



Table: dashboards/q query parameters

| Paramètre de requête | Description | Type | Par défaut |
|---|---|---|---|
| compter | The number of items of each type to return | Positive integer | 6 |
| maxCount | The number of items of max types to return | Positive integer | 25 |
| max | The type to return the maxCount for | String [MAP&#124;USER&#124;REPORT&#124;RESOURCE&#124;VISUALIZATION] | N/A |

JSON and XML response formats are supported. The response in JSON format
will contain references to matching resources and counts of how many
matches were found in total and for each type of resource. It will look
similar to this:

```json
{
  "visualizations": [{
    "name": "ANC: ANC 3 Visits Cumulative Numbers",
    "id": "arf9OiyV7df",
    "type": "LINE"
  }, {
    "name": "ANC: 1st and 2rd trends Monthly",
    "id": "jkf6OiyV7el",
    "type": "PIVOT_TABLE"
  }],
  "maps": [{
    "name": "ANC: 1st visit at facility (fixed) 2013",
    "id": "YOEGBvxjAY0"
  }, {
    "name": "ANC: 3rd visit coverage 2014 by district",
    "id": "ytkZY3ChM6J"
  }],
  "reports": [{
    "name": "ANC: 1st Visit Cumulative Chart",
    "id": "Kvg1AhYHM8Q"
  }, {
    "name": "ANC: Coverages This Year",
    "id": "qYVNH1wkZR0"
  }],
  "searchCount": 8,
  "visualizationCount": 3,
  "mapCount": 2,
  "reportCount": 2,
  "userCount": 0,
  "patientTabularReportCount": 0,
  "resourceCount": 0
}
```

### Creating, updating and removing dashboards { #webapi_creating_updating_removing_dashboards } 

Creating, updating and deleting dashboards follow standard REST
semantics. In order to create a new dashboard you can make a *POST*
request to the `/api/dashboards` resource. From a consumer perspective
it might be convenient to first create a dashboard and later add items
to it. JSON and XML formats are supported for the request payload. To
create a dashboard with the name "My dashboard" you can use a payload in
JSON like this:

    {
      "name": "My dashboard"
    }

To update, e.g. rename, a dashboard, you can make a *PUT* request with a
similar request payload the same api/dashboards resource.

To remove a dashboard, you can make a *DELETE* request to the specific
dashboard resource similar to this:

    /api/dashboards/vQFhmLJU5sK

### Adding, moving and removing dashboard items and content { #webapi_adding_moving_removing_dashboard_items } 

In order to add dashboard items a consumer can use the
`/api/dashboards/<dashboard-id>/items/content` resource, where
<dashboard-id\> should be replaced by the relevant dashboard
identifier. The request must use the *POST* method. The URL syntax and
parameters are described in detail in the following table.



Table: Items content parameters

| Paramètre de requête | Description | Options |
|---|---|---|
| type | Type of the resource to be represented by the dashboard item | visualization &#124; map &#124; reportTable &#124; users &#124; reports &#124; resources &#124; patientTabularReports &#124; app |
| identifiant | Identifier of the resource to be represented by the dashboard item | Resource identifier |

A *POST* request URL for adding a visualization to a specific dashboard could look like this, where the last id query parameter value is the chart resource identifier:

    /api/dashboards/vQFhmLJU5sK/items/content?type=visualization&id=LW0O27b7TdD

When adding resource of type map, visualization and app, the API
will create and add a new item to the dashboard. When adding a resource
of type users, reports and resources, the API will try to
add the resource to an existing dashboard item of the same type. If no
item of same type or no item of same type with less than eight resources
associated with it exists, the API will create a new dashboard item and
add the resource to it.

In order to move a dashboard item to a new position within the list of
items in a dashboard, a consumer can make a *POST* request to the
following resource URL, where `<dashboard-id>` should be replaced by the
identifier of the dashboard, `<item-id>` should be replaced by the
identifier of the dashboard item and `<index>` should be replaced by the
new position of the item in the dashboard, where the index is
zero-based:

    /api/dashboards/<dashboard-id>/items/<item-id>/position/<index>

To remove a dashboard item completely from a specific dashboard a
consumer can make a *DELETE* request to the below resource URL, where
`<dashboard-id>` should be replaced by the identifier of the dashboard
and `<item-id>` should be replaced by the identifier of the dashboard
item. The dashboard item identifiers can be retrieved through a GET
request to the dashboard resource URL.

    /api/dashboards/<dashboard-id>/items/<item-id>

To remove a specific content resource within a dashboard item a consumer
can make a *DELETE* request to the below resource URL, where
`<content-resource-id>` should be replaced by the identifier of a
resource associated with the dashboard item; e.g. the identifier of a
report or a user. For instance, this can be used to remove a single
report from a dashboard item of type reports, as opposed to removing the
dashboard item completely:

    /api/dashboards/<dashboard-id>/items/<item-id>/content/<content-resource-id>

### Defining a dashboard layout { #webapi_dasboard_layout } 

You can define and save a layout for each dashboard. The following object is responsible to hold this setting.

    {
      "layout": {
        "spacing": {
          "column": 5,
          "row": 5
        },
        "columns": [{
          "index": 0,
          "span": 2
        }, {
          "index": 1,
          "span": 1
        }]
      }
    }

The layout definition will be applied for all dashboard items related to the given dashboard, respecting layout attributes like spacing, columns, span and so on. See, below, a brief description of each attribute.

Table: Layout attributes

| Attribut | Description | Type |
|---|---|---|
| layout | This is the root object | Objet |
| spacing | Defines the spacing for specific layout components. Currently, it supports columns and rows. | Objet |
| columns | Stores specific parameters related to columns (at the moment, index and span) | Array of objects |

## Visualization { #webapi_visualization } 

The Visualization API is designed to help clients to interact with charts and pivot/report tables. The endpoints of this API are used by the Data Visualization application which allows the creation, configuration and management of charts and pivot tables based on the client's definitions. The main idea is to enable clients and users to have a unique and centralized API providing all types of charts and pivot tables as well as specific parameters and configuration for each type of visualization.

This API was introduced to unify both `charts` and `reportTables` APIs and entirely replace them by the `visualizations` API.

A Visualization object is composed of many attributes (some of them related to charts and others related to pivot tables), but the most important ones responsible to reflect the core information of the object are: *"id", "name", "type", "dataDimensionItems", "columns", "rows" and "filters".*

The root endpoint of the API is `/api/visualizations`, and the list of current attributes and elements are described in the table below.



Table: Visualization attributes

| Champ | Description |
|---|---|
| identifiant | The unique identifier. |
| code | A custom code to identify the Visualization. |
| nom | The name of the Visualization |
| type | The type of the Visualization. The valid types are: COLUMN, STACKED_COLUMN, BAR, STACKED_BAR, LINE, AREA, PIE, RADAR, GAUGE, YEAR_OVER_YEAR_LINE YEAR_OVER_YEAR_COLUMN, SINGLE_VALUE, PIVOT_TABLE. |
| title | A custom title. |
| subtitle | A custom subtitle. |
| Description | Defines a custom description for the Visualization. |
| créé | The date/time of the Visualization creation. |
| date de début | The beginning date used during the filtering. |
| date de fin | The ending date used during the filtering. |
| sortOrder | The sorting order of this Visualization. Integer value. |
| user | An object representing the creator of the Visualization. |
| publicAccess | Sets the permissions for public access. |
| displayDensity | The display density of the text. |
| fontSize | The font size of the text. |
| fontStyle | Custom font styles for: visualizationTitle, visualizationSubtitle, horizontalAxisTitle, verticalAxisTitle, targetLineLabel, baseLineLabel, seriesAxisLabel, categoryAxisLabel, legend. |
| relativePeriods | An object representing the relative periods used in the analytics query. |
| legendSet | An object representing the definitions for the legend. |
| legendDisplayStyle | The legend's display style. It can be: FILL or TEXT. |
| legendDisplayStrategy | The legend's display style. It can be: FIXED or BY_DATA_ITEM. |
| aggregationType | Determines how the values in the pivot table are aggregated. Valid options: SUM, AVERAGE, AVERAGE_SUM_ORG_UNIT, LAST, LAST_AVERAGE_ORG_UNIT, FIRST, FIRST_AVERAGE_ORG_UNIT, COUNT, STDDEV, VARIANCE, MIN, MAX, NONE, CUSTOM or DEFAULT. |
| regressionType | A valid regression type: NONE, LINEAR, POLYNOMIAL or LOESS. |
| targetLineValue | The chart target line. Accepts a Double type. |
| targetLineLabel | The chart target line label. |
| rangeAxisLabel | The chart vertical axis (y) label/title. |
| domainAxisLabel | The chart horizontal axis (x) label/title. |
| rangeAxisMaxValue | The chart axis maximum value. Values outside of the range will not be displayed. |
| rangeAxisMinValue | The chart axis minimum value. Values outside of the range will not be displayed. |
| rangeAxisSteps | The number of axis steps between the minimum and maximum values. |
| rangeAxisDecimals | The number of decimals for the axes values. |
| baseLineValue | A chart baseline value. |
| baseLineLabel | A chart baseline label. |
| digitGroupSeparator | The digit group separator. Valid values: COMMA, SPACE or NONE. |
| topLimit | The top limit set for the Pivot table. |
| measureCriteria | Describes the criteria applied to this measure. |
| percentStackedValues | Uses stacked values or not. More likely to be applied for graphics/charts. Boolean value. |
| noSpaceBetweenColumns | Show/hide space between columns. Boolean value. |
| regression | Indicates whether the Visualization contains regression columns. More likely to be applicable to Pivot/Report. Boolean value. |
| externalAccess | Indicates whether the Visualization is available as external read-only. Only applies when no user is logged in. Boolean value. |
| userOrganisationUnit | Indicates if the user has an organisation unit. Boolean value. |
| userOrganisationUnitChildren | Indicates if the user has a children organisation unit. Boolean value. |
| userOrganisationUnitGrandChildren | Indicates if the user has a grand children organisation unit . Boolean value. |
| reportingParams | Object used to define boolean attributes related to reporting. |
| rowTotals | Displays (or not) the row totals. Boolean value. |
| colTotals | Displays (or not) the columns totals. Boolean value. |
| rowSubTotals | Displays (or not) the row sub-totals. Boolean value. |
| colSubTotals | Displays (or not) the columns sub-totals. Boolean value. |
| cumulativeValues | Indicates whether the visualization is using cumulative values. Boolean value. |
| hideEmptyColumns | Indicates whether to hide columns with no data values. Boolean value. |
| hideEmptyRows | Indicates whether to hide rows with no data values. Boolean value. |
| fixColumnHeaders | Keeps the columns' headers fixed (or not) in a Pivot Table. Boolean value. |
| fixRowHeaders | Keeps the rows' headers fixed (or not) in a Pivot Table. Boolean value. |
| completedOnly | Indicates whether to hide columns with no data values. Boolean value. |
| skipRounding | Apply or not rounding. Boolean value. |
| showDimensionLabels | Shows the dimension labels or not. Boolean value. |
| hideTitle | Hides the title or not. Boolean value. |
| hideSubtitle | Hides the subtitle or not. Boolean value. |
| hideLegend | Show/hide the legend. Very likely to be used by charts. Boolean value. |
| showHierarchy | Displays (or not) the organisation unit hierarchy names. Boolean value. |
| showData | Used by charts to hide or not data/values within the rendered model. Boolean value. |
| lastUpdatedBy | Object that represents the user that applied the last changes to the Visualization. |
| lastUpdated (dernière mise à jour) | The date/time of the last time the Visualization was changed. |
| favorites | List of user ids who have marked this object as a favorite. |
| subscribers | List of user ids who have subscribed to this Visualization. |
| translations | Set of available object translation, normally filtered by locale. |
| outlierAnalysis | Object responsible to keep settings related to outlier analysis. The internal attribute 'outlierMethod' supports: IQR, STANDARD_Z_SCORE, MODIFIED_Z_SCORE. The 'normalizationMethod' accepts only Y_RESIDUALS_LINEAR for now. |
| seriesKey | Styling options for and whether or not to display the series key. |
| légende | Options for and whether or not to apply legend colors to the chart series. |

### Retrieving visualizations { #webapi_visualization_retrieving_visualizations } 

To retrieve a list of all existing visualizations, in JSON format, with some basic information (including identifier, name and pagination) you can make a `GET` request to the URL below. You should see a list of all public/shared visualizations plus your private ones.

    GET /api/visualizations.json

If you want to retrieve the JSON definition of a specific Visualization you can add its respective identifier to the URL:

    GET /api/visualizations/hQxZGXqnLS9.json

The following representation is an example of a response in JSON format (for brevity, certain information has been removed). For the complete schema, please use `GET /api/schemas/visualization`.

```json
{
  "lastUpdated": "2020-02-06T11:57:09.678",
  "href": "http://my-domain/dhis/api/visualizations/hQxZGXqnLS9",
  "id": "hQxZGXqnLS9",
  "created": "2017-05-19T17:22:00.785",
  "name": "ANC: ANC 1st visits last 12 months cumulative values",
  "publicAccess": "rw------",
  "userOrganisationUnitChildren": false,
  "type": "LINE",
  "access": {},
  "reportingParams": {
    "parentOrganisationUnit": false,
    "reportingPeriod": false,
    "organisationUnit": false,
    "grandParentOrganisationUnit": false
  },
  "dataElementGroupSetDimensions": [],
  "attributeDimensions": [],
  "yearlySeries": [],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "title": {
        "textMode": "CUSTOM",
        "text": "Any Title"
      }
    }
  ],
  "filterDimensions": [
    "dx"
  ],
  "columns": [
    {
      "id": "ou"
    }
  ],
  "dataElementDimensions": [],
  "categoryDimensions": [],
  "rowDimensions": [
    "pe"
  ],
  "columnDimensions": [
    "ou"
  ],
  "dataDimensionItems": [
    {
      "dataDimensionItemType": "DATA_ELEMENT",
      "dataElement": {
        "id": "fbfJHSPpUQD"
      }
    }
  ],
  "filters": [
    {
      "id": "dx"
    }
  ],
  "rows": [
    {
      "id": "pe"
    }
  ]
}
```
A more tailored response can be obtained by specifying, in the URL, the fields you want to extract. Ie.:

    GET /api/visualizations/hQxZGXqnLS9.json?fields=interpretations

will return

```json
{
  "interpretations": [
    {
      "id": "Lfr8I2RPU0C"
    },
    {
      "id": "JuwgdJlJPGb"
    },
    {
      "id": "WAoU2rSpyZp"
    }
  ]
}
```

As seen, the `GET` above will return only the interpretations related to the given identifier (in this case `hQxZGXqnLS9`).

### Creating, updating and removing visualizations { #webapi_visualization_add_update_remove_visualizations } 

These operations follow the standard *REST* semantics. A new Visualization can be created through a `POST` request to the `/api/visualizations` resource with a valid JSON payload. An example of payload could be:

```json
{
  "columns": [
    {
      "dimension": "J5jldMd8OHv",
      "items": [
        {
          "name": "CHP",
          "id": "uYxK4wmcPqA",
          "displayName": "CHP",
          "displayShortName": "CHP",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        },
        {
          "name": "Hospital",
          "id": "tDZVQ1WtwpA",
          "displayName": "Hospital",
          "displayShortName": "Hospital",
          "dimensionItemType": "ORGANISATION_UNIT_GROUP"
        }
      ]
    }
  ],
  "rows": [
    {
      "dimension": "SooXFOUnciJ",
      "items": [
        {
          "name": "DOD",
          "id": "B0bjKC0szQX",
          "displayName": "DOD",
          "displayShortName": "DOD",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        },
        {
          "name": "CDC",
          "id": "OK2Nr4wdfrZ",
          "displayName": "CDC",
          "displayShortName": "CDC",
          "dimensionItemType": "CATEGORY_OPTION_GROUP"
        }
      ]
    }
  ],
  "filters": [
    {
      "dimension": "ou",
      "items": [
        {
          "name": "Sierra Leone",
          "id": "ImspTQPwCqd",
          "displayName": "Sierra Leone",
          "displayShortName": "Sierra Leone",
          "dimensionItemType": "ORGANISATION_UNIT"
        },
        {
          "name": "LEVEL-1",
          "id": "LEVEL-H1KlN4QIauv",
          "displayName": "LEVEL-1"
        }
      ]
    }
  ],
  "name": "HIV Cases Monthly",
  "description": "Cases of HIV across the months",
  "category": "XY1vwCQskjX",
  "showDimensionLabels": true,
  "hideEmptyRows": true,
  "hideEmptyColumns": true,
  "skipRounding": true,
  "aggregationType": "SUM",
  "regressionType": "LINEAR",
  "type": "PIVOT_TABLE",
  "numberType": "VALUE",
  "measureCriteria": "Some criteria",
  "showHierarchy": true,
  "completedOnly": true,
  "displayDensity": "NORMAL",
  "fontSize": "NORMAL",
  "digitGroupSeparator": "SPACE",
  "legendDisplayStyle": "FILL",
  "legendDisplayStrategy": "FIXED",
  "hideEmptyRowItems": "BEFORE_FIRST_AFTER_LAST",
  "fixColumnHeaders": true,
  "fixRowHeaders": false,
  "regression": false,
  "cumulative": true,
  "sortOrder": 1,
  "topLimit": 2,
  "rowTotals": true,
  "colTotals": true,
  "hideTitle": true,
  "hideSubtitle": true,
  "hideLegend": true,
  "showData": true,
  "percentStackedValues": true,
  "noSpaceBetweenColumns": true,
  "rowSubTotals": true,
  "colSubTotals": true,
  "userOrgUnitType": "TEI_SEARCH",
  "externalAccess": false,
  "publicAccess": "--------",
  "reportingParams": {
    "reportingPeriod": true,
    "organisationUnit": true,
    "parentOrganisationUnit": true,
    "grandParentOrganisationUnit": true
  },
  "parentGraphMap": {
    "ImspTQPwCqd": ""
  },
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": false,
    "write": true,
    "manage": false
  },
  "optionalAxes": [
    {
      "dimensionalItem": "fbfJHSPpUQD",
      "axis": 1
    },
    {
      "dimensionalItem": "cYeuwXTCPkU",
      "axis": 2
    }
  ],
  "relativePeriods": {
    "thisYear": false,
    "quartersLastYear": true,
    "last52Weeks": false,
    "thisWeek": false,
    "lastMonth": false,
    "last14Days": false,
    "biMonthsThisYear": false,
    "monthsThisYear": false,
    "last2SixMonths": false,
    "yesterday": false,
    "thisQuarter": false,
    "last12Months": false,
    "last5FinancialYears": false,
    "thisSixMonth": false,
    "lastQuarter": false,
    "thisFinancialYear": false,
    "last4Weeks": false,
    "last3Months": false,
    "thisDay": false,
    "thisMonth": false,
    "last5Years": false,
    "last6BiMonths": false,
    "last4BiWeeks": false,
    "lastFinancialYear": false,
    "lastBiWeek": false,
    "weeksThisYear": false,
    "last6Months": false,
    "last3Days": false,
    "quartersThisYear": false,
    "monthsLastYear": false,
    "lastWeek": false,
    "last7Days": false,
    "thisBimonth": false,
    "lastBimonth": false,
    "lastSixMonth": false,
    "thisBiWeek": false,
    "lastYear": false,
    "last12Weeks": false,
    "last4Quarters": false
  },
  "user": {},
  "yearlySeries": [
    "THIS_YEAR"
  ],
  "userGroupAccesses": [
    {
      "access": "rwx-----",
      "userGroupUid": "ZoHNWQajIoe",
      "displayName": "Bo District M&E officers",
      "id": "ZoHNWQajIoe"
    }
  ],
  "userAccesses": [
    {
      "access": "--------",
      "displayName": "John Barnes",
      "id": "DXyJmlo9rge",
      "userUid": "DXyJmlo9rge"
    }
  ],
  "legendSet": {
    "name": "Death rate up",
    "id": "ham2eIDJ9k6",
    "legends": [
      {
        "startValue": 1,
        "endValue": 2,
        "color": "red",
        "image": "some-image"
      },
      {
        "startValue": 2,
        "endValue": 3,
        "color": "blue",
        "image": "other-image"
      }
    ]
  },
  "outlierAnalysis": {
    "enabled": true,
    "outlierMethod": "IQR",
    "thresholdFactor": 1.5,
    "normalizationMethod": "Y_RESIDUALS_LINEAR",
    "extremeLines": {
      "enabled": true,
      "value": 3.5
    }
  },
  "legend": {
    "strategy": "FIXED",
    "style": "FILL",
    "set": {
      "id": "fqs276KXCXi",
      "displayName": "ANC Coverage"
    },
    "showKey": false
  },
  "seriesKey": {
    "hidden": true,
    "label": {
      "fontStyle": {
        "textColor": "#cccddd"
      }
    }
  },
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "textMode": "CUSTOM",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ],
  "axes": [
    {
      "index": 0,
      "type": "RANGE",
      "label": {
        "fontStyle": {
          "textColor": "#cccddd"
        }
      },
      "title": {
        "text": "Range axis title",
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "decimals": 1,
      "maxValue": 100,
      "minValue": 20,
      "steps": 5,
      "baseLine": {
        "value": 50,
        "title": {
          "text": "My baseline",
          "fontStyle": {
            "textColor": "#000000"
          }
        }
      },
      "targetLine": {
        "value": 80,
        "title": {
          "text": "My targetline",
          "fontStyle": {
            "textColor": "#cccddd"
          }
        }
      }
    },
    {
      "index": 1,
      "type": "DOMAIN",
      "label": {
        "fontStyle": {
          "textColor": "#000000"
        }
      },
      "title": {
        "text": "Domain axis title",
        "fontStyle": {
          "textColor": "#cccddd"
        }
      }
    }
  ]
}
```

To update a specific Visualization, you can send a `PUT` request to the same `/api/visualizations` resource with a similar payload `PLUS` the respective Visualization's identifier, ie.:

    PUT /api/visualizations/hQxZGXqnLS9

Finally, to delete an existing Visualization, you can make a `DELETE` request specifying the identifier of the Visualization to be removed, as shown:

    DELETE /api/visualizations/hQxZGXqnLS9

## Interprétations { #webapi_interpretations } 

For resources related to data analysis in DHIS2, such as visualizations, maps, event reports and event charts, you can write and share data interpretations. An interpretation can be a comment, question, observation or interpretation about a data report or visualization.

    /api/interpretations

### Reading interpretations { #webapi_reading_interpretations } 

To read interpretations we will interact with the
`/api/interpretations` resource. A typical GET request using field
filtering can look like this:

    GET /api/interpretations?fields=*,comments[id,text,user,mentions]

The output in JSON response format could look like below (additional
fields omitted for brevity):

```json
{
  "interpretations": [
    {
      "id": "XSHiFlHAhhh",
      "created": "2013-05-30T10:24:06.181+0000",
      "text": "Data looks suspicious, could be a data entry mistake.",
      "type": "MAP",
      "likes": 2,
      "user": {
        "id": "uk7diLujYif"
      },
      "reportTable": {
        "id": "LcSxnfeBxyi"
      },
      "visualization": {
        "id": "LcSxnfeBxyi"
      }
    }, {
      "id": "kr4AnZmYL43",
      "created": "2013-05-29T14:47:13.081+0000",
      "text": "Delivery rates in Bo looks high.",
      "type": "VISUALIZATION",
      "likes": 3,
      "user": {
        "id": "uk7diLujYif"
      },
      "visualization": {
        "id": "HDEDqV3yv3H"
      },
      "mentions": [
        {
          "created": "2018-06-25T10:25:54.498",
          "username": "boateng"
        }
      ],
      "comments": [
        {
          "id": "iB4Etq8yTE6",
          "text": "This report indicates a surge.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "iB4Etq8yTE6",
          "text": "Likely caused by heavy rainfall.",
          "user": {
            "id": "B4XIfwOcGyI"
          }
        },
        {
          "id": "SIjkdENan8p",
          "text": "Have a look at this @boateng.",
          "user": {
            "id": "xE7jOejl9FI"
          },
          "mentions": [
            {
              "created": "2018-06-25T10:03:52.316",
              "username": "boateng"
            }
          ]
        }
      ]
    }
  ]
}
```



Table: Interpretation fields

| Champ | Description |
|---|---|
| identifiant | The interpretation identifier. |
| créé | The time of when the interpretation was created. |
| type | The type of analytical object being interpreted. Valid options: VISUALIZATION, MAP, EVENT_REPORT, EVENT_CHART, DATASET_REPORT. |
| user | Association to the user who created the interpretation. |
| visualization | Association to the visualization if type is VISUALIZATION |
| map | Association to the map if type is MAP. |
| eventReport | Association to the event report is type is EVENT_REPORT. |
| eventChart | Association to the event chart if type is EVENT_CHART. |
| dataSet (ensemble de données) | Association to the data set if type is DATASET_REPORT. |
| comments | Array of comments for the interpretation. The text field holds the actual comment. |
| mentions | Array of mentions for the interpretation. A list of users identifiers. |

For all analytical objects you can append */data* to the URL to retrieve
the data associated with the resource (as opposed to the metadata). As
an example, by following the map link and appending /data one can
retrieve a PNG (image) representation of the thematic map through the
following URL:

    https://play.dhis2.org/demo/api/maps/bhmHJ4ZCdCd/data

For all analytical objects you can filter by *mentions*. To retrieve all
the interpretations/comments where a user has been mentioned you have
three options. You can filter by the interpretation mentions (mentions
in the interpretation
    description):

    GET /api/interpretations?fields=*,comments[*]&filter=mentions.username:in:[boateng]

You can filter by the interpretation comments mentions (mentions in any
comment):

    GET /api/interpretations?fields=*,comments[*]
      &filter=comments.mentions.username:in:[boateng]

You can filter by intepretations which contains the mentions either
in the interpretation or in any comment (OR junction):

    GET /api/interpretations?fields=*,comments[*]&filter=mentions:in:[boateng]

### Writing interpretations { #webapi_writing_interpretations } 

When writing interpretations you will supply the interpretation text as
the request body using a POST request with content type "text/plain".
The URL pattern looks like the below, where {object-type} refers to the
type of the object being interpreted and {object-id} refers to the
identifier of the object being interpreted.

    /api/interpretations/{object-type}/{object-id}

Valid options for object type are *visualization*, *map*,
*eventReport*, *eventChart* and *dataSetReport*.

Some valid examples for interpretations are listed below.

    /api/interpretations/visualization/hQxZGXqnLS9
    /api/interpretations/map/FwLHSMCejFu
    /api/interpretations/eventReport/xJmPLGP3Cde
    /api/interpretations/eventChart/nEzXB2M9YBz
    /api/interpretations/dataSetReport/tL7eCjmDIgM

As an example, we will start by writing an interpretation for the visualization with identifier *EbRN2VIbPdV*. To write visualization interpretations we will interact with the `/api/interpretations/visualization/{visualizationId}` resource.
The interpretation will be the request body. Based on this we can put
together the following request using cURL:

```bash
curl -d "This visualization shows a significant ANC 1-3 dropout" -X POST
  "https://play.dhis2.org/demo/api/interpretations/visualization/EbRN2VIbPdV" -H "Content-Type:text/plain" -u admin:district
```

Notice that the response provides a Location header with a value
indicating the location of the created interpretation. This is useful
from a client perspective when you would like to add a comment to the
interpretation.

### Updating and removing interpretations { #webapi_updating_removing_interpretations } 

To update an existing interpretation you can use a PUT request where the
interpretation text is the request body using the following URL pattern,
where {id} refers to the interpretation identifier:

    /api/interpretations/{id}

Based on this we can use curl to update the interpretation:

```bash
curl -d "This visualization shows a high dropout" -X PUT
  "https://play.dhis2.org/demo/api/interpretations/visualization/EV08iI1cJRA" -H "Content-Type:text/plain" -u admin:district
```

You can use the same URL pattern as above using a DELETE request to
remove the interpretation.

### Creating interpretation comments { #webapi_creating_interpretation_comments } 

When writing comments to interpretations you will supply the comment
text as the request body using a POST request with content type
"text/plain". The URL pattern looks like the below, where
{interpretation-id} refers to the interpretation identifier.

    /api/interpretations/{interpretation-id}/comments

Second, we will write a comment to the interpretation we wrote in the
example above. By looking at the interpretation response you will see
that a *Location* header is returned. This header tells us the URL of
the newly created interpretation and from that, we can read its
identifier. This identifier is randomly generated so you will have to
replace the one in the command below with your own. To write a comment
we can interact with the `/api/interpretations/{id}/comments`
resource like this:

```bash
curl -d "An intervention is needed" -X POST
  "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments"
  -H "Content-Type:text/plain" -u admin:district
```

### Updating and removing interpretation comments { #webapi_updating_removing_interpretation_comments } 

To updating an interpretation comment you can use a PUT request where
the comment text is the request body using the following URL pattern:

    /api/interpretations/{interpretation-id}/comments/{comment-id}

Based on this we can use curl to update the comment:

```bash
curl "https://play.dhis2.org/demo/api/interpretations/j8sjHLkK8uY/comments/idAzzhVWvh2"
  -d "I agree with that." -X PUT -H "Content-Type:text/plain" -u admin:district
```

You can use the same URL pattern as above using a DELETE request to the
remove the interpretation comment.

### Liking interpretations { #webapi_liking_interpretations } 

To like an interpretation you can use an empty POST request to the
*like* resource:

    POST /api/interpretations/{id}/like

A like will be added for the currently authenticated user. A user can
only like an interpretation once.

To remove a like for an interpretation you can use a DELETE request to
the same resource as for the like operation.

The like status of an interpretation can be viewed by looking at the
regular Web API representation:

    GET /api/interpretations/{id}

The like information is found in the *likes* field, which represents the
number of likes, and the *likedBy* array, which enumerates the users who
have liked the interpretation.

```json
{
  "id": "XSHiFlHAhhh",
  "text": "Data looks suspicious, could be a data entry mistake.",
  "type": "VISUALIZATION",
  "likes": 2,
  "likedBy": [
    {
      "id": "k7Hg12fJ2f1"
    },
    {
      "id": "gYhf26fFkjFS"
    }
  ]
}
```
## SQL views { #webapi_sql_views } 

The SQL views resource allows you to create and retrieve the result set
of SQL views. The SQL views can be executed directly against the
database and render the result set through the Web API resource.

    /api/sqlViews

SQL views are useful for creating data views which may be more easily
constructed with SQL compared combining the multiple objects of the Web
API. As an example, lets assume we have been asked to provide a view of
all organization units with their names, parent names, organization unit
level and name, and the coordinates listed in the database. The view
might look something like this:

```sql
SELECT ou.name as orgunit, par.name as parent, ou.coordinates, ous.level, oul.name from organisationunit ou
INNER JOIN _orgunitstructure ous ON ou.organisationunitid = ous.organisationunitid
INNER JOIN organisationunit par ON ou.parentid = par.organisationunitid
INNER JOIN orgunitlevel oul ON ous.level = oul.level
WHERE ou.coordinates is not null
ORDER BY oul.level, par.name, ou.name
```

We will use *curl* to first execute the view on the DHIS2 server. This
is essentially a materialization process, and ensures that we have the
most recent data available through the SQL view when it is retrieved
from the server. You can first look up the SQL view from the
api/sqlViews resource, then POST using the following command:

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/execute" -X POST -u admin:district
```

The next step in the process is the retrieval of the data.The basic
structure of the URL is as follows

    http://{server}/api/sqlViews/{id}/data(.csv)

The `{server}` parameter should be replaced with your own server. The
next part of the URL `/api/sqlViews/` should be appended with the
specific SQL view identifier. Append either `data` for XML data or
`data.csv` for comma delimited values. Support response formats are
json, xml, csv, xls, html and html+css. As an example, the following
command would retrieve XML data for the SQL view defined above.

```bash
curl "https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv" -u admin:district
```

There are three types of SQL views:

  - *SQL view:* Standard SQL views.

  - *Materialized SQL view:* SQL views which are materialized, meaning
    written to disk. Needs to be updated to reflect changes in
    underlying tables. Supports criteria to filter result set.

  - *SQL queries:* Plain SQL queries. Support inline variables for
    customized queries.

### Criteria { #webapi_sql_view_criteria } 

You can do simple filtering on the columns in the result set by
appending *criteria* query parameters to the URL, using the column names
and filter values separated by columns as parameter values, on the
following format:

    /api/sqlViews/{id}/data?criteria=col1:value1&criteria=col2:value2

As an example, to filter the SQL view result set above to only return
organisation units at level 4 you can use the following
    URL:

    https://play.dhis2.org/demo/api/sqlViews/dI68mLkP1wN/data.csv?criteria=level:4

### Variables { #webapi_sql_view_variables } 

SQL views support variable substitution. Variable substitution is only
available for SQL view of type *query*, meaning SQL views which are not
created in the database but simply executed as regular SQL queries.
Variables can be inserted directly into the SQL query and must be on
this format:

    ${variable-key}

As an example, an SQL query that retrieves all data elements of a given
value type where the value type is defined through a variable can look
like this:

    select * from dataelement where valuetype = '${valueType}';

These variables can then be supplied as part of the URL when requested
through the *sqlViews* Web API resource. Variables can be supplied on
the following format:

    /api/sqlViews/{id}/data?var=key1:value1&var=key2:value2

An example query corresponding to the example above can look like this:

    /api/sqlViews/dI68mLkP1wN/data.json?var=valueType:int

The *valueType* variable will be substituted with the *int* value, and
the query will return data elements with int value type.

The variable parameter must contain alphanumeric characters only. The
variables must contain alphanumeric, dash, underscore and whitespace
characters only.

SQL Views of type *query* also support two system-defined variables that allow the query to access information about the user executing the view:

| variable | signifie |
| -------- | ----- |
| ${_current_user_id} | the user's database id |
| ${_current_username} | the user's username |

Values for these variables cannot be supplied as part of the URL. They are always filled with information about the user.

For example, the following SQL view of type *query* shows all the organisation units that are assigned to the user:

```sql
    select ou.path, ou.name
    from organisationunit ou_user
    join organisationunit ou on ou.path like ou_user.path || '%'
    join usermembership um on um.organisationunitid = ou_user.organisationunitid
    where um.userinfoid = ${_current_user_id}
    order by ou.path
```

### Filtering { #webapi_sql_view_filtering } 

The SQL view api supports data filtering, equal to the [metadata object
filter](#webapi_metadata_object_filter). For a complete list of filter
operators you can look at the documentation for [metadata object
filter](#webapi_metadata_object_filter).

To use filters, simply add them as parameters at the end of the request
url for your SQL view like
    this:

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:eq:2&filter=orgunit_name:ilike:bo

This request will return a result including org units with "bo" in the
name and which has org unit level 2.

The following example will return all org units with `orgunit_level` 2 or
4:

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_level:in:[2,4]

And last, an example to return all org units that does not start with
"Bo"

    /api/sqlViews/w3UxFykyHFy/data.json?filter=orgunit_name:!like:Bo


## Data items { #webapi_data_items } 

This endpoint allows the user to query data related to a few different dimensional items. These items are: `INDICATOR`, `DATA_ELEMENT`, `DATA_SET`, `PROGRAM_INDICATOR`, `PROGRAM_DATA_ELEMENT`, `PROGRAM_ATTRIBUTE`. The endpoint supports only `GET` requests and, as other endpoints, can return responses in JSON or XML format.

The URL is `/api/dataItems` and as you can imagine, it is able to retrieve different objects through the same endpoint in the same `GET` request. For this reason, some queriable attributes available will differ depending on the dimensional item(s) being queried.

To understand the statement above let's have a look at the followings request examples:

1) `GET /api/dataItems?filter=dimensionItemType:eq:DATA_ELEMENT&filter=valueType:eq:TEXT`
In this example the item type `DATA_ELEMENT` has a `valueType` attribute which can be used in the query.

2) `GET /api/dataItems?pageSize=50&order=displayName:asc&filter=dimensionItemType:eq:PROGRAM_INDICATOR&filter=displayName:ilike:someName&filter=programId:eq:WSGAb5XwJ3Y`

Here, the `PROGRAM_INDICATOR` allows filtering by `programId`.

So, based on the examples `1)` and `2)` if you try filtering a `DATA_ELEMENT` by `programId` or filter a `PROGRAM_INDICATOR` by `valueType`, you should get no results.
In other words, the filter will be applied only when the attribute actually exists for the respective data item.

Another important aspect to be highlighted is that this endpoint does NOT follow the same querying standards as other existing endpoints, like [Metadata object filter](#webapi_metadata_object_filter) for example. As a consequence, it supports a smaller set of features and querying.
The main reason for that is the need for querying multiple different items that have different relationships, which is not possible using the existing filtering components (used by the others endpoints).

### Possible endpoint responses { #webapi_data_items_possible_responses } 

Base on the `GET` request/query, a few different responses are possible. Below we are summarizing each possibility.

#### Results found (HTTP status code 200) { #results-found-http-status-code-200 } 

```
{
  "pager": {
    "page": 1,
    "pageCount": 27,
    "total": 1339,
    "pageSize": 50,
    "nextPage": "https://play.dhis2.org/dev/api/36/dataItems?page=2&filter=displayName:ilike:a&filter=id:eq:nomatch&rootJunction=OR&displayName:asc=&paging=true"
  },
  "dataItems": [
    {
      "simplifiedValueType": "TEXT",
      "displayName": "TB program Gender",
      "displayShortName": "TB prog. Gen.",
      "valueType": "TEXT",
      "name": "TB program Gender",
      "shortName": ""TB prog. Gen.",
      "id": "ur1Edk5Oe2n.cejWyOfXge6",
      "programId": "ur1Edk5Oe2n",
      "dimensionItemType": "PROGRAM_ATTRIBUTE"
    },
    ...
  ]
}
```

#### Results not found (HTTP status code 200) { #results-not-found-http-status-code-200 } 

```
{
  "pager": {
    "page": 1,
    "pageCount": 1,
    "total": 0,
    "pageSize": 50
  },
  "dataItems": []
}
```

#### Invalid query (HTTP status code 409) { #invalid-query-http-status-code-409 } 

```
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Unable to parse element `INVALID_TYPE` on filter `dimensionItemType`. The values available are: [INDICATOR, DATA_ELEMENT, DATA_ELEMENT_OPERAND, DATA_SET, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE]",
  "errorCode": "E2016"
}
```

#### Unhandled error (HTTP status code 500) { #unhandled-error-http-status-code-500 } 

```
{
  "httpStatus": "Internal Server Error",
  "httpStatusCode": 500,
  "status": "ERROR"
}
```

### Pagination { #webapi_data_items_pagination } 

This endpoint also supports pagination as a default option. If needed, you can disable pagination by adding `paging=false` to the `GET` request.
ie.: `/api/dataItems?filter=dimensionItemType:in:[INDICATOR]&paging=false`.

Here is an example of a payload when the pagination is enabled. Remember that pagination is the default option and does not need to be explicitly set.

```
{
  "pager": {
    "page": 1,
    "pageCount": 20,
    "total": 969,
    "pageSize": 50,
    "nextPage": "https://play.dhis2.org/dev/api/dataItems?page=2&filter=dimensionItemType:in:[INDICATOR]"
  },
  "dataItems": [...]
}
```

> **Note**
>
> For elements where there is an associated Program, the program name should also be returned as part of the element name (as a prefix). The only exception is `Program Indicators`. We will not prefix the element name in this case, in order to keep the same behavior as existing endpoints.
>
> The /dataItems endpoint will bring only data items that are defined as aggregatable type. The current list of valid aggregatable types is:
`TEXT, LONG_TEXT`, `LETTER`, `BOOLEAN`, `TRUE_ONLY`, `NUMBER`, `UNIT_INTERVAL`, `PERCENTAGE`, `INTEGER`, `INTEGER_POSITIVE`, `INTEGER_NEGATIVE`, `INTEGER_ZERO_OR_POSITIVE`, `COORDINATE`.
>
> Even though the response returns several different attributes, the filtering can only be applied to specific ones: `displayName`, `name`, `valueType`, `id`, `dimensionItemType`, `programId`.
>
> The `order` will be considered invalid if it is set on top of `name` (ie.: order=*name:asc*) and a `filter` is set to `displayName` (ie.: filter=*displayName:ilike:aName*), and vice-versa.

### Response attributes { #webapi_data_items_response_attributes } 

Now that we have a good idea of the main features and usage of this endpoint let's have a look in the list of attributes returned in the response.



Table: Data items attributes

| Champ | Description |
|---|---|
| identifiant | The unique identifier. |
| code | A custom code to identify the dimensional item. |
| nom | The name given for the item. |
| Nom d'affichage | The display name defined. |
| nomAbrégé | The short name given for the item. |
| displayShortName | The display short name defined. |
| dimensionItemType | The dimension type. Possible types: INDICATOR, DATA_ELEMENT, REPORTING_RATE, PROGRAM_INDICATOR, PROGRAM_DATA_ELEMENT, PROGRAM_ATTRIBUTE. |
| Type de valeur | The item value type (more specific definition). Possitble types: TEXT, LONG_TEXT, LETTER, BOOLEAN, TRUE_ONLY, UNIT_INTERVAL, PERCENTAGE, INTEGER, INTEGER_POSITIVE, INTEGER_NEGATIVE, INTEGER_ZERO_OR_POSITIVE, COORDINATE |
| simplifiedValueType | The genereal representation of a value type. Valid values: NUMBER, BOOLEAN, DATE, FILE_RESOURCE, COORDINATE, TEXT |
| programId | The associated programId. |

## Viewing analytical resource representations { #webapi_viewing_analytical_resource_representations } 

DHIS2 has several resources for data analysis. These resources include
*maps*, *visualizations*, *reports* and *documents*. By visiting these resources you will retrieve information about the resource. For instance, by navigating to `/api/visualizations/R0DVGvXDUNP` the response will contain the name, last date of modification and so on for the chart. To retrieve the analytical representation, for instance, a PNG representation of the visualization, you can append */data* to all these resources. For instance, by visiting `/api/visualizations/R0DVGvXDUNP/data` the system will return a PNG image of the visualization.



Table: Analytical resources

| Resource | Description | Data URL | Resource representations |
|---|---|---|---|
| eventCharts | Graphiques d'évènements | /api/eventCharts/<identifier\>/data | png |
| maps | Cartes | /api/maps/<identifier\>/data | png |
| visualization | Pivot tables and charts | /api/visualizations/<identifier\>/data | json &#124; jsonp &#124; html &#124; xml &#124; pdf &#124; xls &#124; csv | png |
| reports | **SIG:**Le SIG intégré à DHIS 2 permet de présenter et d'analyser vos
données à l'aide de cartes géographiques à thèmes. Vous pouvez y
visualiser aussi bien les éléments de données que les indicateurs ; et
en supposant que vous disposiez des coordonnées de toutes vos unités
d’organisation, vous pouvez parcourir votre hiérarchie
organisationnelle et faire apparaitre des cartes pour tous les niveaux à
l’aide de polygones ou de points. Toutes les informations affichées sur
les cartes sont générées par DHIS 2 ; tout ce que vous devez faire est
de procéder à l’enregistrement des coordonnées de vos unités
d'organisation pour que les cartes deviennent disponibles. Voir le
chapitre spécifique qui traite du SIG pour obtenir plus de détails. | /api/reports/<identifier\>/data | pdf &#124; xls &#124; html |
| documents | Ressources | /api/documents/<identifier\>/data | <follows document\> |

The data content of the analytical representations can be modified by
providing a *date* query parameter. This requires that the analytical
resource is set up for relative periods for the period dimension.



Table: Data query parameters

| Paramètre de requête | Valeur | Description |
|---|---|---|
| date | Date in yyyy-MM-dd format | Basis for relative periods in report (requires relative periods) |



Table: Query parameters for png / image types (visualizations, maps)

| Paramètre de requête | Description |
|---|---|
| width | Width of image in pixels |
| height | Height of image in pixels |

Some examples of valid URLs for retrieving various analytical
representations are listed below.

    /api/visualization/R0DVGvXDUNP/data
    /api/visualization/R0DVGvXDUNP/data?date=2013-06-01

    /api/visualization/jIISuEWxmoI/data.html
    /api/visualization/jIISuEWxmoI/data.html?date=2013-01-01
    /api/visualization/FPmvWs7bn2P/data.xls
    /api/visualization/FPmvWs7bn2P/data.pdf

    /api/maps/DHE98Gsynpr/data
    /api/maps/DHE98Gsynpr/data?date=2013-07-01

    /api/reports/OeJsA6K1Otx/data.pdf
    /api/reports/OeJsA6K1Otx/data.pdf?date=2014-01-01

## Plugins { #webapi_plugins } 

DHIS2 comes with plugins which enable you to embed live data directly in
your web portal or web site. Currently, plugins exist for charts, maps
and pivot tables.

Please be aware that all of the code examples in this section are for
demonstration purposes only. They should not be used as is in
production systems. To make things simple, the credentials
(admin/district) have been embedded into the scripts. In a real scenario,
you should never expose credentials in javascript as it opens a
vulnerability to the application. In addition, you would create a user
with more minimal privileges rather than make use of a superuser to
fetch resources for your portal.

It is possible to workaround exposing the credentials by using a reverse
proxy such as nginx or apache2. The proxy can be configured to inject
the required Authorization header for only the endpoints that you wish
to make public. There is some documentation to get you started in the
section of the implementers manual which describes [reverse
proxy](https://docs.dhis2.org/master/en/implementer/html/install_reverse_proxy_configuration.html#install_making_resources_available_with_nginx)
configuration.

### Embedding pivot tables with the Pivot Table plug-in { #webapi_pivot_table_plugin } 

In this example, we will see how we can embed good-looking, light-weight
html pivot tables with data served from a DHIS2 back-end into a Web
page. To accomplish this we will use the Pivot table plug-in. The
plug-in is written in Javascript and depends on the jQuery library only.
A complete working example can be found at
<http://play.dhis2.org/portal/table.html>. Open the page in a web
browser and view the source to see how it is set up.

We start by having a look at what the complete html file could look
like. This setup puts two tables in our web page. The first one is
referring to an existing table. The second is configured inline.

```html
<!DOCTYPE html>
<html>
<head>
  <script src="https://dhis2-cdn.org/v227/plugin/jquery-2.2.4.min.js"></script>
  <script src="https://dhis2-cdn.org/v227/plugin/reporttable.js"></script>

  <script>
    reportTablePlugin.url = "https://play.dhis2.org/demo";
    reportTablePlugin.username = "admin";
    reportTablePlugin.password = "district";
    reportTablePlugin.loadingIndicator = true;

    // Referring to an existing table through the id parameter, render to "report1" div

    var r1 = { el: "report1", id: "R0DVGvXDUNP" };

    // Table configuration, render to "report2" div

    var r2 = {
      el: "report2",
      columns: [
        {dimension: "dx", items: [{id: "YtbsuPPo010"}, {id: "l6byfWFUGaP"}]}
      ],
      rows: [
        {dimension: "pe", items: [{id: "LAST_12_MONTHS"}]}
      ],
      filters: [
        {dimension: "ou", items: [{id: "USER_ORGUNIT"}]}
      ],

      // All following properties are optional
      title: "My custom title",
      showColTotals: false,
      showRowTotals: false,
      showColSubTotals: false,
      showRowSubTotals: false,
      showDimensionLabels: false,
      hideEmptyRows: true,
      skipRounding: true,
      aggregationType: "AVERAGE",
      showHierarchy: true,
      completedOnly: true,
      displayDensity: "COMFORTABLE",
      fontSize: "SMALL",
      digitGroupSeparator: "COMMA",
      legendSet: {id: "fqs276KXCXi"}
    };

    reportTablePlugin.load([r1, r2]);
  </script>
</head>

<body>
  <div id="report1"></div>
  <div id="report2"></div>
</body>
</html>
```

Two files are included in the header section of the HTML document. The
first file is the jQuery JavaScript library (we use the DHIS2 content
delivery network in this case). The second file is the Pivot table
plug-in. Make sure the path is pointing to your DHIS2 server
installation.

Now let us have a look at the various options for the Pivot tables. One
property is required: *el* (please refer to the table below). Now, if
you want to refer to pre-defined tables already made inside DHIS2 it is
sufficient to provide the additional *id* parameter. If you instead want
to configure a pivot table dynamically you should omit the id parameter
and provide data dimensions inside a *columns* array, a *rows* array and
optionally a *filters* array instead.

A data dimension is defined as an object with a text property called
*dimension*. This property accepts the following values: *dx*
(indicator, data element, data element operand, data set, event data
item and program indicator), *pe* (period), *ou* (organisation unit) or
the id of any organisation unit group set or data element group set (can
be found in the web api). The data dimension also has an array property
called *items* which accepts objects with an *id* property.

To sum up, if you want to have e.g. "ANC 1 Coverage", "ANC 2 Coverage"
and "ANC 3 Coverage" on the columns in your table you can make the
following *columns* config:

```json
columns: [{
  dimension: "dx",
  items: [
    {id: "Uvn6LCg7dVU"}, // the id of ANC 1 Coverage
    {id: "OdiHJayrsKo"}, // the id of ANC 2 Coverage
    {id: "sB79w2hiLp8"}  // the id of ANC 3 Coverage
  ]
}]
```



Table: Pivot table plug-in configuration

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| url | string | Oui || Base URL of the DHIS2 server |
| Nom d'utilisateur | string | Yes (if cross-domain) || Used for authentication if the server is running on a different domain |
| password | string | Yes (if cross-domain) || Used for authentication if the server is running on a different domain |
| loadingIndicator | boolean | Non || Whether to show a loading indicator before the table appears |



Table: Pivot table configuration

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| el | string | Oui || Identifier of the HTML element to render the table in your web page |
| identifiant | string | Non || Identifier of a pre-defined table (favorite) in DHIS2 |
| columns | array | Yes (if no id provided) || Data dimensions to include in table as columns |
| rows | array | Yes (if no id provided) || Data dimensions to include in table as rows |
| filter | array | Non || Data dimensions to include in table as filters |
| title | string | Non || Show a custom title above the table |
| showColTotals | boolean | Non | true &#124; false | Whether to display totals for columns |
| showRowTotals | boolean | Non | true &#124; false | Whether to display totals for rows |
| showColSubTotals | boolean | Non | true &#124; false | Whether to display sub-totals for columns |
| showRowSubTotals | boolean | Non | true &#124; false | Whether to display sub-totals for rows |
| showDimensionLabels | boolean | Non | true &#124; false | Whether to display the name of the dimension top-left in the table |
| hideEmptyRows | boolean | Non | faux &#124; vrai | Whether to hide rows with no data |
| skipRounding | boolean | Non | faux &#124; vrai | Whether to skip rounding of data values |
| completedOnly | boolean | Non | faux &#124; vrai | Whether to only show completed events |
| showHierarchy | boolean | Non | faux &#124; vrai | Whether to extend orgunit names with the name of all anchestors |
| aggregationType | string | Non | "SUM" &#124;"AVERAGE" &#124; "AVERAGE_SUM_ORG_UNIT"&#124;"LAST"&#124;"LAST_AVERAGE_ORG_UNIT"&#124; "COUNT" &#124; "STDDEV" &#124; "VARIANCE" &#124; "MIN" &#124; "MAX" | Override the data element's default aggregation type |
| displayDensity | string | Non | "NORMAL" &#124; "COMFORTABLE" &#124; "COMPACT" | The amount of space inside table cells |
| fontSize | string | Non | "NORMAL" &#124; "LARGE" &#124; "SMALL" | Table font size |
| digitGroupSeparator | string | Non | "SPACE" &#124; "COMMA" &#124; "NONE" | How values are formatted: 1 000 &#124; 1,000 &#124; 1000 |
| legendSet | object | Non || Color the values in the table according to the legend set |
| userOrgUnit | string / array | Non || Organisation unit identifiers, overrides organisation units associated with curretn user, single or array |
| relativePeriodDate | string | Non || Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |

### Embedding charts with the Visualizer chart plug-in { #webapi_chart_plugin } 

In this example, we will see how we can embed good-looking Highcharts
charts (<http://www.highcharts.com>) with data served from a DHIS2
back-end into a Web page. To accomplish this we will use the DHIS2
Visualizer plug-in. The plug-in is written in JavaScript and depends on
the jQuery library. A complete working example can be found at
<http://play.dhis2.org/portal/chart.html>. Open the page in a web
browser and view the source to see how it is set up.

We start by having a look at what the complete html file could look
like. This setup puts two charts on our web page. The first one is
referring to an existing chart. The second is configured inline.

```html
<!DOCTYPE html>
<html>
<head>
  <script src="https://dhis2-cdn.org/v227/plugin/jquery-2.2.4.min.js"></script>
  <script src="https://dhis2-cdn.org/v227/plugin/chart.js"></script>

  <script>
    chartPlugin.url = "https://play.dhis2.org/demo";
    chartPlugin.username = "admin";
    chartPlugin.password = "district";
    chartPlugin.loadingIndicator = true;

    // Referring to an existing chart through the id parameter, render to "report1" div

    var r1 = { el: "report1", id: "R0DVGvXDUNP" };

    // Chart configuration, render to "report2" div

    var r2 = {
      el: "report2",
      columns: [
        {dimension: "dx", items: [{id: "YtbsuPPo010"}, {id: "l6byfWFUGaP"}]}
      ],
      rows: [
        {dimension: "pe", items: [{id: "LAST_12_MONTHS"}]}
      ],
      filters: [
        {dimension: "ou", items: [{id: "USER_ORGUNIT"}]}
      ],

      // All following properties are optional
      title: "Custom title",
      type: "line",
      showValues: false,
      hideEmptyRows: true,
      regressionType: "LINEAR",
      completedOnly: true,
      targetLineValue: 100,
      targetLineTitle: "My target line title",
      baseLineValue: 20,
      baseLineTitle: "My base line title",
      aggregationType: "AVERAGE",
      rangeAxisMaxValue: 100,
      rangeAxisMinValue: 20,
      rangeAxisSteps: 5,
      rangeAxisDecimals: 2,
      rangeAxisTitle: "My range axis title",
      domainAxisTitle: "My domain axis title",
      hideLegend: true
    };

    // Render the charts

    chartPlugin.load(r1, r2);
  </script>
</head>

<body>
  <div id="report1"></div>
  <div id="report2"></div>
</body>
</html>
```

Two files are included in the header section of the HTML document. The
first file is the jQuery JavaScript library (we use the DHIS2 content
delivery network in this case). The second file is the Visualizer chart
plug-in. Make sure the path is pointing to your DHIS2 server
installation.

Now let us have a look at the various options for the charts. One
property is required: *el* (please refer to the table below). Now, if
you want to refer to pre-defined charts already made inside DHIS2 it is
sufficient to provide the additional *id* parameter. If you instead want
to configure a chart dynamically you should omit the id parameter and
provide data dimensions inside a *columns* array, a *rows* array and
optionally a *filters* array instead.

A data dimension is defined as an object with a text property called
*dimension*. This property accepts the following values: *dx*
(indicator, data element, data element operand, data set, event data
item and program indicator), *pe* (period), *ou* (organisation unit) or
the id of any organisation unit group set or data element group set (can
be found in the web api). The data dimension also has an array property
called *items* which accepts objects with an *id* property.

To sum up, if you want to have e.g. "ANC 1 Coverage", "ANC 2 Coverage"
and "ANC 3 Coverage" on the columns in your chart you can make the
following *columns* config:

```json
columns: [{
  dimension: "dx",
  items: [
    {id: "Uvn6LCg7dVU"}, // the id of ANC 1 Coverage
    {id: "OdiHJayrsKo"}, // the id of ANC 2 Coverage
    {id: "sB79w2hiLp8"}  // the id of ANC 3 Coverage
  ]
}]
```



Table: Chart plug-in configuration

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| url | string | Oui || Base URL of the DHIS2 server |
| Nom d'utilisateur | string | Yes (if cross-domain) || Used for authentication if the server is running on a different domain |
| password | string | Yes (if cross-domain) || Used for authentication if the server is running on a different domain |
| loadingIndicator | boolean | Non || Whether to show a loading indicator before the chart appears |



Table: Chart configuration

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| el | string | Oui || Identifier of the HTML element to render the chart in your web page |
| identifiant | string | Non || Identifier of a pre-defined chart (favorite) in DHIS |
| type | string | Non | column &#124; stackedcolumn &#124; bar &#124; stackedbar &#124; line &#124; area &#124; pie &#124; radar &#124; gauge | Chart type |
| columns | array | Yes (if no id provided) || Data dimensions to include in chart as series |
| rows | array | Yes (if no id provided) || Data dimensions to include in chart as category |
| filter | array | Non || Data dimensions to include in chart as filters |
| title | string | Non || Show a custom title above the chart |
| showValues | boolean | Non | faux &#124; vrai | Whether to display data values on the chart |
| hideEmptyRows | boolean | Non | faux &#124; vrai | Whether to hide empty categories |
| completedOnly | boolean | Non | faux &#124; vrai | Whether to only show completed events |
| regressionType | string | Non | "NONE" &#124; "LINEAR" | Show trend lines |
| targetLineValue | number | Non || Display a target line with this value |
| targetLineTitle | string | Non || Display a title on the target line (does not apply without a target line value) |
| baseLineValue | number | Non || Display a base line with this value |
| baseLineTitle | string | Non || Display a title on the base line (does not apply without a base line value) |
| rangeAxisTitle | number | Non || Title to be displayed along the range axis |
| rangeAxisMaxValue | number | Non || Max value for the range axis to display |
| rangeAxisMinValue | number | Non || Min value for the range axis to display |
| rangeAxisSteps | number | Non || Number of steps for the range axis to display |
| rangeAxisDecimals | number | Non || Bumber of decimals for the range axis to display |
| domainAxisTitle | number | Non || Title to be displayed along the domain axis |
| aggregationType | string | Non | "SUM" &#124;"AVERAGE" &#124; "AVERAGE_SUM_ORG_UNIT"&#124;"LAST"&#124;"LAST_AVERAGE_ORG_UNIT"&#124; "COUNT" &#124; "STDDEV" &#124; "VARIANCE" &#124; "MIN" &#124; "MAX" | Override the data element's default aggregation type |
| hideLegend | boolean | Non | faux &#124; vrai | Whether to hide the series legend |
| hideTitle | boolean | Non | faux &#124; vrai | Whether to hide the chart title |
| userOrgUnit | string / array | Non || Organisation unit identifiers, overrides organisation units associated with curretn user, single or array |
| relativePeriodDate | string | Non || Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |

### Embedding maps with the GIS map plug-in { #webapi_map_plugin } 

In this example we will see how we can embed maps with data served from
a DHIS2 back-end into a Web page. To accomplish this we will use the GIS
map plug-in. The plug-in is written in JavaScript and depends on the Ext
JS library only. A complete working example can be found at
<http://play.dhis2.org/portal/map.html>. Open the page in a web browser
and view the source to see how it is set up.

We start by having a look at what the complete html file could look
like. This setup puts two maps on our web page. The first one is
referring to an existing map. The second is configured inline.

```html
<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" type="text/css" href="http://dhis2-cdn.org/v215/ext/resources/css/ext-plugin-gray.css" />
  <script src="http://dhis2-cdn.org/v215/ext/ext-all.js"></script>
  <script src="https://maps.google.com/maps/api/js?sensor=false"></script>
  <script src="http://dhis2-cdn.org/v215/openlayers/OpenLayers.js"></script>
  <script src="http://dhis2-cdn.org/v215/plugin/map.js"></script>

  <script>
    var base = "https://play.dhis2.org/demo";

    // Login - if OK, call the setLinks function

    Ext.onReady( function() {
      Ext.Ajax.request({
        url: base + "dhis-web-commons-security/login.action",
        method: "POST",
        params: { j_username: "portal", j_password: "Portal123" },
        success: setLinks
      });
    });

    function setLinks() {
      DHIS.getMap({ url: base, el: "map1", id: "ytkZY3ChM6J" });

      DHIS.getMap({
        url: base,
        el: "map2",
        mapViews: [{
          columns: [{dimension: "in", items: [{id: "Uvn6LCg7dVU"}]}], // data
          rows: [{dimension: "ou", items: [{id: "LEVEL-3"}, {id: "ImspTQPwCqd"}]}], // organisation units,
          filters: [{dimension: "pe", items: [{id: "LAST_3_MONTHS"}]}], // period
          // All following options are optional
          classes: 7,
          colorLow: "02079c",
          colorHigh: "e5ecff",
          opacity: 0.9,
          legendSet: {id: "fqs276KXCXi"}
        }]
      });
    }
  </script>
</head>

<body>
  <div id="map1"></div>
  <div id="map2"></div>
</body>
</html>
```

Four files and Google Maps are included in the header section of the
HTML document. The first two files are the Ext JS JavaScript library (we
use the DHIS2 content delivery network in this case) and its stylesheet.
The third file is the OpenLayers JavaScript mapping framework
(<http://openlayers.org>) and finally we include the GIS map plug-in.
Make sure the path is pointing to your DHIS2 server
    installation.

    <link rel="stylesheet" type="text/css" href="http://dhis2-cdn.org/v215/ext/resources/css/ext-plugin-gray.css" />
    <script src="http://dhis2-cdn.org/v215/ext/ext-all.js"></script>
    <script src="https://maps.google.com/maps/api/js?sensor=false"></script>
    <script src="http://dhis2-cdn.org/v215/openlayers/OpenLayers.js"></script>
    <script src="http://dhis2-cdn.org/v215/plugin/map.js"></script>

To authenticate with the DHIS2 server we use the same approach as in the
previous section. In the header of the HTML document we include the
following Javascript inside a script element. The *setLinks* method will
be implemented later. Make sure the *base* variable is pointing to your
DHIS2 installation.

    Ext.onReady( function() {
      Ext.Ajax.request({
        url: base + "dhis-web-commons-security/login.action",
        method: "POST",
        params: { j_username: "portal", j_password: "Portal123" },
        success: setLinks
      });
    });

Now let us have a look at the various options for the GIS plug-in. Two
properties are required: *el* and *url* (please refer to the table
below). Now, if you want to refer to pre-defined maps already made in
the DHIS2 GIS it is sufficient to provide the additional *id* parameter.
If you instead want to configure a map dynamically you should omit the id
parameter and provide *mapViews* (layers) instead. They should be
configured with data dimensions inside a *columns* array, a *rows* array
and optionally a *filters* array instead.

A data dimension is defined as an object with a text property called
*dimension*. This property accepts the following values: *in*
(indicator), *de* (data element), *ds* (data set), *dc* (data element
operand), *pe* (period), *ou* (organisation unit) or the id of any
organisation unit group set or data element group set (can be found in
the web api). The data dimension also has an array property called
*items* which accepts objects with an *id* property.

To sum up, if you want to have a layer with e.g. "ANC 1 Coverage" in
your map you can make the following *columns* config:

```json
columns: [{
  dimension: "in", // could be "in", "de", "ds", "dc", "pe", "ou" or any dimension id
  items: [{id: "Uvn6LCg7dVU"}], // the id of ANC 1 Coverage
}]
```



Table: GIS map plug-in configuration

| Param | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| el | string | Oui || Identifier of the HTML element to render the map in your web page |
| url | string | Oui || Base URL of the DHIS2 server |
| identifiant | string | Non || Identifier of a pre-defined map (favorite) in DHIS |
| baseLayer | string/boolean | Non | 'gs', 'googlestreets' &#124; 'gh', 'googlehybrid' &#124; 'osm', 'openstreetmap' &#124; false, null, 'none', 'off' | Show background map |
| hideLegend | boolean | Non | faux &#124; vrai | Hide legend panel |
| mapViews | array | Yes (if no id provided) || Array of layers |

If no id is provided you must add map view objects with the following
config options:



Table: Map plug-in configuration

||||||
|---|---|---|---|---|
| layer | string | Non | "thematic1" &#124; "thematic2" &#124; "thematic3" &#124; "thematic4" &#124; "boundary" &#124; "facility" &#124; | The layer to which the map view content should be added |
| columns | array | Oui || Indicator, data element, data operand or data set (only one will be used) |
| rows | array | Oui || Organisation units (multiple allowed) |
| filter | array | Oui || Period (only one will be used) |
| classes | entier | Non | 5 &#124; 1-7 | The number of automatic legend classes |
| method | entier | Non | 2 &#124; 3 | Legend calculation method where 2 = equal intervals and 3 = equal counts |
| colorLow | string | Non | "ff0000" (red) &#124; Any hex color | The color representing the first automatic legend class |
| colorHigh | string | Non | "00ff00" (green) &#124; Any hex color | The color representing the last automatic legend class |
| radiusLow | entier | Non | 5 &#124; Any integer | Only applies for facilities (points) - radius of the point with lowest value |
| radiusHigh | entier | Non | 15 &#124; Any integer | Only applies for facilities (points) - radius of the point with highest value |
| opacity | double | Non | 0.8 &#124; 0 - 1 | Opacity/transparency of the layer content |
| legendSet | object | Non || Pre-defined legend set. Will override the automatic legend set. |
| labels | boolean/object | Non | false &#124; true &#124; object properties: fontSize (integer), color (hex string), strong (boolean), italic (boolean) | Show labels on the map |
| width | entier | Non || Width of map |
| height | entier | Non || Height of map |
| userOrgUnit | string / array | Non || Organisation unit identifiers, overrides organisation units associated with current user, single or array |

We continue by adding one pre-defined and one dynamically configured map
to our HTML document. You can browse the list of available maps using
the Web API here: <http://play.dhis2.org/demo/api/33/maps>.

```javascript
function setLinks() {
  DHIS.getMap({ url: base, el: "map1", id: "ytkZY3ChM6J" });

  DHIS.getMap({
 url: base,
 el: "map2",
 mapViews: [
   columns: [ // Chart series
  columns: [{dimension: "in", items: [{id: "Uvn6LCg7dVU"}]}], // data
   ],
   rows: [ // Chart categories
  rows: [{dimension: "ou", items: [{id: "LEVEL-3"}, {id: "ImspTQPwCqd"}]}], // organisation units
   ],
   filters: [
  filters: [{dimension: "pe", items: [{id: "LAST_3_MONTHS"}]}], // period
   ],
   // All following options are optional
   classes: 7,
   colorLow: "02079c",
   colorHigh: "e5ecff",
   opacity: 0.9,
   legendSet: {id: "fqs276KXCXi"}
 ]
  });
}
```

Finally we include some *div* elements in the body section of the HTML
document with the identifiers referred to in the plug-in JavaScript.

```html
<div id="map1"></div>
<div id="map2"></div>
```

To see a complete working example please visit
<http://play.dhis2.org/portal/map.html>.



# Analyse  { #analytics } 

## Analytics { #webapi_analytics } 

To access analytical, aggregated data in DHIS2 you can work with the
*analytics* resource. The analytics resource is powerful as it lets you
query and retrieve data aggregated along all available data dimensions.
For instance, you can ask the analytics resource to provide the
aggregated data values for a set of data elements, periods and
organisation units. Also, you can retrieve the aggregated data for a
combination of any number of dimensions based on data elements and
organisation unit group sets.

    /api/33/analytics

### Request query parameters { #webapi_analytics_query_parameters } 

The analytics resource lets you specify a range of query parameters:



Table: Query parameters

| Paramètre de requête | Obligatoire | Description | Options (par défaut en premier) |
|---|---|---|---|
| dimension | Oui | Dimensions and dimension items to be retrieved, repeated for each. | Any dimension |
| filter | Non | Filters and filter items to apply to the query, repeated for each. | Any dimension |
| aggregationType | Non | Aggregation type to use in the aggregation process. | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; LAST &#124; LAST_AVERAGE_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX |
| measureCriteria | Non | Filters for the data/measures. | EQ &#124; GT &#124; GE &#124; LT &#124; LE |
| preAggregationMeasureCriteria | Non | Filters for the data/measure, applied before aggregation is performed. | EQ &#124; GT &#124; GE &#124; LT &#124; LE |
| date de début | Non | Start date for a date range. Will be applied as a filter. Can not be used together with a period dimension or filter. | Date |
| date de fin | Non | End date for date range. Will be applied as a filter. Can not be used together with a period dimension or filter. | Date |
| skipMeta | Non | Exclude the metadata part of the response (improves performance). | faux &#124; vrai |
| skipData | Non | Exclude the data part of the response. | faux &#124; vrai |
| skipRounding | Non | Skip rounding of data values, i.e. provide full precision. | faux &#124; vrai |
| hierarchyMeta | Non | Include names of organisation unit ancestors and hierarchy paths of organisation units in the metadata. | faux &#124; vrai |
| ignoreLimit | Non | Ignore limit on max 50 000 records in response - use with care. | faux &#124; vrai |
| tableLayout | Non | Use plain data source or table layout for the response. | faux &#124; vrai |
| hideEmptyRows | Non | Hides empty rows in response, applicable when table layout is true. | faux &#124; vrai |
| hideEmptyColumns | Non | Hides empty columns in response, applicable when table layout is true. | faux &#124; vrai |
| showHierarchy | Non | Display full org unit hierarchy path together with org unit name. | faux &#124; vrai |
| includeNumDen | Non | Include the numerator and denominator used to calculate the value in the response. | faux &#124; vrai |
| includeMetadataDetails | Non | Include metadata details to raw data response. | faux &#124; vrai |
| displayProperty | Non | Property to display for metadata. | NAME &#124; SHORTNAME |
| outputIdScheme | Non | Identifier scheme used for metadata items in the query response. It accepts identifier, code or attributes. | UID &#124; UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| outputOrgUnitIdScheme | Non | Identifier scheme used for metadata items in the query response. This parameter overrides the "outputIdScheme" specifically for for Org Units. It accepts identifier, code or attributes. | UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| outputDataElementIdScheme | Non | Identifier scheme used for metadata items in the query response. This parameter overrides the "outputIdScheme" specifically for Data Elements. It accepts identifier, code or attributes. | UUID &#124; CODE &#124; NAME &#124; ATTRIBUTE:<ID\> |
| inputIdScheme | Non | Identifier scheme to use for metadata items in the query request, can be an identifier, code or attributes. | UID &#124; CODE &#124; ATTRIBUTE:<ID\> |
| approvalLevel | Non | Include data which has been approved at least up to the given approval level, refers to identifier of approval level. | Identifier of approval level |
| relativePeriodDate | Non | Date used as basis for relative periods. | Date. |
| userOrgUnit | Non | Explicitly define the user org units to utilize, overrides organisation units associated with the current user, multiple identifiers can be separated by semicolon. | Organisation unit identifiers. |
| columns | Non | Dimensions to use as columns for table layout. | Any dimension (must be query dimension) |
| rows | Non | Dimensions to use as rows for table layout. | Any dimension (must be query dimension) |
| Ordre | Non | Specify the ordering of rows based on value. | ASC &#124; DESC |
| timeField | Non | The time field to base event aggregation on. Applies to event data items only. Can be a predefined option or the ID of an attribute or data element with a time-based value type. | EVENT_DATE &#124; ENROLLMENT_DATE &#124; INCIDENT_DATE &#124; DUE_DATE &#124; COMPLETED_DATE &#124; CREATED &#124; LAST_UPDATED &#124; <Attribute ID\> &#124; <Data element ID\> |
| orgUnitField | Non | The organisation unit field to base event aggregation on. Applies to event data items only. Can be the ID of an attribute or data element with the Organisation unit value type. The default option is specified as omitting the query parameter. <Attribute ID\> &#124; <Data element ID\> | <Attribute ID\> &#124; <Data element ID\> |

The *dimension* query parameter defines which dimensions should be
included in the analytics query. Any number of dimensions can be
specified. The dimension parameter should be repeated for each dimension
to include in the query response. The query response can potentially
contain aggregated values for all combinations of the specified
dimension items.

The *filter* parameter defines which dimensions should be used as
filters for the data retrieved in the analytics query. Any number of
filters can be specified. The filter parameter should be repeated for
each filter to use in the query. A filter differs from a dimension in
that the filter dimensions will not be part of the query response
content, and that the aggregated values in the response will be
collapsed on the filter dimensions. In other words, the data in the
response will be aggregated on the filter dimensions, but the filters
will not be included as dimensions in the actual response. As an
example, to query for certain data elements filtered by the periods and
organisation units you can use the following URL:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&filter=pe:2014Q1;2014Q2
      &filter=ou:O6uvpzGd5pu;lc3eMKXaEfw

The *aggregationType* query parameter lets you define which aggregation
operator should be used for the query. By default, the aggregation
operator defined for data elements included in the query will be used.
If your query does not contain any data elements but does include data
element groups, the aggregation operator of the first data element in
the first group will be used. The order of groups and data elements is
undefined. This query parameter allows you to override the default and
specify a specific aggregation operator. As an example, you can set the
aggregation operator to "count" with the following URL:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2014Q1&dimension=ou:O6uvpzGd5pu
      &aggregationType=COUNT

The *measureCriteria* query parameter lets you filter out ranges of data
records to return. You can instruct the system to return only records
where the aggregated data value is equal, greater than, greater or
equal, less than or less or equal to certain values. You can specify any
number of criteria on the following format, where *criteria* and
*value* should be substituted with real values:

    /api/33/analytics?measureCriteria=criteria:value;criteria:value

As an example, the following query will return only records where the
data value is greater or equal to 6500 and less than 33000:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&measureCriteria=GE:6500;LT:33000

Similar to *measureCriteria*, the *preAggregationMeasureCriteria* query
parameter lets you filter out data, only before aggregation is
performed. For example, the following query only aggregates data where
the original value is within the criteria defined:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014
      &dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw&preAggregationMeasureCriteria=GE:10;LT:100

The *startDate* and *endDate* parameters can be used to specify a custom
date range to aggregate over. When specifying a date range you can not
specify relative nor fixed periods as dimension or filter. The date range
will filter the analytics response. You can use it like this:

    /api/33/analytics.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=ou:ImspTQPwCqd&startDate=2018-01-01&endDate=2018-06-01

In order to have the analytics resource generate the data in the shape
of a ready-made table, you can provide the *tableLayout* parameter with
true as value. Instead of generating a plain, normalized data source,
the analytics resource will now generate the data in a table layout. You
can use the *columns* and *rows* parameters with dimension identifiers
separated by semi-colons as values to indicate which ones to use as
table columns and rows. The column and rows dimensions must be present
as a data dimension in the query (not a filter). Such a request can look
like this:

    /api/33/analytics.html?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU&dimension=pe:2014Q1;2014Q2
      &dimension=ou:O6uvpzGd5pu&tableLayout=true&columns=dx;ou&rows=pe

The *order* parameter can be used for analytics resource to generate
ordered data. The data will be ordered in ascending (or descending) order
of values. An example request for ordering the values in descending
order is:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:LAST_12_MONTHS
      &dimension=ou:O6uvpzGd5pu&order=DESC

### Dimensions and items { #webapi_analytics_dimensions_and_items } 

DHIS2 features a multi-dimensional data model with several fixed and
dynamic data dimensions. The fixed dimensions are the data element,
period (time) and organisation unit dimension. You can dynamically add
dimensions through categories, data element group sets and organisation
unit group sets. The table below displays the available data dimensions
in DHIS2. Each data dimension has a corresponding *dimension
identifier*, and each dimension can have a set of *dimension items*:



Table: Dimensions and dimension items

| Dimension | Dimension id | Dimension items |
|---|---|---|
| Data elements, indicators, data set reporting rate metrics, data element operands, program indicators, program data elements, program attributes, validation rules | dx | Data element, indicator, data set reporting rate metrics, data element operand, program indicator, program attribute identifiers, keyword DE_GROUP-<group-id\>, IN_GROUP-<group-id\>, use <dataelement-id\>.<optioncombo-id\> for data element operands, <program-id\>.<dataelement-id\> for program data elements, <program-id\>.<attribute-id\> for program attributes, <validationrule-id\> for validation results. |
| Periods (time) | pe | ISO periods and relative periods, see "date and period format" |
| Hiérarchie d'unités d'organisation | ou | Organisation unit identifiers, and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |
| Combinaisons d'options de catégories | co | Category option combo identifiers  (omit to get all items) |
| Attribute option combinations | ao | Category option combo identifiers (omit to get all items) |
| Catégories | <category id\> | Category option identifiers (omit to get all items) |
| Des ensembles de groupes d'éléments de données | <group set id\> | Data element group identifiers (omit to get all items) |
| Ensembles de groupes d'unités d'organisation | <group set id\> | Organisation unit group identifiers (omit to get all items) |
| Category option group sets | <group set id\> | Category option group identifiers (omit to get all items) |

It is not necessary to be aware of which objects are used for the
various dynamic dimensions when designing analytics queries. You can get
a complete list of dynamic dimensions by visiting this URL in the Web API:

    /api/33/dimensions

If you want to retrieve only the dimensional items for a given dynamic dimension you can
use the exemple below. The pagination is disabled by default. It can be enabled by adding
the pagination parameter `paging=true` to the URL.

    /api/33/dimensions/J5jldMd8OHv/items?paging=true

The base URL to the analytics resource is `/api/analytics`. To request
specific dimensions and dimension items you can use a query string on
the following format, where `dim-id` and `dim-item` should be substituted with real values:

    /api/33/analytics?dimension=dim-id:dim-item;dim-item&dimension=dim-id:dim-item;dim-item

As illustrated above, the dimension identifier is followed by a colon
while the dimension items are separated by semi-colons. As an example, a
query for two data elements, two periods and two organisation units can
be done with the following URL:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2016Q1;2016Q2&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

To query for data broken down by category option combinations instead of
data element totals you can include the category dimension in the query
string, for instance like this:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=co&dimension=pe:201601&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

When selecting data elements you can also select all data elements in a
group as items by using the DE_GROUP-<id> syntax:

    /api/33/analytics?dimension=dx:DE_GROUP-h9cuJOkOwY2
      &dimension=pe:201601&dimension=ou:O6uvpzGd5pu

When selecting data set reporting rates, the syntax contains a data
set identifier followed by a reporting rate metric:

    /api/33/analytics?dimension=dx:BfMAe6Itzgt.REPORTING_RATE;BfMAe6Itzgt.ACTUAL_REPORTS
      &dimension=pe:201601&dimension=ou:O6uvpzGd5pu

To query for program data elements (of tracker domain type) you can get
those by specifying the program for each data element using the
<program-id>.<dataelement-id> syntax:

    /api/33/analytics.json?dimension=dx:eBAyeGv0exc.qrur9Dvnyt5;eBAyeGv0exc.GieVkTxp4HH
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

To query for program attributes (tracked entity attributes) you can get
those by specifying the program for each attribute using the
<program.id>.<attribute-id> syntax:

    /api/33/analytics.json?dimension=dx:IpHINAT79UW.a3kGcGDCuk6;IpHINAT79UW.UXz7xuGCEhU
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:ImspTQPwCqd

To query for organisation unit group sets and data elements you can use
the following URL. Notice how the group set identifier is used as
a dimension identifier and the groups as dimension items:

    /api/33/analytics?dimension=Bpx0589u8y0:oRVt7g429ZO;MAs88nJc9nL
      &dimension=pe:2016&dimension=ou:ImspTQPwCqd

To query for data elements and categories you can use this URL. Use the
category identifier as a dimension identifier and the category options as
dimension items:

    /api/33/analytics?dimension=dx:s46m5MS0hxu;fClA2Erf6IO&dimension=pe:2016
      &dimension=YNZyaJHiHYq:btOyqprQ9e8;GEqzEKCHoGA&filter=ou:ImspTQPwCqd

To query using relative periods and organisation units associated with
the current user you can use a URL like this:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:LAST_12_MONTHS&dimension=ou:USER_ORGUNIT

When selecting organisation units for a dimension you can select an
entire level optionally constrained by any number of boundary
organisation units with the `LEVEL-<level>` syntax. Boundary refers to a
top node in a sub-hierarchy, meaning that all organisation units at the
given level below the given boundary organisation unit in the hierarchy
will be included in the response, and is provided as regular organisation unit
dimension items. The level value can either be a numerical level or refer to the identifier
of the organisation unit level entity. A simple query for all org units at level three:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016&dimension=ou:LEVEL-3

A query for level three and four with two boundary org units can be
specified like this:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:LEVEL-3;LEVEL-4;O6uvpzGd5pu;lc3eMKXaEf

When selecting organisation units you can also select all organisation
units in an organisation unit group to be included as dimension items
using the OU_GROUP-<id> syntax. The organisation units in the groups
can optionally be constrained by any number of boundary organisation
units. Both the level and the group items can be repeated any number of
times:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD&dimension=pe:2016
      &dimension=ou:OU_GROUP-w0gFTTmsUcF;OU_GROUP-EYbopBOJWsW;O6uvpzGd5pu;lc3eMKXaEf

You can utilize identifier schemes for the metadata part of the
analytics response with the outputIdScheme property like this. You can
use ID, code and attributes as identifier scheme:

    /api/33/analytics?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &dimension=pe:2017Q1;2017Q2&dimension=ou:O6uvpzGd5pu&outputIdScheme=CODE

A few things to be aware of when using the analytics resource are listed
below.

  - Data elements, indicator, data set reporting rates, program data
    elements and program indicators are part of a common data dimension,
    identified as "dx". This means that you can use any of data
    elements, indicators and data set identifiers together with the "dx"
    dimension identifier in a query.

  - For the category, data element group set and organisation unit group
    set dimensions, all dimension items will be used in the query if no
    dimension items are specified.

  - For the period dimension, the dimension items are ISO period
    identifiers and/or relative periods. Please refer to the section
    above called "Date and period format" for the period format and
    available relative periods.

  - For the organisation unit dimension, you can specify the items to be
    the organisation unit or sub-units of the organisation unit
    associated with the user currently authenticated for the request
    using the keys `USER_ORGUNIT` or `USER_ORGUNIT_CHILDREN` as items,
    respectively. You can also specify organisation unit identifiers
    directly, or a combination of both.

  - For the organisation unit dimension, you can specify the organisation
    hierarchy level and the boundary unit to use for the request on the
    format `LEVEL-<level>-<boundary-id>`; as an example
    `LEVEL-3-ImspTQPwCqd` implies all organisation units below the given
    boundary unit at level 3 in the hierarchy.

  - For the organisation unit dimension, the dimension items are the
    organisation units and their sub-hierarchy - data will be aggregated
    for all organisation units below the given organisation unit in the
    hierarchy.

  - You cannot specify dimension items for the category option
    combination dimension. Instead, the response will contain the items
    which are linked to the data values.

### The dx dimension { #webapi_analytics_dx_dimension } 

The `dx` dimension is a special dimension which can contain all of the
following data types.



Table: Data dx dimension types

| Type | Syntax | Description | Source des données |
|---|---|---|---|
| Indicateur | <indicator-id\> | Indicator identifier. | Aggregated data |
| Indicator grop | IN_GROUP-<indicatorgroup-id\> | Keyword followed by an indicator group identifier. Will include all indicators in the group in the response. | Aggregated data |
| Élément de données | <dataelement-id\> | Identifiant de l'élément de données. | Aggregated data |
| Groupe d'éléments de données | DE_GROUP-<dataelementgroup-id\> | Keyword followed by a data element group identifier. Will include all data elements in the group in the response. | Aggregated data |
| Data element operand | <dataelement-id\>.<categoryoptcombo-id\>.<attributeoptcombo-id\> | Data element identifier followed by one or both of category option combination and attribute option combo identifier. Wildcard "\*" symbol can be used to indicate any option combination value. The attribute option combination identifier can be completely left out. | Données agrégées |
| Ensemble de données | <dataset-id\>.<reporting-rate-metric\> | Data set identifier followed by reporting rate metric. Can be REPORTING_RATE &#124; REPORTING_RATE_ON_TIME &#124; ACTUAL_REPORTS &#124; ACTUAL_REPORTS_ON_TIME &#124; EXPECTED_REPORTS. | Data set completeness registrations |
| Program data element | <program-id\>.<dataelement-id\> | Program identifier followed by data element identifier. Reads from events within the specified program. | Events from the given program |
| Indicateur de programme | <programindicator-id\> | Program indicator identifier. Reads from events from within the program associated with the program identifier. | Events from the program of the program indicator |
| Validation result | <validationrule-id\> | Validation rule identifier. Will include validation rule violations for the validation rule, requires that validation results are generated and persisted. | Validation results |

Items from all of the various `dx` types can be combined in an analytics
request. An example looks like this:

    /api/33/analytics.json
      ?dimension=dx:Uvn6LCg7dVU;BfMAe6Itzgt.REPORTING_RATE;IpHINAT79UW.a3kGcGDCuk6
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

The group syntax can be used together with any other item as well. An
example looks like this:

    /api/33/analytics.json
      ?dimension=dx:DE_GROUP-qfxEYY9xAl6;IN_GROUP-oehv9EO3vP7;BfMAe6Itzgt.REPORTING_RATE
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

Data element operands can optionally specify attribute option
combinations and use wildcards e.g. to specify all category option
combination values:

    /api/33/analytics.json
      ?dimension=dx:Uvn6LCg7dVU.*.j8vBiBqGf6O;Uvn6LCg7dVU.Z4oQs46iTeR
      &dimension=pe:LAST_12_MONTHS&filter=ou:ImspTQPwCqd

> **Tip**
>
> A great way to learn how to use the analytics API is to use the DHIS2
> *pivot table* app. You can play around with pivot tables using the
> various dimensions and items and click Download > Plain data source > JSON
> to see the resulting analytics API calls in the address bar of
> your Web browser.

### Response formats { #webapi_analytics_response_formats } 

The analytics response containing aggregate data can be returned in
various representation formats. As usual, you can indicate interest in a
specific format by appending a file extension to the URL, through the
`Accept` HTTP header or through the `format` query parameter. The
default format is JSON. The available formats and content-types are
listed below.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

  - csv (application/csv)

  - html (text/html)

  - html+css (text/html)

  - xls (application/vnd.ms-excel)

As an example, to request an analytics response in XML format you can
use the following URL:

    /api/33/analytics.xml?dimension=dx:fbfJHSPpUQD
      &dimension=pe:2016&dimension=ou:O6uvpzGd5pu;lc3eMKXaEfw

The analytics responses must be retrieved using the HTTP *GET* method.
This allows for direct linking to analytics responses from Web pages as
well as other HTTP-enabled clients. To do functional testing we can use
the cURL library. By executing this command against the demo database
you will get an analytics response in JSON format:

```bash
curl "play.dhis2.org/demo/api/analytics.json?dimension=dx:eTDtyyaSA7f;FbKK4ofIv5R
  &dimension=pe:2016Q1;2016Q2&filter=ou:ImspTQPwCqd" -u admin:district
```

The JSON response will look like this:

```json
{
  "headers": [
    {
      "name": "dx",
      "column": "Data",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "pe",
      "column": "Period",
      "meta": true,
      "type": "java.lang.String"
    },
    {
      "name": "value",
      "column": "Value",
      "meta": false,
      "type": "java.lang.Double"
    }
  ],
  "height": 4,
  "metaData": {
    "pe": [
      "2016Q1",
      "2016Q2"
    ],
    "ou": [
      "ImspTQPwCqd"
    ],
    "names": {
      "2016Q1": "Jan to Mar 2016",
      "2016Q2": "Apr to Jun 2016",
      "FbKK4ofIv5R": "Measles Coverage <1 y",
      "ImspTQPwCqd": "Sierra Leone",
      "eTDtyyaSA7f": "Fully Immunized Coverage"
    }
  },
  "rows": [
    [
      "eTDtyyaSA7f",
      "2016Q2",
      "81.1"
    ],
    [
      "eTDtyyaSA7f",
      "2016Q1",
      "74.7"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q2",
      "88.9"
    ],
    [
      "FbKK4ofIv5R",
      "2016Q1",
      "84.0"
    ]
  ],
  "width": 3
}
```

The response represents a table of dimensional data. The *headers* array
gives an overview of which columns are included in the table and what
the columns contain. The *column* property shows the column dimension
identifier, or if the column contains measures, the word "Value". The
*meta* property is *true* if the column contains dimension items or
*false* if the column contains a measure (aggregated data values). The
*name* property is similar to the column property, except it displays
"value" in case the column contains a measure. The *type* property
indicates the Java class type of column values.

The *height* and *width* properties indicate how many data columns and
rows are contained in the response, respectively.

The *metaData periods* property contains a unique, ordered array of the
periods included in the response. The *metaData ou* property contains an
array of the identifiers of organisation units included in the response.
The *metaData names* property contains a mapping between the identifiers
used in the data response and the names of the objects they represent.
It can be used by clients to substitute the identifiers within the data
response with names in order to give a more meaningful view of the data
table.

The *rows* array contains the dimensional data table. It contains
columns with dimension items (object or period identifiers) and a column
with aggregated data values. The example response above has a
data/indicator column, a period column and a value column. The first
column contains indicator identifiers, the second contains ISO period
identifiers and the third contains aggregated data values.

### Constraints and validation { #webapi_analytics_constraints } 

There are several constraints to the input parameters you can provide to the
analytics resource. If any of the constraints are violated, the API will
return a *409 Conflict* response and a response message looking similar to this:

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "Only a single indicator can be specified as filter",
  "errorCode": "E7108"
}
```

The `httpStatus` and `httpStatusCode` fields indicate the HTTP status and
status code per the HTTP specification. The `messsage` field provides a
human-readable description of the validation error. The `errorCode` field
provides a machine-readable code which can be used by clients to handle
validation errors. The possible validation errors for the aggregate analytics
API are described in the table below.

| Code d'erreur | Message |
| ---------- | ------- |
| E7100      | Query parameters cannot be null |
| E7101      | At least one dimension must be specified |
| E7102      | At least one data dimension item or data element group set dimension item must be specified |
| E7103      | Dimensions cannot be specified as dimension and filter simultaneously |
| E7104      | At least one period as dimension or filter, or start and dates, must be specified |
| E7105      | Periods and start and end dates cannot be specified simultaneously |
| E7106      | Start date cannot be after end date |
| E7107      | Start and end dates cannot be specified for reporting rates |
| E7108      | Only a single indicator can be specified as filter |
| E7109      | Only a single reporting rate can be specified as filter |
| E7110      | Category option combos cannot be specified as filter |
| E7111      | Dimensions cannot be specified more than once |
| E7112      | Reporting rates can only be specified together with dimensions of type |
| E7113      | Assigned categories cannot be specified when data elements are not specified |
| E7114      | Assigned categories can only be specified together with data elements, not indicators or reporting rates |
| E7115      | Data elements must be of a value and aggregation type that allow aggregation |
| E7116      | Indicator expressions cannot contain cyclic references |
| E7117      | A data dimension 'dx' must be specified when output format is DATA_VALUE_SET |
| E7118      | A period dimension 'pe' must be specified when output format is DATA_VALUE_SET |
| E7119      | An organisation unit dimension 'ou' must be specified when output format is DATA_VALUE_SET |
| E7120      | User is not allowed to view org unit |
| E7121      | User is not allowed to read data for object |
| E7122      | Data approval level does not exist |
| E7123      | Current user is constrained by a dimension but has access to no dimension items |
| E7124      | Dimension is present in query without any valid dimension options |
| E7125      | Dimension identifier does not reference any dimension |
| E7126      | Column must be present as dimension in query |
| E7127      | Row must be present as dimension in query |
| E7128      | Query result set exceeded max limit |
| E7129      | Program is specified but does not exist |
| E7130      | Program stage is specified but does not exist |
| E7131      | Query failed, likely because the query timed out |

### Data value set format { #webapi_analytics_data_value_set_format } 

The analytics *dataValueSet* resource allows for returning aggregated
data in the data value set format. This format represents raw data
values, as opposed to data which has been aggregated along various
dimensions. Exporting aggregated data as regular data values is useful
for data exchange between systems when the target system contains data
of finer granularity compared to what the destination system is storing.

As an example, one can specify an indicator in the target system to
summarize data for multiple data elements and import this data for a
single data element in the destination system. As another example, one
can aggregate data collected at organisation unit level 4 in the target
system to level 2 and import that data in the destination system.

You can retrieve data in the raw data value set format from the
dataValueSet resource:

    /api/33/analytics/dataValueSet

The following resource representations are supported:

  - json (application/json)

  - xml (application/xml)

When using the data value set format, exactly three dimensions must be
specified as analytics dimensions with at least one dimension item each:

  - Data (dx)

  - Period (pe)

  - Organisation unit (ou)

Any other dimension will be ignored. Filters will be applied as with
regular analytics requests. Note that any data dimension type can be
specified, including indicators, data elements, data element operands,
data sets and program indicators.

An example request which aggregates data for specific indicators,
periods and organisation units and returns it as regular data values in
XML looks like this:

    api/analytics/dataValueSet.xml?dimension=dx:Uvn6LCg7dVU;OdiHJayrsKo
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:lc3eMKXaEfw;PMa2VCrupOd

A request which aggregates data for data element operands and uses CODE
as output identifier scheme looks like the below. When defining the
output identifier scheme, all metadata objects part of the response are
affected:

    api/analytics/dataValueSet.json?dimension=dx:fbfJHSPpUQD.pq2XI5kz2BY;fbfJHSPpUQD.PT59n8BQbqM
      &dimension=pe:LAST_12_MONTHS&dimension=ou:ImspTQPwCqd&outputIdScheme=CODE

When using attribute-based identifier schemes for export there is a risk
of producing duplicate data values. The boolean query parameter
duplicatesOnly can be used for debugging purposes to return only
duplicates data values. This response can be used to clean up the
duplicates:

    api/analytics/dataValueSet.xml?dimension=dx:Uvn6LCg7dVU;OdiHJayrsKo
      &dimension=pe:LAST_4_QUARTERS&dimension=ou:lc3eMKXaEfw&duplicatesOnly=true

### Raw data format { #webapi_analytics_raw_data } 

The analytics *rawData* resource allows for returning the data stored in
the analytics data tables without any aggregation being performed. This
is useful for clients which would like to perform aggregation and
filtering on their own without having to denormalize data in the
available data dimensions themselves.

    /api/analytics/rawData

The following resource representations are supported:

  - json (application/json)

  - csv (application/csv)

This resource follows the syntax of the regular analytics resource. Only
a subset of the query parameters are supported. Additionally, a
*startDate* and *endDate* parameter are available. The supported
parameters are listed in the table below.



Table: Query parameters

| Paramètre de requête | Required / Notes |
|---|---|
| dimension | Oui |
| date de début | No / yyyy-MM-dd |
| date de fin | No / yyyy-MM-dd |
| skipMeta | Non |
| skipData | Non |
| hierarchyMeta | Non |
| showHierarchy | Non |
| displayProperty | Non |
| outputIdScheme | Non |
| outputOrgUnitIdScheme | Non |
| outputDataElementIdScheme | Non |
| inputIdScheme | Non |
| userOrgUnit | Non |

The *dimension* query parameter defines which dimensions (table columns)
should be included in the response. It can optionally be constrained
with items. The *filter* query parameter defines which items and
dimensions (table columns) should be used as a filter for the response.

For the organisation unit dimension, the response will contain data
associated with the organisation unit and all organisation units in the
sub-hierarchy (children in the tree). This is different compared to the
regular analytics resource, where only the explicitly selected
organisation units are included.

To retrieve a response with specific data elements, specific periods,
specific organisation units and all data for two custom dimensions you
can issue a request like this:

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      &dimension=J5jldMd8OHv&dimension=Bpx0589u8y0
      &dimension=pe:LAST_12_MONTHS
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji

The *startDate* and *endDate* parameters allow for fetching data linked
to any period between those dates. This avoids the need for defining all
periods explicitly in the
    request:

    /api/analytics/rawData.json?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      &dimension=J5jldMd8OHv&dimension=Bpx0589u8y0
      &startDate=2015-01-01&endDate=2015-12-31
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji

The *filter* parameter can be used to filter a response without
including that dimension as part of the response, this time in CSV
format:

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU;Jtf34kNZhzP
      &filter=J5jldMd8OHv:uYxK4wmcPqA;tDZVQ1WtwpA
      &startDate=2015-01-01&endDate=2015-12-31
      &dimension=ou:O6uvpzGd5pu

The *outputIdScheme* parameter is useful if you want human readable data
responses as it can be set to *NAME* like this:

    /api/analytics/rawData.csv?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &filter=J5jldMd8OHv:uYxK4wmcPqA;tDZVQ1WtwpA
      &startDate=2017-01-01&endDate=2017-12-31
      &dimension=ou:O6uvpzGd5pu
      &outputIdScheme=NAME

The response from the *rawData* resource will look identical to the
regular analytics resource; the difference is that the response contains
raw, non-aggregated data, suitable for further aggregation by
third-party systems.

### Debugging { #webapi_analytics_debugging } 

When debugging analytics requests it can be useful to examine the data
value source of the aggregated analytics response. The
*analytics/debug/sql* resource will provide an SQL statement that
returns the relevant content of the datavalue table. You can produce
this SQL by doing a GET request with content type "text/html" or
"text/plain" like below. The dimension and filter syntax are identical to
regular analytics queries:

    /api/analytics/debug/sql?dimension=dx:fbfJHSPpUQD;cYeuwXTCPkU
      &filter=pe:2016Q1;2016Q2&filter=ou:O6uvpzGd5pu

## Event analytics { #webapi_event_analytics } 

The event analytics API lets you access aggregated event data and query
*events* captured in DHIS2. This resource lets you retrieve events based
on a program and optionally a program stage, and lets you retrieve and
filter events on any event dimensions.

    /api/33/analytics/events

### Dimensions and items { #webapi_event_analytics_dimensions_items } 

Event dimensions include data elements, attributes, organisation units
and periods. The aggregated event analytics resource will return
aggregated information such as counts or averages. The query analytics
resource will simply return events matching a set of criteria and does
not perform any aggregation. You can specify dimension items in the form
of options from option sets and legends from legend sets for data
elements and attributes which are associated with such. The event
dimensions are listed in the table below.



Table: Event dimensions

| Dimension | Dimension id | Description |
|---|---|---|
| Des éléments de données | <id\> | Data element identifiers |
| Attributs | <id\> | Attribute identifiers |
| Périodes | pe | ISO periods and relative periods, see "date and period format" |
| Unités d’organisation | ou | Organisation unit identifiers and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |
| Ensembles de groupes d'unités d'organisation | <org unit group set id\> | Organisation unit group set identifiers |
| Catégories | <category id\> | Category identifiers (program attribute categories only) |

### Request query parameters { #webapi_event_analytics_request_query_parameters } 

The analytics event API lets you specify a range of query parameters.



Table: Query parameters for both event query and aggregate analytics

| Paramètre de requête | Obligatoire | Description | Options (par défaut en premier) |
|---|---|---|---|
| de paludisme) ». | Oui | Program identifier. | Any program identifier |
| stage | Non | Program stage identifier. | Any program stage identifier |
| date de début | Oui | Start date for events. | Date in yyyy-MM-dd format |
| date de fin | Oui | End date for events. | Date in yyyy-MM-dd format |
| dimension | Oui | Dimension identifier including data elements, attributes, program indicators, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. | Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN |
| filter | Non | Dimension identifier including data elements, attributes, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. ||
| hierarchyMeta | Non | Include names of organisation unit ancestors and hierarchy paths of organisation units in the metadata. | faux &#124; vrai |
| eventStatus | Non | Specify status of events to include. | ACTIVE &#124; COMPLETED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED |
| programStatus | Non | Specify enrollment status of events to include. | ACTIVE &#124; COMPLETED &#124; CANCELLED |
| relativePeriodDate | string | Non | Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |
| columns | Non | Dimensions to use as columns for table layout. | Any dimension (must be query dimension) |
| rows | Non | Dimensions to use as rows for table layout. | Any dimension (must be query dimension) |



Table: Query parameters for event query analytics only

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| ou Mode | Non | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. | DESCENDANTS, CHILDREN, SELECTED |
| asc | Non | Dimensions to be sorted ascending, can reference event date, org unit name and code and any item identifiers. | EVENTDATE &#124; OUNAME &#124; OUCODE &#124; item identifier |
| desc | Non | Dimensions to be sorted descending, can reference event date, org unit name and code and any item identifiers. | EVENTDATE &#124; OUNAME &#124; OUCODE &#124; item identifier |
| coordinatesOnly | Non | Whether to only return events which have coordinates. | faux &#124; vrai |
| coordinateOuFallback | Non | Program instance geometry is applied whenever organization unit geometry is missing. | faux &#124; vrai |
| dataIdScheme | Non | Id scheme to be used for data, more specifically data elements and attributes which have an option set or legend set, e.g. return the name of the option instead of the code, or the name of the legend instead of the legend ID, in the data response. | NAME &#124; CODE &#124; UID |
| page | Non | The page number. Default page is 1. | Numeric positive value |
| taille de la page | Non | The page size. Default size is 50 items per page. | Numeric zero or positive value |



Table: Query parameters for aggregate event analytics only

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| valeur | Non | Value dimension identifier. Can be a data element or an attribute which must be of numeric value type. | Data element or attribute identifier |
| aggregationType | Non | Aggregation type for the value dimension. Default is AVERAGE. | SUM &#124; AVERAGE &#124; AVERAGE_SUM_ORG_UNIT &#124; LAST &#124; LAST_AVERAGE_ORG_UNIT &#124; COUNT &#124; STDDEV &#124; VARIANCE &#124; MIN &#124; MAX |
| showHierarchy | Non | Display full org unit hierarchy path together with org unit name. | faux &#124; vrai |
| displayProperty | Non | Property to display for metadata. | NAME &#124; SHORTNAME |
| sortOrder | Non | Sort the records on the value column in ascending or descending order. | ASC &#124; DESC |
| limite | Non | The maximum number of records to return. Cannot be larger than 10 000. | Numeric positive value |
| outputType | Non | Specify output type for analytical data which can be events, enrollments or tracked entity instances. The two last options apply to programs with registration only. | EVENT &#124; ENROLLMENT &#124; TRACKED_ENTITY_INSTANCE |
| collapseDataDimensions | Non | Collapse all data dimensions (data elements and attributes) into a single dimension in the response. | faux &#124; vrai |
| skipMeta | Non | Exclude the meta data part of the response (improves performance). | faux &#124; vrai |
| skipData | Non | Exclude the data part of the response. | faux &#124; vrai |
| skipRounding | Non | Skip rounding of aggregate data values. | faux &#124; vrai |
| aggregateData | Non | Produce aggregate values for the data dimensions (as opposed to dimension items). | faux &#124; vrai |
| timeField | Non | The time field to base event aggregation on. Applies to event data items only. Can be a predefined option or the ID of an attribute or data element having a time-based value type. | EVENT_DATE &#124; ENROLLMENT_DATE &#124; INCIDENT_DATE &#124; DUE_DATE &#124; COMPLETED_DATE &#124; <Attribute ID\> &#124; <Data element ID\> |
| orgUnitField | Non | The organisation unit field to base event aggregation on. Applies to event data items only. Can be the ID of an attribute or data element with the Organisation unit value type. The default option is specified as omitting the query parameter. <Attribute ID\> &#124; <Data element ID\> | <Attribute ID\> &#124; <Data element ID\> |



Table: Query parameters for cluster event analytics only

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| clusterSize | Oui | Size of clusters in meters. | Numeric positive value |
| coordinateField | Non | Field to base geospatial event analytics on. Default is event. Can be set to identifiers of attributes and data elements of value type coordinate. | EVENT &#124; <attribute-id\> &#124; <dataelement-id\> |
| bbox | Oui | Bounding box / area of events to include in the response on the format "min longitude, min latitude, max longitude , max latitude". | Chaîne |
| includeClusterPoints | Non | Include information about underlying points for each cluster, be careful if cluster represent a very high number of points. | faux &#124; vrai |

### Event query analytics { #webapi_event_query_analytics } 

The *analytics/events/query* resource lets you query for captured
events. This resource does not perform any aggregation, rather it lets
you query and filter for information about events.

    /api/33/analytics/events/query

You can specify any number of dimensions and any number of filters in a
query. Dimension item identifiers can refer to any of data elements,
person attributes, person identifiers, fixed and relative periods and
organisation units. Dimensions can optionally have a query operator and
a filter. Event queries should be on the format described
    below.

    /api/33/analytics/events/query/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve events from the "Inpatient morbidity and
mortality" program between January and October 2016, where the "Gender"
and "Age" data elements are included and the "Age" dimension is filtered
on "18", you can use the following
    query:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu;fdc6uOvgoji&dimension=oZg33kd9taw&dimension=qrur9Dvnyt5:EQ:18

To retrieve events for the "Birth" program stage of the "Child
programme" program between March and December 2016, where the "Weight"
data element, filtered for values larger than
    2000:

    /api/33/analytics/events/query/IpHINAT79UW?stage=A03MvHHogjR&startDate=2016-03-01
      &endDate=2016-12-31&dimension=ou:O6uvpzGd5pu&dimension=UXz7xuGCEhU:GT:2000

Sorting can be applied to the query for the event date of the event and
any dimensions. To sort descending on the event date and ascending on
the "Age" data element dimension you can
    use:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&desc=EVENTDATE&asc=qrur9Dvnyt5

Paging can be applied to the query by specifying the page number and the
page size parameters. If page number is specified but page size is not,
a page size of 50 will be used. If page size is specified but page
number is not, a page number of 1 will be used. To get the third page of
the response with a page size of 20 you can use a query like
    this:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=qrur9Dvnyt5&page=3&pageSize=20

#### Filtering { #filtering } 

Filters can be applied to data elements, person attributes and person
identifiers. The filtering is done through the query parameter value on
the following format:

    &dimension=<item-id>:<operator>:<filter-value>

As an example, you can filter the "Weight" data element for values
greater than 2000 and lower than 4000 like this:

    &dimension=UXz7xuGCEhU:GT:2000&dimension=UXz7xuGCEhU:LT:4000

You can filter the "Age" data element for multiple, specific ages using
the IN operator like this:

    &dimension=qrur9Dvnyt5:IN:18;19;20

You can specify multiple filters for a given item by repeating the
operator and filter components, all separated with semi-colons:

    &dimension=qrur9Dvnyt5:GT:5:LT:15

The available operators are listed below.



Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Like (free text match) |
| IN | Equal to one of multiple values separated by ";" |

#### Response formats { #response-formats } 

The default response representation format is JSON. The requests must be
using the HTTP *GET* method. The following response formats are
supported.

  - json (application/json)

  - jsonp (application/javascript)

  - xls (application/vnd.ms-excel)

As an example, to get a response in Excel format you can use a file
extension in the request URL like this:

    /api/33/analytics/events/query/eBAyeGv0exc.xls?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=oZg33kd9taw&dimension=qrur9Dvnyt5

You can set the hierarchyMeta query parameter to true in order to
include names of all ancestor organisation units in the meta-section of
the response:

    /api/33/analytics/events/query/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:YuQRtpLP10I&dimension=qrur9Dvnyt5:EQ:50&hierarchyMeta=true

The default response JSON format will look similar to this:

```json
{
  "headers": [
    {
      "name": "psi",
      "column": "Event",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ps",
      "column": "Program stage",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "eventdate",
      "column": "Event date",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "coordinates",
      "column": "Coordinates",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "hidden": false,
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "qrur9Dvnyt5": "Age",
      "eBAyeGv0exc": "Inpatient morbidity and mortality",
      "ImspTQPwCqd": "Sierra Leone",
      "O6uvpzGd5pu": "Bo",
      "YuQRtpLP10I": "Badjia",
      "oZg33kd9taw": "Gender"
    },
    "ouHierarchy": {
      "YuQRtpLP10I": "/ImspTQPwCqd/O6uvpzGd5pu"
    }
  },
  "width": 8,
  "height": 4,
  "rows": [
    [
      "yx9IDINf82o",
      "Zj7UnCAulEk",
      "2016-08-05",
      "[5.12, 1.23]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "IPNa7AsCyFt",
      "Zj7UnCAulEk",
      "2016-06-12",
      "[5.22, 1.43]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "ZY9JL9dkhD2",
      "Zj7UnCAulEk",
      "2016-06-15",
      "[5.42, 1.33]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ],
    [
      "MYvh4WAUdWt",
      "Zj7UnCAulEk",
      "2016-06-16",
      "[5.32, 1.53]",
      "Ngelehun",
      "OU_559",
      "YuQRtpLP10I",
      "Female",
      "50"
    ]
  ]
}
```

The *headers* section of the response describes the content of the query
result. The event unique identifier, the program stage identifier, the
event date, the organisation unit name, the organisation unit code and
the organisation unit identifier appear as the first six dimensions in
the response and will always be present. Next comes the data elements,
person attributes and person identifiers which were specified as
dimensions in the request, in this case, the "Gender" and "Age" data
element dimensions. The header section contains the identifier of the
dimension item in the "name" property and a readable dimension
description in the "column" property.

The *metaData* section, *ou* object contains the identifiers of all
organisation units present in the response mapped to a string
representing the hierarchy. This hierarchy string lists the identifiers
of the ancestors (parents) of the organisation unit starting from the
root. The *names* object contains the identifiers of all items in the
response mapped to their names.

The *rows* section contains the events produced by the query. Each row
represents exactly one event.

In order to have the event analytics resource generate the data in the
shape of a ready-made table, you can provide *rows* and *columns*
parameters with requested dimension identifiers separated by semi-colons
as values to indicate which ones to use as table columns and rows.
Instead of generating a plain, normalized data source, the event
analytics resource will now generate the data in table layout. The
column and rows dimensions must be present as a data dimension in the
query (not a filter). Such a request can look like this:

    /api/33/analytics.html+css?dimension=dx:cYeuwXTCPkU;fbfJHSPpUQD&dimension=pe:WEEKS_THIS_YEAR
      &filter=ou:ImspTQPwCqd&displayProperty=SHORTNAME&columns=dx&rows=pe

### Event aggregate analytics { #webapi_event_aggregate_analytics } 

The `/analytics/events/aggregate` resource lets you retrieve *aggregated
numbers* of events captured in DHIS2. This resource lets you retrieve
aggregate data based on a program and optionally a program stage, and
lets you filter on any event dimension.

    /api/33/analytics/events/aggregate

The events aggregate resource does not return the event information
itself, rather the aggregate numbers of events matching the request
query. Event dimensions include data elements, person attributes, person
identifiers, periods and organisation units. Aggregate event queries
should be on the format described below.

    /api/33/analytics/events/aggregate/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve aggregate numbers for events from the
"Inpatient morbidity and mortality" program between January and October
2016, where the "Gender" and "Age" data elements are included, the "Age"
dimension item is filtered on "18" and the "Gender" item is filtered on
"Female", you can use the following query:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:O6uvpzGd5pu&dimension=oZg33kd9taw:EQ:Female&dimension=qrur9Dvnyt5:GT:50

To retrieve data for fixed and relative periods instead of start and end
date, in this case, May 2016 and last 12 months, and the organisation
unit associated with the current user, you can use the following query:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:201605;LAST_12_MONTHS
      &dimension=ou:USER_ORGUNIT;fdc6uOvgo7ji&dimension=oZg33kd9taw

In order to specify "Female" as a filter for "Gender" for the data
response, meaning "Gender" will not be part of the response but will
filter the aggregate numbers in it, you can use the following syntax:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?dimension=pe:2016;
      &dimension=ou:O6uvpzGd5pu&filter=oZg33kd9taw:EQ:Female

To specify the "Bo" organisation unit and the period "2016" as filters,
and the "Mode of discharge" and Gender" as dimensions, where "Gender" is
filtered on the "Male" item, you can use a query like this:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&dimension=oZg33kd9taw:EQ:Male

To create a "Top 3 report" for _Mode of discharge_ you can use the limit
and sortOrder query parameters similar to this:

    /api/33/analytics/events/aggregate/eBAyeGv0exc?filter=pe:2016&filter=ou:O6uvpzGd5pu
      &dimension=fWIAEtYVEGk&limit=3&sortOrder=DESC

To specify a value dimension with a corresponding aggregation type you
can use the value and aggregationType query parameters. Specifying a
value dimension will make the analytics engine return aggregate values
for the values of that dimension in the response as opposed to counts of
events.

    /api/33/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &dimension=ou:ImspTQPwCqd&dimension=pe:LAST_12_MONTHS&dimension=fWIAEtYVEGk
      &value=qrur9Dvnyt5&aggregationType=AVERAGE

To base event analytics aggregation on a specific data element or attribute
of value type date or date time you can use the `timeField` parameter:

    /api/33/analytics/events/aggregate/IpHINAT79UW.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:LAST_12_MONTHS&dimension=cejWyOfXge6&stage=A03MvHHogjR
      &timeField=ENROLLMENT_DATE

To base event analytics aggregation on a specific data element or attribute
of value type organisation unit you can use the `orgUnitField` parameter:

    /api/33/analytics/events/aggregate/eBAyeGv0exc.json?dimension=ou:ImspTQPwCqd
      &dimension=pe:THIS_YEAR&dimension=oZg33kd9taw&stage=Zj7UnCAulEk
      &orgUnitField=S33cRBsnXPo

#### Ranges / legend sets { #ranges-legend-sets } 

For aggregate queries, you can specify a range / legend set for numeric
data element and attribute dimensions. The purpose is to group the
numeric values into ranges. As an example, instead of generating data
for an "Age" data element for distinct years, you can group the
information into age groups. To achieve this, the data element or
attribute must be associated with the legend set. The format is
described below:

    ?dimension=<item-id>-<legend-set-id>

Voici donc un exemple :

    /api/33/analytics/events/aggregate/eBAyeGv0exc.json?stage=Zj7UnCAulEk
      &dimension=qrur9Dvnyt5-Yf6UHoPkdS6&dimension=ou:ImspTQPwCqd&dimension=pe:LAST_MONTH

#### Response formats { #response-formats } 

The default response representation format is JSON. The requests must be
using the HTTP *GET* method. The response will look similar to this:

```json
{
  "headers": [
    {
      "name": "oZg33kd9taw",
      "column": "Gender",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "qrur9Dvnyt5",
      "column": "Age",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "pe",
      "column": "Period",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "value",
      "column": "Value",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "metaData": {
    "names": {
      "eBAyeGv0exc": "Inpatient morbidity and mortality"
    }
  },
  "width": 5,
  "height": 39,
  "rows": [
    [
      "Female",
      "95",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "63",
      "201605",
      "O6uvpzGd5pu",
      "2"
    ],
    [
      "Female",
      "67",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "71",
      "201605",
      "O6uvpzGd5pu",
      "1"
    ],
    [
      "Female",
      "75",
      "201605",
      "O6uvpzGd5pu",
      "14"
    ],
    [
      "Female",
      "73",
      "201605",
      "O6uvpzGd5pu",
      "5"
    ]
  ]
}
```

Note that the max limit for rows to return in a single response is 10 000.
If the query produces more than the max limit, a *409 Conflict* status code
will be returned.

### Event clustering analytics { #webapi_event_clustering_analytics } 

The *analytics/events/cluster* resource provides clustered geospatial
event data. A request looks like this:

    /api/33/analytics/events/cluster/eBAyeGv0exc?startDate=2016-01-01&endDate=2016-10-31
      &dimension=ou:LEVEL-2&clusterSize=100000
      &bbox=-13.2682125,7.3721619,-10.4261178,9.904012&includeClusterPoints=false

The cluster response provides the count of underlying points, the center
point and extent of each cluster. If the `includeClusterPoints` query
parameter is set to true, a comma-separated string with the identifiers
of the underlying events is included. A sample response looks like this:

```json
{
  "headers": [
    {
      "name": "count",
      "column": "Count",
      "type": "java.lang.Long",
      "meta": false
    },
    {
      "name": "center",
      "column": "Center",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "extent",
      "column": "Extent",
      "type": "java.lang.String",
      "meta": false
    },
    {
      "name": "points",
      "column": "Points",
      "type": "java.lang.String",
      "meta": false
    }
  ],
  "width": 3,
  "height": 4,
  "rows": [
    [
      "3",
      "POINT(-13.15818 8.47567)",
      "BOX(-13.26821 8.4St7215,-13.08711 8.47807)",
      ""
    ],
    [
      "9",
      "POINT(-13.11184 8.66424)",
      "BOX(-13.24982 8.51961,-13.05816 8.87696)",
      ""
    ],
    [
      "1",
      "POINT(-12.46144 7.50597)",
      "BOX(-12.46144 7.50597,-12.46144 7.50597)",
      ""
    ],
    [
      "7",
      "POINT(-12.47964 8.21533)",
      "BOX(-12.91769 7.66775,-12.21011 8.49713)",
      ""
    ]
  ]
}
```

### Event count and extent analytics { #webapi_event_count_extent_analytics } 

The *analytics/events/count* resource is suitable for geometry-related
requests for retrieving the count and extent (bounding box) of events
for a specific query. The query syntax is equal to the *events/query*
resource. A request looks like
    this:

    /api/33/analytics/events/count/eBAyeGv0exc?startDate=2016-01-01
      &endDate=2016-10-31&dimension=ou:O6uvpzGd5pu

The response will provide the count and extent in JSON format:

```json
{
  extent: "BOX(-13.2682125910096 7.38679562779441,-10.4261178860988 9.90401290212795)",
  count: 59
}
```

### Constraints and validation { #webapi_event_analytics_constraints } 

There are several constraints to the input parameters you can provide to the
event analytics resource. If any of the constraints are violated, the API will
return a *409 Conflict* response and a response message looking similar to this:

```json
{
  "httpStatus": "Conflict",
  "httpStatusCode": 409,
  "status": "ERROR",
  "message": "At least one organisation unit must be specified",
  "errorCode": "E7200"
}
```

The possible validation errors for the event analytics API are described
in the table below.

| Code d'erreur | Message |
| ---------- | ------- |
| E7200      | Au moins une unité d'organisation doit être spécifiée |
| E7201      | Dimensions cannot be specified more than once |
| E7202      | Query items cannot be specified more than once |
| E7203      | Value dimension cannot also be specified as an item or item filter |
| E7204      | Value dimension or aggregate data must be specified when aggregation type is specified |
| E7205      | Start and end date or at least one period must be specified |
| E7206      | Start date is after end date |
| E7207      | Page number must be a positive number |
| E7208      | Page size must be zero or a positive number |
| E7209      | Limit is larger than max limit |
| E7210      | Time field is invalid |
| E7211      | Org unit field is invalid |
| E7212      | Cluster size must be a positive number |
| E7213      | Bbox is invalid, must be on format: 'min-lng,min-lat,max-lng,max-lat' |
| E7214      | Cluster field must be specified when bbox or cluster size are specified |
| E7215      | Query item cannot specify both legend set and option set |
| E7216      | Query item must be aggregateable when used in aggregate query |
| E7217      | User is not allowed to view event analytics data |
| E7218      | Spatial database support is not enabled |
| E7219      | Data element must be of value type coordinate in order to be used as coordinate field |
| E7220      | Attribute must be of value type coordinate to in order to be used as coordinate field |
| E7221      | Coordinate field is invalid |
| E7222      | Query item or filter is invalid |
| E7223      | Value does not refer to a data element or attribute which are numeric and part of the program |
| E7224      | Item identifier does not reference any data element, attribute or indicator part of the program |
| E7225      | Program stage is mandatory for data element dimensions in enrollment analytics queries |
| E7226      | Dimension is not a valid query item |
| E7227      | Relationship entity type not supported |

## Enrollment analytics { #webapi_enrollment_analytics } 

The enrollment analytics API lets you access aggregated event data and query *enrollments with their event data* captured in DHIS2. This resource lets you retrieve data for a program based on program stages and data elements - in addition to tracked entity attributes. When querying event data for a specific programstages within each enrollment, the data element values for each program stage will be returned as one row in the response from the api. If querying a data element in a program stage that is repeatable, the newest data element value will be used for that data element in the api response.

### Dimensions and items { #webapi_enrollment_analytics_dimensions } 

Enrollment dimensions include data elements, attributes, organisation units and periods. The query analytics resource will simply return enrollments matching a set of criteria and does not perform any aggregation.



Table: Enrollment dimensions

| Dimension | Dimension id | Description |
|---|---|---|
| Data elements in program stages | <program stage id\>.<data element id\> | Data element identifiers must include the program stage when querying data for enrollments.      dimension=edqlbukwRfQ.vANAXwtLwcT |
| Attributs | <id\> | Attribute identifiers |
| Périodes | pe | ISO periods and relative periods, see "date and period format" |
| Unités d’organisation | ou | Organisation unit identifiers and keywords USER_ORGUNIT, USER_ORGUNIT_CHILDREN, USER_ORGUNIT_GRANDCHILDREN, LEVEL-<level\> and OU_GROUP-<group-id\> |

### Enrollment query analytics { #webapi_enrollment_query_analytics } 

The *analytics/enrollments/query* resource lets you query for captured enrollments. This resource does not perform any aggregation, rather it lets you query and filter for information about enrollments.

    /api/33/analytics/enrollments/query

You can specify any number of dimensions and any number of filters in a query. Dimension item identifiers can refer to any of the data elements in program stages, tracked entity attributes, fixed and relative periods and organisation units. Dimensions can optionally have a query operator and a filter. Enrollment queries should be on the format described below.

    /api/33/analytics/enrollments/query/<program-id>?startDate=yyyy-MM-dd&endDate=yyyy-MM-dd
      &dimension=ou:<ou-id>;<ou-id>&dimension=<item-id>&dimension=<item-id>:<operator>:<filter>

For example, to retrieve enrollments in the from the "Antenatal care" program from January 2019, where the "First name" is picked up from attributes, "Chronic conditions" and "Smoking" data elements are included from the first program stage, and "Hemoglobin value" from the following program stage, and only women that have "Cronic conditions" would be included, you can use the following query:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=w75KJ2mc4zz&dimension=WZbXY0S00lP.de0FEHSIoxh:eq:1&dimension=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=edqlbukwRfQ.vANAXwtLwcT
      &startDate=2019-01-01&endDate=2019-01-31

To retrieve enrollments in the from the "Antenatal care" program from last month (relative to the point in time the query is executed), where the "Chronic conditions" and "Smoking" data elements are included from the first program stage, and "Hemoglobin value" from the followup program stage, only including smoking women with hemoglobin less than 20:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&dimension=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD:eq:1&dimension=edqlbukwRfQ.vANAXwtLwcT:lt:20
      &dimension=pe:LAST_MONTH

Sorting can be applied to the query for the enrollment and incident dates of the enrollment:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &columns=w75KJ2mc4zz&dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=pe:LAST_MONTH
      &stage=WZbXY0S00lP&pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

Paging can be applied to the query by specifying the page number and the page size parameters. If page number is specified but page size is not, a page size of 50 will be used. If page size is specified but page number is not, a page number of 1 will be used. To get the second page of the response with a page size of 10 you can use a query like this:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&dimension=w75KJ2mc4zz&dimension=pe:LAST_MONTH
      &dimension=WZbXY0S00lP.sWoqcoByYmD&pageSize=10&page=2

#### Filtering { #filtering } 

Filters can be applied to data elements, person attributes and person identifiers. The filtering is done through the query parameter value on the following format:

    &dimension=<item-id>:<operator>:<filter-value>

As an example, you can filter the "Weight" data element for values greater than 2000 and lower than 4000 like this:

    &dimension=WZbXY0S00lP.UXz7xuGCEhU:GT:2000&dimension=WZbXY0S00lP.UXz7xuGCEhU:LT:4000

You can filter the "Age" attribute for multiple, specific ages using the IN operator like this:

    &dimension=qrur9Dvnyt5:IN:18;19;20

You can specify multiple filters for a given item by repeating the operator and filter components, all separated with semi-colons:

    &dimension=qrur9Dvnyt5:GT:5:LT:15

##### NV keyword { #nv-keyword } 
A special keyword `NV` can be used to filter by `null` values

Filter by AGE is null

    &dimension=qrur9Dvnyt5:EQ:NV

Filter by AGE is not null

    &dimension=qrur9Dvnyt5:NE:NV

Filter by AGE is 18, 19 or is null

    &dimension=qrur9Dvnyt5:IN:18;19;NV

`NV` can be used with `EQ`, `NE` and `IN` operators

##### Operators { #operators } 

The available operators are listed below.

Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Like (free text match) |
| IN | Equal to one of multiple values separated by ";" |

### Request query parameters { #webapi_enrollment_analytics_query_parameters } 

The analytics enrollment query API lets you specify a range of query parameters.



Table: Query parameters for enrollment query endpoint

| Paramètre de requête | Obligatoire | Description | Options (par défaut en premier) |
|---|---|---|---|
| de paludisme) ». | Oui | Program identifier. | Any program identifier |
| date de début | Non | Start date for enrollments. | Date in yyyy-MM-dd format |
| date de fin | Non | End date for enrollments. | Date in yyyy-MM-dd format |
| dimension | Oui | Dimension identifier including data elements, attributes, program indicators, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. | Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN |
| filter | Non | Dimension identifier including data elements, attributes, periods, organisation units and organisation unit group sets. Parameter can be repeated any number of times. Item filters can be applied to a dimension on the format <item-id\>:<operator\>:<filter\>. Filter values are case-insensitive. ||
| programStatus | Non | Specify enrollment status of enrollments to include. | ACTIVE &#124; COMPLETED &#124; CANCELLED |
| relativePeriodDate | string | Non | Date identifier e.g: "2016-01-01". Overrides the start date of the relative period |
| ou Mode | Non | The mode of selecting organisation units. Default is DESCENDANTS, meaning all sub units in the hierarchy. CHILDREN refers to immediate children in the hierarchy; SELECTED refers to the selected organisation units only. | DESCENDANTS, CHILDREN, SELECTED |
| asc | Non | Dimensions to be sorted ascending, can reference enrollment date, incident date, org unit name and code. | ENROLLMENTDATE &#124; INCIDENTDATE&#124; OUNAME &#124; OUCODE |
| desc | Non | Dimensions to be sorted descending, can reference enrollment date, incident date, org unit name and code. | ENROLLMENTDATE &#124; INCIDENTDATE&#124; OUNAME &#124; OUCODE |
| coordinatesOnly | Non | Whether to only return enrollments which have coordinates. | faux &#124; vrai |
| page | Non | The page number. Default page is 1. | Numeric positive value |
| taille de la page | Non | The page size. Default size is 50 items per page. | Numeric zero or positive value |

#### Response formats { #response-formats } 

The default response representation format is JSON. The requests must be using the HTTP *GET* method. The following response formats are supported.

  - json (application/json)
  - xml (application/xml)
  - xls (application/vnd.ms-excel)
  - csv  (application/csv)
  - html (text/html)
  - html+css (text/html)

As an example, to get a response in Excel format you can use a file extension in the request URL like this:

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.xls?dimension=ou:ImspTQPwCqd
      &dimension=WZbXY0S00lP.de0FEHSIoxh&columns=w75KJ2mc4zz
      &dimension=WZbXY0S00lP.sWoqcoByYmD&dimension=pe:LAST_MONTH&stage=WZbXY0S00lP
      &pageSize=10&page=1&asc=ENROLLMENTDATE&ouMode=DESCENDANTS

The default response JSON format will look similar to this:

```json
{
  "headers": [
    {
      "name": "pi",
      "column": "Enrollment",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "tei",
      "column": "Tracked entity instance",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "enrollmentdate",
      "column": "Enrollment date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "incidentdate",
      "column": "Incident date",
      "valueType": "DATE",
      "type": "java.util.Date",
      "hidden": false,
      "meta": true
    },
    {
      "name": "geometry",
      "column": "Geometry",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "longitude",
      "column": "Longitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "latitude",
      "column": "Latitude",
      "valueType": "NUMBER",
      "type": "java.lang.Double",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ouname",
      "column": "Organisation unit name",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "oucode",
      "column": "Organisation unit code",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "ou",
      "column": "Organisation unit",
      "valueType": "TEXT",
      "type": "java.lang.String",
      "hidden": false,
      "meta": true
    },
    {
      "name": "de0FEHSIoxh",
      "column": "WHOMCH Chronic conditions",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    },
    {
      "name": "sWoqcoByYmD",
      "column": "WHOMCH Smoking",
      "valueType": "BOOLEAN",
      "type": "java.lang.Boolean",
      "hidden": false,
      "meta": true
    }
  ],
  "metaData": {
    "pager": {
      "page": 2,
      "total": 163,
      "pageSize": 4,
      "pageCount": 41
    },
    "items": {
      "ImspTQPwCqd": {
        "name": "Sierra Leone"
      },
      "PFDfvmGpsR3": {
        "name": "Care at birth"
      },
      "bbKtnxRZKEP": {
        "name": "Postpartum care visit"
      },
      "ou": {
        "name": "Organisation unit"
      },
      "PUZaKR0Jh2k": {
        "name": "Previous deliveries"
      },
      "edqlbukwRfQ": {
        "name": "Antenatal care visit"
      },
      "WZbXY0S00lP": {
        "name": "First antenatal care visit"
      },
      "sWoqcoByYmD": {
        "name": "WHOMCH Smoking"
      },
      "WSGAb5XwJ3Y": {
        "name": "WHO RMNCH Tracker"
      },
      "de0FEHSIoxh": {
        "name": "WHOMCH Chronic conditions"
      }
    },
    "dimensions": {
      "pe": [],
      "ou": [
        "ImspTQPwCqd"
      ],
      "sWoqcoByYmD": [],
      "de0FEHSIoxh": []
    }
  },
  "width": 12,
  "rows": [
    [
      "A0cP533hIQv",
      "to8G9jAprnx",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "",
      "0.0",
      "0.0",
      "Tonkomba MCHP",
      "OU_193264",
      "xIMxph4NMP1",
      "0",
      "1"
    ],
    [
      "ZqiUn2uXmBi",
      "SJtv0WzoYki",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "",
      "0.0",
      "0.0",
      "Mawoma MCHP",
      "OU_254973",
      "Srnpwq8jKbp",
      "0",
      "0"
    ],
    [
      "lE747mUAtbz",
      "PGzTv2A1xzn",
      "2019-02-02 12:05:00.0",
      "2019-02-02 12:05:00.0",
      "",
      "0.0",
      "0.0",
      "Kunsho CHP",
      "OU_193254",
      "tdhB1JXYBx2",
      "",
      "0"
    ],
    [
      "nmcqu9QF8ow",
      "pav3tGLjYuq",
      "2019-02-03 12:05:00.0",
      "2019-02-03 12:05:00.0",
      "",
      "0.0",
      "0.0",
      "Korbu MCHP",
      "OU_678893",
      "m73lWmo5BDG",
      "",
      "1"
    ]
  ],
  "height": 4
}
```

The *headers* section of the response describes the content of the query result. The enrollment unique identifier, the tracked entity instance identifier, the enrollment date, the incident date, geometry, latitude, longitude, the organisation unit name and the organisation unit code appear as the first dimensions in the response and will always be present. Next comes the data elements, and tracked entity attributes which were specified as dimensions in the request, in this case, the "WHOMCH Chronic conditions" and "WHOMCH smoking" data element dimensions. The header section contains the identifier of the dimension item in the "name" property and a readable dimension description in the "column" property.

The *metaData* section, *ou* object contains the identifiers of all organisation units present in the response mapped to a string representing the hierarchy. This hierarchy string lists the identifiers of the ancestors (parents) of the organisation unit starting from the root. The *names* object contains the identifiers of all items in the response mapped to their names.

The *rows* section contains the enrollments produced by the query. Each row represents exactly one enrollment.

### Analytics across TEI relationships with program indicators { #analytics-across-tei-relationships-with-program-indicators } 

The non-aggregation enrollment analytics API also supports linking Program Indicators to Relationship Types, in order to show the result of a calculation of a specific Program Indicator applied to the related entities of the listed Tracked Entity Instance.

![](resources/images/enrollments/enrollments-pi-relationship.jpg)

For the Program Indicator/Relationship Type link to work, the `/api/33/analytics/enrollments/query` API requires an additional dimension which must include the chosen Relationship Type UID and the chosen Program Indicator UID:

    /api/33/analytics/enrollments/query/<program-id>
      ?dimension=<relationshiptype-id>.<programindicator-id>

For example, to retrieve a list of enrollments from the "WHO RMNCH Tracker" program for January 2019 and display the count of Malaria Cases linked to that Enrollment by "Malaria case linked to person" type of relationship, you can use the following query

    /api/33/analytics/enrollments/query/WSGAb5XwJ3Y.json?dimension=mxZDvSZYxlw.nFICjJluo74
      &startDate=2019-01-01&endDate=2019-01-31    

The API supports using program indicators which are not associated to the "main" program (that is the program ID specified after `/query/`).

## Org unit analytics { #webapi_org_unit_analytics } 

The org unit analytics API provides statistics on org units classified by org unit group sets, i.e. counts of org units per org unit group within org unit group sets.

    GET /api/orgUnitAnalytics?ou=<org-unit-id>&ougs=<org-unit-group-set-id>

The API requires at least one organisation unit and at least one organisation unit group set. Multiple org units and group sets can be provided separated by a semicolon.

### Paramètres de requête{ #request-query-parameters }

The org unit analytics resource lets you specify a range of query parameters:



Table: Org unit analytics query parameters

| Propriété | Description | Obligatoire |
|---|---|---|
| ou | Org unit identifiers, potentially separated by a semicolon. | Oui |
| ougs | Org unit group set identifiers, potentially separated by a semicolon. | Oui |
| columns | Org unit group set identifiers, potentially separated by a semicolon. Defines which group sets are rendered as columns in a table layout. | Non |

The response will contain a column for the parent org unit, columns for each org unit group set part of the request and a column for the count. The statistics include the count of org units which are part of the sub-hierarchy of the org units specified in the request. The response contains a metadata section which specifies the name of each org unit and org unit group part of the response referenced by their identifiers.

The default response is normalized with a single `count` column. The response can be rendered in a table layout by specifying at least one org unit group set using the `columns` query parameter.

### Response formats { #response-formats } 

The org unit analytics endpoint supports the following representation formats:

- json (application/json)
- csv (application/csv)
- xls (application/vnd.ms-excel)
- pdf (application/pdf)

### Exemples { #examples }

To fetch org unit analytics for an org unit and org unit group set:

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw&ougs=J5jldMd8OHv

To fetch org unit analytics data for two org units and two org unit group sets:

    GET /api/orgUnitAnalytics?ou=lc3eMKXaEfw;PMa2VCrupOd&ougs=J5jldMd8OHv;Bpx0589u8y0

To fetch org unit analytics data in table mode with one group set rendered as columns:

    GET /api/orgUnitAnalytics?ou=fdc6uOvgoji;jUb8gELQApl;lc3eMKXaEfw;PMa2VCrupOd
      &ougs=J5jldMd8OHv&columns=J5jldMd8OHv

### Contraintes et validation { #constraints-and-validation }

The possible validation errors specifically for the org unit analytics API are described in the table below. Some errors specified for the aggregate analytics API are also relevant.

| Code d'erreur | Message |
| ---------- | ------- |
| E7300      | Au moins une unité d'organisation doit être spécifiée |
| E7301      | At least one organisation unit group set must be specified |

## Data set report { #webapi_data_set_report } 

Data set reports can be generated through the web api using the
`/dataSetReport` resource. This resource generates reports on data set
and returns the result in the form of an HTML table.

    /api/33/dataSetReport

### Paramètres de requête{ #request-query-parameters }

The request supports the following parameters:



Table: Data set report query parameters

| Paramètre | Description | Type | Obligatoire |
|---|---|---|---|
| ds | Data set to create the report from. | Data set UID | Oui |
| pe | Period(s) to create the report from. May be a comma-separated list. | ISO String | Oui |
| ou | Organisation unit to create the report from. | Organisation unit UID | Oui |
| filter | Filters to be used as filters for the report. Can be repeated any number of times. Follows the analytics API syntax. | One or more UIDs | Non |
| selectedUnitOnly | Whether to use captured data only or aggregated data. | Booléen | Non |

The data set report resource accepts `GET` requests only. The response content type is `application/json` and returns data in a grid. This endpoint works for all types of data sets, including default, section and custom forms.

An example request to retrieve a report for a monthly data set and org unit for October 2018 looks like this:

    GET /api/33/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd&selectedUnitOnly=false

An example request to retrieve a report for a monthly data set and org unit for October, November, and December 2018 looks like this:

    GET /api/33/dataSetReport?ds=BfMAe6Itzgt&pe=201810,201811,201812&ou=ImspTQPwCqd&selectedUnitOnly=false

To get a data set report with a filter you can use the `filter` parameter. In this case, the filter is based on an org unit group set and two org unit groups:

    GET /api/33/dataSetReport?ds=BfMAe6Itzgt&pe=201810&ou=ImspTQPwCqd
      &filter=J5jldMd8OHv:RXL3lPSK8oG;tDZVQ1WtwpA

### Response formats { #response-formats } 

The data set report endpoint supports output in the following formats. You can retrieve a specific endpoint using the file extension or `Accept` HTTP header.

- json (application/json)
- pdf (application/pdf)
- xls (application/vnd.ms-excel)

### Custom forms { #custom-forms } 

A dedicated endpoint is available for data sets with custom HTML forms. This endpoint returns the HTML form content with content type `text/html` with data inserted into it. Note that you can use the general data set report endpoint also for data sets with custom forms; however, that will return the report in JSON format as a grid. This endpoint only works for data sets with custom HTML forms.

    GET /api/33/dataSetReport/custom

The syntax for this endpoint is otherwise equal to the general data set report endpoint. To retrieve a custom HTML data set report you can issue a request like this:

    GET /api/33/dataSetReport/custom?ds=lyLU2wR22tC&pe=201810&ou=ImspTQPwCqd


## Push Analysis { #webapi_push_analysis } 

The push analysis API includes endpoints for previewing a push analysis
report for the logged in user and manually triggering the system to
generate and send push analysis reports, in addition to the normal CRUD
operations. When using the create and update endpoints for push
analysis, the push analysis will be scheduled to run based on the
properties of the push analysis. When deleting or updating a
push analysis to be disabled, the job will also be stopped from running
in the future.

To get an HTML preview of an existing push analysis, you can do a GET
request to the following endpoint:

    /api/33/pushAnalysis/<id>/render

To manually trigger a push analysis job, you can do a POST request to
this endpoint:

    /api/33/pushAnalysis/<id>/run

A push analysis consists of the following properties, where some are
required to automatically run push analysis jobs:



Table: Push analysis properties

| Propriété | Description | Type | Obligatoire |
|---|---|---|---|
| dashboard | Dashboard on which reports are based | Dashboard UID | Oui |
| message | Appears after title in reports | Chaîne | Non |
| recipientUserGroups | A set of user groups who should receive the reports | One or more user Group UID | No. Scheduled jobs without any recipient will be skipped. |
| enabled | Indicated whether this push analysis should be scheduled or not. False by default. | Booléen | Yes. Must be true to be scheduled. |
| schedulingFrequency | The frequency of which reports should be scheduled. | "DAILY", "WEEKLY", "MONTHLY" | No. Push analysis without a frequency will not be scheduled |
| schedulingDayOfFrequency | The day in the frequency the job should be scheduled. | Integer. Any value when frequency is "DAILY". 0-7 when frequency is "WEEKLY". 1-31 when frequency is "MONTHLY" | No. Push analysis without a valid day of frequency for the frequency set will not be scheduled. |

## Data usage analytics { #webapi_usage_analytics } 

The usage analytics API lets you access information about how people are
using DHIS2 based on data analysis. When users access favorites, an
event is recorded. The event consists of the user name, the UID of the
favorite, when the event took place, and the type of event. The
different types of events are listed in the table.

    /api/33/dataStatistics

The usage analytics API lets you retrieve aggregated snapshots of usage
analytics based on time intervals. The API captures user views (for
example the number of times a chart or pivot table has been viewed by a
user) and saved analysis favorites (for example favorite charts and
pivot tables). DHIS2 will capture nightly snapshots which are then
aggregated at request.

### Request query parameters { #webapi_usage_analytics_request_query_parameters } 

The usage analytics (data statistics) API supports two operations:

  - *POST:* creates a view event

  - *GET:* retrieves aggregated statistics

### Create view events (POST) { #webapi_usage_analytics_create_view_events } 

The usage analytics API lets you create event views. The
dataStatisticsEventType parameter describes what type of item was
viewed. The favorite parameter indicates the identifier of the relevant
favorite.

URL that creates a new event view of
    charts:

    POST /api/33/dataStatistics?eventType=CHART_VIEW&favorite=LW0O27b7TdD

A successful save operation returns an HTTP status code 201. The table
below shows the supported types of events.



Table: Supported event types

| Clé | Description |
|---|---|
| REPORT_TABLE_VIEW | Report table (pivot table) view |
| CHART_VIEW | Chart view |
| MAP_VIEW | Map view (GIS) |
| EVENT_REPORT_VIEW | Event report view |
| EVENT_CHART_VIEW | Event chart view |
| DASHBOARD_VIEW | Dashboard view |
| PASSIVE_DASHBOARD_VIEW | Dashboard view (when not explicitly selecting the dashboard) |
| DATA_SET_REPORT_VIEW | Data set report view |

### Retrieve aggregated usage analytics report (GET) { #webapi_aggregated_usage_analytics } 

The usage analytics (data statistics) API lets you specify certain query
parameters when asking for an aggregated report.



Table: Query parameters for aggregated usage analytics (data statistics)

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| date de début | Oui | Start date for period | Date in yyyy-MM-dd format |
| date de fin | Oui | End date for period | Date in yyyy-MM-dd format |
| interval | Oui | Type of interval to be aggregated | DAY, WEEK, MONTH, YEAR |

The startDate and endDate parameters specify the period for which
snapshots are to be used in the aggregation. You must format the dates
as shown above. If no snapshots are saved in the specified period, an
empty list is sent back. The parameter called interval specifies what
type of aggregation will be done.

API query that creates a query for a monthly
    aggregation:

    GET /api/33/dataStatistics?startDate=2014-01-02&endDate=2016-01-01&interval=MONTH

### Retrieve top favorites { #webapi_usage_analytics_top_favorites } 

The usage analytics API lets you retrieve the top favorites used in
DHIS2, and by user.



Table: Query parameters for top favorites

| Paramètre de requête | Obligatoire | Description | Options |
|---|---|---|---|
| eventType | Oui | The data statistics event type | See above table |
| taille de la page | Non | Size of the list returned | For example 5, 10, 25. Default is 25 |
| sortOrder | Non | Descending or ascending | ASC or DESC. Default is DESC. |
| Nom d'utilisateur | Non | If specified, the response will only contain favorites by this user. | For example 'admin' |

The API query can be used without a username, and will then find the top
favorites of the system.

    /api/33/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25&sortOrder=ASC

If the username is specified, the response will only contain the top favorites of that user.

    /api/33/dataStatistics/favorites?eventType=CHART_VIEW&pageSize=25
      &sortOrder=ASC&username=admin

### Response format { #webapi_usage_analytics_response_format } 

You can return the aggregated data in a usage analytics response in
several representation formats. The default format is JSON. The
available formats and content types are:

  - json (application/json)

  - xml (application/xml)

  - html (text/html)

API query that requests a usage analytics response in XML
    format:

    /api/33/dataStatistics.xml?startDate=2014-01-01&endDate=2016-01-01&interval=WEEK

You must retrieve the aggregated usage analytics response with the HTTP
GET method. This allows you to link directly from Web pages and other
HTTP-enabled clients to usage analytics responses. To do functional
testing use the cURL library.

To get an usage analytics response in JSON format:

    /api/33/dataStatistics?startDate=2016-02-01&endDate=2016-02-14&interval=WEEK

The JSON response looks like this:

```json
[
  {
    "year": 2016,
    "week": 5,
    "mapViews": 2181,
    "chartViews": 2227,
    "reportTableViews": 5633,
    "eventReportViews": 6757,
    "eventChartViews": 9860,
    "dashboardViews": 10082,
    "passiveDashboardViews": 0,
    "totalViews": 46346,
    "averageViews": 468,
    "averageMapViews": 22,
    "averageChartViews": 22,
    "averageReportTableViews": 56,
    "averageEventReportViews": 68,
    "averageEventChartViews": 99,
    "averageDashboardViews": 101,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1805,
    "savedCharts": 2205,
    "savedReportTables": 1995,
    "savedEventReports": 1679,
    "savedEventCharts": 1613,
    "savedDashboards": 0,
    "savedIndicators": 1831,
    "activeUsers": 99,
    "users": 969
  },
  {
    "year": 2016,
    "week": 6,
    "mapViews": 2018,
    "chartViews": 2267,
    "reportTableViews": 4714,
    "eventReportViews": 6697,
    "eventChartViews": 9511,
    "dashboardViews": 12181,
    "passiveDashboardViews": 0,
    "totalViews": 47746,
    "averageViews": 497,
    "averageMapViews": 21,
    "averageChartViews": 23,
    "averageReportTableViews": 49,
    "averageEventReportViews": 69,
    "averageEventChartViews": 99,
    "averageDashboardViews": 126,
    "averagePassiveDashboardViews": 0,
    "savedMaps": 1643,
    "savedCharts": 1935,
    "savedReportTables": 1867,
    "savedEventReports": 1977,
    "savedEventCharts": 1714,
    "savedDashboards": 0,
    "savedIndicators": 1646,
    "activeUsers": 96,
    "users": 953
  }
]
```

### Retrieve statistics for a favorite { #webapi_usage_analytics_retrieve_favorite_statistics } 

You can retrieve the number of view for a specific favorite by using the
*favorites* resource, where *{favorite-id}* should be substituted with
the identifier of the favorite of interest:

    /api/33/dataStatistics/favorites/{favorite-id}.json

The response will contain the number of views for the given favorite and
look like this:

```json
{
  "views": 3
}
```

## Geospatial features { #webapi_geospatial_features } 

The *geoFeatures* resource lets you retrieve geospatial information from
DHIS2. Geospatial features are stored together with organisation units.
The syntax for retrieving features is identical to the syntax used for
the organisation unit dimension for the analytics resource. It is
recommended to read up on the analytics api resource before continuing
to read this section. You must use the GET request type, and only JSON
response format is supported.

As an example, to retrieve geo features for all organisation units at
level 3 in the organisation unit hierarchy you can use a GET request
with the following URL:

    /api/33/geoFeatures.json?ou=ou:LEVEL-3

To retrieve geo features for organisation units at a level within the
boundary of an organisation unit (e.g. at level 2) you can use this URL:

    /api/33/geoFeatures.json?ou=ou:LEVEL-4;O6uvpzGd5pu

The semantics of the response properties are described in the following
table.



Table: Geo features response

| Propriété | Description |
|---|---|
| identifiant | Organisation unit / geo feature identifier |
| na | Organisation unit / geo feature name |
| hcd | Has coordinates down, indicating whether one or more children organisation units exist with coordinates (below in the hierarchy) |
| hcu | Has coordinates up, indicating whether the parent organisation unit has coordinates (above in the hierarchy) |
| le | Level of this organisation unit / geo feature. |
| pg | Parent graph, the graph of parent organisation unit identifiers up to the root in the hierarchy |
| pi | Parent identifier, the identifier of the parent of this organisation unit |
| pn | Parent name, the name of the parent of this organisation unit |
| ty | Geo feature type, 1 = point and 2 = polygon or multi-polygon |
| co | Coordinates of this geo feature |

### GeoJSON { #geojson } 

To export GeoJSON, you can simply add *.geosjon* as an extension to the
endpoint */api/organisationUnits*, or you can use the *Accept* header
*application/json+geojson*.

Two parameters are supported: `level` (default is 1) and `parent` (default is root organisation units). Both can be included multiple times. Some examples:

Get all features at level 2 and 4:

    /api/organisationUnits.geojson?level=2&level=4

Get all features at level 3 with a boundary organisation unit:

    /api/organisationUnits.geojson?parent=fdc6uOvgoji&level=3

## Analytics table hooks { #webapi_analytics_table_hooks } 

Analytics table hooks provide a mechanism for invoking SQL scripts
during different phases of the analytics table generation process. This
is useful for customizing data in resource and analytics tables, e.g. in
order to achieve specific logic for calculations and aggregation.
Analytics table hooks can be manipulated at the following API endpoint:

    /api/analyticsTableHooks

The analytics table hooks API supports the standard HTTP CRUD operations
for creating (POST), updating (PUT), retrieving (GET) and deleting
(DELETE) entities.

### Hook fields { #webapi_analytics_table_hook_fields } 

Analytics table hooks have the following fields:



Table: Analytics table hook fields

| Champ | Options | Description |
|---|---|---|
| nom | Texte | Name of the hook. |
| phase | RESOURCE_TABLE_POPULATED, ANALYTICS_TABLE_POPULATED | The phase for when the SQL script should be invoked. |
| resourceTableType | See column "Table type" in table "Phases, table types and temporary tables" below | The type of resource table for which to invoke the SQL script. Applies only for hooks defined with the RESOURCE_TABLE_POPULATED phase. |
| analyticsTableType | See column "Table type" in table "Phases, table types and temporary tables" below | The type of analytics table for which to invoke the SQL script. Applies only for hooks defined with the ANALYTICS_TABLE_POPULATED phase. |
| sql | Texte | The SQL script to invoke. |

The *ANALYTICS_TABLE_POPULATED* phase takes place after the analytics
table has been populated, but before indexes have been created and the
temp table has been swapped with the main table. As a result, the SQL
script should refer to the analytics temp table, e.g. *analytics_temp*,
*analytics_completeness_temp*.

This applies also to the *RESOURCE_TABLE_POPULATED* phase, which takes
place after the resource table has been populated, but before indexes
have been created and the temp table has been swapped with the main
table. As a result, the SQL script should refer to the resource temp
table, e.g. *_orgunitstructure_temp*, *_categorystructure_temp*.

You should define only one of the *resourceTableType* and
*analyticsTableType* fields, depending on which *phase* is defined.

You can refer to the temporary database table which matches the
specified hook table type only (other temporary tables will not be
available). As an example, if you specify *ORG_UNIT_STRUCTURE* as the
resource table type, you can refer to the *_orgunitstructure_temp*
temporary database table only.

The following table shows the valid combinations of phases, table types
and temporary tables.



Table: Phases, table types and temporary tables

| Phase | Table type | Temporary table |
|---|---|---|
| RESOURCE_TABLE_POPULATED | ORG_UNIT_STRUCTURE | _orgunitstructure_temp |
|| DATA_SET_ORG_UNIT_CATEGORY | _datasetorgunitcategory_temp |
|| CATEGORY_OPTION_COMBO_NAME | _categoryoptioncomboname_temp |
|| DATA_ELEMENT_GROUP_SET_STRUCTURE | _dataelementgroupsetstructure_temp |
|| INDICATOR_GROUP_SET_STRUCTURE | _indicatorgroupsetstructure_temp |
|| ORG_UNIT_GROUP_SET_STRUCTURE | _organisationunitgroupsetstructure_temp |
|| CATEGORY_STRUCTURE | _categorystructure_temp |
|| DATA_ELEMENT_STRUCTURE | _dataelementstructure_temp |
|| PERIOD_STRUCTURE | _periodstructure_temp |
|| DATE_PERIOD_STRUCTURE | _dateperiodstructure_temp |
|| DATA_ELEMENT_CATEGORY_OPTION_COMBO | _dataelementcategoryoptioncombo_temp |
|| DATA_APPROVAL_MIN_LEVEL | _dataapprovalminlevel_temp |
| ANALYTICS_TABLE_POPULATED | DATA_VALUE | analytics_temp |
|| COMPLETENESS | analytics_completeness_temp |
|| COMPLETENESS_TARGET | analytics_completenesstarget_temp |
|| ORG_UNIT_TARGET | analytics_orgunittarget_temp |
|| ÉVÉNEMENT | analytics_event_temp_<program-uid\> |
|| INSCRIPTION | analytics_enrollment_temp_<program-uid\> |
|| VALIDATION_RESULT | analytics_validationresult_temp |

### Creating hooks { #webapi_create_analytics_table_hook } 

To create a hook which should run after the resource tables have been
populated you can do a *POST* request like this using *JSON* format:

```bash
curl -d @hooks.json "localhost/api/analyticsTableHooks" -H "Content-Type:application/json" -u admin:district
```

```json
{
  "name": "Update 'Area' in org unit group set resource table",
  "phase": "RESOURCE_TABLE_POPULATED",
  "resourceTableType": "ORG_UNIT_GROUP_SET_STRUCTURE",
  "sql": "update _organisationunitgroupsetstructure_temp set \"uIuxlbV1vRT\" = 'b0EsAxm8Nge'"
}
```

To create a hook which should run after the data value analytics table
has been populated you can do a *POST* request like this using *JSON*
format:

```json
{
  "name": "Update 'Currently on treatment' data in analytics table",
  "phase": "ANALYTICS_TABLE_POPULATED",
  "analyticsTableType": "DATA_VALUE",
  "sql": "update analytics_temp set monthly = '200212' where \"monthly\" in ('200210', '200211')"
}
```

## SVG conversion { #webapi_svg_conversion } 

The Web API provides a resource which can be used to convert SVG content
into more widely used formats such as PNG and PDF. Ideally this
conversion should happen on the client side, but not all client side
technologies are capable of performing this task. Currently PNG and PDF
output formats are supported. The SVG content itself should be passed with
a *svg* query parameter, and an optional query parameter *filename* can
be used to specify the filename of the response attachment file. Note
that the file extension should be omitted. For PNG you can send a *POST*
request to the following URL with Content-type
`application/x-www-form-urlencoded`, identical to a regular HTML form
submission.

    api/svg.png

For PDF you can send a *POST* request to the following URL with
content-type `application/x-www-form-urlencoded`.

    api/svg.pdf



Table: Query parameters

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| svg | Oui | The SVG content |
| filename | Non | The file name for the returned attachment without file extension |



# Maintenance { #maintenance } 

## Resource and analytics tables { #webapi_generating_resource_analytics_tables } 

DHIS2 features a set of generated database tables which are used as
a basis for various system functionality. These tables can be executed
immediately or scheduled to be executed at regular intervals through the
user interface. They can also be generated through the Web API as
explained in this section. This task is typically one for a system
administrator and not consuming clients.

The resource tables are used internally by the DHIS2 application for
various analysis functions. These tables are also valuable for users
writing advanced SQL reports. They can be generated with a POST or PUT
request to the following URL:

    /api/33/resourceTables

The analytics tables are optimized for data aggregation and used
currently in DHIS2 for the pivot table module. The analytics tables can
be generated with a POST or PUT request to:

    /api/33/resourceTables/analytics



Table: Analytics tables optional query parameters

| Paramètre de requête | Options | Description |
|---|---|---|
| skipResourceTables | faux &#124; vrai | Skip generation of resource tables |
| skipAggregate | faux &#124; vrai | Skip generation of aggregate data and completeness data |
| skipEvents | faux &#124; vrai | Skip generation of event data |
| skipEnrollment | faux &#124; vrai | Skip generation of enrollment data |
| lastYears | entier | Number of last years of data to include |

"Data Quality" and "Data Surveillance" can be run through the monitoring
task, triggered with the following endpoint:

    /api/33/resourceTables/monitoring

This task will analyse your validation rules, find any violations and
persist them as validation results.

These requests will return immediately and initiate a server-side
process.

## Maintenance { #webapi_maintenance } 

To perform maintenance you can interact with the *maintenance* resource. You should use *POST* or *PUT* as a method for requests. The following methods are available.

Analytics tables clear will drop all analytics tables.

    POST PUT /api/maintenance/analyticsTablesClear

Analytics table analyze will collects statistics about the contents of analytics tables in the database.

    POST PUT /api/maintenance/analyticsTablesAnalyze

Expired invitations clear will remove all user account invitations which
have expired.

    POST PUT /api/maintenance/expiredInvitationsClear

Period pruning will remove periods which are not linked to any data
values.

    POST PUT /api/maintenance/periodPruning

Zero data value removal will delete zero data values linked to data
elements where zero data is defined as not significant:

    POST PUT /api/maintenance/zeroDataValueRemoval

Soft deleted data value removal will permanently delete soft deleted data values.

    POST PUT /api/maintenance/softDeletedDataValueRemoval

Soft deleted program stage instance removal will permanently delete soft deleted events.

    POST PUT /api/maintenance/softDeletedProgramStageInstanceRemoval

Soft deleted program instance removal will permanently delete soft deleted enrollments.

    POST PUT /api/maintenance/softDeletedProgramInstanceRemoval

Soft deleted tracked entity instance removal will permanently delete soft deleted tracked entity instances.

    POST PUT /api/maintenance/softDeletedTrackedEntityInstanceRemoval

Drop SQL views will drop all SQL views in the database. Note that it will not delete the DHIS2 SQL view entities.

    POST PUT /api/maintenance/sqlViewsDrop

Create SQL views will recreate all SQL views in the database.

    POST PUT /api/maintenance/sqlViewsCreate

Category option combo update will remove obsolete and generate missing category option combos for all category combinations.

    POST PUT /api/maintenance/categoryOptionComboUpdate

It is also possible to update category option combos for a single category combo using the following endpoint.

    POST PUT /api/maintenance/categoryOptionComboUpdate/categoryCombo/<category-combo-uid>

Cache clearing will clear the application Hibernate cache and the analytics partition caches.

    POST PUT /api/maintenance/cacheClear

Org unit paths update will re-generate the organisation unit path property. This can be useful e.g. if you imported org units with SQL.

    POST PUT /api/maintenance/ouPathsUpdate

Data pruning will remove complete data set registrations, data approvals, data value audits and data values, in this case for an organisation unit.

    POST PUT /api/maintenance/dataPruning/organisationUnits/<org-unit-id>

Data pruning for data elements, which will remove data value audits and data values.

    POST PUT /api/maintenance/dataPruning/dataElement/<data-element-uid>

Metadata validation will apply all metadata validation rules and return the result of the operation.

    POST PUT /api/metadataValidation

App reload will refresh the DHIS2 managed cache of installed apps by reading from the file system.

    POST PUT /api/appReload

Maintenance operations are supported in a batch style with a POST request to the api/maintenance resource where the operations are supplied as query parameters:

    POST PUT /api/maintenance?analyticsTablesClear=true&expiredInvitationsClear=true
      &periodPruning=true&zeroDataValueRemoval=true&sqlViewsDrop=true&sqlViewsCreate=true
      &categoryOptionComboUpdate=true&cacheClear=true&ouPathsUpdate=true

## System info { #webapi_system_resource } 

The system resource provides you with convenient information and
functions. The system resource can be found at */api/system*.

### Generate identifiers { #webapi_system_resource_generate_identifiers } 

To generate valid, random DHIS2 identifiers you can do a GET request to
this resource:

    /api/33/system/id?limit=3

The *limit* query parameter is optional and indicates how many
identifiers you want to be returned with the response. The default is to
return one identifier. The response will contain a JSON object with an
array named codes, similar to this:

```json
{
  "codes": [
    "Y0moqFplrX4",
    "WI0VHXuWQuV",
    "BRJNBBpu4ki"
  ]
}
```

The DHIS2 UID format has these requirements:

  - 11 characters long.

  - Alphanumeric characters only, ie. alphabetic or numeric characters
    (A-Za-z0-9).

  - Start with an alphabetic character (A-Za-z).

### View system information { #webapi_system_resource_view_system_information } 

To get information about the current system you can do a GET request to
this URL:

    /api/33/system/info

JSON and JSONP response formats are supported. The system info response
currently includes the below properties.

```json
{
  "contextPath": "http://yourdomain.com",
  "userAgent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 Chrome/29.0.1547.62",
  "calendar": "iso8601",
  "dateFormat": "yyyy-mm-dd",
  "serverDate": "2021-01-05T09:16:03.548",
  "serverTimeZoneId": "Etc/UTC",
  "serverTimeZoneDisplayName": "Coordinated Universal Time",
  "version": "2.13-SNAPSHOT",
  "revision": "11852",
  "buildTime": "2013-09-01T21:36:21.000+0000",
  "serverDate": "2013-09-02T12:35:54.311+0000",
  "environmentVariable": "DHIS2_HOME",
  "javaVersion": "1.7.0_06",
  "javaVendor": "Oracle Corporation",
  "javaIoTmpDir": "/tmp",
  "javaOpts": "-Xms600m -Xmx1500m -XX:PermSize=400m -XX:MaxPermSize=500m",
  "osName": "Linux",
  "osArchitecture": "amd64",
  "osVersion": "3.2.0-52-generic",
  "externalDirectory": "/home/dhis/config/dhis2",
  "databaseInfo": {
    "type": "PostgreSQL",
    "name": "dhis2",
    "user": "dhis",
    "spatialSupport": false
  },
  "memoryInfo": "Mem Total in JVM: 848 Free in JVM: 581 Max Limit: 1333",
  "cpuCores": 8
}
```

> **Note**
>
> If the user requesting this resource does not have full authority then only properties which are not considered sensitive will be included.

To get information about the system context only, i.e. `contextPath` and
`userAgent`, you can make a GET request to the below URL. JSON and
JSONP response formats are supported:

    /api/33/system/context

### Check if username and password combination is correct { #webapi_system_resource_check_username_password } 

To check if some user credentials (a username and password combination)
is correct you can make a *GET* request to the following resource using
*basic authentication*:

    /api/33/system/ping

You can detect the outcome of the authentication by inspecting the *HTTP
status code* of the response header. The meanings of the possible status
codes are listed below. Note that this applies to Web API requests in
general.



Table: HTTP Status codes

| HTTP Status code | Description | Résultat |
|---|---|---|
| 200 | OK | Authentication was successful |
| 302 | Found | No credentials were supplied with the request - no authentication took place |
| 401 | Unauthorized | The username and password combination was incorrect - authentication failed |

### View asynchronous task status { #webapi_system_resource_view_async_task_status } 

Tasks which often take a long time to complete can be performed
asynchronously. After initiating an async task you can poll the status
through the `system/tasks` resource by supplying the task category and
the task identifier of interest.

When polling for the task status you need to authenticate as the same
user which initiated the task. The following task categories are
supported:



Table: Task categories

| Identificateur | Description |
|---|---|
| ANALYTICS_TABLE | Generation of the analytics tables. |
| RESOURCE_TABLE | Generation of the resource tables. |
| MONITORING | Processing of data surveillance/monitoring validation rules. |
| DATAVALUE_IMPORT | Import of data values. |
| EVENT_IMPORT | Import of events. |
| ENROLLMENT_IMPORT | Import of enrollments. |
| TEI_IMPORT | Import of tracked entity instances. |
| METADATA_IMPORT | Import of metadata. |
| DATA_INTEGRITY | Processing of data integrity checks. |

Each asynchronous task is automatically assigned an identifier which can
be used to monitor the status of the task. This task identifier is
returned by the API when you initiate an async task through the various
async-enabled endpoints.

#### Monitoring a task { #monitoring-a-task } 

You can poll the task status through a GET request to the system tasks
resource like this:

    /api/33/system/tasks/{task-category-id}/{task-id}

An example request may look like this:

    /api/33/system/tasks/DATAVALUE_IMPORT/j8Ki6TgreFw

The response will provide information about the status, such as the
notification level, category, time and status. The *completed* property
indicates whether the process is considered to be complete.

```json
[{
  "uid": "hpiaeMy7wFX",
  "level": "INFO",
  "category": "DATAVALUE_IMPORT",
  "time": "2015-09-02T07:43:14.595+0000",
  "message": "Import done",
  "completed": true
}]
```

#### Monitoring all tasks for a category { #monitoring-all-tasks-for-a-category } 

You can poll all tasks for a specific category through a GET request to
the system tasks resource:

    /api/33/system/tasks/{task-category-id}

An example request to poll for the status of data value import tasks
looks like this:

    /api/33/system/tasks/DATAVALUE_IMPORT

#### Monitor all tasks { #monitor-all-tasks } 

You can request a list of all currently running tasks in the system with
a GET request to the system tasks resource:

    /api/33/system/tasks

The response will look similar to this:

```json
[{
  "EVENT_IMPORT": {},
  "DATA_STATISTICS": {},
  "RESOURCE_TABLE": {},
  "FILE_RESOURCE_CLEANUP": {},
  "METADATA_IMPORT": {},
  "CREDENTIALS_EXPIRY_ALERT": {},
  "SMS_SEND": {},
  "MOCK": {},
  "ANALYTICSTABLE_UPDATE": {},
  "COMPLETE_DATA_SET_REGISTRATION_IMPORT": {},
  "DATAVALUE_IMPORT": {},
  "DATA_SET_NOTIFICATION": {},
  "DATA_INTEGRITY": {
    "OB1qGRlCzap": [{
      "uid": "LdHQK0PXZyF",
      "level": "INFO",
      "category": "DATA_INTEGRITY",
      "time": "2018-03-26T15:02:32.171",
      "message": "Data integrity checks completed in 38.31 seconds.",
      "completed": true
    }]
  },
  "PUSH_ANALYSIS": {},
  "MONITORING": {},
  "VALIDATION_RESULTS_NOTIFICATION": {},
  "REMOVE_EXPIRED_RESERVED_VALUES": {},
  "DATA_SYNC": {},
  "SEND_SCHEDULED_MESSAGE": {},
  "DATAVALUE_IMPORT_INTERNAL": {},
  "PROGRAM_NOTIFICATIONS": {},
  "META_DATA_SYNC": {},
  "ANALYTICS_TABLE": {},
  "PREDICTOR": {}
}]
```

### View asynchronous task summaries { #view-asynchronous-task-summaries } 

The task summaries resource allows you to retrieve a summary of an
asynchronous task invocation. You need to specify the category and
optionally the identifier of the task. The task identifier can be
retrieved from the response of the API request which initiated the
asynchronous task.

To retrieve the summary of a specific task you can issue a request to:

    /api/33/system/taskSummaries/{task-category-id}/{task-id}

An example request might look like this:

    /api/33/system/taskSummaries/DATAVALUE_IMPORT/k72jHfF13J1

The response will look similar to this:

```json
{
  "responseType": "ImportSummary",
  "status": "SUCCESS",
  "importOptions": {
    "idSchemes": {},
    "dryRun": false,
    "async": true,
    "importStrategy": "CREATE_AND_UPDATE",
    "mergeMode": "REPLACE",
    "reportMode": "FULL",
    "skipExistingCheck": false,
    "sharing": false,
    "skipNotifications": false,
    "datasetAllowsPeriods": false,
    "strictPeriods": false,
    "strictCategoryOptionCombos": false,
    "strictAttributeOptionCombos": false,
    "strictOrganisationUnits": false,
    "requireCategoryOptionCombo": false,
    "requireAttributeOptionCombo": false,
    "skipPatternValidation": false
  },
  "description": "Import process completed successfully",
  "importCount": {
    "imported": 0,
    "updated": 431,
    "ignored": 0,
    "deleted": 0
  },
  "dataSetComplete": "false"
}
```

You might also retrieve import summaries for multiple tasks of a
specific category with a request like
this:

    /api/33/system/taskSummaries/{task-category-id}

### Get appearance information { #webapi_system_resource_get_appearance_information } 

You can retrieve the available flag icons in JSON format with a GET
request:

    /api/33/system/flags

You can retrieve the available UI styles in JSON format with a GET
request:

    /api/33/system/styles

## Cluster info { #cluster-info } 

When DHIS 2 is set up in a cluster configuration, it is useful to know which node in the cluster acts as the leader of the cluster. The following API can be used to get the details of the leader node instance. The API supports both JSON and XML formats.

```
GET /api/36/cluster/leader
```

A sample JSON response looks like this:

```json
{
  "leaderNodeId": "play-dhis2-org-dev",
  "leaderNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "currentNodeId": "play-dhis2-org-dev",
  "currentNodeUuid": "d386e46b-26d4-4937-915c-025eb99c8cad",
  "leader": true
}
```

## Min-max data elements { #webapi_min_max_data_elements } 

The min-max data elements resource allows you to set minimum and maximum
value ranges for data elements. It is unique by the combination of
organisation unit, data element and category option combo.

    /api/minMaxDataElements



Table: Min-max data element data structure

| Élément | Description | Type de données |
|---|---|---|
| source | Identifiant de l'unité d'organisation | Chaîne |
| élément de données | Identifiant de l'élément de données | Chaîne |
| optionCombo | Data element category option combo identifier | Chaîne |
| min | Valeur minimale | Entier |
| max | Valeur maximum | Entier |
| generated | Indicates whether this object is generated by the system (and not set manually). | Booléen |

You can retrieve a list of all min-max data elements from the following
resource:

    GET /api/minMaxDataElements.json

You can filter the response like this:

    GET /api/minMaxDataElements.json?filter=dataElement.id:eq:UOlfIjgN8X6

    GET /api/minMaxDataElements.json?filter=dataElement.id:in:[UOlfIjgN8X6,xc8gmAKfO95]

The filter parameter for min-max data elements supports two operators:
eq and in. You can also use the `fields` query parameter.

    GET /api/minMaxDataElements.json?fields=:all,dataElement[id,name]

### Add/update min-max data element { #webapi_add_update_min_max_data_element } 

To add a new min-max data element, use POST request to:

    POST /api/minMaxDataElements.json

The JSON content format looks like this:

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

If the combination of data element, organisation unit and category
option combo exists, the min-max value will be updated.

### Delete min-max data element { #webapi_delete_min_max_data_element } 

To delete a min-max data element, send a request with DELETE method:

    DELETE /api/minMaxDataElements.json

The JSON content is in similar format as above:

```json
{
  "min": 1,
  "generated": false,
  "max": 100,
  "dataElement": {
    "id": "UOlfIjgN8X6"
   },
  "source": {
    "id": "DiszpKrYNg8"
  },
  "optionCombo": {
    "id": "psbwp3CQEhs"
  }
}
```

## Exceptions de verrouillage { #webapi_lock_exceptions } 

The lock exceptions resource allows you to open otherwise locked data
sets for data entry for a specific data set, period and organisation
unit. You can read lock exceptions from the following resource:

    /api/lockExceptions

To create a new lock exception you can use a POST request and specify
the data set, period and organisation unit:

    POST /api/lockExceptions?ds=BfMAe6Itzgt&pe=201709&ou=DiszpKrYNg8

To delete a lock exception you can use a similar request syntax with a
DELETE request:

    DELETE /api/lockExceptions?ds=BfMAe6Itzgt&pe=201709&ou=DiszpKrYNg8




# I18n { #i18n } 

## Locales { #webapi_locales } 

DHIS2 supports translations both for the user interface and for database
content.

### UI locales { #ui-locales } 

You can retrieve the available locales for the user interface through
the following resource with a GET request. XML and JSON resource
representations are supported.

    /api/33/locales/ui

### Database content locales { #database-content-locales } 

You can retrieve and create locales for the database content with GET and
POST requests through the following resource. XML and JSON resource
representations are supported.

    /api/33/locales/db

## Les traductions { #webapi_translations } 

DHIS2 allows for translations of database content. 
If a metadata is translatable, then it will have a `translations` property.

That means you can retrieve and update translations using metadata class resources such as `api/dataElements`, `api/organisationUnits`, `api/dataSets`, etc.

### Get translations { #get-translations } 

You can get translations for a metadata object such as DataElement by sending a GET request to `api/dataElements/{dataElementUID}`

The response contains full details of the DataElement which also includes the `translations` property as below

```json
{
  "id": "fbfJHSPpUQD",
  "href": "https://play.dhis2.org/dev/api/29/dataElements/fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```
You can also get only the `translations` property of an object by sending a GET request to 
`api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

### Create a translations { #create-a-translations } 

You can create a translation by sending a PUT request with same JSON format to `api/dataElements/{dataElementUID}/translations`

```json
{
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "DESCRIPTION",
      "locale": "fr",
      "value": "description in french"
    },
    {
      "property": "FORM_NAME",
      "locale": "fr",
      "value": "name in french"
    }
  ]
}
```

Alternatively, you can also just update the object with payload including the `translations` property.

Send PUT request to `api/dataElements/{dataElementUID}` with full object payload as below:

```json
{
  "id": "fbfJHSPpUQD",
  "created": "2010-02-05T10:58:43.646",
  "name": "ANC 1st visit",
  "shortName": "ANC 1st visit",
  "translations": 
  [
    {
      "property": "SHORT_NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    },
    {
      "property": "NAME",
      "locale": "fr",
      "value": "Soin prénatal 1"
    },
    {
      "property": "NAME",
      "locale": "en_GB",
      "value": "ANC 1st visit"
    }
  ]
}
```

The common properties which support translations are listed in the table below.

Table: Property names

| Property name | Description |
|---|---|
| nom | Object name |
| nomAbrégé | Object short name |
| Description | Object description |

The classes which support translations are listed in the table below.

Table: Class names

| Class name | Description | Other translatable Properties |
|---|---|---|
| DataElementCategoryOption | Option de catégorie | |
| DataElementCategory | Catégorie | |
| DataElementCategoryCombo | La combinaison de catégories | |
| Élément de données | Élément de données | |
| DataElementGroup | Groupe d'éléments de données | |
| DataElementGroupSet | Ensemble de groupes d'éléments de donnée | |
| Indicateur | Indicateur | numeratorDescription, denominatorDescription |
| IndicatorType | Type d'indicateur | |
| IndicatorGroup | Groupe d’indicateurs | |
| IndicatorGroupSet | Ensemble de groupes d'indicateurs | |
| OrganisationUnit | Unité d’organisation | |
| OrganisationUnitGroup | Groupe d'unités d'organisation | |
| OrganisationUnitGroupSet | Ensemble de groupes d'unités d'organisation | |
| Ensemble de données | Ensemble de données | |
| Section | Data set section | |
| ValidationRule | Règle de validation | instruction |
| ValidationRuleGroup | Groupe de règles de validation | |
| Programme | Programme | enrollmentDateLabel, incidentDateLabel |
| Étape du programme | Étape du programme | executionDateLabel, dueDateLabel |
| TrackedEntityAttribute | Attribut d’entité suivie | |
| TrackedEntity | Tracked entity | |
| Type de relation | Relationship type for tracked entity instances | fromToName, toFromName |
| Ensemble d'options | Ensemble d'options | |
| Attribut | Attribute for metadata | |
| ProgramNotificationTemplate | Program Notification template | subjectTemplate, messageTemplate |
| ValidationNotificationTemplate | Validation Notification template | subjectTemplate, messageTemplate |
| DataSetNotificationTemplate | DataSet Notification template | subjectTemplate, messageTemplate |
| Visualization | Visualization | title, subtitle, rangeAxisLabel, baseLineLabel, targetLineLabel, domainAxisLabel |
| ProgramRuleAction | Program Rule Actions | content |

## Internationalization { #webapi_i18n } 

In order to retrieve key-value pairs for translated strings you can use
the *i18n* resource.

    /api/33/i18n

The endpoint is located at */api/i18n* and the request format is a simple
array of the key-value pairs:

```json
[
  "access_denied",
  "uploading_data_notification"
]
```

The request must be of type *POST* and use *application/json* as
content-type. An example using curl, assuming the request data is saved
as a file `keys.json`:

```bash
curl -d @keys.json "play.dhis2.org/demo/api/33/i18n" -X POST
  -H "Content-Type: application/json" -u admin:district
```

The result will look like this:

```json
{
  "access_denied":"Access denied",
  "uploading_data_notification":"Uploading locally stored data to the server"
}
```





# SMS { #sms } 

## Service de messages courts (SMS) { #webapi_sms } 

Cette section porte sur l'API Web SMS, qui permet d'envoyer et de recevoir des messages 
texte courts.

### Service de SMS sortant { #outbound-sms-service } 

L'API Web prend en charge l'envoi de SMS sortants à l'aide de la méthode POST. Les SMS peuvent 
être envoyés à un ou plusieurs destinataires. Une ou plusieurs passerelles doivent 
être configurées avant d'utiliser le service. Un SMS ne sera pas envoyé si 
aucune passerelle n'est configurée. Il nécessite un ensemble de destinataires et 
un texte de message au format JSON, comme indiqué ci-dessous.

    /api/sms/sortant

```json
{
  "message":"Texte du Sms",
  "destinataires": [
    "004712341234",
    "004712341235"
  ]
}
```

> **Remarque**
>
> La liste des destinataires sera divisée si la taille dépasse la limite `DESTINATAIRES_MAXIMUM_AUTORISÉS` de 200.

L'API Web prend également en charge une version de paramètre de requête, mais 
l'API paramétrée ne peut être utilisée que pour envoyer des SMS à un seul 
destinataire.

    /api/sms/outbound?message=text&recipient=004712341234

Les messages sortants peuvent être récupérés à l'aide de la ressource GET.

    GET /api/sms/outbound
    GET /api/sms/outbound?filter=status:eq:SENT
    GET /api/sms/outbound?filter=status:eq:SENT&fields=*

Les messages sortants peuvent être supprimés à l'aide de la ressource SUPPRIMER.

    SUPPRIMER/api/sms/outbound/{uid}
    SUPPRIMER /api/sms/outbound?ids=uid1,uid2

#### Codes de réponse de la passerelle { #gateway-response-codes } 

La passerelle peut répondre avec les codes de réponse suivants.



Tableau : Codes de réponse de la passerelle

| Code de la réponse | Message de réponse | Description détaillée |
|---|---|---|
| CODE DU_RÉSULTAT_0 | succès | Le message a été envoyé avec succès |
| CODE DU_RÉSULTAT_1 | programmé | Le message a été programmé avec succès |
| CODE DU_RÉSULTAT_22 | erreur fatale interne | erreur fatale interne |
| CODE DU_RÉSULTAT_23 | échec de l'authentification | Les données de l'authentification sont incorrectes |
| CODE DU_RÉSULTAT_24 | échec de la validation des données | Les paramètres fournis dans la demande sont incorrects |
| CODE DU_RÉSULTAT_25 | crédits insuffisants | Le crédit est insuffisant pour envoyer un message |
| CODE DU_RÉSULTAT_26 | montant du crédit non disponible | Montant du crédit non disponible |
| CODE DU_RÉSULTAT_27 | vous avez dépassé votre quota journalier | vous avez dépassé votre quota journalier |
| CODE DU_RÉSULTAT_40 | temporairement indisponible | Le service est temporairement interrompu |
| CODE DU_RÉSULTAT_201 | taille maximale du lot dépassée | Taille maximale du lot dépassée |
| CODE DU_RÉSULTAT_200 | succès | La demande a été traitée avec succès |
| CODE DU_RÉSULTAT_202 | accepté | Le(s) message(s) sera(ont) traité(s) |
| CODE DU_RÉSULTAT_207 | multi-statut | Plus d'un message a été soumis à l'API ; cependant, tous les messages n'ont pas le même statut. |
| CODE DU_RÉSULTAT_400 | mauvaise requête | Échec de validation (paramètres ou en-têtes manquants/invalides) |
| CODE DU_RÉSULTAT_401 | Non-autorisé | Échec de l'authentification. Ce problème peut également être causé par des paramètres de verrouillage de l'IP. |
| CODE DU_RÉSULTAT_402 | paiement requis | Crédit insuffisant pour envoyer un message |
| CODE DU_RÉSULTAT_404 | pas trouvé | La ressource n'existe pas |
| CODE DU_RÉSULTAT_405 | méthode non autorisée | La méthode Http n'est pas supportée par la ressource |
| CODE DU_RÉSULTAT_410 | parti | Le numéro du téléphone portable est bloqué |
| CODE DU_RÉSULTAT_429 | trop de requêtes | Erreur générique de limitation du taux |
| CODE DU_RÉSULTAT_503 | Service indisponible | Une erreur temporaire s'est produite sur notre plateforme - veuillez réessayer |

### Service de SMS entrants { #inbound-sms-service } 

L'API Web prend en charge la collecte des messages SMS entrants à l'aide de la méthode 
POST. Les messages entrants acheminés vers l'API Web DHIS2 peuvent être 
reçus à l'aide de cette API. L'API collecte les messages SMS entrants et 
les fournit aux auditeurs pour qu'ils les analysent, en fonction du contenu du SMS (commande SMS). Un exemple de charge utile au format JSON est donné ci-dessous. Le 
texte, l'expéditeur, la date de réception et la date d'envoi sont des paramètres obligatoires. 
Les autres sont facultatifs, mais le système utilisera la valeur par défaut pour ces 
paramètres.

    /api/sms/entrant

```json
{
  "texte" : "texte de l'échantillon",
  "auteur": "004712341234",
  "iddelapasserelle " : " inconnu",
  "date de réception": "2016-05-01",
  "date d'envoi":"2016-05-01",
  "codage sms": "1",
  "statut sms":"1"
}
```

Les messages entrants peuvent être récupérés à l'aide de la ressource GET.

    GET /api/sms/inbound
    GET /api/sms/inbound?fields=*&filter=smsstatus=INCOMING

Les messages entrants peuvent être supprimés à l'aide de la ressource SUPPRIMER.

    SUPPRIMER /api/sms/inbound/{uid}
    SUPPRIMER /api/sms/inbound?ids=uid1,uid2

Pour importer tous les messages non traités

    POST /api/sms/entrant/importer



Tableau : Paramètres de requête de l'utilisateur

| Paramètre | Type | Description |
|---|---|---|
| message | Chaîne | Il s'agit d'un paramètre obligatoire qui contient le message textuel proprement dit. |
| auteur | Chaîne | Il s'agit d'un paramètre obligatoire qui indique de qui provient le message. |
| passerelle | Chaîne | Il s'agit d'un paramètre facultatif qui indique l'identifiant de la passerelle. S'il n'est pas présent, le texte par défaut " INCONNU " sera stocké |
| heure de réception | Date | Ce paramètre est facultatif. Il indique l'heure à laquelle le message a été reçu par la passerelle. |

### Administration du service de la passerelle { #gateway-service-administration } 

L'API Web expose des ressources qui permettent de configurer et 
de mettre à jour les configurations de la passerelle SMS.

La liste des différentes passerelles configurées peut être obtenue à l'aide de la méthode 
GET

    GET /api/33/gateways

Les configurations peuvent également être récupérées pour un type de passerelle spécifique à l'aide de la
méthode GET.

    GET /api/33/gateways/{uid}

De nouvelles configurations de passerelles peuvent être ajoutées à l'aide de POST. L'api POST nécessite un paramètre de requête de type et actuellement sa valeur peut être *http,bulksms,clickatell,smpp*. La première passerelle ajoutée sera définie par défaut. Une seule passerelle peut être définie par défaut à la fois. La passerelle par défaut ne peut être modifiée que par l'intermédiaire de son interface utilisateur. Si la passerelle par défaut est supprimée, la suivante dans la liste deviendra automatiquement la passerelle par défaut.

    POST /api/33/gateways

La configuration peut être mise à jour en fournissant l'uid et la configuration de la passerelle comme indiqué ci-dessous

    PUT /api/33/gateways/{uids}

Les configurations peuvent être supprimées pour un type de passerelle spécifique à l'aide de la méthode 
SUPPRIMER

    DELETE /api/33/gateways/{uid}

La passerelle par défaut peut être récupérée et mise à jour.

    GET /api/33/gateways/default

Default gateway can be set using the PUT method.

    PUT /api/33/gateways/default/{uid}

### Configuration de la passerelle { #gateway-configuration } 

L'API Web vous permet de créer et de mettre à jour les configurations de la passerelle. Pour chaque
type de passerelle, les paramètres de la charge utile JSON sont différents.
Des exemples de charges utiles JSON pour chaque passerelle sont donnés ci-dessous. POST est utilisé pour
créer et PUT pour mettre à jour les configurations. Le paramètre En-tête peut être utilisé dans
le cas de "GenericHttpGateway" pour envoyer un ou plusieurs paramètres en tant qu'en-tête http.

#### Clickatell { #clickatell } 

```json
{
  "type" : "clickatell",
  "nom" : "clickatell",
  "nom d'utilisateur": "utilisateur de clickatell",
  "authToken": "XXXXXXXXXXXXXXXXXXXX",
  "modèle d'url": "https://platform.clickatell.com/messages"
}
```

#### Bulksms { #bulksms } 

```json
{
  "type": "bulksms",
  "nom": "bulkSMS",
  "nom d'utilisateur": "utilisateur bulk",
  "mot de passe": "abc123"
}
```

#### Passerelle SMPP { #smpp-gateway } 

```json
{
  "type": "smpp",
  "nom": "smpp gateway2",
  "systemId": "smppclient1",
  "hôte" : " hôte local",
  "type de système": "cp",
  "Indicateur de plan de numérotation": "INCONNU",
  "typeDeNombre": "INCONNU",
  "type de lien": "BIND_TX",
  "port": 2775,
  "mot de passe" : "mot de passe",
  "compressé" : faux
}
```

#### Générique HTTP { #generic-http } 

```json
{
  "type": "http",
  "nom": "Générique",
  "modèle de configuration": "nom d'utilisateur=${nom d'utilisateur}&mot de passe=${mot de passe}&to=${destinataires}&code pays=880&message=${text$}&identifiant du message=0",
  "useGet": faux,
  "paramètres d'envoi d'URL":faux,
  "type de contenu": "APPLICATION_JSON",
  "modèle d'url":"https://samplegateway.com/messages",
  "paramètres": [
    {
      "en-tête": vrai,
      "code": faux,
      "clé": "nom d'utilisateur",
      "valeur": "utilisateur_uio",
      "confidentiel": vrai
    },
    {
      "en-tête": vrai,
      "code": faux,
      "clé": "mot de passe",
      "valeur": "123abcxyz",
      "confidentiel": vrai
    },
    {
      "en-tête": faux,
      "code": faux,
      "clé": "rapport de diffusion",
      "valeur": "oui",
      "confidentiel": faux
    }
  ],
  "estParDéfaut": faux
}
```

Dans une passerelle générique http, il est possible d'ajouter un nombre illimité de paramètres.



Tableau : Paramètres génériques de la passerelle SMS

| Paramètre | Type | Description |
|---|---|---|
| nom | Chaîne | nom de la passerelle |
| modèle de configuration | Chaîne | Le modèle de configuration qui est rempli avec les valeurs des paramètres. Par exemple, le modèle de configuration donné ci-dessus sera rempli comme suit : { "to" : "+27001234567", "body" : "Hello World !"} |
| useGet | Booléen | La méthode Http POST est utilisée par défaut. Pour la remplacer par Http GET, l'utilisateur peut attribuer la valeur "true" au paramètre "useGet". |
| type de contenu | Chaîne | Le type de contenu spécifie le type de données envoyées. Les types pris en charge sont l'APPLICATION_JSON, l'APPLICATION_XML, le FORMULAIRE_URL_CODE, TEXTE_CLAIR |
| modèle d'url | Chaîne | modèle d'url |
| En-tête | Booléen | Si le paramètre doit être envoyé dans les en-têtes Http |
| coder | Booléen | Si le paramètre doit être codé |
| clé | Chaîne | clé de paramètre |
| valeur | Chaîne | valeur du paramètre |
| confidentiel | Booléen | Si le paramètre est confidentiel. Ce paramètre ne sera pas exposé à travers l'API |
| Paramètres d'envoi d'Url | Booléen | Si cette option est cochée, le modèle d'url peut être ajouté aux paramètres de la requête. Ceci est utile si l'API de la passerelle ne prend en charge que le HTTP GET. Un exemple de modèle d'url ressemble à ceci `"urlTemplate" : "https://samplegateway.com/messages?apiKey={apiKey}&to={recipients},content={text},deliveryreport={dp}"`. |

HTTP.OK sera renvoyé si les configurations sont sauvegardées avec succès, sinon *Erreur*

## Les commandes SMS { #webapi_sms_commands } 

Les commandes SMS sont utilisées pour collecter des données par SMS. Ces commandes 
appartiennent à un type d'analyseur spécifique. Chaque analyseur a des fonctionnalités différentes.

La liste des commandes peut être récupérée à l'aide de la fonction GET.

    GET /api/smsCommands

Une commande particulière peut être récupérée à l'aide de GET.

    GET /api/smsCommands/uid

Une commande particulière peut être mise à jour à l'aide de PUT.

    PUT /api/smsCommands/uid

La commande peut être créée en utilisant POST.

    POST /api/smsCommands

Une commande particulière peut être supprimée à l'aide de la commande SUPPRIMER.

    DELETE /api/smsCommands/uid

#### Types de commande SMS { #sms-command-types } 

| Type | Utilisation |
|---|---|
|ANALYSEUR_CLÉ_DE VALEUR | Pour la collecte de données agrégées.|
|ANALYSEUR_D'ALERTES | Pour envoyer des messages d'alerte.|
|ANALYSEUR_NON ENREGISTRÉ | Pour la surveillance des maladies et la notification des cas.|
|ANALYSEUR_D'ENREGISTREMENT_D'ENTITÉS_SUIVIES | Pour l'enregistrement de l'entité du tracker.|
|ANALYSEUR_DE SAISIE DE DONNÉES_DE L'ÉTAPE_DU PROGRAMME | Collecte de données pour l'étape du programme. ( L'IES est identifié sur la base du numéro de téléphone )|
|ANALYSEUR_D'ENREGISTREMENT_D'ÉVÉNEMENTS | Enregistrement d'un événement unique. Elle est utilisée pour les programmes d'événements.|

#### Types de commandes SMS pour Android { #sms-command-types-for-android } 

Ces types de commandes peuvent être utilisés par l'application Android pour l'envoi de données par SMS lorsque la connexion internet n'est pas disponible. Le SMS est composé par l'application Android.

| Type | Utilisation |
|---|---|
|ENSEMBLE DE DONNÉES_AGRÉGÉ | Pour la collecte de données agrégées.|
|INSCRIPTION | Pour l'enregistrement de l'entité du tracker.|
|ÉVÉNEMENT_TRACKER | Inscription à un événement pour les programmes tracker.|
|ÉVÉNEMENT_SIMPLE | Inscription aux programmes d'événements.|
|RELATION | Pour créer des relations.|
|SUPPRIMER | Supprimer un événement.|



# Utilisateurs { #users } 

## Utilisateurs { #webapi_users } 

Cette section couvre les méthodes de ressources de l'utilisateur.

    /api/33/users

### Requête de l'utilisateur { #webapi_users_query } 

La ressource *utilisateurs* offre des paramètres de requête supplémentaires en plus des
paramètres standard (par exemple, la pagination). Pour rechercher des utilisateurs 
dans la ressource vous pouvez utiliser les paramètres suivants.

Tableau : Paramètres de requête de l'utilisateur

| Paramètre | Type | Description |
|---|---|---|
| requête | Texte | Valeur de la requête pour le prénom, le nom de famille, le nom d'utilisateur et l'adresse électronique, sensible à la casse. |
| Numéro de Téléphone | Texte | Requête pour un numéro de téléphone. |
| peutGérer | faux &#124; vrai | Filtre permettant de déterminer si l'utilisateur actuel peut gérer les utilisateurs renvoyés à travers les relations de groupe d'utilisateurs gérés. |
| authSubset | faux &#124; vrai | Filtre permettant de déterminer si les utilisateurs renvoyés ont un sous-ensemble des autorisations de l'utilisateur actuel. |
| dernière connexion | Date | Filtre les utilisateurs qui se sont connectés après la date indiquée. |
| mois inactifs | Nombre | Filtre les utilisateurs qui ne se sont pas connectés pendant le nombre de mois indiqué. |
| inactif Depuis | Date | Filtre les utilisateurs qui ne se sont pas connectés après la date indiquée. |
| auto-inscrit | faux &#124; vrai | Filtre les utilisateurs qui se sont auto-inscrits sur leur compte d'utilisateur. |
| statut de l'invitation | aucun &#124; all &#124; expiré | Filtre les invitations des utilisateurs, notamment toutes les invitations ou les invitations expirées. |
| ou | Identificateur | Filtre les utilisateurs associés à l'unité d'organisation dont l'identifiant est indiqué. |
| unités d'organisation des utilisateurs | faux &#124; vrai | Filtre les utilisateurs qui sont associés aux unités d'organisation liées à l'utilisateur actuellement connecté. |
| Inclut les enfants | faux &#124; vrai | Inclut les utilisateurs de toutes les unités d'organisation subordonnées du paramètre de l'uo. |
| page | Nombre | Le nombre de la page. |
| taille de la page | Nombre | La taille de la page |

Une requête pour un maximum de 10 utilisateurs avec "konan" comme prénom ou nom de famille (sensible 
à la casse) qui ont un sous-ensemble d'autorisations par rapport à l'utilisateur 
actuel :

    /api/33/users?query=konan&authSubset=true&pageSize=10

### Recherche d'utilisateurs { #user-lookup } 

L'API de recherche d'utilisateurs propose un système de récupération des utilisateurs lorsque la 
réponse comporte un minimum d'informations. Aucune autorité spécifique 
n'est requise et elle permet aux clients de rechercher des informations 
telles que le prénom et le nom de famille de l'utilisateur, sans pour autant révéler des informations 
potentiellement sensibles.

```
/api/userLookup
```

Le système de recherche de l'utilisateur comporte deux méthodes.

#### Recherche des utilisateurs par identifiant { #user-lookup-by-identifier } 

Vous pouvez effectuer une recherche d'utilisateur par identifiant en utilisant la requête API suivante :

```
GET /api/userLookup/{id}
```

L'`ID` de l'utilisateur sera recherché par rapport aux propriétés d'utilisateur 
suivantes dans l'ordre indiqué :

- UID
- UUID
- Nom d'utilisateur

Voici donc un exemple de requête :

```
/api/userLookup/QqvaU7JjkUV
```

La réponse comportera un minimum d'informations relatives à l'utilisateur.

```json
{
  "id": "QqvaU7JjkUV",
  "nom d'utilisateur": "nkono",
  "prénom": "Thomas",
  "nom de famille": "Nkono",
  "nom affiché": "Thomas Nkono"
}
```

#### Requête de recherche d'utilisateurs { #user-lookup-query } 

Vous pouvez réaliser une requête des utilisateurs à partir de la requête API suivante :

```
GET /api/userLookup?query={string}
```

Le paramètre de requête `query` est obligatoire. La chaîne de requête `query` sera comparée 
aux propriétés utilisateur suivantes :

- Prénom
- Nom
- Adresses électronique
- Nom d'utilisateur

Voici donc un exemple de requête :

```
/api/userLookup?query=John
```

La réponse comportera des informations relatives aux utilisateurs et correspondants à la requête.

```json
{
  "utilisateurs": [
    {
      "id": "DXyJmlo9rge",
      "nom d'utilisateur": "jbarnes",
      "prénom": "John",
      "nom de famille": "Barnes",
      "nom affiché": "John Barnes"
    },
    {
      "id": "N3PZBUlN8vq",
      "nom d'utilisateur": "jkamara",
      "prénom": "John",
      "nom de famille": "Kamara",
      "nom affiché": "John Kamara"
    }
  ]
}
```

### Créer et mettre à jour un compte utilisateur { #webapi_users_create_update } 

La création et la mise à jour des utilisateurs sont prises en charge par l'API. Une charge utile
de base pour créer un utilisateur ressemble à l'exemple ci-dessous. Notez que le mot de passe
sera envoyé en texte clair, n'oubliez donc pas d'activer SSL/HTTPS pour le transport réseau.

```json
{
  "identifiant": "Mj8balLULKp",
  "Prénom": "John",
  "nom ": "Doe",
  "email": "johndoe@mail.com",
  "informations d'identification de l'utilisateur": {
    "identifiant": "lWCkJ4etppc",
    "infoUtilisateur": {
    "identifiant": "Mj8balLULKp"
  },
  "nom d'utilisateur": "johndoe123",
  "mot de passe": "Your-password-123",
  "skype": "john.doe",
  "telegram": "joh.doe",
  "whatsApp": "+1-541-754-3010",
  "facebookMessenger": "john.doe",
  "avatar": {
    "identifiant": "<fileResource id>"
  },
  "rôles d'utilisateur": [
    {
      "identifiant": "Ufph3mGRmMo"
    }
  ]
  },
  "unités d'organisation": [
    {
      "identifiant": "Rp268JB6Ne4"
    }
  ],
  "groupes d'utilisateurs": [
    {
      "identifiant": "wl5cDMuUhmF"
    }
  ]
}
```

```bash
curl -X POST -d @u.json "http://server/api/33/users" -u user:pass
  -H "Content-Type: application/json"
```

Dans la charge utile de création d'utilisateurs, les groupes d'utilisateurs ne sont pris en charge que lors de l'importation 
ou du *POSTing* d'un seul utilisateur à la fois. Si vous tentez de créer plus d'un 
utilisateur tout en spécifiant des groupes d'utilisateurs, vous ne recevrez pas d'erreur et les 
utilisateurs seront créés, mais aucun groupe d'utilisateurs ne sera affecté. Ceci est prévu et 
limité en raison de la relation de plusieurs à plusieurs entre les utilisateurs et les 
groupes d'utilisateurs, les groupes d'utilisateurs étant propriétaires de la relation. Pour mettre à jour 
ou créer plusieurs utilisateurs et leurs groupes d'utilisateurs, envisagez un programme pour *POSTER* 
un à la fois, ou *POSTER* tous les utilisateurs suivi d'une autre action pour mettre à jour 
leurs groupes d'utilisateurs tout en spécifiant les identifiants du nouvel utilisateur.

Après la création de l'utilisateur, une entête *Location* est renvoyée avec l'identifiant 
nouvellement généré (vous pouvez également fournir le vôtre en utilisant le point d'extrémité 
`/api/system/id`). La même charge utile peut alors être utilisée pour faire des mises à jour, mais n'oubliez pas 
d'utiliser *PUT* au lieu de *POST* et le point d'extrémité est désormais `/api/users/ID`.

```bash
curl -X PUT -d @u.json "http://server/api/33/users/ID" -u user:pass
  -H "Content-Type: application/json"
```

Pour plus d'informations sur l'ensemble des données disponibles, voir `/api/schemas/user`.

Pour plus d'informations sur le téléchargement et la récupération des avatars des utilisateurs, veuillez consulter le 
point d'extrémité `/fileResources`.

### Invitations pour les comptes d'utilisateurs { #webapi_user_invitations } 

L'API Web permet d'inviter des personnes à créer des comptes d'utilisateur par le biais de la ressource
`invite`. Pour créer une invitation, vous devez POSTER un utilisateur au format XML
ou JSON à la ressource "invite". Un nom d'utilisateur spécifique peut être imposé
en définissant le nom d'utilisateur dans l'entité postée. En omettant le nom d'utilisateur,
la personne pourra le spécifier elle-même. Le système enverra
une invitation par courrier électronique. Il faut pour cela que les paramètres de messagerie soient
correctement configurés.

La ressource "invite" est utile pour permettre en toute sécurité
à des personnes de créer des comptes sans que personne d'autre ne connaisse le mot de passe
ou en transférant le mot de passe en texte clair. La charge utile à utiliser pour
l'invitation est la même que pour la création d'utilisateurs. Un exemple de charge utile en JSON
ressemble à ceci :

```json
{
  "prénom": "John",
  "nom": "Doe",
  "email": "johndoe@mail.com",
  "informations d'identification de l'utilisateur": {
    "nom d'utilisateur": "johndoe",
    "roles d'utilisateur": [{
      "id": "Euq3XfEIEbx"
    }]
  },
  "unités d'organisation": [ {
    "id": "ImspTQPwCqd"
  } ],
  "groupes d'utilisateurs": [ {
    "id": "vAvEltyXGbD"
  }]
}
```

L'entité d'invitation de l'utilisateur peut être affichée comme suit :

```bash
curl -d @invite.json "localhost/api/33/users/invite" -u admin:district
  -H "Content-Type:application/json"
```

Pour envoyer des invitations à plusieurs utilisateurs en même temps, vous devez utiliser un 
format légèrement différent. Pour JSON :

```json
{
  "utilisateurs": [ {
    "prénom": "John",
    "nom": "Doe",
    "email": "johndoe@mail.com",
    "informations d'identification de l'utilisateur": {
      "nom d'utilisateur": "johndoe",
      "rôles d'utilisateur": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "unités d'organisation": [ {
      "id": "ImspTQPwCqd"
      } ]
    }, {
    "prénom": "Tom",
    "nom": "Johnson",
    "email": "tomj@mail.com",
    "informations d'identification de l'utilisateur": {
      "rôles d'utilisateur": [ {
        "id": "Euq3XfEIEbx"
      } ]
    },
    "unités d'organisation": [ {
      "id": "ImspTQPwCqd"
      } ]
    }
  ]
}
```

Pour créer plusieurs invitations, vous pouvez envoyer la charge utile à la ressource
api/users/invites comme ceci :

```bash
curl -d @invites.json "localhost/api/33/users/invites" -u admin:district
  -H "Content-Type:application/json"
```

Certaines conditions doivent être remplies pour que les invitations à ouvrir un compte d'utilisateur soient 
envoyées :

  - Le serveur SMTP doit être configuré correctement sur le serveur.

  - L'utilisateur à inviter doit avoir indiqué un e-mail valide.

  - Si le nom d'utilisateur est spécifié, il ne doit pas être déjà pris par un autre
    utilisateur existant.

Si l'une de ces conditions n'est pas remplie, la ressource invitée renvoie 
un code d'état *409 Conflict* accompagné d'un message descriptif.

### Réplication de l'utilisateur { #webapi_user_replication } 

Pour répliquer un utilisateur, vous pouvez utiliser la ressource *replica*. Répliquer un
utilisateur peut être utile pour déboguer ou reproduire des problèmes signalés par un
particulier. Vous devez fournir un nouveau nom d'utilisateur et un nouveau mot de passe à l'utilisateur 
répliqué, que vous allez utiliser pour vous authentifier ultérieurement. Notez que vous
avez besoin de l'autorisation ALL pour effectuer cette action. Pour répliquer un utilisateur, vous
vous pouvez envoyer une charge utile JSON comme ci-dessous :

```json
{
  "nom d'utilisateur" : " utilisateur_replica",
  "mot de passe" : " Motdepassesecret "
}
```

Cette charge utile peut être envoyée à la ressource réplique, où vous fournissez
l'identifiant de l'utilisateur à répliquer dans l'URL :

    /api/33/users/<uid>/replica

Voici un exemple de reproduction d'un utilisateur à l'aide de curl :

```bash
curl -d @replica.json "localhost/api/33/users/N3PZBUlN8vq/replica"
  -H "Content-Type:application/json" -u admin:district
```

### Réinitialiser le mot de passe de l'utilisateur { #webapi_user_reset }

Les administrateurs utilisateurs (disposant des droits appropriés) peuvent réinitialiser le compte 
d'un autre utilisateur en déclenchant la récupération du mot de passe. Une fois l'opération déclenchée, un e-mail contenant un lien de récupération 
est envoyé à l'utilisateur. Les utilisateurs qui suivent le lien accèdent à un formulaire qui leur 
permet de définir un nouveau mot de passe.

Pour déclencher ce flux de travail pour l'utilisateur `tH7WIiIJ0O3`, utilisez :

    POST /api/37/users/tH7WIiIJ0O3/reset

### Désactiver et activer des comptes d'utilisateurs { #webapi_user_disable } 

Les comptes d'utilisateurs peuvent être marqués comme désactivés.
Un utilisateur désactivé ne peut plus se connecter.

Pour marquer un utilisateur avec l'UID `tH7WIiIJ0O3` comme désactivé (nécessite un utilisateur avec les droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/disabled

Pour permettre à un utilisateur désactivé d'utiliser à nouveau l'outil en question (l'utilisateur doit disposer des droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/enabled

### Expiration de l'utilisateur { #webapi_user_expiration } 

Une date d'expiration peut être définie pour un compte d'utilisateur.
Elle marque le moment à partir duquel le compte d'utilisateur a expiré 
et ne peut plus être utilisé. L'utilisateur dont le compte a expiré ne peut plus se connecter.

Pour mettre à jour la date d'expiration de l'utilisateur avec l'UID `tH7WIiIJ0O3` 
et la mettre à la date `2021-01-01` (nécessite un utilisateur avec les droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/expired?date=2021-01-01

Pour désactiver la date d'expiration afin que le compte n'expire jamais 
utiliser en conséquence (nécessite un utilisateur disposant des droits appropriés) :

    POST /api/36/users/tH7WIiIJ0O3/unexpired

### Flux de travail pour l'approbation des données des utilisateurs { #user-data-approval-workflows } 

Pour connaître les flux de travail et les niveaux d'approbation des données auxquels un utilisateur peut accéder, 
vous pouvez utiliser la ressource *dataApprovalWorkflows* comme suit :

```
GET /api/users/{id}/dataApprovalWorkflows
```

## Informations sur l'utilisateur actuel { #webapi_current_user_information } 

Pour obtenir des informations sur l'utilisateur actuellement authentifié et ses associations 
avec d'autres ressources, vous pouvez utiliser la ressource *me* 
(vous pouvez également l'appeler par son ancien nom *currentUser*). Les 
ressources liées à l'utilisateur actuel fournissent des informations utiles lors 
de la création de clients, par exemple pour la saisie de données et la gestion des utilisateurs. Les 
paragraphes suivants décrivent ces ressources et leur objectif.

Fournit des informations de base sur l'utilisateur sous lequel vous êtes actuellement connecté.
en tant qu'utilisateur, y compris le nom d'utilisateur, les informations d'identification de l'utilisateur, les unités d'organisation 
affectées:

    /api/me

Donne des informations sur les messages non lus et les interprétations :

    /api/me/tableau de bord

Pour modifier le mot de passe, ce point d'extrémité peut être utilisé pour valider le mot de passe nouvellement saisi.
le nouveau mot de passe. La validation du mot de passe sera effectuée sur la base des
PasswordValidationRules configurées dans le système. Ce point d'extrémité prend en charge
POST et la chaîne du mot de passe doit être envoyée dans le corps de POST.

    /api/me/valider le mot de passe

Lors d'un changement de mot de passe, ce point final (support POST) peut être utilisé pour
vérifier l'ancien mot de passe. La chaîne du mot de passe doit être envoyée dans le corps du POST.

    /api/me/verifier le mot de passe

Renvoie l'ensemble des autorisations accordées à l'utilisateur actuel :

    /api/me/authorisation

Renvoie vrai ou faux, indiquant si l'utilisateur actuel a 
reçu l'autorisation `<auth>` donnée:

    /api/me/authorisation/<auth>

Indique les niveaux d'approbation des données correspondant à l'utilisateur actuel :

    /api/me/Niveaux d'approbation des données

Indique les flux de travail d'approbation des données accessibles à l'utilisateur actuel.
Pour chaque flux de travail, indique les niveaux d'approbation des données que l'utilisateur peut voir, et
les autorisations dont il dispose à chaque niveau :

    /api/me/dataApprovalWorkflows



# Paramètres et configuration { #settings-and-configuration } 

## Paramètres du système { #webapi_system_settings } 

Vous pouvez manipuler les paramètres du système en interagissant avec la ressource
*systemSettings*. Un paramètre système est une simple paire clé-valeur,
où la clé et la valeur sont des chaînes de texte en clair. Pour enregistrer ou
mettre à jour un paramètre système, vous pouvez envoyer une requête *POST* à l'URL suivante :

    /api/33/systemSettings/my-key?value=my-val

Vous pouvez également soumettre la valeur du paramètre dans le corps de la requête,
où le type de contenu est défini sur "texte/clair". Par exemple, vous pouvez utiliser
curl comme suit :

```bash
curl "play.dhis2.org/demo/api/33/systemSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

Pour définir les paramètres du système en bloc, vous pouvez envoyer un objet JSON avec une 
propriété et une valeur pour chaque paire clé-valeur de paramètre du système à l'aide d'une requête POST :

```json
{
  "notification de l'application clé" : "Bienvenue",
  "intro de l'application clé": "DHIS2",
  "pied de page de l'application clé" : "En savoir plus sur dhis2.org"
}
```

Les traductions pour les clés de paramétrage traduisibles peuvent être définies en spécifiant  le paramètre local  comme 
paramètre de requête et la valeur traduite qui peut être spécifiée 
soit comme paramètre de requête, soit dans la charge utile du corps. Voir un exemple d'URL :

    /api/33/systemSettings/<my-key>?locale=<my-locale>&value=<my-translated-value>

Vous devez remplacer my-key par votre clé réelle et my-val par votre valeur 
réelle. Pour récupérer la valeur d'une clé donnée (en JSON ou en texte brut)
vous pouvez envoyer une requête *GET* à l'URL suivante :

    /api/33/systemSettings/my-key

Alternativement, vous pouvez spécifier la clé en tant que paramètre de requête :

    /api/33/systemSettings?key=my-key

Vous pouvez récupérer des paramètres système spécifiques sous forme de JSON en répétant la clé
paramètre de la requête :

```bash
curl "play.dhis2.org/demo/api/33/systemSettings?key=keyApplicationNotification&key=keyApplicationIntro"
  -u admin:district
```

Vous pouvez récupérer tous les paramètres du système à l'aide d'une requête GET :

    /api/33/systemSettings

Pour récupérer une traduction spécifique pour une clé traduisible donnée, vous pouvez spécifier
un paramètre local comme paramètre de requête :

    /api/33/systemSettings/<my-key>?locale=<my-locale>

Si elle est présente, la traduction pour le paramètre local donné est renvoyée. Sinon, une valeur
est renvoyée. Si aucun paramètre local n'est spécifié pour la clé traduisible, le paramètre local par défaut de 
l'interface utilisateur est utilisé pour obtenir la traduction correcte. Si la traduction donnée n'est pas
présente, la valeur par défaut est renvoyée.

La priorité pour les clés traduisibles est la suivante :

 locale spécifiée > UI local par défaut de l'utilisateur > valeur par défaut

Pour supprimer un paramètre du système, vous pouvez envoyer une requête *DELETE* à l'URL
similaire à celle utilisée ci-dessus pour la récupération. Si une clé traduisible est
utilisée, toutes les traductions présentes seront également supprimées.

Pour supprimer uniquement une traduction spécifique d'une clé traduisible, il convient d'utiliser la même URL
que pour l'ajout d'une traduction et la valeur vide doit être
fournie :

    /api/33/systemSettings/<my-key>?locale=<my-locale>&value=

Les paramètres système disponibles sont énumérés ci-dessous.



Tableau : Paramètres du système

| Clé | Description | Traduisible |
|---|---|---|
| cléUiLocale | Paramètre local pour l'interface utilisateur | Non |
| cléDbLocale | Paramètre local de la base de données | Non |
| Propriété d'affichage de l'analyse clé | La propriété à afficher dans l'analyse. Par défaut : " nom " | Non |
| Séparateur de groupes de chiffres de l'analyse clé | Le séparateur utilisé pour séparer les groupes de chiffres | Non |
| type clé du domaine actuel | Pas encore en service | Non |
| présentation du tableau de bord clé du tracker | Used by tracker capture | Non |
| applicationTitle | The application title. Default: "DHIS2" | Oui |
| keyApplicationIntro | La présentation de l'application | Oui |
| Notification clé de l'application | Notification de l'application | Oui |
| keyApplicationFooter | Application left footer | Oui |
| keyApplicationRightFooter | Application right footer | Oui |
| keyFlag | Application flag | Non |
| keyFlagImage | Flag used in dashboard menu | Non |
| startModule | La page de démarrage de l'application. Par défaut :  " Intégration du-tableau de bord-de dhis-web  " | Non |
| factorDeviation | Facteur d'écart-type de l'analyse des données. Par défaut :"2d" | Non |
| keyEmailHostName | Email server hostname | Non |
| keyEmailPort | Email server port | Non |
| keyEmailTls | Use TLS. Default: "true" | Non |
| keyEmailSender | Email sender | Non |
| keyEmailUsername | Email server username | Non |
| keyEmailPassword | Email server password | Non |
| minPasswordLength | Minimum length of password | Non |
| maxPasswordLength | Maximum length of password | Non |
| keySmsSetting | Configuration de SMS | Non |
| keyCacheStrategy | Stratégie de mise en cache. Par défaut : " MIS EN CACHE_6H_DEMAIN " | Non |
| keyCacheability | PUBLIC ou PRIVÉ. Détermine si les serveurs proxy sont autorisés à mettre des données en cache ou non. | Non |
| phoneNumberAreaCode | Phonenumber area code | Non |
| multiOrganisationUnitForms | Permet d'activer les formulaires d'unités multi-organisations. Par défaut :  " faux  " | Non |
| keyConfig || Non |
| keyAccountRecovery | Active la récupération des comptes d'utilisateurs. Par défaut : " faux " | Non |
| keyLockMultipleFailedLogins | Active le verrouillage de l'accès après plusieurs échecs de connexion | Non |
| googleAnalyticsUA | Google Analytic UA key for tracking site-usage | Non |
| credentialsExpires | Require user account password change. Default: "0" (Never) | Non |
| credentialsExpiryAlert | Enable alert when credentials are close to expiration date | Non |
| alerte d'expiration du compte | Envoi un e-mail d'alerte aux utilisateurs dont le compte est sur le point d'expirer en raison d'une date d'expiration définie. Par défaut : " faux " | Non |
| accountExpiresInDays | Number of days the account expiry alert should be send in advance of the actual expiry. Default: 7 | Non |
| keySelfRegistrationNoRecaptcha | Do not require recaptcha for self registration. Default: "false" | Non |
| recaptchaSecret | Google API recaptcha secret. Default: dhis2 play instance API secret, but this will only works on you local instance and not in production. | Non |
| recaptchaSite | Google API recaptcha site. Default: dhis2 play instance API site, but this will only works on you local instance and not in production. | Non |
| keyCanGrantOwnUserAuthorityGroups | Allow users to grant own user roles. Default: "false" | Non |
| keySqlViewMaxLimit | Max limit for SQL view | Non |
| keyRespectMetaDataStartEndDatesInAnalyticsTableExport | When "true", analytics will skip data not within category option's start and end dates. Default: "false" | Non |
| keySkipDataTypeValidationInAnalyticsTableExport | Skips data type validation in analytics table export | Non |
| keyCustomLoginPageLogo | Logo for custom login page | Non |
| keyCustomTopMenuLogo | Logo for custom top menu | Non |
| keyCacheAnalyticsDataYearThreshold | Analytics data older than this value (in years) will always be cached. "0" disabled this setting. Default: 0 | Non |
| keyCacheAnalyticsDataYearThreshold | Analytics data older than this value (in years) will always be cached. "0" disabled this setting. Default: 0 | Non |
| analyticsFinancialYearStart | Set financial year start. Default: October | Non |
| keyIgnoreAnalyticsApprovalYearThreshold | "0" check approval for all data. "-1" disable approval checking. "1" or higher checks approval for all data that is newer than "1" year. | Non |
| keyAnalyticsMaxLimit | Maximum number of analytics recors. Default: "50000" | Non |
| keyAnalyticsMaintenanceMode | Put analytics in maintenance mode. Default: "false" | Non |
| keyDatabaseServerCpus | Number of database server CPUs. Default: "0" (Automatic) | Non |
| keyLastSuccessfulAnalyticsTablesRuntime | Keeps timestamp of last successful analytics tables run | Non |
| keyLastSuccessfulLatestAnalyticsPartitionRuntime | Keeps timestamp of last successful latest analytics partition run | Non |
| keyLastMonitoringRun | Keeps timestamp of last monitoring run | Non |
| keyLastSuccessfulDataSynch | Keeps timestamp of last successful data values synchronization | Non |
| keyLastSuccessfulEventsDataSynch | Keeps timestamp of last successful Event programs data synchronization | Non |
| keyLastCompleteDataSetRegistrationSyncSuccess | Keeps timestamp of last successful completeness synchronization | Non |
| syncSkipSyncForDataChangedBefore | Specifies timestamp used to skip synchronization of all the data changed before this point in time | Non |
| keyLastSuccessfulAnalyticsTablesUpdate | Keeps timestamp of last successful analytics tables update | Non |
| keyLastSuccessfulLatestAnalyticsPartitionUpdate | Keeps timestamp of last successful latest analytics partition update | Non |
| keyLastSuccessfulResourceTablesUpdate | Keeps timestamp of last successful resource tables update | Non |
| keyLastSuccessfulSystemMonitoringPush | Keeps timestamp of last successful system monitoring push | Non |
| keyLastSuccessfulMonitoring | Keeps timestamp of last successful monitoring | Non |
| keyNextAnalyticsTableUpdate | Keeps timestamp of next analytics table update | Non |
| helpPageLink | Link to help page. Default: "[https://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html](http://dhis2.github.io/dhis2-docs/master/en/user/html/dhis2_user_manual_en.html) | Non |
| keyAcceptanceRequiredForApproval | Acceptance required before approval. Default: "false" | Non |
| keySystemNotificationsEmail | Where to email system notifications | Non |
| keyAnalysisRelativePeriod | Default relative period for analysis. Default: "LAST_12_MONTHS" | Non |
| keyRequireAddToView | Require authority to add to view object lists. Default: "false" | Non |
| keyAllowObjectAssignment | Allow assigning object to related objects during add or update. Default: "false" | Non |
| keyUseCustomLogoFront | Enables the usage of a custom logo on the front page. Default: "false" | Non |
| keyUseCustomLogoBanner | Enables the usage of a custom banner on the website. Default: "false" | Non |
| keyDataImportStrictPeriods || Non |
| keyDataImportStrictPeriods | Require periods to match period type of data set. Default: "false" | Non |
| keyDataImportStrictDataElements | Require data elements to be part of data set. Default: "false" | Non |
| keyDataImportStrictCategoryOptionCombos | Require category option combos to match category combo of data element. Default: "false" | Non |
| keyDataImportStrictOrganisationUnits | Require organisation units to match assignment of data set. Default: "false" | Non |
| keyDataImportStrictAttributeOptionsCombos | Require attribute option combis to match category combo of data set. Default: "false" | Non |
| keyDataImportRequireCategoryOptionCombo | Require category option combo to be specified. Default: "false" | Non |
| keyDataImportRequireAttributeOptionCombo | Require attribute option combo to be specified. Default: "false" | Non |
| keyCustomJs | Custom JavaScript to be used on the website | Non |
| keyCustomCss | Custom CSS to be used on the website | Non |
| keyCalendar | The calendar type. Default: "iso8601". | Non |
| keyDateFormat | The format in which dates should be displayed. Default: "yyyy-MM-dd". | Non |
| keyStyle | The style used on the DHIS2 webpages. Default: "light_blue/light_blue.css". | Non |
| keyRemoteInstanceUrl | Url used to connect to remote instance | Non |
| keyRemoteInstanceUsername | Username used to connect to remote DHIS2 instance | Non |
| keyRemoteInstancePassword | Password used to connect to remote DHIS2 instance | Non |
| keyGoogleMapsApiKey | Google Maps API key | Non |
| keyGoogleCloudApiKey | Google Cloud API key | Non |
| keyLastMetaDataSyncSuccess | Keeps timestamp of last successful metadata synchronization | Non |
| keyVersionEnabled | Enables metadata versioning | Non |
| keyMetadataFailedVersion | Keeps details about failed metadata version sync | Non |
| keyMetadataLastFailedTime | Keeps timestamp of last metadata synchronization failure | Non |
| keyLastSuccessfulScheduledProgramNotifications || Non |
| keyLastSuccessfulScheduledDataSetNotifications || Non |
| keyRemoteMetadataVersion | Details about metadata version of remote instance | Non |
| keySystemMetadataVersion | Details about metadata version of the system | Non |
| keyStopMetadataSync | Flag to stop metadata synchronization | Non |
| keyFileResourceRetentionStrategy | Determines how long file resources associated with deleted or updated values are kept. NONE, THREE_MONTHS, ONE_YEAR, or FOREVER. | Non |
| syncMaxRemoteServerAvailabilityCheckAttempts | Specifies how many times the availability of remote server will be checked before synchronization jobs fail. | Non |
| syncMaxAttempts | Specifies max attempts for synchronization jobs | Non |
| syncDelayBetweenRemoteServerAvailabilityCheckAttempts | Delay between remote server availability checks | Non |
| lastSuccessfulDataStatistics | Keeps timestamp of last successful data analytics | Non |
| keyHideDailyPeriods | Not in use | Non |
| keyHideWeeklyPeriods || Non |
| keyHideBiWeeklyPeriods | Boolean flag used to hide/show bi-weekly periods | Non |
| keyHideMonthlyPeriods || Non |
| keyHideBiMonthlyPeriods || Non |
| keyGatherAnalyticalObjectStatisticsInDashboardViews | Whether to gather analytical statistics on objects when they are viewed within a dashboard | Non |
| keyCountPassiveDashboardViewsInUsageAnalytics | Counts "passive" dashboard views (not selecting a particular dashboard) in usage analytics | Non |
| keyDashboardContextMenuItemSwitchViewType | Allow users to switch dashboard favorites' view type | Oui |
| keyDashboardContextMenuItemOpenInRelevantApp | Allow users to open dashboard favorites in relevant apps | Oui |
| keyDashboardContextMenuItemShowInterpretationsAndDetails | Allow users to show dashboard favorites' interpretations and details | Oui |
| keyDashboardContextMenuItemViewFullscreen | Allow users to view dashboard favorites in fullscreen | Oui |


## Paramètres de l'utilisateur { #webapi_user_settings } 

You can manipulate user settings by interacting with the *userSettings*
resource. A user setting is a simple key-value pair, where both the key
and the value are plain text strings. The user setting will be linked to
the user who is authenticated for the Web API request. To return a list
of all user settings, you can send a *GET* request to the following URL:

    /api/33/userSettings

User settings not set by the user, will fall back to the equivalent
system setting. To only return the values set explicitly by the user,
you can append ?useFallback=false to the above URL, like this:

    /api/33/userSettings?useFallback=false

To save or update a setting for the currently authenticated user you can
make a *POST* request to the following URL:

    /api/33/userSettings/my-key?value=my-val

You can specify the user for which to save the setting explicitly with
this syntax:

    /api/33/userSettings/my-key?user=username&value=my-val

Vous pouvez également soumettre la valeur du paramètre dans le corps de la requête,
où le type de contenu est défini sur "texte/clair". Par exemple, vous pouvez utiliser
curl comme suit :

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/my-key" -d "My long value"
  -H "Content-Type: text/plain" -u admin:district
```

As an example, to set the UI locale of the current user to French you
can use the following command.

```bash
curl "https://play.dhis2.org/demo/api/33/userSettings/keyUiLocale?value=fr"
  -X POST -u admin:district
```

You should replace my-key with your real key and my-val with your real
value. To retrieve the value for a given key in plain text you can make
a *GET* request to the following URL:

    /api/33/userSettings/my-key

To delete a user setting, you can make a *DELETE* request to the URL
similar to the one used above for retrieval.

Les paramètres système disponibles sont énumérés ci-dessous.



Table: User settings

| Clé | Options | Description |
|---|---|---|
| keyStyle | light_blue/light_blue.css &#124; green/green.css &#124; vietnam/vietnam.css | User interface stylesheet. |
| keyMessageEmailNotification | faux &#124; vrai | Whether to send email notifications. |
| keyMessageSmsNotification | faux &#124; vrai | Whether to send SMS notifications. |
| cléUiLocale | Valeur locale | User interface locale. |
| cléDbLocale | Valeur locale | Database content locale. |
| Propriété d'affichage de l'analyse clé | nom &#124; Nom court | Property to display for metadata in analysis apps. |
| type clé du domaine actuel | all &#124; aggregate &#124; tracker | Data element domain type to display in lists. |
| keyAutoSaveCaseEntryForm | faux &#124; vrai | Save case entry forms periodically. |
| keyAutoSaveTrackedEntityForm | faux &#124; vrai | Save person registration forms periodically. |
| keyAutoSaveDataEntryForm | faux &#124; vrai | Save aggregate data entry forms periodically. |
| présentation du tableau de bord clé du tracker | faux &#124; vrai | Tracker dasboard layout. |

## Configuration { #webapi_configuration } 

To access configuration you can interact with the *configuration*
resource. You can get XML and JSON responses through the *Accept* header
or by using the .json or .xml extensions. You can *GET* all properties
of the configuration from:

    /api/33/configuration

You can send *GET* and *POST* requests to the following specific
resources:

    GET /api/33/configuration/systemId

    GET POST DELETE /api/33/configuration/feedbackRecipients

    GET POST DELETE /api/33/configuration/offlineOrganisationUnitLevel

    GET POST /api/33/configuration/infrastructuralDataElements

    GET POST /api/33/configuration/infrastructuralIndicators

    GET POST /api/33/configuration/infrastructuralPeriodType

    GET POST DELETE /api/33/configuration/selfRegistrationRole

    GET POST DELETE /api/33/configuration/selfRegistrationOrgUnit

For the CORS whitelist configuration you can make a POST request with an
array of URLs to whitelist as payload using "application/json" as
content-type, for instance:

```json
["www.google.com", "www.dhis2.org", "www.who.int"]
```

    GET POST /api/33/configuration/corsWhitelist

For POST requests, the configuration value should be sent as the request
payload as text. The following table shows appropriate configuration
values for each property.



Table: Configuration values

| Configuration property | Valeur |
|---|---|
| feedbackRecipients | User group ID |
| offlineOrganisationUnitLevel | Organisation unit level ID |
| infrastructuralDataElements | Data element group ID |
| infrastructuralIndicators | Indicator group ID |
| infrastructuralPeriodType | Period type name (e.g. "Monthly") |
| selfRegistrationRole | User role ID |
| selfRegistrationOrgUnit | Organisation unit ID |
| smtpPassword | SMTP email server password |
| remoteServerUrl | URL to remote server |
| remoteServerUsername | Username for remote server authentication |
| remoteServerPassword | Password for remote server authentication |
| corsWhitelist | JSON list of URLs |

As an example, to set the feedback recipients user group you can invoke
the following curl command:

```bash
curl "localhost/api/33/configuration/feedbackRecipients" -d "wl5cDMuUhmF"
  -H "Content-Type:text/plain"-u admin:district
```

## Read-only configuration { #webapi_readonly_configuration_interface } 

To access all configuration settings and properties you can use the read-only configuration endpoint. This will provide read-only access to *UserSettings, SystemSettings and DHIS2 server configurations* You can get XML and JSON responses through the *Accept* header. You can *GET* all settings from:

    /api/33/configuration/settings

You can get filtered settings based on setting type:

    GET /api/33/configuration/settings/filter?type=USER_SETTING

    GET /api/33/configuration/settings/filter?type=CONFIGURATION

More than one type can be provided:

    GET /api/33/configuration/settings/filter?type=USER_SETTING&type=SYSTEM_SETTING



Table: SettingType values

| Valeur | Description |
|---|---|
| USER_SETTING | To get user settings |
| SYSTEM_SETTING | To get system settings |
| CONFIGURATION | To get DHIS server settings |

> **Note**
>
> Fields which are confidential will be provided in the output but without values.

## Jetons { #webapi_tokens } 

The *tokens* resource provides access tokens to various services.

### Google Service Account { #webapi_tokens_google_service_account } 

You can retrieve a Google service account OAuth 2.0 access token with a
GET request to the following resource.

    GET /api/tokens/google

The token will be valid for a certain amount of time, after which
another token must be requested from this resource. The response
contains a cache control header which matches the token expiration. The
response will contain the following properties in JSON format.



Table: Token response

| Propriété | Description |
|---|---|
| access_token | The OAuth 2.0 access token to be used when authentication against Google services. |
| expires_in | The number of seconds until the access token expires, typically 3600 seconds (1 hour). |
| client_id | The Google service account client id. |

This assumes that a Google service account has been set up and configured for DHIS2. Please consult the installation guide for more info.

## Static content { #webapi_static_content } 

The *staticContent* resource allows you to upload and retrieve custom
logos used in DHIS2. The resource lets the user upload a file with an
associated key, which can later be retrieved using the key. Only PNG
files are supported and can only be uploaded to the `logo_banner` and
`logo_front` keys.

    /api/33/staticContent



Table: Static content keys

| Clé | Description |
|---|---|
| logo_banner | Logo in the application top menu on the left side. |
| logo_front | Logo on the login-page above the login form. |

To upload a file, send the file with a *POST* request to:

    POST /api/33/staticContent/<key>

Example request to upload logo.png to the `logo_front` key:

```bash
curl -F "file=@logo.png;type=image/png" "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -X POST -H "Content-Type: multipart/form-data" -u admin:district
```

Uploading multiple files with the same key will overwrite the existing
file. This way, retrieving a file for any given key will only return the
latest file uploaded.

To retrieve a logo, you can *GET* the following:

    GET /api/33/staticContent/<key>

Example of requests to retrieve the file stored for `logo_front`:

* Adding "Accept: text/html" to the HTTP header.*__ In this case, the endpoint will return a default image if nothing is defined. Will return an image stream when a custom or default image is found.

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -H "Accept: text/html" -L -u admin:district
```

* Adding "Accept: application/json" to the HTTP header.*__ With this parameter set, the endpoint will never return a default image if the custom logo is not found. Instead, an error message will be returned. When the custom image is found this endpoint will return a JSON response containing the path/URL to the respective image.

```bash
curl "https://play.dhis2.org/demo/api/33/staticContent/logo_front"
  -H "Accept: application/json" -L -u admin:district
```

Success and error messages will look like this:

```json
{
  "images": {
    "png": "http://localhost:8080/dhis/api/staticContent/logo_front"
  }
}
```

```json
{
  "httpStatus": "Non trouvé",
  "httpStatusCode": 404,
  "statut": "ERREUR",
  "message": "Aucun fichier personnalisé n'a été trouvé."
}
```

To use custom logos, you need to enable the corresponding system
settings by setting it to *true*. If the corresponding setting is false,
the default logo will be served.

## UI customization { #webapi_ui_customization } 

To customize the UI of the DHIS2 application you can insert custom
JavaScript and CSS styles through the *files* resource.

```
POST GET DELETE /api/33/files/script
POST GET DELETE /api/33/files/style
```

The JavaScript and CSS content inserted through this resource will be loaded by the
DHIS2 web application. This can be particularly useful in certain situations:

  - Overriding the CSS styles of the DHIS2 application, such as the
    login page or main page.

  - Defining JavaScript functions which are common to several custom
    data entry forms and HTML-based reports.

  - Including CSS styles which are used in custom data entry forms and
    HTML-based reports.

### Javascript { #webapi_customization_javascript } 

To insert Javascript from a file called *script.js* you can interact
with the *files/script* resource with a POST request:

```bash
curl --data-binary @script.js "localhost/api/33/files/script"
  -H "Content-Type:application/javascript" -u admin:district
```

Note that we use the `--data-binary` option to preserve formatting of the
file content. You can fetch the JavaScript content with a GET request:

    /api/33/files/script

Pour supprimer le contenu JavaScript, vous pouvez utiliser une requête de type SUPPRIMER (DELETE).

### CSS { #webapi_customization_css } 

To insert CSS from a file called *style.css* you can interact with the
*files/style* resource with a POST-request:

```bash
curl --data-binary @style.css "localhost/api/33/files/style"
  -H "Content-Type:text/css" -u admin:district
```

Vous pouvez récupérer le contenu CSS à l'aide d'une requête GET :

    /api/33/files/style

Pour supprimer le contenu JavaScript, vous pouvez utiliser une requête de type SUPPRIMER (DELETE).



# Tracker { #tracker } 

## Tracker Web API { #webapi_tracker_api } 

Tracker Web API consists of 3 endpoints that have full CRUD (create,
read, update, delete) support. The 3 endpoints are
`/api/trackedEntityInstances`, `/api/enrollments` and
`/api/events` and they are responsible for tracked entity instance,
enrollment and event items.

### Tracked entity instance management { #webapi_tracked_entity_instance_management } 

Tracked entity instances have full CRUD support in the API. Together
with the API for enrollment most operations needed for working with
tracked entity instances and programs are supported.

    /api/33/trackedEntityInstances

#### Creating a new tracked entity instance { #webapi_creating_tei } 

For creating a new person in the system, you will be working with the
*trackedEntityInstances* resource. A template payload can be seen below:

```json
{
  "trackedEntity": "tracked-entity-id",
  "orgUnit": "org-unit-id",
  "geometry": "<Geo JSON>",
  "attributes": [{
    "attribute": "attribute-id",
    "value": "attribute-value"
  }]
}
```

The field "geometry" accepts a GeoJson object, where the type of the
GeoJson have to match the featureType of the TrackedEntityType
definition. An example GeoJson object looks like this:

```json
{
  "type": "Point",
  "coordinates": [1, 1]
}
```

The "coordinates" field was introduced in 2.29, and accepts a coordinate
or a polygon as a value.

For getting the IDs for `relationship` and `attributes` you can have a look
at the respective resources `relationshipTypes`, `trackedEntityAttributes`.
To create a tracked entity instance you must use the HTTP *POST* method.
You can post the payload the following URL:

    /api/trackedEntityInstances

For example, let us create a new instance of a person tracked entity and
specify its first name and last name attributes:

```json
{
  "trackedEntity": "nEenWmSyUEp",
  "orgUnit": "DiszpKrYNg8",
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "value": "Joe"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "value": "Smith"
    }
  ]
}
```

To push this to the server you can use the cURL command like this:

```bash
curl -d @tei.json "https://play.dhis2.org/demo/api/trackedEntityInstances" -X POST
  -H "Content-Type: application/json" -u admin:district
```

To create multiple instances in one request you can wrap the payload in
an outer array like this and POST to the same resource as above:[]()

```json
{
  "trackedEntityInstances": [
    {
      "trackedEntity": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": "Joe"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "value": "Smith"
        }
      ]
    },
    {
      "trackedEntity": "nEenWmSyUEp",
      "orgUnit": "DiszpKrYNg8",
      "attributes": [
        {
          "attribute": "w75KJ2mc4zz",
          "value": "Jennifer"
        },
        {
          "attribute": "zDhUuAYrxNC",
          "value": "Johnson"
        }
      ]
    }
  ]
}
```

The system does not allow the creation of a tracked entity instance
(as well as enrollment and event) with a UID that was already used in
the system. That means that UIDs cannot be reused.

#### Updating a tracked entity instance { #webapi_updating_tei } 

For updating a tracked entity instance, the payload is equal to the
previous section. The difference is that you must use the HTTP *PUT*
method for the request when sending the payload. You will also need to
append the person identifier to the *trackedEntityInstances* resource in
the URL like this, where `<tracked-entity-instance-identifier>` should
be replaced by the identifier of the tracked entity instance:

    /api/trackedEntityInstances/<tracked-entity-instance-id>

The payload has to contain all, even non-modified, attributes and
relationships. Attributes or relationships that were present before and
are not present in the current payload any more will be removed from the
system. This means that if attributes/relationships are empty in the
current payload, all existing attributes/relationships will be deleted
from the system. From 2.31, it is possible to ignore empty
attributes/relationships in the current payload. A request parameter of
`ignoreEmptyCollection` set to `true` can be used in case you do not
wish to send in any attributes/relationships and also do not want them
to be deleted from the system.

It is not allowed to update an already deleted tracked entity instance.
Also, it is not allowed to mark a tracked entity instance as deleted via
an update request. The same rules apply to enrollments and events.

#### Deleting a tracked entity instance { #webapi_deleting_tei } 

In order to delete a tracked entity instance, make a request to the URL
identifying the tracked entity instance with the *DELETE*
method. The URL is equal to the one above used for update.

#### Create and enroll tracked entity instances { #webapi_create_enroll_tei } 

It is also possible to both create (and update) a tracked entity
instance and at the same time enroll into a program.

```json
{
  "trackedEntity": "tracked-entity-id",
  "orgUnit": "org-unit-id",
  "attributes": [{
    "attribute": "attribute-id",
    "value": "attribute-value"
  }],
  "enrollments": [{
    "orgUnit": "org-unit-id",
    "program": "program-id",
    "enrollmentDate": "2013-09-17",
    "incidentDate": "2013-09-17"
   }, {
    "orgUnit": "org-unit-id",
    "program": "program-id",
    "enrollmentDate": "2013-09-17",
    "incidentDate": "2013-09-17"
   }]
}
```

You would send this to the server as you would normally when creating or
updating a new tracked entity instance.

```bash
curl -X POST -d @tei.json -H "Content-Type: application/json"
  -u user:pass "http://server/api/33/trackedEntityInstances"
```

#### Complete example of payload including: tracked entity instance, enrollment and event { #webapi_create_enroll_tei_create_event } 

It is also possible to create (and update) a tracked entity instance, at
the same time enroll into a program and create an event.

```json
{
  "trackedEntityType": "nEenWmSyUEp",
  "orgUnit": "DiszpKrYNg8",
  "attributes": [
    {
      "attribute": "w75KJ2mc4zz",
      "value": "Joe"
    },
    {
      "attribute": "zDhUuAYrxNC",
      "value": "Rufus"
    },
    {
     "attribute":"cejWyOfXge6",
     "value":"Male"
    }
  ],
  "enrollments":[
    {
      "orgUnit":"DiszpKrYNg8",
      "program":"ur1Edk5Oe2n",
      "enrollmentDate":"2017-09-15",
      "incidentDate":"2017-09-15",
      "events":[
        {
          "program":"ur1Edk5Oe2n",
          "orgUnit":"DiszpKrYNg8",
          "eventDate":"2017-10-17",
          "status":"COMPLETED",
          "storedBy":"admin",
          "programStage":"EPEcjy3FWmI",
          "coordinate": {
            "latitude":"59.8",
            "longitude":"10.9"
          },
          "dataValues": [
            {
              "dataElement":"qrur9Dvnyt5",
              "value":"22"
            },
            {
              "dataElement":"oZg33kd9taw",
              "value":"Male"
            }
         ]
      },
      {
         "program":"ur1Edk5Oe2n",
         "orgUnit":"DiszpKrYNg8",
         "eventDate":"2017-10-17",
         "status":"COMPLETED",
         "storedBy":"admin",
         "programStage":"EPEcjy3FWmI",
         "coordinate": {
           "latitude":"59.8",
           "longitude":"10.9"
         },
         "dataValues":[
           {
             "dataElement":"qrur9Dvnyt5",
             "value":"26"
           },
           {
             "dataElement":"oZg33kd9taw",
             "value":"Female"
           }
         ]
       }
     ]
    }
  ]  
}
```

You would send this to the server as you would normally when creating or
updating a new tracked entity instance.

```bash
curl -X POST -d @tei.json -H "Content-Type: application/json"
  -u user:pass "http://server/api/33/trackedEntityInstances"
```

#### Generated tracked entity instance attributes { #webapi_generate_tei_attributes } 

Tracked entity instance attributes that are using automatic generation of
unique values have three endpoints that are used by apps. The endpoints
are all used for generating and reserving values.

In 2.29 we introduced TextPattern for defining and generating these
patterns. All existing patterns will be converted to a valid TextPattern
when upgrading to 2.29.

> **Note**
>
> As of 2.29, all these endpoints will require you to include any
> variables reported by the `requiredValues` endpoint listed as
> required. Existing patterns, consisting of only `#`, will be upgraded
> to the new TextPattern syntax `RANDOM(<old-pattern>)`. The RANDOM
> segment of the TextPattern is not a required variable, so this
> endpoint will work as before for patterns defined before 2.29.

##### Finding required values { #finding-required-values } 

A TextPattern can contain variables that change based on different
factors. Some of these factors will be unknown to the server, so the
values for these variables have to be supplied when generating and
reserving values.

This endpoint will return a map of required and optional values, that
the server will inject into the TextPattern when generating new values.
Required variables have to be supplied for the generation, but optional
variables should only be supplied if you know what you are doing.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/requiredValues

```json
{
  "REQUIRED": [
    "ORG_UNIT_CODE"
  ],
  "OPTIONAL": [
    "RANDOM"
  ]
}
```

##### Generate value endpoint { #webapi_generate_values } 

Online web apps and other clients that want to generate a value that
will be used right away can use the simple generate endpoint. This
endpoint will generate a value that is guaranteed to be unique at the
time of generation. The value is also guaranteed not to be reserved. As
of 2.29, this endpoint will also reserve the value generated for 3 days.

If your TextPattern includes required values, you can pass them as
parameters like the example below:

The expiration time can also be overridden at the time of generation, by
adding the `?expiration=<number-of-days>` to the request.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generate?ORG_UNIT_CODE=OSLO

```json
{
  "ownerObject": "TRACKEDENTITYATTRIBUTE",
  "ownerUid": "Gs1ICEQTPlG",
  "key": "RANDOM(X)-OSL",
  "value": "C-OSL",
  "created": "2018-03-02T12:01:36.680",
  "expiryDate": "2018-03-05T12:01:36.678"
}
```

##### Generate and reserve value endpoint { #webapi_generate_reserve_values } 

The generate and reserve endpoint is used by offline clients that need
to be able to register tracked entities with unique ids. They will
reserve a number of unique ids that this device will then use when
registering new tracked entity instances. The endpoint is called to
retrieve a number of tracked entity instance reserved values. An
optional parameter numberToReserve specifies how many ids to generate
(default is 1).

If your TextPattern includes required values, you can pass them as
parameters like the example below:

Similar to the /generate endpoint, this endpoint can also specify the
expiration time in the same way. By adding the `?expiration=<number-of-days>`
you can override the default 60 days.

    GET /api/33/trackedEntityAttributes/Gs1ICEQTPlG/generateAndReserve?numberToReserve=3&ORG_UNIT_CODE=OSLO

```json
[
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "B-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "Q-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  },
  {
    "ownerObject": "TRACKEDENTITYATTRIBUTE",
    "ownerUid": "Gs1ICEQTPlG",
    "key": "RANDOM(X)-OSL",
    "value": "S-OSL",
    "created": "2018-03-02T13:22:35.175",
    "expiryDate": "2018-05-01T13:22:35.174"
  }
]
```

##### Reserved values { #reserved-values } 

Reserved values are currently not accessible through the api, however, they
are returned by the `generate` and `generateAndReserve` endpoints. The
following table explains the properties of the reserved value object:

#####



Table: Reserved values

| Propriété | Description |
|---|---|
| ownerObject | The metadata type referenced when generating and reserving the value. Currently only TRACKEDENTITYATTRIBUTE is supported. |
| ownerUid | The uid of the metadata object referenced when generating and reserving the value. |
| clé | A partially generated value where generated segments are not yet added. |
| valeur | The fully resolved value reserved. This is the value you send to the server when storing data. |
| créé | The timestamp when the reservation was made |
| expiryDate | The timestamp when the reservation will no longer be reserved |

Expired reservations are removed daily. If a pattern changes, values
that were already reserved will be accepted when storing data, even if
they don't match the new pattern, as long as the reservation has not
expired.

#### Image attributes { #image-attributes } 

Working with image attributes is a lot like working with file data
values. The value of an attribute with the image value type is the id of
the associated file resource. A GET request to the
`/api/trackedEntityInstances/<entityId>/<attributeId>/image`
endpoint will return the actual image. The optional height and width
parameters can be used to specify the dimensions of the image.

```bash
curl "http://server/api/33/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/image?height=200&width=200"
  > image.jpg
```

The API also supports a *dimension* parameter. It can take three possible values (please note capital letters): `SMALL` (254x254), `MEDIUM` (512x512), `LARGE` (1024x1024) or `ORIGINAL`. Image type attributes will be stored in pre-generated sizes
and will be furnished upon request based on the value of the `dimension` parameter.

```bash
curl "http://server/api/33/trackedEntityInstances/ZRyCnJ1qUXS/zDhUuAYrxNC/image?dimension=MEDIUM"
```

#### Tracked entity instance query { #webapi_tracked_entity_instance_query } 

To query for tracked entity instances you can interact with the
`/api/trackedEntityInstances` resource.

    /api/33/trackedEntityInstances

##### Request syntax { #webapi_tei_query_request_syntax } 



Table: Tracked entity instances query parameters

| Paramètre de requête | Description |
|---|---|
| filter | Attributes to use as a filter for the query. Param can be repeated any number of times. Filters can be applied to a dimension on the format <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>]. Filter values are case-insensitive and can be repeated together with operator any number of times. Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN. |
| ou | Organisation unit identifiers, separated by ";". |
| ou Mode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; CAPTURE &#124; ALL. Default is SELECTED, which refers to the selected selected organisation units only. See table below for explanations. |
| de paludisme) ». | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| suivi | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| Entité suivie | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| page | The page number. Default page is 1. |
| taille de la page | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| lastUpdatedStartDate | Filter for teis which were updated after this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedEndDate | Filter for teis which were updated up until this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedDuration (durée de la dernière mise à jour) | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). Cannot be used together with *lastUpdatedStartDate* and/or *lastUpdatedEndDate*. |
| Mode utilisateur attribué | Restricts result to tei with events assigned based on the assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser (Utilisateur assigné) | Filter the result down to a limited set of teis with events that are assigned to the given user IDs by using *assignedUser=id1;id2*.This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |
| trackedEntityInstance | Filter the result down to a limited set of teis using explicit uids of the tracked entity instances by using *trackedEntityInstance=id1;id2*. This parameter will at the very least create the outer boundary of the results, forming the list of all teis using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary. |
| includeDeleted | Indicates whether to include soft deleted teis or not. It is false by default. |
| potentialDuplicate | Il est possible de filtrer le résultat en supposant qu'une TEI soit un doublon potentiel. true: renvoie les TEI marqués comme doublons potentiels. false: renvoie les TEI NON marqués comme doublons potentiels. En cas d'omission, nous ne vérifions pas si une TEI est un doublon potentiel ou pas.|

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.



Table: Organisation unit selection modes

| Mode | Description |
|---|---|
| SELECTED | Unités d'organisation définies dans la requête. |
| CHILDREN | The selected organisation units and the immediate children, i.e. the organisation units at the level below. |
| DESCENDANTS | The selected organisation units and all children, i.e. all organisation units in the sub-hierarchy. |
| ACCESSIBLE | The data view organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| CAPTURE | The data capture organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. |
| ALL | Il s'agit de toutes les unités d'organisation du système. L'utilisateur doit disposer de l'autorité `TOUS` pour pouvoir l'utiliser. |

La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

  - At least one organisation unit must be specified using the *ou*
    parameter (one or many), or *ouMode=ALL* must be specified.

  - Only one of the *program* and *trackedEntity* parameters can be
    spécifié (zéro ou un).

  - If *programStatus* is specified then *program* must also be
    spécifiés.

  - If *followUp* is specified then *program* must also be specified.

  - If *programStartDate* or *programEndDate* is specified then
    *program* must also be specified.

  - Les éléments du filtre ne peuvent être spécifiés qu'une seule fois.

Une requête pour toutes les instances associées à une unité d'organisation spécifique peut ressembler à ceci :

    /api/33/trackedEntityInstances.json?ou=DiszpKrYNg8

To query for instances using one attribute with a filter and one
attribute without a filter, with one organisation unit using the
descendant organisation unit query mode:

    /api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A
      &filter=AMpUYgxuCaE&ou=DiszpKrYNg8;yMCshbaVExv

A query for instances where one attribute is included in the response
and one attribute is used as a filter:

    /api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A
      &filter=AMpUYgxuCaE:LIKE:Road&ou=DiszpKrYNg8

A query where multiple operand and filters are specified for a filter
item:

    api/33/trackedEntityInstances.json?ou=DiszpKrYNg8&program=ur1Edk5Oe2n
      &filter=lw1SqmMlnfh:GT:150:LT:190

To query on an attribute using multiple values in an *IN* filter:

    api/33/trackedEntityInstances.json?ou=DiszpKrYNg8
      &filter=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

To constrain the response to instances which are part of a specific
program you can include a program query parameter:

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &ouMode=DESCENDANTS&program=ur1Edk5Oe2n

To specify program enrollment dates as part of the query:

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &program=ur1Edk5Oe2n&programStartDate=2013-01-01&programEndDate=2013-09-01

To constrain the response to instances of a specific tracked entity you
can include a tracked entity query parameter:

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

By default the instances are returned in pages of size 50, to change
this you can use the page and pageSize query parameters:

    api/33/trackedEntityInstances.json?filter=zHXD5Ve1Efw:EQ:A&ou=O6uvpzGd5pu
      &ouMode=DESCENDANTS&page=2&pageSize=3

You can use a range of operators for the filtering:



Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Like (free text match) |
| IN | Equal to one of multiple values separated by ";" |

##### Response format { #webapi_tei_query_response_format } 

This resource supports JSON, JSONP, XLS and CSV resource
representations.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

The response in JSON/XML is in object format and can look like the
following. Please note that field filtering is supported, so if you want
a full view, you might want to add `fields=*` to the query:

```json
{
  "trackedEntityInstances": [
    {
      "lastUpdated": "2014-03-28 12:27:52.399",
      "trackedEntity": "cyl5vuJ5ETQ",
      "created": "2014-03-26 15:40:19.997",
      "orgUnit": "ueuQlqb8ccl",
      "trackedEntityInstance": "tphfdyIiVL6",
      "relationships": [],
      "attributes": [
        {
          "displayName": "Address",
          "attribute": "AMpUYgxuCaE",
          "type": "string",
          "value": "2033 Akasia St"
        },
        {
          "displayName": "TB number",
          "attribute": "ruQQnf6rswq",
          "type": "string",
          "value": "1Z 989 408 56 9356 521 9"
        },
        {
          "displayName": "Weight in kg",
          "attribute": "OvY4VVhSDeJ",
          "type": "number",
          "value": "68.1"
        },
        {
          "displayName": "Email",
          "attribute": "NDXw0cluzSw",
          "type": "string",
          "value": "LiyaEfrem@armyspy.com"
        },
        {
          "displayName": "Gender",
          "attribute": "cejWyOfXge6",
          "type": "optionSet",
          "value": "Female"
        },
        {
          "displayName": "Phone number",
          "attribute": "P2cwLGskgxn",
          "type": "phoneNumber",
          "value": "085 813 9447"
        },
        {
          "displayName": "First name",
          "attribute": "dv3nChNSIxy",
          "type": "string",
          "value": "Liya"
        },
        {
          "displayName": "Last name",
          "attribute": "hwlRTFIFSUq",
          "type": "string",
          "value": "Efrem"
        },
        {
          "code": "Height in cm",
          "displayName": "Height in cm",
          "attribute": "lw1SqmMlnfh",
          "type": "number",
          "value": "164"
        },
        {
          "code": "City",
          "displayName": "City",
          "attribute": "VUvgVao8Y5z",
          "type": "string",
          "value": "Kranskop"
        },
        {
          "code": "State",
          "displayName": "State",
          "attribute": "GUOBQt5K2WI",
          "type": "number",
          "value": "KwaZulu-Natal"
        },
        {
          "code": "Zip code",
          "displayName": "Zip code",
          "attribute": "n9nUvfpTsxQ",
          "type": "number",
          "value": "3282"
        },
        {
          "code": "National identifier",
          "displayName": "National identifier",
          "attribute": "AuPLng5hLbE",
          "type": "string",
          "value": "465700042"
        },
        {
          "code": "Blood type",
          "displayName": "Blood type",
          "attribute": "H9IlTX2X6SL",
          "type": "string",
          "value": "B-"
        },
        {
          "code": "Latitude",
          "displayName": "Latitude",
          "attribute": "Qo571yj6Zcn",
          "type": "string",
          "value": "-30.659626"
        },
        {
          "code": "Longitude",
          "displayName": "Longitude",
          "attribute": "RG7uGl4w5Jq",
          "type": "string",
          "value": "26.916172"
        }
      ]
    }
  ]
}
```

#### Tracked entity instance grid query { #webapi_tracked_entity_instance_grid_query } 

To query for tracked entity instances you can interact with the
*/api/trackedEntityInstances/grid* resource. There are two types of
queries: One where a *query* query parameter and optionally *attribute*
parameters are defined, and one where *attribute* and *filter*
parameters are defined. This endpoint uses a more compact "grid" format,
and is an alternative to the query in the previous section.

    /api/33/trackedEntityInstances/query

##### Request syntax { #webapi_tei_grid_query_request_syntax } 



Table: Tracked entity instances query parameters

| Paramètre de requête | Description |
|---|---|
| requête | Query string. Attribute query parameter can be used to define which attributes to include in the response. If no attributes but a program is defined, the attributes from the program will be used. If no program is defined, all attributes will be used. There are two formats. The first is a plan query string. The second is on the format <operator\>:<query\>. Operators can be EQ &#124; LIKE. EQ implies exact matches on words, LIKE implies partial matches on words. The query will be split on space, where each word will form a logical AND query. |
| attribut | Attributes to be included in the response. Can also be used as a filter for the query. Param can be repeated any number of times. Filters can be applied to a dimension on the format <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>]. Filter values are case-insensitive and can be repeated together with operator any number of times. Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN. Filters can be omitted in order to simply include the attribute in the response without any constraints. |
| filter | Attributes to use as a filter for the query. Param can be repeated any number of times. Filters can be applied to a dimension on the format <attribute-id\>:<operator\>:<filter\>[:<operator\>:<filter\>]. Filter values are case-insensitive and can be repeated together with operator any number of times. Operators can be EQ &#124; GT &#124; GE &#124; LT &#124; LE &#124; NE &#124; LIKE &#124; IN. |
| ou | Organisation unit identifiers, separated by ";". |
| ou Mode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; ALL. Default is SELECTED, which refers to the selected organisation units only. See table below for explanations. |
| de paludisme) ». | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| suivi | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| Entité suivie | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| eventStatus | Status of any event associated with the given program and the tracked entity instance. Can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULED &#124; OVERDUE &#124; SKIPPED. |
| eventStartDate | Start date of event associated with the given program and event status. |
| eventEndDate | End date of event associated with the given program and event status. |
| Étape du programme | The programStage for which the event related filters should be applied to. If not provided all stages will be considered. |
| skipMeta | Indicates whether meta data for the response should be included. |
| page | The page number. Default page is 1. |
| taille de la page | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| Mode utilisateur attribué | Restricts result to tei with events assigned based on the assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser (Utilisateur assigné) | Filter the result down to a limited set of teis with events that are assigned to the given user IDs by using *assignedUser=id1;id2*.This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |
| trackedEntityInstance | Filter the result down to a limited set of teis using explicit uids of the tracked entity instances by using *trackedEntityInstance=id1;id2*. This parameter will at the very least create the outer boundary of the results, forming the list of all teis using the uids provided. If other parameters/filters from this table are used, they will further limit the results from the explicit outer boundary. |
| potentialDuplicate | Il est possible de filtrer le résultat en supposant qu'une TEI soit un doublon potentiel. true: renvoie les TEI marqués comme doublons potentiels. false: renvoie les TEI NON marqués comme doublons potentiels. En cas d'omission, nous ne vérifions pas si une TEI est un doublon potentiel ou pas.|

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.



Table: Organisation unit selection modes

| Mode | Description |
|---|---|
| SELECTED | Unités d'organisation définies dans la requête. |
| CHILDREN | Immediate children, i.e. only the first level below, of the organisation units defined in the request. |
| DESCENDANTS | All children, i.e. at only levels below, e.g. including children of children, of the organisation units defined in the request. |
| ACCESSIBLE | All descendants of the data view organisation units associated with the current user. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| CAPTURE | The data capture organisation units associated with the current user and all children, i.e. all organisation units in the sub-hierarchy. |
| ALL | All organisation units in the system. Requires authority. |

Note that you can specify "attribute" with filters or directly using the "filter" params for constraining the
instances to return.

Certain rules apply to which attributes are returned.

  - If "query" is specified without any attributes or program, then all attributes that
    are marked as "Display in List without Program" is included in the response.

  - If program is specified,  all the attributes linked to the program will
    be included in the response.

  - If tracked entity type is specified, then all tracked entity type attributes
    will be included in the response.

You can specify queries with words separated by space - in that
situation the system will query for each word independently and return
records where each word is contained in any attribute. A query item can
be specified once as an attribute and once as a filter if needed. The
query is case insensitive. The following rules apply to the query
parameters.

  - At least one organisation unit must be specified using the *ou*
    parameter (one or many), or *ouMode=ALL* must be specified.

  - Only one of the *program* and *trackedEntity* parameters can be
    spécifié (zéro ou un).

  - If *programStatus* is specified then *program* must also be
    spécifiés.

  - If *followUp* is specified then *program* must also be specified.

  - If *programStartDate* or *programEndDate* is specified then
    *program* must also be specified.

  - If *eventStatus* is specified then *eventStartDate* and
    *eventEndDate* must also be specified.

  - A query cannot be specified together with filters.

  - Attribute items can only be specified once.

  - Les éléments du filtre ne peuvent être spécifiés qu'une seule fois.

Une requête pour toutes les instances associées à une unité d'organisation spécifique peut ressembler à ceci :

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8

A query on all attributes for a specific value and organisation unit,
using an exact word match:

    /api/33/trackedEntityInstances/query.json?query=scott&ou=DiszpKrYNg8

A query on all attributes for a specific value, using a partial word
match:

    /api/33/trackedEntityInstances/query.json?query=LIKE:scott&ou=DiszpKrYNg8

You can query on multiple words separated by the URL character for
space which is %20, will use a logical AND query for each
    word:

    /api/33/trackedEntityInstances/query.json?query=isabel%20may&ou=DiszpKrYNg8

A query where the attributes to include in the response are specified:

    /api/33/trackedEntityInstances/query.json?query=isabel
      &attribute=dv3nChNSIxy&attribute=AMpUYgxuCaE&ou=DiszpKrYNg8

To query for instances using one attribute with a filter and one
attribute without a filter, with one organisation unit using the
descendants organisation unit query mode:

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &attribute=AMpUYgxuCaE&ou=DiszpKrYNg8;yMCshbaVExv

A query for instances where one attribute is included in the response
and one attribute is used as a
    filter:

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &filter=AMpUYgxuCaE:LIKE:Road&ou=DiszpKrYNg8

A query where multiple operand and filters are specified for a filter
item:

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8&program=ur1Edk5Oe2n
      &filter=lw1SqmMlnfh:GT:150:LT:190

To query on an attribute using multiple values in an IN
    filter:

    /api/33/trackedEntityInstances/query.json?ou=DiszpKrYNg8
      &attribute=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

To constrain the response to instances which are part of a specific
program you can include a program query parameter:

    /api/33/trackedEntityInstances/query.json?filter=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

To specify program enrollment dates as part of the query:

    /api/33/trackedEntityInstances/query.json?filter=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&program=ur1Edk5Oe2n&programStartDate=2013-01-01
      &programEndDate=2013-09-01

To constrain the response to instances of a specific tracked entity you
can include a tracked entity query parameter:

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

By default the instances are returned in pages of size 50, to change
this you can use the page and pageSize query parameters:

    /api/33/trackedEntityInstances/query.json?attribute=zHXD5Ve1Efw:EQ:A
      &ou=O6uvpzGd5pu&ouMode=DESCENDANTS&page=2&pageSize=3

To query for instances which have events of a given status within a
given time span:

    /api/33/trackedEntityInstances/query.json?ou=O6uvpzGd5pu
      &program=ur1Edk5Oe2n&eventStatus=LATE_VISIT
      &eventStartDate=2014-01-01&eventEndDate=2014-09-01

You can use a range of operators for the filtering:



Table: Filter operators

| Opérateur | Description |
|---|---|
| EQ | Egale à |
| GT | Supérieure à |
| GE | Supérieure ou égal à |
| LT | Inférieur à |
| LE | inférieur ou égal à |
| NE | Pas égal à |
| LIKE | Like (free text match) |
| IN | Equal to one of multiple values separated by ";" |

##### Response format { #webapi_tei_grid_query_response_format } 

This resource supports JSON, JSONP, XLS and CSV resource
representations.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

  - csv (application/csv)

  - xls (application/vnd.ms-excel)

The response in JSON comes is in a tabular format and can look like the
following. The *headers* section describes the content of each column.
The instance, created, last updated, org unit and tracked entity columns
are always present. The following columns correspond to attributes
specified in the query. The *rows* section contains one row per
instance.

```json
{
  "headers": [{
    "name": "instance",
    "column": "Instance",
    "type": "java.lang.String"
  }, {
    "name": "created",
    "column": "Created",
    "type": "java.lang.String"
  }, {
    "name": "lastupdated",
    "column": "Last updated",
    "type": "java.lang.String"
  }, {
    "name": "ou",
    "column": "Org unit",
    "type": "java.lang.String"
  }, {
    "name": "te",
    "column": "Tracked entity",
    "type": "java.lang.String"
  }, {
    "name": "zHXD5Ve1Efw",
    "column": "Date of birth type",
    "type": "java.lang.String"
  }, {
    "name": "AMpUYgxuCaE",
    "column": "Address",
    "type": "java.lang.String"
  }],
  "metaData": {
    "names": {
      "cyl5vuJ5ETQ": "Person"
    }
  },
  "width": 7,
  "height": 7,
  "rows": [
    ["yNCtJ6vhRJu", "2013-09-08 21:40:28.0", "2014-01-09 19:39:32.19", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "21 Kenyatta Road"],
    ["fSofnQR6lAU", "2013-09-08 21:40:28.0", "2014-01-09 19:40:19.62", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "56 Upper Road"],
    ["X5wZwS5lgm2", "2013-09-08 21:40:28.0", "2014-01-09 19:40:31.11", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "56 Main Road"],
    ["pCbogmlIXga", "2013-09-08 21:40:28.0", "2014-01-09 19:40:45.02", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "12 Lower Main Road"],
    ["WnUXrY4XBMM", "2013-09-08 21:40:28.0", "2014-01-09 19:41:06.97", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "13 Main Road"],
    ["xLNXbDs9uDF", "2013-09-08 21:40:28.0", "2014-01-09 19:42:25.66", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "14 Mombasa Road"],
    ["foc5zag6gbE", "2013-09-08 21:40:28.0", "2014-01-09 19:42:36.93", "DiszpKrYNg8", "cyl5vuJ5ETQ", "A", "15 Upper Hill"]
  ]
}
```

#### Tracked entity instance filters { #webapi_tei_filters } 

To create, read, update and delete tracked entity instance filters you
can interact with the */api/trackedEntityInstanceFilters* resource.

    /api/33/trackedEntityInstanceFilters

##### Create and update a tracked entity instance filter definition { #create-and-update-a-tracked-entity-instance-filter-definition } 

For creating and updating a tracked entity instance filter in the
system, you will be working with the *trackedEntityInstanceFilters*
resource. The tracked entity instance filter definitions are used in the
Tracker Capture app to display relevant predefined "Working lists" in
the tracker user interface.



Tableau : Charge utile

| Valeurs de charge utile | Description | Exemple |
|---|---|---|
| nom | Name of the filter. Required. ||
| Description | A description of the filter. ||
| sortOrder | The sort order of the filter. Used in Tracker Capture to order the filters in the program dashboard. ||
| style | Object containing css style. | ( "color": "blue", "icon": "fa fa-calendar"} |
| de paludisme) ». | Objet contenant l'identifiant du programme. Obligatoire. | { "id" : "uy2gU8kTjF"} |
| Statut de l'inscription | The TEIs enrollment status. Can be none(any enrollmentstatus) or ACTIVE&#124;COMPLETED&#124;CANCELED ||
| followup | When this parameter is true, the filter only returns TEIs that have an enrollment with status followup. ||
| enrollmentCreatedPeriod | Period object containing a period in which the enrollment must be created. See *Period* definition table below. | { "periodFrom": -15, "periodTo": 15} |
| eventFilters | A list of eventFilters. See *Event filters* definition table below. | [{"programStage": "eaDH9089uMp", "eventStatus": "OVERDUE", "eventCreatedPeriod": {"periodFrom": -15, "periodTo": 15}}] |



Table: Event filters definition

||||
|---|---|---|
| Étape du programme | Which programStage the TEI needs an event in to be returned. | "eaDH9089uMp" |
| eventStatus | The events status. Can be none(any event status) or ACTIVE&#124;COMPLETED&#124;SCHEDULED&#124;OVERDUE | ACTIVE |
| eventCreatedPeriod | Period object containing a period in which the event must be created. See *Period* definition below. | { "periodFrom": -15, "periodTo": 15} |
| Mode utilisateur attribué | To specify the assigned user selection mode for events. Possible values are CURRENT (events assigned to current user)&#124; PROVIDED (events assigned to users provided in "assignedUsers" list) &#124; NONE (events assigned to no one) &#124; ANY (events assigned to anyone). If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUser (Utilisateur assigné) | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |



Table: Period definition

||||
|---|---|---|
| periodFrom | Number of days from current day. Can be positive or negative integer. | -15 |
| periodTo | Number of days from current day. Must be bigger than periodFrom. Can be positive or negative integer. | 15 |

##### Tracked entity instance filters query { #tracked-entity-instance-filters-query } 

To query for tracked entity instance filters in the system, you can
interact with the */api/trackedEntityInstanceFilters* resource.



Table: Tracked entity instance filters query parameters

| Paramètre de requête | Description |
|---|---|
| de paludisme) ». | Program identifier. Restricts filters to the given program. |

### Enrollment management { #webapi_enrollment_management } 

Enrollments have full CRUD support in the API. Together with the API
for tracked entity instances most operations needed for working with
tracked entity instances and programs are supported.

    /api/33/enrollments

#### Enrolling a tracked entity instance into a program { #webapi_enrolling_tei } 

For enrolling persons into a program, you will need to first get the
identifier of the person from the *trackedEntityInstances* resource.
Then, you will need to get the program identifier from the *programs*
resource. A template payload can be seen below:

```json
{
  "trackedEntityInstance": "ZRyCnJ1qUXS",
  "orgUnit": "ImspTQPwCqd",
  "program": "S8uo8AlvYMz",
  "enrollmentDate": "2013-09-17",
  "incidentDate": "2013-09-17"
}
```

This payload should be used in a *POST* request to the enrollments
resource identified by the following URL:

    /api/33/enrollments

For cancelling or completing an enrollment, you can make a *PUT*
request to the `enrollments` resource, including the identifier and the
action you want to perform. For cancelling an enrollment for a tracked
entity instance:

    /api/33/enrollments/<enrollment-id>/cancelled

For completing an enrollment for a tracked entity instance you can make a
*PUT* request to the following URL:

    /api/33/enrollments/<enrollment-id>/completed

For deleting an enrollment, you can make a *DELETE* request to the
following URL:

    /api/33/enrollments/<enrollment-id>

#### Enrollment instance query { #webapi_enrollment_instance_query } 

To query for enrollments you can interact with the */api/enrollments*
resource.

    /api/33/enrollments

##### Request syntax { #webapi_enrollment_query_request_syntax } 



Table: Enrollment query parameters

| Paramètre de requête | Description |
|---|---|
| ou | Organisation unit identifiers, separated by ";". |
| ou Mode | The mode of selecting organisation units, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS &#124; ACCESSIBLE &#124; CAPTURE &#124; ALL. Default is SELECTED, which refers to the selected organisation units only. See table below for explanations. |
| de paludisme) ». | Program identifier. Restricts instances to being enrolled in the given program. |
| programStatus | Status of the instance for the given program. Can be ACTIVE &#124; COMPLETED &#124; CANCELLED. |
| suivi | Follow up status of the instance for the given program. Can be true &#124; false or omitted. |
| programStartDate | Start date of enrollment in the given program for the tracked entity instance. |
| programEndDate | End date of enrollment in the given program for the tracked entity instance. |
| lastUpdatedDuration (durée de la dernière mise à jour) | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). |
| Entité suivie | Tracked entity identifier. Restricts instances to the given tracked instance type. |
| trackedEntityInstance | Tracked entity instance identifier. Should not be used together with trackedEntity. |
| page | The page number. Default page is 1. |
| taille de la page | The page size. Default size is 50 rows per page. |
| totalPages | Indicates whether to include the total number of pages in the paging response (implies higher response time). |
| skipPaging | Indicates whether paging should be ignored and all rows should be returned. |
| includeDeleted | Indicates whether to include soft deleted enrollments or not. It is false by default. |

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.



Table: Organisation unit selection modes

| Mode | Description |
|---|---|
| SELECTED | Organisation units defined in the request (default). |
| CHILDREN | Immediate children, i.e. only the first level below, of the organisation units defined in the request. |
| DESCENDANTS | All children, i.e. at only levels below, e.g. including children of children, of the organisation units defined in the request. |
| ACCESSIBLE | All descendants of the data view organisation units associated with the current user. Will fall back to data capture organisation units associated with the current user if the former is not defined. |
| ALL | All organisation units in the system. Requires authority. |

La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

  - At least one organisation unit must be specified using the *ou*
    parameter (one or many), or *ouMode=ALL* must be specified.

  - Only one of the *program* and *trackedEntity* parameters can be
    spécifié (zéro ou un).

  - If *programStatus* is specified then *program* must also be
    spécifiés.

  - If *followUp* is specified then *program* must also be specified.

  - If *programStartDate* or *programEndDate* is specified then
    *program* must also be specified.

A query for all enrollments associated with a specific organisation unit
can look like this:

    /api/33/enrollments.json?ou=DiszpKrYNg8

To constrain the response to enrollments which are part of a specific
program you can include a program query
    parameter:

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

To specify program enrollment dates as part of the
    query:

    /api/33/enrollments.json?&ou=O6uvpzGd5pu&program=ur1Edk5Oe2n
      &programStartDate=2013-01-01&programEndDate=2013-09-01

To constrain the response to enrollments of a specific tracked entity
you can include a tracked entity query
    parameter:

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

To constrain the response to enrollments of a specific tracked entity
instance you can include a tracked entity instance query parameter, in
this case we have restricted it to available enrollments viewable for
current
    user:

    /api/33/enrollments.json?ouMode=ACCESSIBLE&trackedEntityInstance=tphfdyIiVL6

By default the enrollments are returned in pages of size 50, to change
this you can use the page and pageSize query
    parameters:

    /api/33/enrollments.json?ou=O6uvpzGd5pu&ouMode=DESCENDANTS&page=2&pageSize=3

##### Response format { #webapi_enrollment_query_response_format } 

This resource supports JSON, JSONP, XLS and CSV resource
representations.

  - json (application/json)

  - jsonp (application/javascript)

  - xml (application/xml)

The response in JSON/XML is in object format and can look like the
following. Please note that field filtering is supported, so if you want
a full view, you might want to add `fields=*` to the query:

```json
{
  "enrollments": [
    {
      "lastUpdated": "2014-03-28T05:27:48.512+0000",
      "trackedEntity": "cyl5vuJ5ETQ",
      "created": "2014-03-28T05:27:48.500+0000",
      "orgUnit": "DiszpKrYNg8",
      "program": "ur1Edk5Oe2n",
      "enrollment": "HLFOK0XThjr",
      "trackedEntityInstance": "qv0j4JBXQX0",
      "followup": false,
      "enrollmentDate": "2013-05-23T05:27:48.490+0000",
      "incidentDate": "2013-05-10T05:27:48.490+0000",
      "status": "ACTIVE"
    }
  ]
}
```

### Événements { #webapi_events } 

This section is about sending and reading events.

    /api/33/events

#### Sending events { #webapi_sending_events } 

DHIS2 supports three kinds of events: single events with no registration
(also referred to as anonymous events), single event with registration
and multiple events with registration. Registration implies that the
data is linked to a tracked entity instance which is identified using
some sort of identifier.

To send events to DHIS2 you must interact with the *events* resource.
The approach to sending events is similar to sending aggregate data
values. You will need a *program* which can be looked up using the
*programs* resource, an *orgUnit* which can be looked up using the
*organisationUnits* resource, and a list of valid data element
identifiers which can be looked up using the *dataElements* resource.
For events with registration, a *tracked entity instance* identifier is
required, read about how to get this in the section about the
*trackedEntityInstances* resource. For sending events to programs with
multiple stages, you will need to also include the *programStage*
identifier, the identifiers for programStages can be found in the
*programStages* resource.

A simple single event with no registration example payload in XML format
where we send events from the "Inpatient morbidity and mortality"
program for the "Ngelehun CHC" facility in the demo database can be seen
below:

```xml
<?xml version="1.0" encoding="utf-8"?>
<event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
  eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
  <coordinate latitude="59.8" longitude="10.9" />
  <dataValues>
    <dataValue dataElement="qrur9Dvnyt5" value="22" />
    <dataValue dataElement="oZg33kd9taw" value="Male" />
    <dataValue dataElement="msodh3rEMJa" value="2013-05-18" />
  </dataValues>
</event>
```

To perform some testing we can save the XML payload as a file
called*event.xml* and send it as a POST request to the events resource
in the API using curl with the following command:

```bash
curl -d @event.xml "https://play.dhis2.org/demo/api/33/events"
  -H "Content-Type:application/xml" -u admin:district
```

The same payload in JSON format looks like this:

```json
{
  "program": "eBAyeGv0exc",
  "orgUnit": "DiszpKrYNg8",
  "eventDate": "2013-05-17",
  "status": "COMPLETED",
  "completedDate": "2013-05-18",
  "storedBy": "admin",
  "coordinate": {
    "latitude": 59.8,
    "longitude": 10.9
  },
  "dataValues": [
    {
      "dataElement": "qrur9Dvnyt5",
      "value": "22"
    },
    {
      "dataElement": "oZg33kd9taw",
      "value": "Male"
    },
    {
      "dataElement": "msodh3rEMJa",
      "value": "2013-05-18"
    }
  ]
}
```

To send this you can save it to a file called *event.json* and use curl
like this:

```bash
curl -d @event.json "localhost/api/33/events" -H "Content-Type:application/json"
  -u admin:district
```

We also support sending multiple events at the same time. A payload in
XML format might look like this:

```xml
<?xml version="1.0" encoding="utf-8"?>
<events>
  <event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
    eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
    <coordinate latitude="59.8" longitude="10.9" />
    <dataValues>
      <dataValue dataElement="qrur9Dvnyt5" value="22" />
      <dataValue dataElement="oZg33kd9taw" value="Male" />
    </dataValues>
  </event>
  <event program="eBAyeGv0exc" orgUnit="DiszpKrYNg8"
    eventDate="2013-05-17" status="COMPLETED" storedBy="admin">
    <coordinate latitude="59.8" longitude="10.9" />
    <dataValues>
      <dataValue dataElement="qrur9Dvnyt5" value="26" />
      <dataValue dataElement="oZg33kd9taw" value="Female" />
    </dataValues>
  </event>
</events>
```

You will receive an import summary with the response which can be
inspected in order to get information about the outcome of the request,
like how many values were imported successfully. The payload in JSON
format looks like this:

```json
{
  "events": [
  {
    "program": "eBAyeGv0exc",
    "orgUnit": "DiszpKrYNg8",
    "eventDate": "2013-05-17",
    "status": "COMPLETED",
    "storedBy": "admin",
    "coordinate": {
      "latitude": "59.8",
      "longitude": "10.9"
    },
    "dataValues": [
      {
        "dataElement": "qrur9Dvnyt5",
        "value": "22"
      },
      {
        "dataElement": "oZg33kd9taw",
        "value": "Male"
      }
    ]
  },
  {
    "program": "eBAyeGv0exc",
    "orgUnit": "DiszpKrYNg8",
    "eventDate": "2013-05-17",
    "status": "COMPLETED",
    "storedBy": "admin",
    "coordinate": {
      "latitude": "59.8",
      "longitude": "10.9"
    },
    "dataValues": [
      {
        "dataElement": "qrur9Dvnyt5",
        "value": "26"
      },
      {
        "dataElement": "oZg33kd9taw",
        "value": "Female"
      }
    ]
  } ]
}
```

You can also use GeoJson to store any kind of geometry on your event. An example payload using GeoJson instead of the former latitude and longitude properties can be seen here:

```json
{
  "program": "eBAyeGv0exc",
  "orgUnit": "DiszpKrYNg8",
  "eventDate": "2013-05-17",
  "status": "COMPLETED",
  "storedBy": "admin",
  "geometry": {
    "type": "POINT",
    "coordinates": [59.8, 10.9]
  },
  "dataValues": [
    {
      "dataElement": "qrur9Dvnyt5",
      "value": "22"
    },
    {
      "dataElement": "oZg33kd9taw",
      "value": "Male"
    },
    {
      "dataElement": "msodh3rEMJa",
      "value": "2013-05-18"
    }
  ]
}
```

As part of the import summary you will also get the identifier
*reference* to the event you just sent, together with a *href* element
which points to the server location of this event. The table below
describes the meaning of each element.



Table: Events resource format

| Paramètre | Type | Obligatoire | Options (par défaut en premier) | Description |
|---|---|---|---|---|
| de paludisme) ». | string | vrai || Identifier of the single event with no registration program |
| orgUnit (Unité d'organisation) | string | vrai || Identifier of the organisation unit where the event took place |
| eventDate | date | vrai || The date of when the event occurred |
| completedDate | date | faux || The date of when the event is completed. If not provided, the current date is selected as the event completed date |
| statut | enum | faux | ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULE &#124; OVERDUE &#124; SKIPPED | Whether the event is complete or not |
| Stocké par | string | faux | Defaults to current user | Who stored this event (can be username, system-name, etc) |
| coordinate | double | faux || Refers to where the event took place geographically (latitude and longitude) |
| élément de données | string | vrai || Identifier of data element |
| valeur | string | vrai || Data value or measure for this event |

##### OrgUnit matching { #orgunit-matching } 

By default the orgUnit parameter will match on the
ID, you can also select the orgUnit id matching scheme by using the
parameter orgUnitIdScheme=SCHEME, where the options are: *ID*, *UID*,
*UUID*, *CODE*, and *NAME*. There is also the *ATTRIBUTE:* scheme, which
matches on a *unique* metadata attribute value.

#### Updating events { #webapi_updating_events } 

To update an existing event, the format of the payload is the same, but
the URL you are posting to must add the identifier to the end of the URL
string and the request must be PUT.

The payload has to contain all, even non-modified, attributes.
Attributes that were present before and are not present in the current
payload any more will be removed by the system.

It is not allowed to update an already deleted event. The same applies
to tracked entity instance and enrollment.

```bash
curl -X PUT -d @updated_event.xml "localhost/api/33/events/ID"
  -H "Content-Type: application/xml" -u admin:district
```

```bash
curl -X PUT -d @updated_event.json "localhost/api/33/events/ID"
  -H "Content-Type: application/json" -u admin:district
```

#### Deleting events { #webapi_deleting_events } 

To delete an existing event, all you need is to send a DELETE request
with an identifier reference to the server you are using.

```bash
curl -X DELETE "localhost/api/33/events/ID" -u admin:district
```

#### Assigning user to events { #webapi_user_assign_event } 

A user can be assigned to an event. This can be done by including the appropriate property in the payload when updating or creating the event.

      "assignedUser": "<id>"

The id refers to the if of the user. Only one user can be assigned to an event at a time.

User assignment must be enabled in the program stage before users can be assigned to events.
#### Getting events { #webapi_getting_events } 

To get an existing event you can issue a GET request including the
identifier like this:

```bash
curl "http://localhost/api/33/events/ID" -H "Content-Type: application/xml" -u admin:district
```

#### Querying and reading events { #webapi_querying_reading_events } 

This section explains how to read out the events that have been stored
in the DHIS2 instance. For more advanced uses of the event data, please
see the section on event analytics. The output format from the
`/api/events` endpoint will match the format that is used to send events
to it (which the analytics event api does not support). Both XML and
JSON are supported, either through adding .json/.xml or by setting the
appropriate *Accept* header. The query is paged by default and the
default page size is 50 events, *field* filtering works as it does for
metadata, add the *fields* parameter and include your wanted properties,
i.e. *?fields=program,status*.



Table: Events resource query parameters

| Clé | Type | Obligatoire | Description |
|---|---|---|---|
| de paludisme) ». | identifier | true (if not programStage is provided) | Identifier of program |
| Étape du programme | identifier | faux | Identifier of program stage |
| programStatus | enum | faux | Status of event in program, ca be ACTIVE &#124; COMPLETED &#124; CANCELLED |
| suivi | boolean | faux | Whether event is considered for follow up in program, can be true &#124; false or omitted. |
| trackedEntityInstance | identifier | faux | Identifier of tracked entity instance |
| orgUnit (Unité d'organisation) | identifier | vrai | Identifier of organisation unit |
| ou Mode | enum | faux | Org unit selection mode, can be SELECTED &#124; CHILDREN &#124; DESCENDANTS |
| date de début | date | faux | Only events newer than this date |
| date de fin | date | faux | Only events older than this date |
| statut | enum | faux | Status of event, can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULED &#124; OVERDUE &#124; SKIPPED |
| lastUpdatedStartDate | date | faux | Filter for events which were updated after this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedEndDate | date | faux | Filter for events which were updated up until this date. Cannot be used together with *lastUpdatedDuration*. |
| lastUpdatedDuration (durée de la dernière mise à jour) | string | faux | Include only items which are updated within the given duration. The format is , where the supported time units are “d” (days), “h” (hours), “m” (minutes) and “s” (seconds). Cannot be used together with *lastUpdatedStartDate* and/or *lastUpdatedEndDate*. |
| skipMeta | boolean | faux | Exclude the meta data part of response (improves performance) |
| page | entier | faux | Page number |
| taille de la page | entier | faux | Number of items in each page |
| totalPages | boolean | faux | Indicates whether to include the total number of pages in the paging response. |
| skipPaging | boolean | faux | Indicates whether to skip paging in the query and return all events. |
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | string | faux | Data element ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | string | faux | Category Option Combo ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | string | faux | Organisation Unit ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| programIdScheme (Schéma d'identification du programme) | string | faux | Program ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| programmeStageIdScheme (Schéma d'identification de l'étape de programme) | string | faux | Program Stage ID scheme to use for export, valid options are UID, CODE and ATTRIBUTE:{ID} |
| idScheme | string | faux | Allows to set id scheme for data element, category option combo, orgUnit, program and program stage at once. |
| Ordre | string | faux | The order of which to retrieve the events from the API. Usage: order=<property\>:asc/desc - Ascending order is default. <br>Properties: event &#124; program &#124; programStage &#124; enrollment &#124; enrollmentStatus &#124; orgUnit &#124; orgUnitName &#124; trackedEntityInstance &#124; eventDate &#124; followup &#124; status &#124; dueDate &#124; storedBy &#124; created &#124; lastUpdated &#124; completedBy &#124; completedDate<br> order=orgUnitName:DESC order=lastUpdated:ASC |
| événement | comma delimited string | faux | Filter the result down to a limited set of IDs by using *event=id1;id2*. |
| skipEventId | boolean | faux | Skips event identifiers in the response |
| attributeCc (\*\*) | string | faux | Attribute category combo identifier (must be combined with *attributeCos*) |
| attributeCos (\*\*) | string | faux | Attribute category option identifiers, separated with ; (must be combined with *attributeCc*) |
| async | faux &#124; vrai | faux | Indicates whether the import should be done asynchronous or synchronous. |
| includeDeleted | boolean | faux | When true, soft deleted events will be included in your query result. |
| Mode utilisateur attribué | enum | faux | Assigned user selection mode, can be CURRENT &#124; PROVIDED &#124; NONE &#124; ANY. |
| assignedUser (Utilisateur assigné) | comma delimited strings | faux | Filter the result down to a limited set of events that are assigned to the given user IDs by using *assignedUser=id1;id2*. This parameter will be considered only if assignedUserMode is either PROVIDED or null. The API will error out, if for example, assignedUserMode=CURRENT and assignedUser=someId |

> **Note**
>
> If the query contains neither `attributeCC` nor `attributeCos`, the server returns events for all attribute option combos where the user has read access.

##### Exemples { #examples }

Query for all events with children of a certain organisation unit:

    /api/29/events.json?orgUnit=YuQRtpLP10I&ouMode=CHILDREN

Query for all events with all descendants of a certain organisation
unit, implying all organisation units in the sub-hierarchy:

    /api/33/events.json?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS

Query for all events with a certain program and organisation unit:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

Query for all events with a certain program and organisation unit,
sorting by due date
    ascending:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=dueDate

Query for the 10 events with the newest event date in a certain program
and organisation unit - by paging and ordering by due date descending:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &order=eventDate:desc&pageSize=10&page=1

Query for all events with a certain program and organisation unit for a
specific tracked entity instance:

    /api/33/events.json?orgUnit=DiszpKrYNg8
      &program=eBAyeGv0exc&trackedEntityInstance=gfVxE3ALA9m

Query for all events with a certain program and organisation unit older
or equal to
    2014-02-03:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&endDate=2014-02-03

Query for all events with a certain program stage, organisation unit and
tracked entity instance in the year 2014:

    /api/33/events.json?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &trackedEntityInstance=gfVxE3ALA9m&startDate=2014-01-01&endDate=2014-12-31

Query files associated with event data values. In the specific case of fetching an image file an
additional parameter can be provided to fetch the image with different dimensions. If dimension is
not provided, the system will return the original image. The parameter will be ignored in case of
fetching non-image files e.g pdf. Possible dimension values are *small(254 x 254),
medium(512 x 512), large(1024 x 1024) or original*. Any value other than those mentioned will be
discarded and the original image will be returned.

    /api/33/events/files?eventUid=hcmcWlYkg9u&dataElementUid=C0W4aFuVm4P&dimension=small

Retrieve events with specified Organisation unit and Program, and use _Attribute:Gq0oWTf2DtN_ as
identifier scheme

    /api/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN

Retrieve events with specified Organisation unit and Program, and use UID as identifier scheme for
orgUnits, Code as identifier scheme for Program stages, and _Attribute:Gq0oWTf2DtN_ as identifier
scheme for the rest of the metadata with assigned attribute.

    api/events.json?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN
      &orgUnitIdScheme=UID&programStageIdScheme=Code

#### Event grid query { #event-grid-query } 

In addition to the above event query end point, there is an event grid
query end point where a more compact "grid" format of events are
returned. This is possible by interacting with
/api/events/query.json|xml|xls|csv endpoint.

    /api/33/events/query

Most of the query parameters mentioned in event querying and reading
section above are valid here. However, since the grid to be returned
comes with specific set of columns that apply to all rows (events), it
is mandatory to specify a program stage. It is not possible to mix
events from different programs or program stages in the return.

Returning events from a single program stage, also opens up for new
functionality - for example sorting and searching events based on their
data element values. api/events/query has support for this. Below are
some examples

A query to return an event grid containing only selected data elements
for a program stage

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &dataElement=qrur9Dvnyt5,fWIAEtYVEGk,K6uUAvq500H&order=lastUpdated:desc
      &pageSize=50&page=1&totalPages=true

A query to return an event grid containing all data elements of a
program
    stage

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &includeAllDataElements=true

A query to filter events based on data element
    value

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &filter=qrur9Dvnyt5:GT:20:LT:50

In addition to the filtering, the above example also illustrates one
thing: the fact that there are no data elements mentioned to be returned
in the grid. When this happens, the system defaults back to return only
those data elements marked "Display in report" under program stage
configuration.

We can also extend the above query to return us a grid sorted (asc|desc)
based on data element
    value

    /api/33/events/query.json?orgUnit=DiszpKrYNg8&programStage=Zj7UnCAulEk
      &filter=qrur9Dvnyt5:GT:20:LT:50&order=qrur9Dvnyt5:desc

#### Event filters { #webapi_event_filters } 

To create, read, update and delete event filters you
can interact with the `/api/eventFilters` resource.

    /api/33/eventFilters

##### Create and update an event filter definition { #create-and-update-an-event-filter-definition } 

For creating and updating an event filter in the
system, you will be working with the *eventFilters*
resource. *POST* is used to create and *PUT* method is used to update. The event filter definitions are used in the
Tracker Capture app to display relevant predefined "Working lists" in
the tracker user interface.



Table: Request Payload

| Request Property | Description | Exemple |
|---|---|---|
| nom | Name of the filter. | "name":"My working list" |
| Description | A description of the filter. | "description":"for listing all events assigned to me". |
| de paludisme) ». | The uid of the program. | "program" : "a3kGcGDCuk6" |
| Étape du programme | The uid of the program stage. | "programStage" : "a3kGcGDCuk6" |
| eventQueryCriteria | Object containing parameters for querying, sorting and filtering events. | "eventQueryCriteria": {     "organisationUnit":"a3kGcGDCuk6",     "status": "COMPLETED",     "createdDate": {       "from": "2014-05-01",       "to": "2019-03-20"     },     "dataElements": ["a3kGcGDCuk6:EQ:1", "a3kGcGDCuk6"],     "filters": ["a3kGcGDCuk6:EQ:1"],     "programStatus": "ACTIVE",     "ouMode": "SELECTED",     "assignedUserMode": "PROVIDED",     "assignedUsers" : ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "followUp": false,     "trackedEntityInstance": "a3kGcGDCuk6",     "events": ["a3kGcGDCuk7", "a3kGcGDCuk8"],     "fields": "eventDate,dueDate",     "order": "dueDate:asc,createdDate:desc"   } |



Table: Event Query Criteria definition

||||
|---|---|---|
| suivi | Used to filter events based on enrollment followUp flag. Possible values are true&#124;false. | "followUp": true |
| organisationUnit | To specify the uid of the organisation unit | "organisationUnit": "a3kGcGDCuk7" |
| ou Mode | To specify the OU selection mode. Possible values are SELECTED&#124; CHILDREN&#124;DESCENDANTS&#124;ACCESSIBLE&#124;CAPTURE&#124;ALL | "ouMode": "SELECTED" |
| Mode utilisateur attribué | To specify the assigned user selection mode for events. Possible values are CURRENT&#124; PROVIDED&#124; NONE &#124; ANY. See table below to understand what each value indicates. If PROVIDED (or null), non-empty assignedUsers in the payload will be considered. | "assignedUserMode": "PROVIDED" |
| assignedUser (Utilisateur assigné) | To specify a list of assigned users for events. To be used along with PROVIDED assignedUserMode above. | "assignedUsers": ["a3kGcGDCuk7", "a3kGcGDCuk8"] |
| displayOrderColumns | To specify the output ordering of columns | "displayOrderColumns": ["eventDate", "dueDate", "program"] |
| Ordre | To specify ordering/sorting of fields and its directions in comma separated values. A single item in order is of the form "dataItem:direction". | "order"="a3kGcGDCuk6:desc,eventDate:asc" |
| Filtres de données | To specify filters to be applied when listing events | "dataFilters"=[{       "dataItem": "abcDataElementUid",       "le": "20",       "ge": "10",       "lt": "20",       "gt": "10",       "in": ["India", "Norway"],       "like": "abc",       "dateFilter": {         "startDate": "2014-05-01",         "endDate": "2019-03-20",         "startBuffer": -5,         "endBuffer": 5,         "period": "LAST_WEEK",         "type": "RELATIVE"       }     }] |
| statut | Any valid EventStatus | "eventStatus": "COMPLETED" |
| événements | To specify list of events | "events"=["a3kGcGDCuk6"] |
| completedDate | DateFilterPeriod object date filtering based on completed date. | "completedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "startBuffer": -5,     "endBuffer": 5,     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| eventDate | DateFilterPeriod object date filtering based on event date. | "eventDate": {     "startBuffer": -5,     "endBuffer": 5,     "type": "RELATIVE"   } |
| dueDate | DateFilterPeriod object date filtering based on due date. | "dueDate": {     "period": "LAST_WEEK",     "type": "RELATIVE"   } |
| lastUpdatedDate | DateFilterPeriod object date filtering based on last updated date. | "lastUpdatedDate": {     "startDate": "2014-05-01",     "endDate": "2019-03-20",     "type": "ABSOLUTE"   } |



Table: DateFilterPeriod object definition

||||
|---|---|---|
| type | Specify whether the date period type is ABSOLUTE &#124; RELATIVE | "type" : "RELATIVE" |
| période | Specify if a relative system defined period is to be used. Applicable only when "type" is RELATIVE. (see [Relative Periods](#webapi_date_relative_period_values) for supported relative periods) | "period" : "THIS_WEEK" |
| date de début | Absolute start date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| date de fin | Absolute end date. Applicable only when "type" is ABSOLUTE | "startDate":"2014-05-01" |
| startBuffer | Relative custom start date. Applicable only when "type" is RELATIVE | "startBuffer":-10 |
| endBuffer | Relative custom end date. Applicable only when "type" is RELATIVE | "startDate":+10 |

The available assigned user selection modes are explained in the
following table.



Table: Assigned user selection modes (event assignment)

| Mode | Description |
|---|---|
| ACTUEL | Assigned to the current logged in user |
| FOURNI | Assigned to the users provided in the "assignedUser" parameter |
| AUCUNE | Assigned to no users. |
| TOUT | Assigned to any users. |

A sample payload that can be used to create/update an eventFilter is shown below.

```json
{
  "program": "ur1Edk5Oe2n",
  "description": "Simple Filter for TB events",
  "name": "TB events",
  "eventQueryCriteria": {
    "organisationUnit":"DiszpKrYNg8",
    "eventStatus": "COMPLETED",
    "eventDate": {
      "startDate": "2014-05-01",
      "endDate": "2019-03-20",
      "startBuffer": -5,
      "endBuffer": 5,
      "period": "LAST_WEEK",
      "type": "RELATIVE"
    },
    "dataFilters": [{
      "dataItem": "abcDataElementUid",
      "le": "20",
      "ge": "10",
      "lt": "20",
      "gt": "10",
      "in": ["India", "Norway"],
      "like": "abc"
    },
    {
      "dataItem": "dateDataElementUid",
      "dateFilter": {
        "startDate": "2014-05-01",
        "endDate": "2019-03-20",
        "type": "ABSOLUTE"
      }
    },
    {
      "dataItem": "anotherDateDataElementUid",
      "dateFilter": {
        "startBuffer": -5,
        "endBuffer": 5,
        "type": "RELATIVE"
      }
    },
    {
      "dataItem": "yetAnotherDateDataElementUid",
      "dateFilter": {
        "period": "LAST_WEEK",
        "type": "RELATIVE"
      }
    }],
    "programStatus": "ACTIVE"
  }
}
```


##### Retrieving and deleting event filters { #retrieving-and-deleting-event-filters } 

A specific event filter can be retrieved by using the following api

    GET /api/33/eventFilters/{uid}

All event filters can be retrieved by using the following api.

    GET /api/33/eventFilters?fields=*

All event filters for a specific program can be retrieved by using the following api

    GET /api/33/eventFilters?filter=program:eq:IpHINAT79UW

An event filter can be deleted by using the following api

    DELETE /api/33/eventFilters/{uid}

### Relationships { #relationships } 
Relationships are links between two entities in tracker. These entities can be tracked entity instances, enrollments and events.

There are multiple endpoints that allow you to see, create, delete and update relationships. The most common is the /api/trackedEntityInstances endpoint, where you can include relationships in the payload to create, update or deleting them if you omit them - Similar to how you work with enrollments and events in the same endpoint. All the tracker endpoints, /api/trackedEntityInstances, /api/enrollments and /api/events also list their relationships if requested in the field filter.

The standard endpoint for relationships is, however, /api/relationships. This endpoint provides all the normal CRUD operations for relationships.

List all relationships require you to provide the UID of the trackedEntityInstance, Enrollment or event that you want to list all the relationships for:  

    GET /api/relationships?tei=ABCDEF12345
    GET /api/relationships?enrollment=ABCDEF12345
    GET /api/relationships?event=ABCDEF12345

This request will return a list of any relationship you have access to see that includes the trackedEntityInstance, enrollment or event you specified. Each relationship is represented with the following JSON:

```json
{
  "relationshipType": "dDrh5UyCyvQ",
  "relationshipName": "Mother-Child",
  "relationship": "t0HIBrc65Rm",
  "bidirectional": false,
  "from": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "vOxUH373fy5"
    }
  },
  "to": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "pybd813kIWx"
    }
  },
  "created": "2019-04-26T09:30:56.267",
  "lastUpdated": "2019-04-26T09:30:56.267"
}
```

You can also view specified relationships using the following endpoint:

    GET /api/relationships/<id>

To create or update a relationship, you can use the following endpoints:

    POST /api/relationships
    PUT /api/relationships

And use the following payload structure:

```json
{
  "relationshipType": "dDrh5UyCyvQ",
  "from": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "vOxUH373fy5"
    }
  },
  "to": {
    "trackedEntityInstance": {
      "trackedEntityInstance": "pybd813kIWx"
    }
  }
}
```

To delete a relationship, you can use this endpoint:

      DELETE /api/relationships/<id>

In our example payloads, we use a relationship between trackedEntityInstances. Because of this, the "from" and "to" properties of our payloads include "trackedEntityInstance" objects. If your relationship includes other entities, you can use the following properties:

```json
{
  "enrollment": {
    "enrollment": "<id>"
  }
}
```

```json
{
  "event": {
    "event": "<id>"
  }
}
```

### Update strategies { #webapi_tei_update_strategies } 

Two update strategies for all 3 tracker endpoints are supported:
enrollment and event creation. This is useful when you have generated an
identifier on the client side and are not sure if it was created or not
on the server.



Table: Available tracker strategies

| Paramètre | Description |
|---|---|
| CRÉER | Create only, this is the default behavior. |
| CREATE_AND_UPDATE | Try and match the ID, if it exist then update, if not create. |

To change the parameter, please use the strategy parameter:

    POST /api/33/trackedEntityInstances?strategy=CREATE_AND_UPDATE

### Tracker bulk deletion { #webapi_tracker_bulk_deletion } 

Bulk deletion of tracker objects work in a similar fashion to adding and
updating tracker objects, the only difference is that the
`importStrategy` is *DELETE*.

*Example: Bulk deletion of tracked entity instances:*

```json
{
  "trackedEntityInstances": [
    {
      "trackedEntityInstance": "ID1"
    }, {
      "trackedEntityInstance": "ID2"
    }, {
      "trackedEntityInstance": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/trackedEntityInstances?strategy=DELETE"
```

*Example: Bulk deletion of enrollments:*

```json
{
  "enrollments": [
    {
       "enrollment": "ID1"
    }, {
      "enrollment": "ID2"
    }, {
      "enrollment": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/enrollments?strategy=DELETE"
```

*Example: Bulk deletion of events:*

```json
{
  "events": [
    {
      "event": "ID1"
    }, {
      "event": "ID2"
    }, {
      "event": "ID3"
    }
  ]
}
```

```bash
curl -X POST -d @data.json -H "Content-Type: application/json"
  "http://server/api/33/events?strategy=DELETE"
```

### Identifier reuse and item deletion via POST and PUT methods { #webapi_updating_and_deleting_items } 

Tracker endpoints */trackedEntityInstances*, */enrollments*, */events*
support CRUD operations. The system keeps track of used identifiers.
Therefore, an item which has been created and then deleted (e.g. events,
enrollments) cannot be created or updated again. If attempting to delete
an already deleted item, the system returns a success response as
deletion of an already deleted item implies no change.

The system does not allow to delete an item via an update (*PUT*) or
create (*POST*) method. Therefore, an attribute *deleted* is ignored in
both *PUT* and *POST* methods, and in *POST* method it is by default set
to *false*.

### Import parameters { #webapi_import_parameters } 

Le processus d'importation peut être personnalisé à l'aide d'un ensemble de paramètres d'importation :



Tableau : Paramètres d'importation

| Paramètre | Valeurs (par défaut en premier) | Description |
|---|---|---|
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'élément de données à utiliser pour faire correspondre les données. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'objet d'unité d'organisation à utiliser pour faire correspondre les données. |
| idScheme | id &#124; name &#124; code&#124; attribute:ID | Property of all objects including data elements, org units and category option combos, to use to map the data values. |
| dryRun | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| strategy | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipNotifications | true &#124; false | Indicates whether to send notifications for completed events. |
| skipFirst | true &#124; false | Relevant for CSV import only. Indicates whether CSV file contains a header row which should be skipped. |
| importReportMode | FULL, ERRORS, DEBUG | Sets the `ImportReport` mode, controls how much is reported back after the import is done. `ERRORS` only includes *ObjectReports* for object which has errors. `FULL` returns an *ObjectReport* for all objects imported, and `DEBUG` returns the same plus a name for the object (if available). |

#### CSV Import / Export { #webapi_events_csv_import_export } 

In addition to XML and JSON for event import/export, in DHIS2.17 we
introduced support for the CSV format. Support for this format builds on
what was described in the last section, so here we will only write about
what the CSV specific parts are.

To use the CSV format you must either use the `/api/events.csv`
endpoint, or add *content-type: text/csv* for import, and *accept:
text/csv* for export when using the `/api/events` endpoint.

The order of column in the CSV which are used for both export and import
is as follows:



Table: CSV column

| Index | Clé | Type | Description |
|---|---|---|---|
| 1 | événement | identifier | Identifier of event |
| 2 | statut | enum | Status of event, can be ACTIVE &#124; COMPLETED &#124; VISITED &#124; SCHEDULED &#124; OVERDUE &#124; SKIPPED |
| 3 | de paludisme) ». | identifier | Identifier of program |
| 4 | Étape du programme | identifier | Identifier of program stage |
| 5 | inscription | identifier | Identifier of enrollment (program instance) |
| 6 | orgUnit (Unité d'organisation) | identifier | Identifier of organisation unit |
| 7 | eventDate | date | Date de l'événement |
| 8 | dueDate | date | Due Date |
| 9 | latitude | double | Latitude where event happened |
| 10 | longitude | double | Longitude where event happened |
| 11 | élément de données | identifier | Identifier of data element |
| 12 | valeur | string | Value / measure of event |
| 13 | Stocké par | string | Event was stored by (defaults to current user) |
| 14 | Fourni ailleurs | boolean | Was this value collected somewhere else |
| 14 | completedDate | date | Completed date of event |
| 14 | completedBy (terminé par) | string | Username of user who completed event |

*Example of 2 events with 2 different data value
    each:*

```csv
EJNxP3WreNP,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,1,,
EJNxP3WreNP,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,2,,
qPEdI1xn7k0,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,3,,
qPEdI1xn7k0,COMPLETED,<pid>,<psid>,<enrollment-id>,<ou>,2016-01-01,2016-01-01,,,<de>,4,,
```

#### Import strategy: SYNC { #webapi_sync_import_strategy } 

The import strategy SYNC should be used only by internal synchronization
task and not for regular import. The SYNC strategy allows all 3
operations: CREATE, UPDATE, DELETE to be present in the payload at the
same time.

### Tracker Ownership Management { #webapi_tracker_ownership_management } 

A new concept called Tracker Ownership is introduced from 2.30. There
will now be one owner organisation unit for a tracked entity instance in
the context of a program. Programs that are configured with an access
level of *PROTECTED* or *CLOSED* will adhere to the ownership
privileges. Only those users belonging to the owning org unit for a
tracked entity-program combination will be able to access the data
related to that program for that tracked entity.

#### Tracker Ownership Override : Break the Glass { #webapi_tracker_ownership_override_api } 

It is possible to temporarily override this ownership privilege for a
program that is configured with an access level of *PROTECTED*. Any user
will be able to temporarily gain access to the program related data, if
the user specifies a reason for accessing the tracked entity-program
data. This act of temporarily gaining access is termed as *breaking the
glass*. Currently, the temporary access is granted for 3 hours. DHIS2
audits breaking the glass along with the reason specified by the user.
It is not possible to gain temporary access to a program that has been
configured with an access level of *CLOSED*. To break the glass for a
tracked entity program combination, you can issue a POST request as
shown:

    /api/33/tracker/ownership/override?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&reason=patient+showed+up+for+emergency+care

#### Tracker Ownership Transfer { #webapi_tracker_ownership_transfer_api } 

It is possible to transfer the ownership of a tracked entity-program
from one org unit to another. This will be useful in case of patient
referrals or migrations. Only an owner (or users who have broken the
glass) can transfer the ownership. To transfer ownership of a tracked
entity-program to another organisation unit, you can issue a PUT request
as shown:

    /api/33/tracker/ownership/transfer?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&ou=EJNxP3WreNP


## Potential Duplicates   { #potential-duplicates } 

Potential duplicates are records we work with in the data deduplication feature. Due to the nature of the deduplication feature, this API endpoint is somewhat restricted.

A potential duplicate represents a pair of records which are suspected to be a duplicate.

The payload of a potential duplicate looks like this:

```json
{
  "teiA": "<id>",
  "teiB": "<id>",
  "status": "OPEN|INVALID|MERGED"
}
```

You can retrieve a list of potential duplicates using the following endpoint:

    GET /api/potentialDuplicates

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| teis | List of tracked entity instances | List of string (separated by comma)| existing tracked entity instance id |
| statut | Potential duplicate status | string | `OPEN <default>`, `INVALID`, `MERGED`, `ALL` |

| Status code | Description
|---|---|
| 400 | Invalid input status

You can inspect individual potential duplicate records:

    GET /api/potentialDuplicates/<id>

| Status code | Description
|---|---|
| 404 | Potential duplicate not found

You can also filter potential duplicates by Tracked Entity Instance (referred as tei) :

    GET /api/potentialDuplicates/tei/<tei>

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| statut | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED`, `ALL <default>` |

| Status code | Description
|---|---|
| 400 | Invalid input status
| 403 | User do not have access to read tei
| 404 | Tei not found

To create a new potential duplicate, you can use this endpoint:

    POST /api/potentialDuplicates

The payload you provide must include both teiA and teiB

```json
{
  "teiA": "<id>",
  "teiB": "<id>"
}
```

| Status code | Description
|---|---|
| 400 | Input teiA or teiB is null or has invalid id
| 403 | User do not have access to read teiA or teiB
| 404 | Tei not found
| 409 | Pair of teiA and teiB already existing

To update a potential duplicate status:

    PUT /api/potentialDuplicates/<id>

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| statut | Potential duplicate status | string | `OPEN`, `INVALID`, `MERGED` |

| Status code | Description
|---|---|
| 400 | You can't update a potential duplicate to MERGED as this is possible only by a merging request
| 400 | You can't update a potential duplicate that is already in a MERGED status

## Flag Tracked Entity Instance as Potential Duplicate { #flag-tracked-entity-instance-as-potential-duplicate } 

To flag as potential duplicate a Tracked Entity Instance (referred as tei)

 `PUT /api/trackedEntityInstances/{tei}/potentialDuplicate`

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| flag | either flag or unflag a tei as potential duplicate | string | `true`, `false` |


| Status code | Description
|---|---|
| 400 | Invalid flag must be true of false
| 403 | User do not have access to update tei
| 404 | Tei not found

## Merging Tracked Entity Instances { #merging-tracked-entity-instances } 
Tracked entity instances can now be merged together if they are viable. To initiate a merge, the first step is to define two tracked entity instances as a Potential Duplicate. The merge endpoint
will move data from the duplicate tracked entity instance to the original tracked entity instance, and delete the remaining data of the duplicate.

To merge a Potential Duplicate, or the two tracked entity instances the Potential Duplicate represents, the following endpoint can be used:

    POST /potentialDuplicates/<id>/merge

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| mergeStrategy | Strategy to use for merging the potentialDuplicate | enum | AUTO(default) or MANUAL |

The endpoint accepts a single parameter, "mergeStrategy", which decides which strategy to use when merging. For the AUTO strategy, the server will attempt to merge the two tracked entities
automatically, without any input from the user. This strategy only allows merging tracked entities without conflicting data (See examples below). The other strategy, MANUAL, requires the
user to send in a payload describing how the merge should be done. For examples and rules for each strategy, see their respective sections below.

### Merge Strategy AUTO { #merge-strategy-auto } 
The automatic merge will evaluate the mergability of the two tracked entity instances, and merge them if they are deemed mergable. The mergability is based on whether the two tracked entity instances
has any conflicts or not. Conflicts refers to data which cannot be merged together automatically. Examples of possible conflicts are:
- The same attribute has different values in each tracked entity instance
- Both tracked entity instances are enrolled in the same program
- Tracked entity instances have different types

If any conflict is encountered, an errormessage is returned to the user.

When no conflicts are found, all data in the duplicate that is not already in the original will be moved over to the original. This includes attribute values, enrollments (Including events) and relationships.
After the merge completes, the duplicate is deleted and the potentialDuplicate is marked as MERGED.

When requesting an automatic merge like this, a payload is not required and will be ignored.

### Merge Strategy MANUAL { #merge-strategy-manual } 
The manual merge is suitable when the merge has resolvable conflicts, or when not all the data is required to be moved over during a merge. For example, if an attribute has different values in both tracked
entity instances, the user can specify whether to keep the original value, or move over the duplicate's value. Since the manual merge is the user explicitly requesting to move data, there are some different 
checks being done here:
- Relationship cannot be between the original and the duplicate (This results in an invalid self-referencing relationship)
- Relationship cannot be of the same type and to the same object in both tracked entity instances (IE. between original and other, and duplicate and other; This would result in a duplicate relationship)

There are two ways to do a manual merge: With and without a payload.

When a manual merge is requested without a payload, we are telling the API to merge the two tracked entity instances without moving any data. In other words, we are just removing the duplicate and marking the 
potentialDuplicate MERGED. This might be valid in a lot of cases where the tracked entity instance was just created, but not enrolled for example.

Otherwise, if a manual merge is requested with a payload, the payload refers to what data should be moved from the duplicate to the original. The payload looks like this:
```json
{
  "attributes": ["B58KFJ45L9D"],
  "enrollments": ["F61SJ2DhINO"],
  "relationships": ["ETkkZVSNSVw"]
}
```

This payload contains three lists, one for each of the types of data that can be moved. Attributes is a list of uids for Tracked Entity Attributes, enrollments is a list of uids for enrollments and relationships 
a list of uids for relationships. The uids in this payload have to refer to data that actually exists on the duplicate. There is no way to add new data or change data using the merge endpoint - Only moving data.


### Additional information about merging { #additional-information-about-merging } 
Currently it is not possible to merge tracked entity instances that are enrolled in the same program, due to the added complexity. A workaround is to manually remove the enrollments from one of the tracked entity
instances before starting the merge.

All merging is based on data already persisted in the database, which means the current merging service is not validating that data again. This means if data was already invalid, it will not be reported during the merge.
The only validation done in the service relates to relationships, as mentioned in the previous section.



## Program Notification Template { #program-notification-template } 

Program Notification Template lets you create message templates which can be sent as a result of different type of events.
Message and Subject templates will be translated into actual values and can be sent to the configured destination. Each program notification template will be
transformed to either MessageConversation object or ProgramMessage object based on external or internal notificationRecipient. These intermediate objects will
only contain translated message and subject text.
There are multiple configuraiton parameters in Program Notification Tempalte which are critical for correct working of notifications.
All those are explained in the table below.

    POST /api/programNotificationTemplates

```json
{
    "name": "Case notification",
    "notificationTrigger": "ENROLLMENT",
    "subjectTemplate": "Case notification V{org_unit_name}",
    "displaySubjectTemplate": "Case notification V{org_unit_name}",
    "notifyUsersInHierarchyOnly": false,
    "sendRepeatable": false,
    "notificationRecipient": "ORGANISATION_UNIT_CONTACT",
    "notifyParentOrganisationUnitOnly": false,
    "displayMessageTemplate": "Case notification A{h5FuguPFF2j}",
    "messageTemplate": "Case notification A{h5FuguPFF2j}",
    "deliveryChannels": [
        "EMAIL"
    ]
}
```

The fields are explained in the following table.


Table: Program Notification Template payload

| Champ | Obligatoire | Description | Valeurs |
|---|---|---|---|
| nom | Oui | name of Program Notification Tempalte | case-notification-alert |
| notificationTrigger | Oui | When notification should be triggered. Possible values are ENROLLMENT, COMPLETION, PROGRAM_RULE, SCHEDULED_DAYS_DUE_DATE| INSCRIPTION |
| subjectTemplate | Non | Subject template string | Case notification V{org_unit_name} |
| messageTemplate | Oui | Message template string | Case notification A{h5FuguPFF2j} |
| notificationRecipient | OUI | Who is going to receive notification. Possible values are USER_GROUP, ORGANISATION_UNIT_CONTACT, TRACKED_ENTITY_INSTANCE, USERS_AT_ORGANISATION_UNIT, DATA_ELEMENT, PROGRAM_ATTRIBUTE, WEB_HOOK  | USER_GROUP |
| deliveryChannels | Non | Which channel should be used for this notification. It can be either SMS, EMAIL or HTTP | SMS |
| sendRepeatable | Non | Whether notification should be sent multiple times | faux |

NOTE: WEB_HOOK notificationRecipient is used only to POST http request to an external system. Make sure to choose HTTP delivery channel when using WEB_HOOK.

### Retrieving and deleting Program Notification Template { #retrieving-and-deleting-program-notification-template } 

The list of Program Notification Templates can be retrieved using GET.

    GET /api/programNotificationTemplates

For one particular Program Notification Template.

    GET /api/33/programNotificationTemplates/{uid}

To get filtered list of Program Notification Templates

    GET /api/programNotificationTemplates/filter?program=<uid>
    GET /api/programNotificationTemplates/filter?programStage=<uid>

Program Notification Template can be deleted using DELETE.

    DELETE /api/33/programNotificationTemplates/{uid}


## Program Messages { #program-messages } 

Program message lets you send messages to tracked entity instances,
contact addresses associated with organisation units, phone numbers and
email addresses. You can send messages through the `messages` resource.

    /api/33/messages

### Sending program messages { #sending-program-messages } 

Program messages can be sent using two delivery channels:

  - SMS (SMS)

  - Email address (EMAIL)

Program messages can be sent to various recipients:

  - Tracked entity instance: The system will look up attributes of value
    type PHONE_NUMBER or EMAIL (depending on the specified delivery
    channels) and use the corresponding attribute values.

  - Organisation unit: The system will use the phone number or email
    information registered for the organisation unit.

  - List of phone numbers: The system will use the explicitly defined
    phone numbers.

  - List of email addresses: The system will use the explicitly defined
    email addresses.

Below is a sample JSON payload for sending messages using POST requests.
Note that message resource accepts a wrapper object named
`programMessages` which can contain any number of program messages.

    POST /api/33/messages

```json
{
  "programMessages": [{
    "recipients": {
      "trackedEntityInstance": {
        "id": "UN810PwyVYO"
      },
      "organisationUnit": {
        "id": "Rp268JB6Ne4"
      },
      "phoneNumbers": [
        "55512345",
        "55545678"
      ],
      "emailAddresses": [
        "johndoe@mail.com",
        "markdoe@mail.com"
      ]
    },
    "programInstance": {
      "id": "f3rg8gFag8j"
    },
    "programStageInstance": {
      "id": "pSllsjpfLH2"
    },
    "deliveryChannels": [
      "SMS", "EMAIL"
    ],
    "notificationTemplate": "Zp268JB6Ne5",
    "subject": "Outbreak alert",
    "text": "An outbreak has been detected",
    "storeCopy": false
  }]
}
```

The fields are explained in the following table.



Table: Program message payload

| Champ | Obligatoire | Description | Valeurs |
|---|---|---|---|
| recipients | Oui | Recipients of the program message. At least one recipient must be specified. Any number of recipients / types can be specified for a message. | Can be trackedEntityInstance, organisationUnit, an array of phoneNumbers or an array of emailAddresses. |
| programInstance | Either this or programStageInstance required | The program instance / enrollment. | Enrollment ID. |
| programStageInstance | Either this or programInstance required | The program stage instance / event. | Event ID. |
| deliveryChannels | Oui | Array of delivery channels. | SMS &#124; EMAIL |
| subject | Non | The message subject. Not applicable for SMS delivery channel. | Text. |
| texte | Oui | The message text. | Text. |
| storeCopy | Non | Whether to store a copy of the program message in DHIS2. | false (default) &#124; true |

A minimalistic example for sending a message over SMS to a tracked
entity instance looks like this:

```bash
curl -d @message.json "https://play.dhis2.org/demo/api/33/messages"
  -H "Content-Type:application/json" -u admin:district
```

```json
{
  "programMessages": [{
    "recipients": {
      "trackedEntityInstance": {
        "id": "PQfMcpmXeFE"
      }
    },
    "programInstance": {
      "id": "JMgRZyeLWOo"
    },
    "deliveryChannels": [
      "SMS"
    ],
    "text": "Please make a visit on Thursday"
  }]
}
```

### Retrieving and deleting program messages { #retrieving-and-deleting-program-messages } 

The list of messages can be retrieved using GET.

    GET /api/33/messages

To get the list of sent tracker messages, the below endpoint can be used. ProgramInstance or ProgramStageInstance uid has to be provided.

    GET /api/33/messages/scheduled/sent?programInstance={uid}
    GET /api/33/messages/scheduled/sent?programStageInstance={uid}

To get the list of all scheduled message

    GET /api/33/messages/scheduled
    GET /api/33/messages/scheduled?scheduledAt=2020-12-12

One particular message can also be retrieved using GET.

    GET /api/33/messages/{uid}

Message can be deleted using DELETE.

    DELETE /api/33/messages/{uid}


### Querying program messages { #querying-program-messages } 

The program message API supports program message queries based on
request parameters. Messages can be filtered based on below mentioned
query parameters. All requests should use the GET HTTP verb for
retrieving information.



Table: Query program messages API

| Paramètre | URL |
|---|---|
| programInstance | /api/33/messages?programInstance=6yWDMa0LP7 |
| programStageInstance | /api/33/messages?programStageInstance=SllsjpfLH2 |
| trackedEntityInstance | /api/33/messages?trackedEntityInstance=xdfejpfLH2 |
| organisationUnit | /api/33/messages?ou=Sllsjdhoe3 |
| processedDate | /api/33/messages?processedDate=2016-02-01 |


# New Tracker { #new-tracker } 

Version 2.36 of DHIS2 introduced a set of new tracker endpoints dedicated to importing and querying tracker objects (Including tracked entities, enrollments, events, and relationships).
These new endpoints set a discontinuity with earlier implementations. Re-engineering the endpoints allowed developers to improve, redesign, and formalize the API's behavior to improve the Tracker services.

The newly introduced endpoints consist of:

* `POST /api/tracker`
* `GET /api/tracker/enrollments`
* `GET /api/tracker/events`
* `GET /api/tracker/trackedEntities`
* `GET /api/tracker/relationships`

> **NOTE**
>
> - The old endpoints are marked as deprecated but still work as before.
> - Some functionality is not yet ready in the new endpoints, but they support their primary use-cases.
> - These endpoints currently only support the `JSON` format as input/output.
> - Support for the `CSV` format will also be available in the future.

## Changes in the API { #changes-in-the-api } 

Property names used in the API have changed to use consistent naming across all the new endpoints.

### Tracker Import changelog (`POST`) { #tracker-import-changelog-post } 

The following table highlights the differences between the previous tracker import endpoints (/api/trackedEntityInstance, /api/enrollments, /api/events and /api/relatiosnhips) and the new endpoint (/api/tracker). All endpoints are still currently available.

|Tracker Object|Previously|Now|
|---|---|---|
|**Attribute**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**DataValue**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**Enrollment**|`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`trackedEntityInstance`<br>`enrollmentDate`<br>`incidentDate`<br>`completedDate`|`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`trackedEntity`<br>`enrolledAt`<br>`occurredAt`<br>`completedAt`|
|**Manifestation**|`trackedEntityInstance`<br>`eventDate`<br>`dueDate`<br>`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`<br>`completedDate`|`trackedEntity`<br>`occurredAt`<br>`scheduledAt`<br>`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`<br>`completedAt`|
|**Remarque**|`storedDate`|`storedAt`|
|**ProgramOwner**|`ownerOrgUnit`<br>`trackedEntityInstance`|`orgUnit`<br>`trackedEntity`|
|**RelationshipItem**|`trackedEntityInstance.trackedEntityInstance`<br>`enrollment.enrollment`<br>`event.event`|`trackedEntity`<br>`enrollment`<br>`event`|
|**Relationship**|`created`<br>`lastUpdated`|`createdAt`<br>`updatedAt`|
|**TrackedEntity**|`trackedEntityInstance`<br>`created`<br>`createdAtClient`<br>`lastUpdated`<br>`lastUpdatedAtClient`|`trackedEntity`<br>`createdAt`<br>`createdAtClient`<br>`updatedAt`<br>`updatedAtClient`|

### Tracker Export changelog (`GET`) { #tracker-export-changelog-get } 

The `GET` endpoints all conform to the same naming conventions reported in the previous paragraph. Additionally, we made some changes regarding the request parameters to respect the same naming conventions here as well.

These tables highlight the old endpoint differences in request parameters for `GET` endpoints compared to the new

#### Request parameter changes for `GET /api/tracker/enrollments` { #request-parameter-changes-for-get-apitrackerenrollments } 
|Previously|Now|
|---|---|
|`ou`|`orgUnit` (unité d'organisation)|
|`lastUpdated`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedWithin`|
|`programStartDate`<br>`programEndDate`|`enrolledAfter`<br>`enrolledBefore`|
|`trackedEntityInstance`|`trackedEntity` (entité suivie)|

#### Request parameter changes for `GET /api/tracker/events` { #request-parameter-changes-for-get-apitrackerevents } 
|Previously|Now|
|---|---|
|`trackedEntityInstance`|`trackedEntity` (entité suivie)|
|`startDate`<br>`endDate`|`occurredAfter`<br>`occurredBefore`|
|`dueDateStart`<br>`dueDateEnd`|`scheduledAfter`<br>`scheduledBefore`|
|`lastUpdated`|Removed - obsolete, see: <br><ul><li>`updatedAfter`</li><li>`updatedBefore`</li></ul>|
|`lastUpdatedStartDate`<br>`lastUpdateEndDate`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedBefore`<br>`updatedWithin`|

#### Request parameter changes for `GET /api/tracker/trackedEntities` { #request-parameter-changes-for-get-apitrackertrackedentities } 
|Previously|Now|
|---|---|
|`trackedEntityInstance`|`trackedEntity` (entité suivie)|
|`ou`|`orgUnit` (unité d'organisation)|
|`programStartDate`<br>`programEndDate`|Removed - obsolete, see <br><ul><li>`enrollmentEnrolledAfter`</li><li>`enrollmentEnrolledBefore`</li></ul>|
|`programEnrollmentStartDate`<br>`programEnrollmentEndDate`|`enrollmentEnrolledAfter`<br>`enrollmentEnrolledBefore`|
|`programIncidentStartDate`<br>`programIncidentEndDate`|`enrollmentOccurredAfter`<br>`enrollmentOccurredBefore`|
|`eventStartDate`<br>`eventEndDate`|`eventOccurredAfter`<br>`eventOccurredBefore`|
|`lastUpdatedStartDate`<br>`lastUpdateEndDate`<br>`lastUpdateDuration`|`updatedAfter`<br>`updatedBefore`<br>`updatedWithin`|


## Objets Tracker { #webapi_nti_tracker_objects }

Tracker est constitué de différents types d'objets interconnectés destinés à représenter les données. Dans cette section, nous montrerons et décrirons chacun des objets utilisés dans l'API du Tracker.

### Entité suivie { #tracked-entity }

Les `entités suivies` constituent la base du modèle Tracker.

| Propriété | Description | Obligatoire | Updateable | Type | Exemple |
|---|---|---|---|---|---|
| Entité suivie | L’identifiant de l’entité suivie. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| TrackedEntityType (Type d'entité suivie) | Le type d’entité suivie. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| créé à | Date à laquelle l'utilisateur a créé l'entité suivie. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| crééAtClient (Création au niveau du client) | Date à laquelle l'utilisateur a créé l'entité suivie au niveau du client. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de l'objet. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAtClient (mise à jour au niveau du client) | Date de la dernière mise à jour de l'objet au niveau du client. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| orgUnit (Unité d'organisation) | L'unité d'organisation dans laquelle l'utilisateur a créé l'entité suivie. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| inactif | Indique si l'entité suivie est inactive ou non. | Non | Non | Booléen | Par défaut : Faux, Vrai |
| supprimé | Indique si l'entité suivie a été supprimée. Ne peut être modifié qu'au moment de la suppression. | Non | Oui | Booléen | Faux jusqu'à suppression |
| géométrie | Il s'agit d'une représentation géographique de l'entité suivie. Elle est basée sur le « type de fonctionnalité » du type d'entité suivie. | Non | Non | GeoJson | {<br>"type": "POINT",<br>"coordonnées": [123.0, 123.0]<br>} |
| Stocké par | Référence client indiquant celui a stocké/créé l’entité suivie. | Non | Non | Chaîne : Toute | John Doe |
| les attributs | Une liste de valeurs d'attributs d'entité suivie appartenant à l'entité suivie. | Non | Non | Liste des valeurs d'attributs d'entités suivies | Voir l'attribut |
| inscriptions | Une liste des inscriptions appartenant à l’entité suivie. | Non | Non | Liste des inscriptions | Voir les inscriptions |
| relations | Une liste de relations connectées à l'entité suivie. | Non | Non | Liste des relations | Voir les relations |
| Propriétaires du programme | Liste des unités d'organisation qui ont accès via des programmes spécifiques à cette entité suivie. Voir « Propriété du programme » pour en savoir plus. | Non | Non | Liste des propriétaires du programme | Voir la section « Propriété du programme » |

> **Note**
>
> `Tracked Entities` "owns" all `Tracked Entity Attribute Values` (Or "attributes" as described in the previous table). However, `Tracked Entity Attributes` are either connected to a `Tracked Entity` through its `Tracked Entity Type` or a `Program`. We often refer to this separation as `Tracked Entity Type Attrbiutes` and `Tracked Entity Program Attributes`. The importance of this separation is related to access control and limiting what information the user can see.
>
> The "attributes" referred to in the `Tracked Entity` are `Tracked Entity Type Attributes`.


### Inscription { #enrollment } 
Les `Entités suivies` peuvent s'inscrire aux `Programmes` pour lesquels elles sont éligibles. Les entités suivies sont éligibles tant que le programme est configuré avec le même `Type d'entité suivie` que l'entité suivie. Nous représentons l'inscription avec l'objet `Inscription`, que nous décrivons dans cette section.


| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| inscription | L’identifiant de l'inscription. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| de paludisme) ». | Le programme que représente l’inscription. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| Entité suivie | Une référence à l’entité suivie inscrite. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| TrackedEntityType (Type d'entité suivie) | Uniquement pour lire les données. Il s'agit du type de l'entité suivie inscrite | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| statut | Statut de l'inscription. Il est ACTIF au cas où n'est pas fourni. | Non | Non | Énumération | ACTIF, TERMINÉ, ANNULÉ |
| orgUnit (Unité d'organisation) | L'unité d'organisation dans laquelle l'utilisateur a inscrit l'entité suivie. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| orgUnitName (nom de l'unité d'organisation) | Uniquement pour lire les données. Il s'agit du nom de l'unité d'organisation où l'inscription a eu lieu. | Non | Non | Chaîne : Toute | Sierra Leone |
| créé à | Date à laquelle l'utilisateur a créé l'objet. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| crééAtClient (Création au niveau du client) | Date à laquelle l'utilisateur a créé l'objet au nibveau du client | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de l'objet. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAtClient (mise à jour au niveau du client) | Date de la dernière mise à jour de l'objet au niveau du client. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| enrolledAt (inscrit à) | Date à laquelle l'utilisateur a inscrit l'entité suivie. | Oui | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| occurredAt (s'est produit à) | Date à laquelle l'inscription a eu lieu. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedAt (terminé à) | Date à laquelle l'utilisateur a terminé l'inscription. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedBy (terminé par) | Fait référence à la personne qui a effectué l'inscription | Non | Non | John Doe |
| suivi | Indicates whether the enrollment requires follow-up. False if not supplied | Non | Non | Booléen | Par défaut : Faux, Vrai |
| supprimé | Indique si l'inscription a été supprimée. Ne peut être modifié qu'au moment de la suppression. | Non | Oui | Booléen | Faux jusqu'à suppression |
| géométrie | Il s'agit d'une représentation géographique de l'inscription. Elle se base sur le « type de fonctionnalité » du programme. | Non | Non | GeoJson | {<br>"type": "POINT",<br>"coordonnées": [123.0, 123.0]<br>} |
| Stocké par | Référence client indiquant celui a stocké/créé l'inscription. | Non | Non | Chaîne : Toute | John Doe |
| les attributs | Une liste de valeurs d'attributs d'entité suivie associées à l'inscription. | Non | Non | Liste des valeurs d'attributs d'entités suivies | Voir l'attribut |
| événements | Une liste des événements appartenant à l'inscription. | Non | Non | Liste des événements | Voir les évènements |
| relations | Une liste des relations liées à l'inscription. | Non | Non | Liste des relations | Voir les relations |
| notes | Notes liées à l'inscription. Elles ne peuvent qu'être créées. | Non | Oui | Liste des notes | Voir les notes |

> **Note**
>
> `Tracked Entities` "owns" all `Tracked Entity Attribute Values` (Or "attributes" as described in the previous table). However, `Tracked Entity Attributes` are either connected to a `Tracked Entity` through its `Tracked Entity Type` or a `Program`. We often refer to this separation as `Tracked Entity Type Attrbiutes` and `Tracked Entity Program Attributes`. The importance of this separation is related to access control and limiting what information the user can see.
>
> The "attributes" referred to in the `Enrollment` are `Tracked Entity Program Attributes`.


### Événements { #events } 
Les `Événements` font partie d'un `PROGRAMME D'ÉVÉNEMENT` ou d'un `PROGRAMME TRACKER`. Pour le `PROGRAMME TRACKER`, les événements appartiennent à une `Inscription`, laquelle appartient à une `Entité suivie`. D'un autre côté, `PROGRAMME D'ÉVÉNEMENT` concerne les `Événements` non rattachées à une `Inscription` ou à une `Entité suivie` spécifique. La différence réside dans le fait que nous effectuons ou non un suivi pour une `Entité suivie` spécifique. Nous désignons parfois les événements `PROGRAMME D'ÉVÉNEMENT` "événements anonymes "ou "événements uniques" puisqu'ils ne se représentent qu'eux-mêmes et non une autre `Entité suivie`.

Dans l'API, la différence majeure est que tous les événements sont soit rattachés à la même inscription (`PROGRAMME D'ÉVÈNEMENT`), soit à des inscriptions différentes (`PROGRAMME TRACKER`). Le tableau ci-dessous signalera les cas exceptionnels entre ces deux.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| événement | L'identifiant de l'événement. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| Étape du programme | L'étape du programme que représente l'événement. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| inscription | A reference to the enrollment which owns the event. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| de paludisme) ». | Uniquement pour lire les données. Il s'agit du type de programme de l'inscription qui possède l'événement. | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| Entité suivie | Uniquement pour lire les données. Il s'agit de l'entité suivie propriétaire de l'événement. Ceci ***ne s'applique pas au `PROGRAMME D'ÉVÉNEMENT`*** | Non | Non | Chaîne : Uid | ABCDEF12345 |
| statut | Statut de l'évènement. Il est ACTIF au cas où n'est pas fourni. | Non | Non | Énumération | ACTIF, EFFECTUÉ, VISITÉ, HORAIRE, EN RETARD, SAUTÉ |
| Statut de l'inscription | Uniquement pour lire les données. Il s'agit du statut de l'inscription propriétaire de l'événement. Ceci ***ne s'applique pas au `PROGRAMME D'ÉVÉNEMENT`*** | Non | Non | Énumération | ACTIF, TERMINÉ, ANNULÉ |
| orgUnit (Unité d'organisation) | Il s'agit de l'unité d'organisation dans laquelle l'utilisateur a enregistré l'événement. | Oui | Non | Chaîne : Uid | ABCDEF12345 |
| orgUnitName (nom de l'unité d'organisation) | Uniquement pour lire les données. Il s'agit du nom de l'unité d'organisation où l'utilisateur a enregistré l'évènement. | Non | Non | Chaîne : Toute | Sierra Leone |
| créé à | Date à laquelle l'utilisateur a créé l'évènement. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| crééAtClient (Création au niveau du client) | Date à laquelle l'utilisateur a créé l'évènement au niveau du client | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de l'évènement. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAtClient (mise à jour au niveau du client) | Date de la dernière mise à jour de l'évènement au niveau du client. | Non | Non | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| scheduledAt (programmé à) | Date à laquelle l'évènement a été programmée. | Oui | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| occurredAt (s'est produit à) | Date à laquelle quelque chose se passe. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedAt (terminé à) | Date à laquelle l'utilisateur a effectué l'évènement. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| completedBy (terminé par) | Fait référence à la personne qui a effectué l'évènement | Non | Non | Chaîne : Toute | John Doe |
| suivi | Indique si l'événement a été marqué pour un suivi. Faux si non fourni | Non | Non | Booléen | Par défaut : Faux, Vrai |
| supprimé | Indique si l'évènement a été supprimée. Ne peut être modifié qu'au moment de la suppression. | Non | Oui | Booléen | Faux jusqu'à suppression |
| géométrie | Il s'agit d'une représentation géographique de l'évènement. Elle se base sur le « type de fonctionnalité » de l'étape de programme. | Non | Non | GeoJson | {<br>"type": "POINT",<br>"coordonnées": [123.0, 123.0]<br>} |
| Stocké par | Référence client indiquant celui a stocké/créé l'évènement. | Non | Non | Chaîne : Toute | John Doe |
| attributeOptionCombo (combinaison d'options d'attribut) | Combinaison d'options d'attribut pour l'événement. Utiliser l'option par défaut s’il n’est pas fourni ou configuré. | Non | Non | Chaîne : Uid | ABCDEF12345
| attributeCategoryOptions (options de catégorie d'attribut) | Il s'agit de l'option de catégorie d'attribut pour l'événement. Utiliser l'option par défaut si rien n’est fourni ou configuré. | Non | Non | Chaîne : Uid | ABCDEF12345
| assignedUser (Utilisateur assigné) | Fait référence à un utilisateur qui a été assigné à l'événement. | Non | Non | Chaîne : Uid | ABCDEF12345 |
| dataValues (Valeurs de données) | Liste des valeurs de données liées à l'événement. | Non | Non | Liste des valeurs d'attributs d'entités suivies | Voir l'attribut |
| relations | Liste des relations liées à l'évènement. | Non | Non | Liste des relations | Voir les relations |
| notes | Notes liées à l'évènement. Elles ne peuvent qu'être créées. | Non | Oui | Liste des notes | Voir les notes |

### Relation { #relationship }

Les `Relations` sont des objets qui relient deux autres objets Tracker. Les contraintes auxquelles chaque côté de la relation doit se conformer sont basées sur le `Type de relation` de la `Relation`.


| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| relation | L'identifiant de la relation. Il est généré au cas où il n'est pas fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| type de relation | Il s'agit du type de relation. Il détermine quels objets peuvent être reliés dans une relation. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| Nom de la relation | Uniquement pour lire les données. Il s'agit du nom du type de relation de cette relation | Non | Non | Chaîne : Toute | Sibling |
| créé à | Date à laquelle l'utilisateur a créé la relation. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de la relation. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| bidirectionnel | Uniquement pour lire les données. Indique si le type de relation est bidirectionnel ou non. | Non | Non | Booléen | Vrai ou faux |
| de, à | Fait référence à chaque côté de la relation. Doit être conforme aux contraintes définies dans le type de relation | Oui | Oui | Élément de la relation | {"trackedEntity": "ABCEF12345"}, {"enrollment": "ABCDEF12345"} or {"event": "ABCDEF12345"} |

> **Note**
>
>`Relationship item` represents a link to an object. Since a `relationship` can be between any tracker object like `tracked entity`, `enrollment`, and `event`, the value depends on the `relationship type`. For example, if the `relationship type` connects from an `event` to a `tracked entity`, the format is strict:
>```json
>{
>   "from": {
>     "event": "ABCDEF12345"    
>   },
>   "to": {
>     "trackedEntity": "FEDCBA12345"
>   }
>}
>```

### Attribut { #attribute } 
Les `Attributs` sont les valeurs qui décrivent les `entités suivies`. Ils peuvent être reliés via un `type d'entité suivi` ou un `programme`. Implicitement, cela signifie que les `attributs` peuvent faire partie à la fois d'une `entité suivie` et d'une `inscription`.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| attribut | Fait référence à l’attribut d’entité suivi représenté. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| code | Uniquement pour lire les données. Il s'agit du code de l'attribut de l'entité suivie | Non | Non | Chaîne : Toute | ABC |
| Nom d'affichage | Uniquement pour lire les données. Il s'agit du nom d'affichage de l'attribut de l'entité suivie | Non | Non | Chaîne : Toute | Nom |
| créé à | Date à laquelle la valeur a été ajoutée. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de la valeur. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| Stocké par | Référence client indiquant celui a stocké/créé la valeur. | Non | Non | Chaîne : Toute | John Doe |
| Type de valeur | Uniquement pour lire les données. Il s'agit du type de valeur que l'attribut représente. | Non | Non | Énumération | TEXTE, ENTIER et plus |
| valeur | La valeur de l'attribut d'entité suivi. | Non | Non | Chaîne : Toute | John Doe |

> **Remarque**
>
> Pour les `attributs`, seules les propriétés "attribut" et "valeur" sont requises lors de l'ajout des données. Une "valeur" peut être nulle, ce qui suppose que l'utilisateur doit la supprimer.
>
> Dans le contexte des objets Tracker, nous considérons les `Attributs d'entité suivie` et les `Valeurs d'attribut d'entité suivie` comme des "attributs". Cependant, les attributs sont également des éléments distincts, liés aux métadonnées. Il est donc essentiel de séparer les attributs Tracker et les attributs de métadonnées. Dans l'API du Tracker, il est possible de référencer les attributs des métadonnées lors de la spécification du `Schéma d'identification` (voir les paramètres de requête pour plus d'informations).

### Valeurs de données { #data-values }
Alors que les `Attributs` décrivent une `entité suivie` ou une `inscription`, les `valeurs de données` décrivent un `évènement`. La différence majeure est que les `attributs ` ne peuvent avoir qu'une seule valeur pour une `entité suivie` donnée. En revanche, les `valeurs de données` peuvent avoir plusieurs valeurs différentes selon les `événements` - même si les `événements` appartiennent tous à la même `inscription` ou à la même `entité suivie`.

| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| élément de données | L'élément de données que cette valeur représente. | Oui | Oui | Chaîne : Uid | ABCDEF12345 |
| valeur | La valeur de la valeur des données. | Non | Non | Chaîne : Toute | 123 |
| Fourni ailleurs | Indique si l'utilisateur a fourni la valeur ailleurs ou non. Faux si la valeur n'a pas été fournie. | Non | Non | Booléen | Faux ou vrai |
| créé à | Date à laquelle l'utilisateur a ajouté la valeur. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Date de la dernière mise à jour de la valeur. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| Stocké par | Référence client indiquant celui a stocké/créé la valeur. | Non | Non | Chaîne : Toute | John Doe |


> **Remarque**
>
> Pour les `éléments de données`, seules les propriétés "élément de données" et "valeur" sont requises lors de l'ajout des données. Une "valeur" peut être nulle, et dans ce cas l'utilisateur doit la supprimer.

### Notes Tracker { #tracker-notes }

Le Tracker de DHIS2 permet de recueillir des données à l'aide d'éléments de données et d'attributs d'entités suivies. Cependant, il est parfois nécessaire d'enregistrer des informations supplémentaires ou des commentaires sur le sujet en question. Ces informations supplémentaires peuvent être saisies à l'aide de notes Tracker. Les notes Tracker correspondent aux commentaires sur les valeurs de données dans DHIS2 Agrégé.

Il existe deux types de notes Tracker : les notes enregistrées au niveau de l'événement et celles enregistrées au niveau de l'inscription. Une inscription peut comporter un ou plusieurs événements. Des commentaires sur chaque événement - par exemple, pourquoi un événement a été manqué, reprogrammé, ou pourquoi seuls quelques éléments de données ont été renseignés et ainsi de suite - peuvent être documentés à l'aide de notes d'événements. Chaque événement d'une inscription peut avoir son propre récit ou ses propres notes. Il est alors possible d'enregistrer, par exemple, une observation générale de ces événements à l'aide de la note d'inscription racine. Les notes d'inscription permettent également de documenter, par exemple, les raisons pour lesquelles une inscription est annulée. C'est à l'utilisateur de faire preuve d'imagination et de déterminer quand et comment utiliser les notes.

L'inscription et l'événement peuvent avoir autant de notes que nécessaire - il n'y a pas de limite. Toutefois, ces notes ne peuvent ni être supprimées ni être mises à jour. Elles servent en quelque sorte de journal de bord. Pour modifier une note, il faut en créer une autre. La seule façon de supprimer une note est de supprimer l'objet racine, à savoir l'événement ou l'inscription. 

Les notes Tracker n'ont pas de point d'extrémité qui leur soit dédié. Elles sont échangées dans le cadre de la charge utile de l'événement racine et/ou de l'inscription. Vous trouverez ci-dessous un exemple de charge utile.

```json
{
  "trackedEntityInstance": "oi3PMIGYJH8",
  <entity_details>,
  ],
  "enrollments": [
    {
      "enrollment": "EbRsJr8LSSO",
      <enrollment_details>
      "notes": [
        {
          "note": "vxmCvYcPdaW",
          "value": "Enrollment note 2.",
        },
        {
          "value": "Enrollment note 1",
        }
      ],

      "events": [
        {
          "event": "zfzS9WeO0uM",
          <event_details>,
          "notes": [
            {
              "note": "MAQFb7fAggS",
              "value": "Event Note 1.",
            },
            {
              "value": "Event Note 2.",
            }
          ],
        },
        {
          ...
        }
      ]
    }
  ]
}
```


| Propriété | Description | Obligatoire | Immuable | Type | Exemple |
|---|---|---|---|---|---|
| note | La référence de la note. Elle est générée si rien n'est fourni | Non | Oui | Chaîne : Uid | ABCDEF12345 |
| valeur | Le contenu de la note. | Oui | Oui | Chaîne : Toute | Ceci est une note |
| Stocké à | Date à laquelle l'utilisateur a ajouté la note. Elle est définie sur le serveur. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| updatedAt (mis à jour à) | Timestamp when the note was last updated. Set on the server. | Non | Oui | Date : ISO 8601 | AAAA-MM-JJThh:mm:ss |
| Stocké par | Référence client indiquant celui a stocké/créé la note. | Non | Non | Chaîne : Toute | John Doe |

## Importation Tracker (`POST /api/tracker`) { #webapi_nti_import }

Le point d'extrémité `POST /api/tracker` permet aux clients d'importer les objets Tracker suivants dans DHIS2 :

* **Entités suivies**
* **Inscriptions**
* **Événements**
* **Relations**
* Données intégrées dans d'autres [objets Tracker](#webapi_nti_tracker_objects)

Les principaux changements à noter par rapport aux autres points d'extrémité dédiés à l'importation Tracker sont :

1. La charge utile d'importation peut être ***imbriquée*** ou ***plate***
2. L'appel peut être ***synchrone*** ou ***asynchrone***

### Paramètres de requête { #request-parameters }

Actuellement, le point d'extrémité de l'importation Tracker prend en charge les paramètres suivants :

| Le nom du paramètre | Description | Type | Valeurs autorisées |
|---|---|---|---|
| async | Indique si l’importation doit avoir lieu de manière asynchrone ou synchrone. | Booléen | `VRAI`, `FAUX` |
| Mode de rapport | Uniquement lors d'une importation synchrone. Voir le "Récapitulatif de l'importation" pour plus d’informations. | Énumération | `COMPLET`, `ERREURS`, `AVERTISSEMENTS` |
| Mode d'importation  | Indicates the mode of import. Can either be validation only or commit (Default) | Énumération | `VALIDATION`, `COMMIT` |
| idScheme | Indicates the overall idScheme to use when importing. Default is AUTO (UID). Can be overridden for specific metadata (Listed below) | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| dataElementIdScheme (Schéma d'identifiant d'élément de données) | Indique le schéma d'identification à utiliser pour les éléments de données lors de l'importation. | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Indique le schéma d'identification à utiliser pour les unités d'organisation lors de l'importation. | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| programIdScheme (Schéma d'identification du programme) | Indique le schéma d'identification à utiliser pour les programmes lors de l'importation. | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| programmeStageIdScheme (Schéma d'identification de l'étape de programme) | Indique le schéma d'identification à utiliser pour les étapes de programme lors de l'importation. | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| categoryOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Indique le schéma d'identification à utiliser pour les combinaisons d'options de catégorie lors de l'importation. | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| categoryOptionIdScheme (Schéma de l'identifiant d'option de catégorie) | Indique le schéma d'identification à utiliser pour les options de catégorie lors de l'importation. | Énumération | `UID`, `CODE`, `NAME`, `ATTRIBUTE`, `AUTO` |
| importStrategy (stratégie d'importation) | Indique l'effet que l'importation doit avoir. Les différentes possibilités sont `CRÉER`, `METTRE À JOUR`, `CRÉER_ET_METTRE À JOUR` et `SUPPRIMER`. Respectivement, elles permettent d'importer de nouvelles données, d'importer des modifications à des données existantes, d'importer de nouvelles données ou des mises à jour à des données existantes et, enfin, de supprimer des données. | Énumération | `CRÉER`, `METTRE À JOUR`, `CRÉER_ET_METTRE À JOUR` et `SUPPRIMER` |
| Mode atomique | Indique comment l'importation répond aux erreurs de validation. S'il est défini sur `TOUS`, toutes les données importées doivent être valides avant que chaque donnée ne soit commitée. Par contre s'il est défini sur `OBJET`, seules les données commitées doivent être valides, tandis que d'autres données peuvent être invalides. | Énumération | `TOUS`, `OBJET` |
| flushMode | Indique la fréquence de vidange. Il s'agit de la fréquence à laquelle les données sont introduites dans la base de données au cours de l'importation. Il est principalement utilisé à des fins de débogage et ne doit pas être modifié dans un environnement de production. | Énumération | `AUTO`, `OBJECT` |
| Mode de validation | Indique l'intégralité de l'étape de validation. Il peut être ignoré, configuré pour échouer rapidement (retour à la première erreur) ou complet (par défaut), ce qui renverra toutes les erreurs trouvées. | Énumération | `COMPLET`, `ÉCHOUER_RAPIDEMENT`, `IGNORER` |
| Validation du modèle de saut | S'il est défini sur 'vrai', la validation du modèle des attributs générés sera sautée. | Booléen | `VRAI`, `FAUX` |
| Sauter les effets secondaires | Si défini sur 'vrai', les effets secondaires de l'importation seront ignorés. | Booléen | `VRAI`, `FAUX` |
| Sauter les règles | Si défini sur 'vrai', l'exécution des règles de programme pour l'importation sera ignorée. | Booléen | `VRAI`, `FAUX` |

### Charges utiles plates et imbriquées { #flat-and-nested-payloads }

L'importateur prend en charge les charges utiles plates et imbriquées. La principale différence réside dans la manière dont le client exige que ses données soient structurées.

**Charge utile plate**
: La charge utile de type plate est simple. Elle peut contenir des collections pour chacun des principaux objets Tracker dont nous disposons. Cela fonctionne de manière transparente avec les données existantes, auxquelles des UID sont déjà attribués. Cependant, pour les nouvelles données, le client devra fournir de nouveaux UID pour toute référence entre objets. Par exemple, si vous importez une nouvelle entité suivie avec une nouvelle inscription, l'entité suivie demande au client de fournir un UID afin que l'inscription puisse être rattachée à cet UID.

**Charge utile imbriqué**
: Les charges utiles imbriquées sont la structure la plus couramment utilisée. Ici, les objets Tracker sont intégrés dans leur objet racine - par exemple, une inscription dans une entité suivie. L'avantage avec cette structure est que le client n'a pas besoin de fournir d'UID pour toutes ces connexions puisqu'il se verra attribuer la connexion au cours du processus d'importation, étant donné qu'elles sont imbriquées les unes aux autres.

> **REMARQUE**
>
> Même si les charges utiles imbriquées peuvent s'avérer plus simples à gérer pour les clients, elles seront toujours aplaties avant l'importation. Cela signifie que pour les importations volumineuses, le fait de fournir une charge utile plate permettra non seulement d'avoir plus de contrôle mais aussi moins de surcharge sur le processus d'importation.

Ci-dessous, des exemples de versions **PLATES** et **IMBRIQUÉES** de la charge utile. Les mêmes données sont utilisées dans les deux cas.

#### Charge utile ***PLATE*** { #flat-payload }

```json
{
  "trackedEntities": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "Q9GufDoplCL"
    }
  ],
  "enrollments": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "program": "f1AyMswryyQ",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "trackedEntityType": "Q9GufDoplCL",
      "enrolledAt": "2019-08-19T00:00:00.000",
      "deleted": false,
      "occurredAt": "2019-08-19T00:00:00.000",
      "status": "ACTIVE",
      "notes": [],
      "attributes": [],
    }
  ],
  "events": [
    {
      "scheduledAt": "2019-08-19T13:59:13.688",
      "program": "f1AyMswryyQ",
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "status": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "attributeCategoryOptions": "xYerKDKCefk",
      "deleted": false,
      "attributeOptionCombo": "HllvX50cXC0",
      "dataValues": [
        {
          "updatedAt": "2019-08-19T13:58:37.477",
          "storedBy": "admin",
          "dataElement": "BuZ5LGNfGEU",
          "value": "20",
          "providedElsewhere": false
        },
        {
          "updatedAt": "2019-08-19T13:58:40.031",
          "storedBy": "admin",
          "dataElement": "ZrqtjjveTFc",
          "value": "Male",
          "providedElsewhere": false
        },
        {
          "updatedAt": "2019-08-19T13:59:13.691",
          "storedBy": "admin",
          "dataElement": "mB2QHw1tU96",
          "value": "[-11.566044,9.477801]",
          "providedElsewhere": false
        }
      ],
      "notes": []
    },
    {
      "scheduledAt": "2019-08-19T13:59:13.688",
      "program": "f1AyMswryyQ",
      "event": "XwwuwNp6gVE",
      "programStage": "PaOOjwLVW23",
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "enrollment": "MNWZ6hnuhSw",
      "enrollmentStatus": "ACTIVE",
      "status": "ACTIVE",
      "occurredAt": "2019-08-01T00:00:00.000",
      "attributeCategoryOptions": "xYerKDKCefk",
      "deleted": false,
      "attributeOptionCombo": "HllvX50cXC0",
      "notes": []
    }
  ],
  "relationships": [
    {
      "relationshipType": "Udhj3bsdHeT",
      "from": {
        "trackedEntity": "Kj6vYde4LHh"
      },
      "to": {
        "trackedEntity": "Gjaiu3ea38E"
      }
    }
  ]
}
```

#### Charge utile ***IMBRIQUÉES*** { #nested-payload }

```json
{
  "trackedEntities": [
    {
      "orgUnit": "O6uvpzGd5pu",
      "trackedEntity": "Kj6vYde4LHh",
      "trackedEntityType": "Q9GufDoplCL",
      "relationships": [
        {
          "relationshipType": "Udhj3bsdHeT",
          "from": {
            "trackedEntity": "Kj6vYde4LHh"
          },
          "to": {
            "trackedEntity": "Gjaiu3ea38E"
          }
        }
      ],
      "enrollments": [
        {
          "orgUnit": "O6uvpzGd5pu",
          "program": "f1AyMswryyQ",
          "trackedEntity": "Kj6vYde4LHh",
          "enrollment": "MNWZ6hnuhSw",
          "trackedEntityType": "Q9GufDoplCL",
          "enrolledAt": "2019-08-19T00:00:00.000",
          "deleted": false,
          "occurredAt": "2019-08-19T00:00:00.000",
          "status": "ACTIVE",
          "notes": [],
          "relationships": [],
          "attributes": [],
          "events": [
            {
              "scheduledAt": "2019-08-19T13:59:13.688",
              "program": "f1AyMswryyQ",
              "event": "ZwwuwNp6gVd",
              "programStage": "nlXNK4b7LVr",
              "orgUnit": "O6uvpzGd5pu",
              "trackedEntity": "Kj6vYde4LHh",
              "enrollment": "MNWZ6hnuhSw",
              "enrollmentStatus": "ACTIVE",
              "status": "ACTIVE",
              "occurredAt": "2019-08-01T00:00:00.000",
              "attributeCategoryOptions": "xYerKDKCefk",
              "deleted": false,
              "attributeOptionCombo": "HllvX50cXC0",
              "dataValues": [
                {
                  "updatedAt": "2019-08-19T13:58:37.477",
                  "storedBy": "admin",
                  "dataElement": "BuZ5LGNfGEU",
                  "value": "20",
                  "providedElsewhere": false
                },
                {
                  "updatedAt": "2019-08-19T13:58:40.031",
                  "storedBy": "admin",
                  "dataElement": "ZrqtjjveTFc",
                  "value": "Male",
                  "providedElsewhere": false
                },
                {
                  "updatedAt": "2019-08-19T13:59:13.691",
                  "storedBy": "admin",
                  "dataElement": "mB2QHw1tU96",
                  "value": "[-11.566044,9.477801]",
                  "providedElsewhere": false
                }
              ],
              "notes": [],
              "relationships": []
            },
            {
              "scheduledAt": "2019-08-19T13:59:13.688",
              "program": "f1AyMswryyQ",
              "event": "XwwuwNp6gVE",
              "programStage": "PaOOjwLVW23",
              "orgUnit": "O6uvpzGd5pu",
              "trackedEntity": "Kj6vYde4LHh",
              "enrollment": "MNWZ6hnuhSw",
              "enrollmentStatus": "ACTIVE",
              "status": "ACTIVE",
              "occurredAt": "2019-08-01T00:00:00.000",
              "attributeCategoryOptions": "xYerKDKCefk",
              "deleted": false,
              "attributeOptionCombo": "HllvX50cXC0",
              "notes": [],
              "relationships": []
            }
          ]
        }
      ]
    }
  ]
}
```

### SYNC et ASYNC { #sync-and-async }
Pour l'utilisateur, la principale différence entre une importation synchrone et une importation asynchrone est la réponse immédiate de l'API. Dans le cas d'une importation synchrone, la réponse sera renvoyée avec le récapitulatif de l'importation (importSummary) dès que l'importation sera terminée. En revanche, pour les importations asynchrones, la réponse sera immédiate et contiendra une référence à travers laquelle le client pourra demander des mises à jour de l'importation.

Dles importations importantes, il peut être avantageux pour le client d'utiliser l'importation asynchrone pour éviter d'attendre trop longtemps une réponse.


Des exemples de réponse **ASYNC** sont présentés ci-dessous. Pour la réponse **SYNC**, consultez la [section importSummary](#webapi_nti_import_summary).

```json
{
    "httpStatus": "OK",
    "httpStatusCode": 200,
    "status": "OK",
    "message": "Tracker job added",
    "response": {
        "responseType": "TrackerJob",
        "id": "LkXBUdIgbe3",
        "location": "https://play.dhis2.org/dev/api/tracker/jobs/LkXBUdIgbe3"
    }
}
```

### Récapitulatif des importations { #webapi_nti_import_summary }

L'API du Tracker dispose de deux points d'extrémité de base qui permettent aux consommateurs d'obtenir des commentaires sur leurs importations. Ces points d'extrémité concernent plus les tâches d'importation asynchrone, mais ils sont également disponibles pour les importations synchrones. Ces points d'extrémité renverront soit le journal de l'importation, soit le récapitulatif de l'importation lui-même.

> **Remarque**
>
> Ces points d'extrémité s'appuient sur des informations stockées dans la mémoire de l'application. Cela signifie que les informations seront indisponibles après certaines situations, telle qu'un redémarrage de l'application ou après un grand nombre de requêtes d'importation qui commencent après celle-ci.

Après avoir soumis une requête d'importation Tracker, nous pouvons accéder aux points d'extrémité suivants afin de surveiller la progression de la tâche en fonction des journaux :

`GET /tracker/jobs/{uid}`

| Paramètre|Description|Exemple
|---|---|---|
|`{uid}`| L'UID d'une tâche d'importation Tracker existante | ABCDEF12345

#### exemple de ***REQUÊTE*** { #request-example }

`GET /tracker/jobs/mEfEaFSCKCC`

#### Exemple de ***RÉPONSE*** { #response-example }

```json
[
  {
    "uid": "mEfEaFSCKCC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:06.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) finished in 6.00000 sec. Import:Done",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:05.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) commit completed in 1.00000 sec. Import:commit",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:04.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) programruleValidation completed in 1.00000 sec. Import:programruleValidation",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:03.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) programrule completed in 1.00000 sec. Import:programrule",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:02.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) validation completed in 1.00000 sec. Import:validation",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "DEBUG",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:01.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) preheat completed in 1.00000 sec. Import:preheat",
    "completed": true,
    "id": "mEfEaFSCKCC"
  },
  {
    "uid": "mEfEaFSCKCC",
    "level": "INFO",
    "category": "TRACKER_IMPORT_JOB",
    "time": "2021-01-01T00:00:00.00",
    "message": "TRACKER_IMPORT_JOB ( mEfEaFSCKCC ) started by admin ( xE7jOejl9FI ) Import:Start",
    "completed": true,
    "id": "mEfEaFSCKCC"
  }
]
```

De plus, le point d'extrémité suivant renverra le récapitulatif de la tâche d’importation. Ce récapitulatif ne sera disponible qu'une fois l'importation terminée :

`GET /tracker/jobs/{uid}/report`

| Paramètre|Description|Exemple
|---|---|---|
|path `/{uid}`| L'UID d'une tâche d'importation Tracker existante | ABCDEF12345
|`reportMode` (Mode de rapport)| Le niveau du rapport à renvoyer | `FULL`&#124;`ERRORS`&#124;`WARNINGS`|

#### exemple de ***REQUÊTE*** { #request-example }

`GET /tracker/jobs/mEfEaFSCKCC/report`

#### Exemple de ***RÉPONSE*** { #response-example }

La [charge utile de la réponse](#sample-responses) est la même que celle renvoyée après une requête d'importation synchrone.

> **Remarque**
>
> Les deux points d'extrémité sont principalement utilisés pour l'importation asynchrone. Cependant, `GET /tracker/jobs/{uid}` devrait également fonctionner pour les demandes synchrones car au final il utilise le même processus d'importation et la même journalisation que les demandes asynchrones.

### Structure du récapitulatif d'importation { #import-summary-structure }

La structure globale des récapitulatifs d'importation se présente comme suit, en fonction du `mode de rapport` faisant l'objet de la requête :
```json
{
  "status": "...",
  "validationReport": { },
  "stats": { },
  "timingsStats": { },
  "bundleReport": { },
  "message" : { }
}
```

***statut***

La propriété `statut` du récapitulatif d'importation indique l'état global de l'importation. Si aucune erreur ou avertissement n'est signalé(e) lors de l'importation, le `statut` est `OK`. Par contre, si une erreur ou un avertissement est signalé(e) lors de l'importation, le statut devient `ERREUR` ou `AVERTISSEMENT`.

Le `statut` dépend du `Rapport de validation` le plus important. `ERREUR` est le plus important, suivi de `AVERTISSEMENT` et enfin `OK`. Cela implique que `ERREUR` est signalé si une seule erreur a été détectée lors de l'importation, quel que soit le nombre d'avertissements.

> **Remarque**
>
> Si l'importation est faite selon le mode atomique "OBJET", où les données sont importées sans erreurs de validation, le statut sera toujours `ERREUR` si des erreurs sont détectées.

***Rapport de validation***

Le `Rapport de validation` peut inclure des `Rapports d'erreur` et des `Rapports d'avertissement` si des erreurs ou des avertissements étaient présents lors de l'importation. Lorsqu'ils sont présents, ils fournissent une liste détaillée des erreurs ou avertissements rencontrés.

Ci-dessous, un exemple d'erreur de validation lors de l'importation d'une `ENTIÉE_SUIVIE` :
```json
{
  "validationReport": {
    "errorReports": [
      {
        "message": "Could not find TrackedEntityType: `Q9GufDoplCL`.",
        "errorCode": "E1005",
        "trackerType": "TRACKED_ENTITY",
        "uid": "Kj6vYde4LHh"
      },
      ...
    ],
    "warningReports" : [ ... ]
  }
}
```

Le rapport contient un message et un code décrivant l'erreur (voir la section [codes d'erreur] (#error-codes) pour plus d'informations sur les erreurs). Il contient également le `type de tracker` et l'`uid`, lesquels permettent d'identifier l'emplacement de l'erreur dans les données. Dans ce cas, il y avait une `ENTITÉ_SUIVIE` avec l'uid `Kj6vYde4LHh` qui renvoyait à un type d'entité suivi qui n'a pas été trouvé.

> **Remarque**
>
> Les `uid` des objets trackers servent de noms à ces objets dans la charge utile. Par exemple, l'`uid` d'une entité suivie dans la charge utile serait "trackedEntity". La même chose s'applique aux inscriptions, aux événements et aux relations qui portent respectivement les noms "enrollment", "event" et "relationship".
>
> Si aucun uid n'est fourni dans la charge utile, le processus d'importation générera de nouveaux uids. Cela signifie que le rapport d'erreur peut faire référence à un uid qui n'existe pas dans votre charge utile.
>
> Les erreurs signalent des problèmes avec la charge utile que l'importateur ne peut pas contourner. Toute erreur empêchera l'importation de ces données. Les avertissements, en revanche, sont des problèmes qui peuvent être contournés en toute sécurité, mais dont l'utilisateur doit être informé. Les avertissements ne bloquent pas l'importation des données.

***Statistiques***

Les statistiques donnent un aperçu rapide de l'importation. Une fois l'importation terminée, ces statistiques indiqueront la quantité de données créées, mises à jour, supprimées ou ignorées.

Exemple:
```json
{
  "stats": {
    "created": 2,
    "updated": 2,
    "deleted": 1,
    "ignored": 5,
    "total": 10
  }
}
```
`cre` fait référence au nombre de nouveaux objets créés. En général, les objets sans UID existant dans la charge utile seront traités comme de nouveaux objets.

`updated` fait référence au nombre d'objets mis à jour. Si un objet a un UID défini dans la charge utile, il sera considéré comme étant à jour tant que ce même UID se trouve dans la base de données.

`deleted` fait référence au nombre d'objets supprimés lors de l'importation. La suppression ne se produit que lorsque l'importation est configurée pour supprimer des données et uniquement lorsque les objets présents dans la charge utile ont des UID existants définis.

`ignored` fait référence aux objets qui n'ont pas été conservés. Les objets peuvent être ignorés pour plusieurs raisons, par exemple pour éviter de créer un objet qui existe déjà. Ignorer des objets ne pose pas de réels problèmes, car si un objet est ignoré, c'est parce que sa création n'était pas nécessaire ou cela lié à la configuration de l'importation.

***timingStats*** (Statistiques de temps)

`timingStats` représente le temps écoulé dans les différentes étapes de l'importation. Ces statistiques ne donnent pas le temps total exact de l'importation, mais plutôt le temps passé dans le code pour les différentes étapes.

Les `timingStats` servent principalement à déboguer les importations qui posent des problèmes afin de voir quelle partie de l'importation rencontre des problèmes.
```json
{
  "timingsStats": {
    "timers": {
      "preheat": "0.234086 sec.",
      "preprocess": "0.000058 sec.",
      ...
      "totalImport": "0.236810 sec.",
      "validation": "0.001533 sec."
    }
  }
}
```

***bundleRapport*** (Rapport d'ensemble)

Une fois l'importation terminée, le `bundleReport` contient tous les [objets tracker](#tracker-objects) importés.

Prenons en exemple l'`ENTITÉ_SUIVIE` :
```json
{
  "bundleReport": {
    "status": "OK",
    "typeReportMap": {
      "TRACKED_ENTITY": {
        "trackerType": "TRACKED_ENTITY",
        "stats": {
          "created": 1,
          "updated": 0,
          "deleted": 0,
          "ignored": 0,
          "total": 1
        },
        "objectReports": [
          {
            "trackerType": "TRACKED_ENTITY",
            "uid": "FkxTQC4EAKK",
            "index": 0,
            "errorReports": []
          }
        ]
      },
      ...
    }
  }
}
```
Comme nous l'avons vu, chaque type d'objet Tracker sera rapporté, et chacun a ses propres statistiques et `objectReports`(rapports d'objets). Ces `rapports d'objets` fourniront des détails sur chaque objet importé, notamment leur type, leur UID et tout rapport d'erreur ou d'avertissement qui les concerne.

***message***

Si l'importation se termine brusquement, le `message`  va contenir des informations supplémentaires sur ce qui s'est passé.

### Import Summary Report Level { #import-summary-report-level } 

Comme indiqué précédemment, `GET /tracker/jobs/{uid}/report` peut être récupéré à l'aide d'un paramètre `reportMode` spécifique. Par défaut, le point d'extrémité renverra un `importSummary` avec `pour reportMode` `ERROR`.

| Paramètre | Description |
|---|---|
| `COMPLET` | Renvoie tout à partir de `AVERTISSEMENTS`, en plus des `timingsStats` |
| `AVERTISSEMENTS` | Renvoie tout à partir de `ERREURS`, en plus de `warningReports` (rapports d'avertissement) dans `validationReports` (rapports de validation) |
| `ERREURS` (par défaut) | Renvoie uniquement `errorReports` (rapports d'erreurs) dans `validationReports` |

De plus, tous les `reportModes` (modes de rapports) renverront `statut`, `statistiques`, `bundleReport` et `message` le cas échéant.

### Codes d'erreur { #webapi_nti_error_codes }

Il existe plusieurs codes d'erreur pour différents scénarios d'erreur. Le tableau suivant contient la liste des codes d'erreur générés par la nouvelle API du Tracker, ainsi que les messages d'erreur et quelques descriptions supplémentaires. Les espaces réservés dans les messages d'erreur (`{0}`, `{1}`, `{2}`..) sont généralement des uids, sauf indication contraire.

| Code d'erreur | Message d'erreur | Description |
|:--|:----|:----|
| E1000 | Utilisateur : `{0}`, n'a pas d'accès en écriture à l'unité d'organisation : `{1}`. | Cela signifie que l'unité d'organisation `{1}` ne fait pas partie du champ de saisie de l'utilisateur `{0}` pour que l'opération d'écriture soit autorisée. |
| E1001 | L'utilisateur : `{0}`, n'a pas d'accès en écriture de données sur le type d'entité suivie : `{1}`. | L'erreur se produit lorsque l'utilisateur n'est pas autorisé à créer ou à modifier les données du Type d'entité suivie `{1}`
| E1002 | L'instance d'entité suivie `{0}` existe déjà. | Cette erreur se produit lorsque l'on essaie de créer une nouvelle entité suivie avec un uid déjà existant. Veillez à utiliser un nouvel uid lors de l'ajout d'une nouvelle entité suivie. |
| E1005 | Impossible de trouver le Type d'entité suivie : `{0}`. | L'erreur se produit lorsque l'on essaie de récupérer un Type d'entité suivie non existant avec l'uid `{0}` . Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture au Type d'entité suivie. |
| E1006 | L'attribut : `{0}` n'existe pas. | L'erreur se produit lorsque le système n'a pas pu trouver un attribut d'entité suivie correspondant avec l'uid `{0}`. Cela peut également signifier que l'utilisateur n'a pas accès à l'attribut d'entité suivie. |
| E1007 | Erreur de validation du type de valeur d'attribut : `{0}` ; Erreur : `{1}`. | Incompatibilité entre le type de valeur d'un attribut d'entité suivie et la valeur d'attribut qui lui est fournie. L'erreur de validation réelle sera affichée dans `{1}`. |
| E1009 | Le ressource de fichier : `{0}` a déjà été attribuée à un autre objet. | L'uid de ressource de fichier `{0}` est déjà attribué à un autre objet du système. |
| E1010 | Impossible de trouver le programme : `{0}` lié à l'événement. | Le système n'a pas pu trouver un programme avec l'uid `{0}` spécifié dans la charge utile Événement. Cela peut également signifier que le programme spécifique n'est pas accessible par l'utilisateur connecté. |
| E1011 | Impossible de trouver l'unité d'organisation : `{0}` lié à l'événement. | Le système n'a pas pu trouver une unité d'organisation avec l'uid `{0}` spécifié dans la charge utile de l'événement.  |
| E1012 | La géométrie n'est pas conforme au FeatureType (type de fonctionnalité) : `{0}`. | Le type de fonctionnalité fourni est soit NONE (aucun), soit il est incompatible pour la valeur géométrique fournie. |
| E1013 | Impossible de trouver le ProgramStage (étape de programme) : `{0}`, lié à l'événement. | Le système n'a pas pu trouver une étape de programme avec l'uid `{0}` spécifié dans la charge utile de l'événement. Cela peut également signifier que l'étape de programme n'est pas accessible à l'utilisateur connecté.  |
| E1014 | Un programme identifié `{0}` est un programme sans enregistrement. Aucune inscription ne peut être faite dans un programme sans enregistrement. | Les inscriptions ne peuvent être créées que pour les programmes avec des enregistrements. |
| E1015 | L'instance d'entité suivie : `{0}` a déjà une inscription active dans le programme `{1}`. | Il est impossible de s'inscrire à un programme si une autre inscription active existe déjà pour le programme. L’inscription active devra au moins être terminée au préalable. |
| E1016 | L'instance d'entité suivie : `{0}` a déjà une inscription active dans le programme : `{1}`, et ce programme n'autorise qu'une seule inscription . | Conformément à la configuration du programme `{1}`, une entité suivie ne peut être inscrite qu'une seule fois à ce programme. Il semble que l'entité suivie `{0}` ait déjà une inscription ACTIVE ou TERMINÉE dans ce programme. Une autre inscription ne peut donc pas être ajoutée. |
| E1018 | L'attribut : `{0}` est obligatoire dans le programme `{1}` mais il n'est pas déclaré dans l'inscription `{2}`. | La valeur de l'attribut est manquante dans la charge utile, pour un attribut défini comme obligatoire pour un programme. Assurez-vous que les valeurs des attributs obligatoires sont fournies dans la charge utile.  |
| E1019 | Only Program attributes is allowed for enrollment; Non valid attribute: `{0}`. | L'uid d'attribut `{0}` spécifié dans la charge utile d'inscription n'est pas associé au programme.  |
| E1020 | La date d'inscription : `{0}` ne peut pas être une date ultérieure.` | Il est impossible de créer une inscription à une date ultérieure à moins que le Programme ne le permette dans sa configuration. |
| E1021 | La date d'incidence identifiée `{0}` ne peut pas être une date ultérieure.` | La date d'incidence ne peut pas être une date ultérieure à moins que le Programme ne le permette dans sa configuration. |
| E1022 | L'instance d'entité suivie `{0}` doit avoir le même type d'entité suivie que le programme `{1}`. | Le programme est configuré pour accepter un UID de type d'entité suivie différent de celui fourni dans la charge utile d’inscription. |
| E1023 | La DisplayIncidentDate (date d'affichage de l'incident) est vraie mais la propriété occurredAt (survenu à) est nulle ou a un format invalide : `{0}`. | Le programme est configuré avec la date d'affichage de l'incident mais sa date est nulle ou invalide dans la charge utile. |
| E1025 | La propriété enrolledAt (inscrit à) est nulle ou a un format non valide : `{0}`. | La date d'inscription est obligatoire pour une inscription. Assurez-vous qu'il ne soit pas nul et qu'il ait un format de date valide. |
| E1029 | L'unité d'organisation Évènement identifiée `{0}` et le Programme `{1}` ne correspondent pas. | La charge utile de l'événement utilise un programme `{1}` qui n'est pas configuré pour être accessible par l'unité d'organisation `{0}`. |
| E1030 | L'Événement `{0}` existe déjà. | Cette erreur se produit lorsque l'on essaie d'ajouter un nouvel événement avec un uid déjà existant. Veillez à utiliser un nouvel uid lors de l'ajout d'un nouvel événement. |
| E1031 | La date à laquelle l'événement est survenu (OccurredAt) est manquante. | La propriété OccuredAt (est survenue) est nulle ou a un format de date invalide dans la charge utile. |
| E1032 | L'Événement `{0}` n'existe pas. | |
| E1033 | La valeur d'inscription de l'Événement `{0}`  est NULLE. | |
| E1035 | La valeur d'inscription de l'Étape de programme `{0}`  est NULLE. | |
| E1036 | L'instance d'entité suivie de l'Événement `{0}` ne pointe pas vers un objet existant. | Le système n'a pas pu trouver une entité suivie avec l'UID spécifié dans la charge utile de l'événement. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à l'entité suivie. |
| E1039 | L'Étape de programme `{0}` n'est pas répétable et un événement existe déjà. | Un événement existe déjà pour l'étape de programme de l’inscription. Étant donné que l'étape de programme est configuré pour être non répétable, un autre événement ne peut pas être ajouté pour la même étape de programme.  |
| E1041 | L'unité d'organisation Inscription `{0}` et le Programme `{1}` ne correspondent pas. | La charge utile de l'inscription contient un programme `{1}` qui n'est pas configuré pour être accessible par l'unité d'organisation `{0}`. |
| E1042 | L'Événement `{0}` doit avoir une date de fin. | Si le programme est configuré pour avoir des completeExpiryDays (dates d'expiration complètes), alors la date de fin est obligatoire pour la charge utile d'un événement TERMINÉ. La propriété "completedDate" d'un événement dont le statut est "COMPLETED" (TERMINÉ) doit être non nulle et correspondre à un format de date valide. |
| E1048 | Object: `{0}`, uid: `{1}`, has an invalid uid format. | Un uid valide comporte 11 caractères. Le premier caractère doit être une lettre de l'alphabet (a-z ou A-Z) et les 10 caractères restants peuvent être alphanumériques (a-z ou A-Z ou 0-9). |
| E1049 | Could not find OrganisationUnit: `{0}`, linked to Tracked Entity. | The system could not find an OrganisationUnit with uid `{0}`. |
| E1050 | La date à laquelle l'événement est programmé (ScheduledAt) est manquante. | La propriété "ScheduledAt" dans la charge utile de l'événement est soit manquante, soit son format de date est invalide. |
| E1055 | La combinaison d'options d'attribut (AttributeOptionCombo) par défaut n'est pas autorisée car le programme n'a pas de combinaison de catégories (CategoryCombo) par défaut. | Le programme est configuré pour contenir une combinaison de catégories différente de celle par défaut, mais la requête utilise la combinaison d'options d'attribut par défaut. |
| E1056 | La date d'événement : `{0}`, est antérieure à la date de début : `{1}`, pour l'option d'attribut (AttributeOption) : `{2}`. | L'option de catégorie a une date de début configurée ; la date de l'événement dans la charge utile ne peut pas être antérieure à cette date de début. |
| E1057 | La date d'événement : `{0}`, est postérieure à la date de début : `{1}`, pour l'option d'attribut (AttributeOption) : `{2}`. | L'option de catégorie a une date de fin configurée ; la date de l'événement dans la charge utile ne peut pas être postérieure à cette date de fin.  |
| E1063 | L'instance d'entité suivie `{0}` n'existe pas. | L'erreur se produit lorsque l'on essaie de récupérer une Entité suivie qui n'existe pas avec l'uid `{0}`. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à l'Entité suivie. |
| E1064 | Valeur d'attribut non unique `{0}` pour l'attribut `{1}` | La valeur de l'attribut doit être unique dans le champ d'application défini. L'erreur indique que la valeur de l'attribut existe déjà pour une autre Entité suivie. |
| E1068 | Impossible de trouver l'Instance d'entité suivie : `{0}`, lié à l'inscription. | Le système n'a pas pu trouver l'entité suivie spécifiée dans la charge utile d'inscription. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à cette entité suivie. |
| E1069 | Impossible de trouver le programme : `{0}` lié à l'inscription. | Le système n'a pas pu trouver le programme spécifié dans la charge utile d'inscription. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à cet programme . |
| E1070 | Impossible de trouver l'unité d'organisation : `{0}` lié à l'inscription. | Le système n'a pas pu trouver l'unité d'organisation spécifiée dans la charge utile d'inscription. |
| E1074 | FeatureType (Type de fonctionnalité) est manquant. | |
| E1075 | L'attribut : `{0}`, n'a pas d'uid. | |
| E1076 | `{0}` `{1}` est obligatoire et ne peut pas être nul | |
| E1077 | La valeur du texte de l'attribut : `{0}`, dépasse la longueur maximale autorisée : `{0}`. | |
| E1080 | L'Inscription `{0}` existe déjà. | Cette erreur se produit lorsque l'on essaie de créer une nouvelle inscription avec un uid déjà existant. Veillez à utiliser un nouvel uid pour une nouvelle inscription. |
| E1081 | L'Inscription `{0}` n'existe pas. | L'erreur se produit lorsque l'on essaie de récupérer une Inscription qui n'existe pas avec l'uid `{0}`. Cela peut également signifier que l'utilisateur n'a pas d'accès en lecture à cette Inscription. |
| E1082 | L'Événement : `{0}`, est déjà supprimé et ne peut pas être modifié. | Si l’événement est supprimé mais pas définitivement (soft delete), aucune modification n’est autorisée sur cet événement. |
| E1083 | L'Utilisateur : `{0}`, n'est pas autorisé à modifier les événements terminés. | Seul un super utilisateur ou un utilisateur disposant de l'autorité "F_UNCOMPLETE_EVENT" peut modifier les événements terminés. Les événements terminés sont les événements dont le statut est "TERMINÉ". |
| E1084 | La référence de la ressource de fichier : `{0}`, est introuvable. | |
| E1085 | La valeur de l'Attribut : `{0}`, ne correspond pas au type de valeur : `{1}`. | Incompatibilité entre le type de valeur d'un attribut et la valeur d'attribut fournie. |
| E1089 | L'Événement : `{0}`, fait référence à une Étape de programme `{1}` qui n'appartient pas au Programme `{2}`. | L’uid de l'Étape de programme et l’uid de Programme présent dans la charge utile de l’Événement sont incompatibles. |
| E1090 | L'attribut : `{0}` est obligatoire dans le type d'entité suivie `{1}` mais il n'est pas déclaré dans l'entité suivie `{2}`. | Des valeurs manquent dans la charge utile pour les attributs de type d'entité suivie obligatoires. |
| E1091 | L'utilisateur : `{0}` n'a pas d'accès en écriture de données sur le Programme : `{1}`. | La configuration du partage du Programme est telle que l'utilisateur n'a pas d'accès en écriture pour ce programme. |
| E1095 | L'utilisateur : `{0}` n'a pas d'accès en écriture de données sur l'Étape de programme : `{1}`. | La configuration du partage de l'Étape de programme est telle que l'utilisateur n'a pas d'accès en écriture pour cette Étape de programme.  |
| E1096 | L'utilisateur : `{0}` n'a pas d'accès en lecture de données sur le Programme : `{1}`. | La configuration du partage du Programme est telle que l'utilisateur n'a pas d'accès en lecture pour ce programme. |
| E1099 | L'utilisateur : `{0}` n'a pas d'accès en écriture sur l'Option de catégorie : `{1}`. | La configuration du partage de l'Option de catégorie est telle que l'utilisateur n'a pas d'accès en écriture pour cette Option de catégorie. |
| E1100 | L'Utilisateur : `{0}`, ne dispose pas de l'autorité 'F_TEI_CASCADE_DELETE' pour supprimer l'Instance d'entité suivie : `{1}`. | Certaines Inscriptions n'ont pas été supprimées pour cette Entité suivie. Si l'utilisateur ne dispose pas de l'autorité "F_TEI_CASCADE_DELETE", ces inscriptions devront d'abord être supprimées explicitement avant qu'il puisse supprimer l'Entité suivie. |
| E1102 | L'Utilisateur : `{0}`, n'a pas accès à la combinaison de l'Entité suivie : `{1}` et du Programme : `{2}`. | Cette erreur se produit lorsque l'unité d'organisation de l'utilisateur ne possède pas cette entité suivie, pour ce programme spécifique. L'unité d'organisation propriétaire de la combinaison Entité Suivie-Programme (TrackedEntity-Program) doit se trouver dans le champ de saisie (dans certains cas, dans le champ de recherche) de l'utilisateur. |
| E1103 | L'Utilisateur : `{0}`, ne dispose pas de l'autorité 'F_ENROLLMENT_CASCADE_DELETE' pour supprimer l'Inscription : `{1}`. | Certains Événements n'ont pas été supprimées pour cette Inscription. Si l'utilisateur ne dispose pas de l'autorité 'F_ENROLLMENT_CASCADE_DELETE', ces Événements devront d'abord être supprimées explicitement avant qu'il puisse supprimer l'Inscription. |
| E1104 | L'utilisateur : `{0}` n'a pas d'accès en lecture de données sur le programme : `{1}` et le type d'entité suivie : `{2}`. | La configuration du partage du Type d'entité suivie associé au Programme est telle que l'utilisateur n'a pas d'accès en lecture de données pour ce type d'entité suivie. |
| E1112 | La Valeur d'attribut : `{0}`, est définie sur 'confidentiel' mais le système n'est pas correctement configuré pour crypter les données. | Soit les fichiers JCE sont manquants, soit la propriété de configuration `encryption.password` peut être manquante dans `dhis.conf`. |
| E1113 | L'Inscription : `{0}`, est déjà supprimée et ne peut plus être modifiée. | Si l'inscription est supprimée mais pas définitivement (soft delete), aucune modification n’est autorisée sur cette inscription. |
| E1114 | L'Entité suivie : `{0}`, est déjà supprimée et ne peut donc plus être modifiée. | Si l'entité suivie est supprimée mais pas définitivement (soft delete), aucune modification n’est autorisée sur cette entité suivie. |
| E1115 | Impossible de trouver la combinaison d'options de catégorie : `{0}`. | |
| E1116 | Impossible de trouver la l'Option de catégorie : `{0}`. | Cela peut également signifier que l'utilisateur n'a pas accès à cette option de catégorie.|
| E1117 | La Combinaison d'options de catégorie n'existe pas pour la combinaison de catégories et les options de catégorie fournies : `{0}`. | |
| E1118 | L'utilisateur attribué `{0}` n'est pas un uid valide. | |
| E1119 | Une note de Tracker avec l'uid `{0}` existe déjà. | |
| E1120 | L'Étape de programme `{0}` n'autorise pas l'attribution d'utilisateurs | La charge utile d'événement a attribué un identifiant d'utilisateur (uid) mais l'étape de programme n’est pas configurée pour autoriser l'attribution d’utilisateurs. |
| E1121 | Propriété d'entité suivie obligatoire manquante : `{0}`. | |
| E1122 | La propriété d'inscription requise est manquante : `{0}`. | |
| E1123 | La propriété d'événement requise est manquante : `{0}`. | |
| E1124 | La propriété de relation requise est manquante : `{0}`. | |
| E1125 | La valeur `{0}` n'est pas une option valide pour `{1}` `{2}` dans l'ensemble d'options `{3}` | |
| E1017 | L'attribut : `{0}` n'existe pas. | |
| E1093 | L'utilisateur : `{0}` n'a pas d'accès en écriture sur l'unité d'organisation : `{1}`. | |
| E1094 | Il n'est pas permis de mettre à jour l'Inscription : `{0}`, Programme existant `{1}`. | La charge utile d’inscription pour inscription existante a un uid de programme différent de celui avec lequel l'inscription a été initialement faite. |
| E1110 | Il n'est pas permis de mettre à jour l'Événement : `{0}`, Programme existant `{1}`. | La charge utile d'Événement pour un Événement existant a un uid de programme différent de celui avec lequel il a été initialement créé.  |
| E1111 | Nous avons un attribut généré : `{0}`, mais aucun modèle. | |
| E1043 | La date de fin de l'événement : `{0}`, a expiré ; il n'est donc  plus possible d'apporter des modifications à cet événement. | A user without 'F_EDIT_EXPIRED' autthority cannot update an Event that has passed its expiry days as configured in its Program. |
| E1046 | L'Événement : `{0}`, doit avoir au moins une date (d'événement ou de programmation). | La propriété occuredAt (survenu à) ou selectedAt (sélectionné à) doit être présente dans la charge utile de l’événement. |
| E1047 | La date de l'événement : `{0}`, appartient à une période expirée. Un tel événement ne peut être créé. | Les propriétés occuredAt et scheduledAt de l'événement ont une valeur antérieure à la date de début du type de période (PeriodType).  |
| E1300 | Généré par la règle du programme (`{0}`) - `{1}` | |
| E1302 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` n'est pas valide : `{2}` | |
| E1303 | Généré par la règle de programme (`{0}`) - L'élément de données obligatoire `{1}` n'est pas présent | |
| E1304 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` n'est pas valide | |
| E1305 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` ne fait pas partie de l'étape de programme `{2}` | |
| E1306 | Généré par la règle de programme (`{0}`) - L'attribut obligatoire `{1}` n'est pas présent | |
| E1307 | Généré par la règle de programme (`{0}`) - Impossible d'attribuer une valeur à l'élément de données `{1}`. La valeur fournie doit être vide ou correspondre à la valeur calculée `{2}` | |
| E1308 | Généré par la règle de programme (`{0}`) - L'élément de données `{1}` est remplacé dans l'événement `{2}` | |
| E1309 | Généré par la règle de programme (`{0}`) - Impossible d'attribuer une valeur à l'attribut `{1}`. La valeur fournie doit être vide ou correspondre à la valeur calculée `{2}` | |
| E1310 | Généré par la règle de programme (`{0}`) - L'attribut `{1}` est remplacé dans l'instance d'entité suivie `{2}` | |
| E4000 | La relation : `{0}` ne peut pas être reliée à elle-même | |
| E4001 | L'élément de relation `{0}` n'est pas valide pour la relation `{1}`  : un élément ne peut être relié qu'à une seule entité Tracker. | |
| E4006 | Impossible de trouver le Type de relation : `{0}`. | |
| E4009 | Le Type de relation `{0}` n'est pas valide. | |
| E4010 | La contrainte du type de relation `{0}` nécessite un {1} mais un {2} a été trouvé . | |
| E4011 | Relationship: `{0}` cannot be persisted because {1} {2} referenced by this relationship is not valid. | |
| E4012 | Impossible de trouver `{0}` : `{1}`, liés à la relation. | |
| E4013 | La contrainte du type de relation `{0}` est manquante {1}. | |
| E4014 | La contrainte du type de relation `{0}` nécessite une entité suivie de type `{1}` mais c'est un type `{2} ` qui a été trouvé. | |
| E9999 | N/A | Message d'erreur non défini. |

### Validation { #webapi_nti_validation }

Lors de l'importation de données à l'aide de l'importateur du Tracker, une série de validations est effectuée pour garantir la validité des données. Cette section décrit certains des différents types de validation effectués afin d'avoir une meilleure compréhension si la validation échoue pour votre importation.

#### Propriétés requises { #required-properties }

Chaque objet Tracker possède quelques propriétés qui doivent être présentes lors de l'importation des données. Pour obtenir une liste exhaustive des propriétés requises, consultez la [section sur les objets Tracker] (#webapi_nti_tracker_objects).

Lors de la validation des propriétés requises, nous parlons généralement de références à d'autres données ou métadonnées. Dans ces cas, on note trois critères principaux :

1. La référence est présente et non nulle dans la charge utile.
2. La référence pointe vers le bon type de données et existe dans la base de données
3. L'utilisateur est autorisé à voir la référence

Si la première condition n'est pas remplie, l'importation échouera et un message indiquant une référence manquante sera généré. Cependant, si la référence indique un objet qui n'existe pas ou auquel l'utilisateur n'a pas accès, le message généré indiquera que la référence n'a pas été trouvée.

#### Formats { #formats }

Certaines propriétés des objets Tracker requièrent un format spécifique. Lors de l'importation des données, chacune de ces propriétés est validée au regard du format attendu et renvoie des erreurs en fonction de la propriété dont le format est incorrect. Voici quelques exemples de propriétés validées de cette manière :

- UID (Ceux-ci couvrent toutes les références à d’autres données ou métadonnées dans DHIS2.)
- Dates
- Géométrie (Les coordonnées doivent correspondre au format spécifié par son type)

#### Accès des utilisateurs { #user-access }
Toutes les données importées seront validées en fonction des métadonnées ([Partage](#webapi_nti_metadata_sharing)) et des unités d'organisation ([Champs d'application des unités d'organisation](#webapi_nti_ou_scope)) référencées dans les données. Vous pourrez trouver plus d’informations sur les champs d'application du partage et des unités d’organisation dans les sections suivantes.

Le partage est validé en même temps que la recherche des références dans la base de données. Les métadonnées auxquelles l'utilisateur n'a pas accès seront traitées comme si elles n'existaient pas. L'importation validera toutes les métadonnées référencées dans les données.

Les unités d'organisation, quant à elles, servent un double objectif. D'une part, elles permettent de s'assurer que les données ne soient importées que pour une unité d'organisation figurant dans le "champ de saisie" de l'utilisateur. D'autre part, elles sont également utilisées pour restreindre les programmes disponibles. Cela signifie que si vous essayez d'importer des données pour une unité d'organisation qui n'a pas accès au programme que vous importez, l'importation ne sera pas valide.

Les utilisateurs disposant de l'autorité `TOUS` ne sont pas affectés par les limites des champs d'application de partage et d'unité d'organisation lorsqu'ils importent des données. Cependant, ils ne peuvent pas importer d'inscriptions dans des unités d'organisation qui n'ont pas accès au programme d'inscription.

#### Valeurs d'attribut et de données { #attribute-and-data-values }

Les attributs et les valeurs de données font partie respectivement d'une entité suivie et d'un événement. Cependant, les attributs peuvent être liés à une entité suivie soit par son type (TrackedEntityType), soit par son programme (Program). Les attributs peuvent également être uniques.

La première validation effectuée lors de l'importation consiste à s'assurer que la valeur fournie pour un attribut ou un élément de données est conforme au type de valeur attendu. Par exemple, supposons que vous importiez une valeur pour un élément de données de type numérique. Dans ce cas, la valeur doit être numérique. Toute erreur liée à une non-concordance entre un type et une valeur se traduira par le même code d'erreur, mais avec un message spécifique lié au type de violation.

Les attributs et les valeurs de données obligatoires sont également vérifiés. Actuellement, la suppression des attributs obligatoires n'est pas autorisée. Dans certains cas d'utilisation, les valeurs doivent être envoyées séparément, tandis que dans d'autres, toutes les valeurs doivent être envoyées en une seule fois. Les programmes peuvent être configurés pour valider les attributs obligatoires `ON_COMPLETE` (complet ou `ON_UPDATE_AND_INSERT` pour s'adapter à ces cas d'utilisation.

Les attributs uniques sont validés au moment de l'importation. Cela signifie que tant que la valeur fournie est unique pour l'attribut et ce dans tout le système, l'importation sera acceptée. Cependant, si la valeur unique est utilisée par une autre entité suivie que celle qui est importée, l'importation échouera.

#### Configuration { #configuration }

Les dernières validations dans l'importateur sont des validations basées sur la configuration des métadonnées pertinentes par l'utilisateur. Pour plus d'informations sur chaque configuration, consultez les sections correspondantes. Trouvez ci-après quelques exemples de validations configurables :
- Type de fonctionnalité (pour la géométrie)
- Événements attribuables à l'utilisateur
- Autoriser les dates futures
- Inscrire une fois
- Et plus.

Ces configurations apporteront des modifications supplémentaires à la manière dont la validation est effectuée lors de l'importation.

### Règles de programme { #webapi_nti_program_rules }

Les utilisateurs peuvent configurer des [Règles de programme](#webapi_program_rules), qui vont ajouter un fonctionnement conditionnel aux formulaires du Tracker. En plus d'exécuter ces règles dans les applications du Tracker, l'importateur du Tracker va également procéder à une sélection de ces règles. Puisque l'importateur exécute également ces règles, nous pouvons garantir un niveau de validation supplémentaire.

Toutes les actions de règles de programme ne sont pas prises en charge, car elles ne sont adaptées qu'à une présentation de type « frontend ». Une liste complète des actions de règles de programme prises en charge est présentée ci-dessous.

  |Action de règle de programme|Pris en charge|
  |---|:---:|
  |**DISPLAYTEXT** (afficher le texte)| |
  |**DISPLAYKEYVALUEPAIR** (afficher la paire clé-valeur)| |
  |**HIDEFIELD** (cacher le champ)||
  |**HIDESECTION** (cacher la section)||
  |**ASSIGN** (attribuer )|**X**|
  |**SHOWWARNING** (afficher un avertissement)|**X**|
  |**SHOWERROR** (afficher l'erreur)|**X**|
  |**WARNINGONCOMPLETION** (avertissement à la fin)|**X**|
  |**ERRORONCOMPLETION** (erreur à la fin)|**X**|
  |**CREATEEVENT** (créer un événement)||
  |**SETMANDATORYFIELD** (définir un champ obligatoire)|**X**|
  |**SENDMESSAGE** (envoyer un message)|**X**|
  |**SCHEDULEMESSAGE** (planifier un message)|**X**|

Les règles de programme sont évaluées dans l'importateur de la même manière que dans les applications du Tracker. En résumé, les conditions suivantes sont prises en compte lors de l'application des règles de programme :

* La règle de programme doit être liée aux données importées ; par exemple, une étape de programme ou un élément de données.
* La condition de la règle de programme doit être évaluée comme étant vraie

Les résultats des règles de programme dépendent des actions définies dans ces règles :

* Les actions des règles de programme peuvent aboutir à 2 résultats différents : avertissements ou erreurs.
  * Les erreurs feront échouer la validation, tandis que les avertissements seront rapportés sous forme de message dans le récapitulatif de l'importation.
    * Les actions SHOWWARNING (afficher l'avertissement) et WARNINGONCOMPLETION (avertissement à la fin) ne peuvent générer que des avertissements.
    * Les actions SHOWERROR (afficher l'erreur), ERRORONCOMPLETION (erreur à la fin), et SETMANDATORYFIELD (définir un champ obligatoire) ne peuvent générer que des erreurs.
    * L'action ASSIGN (attribuer) peut générer à la fois des avertissements et des erreurs.
      * Lorsque l'action attribue une valeur à un attribut/élément de données vide, un avertissement est généré.
      * Lorsque l'action attribue une valeur à un attribut/élément de données qui a déjà la même valeur à attribuer, un avertissement est généré.
      * Lorsque l'action attribue une valeur à un attribut/élément de données qui a déjà une valeur et que la valeur à attribuer est différente, une erreur est générée à moins que le paramètre système `RULE_ENGINE_ASSIGN_OVERWRITE` soit défini sur "vrai".

Les règles de programme peuvent également entraîner des actions non voulues, telles que l'envoi et la planification de messages. Pour plus d’informations sur les actions non voulues, veuillez consulter la section suivante.

> **REMARQUE**
>
> Les règles de programme peuvent être ignorées lors de l'importation à l'aide du paramètre `skipProgramRules` (ignorer les règles de programme).

### Actions non voulues { #webapi_nti_side_effects }

Une fois qu'une importation est terminée, des tâches spécifiques peuvent être déclenchées du fait de cette importation. Ces tâches sont ce que nous appelons des « effets secondaires ». Ces tâches exécutent des opérations qui n'affectent pas l'importation elle-même.

Les effets secondaires sont des tâches qui s'exécutent séparément de l'importation, mais qui sont toujours déclenchées par une importation. Étant donné que les effets secondaires sont dissociés de l'importation, ils peuvent échouer même si l'importation réussit. De plus, les effets secondaires ne sont exécutés que lorsque l'importation réussit ; ils ne peuvent donc pas échouer dans l'autre sens.

Voici donc les effets secondaires actuellement pris en charge :

  |Effets secondaires|Pris en charge|Description|
  |---|:---:|---|
  |**Notification de Tracker**|**X**| Les mises à jour peuvent déclencher des notifications. Celles qui déclenchent des notifications sont **inscription**, **mise à jour d'événement**, **achèvement d'événement ou d'inscription**. |
  |**Notification de règle de programme**|**X**| Les règles de programme peuvent déclencher des notifications. Notez que ces notifications font partie des effets des règles de programme qui sont générés via le moteur de règles de DHIS2.|

  > **REMARQUE**
  >
  > Certaines configurations peuvent contrôler l'exécution des effets secondaires. La fonction `skipSideEffects` (ignorer les effets secondaires) peut être activée lors de l'importation pour ignorer complètement les effets secondaires. Par exemple, vous pouvez utiliser ce paramètre lors de l'importation d'un objet pour lequel vous ne voulez pas déclencher de notifications.

### Attribuer un utilisateur à des événements { #webapi_nti_user_event_assignment }

Certains processus bénéficient du fait que des événements soient traités comme des tâches, et pour cette raison, vous pouvez attribuer un utilisateur à un événement.

L'attribution d'un utilisateur à un événement ne modifie pas l'accès ou les autorisations des utilisateurs, mais crée un lien entre l'événement et l'utilisateur.
Lorsqu'un utilisateur est attribué à un événement, vous pouvez lancer des requêtes sur les événements à partir de l'API en utilisant le champ `assignedUser` (utilisateur attribué) en tant que paramètre.

Lorsque vous voulez attribuer un utilisateur à un événement, fournissez simplement l'UID de cet utilisateur dans le champ `assignedUser`. Voir l'exemple suivant :

```json
{
  ...
  "events": [
    {
      "event": "ZwwuwNp6gVd",
      "programStage": "nlXNK4b7LVr",
      "orgUnit": "O6uvpzGd5pu",
      "enrollment": "MNWZ6hnuhSw",
      "assignedUser" : "M0fCOxtkURr"
    }
  ],
  ...
}
```

Dans cet exemple, l'utilisateur avec l'uid `M0fCOxtkURr` sera attribué à l'événement avec l'uid `ZwwuwNp6gVd`. Un seul utilisateur peut être attribué à un événement unique.

Pour utiliser cette fonctionnalité, l'attribution d'utilisateurs doit être activée pour l'étape de programme concernée et l'uid fourni pour l'utilisateur doit renvoyer à un utilisateur existant et valide.

## Exportation Tracker  { #webapi_nti_export }

Tracker export endpoints are a set of services that allow clients to query and retrieve objects stored using the import endpoint.

Besides differences highlighted in **[Changes in the API](#Changes-in-the-API)**, request parameters for these endpoints match older ones.

These endpoints are still being developed and are subject to change. However, 
the `request` and `response` interfaces will most likely not undergo significant changes.

Tracker export endpoints deal with the following Tracker objects:

- **Tracked Entities**
- **Événements**
- **Inscriptions**
- **Relations**

> **NOTE**
>
> - These endpoints currently only support `JSON`, but `CSV` will be supported in the near future.
>
> - These endpoints adopt the new naming convention documented in **[Changes in the API](#Changes-in-the-API)**
>
> - The following functionalities are still missing but available in older endpoints:
>
>     - field filtering

### Paramètres de requête courants { #common-request-parameters }

Le point d'extrémité suivant prend en charge les paramètres normalisés pour la pagination.

- **Entités suivies** `GET /api/tracker/trackedEntities`
- **Évènements** `GET /api/tracker/events`
- **Inscriptions** `GET /api/tracker/enrollments`
- **Relations** `GET /api/tracker/relationships`

#### Paramètres de requête pour la pagination { #request-parameters-for-pagination }

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`page`|`Entier`| Tout entier positif |Numéro de page à renvoyer. La valeur par défaut est 1 si rien n'est fourni.|
|`taille de la page`|`Entier`| Tout entier positif |Taille de la page. La valeur par défaut est 50. |
|`totalPages` (pages totales)|`Booléen`| `vrai`, `faux` |Indique s'il faut renvoyer le nombre total de pages dans la réponse |
|`skipPaging` (ignorer la pagination)|`Booléen`| `vrai`, `faux` |Indique si la pagination doit être ignorée et si toutes les lignes doivent être renvoyées. La valeur par défaut est `faux`, ce qui signifie que par défaut toutes les requêtes sont paginées, sauf si `skipPaging=true` (c'est-à-dire si le paramètre "ignorer la pagination" est définie sur "vrai")|
|`ordre`|`Chaîne`|comma-delimited list of `OrderCriteria` in the form of `propName:sortDirection`.<br><br> Example: `createdAt:desc`<br><br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive|Sort the response based on given `OrderCriteria`|

> **Attention**
>
> Sachez que les performances sont directement liées à la quantité de données qui fait l'objet de la requête. Le renvoi des pages plus volumineuses prendra plus de temps.

#### Paramètres de requête pour le mode de sélection de l'unité d'organisation{ #request-parameters-for-organisational-unit-selection-mode }

Les modes de sélection d'unités d'organisation disponibles sont expliqués dans le tableau suivant.

|Mode|Description|
|---|---|
|`SÉLECTIONNÉ`|  Unités d'organisation définies dans la requête.|
|`SUBORDONNÉES`|  Les unités d'organisation sélectionnées et leurs subordonnées directs, c'est-à-dire les unités d'organisation au niveau inférieur.|
|`DESCENDANTS`| Les unités d'organisation sélectionnées et tous leurs subordonnées, c'est-à-dire toutes les unités d'organisation de niveau inférieur dans la hiérarchie.|
|`ACCESSIBLE`|  Il s'agit des unités d'organisation de visualisation de données associées à l'utilisateur actuel et toutes leurs subordonnées, c'est-à-dire toutes les unités d'organisation qui leur sont inférieures dans la hiérarchie. Les unités d'organisation de saisie de données associées à l'utilisateur actuel seront utilisées si celles dédiées à la visualisation ne sont pas définies.|
|`SAISIE`| Il s'agit des unités d'organisation de saisie de données associées à l'utilisateur actuel et toutes leurs subordonnées, c'est-à-dire toutes les unités d'organisation qui leur sont inférieures dans la hiérarchie.|
|`TOUS`| Il s'agit de toutes les unités d'organisation du système. L'utilisateur doit disposer de l'autorité `TOUS` pour pouvoir l'utiliser.|

#### Request parameter to filter responses { #request-parameter-to-filter-responses } 

All new export endpoints support a `fields` parameter which allows to filter the response based on a simple grammar.

`fields` parameter accepts a comma separated list of field names or patterns and responses are filtered based on it

##### Exemples { #examples }

|Exemple de paramètre|Signification|
|:---|:---|
|`fields=createdAt,uid` (champs=créés à, uid)| only returns `createdAt` and `uid` fields for the requested object|
|`fields=enrollments.uid`| only returns `uid` field for nested `enrollments`|
|`fields=enrollments[uid]`| same as above with a different syntax|
|`fields=enrollments[uid,enrolledAt]`| only returns `uid` and `enrolledAt` fields for nested `enrollments`|
|`fields=**`| don't filter (same behaviour as not passing the `field` parameter at all)|

### Tracked Entities { #tracked-entities } 

Deux points d'extrémité sont dédiés aux entités suivies :

- `GET /api/tracker/trackedEntities`
  - récupère les entités suivies correspondant aux critères donnés
- `GET /api/tracker/trackedEntities/{id}`
  - récupère une entité suivie en fonction de l'identifiant fourni

#### Point d'extrémité de la collection d'entités suivies `GET /api/tracker/trackedEntities` { #tracked-entities-collection-endpoint-get-apitrackertrackedentities }

Le but de ce point d'extrémité est de récupérer les entités suivies correspondant aux critères fournis par le client.

Le point d'extrémité renvoie une liste d'entités suivies qui correspondent aux paramètres de la requête.

##### Syntaxe de la requête { #request-syntax }

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`requête`|`Chaîne`|`{operator}:{filter-value}`|Crée un filtre sur les attributs d'entité suivie. Seule la valeur du filtre est obligatoire. L'opérateur `EQ` est utilisé si l'`opérateur` n'est pas spécifié.|
|`attribut`|`Chaîne`|Comma separated values of attribute `UID` | Pour chaque entité suivie dans la réponse, renvoie uniquement les attributs spécifiés |
|`filtre`|`Chaîne`|Comma separated values of filters|Filter is properties or attributes with operator and value.<br>Example: `filter=updatedAfter:lt:2000-01-01`<br>Multiple filters are allowed. User needs access to attribute to being able to have a filter on it|
|`orgUnit` (unité d'organisation)|`Chaîne`|semicolon-delimited list of organisational unit `UID`|Renvoie uniquement les instances d'entités suivies appartenant aux unités d'organisation fournies|
|Pour plus d'informations sur le `ouMode` (mode d'unité d'organisation) voir [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`Chaîne`|`SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL`|Le mode de sélection des unités d'organisation peut l'être. La valeur par défaut est `SÉLECTIONNÉ`, qui fait uniquement référence aux unités d'organisation sélectionnées.|
|`programme`|`Chaîne`|`UID` de programme| un `UID` de programme dans lequel les instances présentes dans la réponse doivent être inscrites|
|`statut du programme`|`Chaîne`|`ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`|Le statut du programme de l’instance d’entité suivie dans le programme donné|
|`programStage` (étape de programme)|`Chaîne`|`UID`|un `UID` d'étape de programme pour lequel les instances présentes dans la réponse doivent avoir des événements|
|`followUp` (suivi)|`Booléen`|`vrai`, `faux`|Indique si l'instance d'entité suivie est marquée pour le suivi du programme spécifié.|
|`updatedAfter` (mis à jour après)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Date de début de la dernière mise à jour|
|`updatedBefore` (mis à jour avant)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Date de fin de la dernière mise à jour|
|`updatedWithin`|`Durée`|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations) | Renvoie les TEI qui ne dépassent pas la durée spécifiée|
|`enrollmentEnrolledAfter` (Inscription après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de début de l'incident dans le programme donné|
|`enrollmentEnrolledBefore` (Inscription avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de fin de l'incident dans le programme donné|
|`enrollmentOccurredAfter` (Inscription survenue après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de début de l'incident dans le programme donné|
|`enrollmentOccurredBefore` (inscription survenue avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de fin de l'incident dans le programme donné|
|`TrackedEntityType` (Type d'entité suivie)|`Chaîne`|UID du type d'entité suivi|Renvoie uniquement les instances d'entité suivies d'un type donné|
|`trackedEntity` (entité suivie)|`Chaîne`|semicolon-delimited list of tracked entity instance `UID`|Filtrez le résultat de manière à obtenir un ensemble limité d'entités suivies qui utilisent les uids explicites des instances d'entités suivies. Faites-le en utilisant le paramètre `trackedEntity=id1;id2`. Ce paramètre créera, au minimum, la limite externe des résultats, en constituant la liste de toutes les entités suivies à l'aide des uids fournis. Si d'autres paramètres/filtres de ce tableau sont utilisés, ils limiteront davantage les résultats à partir de la limite externe explicite.|
|`assignedUserMode` (mode utilisateur attribué)|`Chaîne`|`CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`|Restricts result to tracked entities with events assigned based on the assigned user selection mode|
|`assignedUser` (utilisateur attribué)|`Chaîne`|Semicolon-delimited list of user UIDs to filter based on events assigned to the users.|Il est possible de filtrer le résultat pour obtenir un ensemble limité d'entités suivies avec des événements attribués aux UID donnés, à l'aide du paramètre `assignedUser=id1;id2`. Ce paramètre ne sera pris en compte que si le "mode utilisateur assigné" est `FOURNI` ou `nul`. L'API va générer une erreur si, par exemple, `assignedUserMode=CURRENT` et `assignedUser=someId`|
|`eventStatus` (statut d'événement)|`Chaîne`|`ACTIVE`&#124;`COMPLETED`&#124;`VISITED`&#124;`SCHEDULE`&#124;`OVERDUE`&#124;`SKIPPED`|Il s'agit du statut de tous les événements présents dans le programme spécifié|
|`eventOccurredAfter` (événement survenu après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de début de l'événement pour le programme donné|
|`eventOccurredBefore` (événement survenu avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|Date de fin de l'événement pour le programme donné|
|`skipMeta`|`Booléen`|`vrai`, `faux`|Indique s’il convient de ne pas inclure les métadonnées dans la réponse.|
|`includeDeleted` (inclure les éléments supprimés)|`Booléen`|`vrai`, `faux`|Indique s’il faut inclure les éléments supprimés mais pas définitivement (soft delete)|
|`includeAllAttributes` (inclure tous les attributs)|`Booléen`|`vrai`, `faux`|Indique s'il faut inclure tous les attributs TEI|
|`attachment`|`Chaîne`| |Il s'agit du nom du fichier en cas d'exportation sous forme de fichier|
|`potentialDuplicate` (doublon potentiel)|`Booléen`|`vrai`, `faux`| Filter the result based on the fact that a tei is a Potential Duplicate. true: return teis flagged as Potential Duplicates. false: return teis NOT flagged as Potential Duplicates. If omitted, we don't check whether a tei is a Potential Duplicate or not. |

La requête n'est pas sensible à la casse. Les règles suivantes s'appliquent aux paramètres de la requête.

- Au moins une unité d'organisation doit être spécifiée avec le paramètre `orgUnit`
  (un ou plusieurs), ou `ouMode=ALL` doit être spécifié.

- Un seul des paramètres `program` et `trackedEntity` peut être
  spécifié (zéro ou un).

- Si `programStatus` est spécifié, alors `program` doit également être
  spécifiés.

- Si `followUp` est spécifié, alors `program` doit également être spécifié.

- Si `enrollmentEnrolledAfter` ou `enrollmentEnrolledBefore` est spécifié, alors
  `program` doit également être spécifié.

- Les éléments du filtre ne peuvent être spécifiés qu'une seule fois.

##### Exemples de requêtes { #example-requests }

Une requête pour toutes les instances associées à une unité d'organisation spécifique peut ressembler à ceci :

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8

To query for instances using one attribute with a filter and one
attribute without a filter, with one organisation unit using the
descendant organisation unit query mode:

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &attribure=AMpUYgxuCaE&orgUnit=DiszpKrYNg8;yMCshbaVExv

A query for instances where attributes are included in the response
and one attribute is used as a filter:

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &filter=AMpUYgxuCaE:LIKE:Road
        &orgUnit=DiszpKrYNg8

A query where multiple operand and filters are specified for a filter
item:

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &program=ur1Edk5Oe2n
        &filter=lw1SqmMlnfh:GT:150
        &filter=lw1SqmMlnfh:LT:190

To query on an attribute using multiple values in an *IN* filter:

    GET /api/tracker/trackedEntities?orgUnit=DiszpKrYNg8
        &filter=dv3nChNSIxy:IN:Scott;Jimmy;Santiago

To constrain the response to instances which are part of a specific
program you can include a program query parameter:

    GET GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS
        &program=ur1Edk5Oe2n

To specify program enrollment dates as part of the query:

    GET /API/tracker/trackedEntities?
        &orgUnit=O6uvpzGd5pu&program=ur1Edk5Oe2n
        &enrollmentEnrolledAfter=2013-01-01
        &enrollmentEnrolledBefore=2013-09-01

To constrain the response to instances of a specific tracked entity you
can include a tracked entity query parameter:

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu
        &ouMode=DESCENDANTS
        &trackedEntity=cyl5vuJ5ETQ

By default the instances are returned in pages of size 50, to change
this you can use the page and pageSize query parameters:

    GET /api/tracker/trackedEntities?filter=zHXD5Ve1Efw:EQ:A
        &orgUnit=O6uvpzGd5pu
        &ouMode=DESCENDANTS
        &page=2&pageSize=3

You can use a range of operators for the filtering:

|Opérateur|  Description|
|---|---|
|`EQ`|  Egale à|
|`GT`|  Supérieure à|
|`GE`|  Supérieure ou égal à|
|`LT`|  Inférieur à|
|`LE`|  inférieur ou égal à|
|`NE`|  Pas égal à|
|`LIKE`|  Like (free text match)|
|`IN`|  Equal to one of the multiple values separated by ";"|

##### Format de réponse { #response-format }

La réponse `JSON` peut ressembler à ceci :

Responses can be filtered on desired fields, see [Request parameter to filter responses](#Request-parameter-to-filter-responses)

```json
{
  "instances": [
    {
      "trackedEntity": "IzHblRD2sDH",
      "trackedEntityType": "nEenWmSyUEp",
      "createdAt": "2014-03-26T15:40:36.669",
      "createdAtClient": "2014-03-26T15:40:36.669",
      "updatedAt": "2014-03-28T12:28:17.544",
      "orgUnit": "g8upMTyEZGZ",
      "inactive": false,
      "deleted": false,
      "relationships": [],
      "attributes": [
        {
          "attribute": "VqEFza8wbwA",
          "code": "MMD_PER_ADR1",
          "displayName": "Address",
          "createdAt": "2016-01-12T00:00:00.000",
          "updatedAt": "2016-01-12T00:00:00.000",
          "valueType": "TEXT",
          "value": "1061 Marconi St"
        },
        {
          "attribute": "RG7uGl4w5Jq",
          "code": "Longitude",
          "displayName": "Longitude",
          "createdAt": "2016-01-12T00:00:00.000",
          "updatedAt": "2016-01-12T00:00:00.000",
          "valueType": "TEXT",
          "value": "27.866613"
        },
        ...,
        ...,
      ],
      "enrollments": [],
      "programOwners": []
    }
  ],
  "page": 1,
  "total": 39,
  "pageSize": 1
}
```

#### Tracked Entities single object endpoint `GET /api/tracker/trackedEntities/{uid}`

The purpose of this endpoint is to retrieve one tracked entity given its uid.

##### Syntaxe de la requête { #request-syntax }

`GET /api/tracker/trackedEntities/{uid}?program={programUid}&fields={fields}`

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`uid`|`Chaîne`|`uid`|Return the Tracked Entity Instance with specified `uid`|
|`programme`|`Chaîne`|`uid`| Include program attributes in the response (only the ones user has access to) |
|`champs`|`Chaîne`| **Currently:** <br>`*`&#124;`relationships`&#124;`enrollments`&#124;`events`&#124;`programOwners`<br><br>**Planned:**<br> a `String` specifying which fields to include in the response|Include specified sub-objects in the response| 

##### Exemples de requêtes { #example-requests }

A query for a Tracked Entity Instance:

    GET /api/tracker/trackedEntities/IzHblRD2sDH?program=ur1Edk5Oe2n&fields=*

##### Format de réponse { #response-format }

This endpoint supports returning sub-objects when the `fields` request parameter is passed.

```json
{
    "trackedEntity": "IzHblRD2sDH",
    "trackedEntityType": "nEenWmSyUEp",
    "createdAt": "2014-03-26T15:40:36.669",
    "updatedAt": "2014-03-28T12:28:17.544",
    "orgUnit": "g8upMTyEZGZ",
    "inactive": false,
    "deleted": false,
    "relationships": [],
    "attributes": [
        {
            "attribute": "w75KJ2mc4zz",
            "code": "MMD_PER_NAM",
            "displayName": "First name",
            "createdAt": "2016-01-12T09:10:26.986",
            "updatedAt": "2016-01-12T09:10:35.884",
            "valueType": "TEXT",
            "value": "Wegahta"
        },
        {
            "attribute": "zDhUuAYrxNC",
            "displayName": "Last name",
            "createdAt": "2016-01-12T09:10:26.986",
            "updatedAt": "2016-01-12T09:10:35.884",
            "valueType": "TEXT",
            "value": "Goytiom"
        }
    ],
    "enrollments": [
        {
            "enrollment": "uT5ZysTES7j",
            "createdAt": "2017-03-28T12:28:17.539",
            "createdAtClient": "2016-03-28T12:28:17.539",
            "updatedAt": "2017-03-28T12:28:17.544",
            "trackedEntity": "IzHblRD2sDH",
            "trackedEntityType": "nEenWmSyUEp",
            "program": "ur1Edk5Oe2n",
            "status": "ACTIVE",
            "orgUnit": "g8upMTyEZGZ",
            "orgUnitName": "Njandama MCHP",
            "enrolledAt": "2020-11-10T12:28:17.532",
            "occurredAt": "2020-10-12T12:28:17.532",
            "followUp": false,
            "deleted": false,
            "events": [
                {
                    "event": "ixDYEGrNQeH",
                    "status": "ACTIVE",
                    "program": "ur1Edk5Oe2n",
                    "programStage": "ZkbAXlQUYJG",
                    "enrollment": "uT5ZysTES7j",
                    "enrollmentStatus": "ACTIVE",
                    "trackedEntity": "IzHblRD2sDH",
                    "relationships": [],
                    "scheduledAt": "2019-10-12T12:28:17.532",
                    "followup": false,
                    "deleted": false,
                    "createdAt": "2017-03-28T12:28:17.542",
                    "createdAtClient": "2016-03-28T12:28:17.542",
                    "updatedAt": "2017-03-28T12:28:17.542",
                    "attributeOptionCombo": "HllvX50cXC0",
                    "attributeCategoryOptions": "xYerKDKCefk",
                    "dataValues": [],
                    "notes": []
                }
            ],
            "relationships": [],
            "attributes": [],
            "notes": []
        }
    ],
    "programOwners": [
        {
            "orgUnit": "g8upMTyEZGZ",
            "trackedEntity": "IzHblRD2sDH",
            "program": "ur1Edk5Oe2n"
        }
    ]
}
```

### Events (`GET /api/tracker/events`) { #events-get-apitrackerevents } 

Two endpoints are dedicated to events:

- `GET /api/tracker/events`
    - retrieves events matching given criteria
- `GET /api/tracker/events/{id}`
    - retrieves an event given the provided id

#### Events Collection endpoint `GET /api/tracker/events` { #events-collection-endpoint-get-apitrackerevents } 

Returns a list of events based on the provided filters.

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`programme`|`Chaîne`|`uid`| Identifier of program|
|`programStage` (étape de programme)|`Chaîne`|`uid`| Identifier of program stage|
|`statut du programme`|`enum`| `ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`| Status of event in program | 
|`followUp` (suivi)|`booléen`| `vrai`, `faux` | Whether event is considered for follow up in program. Defaults to `true`|
|`trackedEntityInstance`|`Chaîne`|`uid`| Identifier of tracked entity instance|
|`orgUnit` (unité d'organisation)|`Chaîne`|`uid`| Identifier of organisation unit|
|Pour plus d'informations sur le `ouMode` (mode d'unité d'organisation) voir [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`Chaîne`| `SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`|  Org unit selection mode| 
|`occurredAfter`|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only events newer than this date|
|`occurredBefore`|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only events older than this date|
|`status`|`Chaîne`|`COMPLETED`&#124;`VISITED`&#124;`SCHEDULED`&#124;`OVERDUE`&#124;`SKIPPED` | Status of event|
|`occurredAfter`|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were occurred after this date.|
|`occurredBefore`|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were occurred up until this date.|
|`scheduledAfter`|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were scheduled after this date.|
|`scheduledBefore`|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were scheduled up until this date.|
|`updatedAfter` (mis à jour après)|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Filter for events which were updated after this date. Cannot be used together with `updatedWithin`.|
|`updatedBefore` (mis à jour avant)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Filter for events which were updated up until this date. Cannot be used together with `updatedWithin`.|
|`updatedWithin`|`Durée`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601#Durations)| Include only items which are updated within the given duration.<br><br> The format is [ISO-8601#Duration](https://en.wikipedia.org/wiki/ISO_8601#Durations)|
|`skipMeta`|`Booléen`| `vrai`, `faux` | Exclude the meta data part of response (improves performance)|
|`dataElementIdScheme`|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Data element ID scheme to use for export.|
|`categoryOptionComboIdScheme`|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Category Option Combo ID scheme to use for export|
|`orgUnitIdScheme`|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Organisation Unit ID scheme to use for export|
|`programIdScheme`|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Program ID scheme to use for export|
|`programStageIdScheme`|`Chaîne`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Program Stage ID scheme to use for export|
|`idScheme`|`string`| `UID`&#124;`CODE`&#124;`ATTRIBUTE:{ID}`| Allows to set id scheme for data element, category option combo, orgUnit, program and program stage at once.|
|`ordre`|`Chaîne`|comma-delimited list of `OrderCriteria` in the form of `propName:sortDirection`.<br><br> Example: `createdAt:desc`<br><br>**Note:** `propName` is case sensitive, `sortDirection` is case insensitive|Sort the response based on given `OrderCriteria`|
|`event`|`Chaîne`|comma-delimited list of `uid`| Filter the result down to a limited set of IDs by using event=id1;id2.|
|`skipEventId`|`Booléen`| | Skips event identifiers in the response|
|`attributeCc` (see note)|`Chaîne`| Attribute category combo identifier (must be combined with attributeCos)|
|`attributeCos` (see note)|`Chaîne`| Attribute category option identifiers, separated with ; (must be combined with attributeCc)|
|`includeDeleted` (inclure les éléments supprimés)|`Booléen`| |  When true, soft deleted events will be included in your query result.|
|`assignedUserMode` (mode utilisateur attribué)|`Chaîne`| `CURRENT`&#124;`PROVIDED`&#124;`NONE`&#124;`ANY`| Assigned user selection mode|
|`assignedUser` (utilisateur attribué)|`Chaîne`|comma-delimited list od `uid`| Filter the result down to a limited set of events that are assigned to the given user IDs by using `assignedUser=id1;id2`.<br><br>This parameter will be considered only if assignedUserMode is either `PROVIDED` or `null`.<br><br>The API will error out, if for example, `assignedUserMode=CURRENT` and `assignedUser=someId`|

> **Note**
>
> If the query contains neither `attributeCC` nor `attributeCos`, 
> the server returns events for all attribute option combos where the user has read access.

##### Exemples de requêtes { #example-requests }

The query for all events with children of a particular organisation unit:

    GET /api/tracker/events?orgUnit=YuQRtpLP10I&ouMode=CHILDREN

The query for all events with all descendants of a particular organisation
unit, implying all organisation units in the sub-hierarchy:

    GET /api/tracker/events?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS

Query for all events with a certain program and organisation unit:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc

Query for all events with a certain program and organisation unit,
sorting by due date
ascending:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&order=dueDate

Query for the 10 events with the newest event date in a certain program
and organisation unit - by paging and ordering by due date descending:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &order=eventDate:desc&pageSize=10&page=1

Query for all events with a certain program and organisation unit for a
specific tracked entity instance:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8
      &program=eBAyeGv0exc&trackedEntityInstance=gfVxE3ALA9m

Query for all events with a certain program and organisation unit older
or equal to
2014-02-03:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc&endDate=2014-02-03

Query for all events with a certain program stage, organisation unit and
tracked entity instance in the year 2014:

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=eBAyeGv0exc
      &trackedEntityInstance=gfVxE3ALA9m&occurredAfter=2014-01-01&occurredBefore=2014-12-31

Retrieve events with specified Organisation unit and Program, and use `Attribute:Gq0oWTf2DtN` as
identifier scheme

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN

Retrieve events with specified Organisation unit and Program, and use UID as identifier scheme for
organisation units, Code as identifier scheme for Program stages, and _Attribute:Gq0oWTf2DtN_ as the identifier
scheme for the rest of the metadata with assigned attributes.

    GET /api/tracker/events?orgUnit=DiszpKrYNg8&program=lxAQ7Zs9VYR&idScheme=Attribute:Gq0oWTf2DtN
      &orgUnitIdScheme=UID&programStageIdScheme=Code

##### Format de réponse { #response-format }

La réponse `JSON` peut ressembler à ceci :

Please note that field filtering (`fields=...`) support is planned but not yet implemented.

```json
{
    "instances": [
        {
            "href": "https://play.dhis2.org/dev/api/tracker/events/rgWr86qs0sI",
            "event": "rgWr86qs0sI",
            "status": "ACTIVE",
            "program": "kla3mAPgvCH",
            "programStage": "aNLq9ZYoy9W",
            "orgUnit": "DiszpKrYNg8",
            "orgUnitName": "Ngelehun CHC",
            "relationships": [],
            "occurredAt": "2021-10-12T00:00:00.000",
            "followup": false,
            "deleted": false,
            "createdAt": "2018-10-20T12:09:19.492",
            "updatedAt": "2018-10-20T12:09:19.492",
            "attributeOptionCombo": "amw2rQP6r6M",
            "attributeCategoryOptions": "RkbOhHwiOgW",
            "dataValues": [
                {
                    "createdAt": "2015-10-20T12:09:19.640",
                    "updatedAt": "2015-10-20T12:09:19.640",
                    "storedBy": "system",
                    "providedElsewhere": false,
                    "dataElement": "HyJL2Lt37jN",
                    "value": "12"
                },
              ...
            ],
            "notes": []
        }
    ],
    "page": 1,
    "pageSize": 1
}
```
#### Events single object endpoint `GET /api/tracker/events/{uid}`

The purpose of this endpoint is to retrieve one Event given its uid.

##### Syntaxe de la requête { #request-syntax }

`GET /api/tracker/events/{uid}?fields={fields}`

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`uid`|`Chaîne`|`uid`|Return the Event with specified `uid`|
|`champs`|`Chaîne`| **Not implemented yet**|Include specified properties in the response| 

##### Exemples de requêtes { #example-requests }

A query for an Event:

    GET /api/tracker/events/rgWr86qs0sI

##### Format de réponse { #response-format }

```json
{
  "href": "https://play.dhis2.org/dev/api/tracker/events/rgWr86qs0sI",
  "event": "rgWr86qs0sI",
  "status": "ACTIVE",
  "program": "kla3mAPgvCH",
  "programStage": "aNLq9ZYoy9W",
  "enrollment": "Lo3SHzCnMSm",
  "enrollmentStatus": "ACTIVE",
  "orgUnit": "DiszpKrYNg8",
  "orgUnitName": "Ngelehun CHC",
  "relationships": [],
  "occurredAt": "2021-10-12T00:00:00.000",
  "followup": false,
  "deleted": false,
  "createdAt": "2018-10-20T12:09:19.492",
  "createdAtClient": "2017-10-20T12:09:19.492",
  "updatedAt": "2018-10-20T12:09:19.492",
  "attributeOptionCombo": "amw2rQP6r6M",
  "attributeCategoryOptions": "RkbOhHwiOgW",
  "dataValues": [
    {
      "createdAt": "2015-10-20T12:09:19.640",
      "updatedAt": "2015-10-20T12:09:19.640",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HyJL2Lt37jN",
      "value": "12"
    },
    {
      "createdAt": "2015-10-20T12:09:19.514",
      "updatedAt": "2015-10-20T12:09:19.514",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "b6dOUjAarHD",
      "value": "213"
    },
    {
      "createdAt": "2015-10-20T12:09:19.626",
      "updatedAt": "2015-10-20T12:09:19.626",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "UwCXONyUtGs",
      "value": "3"
    },
    {
      "createdAt": "2015-10-20T12:09:19.542",
      "updatedAt": "2015-10-20T12:09:19.542",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "fqnXmRYo5Cz",
      "value": "123"
    },
    {
      "createdAt": "2015-10-20T12:09:19.614",
      "updatedAt": "2015-10-20T12:09:19.614",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "Qz3kfeKgLgL",
      "value": "23"
    },
    {
      "createdAt": "2015-10-20T12:09:19.528",
      "updatedAt": "2015-10-20T12:09:19.528",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "W7aC8jLASW8",
      "value": "12"
    },
    {
      "createdAt": "2015-10-20T12:09:19.599",
      "updatedAt": "2015-10-20T12:09:19.599",
      "storedBy": "system",
      "providedElsewhere": false,
      "dataElement": "HrJmqlBqTFG",
      "value": "3"
    }
  ],
  "notes": []
}
```

### Enrollments (`GET /api/tracker/enrollments`) { #enrollments-get-apitrackerenrollments } 

Two endpoints are dedicated to enrollments:

- `GET /api/tracker/enrollments`
    - retrieves enrollments matching given criteria
- `GET /api/tracker/enrollments/{id}`
    - retrieves an enrollment given the provided id

#### Enrollment Collection endpoint `GET /api/tracker/enrollments` { #enrollment-collection-endpoint-get-apitrackerenrollments } 

Returns a list of events based on filters.

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`orgUnit` (unité d'organisation)|`Chaîne`|`uid`| Identifier of organisation unit|
|Pour plus d'informations sur le `ouMode` (mode d'unité d'organisation) voir [ouModes](#Request-parameters-for-Organisational-Unit-selection-mode)|`Chaîne`| `SELECTED`&#124;`CHILDREN`&#124;`DESCENDANTS`&#124;`ACCESSIBLE`&#124;`CAPTURE`&#124;`ALL| Org unit selection mode| 
|`programme`|`Chaîne`|`uid`| Identifier of program|
|`statut du programme`|`enum`| `ACTIVE`&#124;`COMPLETED`&#124;`CANCELLED`| Program Status |
|`followUp` (suivi)|`booléen`| `vrai`, `faux` | Follow up status of the instance for the given program. Can be `true`&#124;`false` or omitted.|
|`updatedAfter` (mis à jour après)|`DateTime` (date et heure)|[ISO-8601](https://en.wikipedia.org/wiki/ISO_8601) | Only enrollments updated after this date|
|`updatedWithin`|`Durée`| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only enrollments updated since given duration |
|`enrolledAfter`|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)|  Only enrollments newer than this date|
|`enrolledBefore`|`DateTime` (date et heure)| [ISO-8601](https://en.wikipedia.org/wiki/ISO_8601)| Only enrollments older than this date|
|`TrackedEntityType` (Type d'entité suivie)|`Chaîne`|`uid`| Identifier of tracked entity type|
|`trackedEntity` (entité suivie)|`Chaîne`|`uid`| Identifier of tracked entity instance|
|`enrollment`|`Chaîne`|Comma-delimited list of `uid`| Filter the result down to a limited set of IDs by using enrollment=id1;id2.|
|`includeDeleted` (inclure les éléments supprimés)|`Booléen`| |  When true, soft deleted events will be included in your query result.|

The query is case-insensitive. The following rules apply to the query parameters.

- Au moins une unité d'organisation doit être spécifiée avec le paramètre `orgUnit`
  parameter (one or many), or *ouMode=ALL* must be specified.

- Only one of the *program* and *trackedEntity* parameters can be
  spécifié (zéro ou un).

- If *programStatus* is specified, then *program* must also be
  spécifiés.

- If *followUp* is specified, then *program* must also be specified.

- If *enrolledAfter* or *enrolledBefore* is specified, then *program* must also be specified.

##### Exemples de requêtes { #example-requests }

A query for all enrollments associated with a specific organisation unit
can look like this:

    GET /api/tracker/enrollments?orgUnit=DiszpKrYNg8

To constrain the response to enrollments which are part of a specific
program you can include a program query
parameter:

    GET /api/tracker/enrollments?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS&program=ur1Edk5Oe2n

To specify program enrollment dates as part of the
query:

    GET /api/tracker/enrollments?&orgUnit=O6uvpzGd5pu&program=ur1Edk5Oe2n
      &enrolledAfter=2013-01-01&enrolledBefore=2013-09-01

To constrain the response to enrollments of a specific tracked entity
you can include a tracked entity query
parameter:

    GET /api/tracker/enrollments?orgUnit=O6uvpzGd5pu&ouMode=DESCENDANTS&trackedEntity=cyl5vuJ5ETQ

To constrain the response to enrollments of a specific tracked entity
you can include a tracked entity instance query parameter, in
In this case, we have restricted it to available enrollments viewable for
current
user:

    GET /API/tracker/enrollments?ouMode=ACCESSIBLE&trackedEntity=tphfdyIiVL6

##### Format de réponse { #response-format }

La réponse `JSON` peut ressembler à ceci :

Please note that field filtering (`fields=...`) support is planned but not yet implemented.

```json
{
  "instances": [
    {
      "enrollment": "iKaBMOyq7QQ",
      "createdAt": "2017-03-28T12:28:19.812",
      "createdAtClient": "2016-03-28T12:28:19.812",
      "updatedAt": "2017-03-28T12:28:19.817",
      "trackedEntity": "PpqV8ytvW5i",
      "trackedEntityType": "nEenWmSyUEp",
      "program": "ur1Edk5Oe2n",
      "status": "ACTIVE",
      "orgUnit": "NnQpISrLYWZ",
      "orgUnitName": "Govt. Hosp. Bonthe",
      "enrolledAt": "2020-10-23T12:28:19.805",
      "occurredAt": "2020-10-07T12:28:19.805",
      "followUp": false,
      "deleted": false,
      "events": [],
      "relationships": [],
      "attributes": [],
      "notes": []
    }
  ],
  "page": 1,
  "total": 1,
  "pageSize": 5
}
```

#### Enrollments single object endpoint `GET /api/tracker/enrollments/{uid}`

The purpose of this endpoint is to retrieve one Enrollment given its uid.

##### Syntaxe de la requête { #request-syntax }

`GET /api/tracker/enrollment/{uid}`

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`uid`|`Chaîne`|`uid`|Return the Enrollment with specified `uid`|
|`champs`|`Chaîne`| **Not implemented yet**|Include specified sub-objects in the response| 

##### Exemples de requêtes { #example-requests }

A query for a Enrollment:

    GET /api/tracker/enrollments/iKaBMOyq7QQ

##### Format de réponse { #response-format }

```json
{
  "enrollment": "iKaBMOyq7QQ",
  "createdAt": "2017-03-28T12:28:19.812",
  "createdAtClient": "2016-03-28T12:28:19.812",
  "updatedAt": "2017-03-28T12:28:19.817",
  "trackedEntity": "PpqV8ytvW5i",
  "trackedEntityType": "nEenWmSyUEp",
  "program": "ur1Edk5Oe2n",
  "status": "ACTIVE",
  "orgUnit": "NnQpISrLYWZ",
  "orgUnitName": "Govt. Hosp. Bonthe",
  "enrolledAt": "2020-10-23T12:28:19.805",
  "occurredAt": "2020-10-07T12:28:19.805",
  "followUp": false,
  "deleted": false,
  "events": [],
  "relationships": [],
  "attributes": [],
  "notes": []
}
```

### Relationships (`GET /api/tracker/relationships`) { #relationships-get-apitrackerrelationships } 

Relationships are links between two entities in the Tracker.
These entities can be tracked entity instances, enrollments, and events.

The purpose of this endpoint is to retrieve Relationships between objects.

Unlike other tracked objects endpoints, Relationship only expose one endpoint:

- `GET /api/tracker/relationships?[tei={teiUid}|enrollment={enrollmentUid}|event={eventUid}]&fields=[fields]`

#### Paramètres de requête { #request-parameters }

|Paramètre de requête|Type|Valeurs autorisées|Description|
|---|---|---|---|
|`tei`|`Chaîne`|`uid`| Identifier of a Tracked Entity Instance|
|`enrollment`|`Chaîne`|`uid`| Identifier of an Enrollment |
|`event`|`Chaîne`|`uid`| Identifier of and Event|
|`champs`|`Chaîne`| | **Not implemented yet:** Only includes specified properties in the response| 

The following rules apply to the query parameters.

- only one parameter among `tei`,`enrollment`,`event` can be passed

> **NOTE**
>
> Using tracked entity, Enrollment or Event params, will return any relationship where the tei, enrollment or
> event is part of the relationship (either from or to). As long as user has access, that is.
>

#### Example response { #example-response } 

```json
{
  "instances": [
    {
      "relationship": "SSfIicJKbh5",
      "relationshipName": "Focus to Case",
      "relationshipType": "Mv8R4MPcNcX",
      "createdAt": "2019-08-21T13:29:45.648",
      "updatedAt": "2019-08-21T13:31:42.064",
      "bidirectional": false,
      "from": {
        "trackedEntity": "neR4cmMY22o"
      },
      "to": {
        "trackedEntity": "rEYUGH97Ssd"
      }
    },
    {
      "relationship": "S9kZGYPKk3x",
      "relationshipName": "Focus to Case",
      "relationshipType": "Mv8R4MPcNcX",
      "createdAt": "2019-08-21T13:29:45.630",
      "updatedAt": "2019-08-21T13:31:42.071",
      "bidirectional": false,
      "from": {
        "trackedEntity": "neR4cmMY22o"
      },
      "to": {
        "trackedEntity": "k8TU70vWtnP"
      }
    }
  ],
  "page": 1,
  "pageSize": 2
}
```

## Tracker Access Control { #webapi_nti_access_control }

Tracker has a few different concepts in regards to access control, like sharing, organisation unit scopes, ownership, and access levels. The following sections provide a short introduction to the different topics.

### Metadata Sharing { #webapi_nti_metadata_sharing }


Sharing setting is standard DHIS2 functionality that applies to both Tracker and Aggregate metadata/data as well as dashboards and visualization items. At the core of sharing is the ability to define who can see/do what. In general, there are five possible sharing configurations – no access, metadata read, metadata write, data read, and data write. These access configurations can be granted at user and/or user group level (for more flexibility). With a focus on Tracker, the following metadata and their sharing setting is of particular importance: Data Element, Category Option, Program, Program Stage, Tracked Entity Type, Tracked Entity Attribute as well as Tracker related Dashboards and Dashboard Items.

How sharing setting works is straightforward – the settings are enforced during Tracker data import/export processes. To read value, one needs to have data read access. If a user is expected to modify data, he/she needs to have data write access. Similarly, if a user is expected to modify metadata, it is essential to grant metadata write access.

One critical point with Tracker data is the need to have a holistic approach. For example, a user won’t be able to see the Data Element value by having read access to just the Data Element. The user needs to have data read to access the parent Program Stage and Program where this Data Element belongs. It is the same with the category option combination. In Tracker, the Event is related to AttributeOptionCombo, which is made up of a combination of Category Options. Therefore, for a user to read data of an Event, he/she needs to have data read access to all Category Options and corresponding Categories that constitute the AttributeOptionCombo of the Event in question. If a user lacks access to just one Category Option or Category, then the user has no access to the entire Event.

When it comes to accessing Enrollment data, it is essential to have access to the Tracked Entity first. Access to a Tracked Entity is controlled through sharing setting of Program, Tracked Entity Type, and Tracked Entity Attribute. Once Enrollment is accessed, it is possible to access Event data, again depending on Program Stage and Data element sharing setting.

Another vital point to consider is how to map out access to different Program Stages of a Program. Sometimes we could be in a situation where we need to grant access to a specific stage – for example, “Lab Result” – to a specific group of users (Lab Technicians). In this situation, we can provide data write access to "Lab Result" stage, probably data read to one or more stages just in case we want Lab Technicians to read other medical results or no access if we think it not necessary for the Lab Technicians to see data other than lab related.

In summary, DHIS2 has a fine-grained sharing setting that we can use to implement access control mechanisms both at the data and metadata level. These sharing settings can be applied directly at the user level or user group level. How exactly to apply a sharing setting depends on the use-case at hand.

For more detailed information about data sharing, check out [Data sharing](https://docs.dhis2.org/en/use/user-guides/dhis-core-version-master/configuring-the-system/about-sharing-of-objects.html#data-sharing-for-event-based-programs).

### Organisation Unit Scopes { #webapi_nti_ou_scope }

Organisation units are one of the most fundamental objects in DHIS2. They define a universe under which a user is allowed to record and/or read data. There are three types of organisation units that can be assigned to a user. These are data capture, data view, and tracker search. As the name implies, these organisation units define a scope under which a user is allowed to conduct the respective operations.

However, to further fine-tune the scope, DHIS2 Tracker introduces a concept that we call **OrganisationUnitSelectionMode**. Such a mode is often used at the time exporting tracker objects. For example, given that a user has a particular tracker search scope, does it mean that we have to use this scope every time a user tries to search for a tracker, Enrollment, or Event object? Or is the user interested in limiting the searching just to the selected org unit, or the entire capture org unit scope, and so on. 

Users can do the fine-tuning by passing a specific value of ouMode in their API request:

*api/tracker/trackedEntities?orgUnit=UID&ouMode=specific_organisation_unit_selection_mode*

Currently, there are six selection modes available: *SELECTED, CHILDREN, DESCENDANTS, CAPTURE, ACCESSIBLE, and ALL*.

1. **SELECTED**: as the name implies, all operations intended by the requesting API narrow down to the selected organisation unit.
2. **CHILDREN**: under this mode, the organisation unit scope will be constructed using the selected organisation unit and its immediate children. 
3. **DESCENDANTS**: here, the selected organisation unit and everything underneath it, not just the immediate children, constitute the data operation universe.
4. **CAPTURE**: as the name implies, organisation units assigned as the user's data capture constitute the universe. Note that, of the three organisation units that can be assigned to a user data capture is the mandatory one. If a user does not have data view and tracker search organisation units, the system will fall back to data capture. This way, we are always sure that a user has at least one universe.
5. **ACCESSIBLE**: technically, this is the same scope as the user's tracker search organisation units.
6. **ALL**: the name ALL makes perfect sense if we are dealing with a superuser. For super users, this scope means the entire organisation unit available in the system. However, for non-superusers, ALL boils down to ACCESSIBLE organisation units.

It makes little sense to pass these modes at the time of tracker import operations. Because when writing tracker data, each of the objects needs to have a specific organisation unit attached to them. The system will then ensure if each of the mentioned organisation units falls under the CAPTURE scope. If not, the system will simply reject the write operation.

Note that there is 4 type of organisation unit associations relevant for Tracker objects. A TrackedEntity has an organisation unit, commonly referred to as the Registration Organisation unit. Enrollments have an organisation unit associated with them. Events also have an organisation unit associated with them. There is also an Owner organisation unit for a TrackedEntity-Program combination. 

When fetching Tracker objects, depending on the context, the organisation unit scope is applied to one of the above four organisation unit associations. 

For example, when retrieving TrackedEntities without the context of a program, the organisation unit scope is applied to the registration organisation unit of the TrackedEntity. Whereas, when retrieving TrackedEntities, including specific program data, the organisation unit scope is applied to the Owner organisation unit. 

  * **Explain how they relate to ownership - Link to Program Ownership**

### Tracker Program Ownership { #webapi_nti_ownership }

A new concept called Tracker Ownership is introduced from 2.30. This introduces a new organisation unit association for a TrackedEntity - Program combination.
We call this the Owner (or Owning) Organisation unit of a TrackedEntity in
the context of a Program. The Owner organisation unit is used to decide access privileges when reading and writing tracker data related to a program.
This, along with the Program's [Access Level](#webapi_nti_access_level) configuration, decides the access behavior for Program-related data (Enrollments and Events). 
A user can access a TrackedEntity's Program data if the corresponding Owner OrganisationUnit for that TrackedEntity-Program combination falls under the user's organisation unit scope (Search/Capture). For Programs that are configured with access level  *OPEN* or *AUDITED* , the Owner OrganisationUnit has to be in the user's search scope.
For Programs that are configured with access level  *PROTECTED* or *CLOSED* , the Owner OrganisationUnit has to be in the user's capture scope to be able to access the corresponding program data for the specific tracked entity.

#### Tracker Ownership Override: Break the Glass { #webapi_nti_tracker_ownership_override }

It is possible to temporarily override this ownership privilege for a
program that is configured with an access level of *PROTECTED*. Any user
will be able to temporarily gain access to the Program related data if
the user specifies a reason for accessing the TrackedEntity-Program
data. This act of temporarily gaining access is termed as *breaking the
glass*. Currently, temporary access is granted for 3 hours. DHIS2
audits breaking the glass along with the reason specified by the user.
It is not possible to gain temporary access to a program that has been
configured with an access level of *CLOSED*. To break the glass for a
TrackedEntity-Program combination, the following POST request can be used:

    /API/33/tracker/ownership/override?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&reason=patient+showed+up+for+emergency+care

#### Tracker Ownership Transfer { #webapi_nti_tracker_ownership_transfer }

It is possible to transfer the ownership of a TrackedEntity-Program
from one organisation unit to another. This will be useful in case of patient
referrals or migrations. Only a user who has Ownership access (or temporary access by breaking the glass) can transfer the ownership. To transfer ownership of a TrackedEntity-Program to another organisation unit, the following PUT request can be used:

    /API/33/tracker/ownership/transfer?trackedEntityInstance=DiszpKrYNg8
      &program=eBAyeGv0exc&ou=EJNxP3WreNP


### Access Level { #webapi_nti_access_level }

DHIS2 treats Tracker data with an extra level of protection. In addition to the standard feature of metadata and data protection through sharing settings, Tracker data are shielded with additional access level protection mechanisms.  Currently, there are four access levels that can be configured for a Program: Open, Audited, Protected, and Closed.

These access levels are only triggered when users try to interact with program data, namely Enrollments and Events data. The different Access Level configuration for Program is a degree of openness (or closedness) of program data. Note that all other sharing settings are still respected, and the access level is only an additional layer of access control. Here is a short description of the four access levels that can be configured for a Program. 

1. Open: This access level is the least restricted among the access levels. Data inside an OPEN program can be accessed and modified by users if the Owner organisation unit falls under the user's search scope.  With this access level, accessing and modifying data outside the capture scope is possible without any justification or consequence. 
2.  Audited: This is the same as the Open access level. The difference here is that the system will automatically add an audit log entry on the data being accessed by the specific user.
3.  Protected: This access level is slightly more restricted. Data inside a PROTECTED program can only be accessed by users if the Owner organisation unit falls under the user's capture scope. However, a user who only has the Owner organisation unit in the search scope can gain temporary ownership by [breaking the glass](#webapi_nti_tracker_ownership_override). The user has to provide a justification of why they are accessing the data at hand. The system will then put a log of both the justification and access audit and provide temporary access for 3 hours to the user. Note that when breaking the glass, the Owner Organisation Unit remains unchanged, and only the user who has broken the glass gains temporary access. 
4.  Closed: This is the most restricted access level. Data recorded under programs configured with access level CLOSED will not be accessible if the Owner Organisation Unit does not fall within the user's capture scope. It is also not possible to break the glass or gain temporary ownership in this configuration. Note that it is still possible to transfer the ownership to another organisation unit. Only a user who has access to the data can transfer the ownership of a TrackedEntity-Program combination to another Organisation Unit. If ownership is transferred, the Owner Organisation Unit is updated.



# Adresses électronique { #email } 

## Adresses électronique { #webapi_email } 

The Web API features a resource for sending emails. For emails to be
sent it is required that the SMTP configuration has been properly set up
and that a system notification email address for the DHIS2 instance has
been defined. You can set SMTP settings from the email settings screen
and system notification email address from the general settings screen
in DHIS2.

    /api/33/email

### System notification { #webapi_email_system_notification } 

The *notification* resource lets you send system email notifications
with a given subject and text in JSON or XML. The email will be sent to
the notification email address as defined in the DHIS2 general system
settings:

```json
{
  "subject": "Integrity check summary",
  "text": "All checks ran successfully"
}
```

You can send a system email notification by posting to the notification
resource like this:

```bash
curl -d @email.json "localhost/api/33/email/notification" -X POST
  -H "Content-Type:application/json" -u admin:district
```

### Outbound emails { #outbound-emails } 

You can also send a general email notification by posting to the
notification resource as mentioned below. `F_SEND_EMAIL` or `ALL`
authority has to be in the system to make use of this api. Subject
parameter is optional. "DHIS 2" string will be sent as default subject
if it is not provided in url. Url should be encoded in order to use this
API.

```bash
curl "localhost/api/33/email/notification?recipients=xyz%40abc.com&message=sample%20email&subject=Test%20Email"
  -X POST -u admin:district
```

### Test message { #webapi_email_test_message } 

To test whether the SMTP setup is correct by sending a test email to
yourself you can interact with the *test* resource. To send test emails
it is required that your DHIS2 user account has a valid email address
associated with it. You can send a test email like this:

```bash
curl "localhost/api/33/email/test" -X POST -H "Content-Type:application/json" -u admin:district
```






# Data store { #data-store } 

## Data store { #webapi_data_store } 

Using the *dataStore* resource, developers can store arbitrary data for
their apps. Access to a datastore's key is based on its sharing settings.
By default all keys created are publicly accessible (read and write).
Additionally,  access to a datastore's namespace is limited to the user's
access to the corresponding app, if the app has reserved the namespace.
For example a user with access to the "sampleApp" application will also
be able to use the sampleApp namespace in the datastore. If a namespace
is not reserved, no specific access is required to use it.

    /api/33/dataStore

Note that there are reserved namespaces used by the system that require 
special authority to be able to read or write entries. 
For example the namespace for the android settings app `ANDROID_SETTINGS_APP`
will require `F_METADATA_MANAGE` authority.

### Data store structure { #webapi_data_store_structure } 

Data store entries consist of a namespace, key and value. The
combination of namespace and key is unique. The value data type is JSON.



Table: Data store structure

| Élément | Description | Type de données |
|---|---|---|
| Espace de noms | Namespace for organization of entries. | Chaîne |
| Clé | Key for identification of values. | Chaîne |
| Valeur | Value holding the information for the entry. | JSON |
| Encrypted | Indicates whether the value of the given key should be encrypted | Booléen |

### Get keys and namespaces { #webapi_data_store_get_keys_and_namespaces } 

For a list of all existing namespaces:

    GET /api/33/dataStore

Example curl request for listing:

```bash
curl "play.dhis2.org/demo/api/33/dataStore" -u admin:district
```

Example response:

```json
[
  "foo",
  "bar"
]
```

For a list of all keys in a namespace:

    GET /api/33/dataStore/<namespace>

Example curl request for listing:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -u admin:district
```

Example response:

```json
[
  "key_1",
  "key_2"
]
```

To retrieve a value for an existing key from a namespace:

    GET /api/33/dataStore/<namespace>/<key>

Example curl request for retrieval:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1"-u admin:district
```

Example response:

```json
{
  "foo":"bar"
}
```

To retrieve meta-data for an existing key from a namespace:

    GET /api/33/dataStore/<namespace>/<key>/metaData

Example curl request for retrieval:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1/metaData" -u admin:district
```

Example response:

```json
{
  "id": "dsKeyUid001", 
  "created": "...",
  "user": {...},
  "namespace": "foo",
  "key": "key_1"
}
```

### Create values { #webapi_data_store_create_values } 

To create a new key and value for a namespace:

    POST /api/33/dataStore/<namespace>/<key>

Example curl request for create, assuming a valid JSON payload:

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X POST
  -H "Content-Type: application/json" -d "{\"foo\":\"bar\"}" -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'key_1' created."
}
```

If you require the data you store to be encrypted (for example user
credentials or similar) you can append a query to the url like this:

    GET /api/33/dataStore/<namespace>/<key>?encrypt=true

### Update values { #webapi_data_store_update_values } 

To update a key that exists in a namespace:

    PUT /api/33/dataStore/<namespace>/<key>

Example curl request for update, assuming valid JSON payload:

```bash
curl "https://play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X PUT -d "[1, 2, 3]"
  -H "Content-Type: application/json" -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' updated."
}
```

### Delete keys { #webapi_data_store_delete_keys } 

To delete an existing key from a namespace:

    DELETE /api/33/dataStore/<namespace>/<key>

Example curl request for delete:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo/key_1" -X DELETE -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Key 'key_1' deleted from namespace 'foo'."
}
```

To delete all keys in a namespace:

    DELETE /api/33/dataStore/<namespace>

Example curl request for delete:

```bash
curl "play.dhis2.org/demo/api/33/dataStore/foo" -X DELETE -u admin:district
```

Example response:

```json
{
  "httpStatus": "OK",
  "httpStatusCode": 200,
  "status": "OK",
  "message": "Namespace 'foo' deleted."
}
```

### Sharing datastore keys { #webapi_data_store_sharing } 

Sharing of datastore keys follows the same principle as for other metadata sharing (see
[Sharing](#webapi_sharing)).

To get sharing settings for a specific datastore key:

    GET /api/33/sharing?type=dataStore&id=<uid>

Where the id for the datastore key comes from the `/metaData` endpoint for that key:

    /api/33/dataStore/<namespace>/<key>/metaData

To modify sharing settings for a specific datastore key:

    POST /api/33/sharing?type=dataStore&id=<uid>

with the following request:

```json
{
  "object": {
    "publicAccess": "rw------",
    "externalAccess": false,
    "user": {},
    "userAccesses": [],
    "userGroupAccesses": [
      {
        "id": "hj0nnsVsPLU",
        "access": "rw------"
      },
      {
        "id": "qMjBflJMOfB",
        "access": "r-------"
      }
    ]
  }
}
```

## User data store { #webapi_user_data_store } 

In addition to the *dataStore* which is shared between all users of the
system, a user-based data store is also available. Data stored to the
*userDataStore* is associated with individual users, so that each user
can have different data on the same namespace and key combination. All
calls against the *userDataStore* will be associated with the logged in
user. This means one can only see, change, remove and add values
associated with the currently logged in user.

    /api/33/userDataStore

### User data store structure { #webapi_user_data_store_structure } 

*userDataStore* consists of a user, a namespace, keys and associated
values. The combination of user, namespace and key is unique.



Table: User data store structure

| Élément | Description | Data Type |
|---|---|---|
| Utilisateur | The user this data is associated with | Chaîne |
| Espace de noms | The namespace the key belongs to | Chaîne |
| Clé | The key a value is stored on | Chaîne |
| Valeur | The value stored | JSON |
| Encrypted | Indicates whether the value should be encrypted | Booléen |

### Get namespaces { #webapi_user_data_store_get_namespaces } 

Returns an array of all existing namespaces

    GET /api/33/userDataStore

Example
    request:

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore"
```

```json
[
  "foo",
  "bar"
]
```

### Get keys { #webapi_user_data_store_get_keys } 

Returns an array of all existing keys in a given namespace

    GET /api/userDataStore/<namespace>

Example request:

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
[
  "key_1",
  "key_2"
]
```

### Get values { #webapi_user_data_store_get_values } 

Returns the value for a given namespace and key

    GET /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -H "Content-Type: application/json" -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "some": "value"
}
```

### Create value { #webapi_user_data_store_create_values } 

Adds a new value to a given key in a given namespace.

    POST /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -X POST -H "Content-Type: application/json" -u admin:district -d "['some value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus": "Created",
  "httpStatusCode": 201,
  "status": "OK",
  "message": "Key 'bar' in namespace 'foo' created."
}
```

If you require the value to be encrypted (For example user credentials
and such) you can append a query to the url like this:

    GET /api/33/userDataStore/<namespace>/<key>?encrypt=true

### Update values { #webapi_user_data_store_update_values } 

Updates an existing value

    PUT /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -X PUT -H "Content-Type: application/json" -u admin:district -d "['new value']"
  "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"Created",
  "httpStatusCode":201,
  "status":"OK",
  "message":"Key 'bar' in namespace 'foo' updated."
}
```

### Delete key { #webapi_user_data_store_delete_key } 

Delete a key

    DELETE /api/33/userDataStore/<namespace>/<key>

Example request:

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo/bar"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"Key 'bar' deleted from the namespace 'foo."
}
```

### Delete namespace { #webapi_user_data_store_delete_namespace } 

Delete all keys in the given namespace

    DELETE /api/33/userDataStore/<namespace>

Example request:

```bash
curl -X DELETE -u admin:district "play.dhis2.org/api/33/userDataStore/foo"
```

```json
{
  "httpStatus":"OK",
  "httpStatusCode":200,
  "status":"OK",
  "message":"All keys from namespace 'foo' deleted."
}
```







# Organisation unit profile { #org_unit_profile }

The organisation unit profile resource allows you to define and retrieve an information profile for organisation units in DHIS 2.

```
/api/organisationUnitProfile
```

A single organisation unit profile can be created and applies to all organisation units.

The information part of the organisation unit profile includes:

- Name, short name, description, parent organisation unit, level, opening date, closed date, URL.
- Contact person, address, email, phone number (if exists).
- Location (longitude/latitude).
- Metadata attributes (configurable).
- Organisation unit group sets and groups (configurable).
- Aggregate data for data elements, indicators, reporting rates, program indicators (configurable).

## Create organisation unit profile { #create-organisation-unit-profile } 

To define the organisation unit profile you can use a `POST` request:

```
POST /api/organisationUnitProfile
```

The payload in JSON format looks like this, where `attributes` refers to metadata attributes,  `groupSets` refer to organisation unit group sets and `dataItems` refers to data elements, indicators, data sets and program indicators:

```json
{
  "attributes": [
    "xqWyz9jNCA5",
    "n2xYlNbsfko"
  ],
  "groupSets": [
    "Bpx0589u8y0",
    "J5jldMd8OHv"
  ],
  "dataItems": [
    "WUg3MYWQ7pt",
    "vg6pdjObxsm",
    "DTVRnCGamkV",
    "Uvn6LCg7dVU",
    "eTDtyyaSA7f"
  ]
}
```

The `F_ORG_UNIT_PROFILE_ADD` authority is required to define the profile.

## Get organisation unit profile { #get-organisation-unit-profile } 

To retrieve the organisation unit profile definition you can use a `GET` request:

```
GET /api/organisationUnitProfile
```

The response will be in JSON format.

## Get organisation unit profile data { #get-organisation-unit-profile-data } 

To retrieve the organisation unit profile data you can use a `GET` request:

```
GET /api/organisationUnitProfile/{org-unit-id}/data?period={iso-period}
```

The organisation unit profile data endpoint will combine the profile definition with the associated information/data values. 

* The `org-unit-id` path variable is required and refers to the ID of the organisation unit to provide aggregated data for.
* The `iso-period` query parameter is optional and refers to the ISO period ID for the period to provide aggregated data for the data items. If none is specified, the _this year_ relative period will be used as fallback.

The response will include the following sections:

* `info`: Fixed information about the organisation unit.
* `attributes`: Metadata attributes with corresponding attribute values.
* `groupSets`: Organisation unit group sets with the corresponding organisation unit group which the organisation unit is a member of.
* `dataItems`: Data items with the corresponding aggregated data value.

Note that access control checks are performed and metadata items which are not accessible to the current user will be omitted.

Voici donc un exemple de requête :

```
GET /api/organisationUnitProfile/DiszpKrYNg8/data?period=2021
```

The profile data response payload in JSON format will look like this, where the `id` and `label` fields refer to the metadata item, and the `value` field refers to the associated value:

```json
{
  "info": {
    "id": "DiszpKrYNg8",
    "code": "OU_559",
    "name": "Ngelehun CHC",
    "shortName": "Ngelehun CHC",
    "parentName": "Badjia",
    "level": 4,
    "levelName": "Facility",
    "openingDate": "1970-01-01T00:00:00.000",
    "longitude": -11.4197,
    "latitude": 8.1039
  },
  "attributes": [
    {
      "id": "n2xYlNbsfko",
      "label": "NGO ID",
      "value": "GHE51"
    },
    {
      "id": "xqWyz9jNCA5",
      "label": "TZ code",
      "value": "NGE54"
    }
  ],
  "groupSets": [
    {
      "id": "Bpx0589u8y0",
      "label": "Facility Ownership",
      "value": "Public facilities"
    },
    {
      "id": "J5jldMd8OHv",
      "label": "Facility Type",
      "value": "CHC"
    }
  ],
  "dataItems": [
    {
      "id": "WUg3MYWQ7pt",
      "label": "Total Population",
      "value": 3503
    },
    {
      "id": "DTVRnCGamkV",
      "label": "Total population < 1 year",
      "value": 140
    },
    {
      "id": "vg6pdjObxsm",
      "label": "Population of women of child bearing age (WRA)",
      "value": 716
    },
    {
      "id": "Uvn6LCg7dVU",
      "label": "ANC 1 Coverage",
      "value": 368.2
    },
    {
      "id": "eTDtyyaSA7f",
      "label": "FIC <1y",
      "value": 291.4
    }
  ]
}
```

## Upload image for organisation unit { #upload-image-for-organisation-unit } 

To upload an image for an organisation unit you can use the `fileResources` endpoint.

```
/api/fileResources
```

The `fileResource` endpoint accepts a raw file as the request body. The `JPG`, `JPEG` and `PNG` formats are supported for organisation unit images. The domain for organisation unit images is `ORG_UNIT`.

Please consult *File resources* in the *Metadata* section for details about the `fileResources` endpoint. 

To upload an image you can send a `POST` request with `ORG_UNIT` as domain query parameter together with the image as the request payload. The `Content-Type` header should match the type of file being uploaded.

```
POST /api/fileResources?domain=ORG_UNIT
```

The `id ` property of the `response` > `fileResource` object in the JSON response will contain a reference to the identifier of the file resource.

The organisation unit entity has an `image` property which refers to the file resource image. To set the file resource reference on an organisation unit you can send a `PATCH` request to the organisation unit with a JSON payload:

```
PATCH /api/organisationUnits/{id}
```

```json
{ 
  "image": "{file-resource-id}" 
}
```

Alternatively, you can use a `PUT` request with the full organisation unit payload (fields omitted for brevity):

```
PUT /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-iid}"
  }
}
```

## Get image for organisation unit { #get-image-for-organisation-unit } 

The organisation unit entity has an `image` object which refers to a file resource by identifier. You can get the organisation unit information from the `organisationUnits` endpoint. If set, the JSON format looks like this:

```
GET /api/organisationUnits/{id}
```

```json
{
  "id": "Rp268JB6Ne4",
  "name": "Adonkia CHP",
  "image": {
    "id":  "{file-resource-id}"
  }
}
```

The image file resource identifier can be used to make a request to the `fileResources` endpoint to retrieve the file content:

```
GET /api/fileResources/{id}/data
```

The `Content-Type` header will reflect the type of file being retrieved.



# Applications { #apps } 

## Applications { #webapi_apps } 

The `/api/apps` endpoint can be used for installing, deleting and
listing apps. The app key is based on the app name, but with all
non-alphanumerical characters removed, and spaces replaced with a dash.
*My app!* will return the key *My-app*.

> **Note**
>
> Previous to 2.28, the app key was derived from the name of the ZIP
> archive, excluding the file extension. URLs using the old format
> should still return the correct app in the api.

    /api/33/apps

### Get apps { #webapi_get_apps } 

> **Note**
>
> Previous to 2.28 the app property folderName referred to the actual
> path of the installed app. With the ability to store apps on cloud
> services, folderName's purpose changed, and will now refer to the app
> key.

You can read the keys for apps by listing all apps from the apps
resource and look for the *key* property. To list all installed apps in
JSON:

```bash
curl -u user:pass -H "Accept: application/json" "http://server.com/api/33/apps"
```

You can also simply point your web browser to the resource URL:

    http://server.com/api/33/apps

The apps list can also be filtered by app type and by name, by appending
one or more *filter* parameters to the URL:

    http://server.com/api/33/apps?filter=appType:eq:DASHBOARD_APP&filter=name:ilike:youtube

App names support the *eq* and *ilike* filter operators, while *appType*
supports *eq* only.

### Install an app { #webapi_install_app } 

To install an app, the following command can be issued:

```bash
curl -X POST -u user:pass -F file=@app.zip "http://server.com/api/33/apps"
```

### Delete an app { #webapi_delete_app } 

To delete an app, you can issue the following command:

```bash
curl -X DELETE -u user:pass "http://server.com/api/33/apps/<app-key>"
```

### Reload apps { #webapi_reload_apps } 

To force a reload of currently installed apps, you can issue the
following command. This is useful if you added a file manually directly
to the file system, instead of uploading through the DHIS2 user
interface.

```bash
curl -X PUT -u user:pass "http://server.com/api/33/apps"
```

### Share apps between instances { #webapi_share_apps_between_instances } 

If the DHIS2 instance has been configured to use cloud storage, apps
will now be installed and stored on the cloud service. This will enable
multiple instances share the same versions on installed apps, instead of
installing the same apps on each individual instance.

> **Note**
>
> Previous to 2.28, installed apps would only be stored on the instance's
> local filesystem. Apps installed before 2.28 will still be available on the
> instance it was installed, but it will not be shared with other
> instances, as it's still located on the instances local filesystem.

## App store { #webapi_app_store } 

The Web API exposes the content of the DHIS2 App Store as a JSON
representation which can found at the `/api/appHub` resource.

    /api/33/appHub

### Get apps { #webapi_get_app_store_apps } 

You can retrieve apps with a GET request:

    GET /api/33/appHub

A sample JSON response is described below.

```json
{
  [
    {
      "name": "Tabular Tracker Capture",
      "description": "Tabular Tracker Capture is an app that makes you more effective.",
      "sourceUrl": "https://github.com/dhis2/App-repository",
      "appType": "DASHBOARD_WIDGET",
      "status": "PENDING",
      "id": "NSD06BVoV21",
      "developer": {
        "name": "DHIS",
        "organisation": "Uio",
        "address": "Oslo",
        "email": "dhis@abc.com",
      },
      "versions": [
        {
          "id": "upAPqrVgwK6",
          "version": "1.2",
          "minDhisVersion": "2.17",
          "maxDhisVersion": "2.20",
          "downloadUrl": "https://dhis2.org/download/appstore/tabular-capture-12.zip",
          "demoUrl": "http://play.dhis2.org/demo"
        }
      ],
      "images": [
        {
          "id": "upAPqrVgwK6",
          "logo": "true",
          "imageUrl": "https://dhis2.org/download/appstore/tabular-capture-12.png",
          "description": "added feature snapshot",
          "caption": "dialog",
        }
      ]
    }
  ]
}
```

### Install apps { #webapi_install_app_store_apps } 

You can install apps on your instance of DHIS2 assuming you have the
appropriate permissions. An app is referred to using the `id` property
of the relevant version of the app. An app is installed with a POST
request with the version id to the following resource:

    POST /api/33/appHub/{app-version-id}

