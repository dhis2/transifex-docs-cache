---
revision_date: "2022-05-05"
template: single.html
---

# Installation { #installation }

Le chapitre d'installation donne des informations sur comment installer DHIS2 dans des des contextes variables, incluant serveur central en ligne, application autonome et paquet auto-contenu appellé DHIS2 Live.

## Introduction { #install_introduction }

DHIS2 runs on all platforms for which there exists a Java JDK, which includes most popular operating systems such as Windows, Linux and Mac. DHIS2 runs on the PostgreSQL database system. DHIS2 is packaged as a standard Java Web Archive (WAR-file) and thus runs on any Servlet containers such as Tomcat and Jetty.

L'equipe de DHIS2 recommande le systèmes d'exploitation Ubuntu 18.04 LTS, le système de base de donnné PostgreSQL et le conteneur Tomcay Servlet comme environnement favoris pour l'installation de serveur.

This chapter provides a guide for setting up the above technology stack. It should however be read as a guide for getting up and running and not as an exhaustive documentation for the mentioned environment. We refer to the official Ubuntu, PostgreSQL and Tomcat documentation for in-depth reading.

The `dhis2-tools` Ubuntu package automates many of the tasks described in the guide below and is recommended for most users, especially those who are not familiar with the command line or administration of servers. It is described in detail in a separate chapter in this guide.

## Server specifications { #install_server_specifications }

DHIS2 is a database intensive application and requires that your server has an appropriate amount of RAM, number of CPU cores and a fast disk. These recommendations should be considered as rules-of-thumb and not exact measures. DHIS2 scales linearly on the amount of RAM and number of CPU cores so the more you can afford, the better the application will perform.

-   _RAM:_ At least 2 GB for a small instance, 12 GB for a medium instance, 64 GB or more for a large instance.
-   _CPU cores:_ 4 CPU cores for a small instance, 8 CPU cores or more for a medium or large instance.
-   _Disk:_ SSD is recommeded as storage device. Minimum read speed is 150 Mb/s, 200 Mb/s is good, 350 Mb/s or better is ideal. In terms of disk space, at least 100 GB is recommended, but will depend entirely on the amount of data which is contained in the data value tables. Analytics tables require a significant amount of disk space. Plan ahead and ensure that your server can be upgraded with more disk space as needed.

## Software requirements { #install_software_requirements }

Les versions ultérieures de DHIS2 nécessitent les versions logicielles suivantes pour fonctionner.

-   Un système d'exploitation pour lequel un Java JDK ou JRE version 8 ou 11 existe. Linux est recommandé.
-   Java JDK. OpenJDK is recommended.
    -   For DHIS 2 version 2.35 version and later, JDK 11 is recommended and JDK 8 or later is required.
    -   Pour les versions DHIS 2 antérieures à 2.35, JDK 8 est requis.
-   PostgreSQL database version 9.6 or later. A later PostgreSQL version such as version 13 is recommended.
-   Extension de base de données PostGIS version 2.2 ou plus.
-   Tomcat servlet container version 8.5.50 or later, or other Servlet API 3.1 compliant servlet containers.
-   Cluster setup only (optional): Redis data store version 4 or later.

## Server setup { #install_server_setup }

This section describes how to set up a server instance of DHIS2 on Ubuntu 18.04 64 bit with PostgreSQL as database system and Tomcat as Servlet container. This guide is not meant to be a step-by-step guide per se, but rather to serve as a reference to how DHIS2 can be deployed on a server. There are many possible deployment strategies, which will differ depending on the operating system and database you are using, and other factors. The term _invoke_ refers to executing a given command in a terminal.

For this guide we assume that 8 Gb RAM is allocated for PostgreSQL and 8 GB RAM is allocated for Tomcat/JVM, and that a 64-bit operating system is used. _If you are running a different configuration please adjust the suggested values accordingly\!_ We recommend that the available memory is split roughly equally between the database and the JVM. Remember to leave some of the physical memory to the operating system for it to perform its tasks, for instance around 2 GB. The steps marked as _optional_, like the step for performance tuning, can be done at a later stage.

### Creating a user to run DHIS2 { #install_creating_user }

Vous devriez créer un utilisateur dédié pour lancer DHIS2

> **Important**
>
> Vous ne devez pas exécuter le serveur DHIS2 en tant qu'utilisateur privilégié tel que super-utilisateur.

Créez un nouvel utilisateur appelé "dhis" en appelant :

```sh
sudo useradd -d /home/dhis -m dhis -s /bin/false
```

Ensuite, pour définir le mot de passe de votre compte, appelez :

```sh
sudo passwd dhis
```

Créez un mot de passe sécurisé comportant au moins 15 caractères aléatoires.

### Creating the configuration directory { #install_creating_config_directory }

Start by creating a suitable directory for the DHIS2 configuration files. This directory will also be used for apps, files and log files. An example directory could be:

```sh
mkdir /home/dhis/config
chown dhis:dhis /home/dhis/config
```

DHIS2 will look for an environment variable called _DHIS2_HOME_ to locate the DHIS2 configuration directory. This directory will be referred to as _DHIS2_HOME_ in this installation guide. We will define the environment variable in a later step in the installation process.

### Setting server time zone and locale { #install_setting_server_tz }

It may be necessary to reconfigure the time zone of the server to match the time zone of the location which the DHIS2 server will be covering. If you are using a virtual private server, the default time zone may not correspond to the time zone of your DHIS2 location. You can easily reconfigure the time zone by invoking the below and following the instructions.

```sh
sudo dpkg-reconfigure tzdata
```

PostgreSQL is sensitive to locales so you might have to install your locale first. To check existing locales and install new ones (e.g. Norwegian):

```sh
locale -a
sudo locale-gen nb_NO.UTF-8
```

### PostgreSQL installation { #install_postgresql_installation }

Installez PostgreSQL en appelant :

```sh
sudo apt-get install postgresql-12 postgresql-12-postgis-3
```

Create a non-privileged user called _dhis_ by invoking:

```sh
sudo -u postgres createuser -SDRP dhis
```

Entrez un mot de passe sécurisé à l'invite. Créez une base de données en appelant :

```sh
sudo -u postgres createdb -O dhis dhis2
```

Return to your session by invoking `exit` You now have a PostgreSQL user called _dhis_ and a database called _dhis2_.

The _PostGIS_ extension is needed for several GIS/mapping features to work. DHIS 2 will attempt to install the PostGIS extension during startup. If the DHIS 2 database user does not have permission to create extensions you can create it from the console using the _postgres_ user with the following commands:

```sh
sudo -u postgres psql -c "create extension postgis;" dhis2
```

Exit the console and return to your previous user with _\\q_ followed by _exit_.

### PostgreSQL performance tuning { #install_postgresql_performance_tuning }

Tuning PostgreSQL is necessary to achieve a high-performing system but is optional in terms of getting DHIS2 to run. PostgreSQL is configured and tuned through the _postgresql.conf_ file which can be edited like this:

```sh
sudo nano /etc/postgresql/12/main/postgresql.conf
```

et modifez la propriété suivante:

```properties
max_connections = 200
```

Détermine le nombre maximum de connexions autorisées par PostgreSQL.

```properties
shared_buffers = 3200MB
```

Determines how much memory should be allocated exclusively for PostgreSQL caching. This setting controls the size of the kernel shared memory which should be reserved for PostgreSQL. Should be set to around 40% of total memory dedicated for PostgreSQL.

```properties
work_mem = 20MB
```

Determines the amount of memory used for internal sort and hash operations. This setting is per connection, per query so a lot of memory may be consumed if raising this too high. Setting this value correctly is essential for DHIS2 aggregation performance.

```properties
maintenance_work_mem = 512MB
```

Determines the amount of memory PostgreSQL can use for maintenance operations such as creating indexes, running vacuum, adding foreign keys. Increasing this value might improve performance of index creation during the analytics generation processes.

```properties
effective_cache_size = 8000MB
```

An estimate of how much memory is available for disk caching by the operating system (not an allocation) and isdb.no used by PostgreSQL to determine whether a query plan will fit into memory or not. Setting it to a higher value than what is really available will result in poor performance. This value should be inclusive of the shared_buffers setting. PostgreSQL has two layers of caching: The first layer uses the kernel shared memory and is controlled by the shared_buffers setting. PostgreSQL delegates the second layer to the operating system disk cache and the size of available memory can be given with the effective_cache_size setting.

```properties
checkpoint_completion_target = 0.8
```

Sets the memory used for buffering during the WAL write process. Increasing this value might improve throughput in write-heavy systems.

```properties
synchronous_commit = off
```

Specifies whether transaction commits will wait for WAL records to be written to the disk before returning to the client or not. Setting this to off will improve performance considerably. It also implies that there is a slight delay between the transaction is reported successful to the client and it actually being safe, but the database state cannot be corrupted and this is a good alternative for performance-intensive and write-heavy systems like DHIS2.

```properties
wal_writer_delay = 10000ms
```

Specifies the delay between WAL write operations. Setting this to a high value will improve performance on write-heavy systems since potentially many write operations can be executed within a single flush to disk.

```properties
random_page_cost = 1.1
```

_SSD only._ Sets the query planner's estimate of the cost of a non-sequentially-fetched disk page. A low value will cause the system to prefer index scans over sequential scans. A low value makes sense for databases running on SSDs or being heavily cached in memory. The default value is 4.0 which is reasonable for traditional disks.

```properties
max_locks_per_transaction = 96
```

Spécifie le nombre moyen de verrous d'objets alloués pour chaque transaction. Cette valeur est principalement définie pour permettre la réalisation des mises à niveau de routine qui touchent un grand nombre de tableaux.

Redémarrez PostgreSQL en appelant la commande suivante :

```sh
sudo /etc/init.d/postgresql restart
```

### Java installation { #install_java_installation }

Le JDK Java recommandé pour DHIS 2 est OpenJDK 11 (pour les version 2.35 et plus). Vous pouvez l'installer avec la commande suivante :

```
sudo apt-get install openjdk-11-jdk
```

Si vous préférez OpenJDK 8 (pour les versions antérieures à la 2.35), vous pouvez l'installer avec cette commande :

```
sudo apt-get install openjdk-8-jdk
```

Vérifiez que votre installation est correcte en appelant :

```
java -version
```

### DHIS2 configuration { #install_database_configuration }

The database connection information is provided to DHIS2 through a configuration file called `dhis.conf`. Create this file and save it in the `DHIS2\_HOME` directory. As an example this location could be:

```sh
/home/dhis/config/dhis.conf
```

A configuration file for PostgreSQL corresponding to the above setup has these properties:

```properties
# ----------------------------------------------------------------------
# Database connection
# ----------------------------------------------------------------------

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password
connection.password = xxxx

# ----------------------------------------------------------------------
# Server
# ----------------------------------------------------------------------

# Enable secure settings if deployed on HTTPS, default 'off', can be 'on'
# server.https = on

# Server base URL
# server.base.url = https://server.com/
```

Il est fortement recommandé d'activer le paramètre `server.https` et de déployer DHIS 2 avec un protocole HTTPS crypté. Ce paramètre activera par exemple des cookies sécurisés. Le déploiement HTTPS est requis lorsque ce paramètre est activé.

Le paramètre `server.base.url` fait référence à l'URL à laquelle les utilisateurs finaux accèdent au système sur le réseau.

Note that the configuration file supports environment variables. This means that you can set certain properties as environment variables and have them resolved, e.g. like this where `DB\_PASSWD` is the name of the environment variable:

```properties
connection.password = ${DB_PASSWD}
```

Note that this file contains the password for your DHIS2 database in clear text so it needs to be protected from unauthorized access. To do this, invoke the following command which ensures only the _dhis_ user is allowed to read it:

```sh
chmod 600 dhis.conf
```

### Tomcat and DHIS2 installation { #install_tomcat_dhis2_installation }

To install the Tomcat servlet container we will utilize the Tomcat user package by invoking:

```sh
sudo apt-get install tomcat8-user
```

This package lets us easily create a new Tomcat instance. The instance will be created in the current directory. An appropriate location is the home directory of the `dhis` user:

```sh
cd /home/dhis/
sudo tomcat8-instance-create tomcat-dhis
sudo chown -R dhis:dhis tomcat-dhis/
```

This will create an instance in a directory called `tomcat-dhis`. Note that the `tomcat8-user` package allows for creating any number of DHIS2 instances if that is desired.

Modifiez ensuite le fichier `tomcat-dhis/bin/setenv.sh` et ajoutez les lignes ci-dessous.

-   `JAVA_HOME` définit l'emplacement de l'installation du JDK.
-   `JAVA_OPTS` transmet les paramètres à la JVM.
    -   `-Xms` définit l'allocation initiale de mémoire à l'espace de mémoire du tas Java.
    -   `-Xmx` définit l'allocation maximale de mémoire à l'espace mémoire du tas Java. Cela doit refléter la quantité de mémoire que vous voulez allouer à l'application logicielle DHIS 2 sur votre serveur.
-   `DHIS2_HOME` définit l'emplacement du fichier de configuration `dhis.conf` pour DHIS 2.

Check that the path the Java binaries are correct as they might vary from system to system, e.g. on AMD systems you might see `/java-11-openjdk-amd64`. Note that you should adjust these values to your environment.

```sh
JAVA_HOME='/usr/lib/jvm/java-11-openjdk-amd64/'
JAVA_OPTS='-Xms4000m -Xmx7000m'
DHIS2_HOME='/home/dhis/config'
```

The Tomcat configuration file is located in `tomcat-dhis/conf/server.xml`. The element which defines the connection to DHIS is the _Connector_ element with port 8080. You can change the port number in the Connector element to a desired port if necessary. The `relaxedQueryChars` attribute is necessary to allow certain characters in URLs used by the DHIS2 front-end.

```xml
<Connector port="8080" protocol="HTTP/1.1"
  connectionTimeout="20000"
  redirectPort="8443"
  relaxedQueryChars="[]" />
```

The next step is to download the DHIS2 WAR file and place it into the _webapps_ directory of Tomcat. You can download DHIS2 WAR files from the following location:

```sh
https://releases.dhis2.org/
```

Move the WAR file into the Tomcat `webapps` directory. We want to call the WAR file `ROOT.war` in order to make it available at `localhost` directly without a context path:

```sh
mv dhis.war tomcat-dhis/webapps/ROOT.war
```

DHIS2 should never be run as a privileged user. After you have modified the `setenv.sh file`, modify the startup script to check and verify that the script has not been invoked as root.

```sh
#!/bin/sh
set -e

if [ "$(id -u)" -eq "0" ]; then
  echo "This script must NOT be run as root" 1>&2
  exit 1
fi

export CATALINA_BASE="/home/dhis/tomcat-dhis"
/usr/share/tomcat8/bin/startup.sh
echo "Tomcat started"
```

### Running DHIS2 { #install_running_dhis2 }

DHIS2 peut désormais être lancé en appelant :

    sudo -u dhis tomcat-dhis/bin/startup.sh

> **Important**
>
> The DHIS2 server should never be run as root or other privileged user.

DHIS2 peut être arrêté en appelant :

    sudo -u dhis tomcat-dhis/bin/shutdown.sh

To monitor the behavior of Tomcat the log is the primary source of information. The log can be viewed with the following command:

    tail -f tomcat-dhis/logs/catalina.out

Assuming that the WAR file is called ROOT.war, you can now access your DHIS2 instance at the following URL:

    http://localhost:8080

## File store configuration { #install_file_store_configuration }

DHIS2 is capable of capturing and storing files. By default, files will be stored on the local file system of the server which runs DHIS2 in a _files_ directory under the _DHIS2_HOME_ external directory location.

You can also configure DHIS2 to store files on cloud-based storage providers. AWS S3 is the only supported provider currently. To enable cloud-based storage you must define the following additional properties in your _dhis.conf_ file:

```propriétés
# Fournisseur d'entrepôts de fichiers. Actuellement, 'filesystem' et 'aws-s3' sont pris en charge.
filestore.provider = 'aws-s3'

# Répertoire dans le répertoire externe sur le système de fichiers local et le compartiment sur AWS S3
filestore.container = fichiers

# La configuration suivante s'applique uniquement au stockage sur cloud (AWS S3)

# Emplacement du centre de données. Facultatif mais recommandé pour des raisons de performances.
filestore.emplacement = eu-west-1

# Nom d'utilisateur / Clé d'accès sur AWS S3
filestore.identité = xxxx

# Mot de passe / Clé secrète sur AWS S3 (sensible)
filestore.secret = xxxx
```

This configuration is an example reflecting the defaults and should be changed to fit your needs. In other words, you can omit it entirely if you plan to use the default values. If you want to use an external provider the last block of properties needs to be defined, as well as the _provider_ property is set to a supported provider (currently only AWS S3).

> **Note**
>
> If you’ve configured cloud storage in dhis.conf, all files you upload or the files the system generates will use cloud storage.

For a production system the initial setup of the file store should be carefully considered as moving files across storage providers while keeping the integrity of the database references could be complex. Keep in mind that the contents of the file store might contain both sensitive and integral information and protecting access to the folder as well as making sure a backup plan is in place is recommended on a production implementation.

> **Note**
>
> AWS S3 is the only supported provider but more providers are likely to be added in the future, such as Google Cloud Store and Azure Blob Storage. Let us know if you have a use case for additional providers.

## Google service account configuration { #install_google_service_account_configuration }

DHIS2 can connect to various Google service APIs. For instance, the DHIS2 GIS component can utilize the Google Earth Engine API to load map layers. In order to provide API access tokens you must set up a Google service account and create a private key:

-   Create a Google service account. Please consult the [Google identify platform](https://developers.google.com/identity/protocols/OAuth2ServiceAccount#overview) documentation.

-   Visit the [Google cloud console](https://console.cloud.google.com) and go to API Manager \> Credentials \> Create credentials \> Service account key. Select your service account and JSON as key type and click Create.

-   Rename the JSON key to _dhis-google-auth.json_.

After downloading the key file, put the _dhis-google-auth.json_ file in the DHIS2_HOME directory (the same location as the _dhis.conf_ file). As an example this location could be:

    /home/dhis/config/dhis-google-auth.json

## Configuration d'OpenID Connect (OIDC) { #install_oidc_configuration }

DHIS2 prend en charge la couche d'identité de l'OpenID Connect (OIDC) pour une identification unique (IU). L'OIDC est un protocole d'authentification standard qui permet aux utilisateurs de se connecter à un fournisseur d'identité (IdP) comme Google. Une fois que les utilisateurs parviennent à se connecter à leur IdP, ils sont donc automatiquement connectés à DHIS2.

Cette section présente des informations générales sur l'utilisation du DHIS2 avec l'OIDC, ainsi que les options de configuration de l'IdP et du DHIS2. Le déroulement de l'authentification se présente comme suit.

1. Un utilisateur tente de se connecter à DHIS2 à partir d'un ordinateur client.

2. Le DHIS2 redirige la requête d'authentification vers la passerelle IdP.

3. Le système demande à l'utilisateur de fournir des informations d'identification et l'authentifie auprès de l'IdP. L'IdP répond par une URL permettant de rediriger l'utilisateur vers le DHIS2. L'URL de redirection comprend un code d'autorisation spécifique destiné à l'utilisateur.

4. Le client est redirigé vers le DHIS2 et présente le code d'autorisation.

5. Le DHIS2 présente le code d'autorisation du client à l'IdP en même temps que ses propres références client.

6. The IdP returns an access token and an ID token to DHIS2. DHIS2 performs a validation of the IdP token (JWT). The ID token is a set of attribute key pairs for the user. The key pairs are called claims.

7. DHIS2 identifies the user from the IdP claims and completes the authentication request from Step 1. DHIS2 searches for a user that matches the `email` claim from the IdP. DHIS2 can be configured to use different claims for this process.

8. Le DHIS2 autorise l'utilisateur.

### Exigences requises pour l'OIDC { #requirements-for-oidc }

#### Compte IdP { #idp-account }

Vous devez avoir accès à un fournisseur d'identité (IdP) pris en charge par le DHIS2.

Voici donc les IdP actuellement pris en charge :

-   Google
-   Azure AD
-   WSO2
-   Generic provider

#### Compte de l'utilisateur local { #local-user-account }

Vous devez créer expressément des utilisateurs dans l'instance DHIS2. L'importation à partir d'un répertoire externe tel qu'Active Directory n'est actuellement pas prise en charge. La gestion des utilisateurs avec un magasin d'identité externe n'est pas prise en charge par l'OIDC.

#### Requêtes d'IdP et cartographie des utilisateurs { #idp-claims-and-mapping-of-users }

Pour se connecter au DHIS2, l'utilisateur doit être enregistré dans l'IdP et ensuite connecté à un compte d'utilisateur dans le DHIS2. L'OIDC utilise une méthode basée sur les requêtes pour partager les attributs des comptes utilisateurs avec d'autres applications. Les requêtes comportent des attributs de compte d'utilisateur tels que l'adresse électronique, le numéro de téléphone, le nom, etc. DHIS2 utilise les requêtes IdP pour établir des liens de correspondance entre les comptes d'utilisateurs de l'IdP et ceux hébergés dans DHIS2. Par défaut, DHIS2 exige que l'IdP transmette la requête _email_. En fonction de votre IdP, vous devrez peut-être configurer DHIS2 de manière à ce qu'il utilise une requête IdP différente.

If you are using Google or Azure AD as an IdP, the default behavior is to use the email claim to map IdP identities to DHIS2 user accounts.

In order for a DHIS2 user to be able to login with an IdP, the user profile checkbox _External authentication only (OpenID or LDAP)_ must be checked and _OpenID_ field must match the claim (mapping claim) returned by the IdP. Email is used as the claim by default by both Google and Azure AD.

### Configurer le fournisseur d'identité pour l'OIDC { #configure-the-identity-provider-for-oidc }

Cette rubrique fournit des informations sur comment configurer un fournisseur d'identité (IdP) de manière à utiliser l'OIDC avec le DHIS2. Il s'agit d'une étape d'un processus en plusieurs étapes. Les rubriques suivantes sont consacrées à la configuration et à l'utilisation de l'OIDC avec le DHIS2.

#### Configuration de l'IdP { #configure-the-idp }

Avant de pouvoir utiliser l'OIDC avec le DHIS2, vous devez disposer d'un compte chez un fournisseur d'identité pris en charge (IdP) et d'un projet ou d'une application avec l'IdP. Lorsque vous configurez le DHIS2, vous devez fournir les informations suivantes :

-   **Identifiant du client du fournisseur :** Il s'agit de l'identifiant que l'IdP a attribué à votre demande.

-   **Client secret du fournisseur :** Cette valeur est un secret et doit être gardée en toute sécurité.

#### Rediriger l'URL { #redirect-url }

Certains IdP nécessitent une URL de redirection pour votre instance DHIS2. Vous pouvez définir votre URL pour l'IdP en utilisant la syntaxe suivante :

```
(protocol):/(your DHIS2 host)/oauth2/code/{IdP-code}
```

Voici donc un exemple :

```
https://dhis2.org/oauth2/code/google
```

#### Exemple de procédure IdP (Google) { #example-idp-process-google }

The following procedure provides an outline of the steps that you follow with the provider. As an example, the procedure discusses using Google as an identity provider. However, each provider has a somewhat different flow, so the specifics of the steps and their order might vary depending on your provider.

1. Register at the provider's developer site and sign in. For example, for Google, you can go to the Google [developer console](https://console.developers.google.com).

2. Créer un nouveau projet ou une nouvelle application.

3. Dans le tableau de bord du développeur, suivez les étapes de création d'un client ID et d'un client secret OAuth 2.0. Enregistrez ces valeurs pour une utilisation ultérieure.

4. Set your Authorized redirect URIs to: `(protocol):/(host)/oauth2/code/google` Keep the client secret in a secure place.

Suivez les instructions de votre service IdP pour la configuration de votre IdP :

-   [Google](https://developers.google.com/identity/protocols/oauth2/openid-connect)

-   [Azure AD](https://medium.com/xebia-engineering/authentication-and-authorization-using-azure-active-directory-266980586ab8)

> **Note**
>
> Azure AD Authorized redirect URIs must have this form: `(protocol):/(host)/oauth2/code/my_azure_ad_tenant_id`

### Configurer le DHIS2 pour l'OIDC { #configure-dhis2-for-oidc }

> **Note**
>
> Before you perform the following steps you must configure the OIDC identity provider as described in Configure the Identity Provider for OIDC.

Cette rubrique présente les options de configuration à définir dans `dhis.conf`. N'oubliez pas de redémarrer DHIS 2 pour que les changements prennent effet.

To enable OIDC, start by setting the following property in `dhis.conf`.

```properties
oidc.oauth2.login.enabled = on
```

The following sections cover provider-specific configuration.

#### Google { #google }

```properties
# ----------------------------------------------------------------------
# Google OIDC Configuration
# ----------------------------------------------------------------------

# Generic config parameters

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)

# Google specific parameters:
oidc.provider.google.client_id = my_client_id
oidc.provider.google.client_secret = my_client_secret

# DHIS 2 instance URL, do not end with a slash, e.g.: https://dhis2.org/demo
oidc.provider.google.redirect_url = (protocol)://(host)/(optional app context)

# Optional, defaults to 'email'
oidc.provider.google.mapping_claim = email

```

#### Azure AD { #azure-ad }

Note that Azure AD supports having multiple tenants, hence the numbering scheme `oidc.provider.azure.NUMBER.VARIABLE` below.

Make sure your Azure AD account in the Azure portal is configured with a redirect URL like `(protocol):/(host)/oauth2/code/my_azure_ad_tenant_id`. To register DHIS 2 as an "app" in the Azure portal, follow these steps:

1. Search for and select _App registrations_.

2. Click _New registration_.

3. In the _Name_ field, enter a descriptive name for your DHIS 2 instance.

4. In the _Redirect URI_ field, enter the redirect URL as specified above.

5. Click _Register_.

```properties
# ----------------------------------------------------------------------
# Azure OIDC Configuration
# ----------------------------------------------------------------------

# Generic config parameters

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)

# Azure AD specific parameters:

# First provider (0)
oidc.provider.azure.0.tenant = my_azure_ad_tenant_id
oidc.provider.azure.0.client_id = my_azure_ad_client_id
oidc.provider.azure.0.client_secret = my_azure_ad_client_secret

# DHIS 2 instance URL, do not end with a slash, e.g.: https://dhis2.org/demo
oidc.provider.azure.0.redirect_url = (protocol)://(host)/(optional app context)

# Optional, defaults to 'email'
oidc.provider.azure.0.mapping_claim = email

# Optional, defaults to 'true'
oidc.provider.azure.0.support_logout = true

# Second provider (1)
oidc.provider.azure.1.tenant = my_other_azure_ad_tenant_id
...
```

#### Generic providers { #generic-providers }

The generic provider can be used to configure any standard OIDC provider which are compatible with Spring Security.

In the example below we configure the Norwegian governmental _*HelseID*_ OIDC provider using the key `helseid`.

The client key will automatically appear as a button in the login page with the key value, or the value of the `display_alias` if defined. The `key` is arbitrary and can be any value, except for the keys used by the specific providers (`google`, `azure`, `wso2`). It is recommended to use a key which is descriptive and reflects the provider.

The DHIS2 generic provider uses the following defaults:

-   Client Authentication: https://tools.ietf.org/html/rfc6749#section-2.3 > `ClientAuthenticationMethod.BASIC`

-   Authenticated Requests: https://tools.ietf.org/html/rfc6750#section-2 > `AuthenticationMethod.HEADER`

> **Note**
>
> The following client names are reserved for non-generic provider use and can not be used here: google, azure, wso2.

```properties
# ----------------------------------------------------------------------
# Generic OIDC Configuration
# ----------------------------------------------------------------------

# Generic config parameters

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)


# This is the name displayed on the DHIS2 login page
oidc.provider.helseid.display_alias = HelseID

oidc.provider.helseid.client_id = CLIENT_ID
oidc.provider.helseid.client_secret = CLIENT_SECRET
oidc.provider.helseid.mapping_claim = helseid://claims/identity/email
oidc.provider.helseid.authorization_uri = https://helseid.no/connect/authorize
oidc.provider.helseid.enable_logout = true
oidc.provider.helseid.token_uri = https://helseid.no/connect/token
oidc.provider.helseid.user_info_uri = https://helseid.no/connect/userinfo
oidc.provider.helseid.jwk_uri = https://helseid.no/.well-known/openid-configuration/jwks
oidc.provider.helseid.end_session_endpoint = https://helseid.no/connect/endsession
oidc.provider.helseid.scopes = helseid://scopes/identity/email
oidc.provider.helseid.redirect_url = {baseUrl}/oauth2/code/{registrationId}

# Link to an url for any logo here as long as it is served from the same domain as DHIS2
oidc.provider.helseid.logo_image = ../security/btn_helseid.svg
oidc.provider.helseid.logo_image_padding = 0px 1px

# Appended to the request, must be key/value pairs like: "KEY1 VALUE1,KEY2 VALUE2,..."
oidc.provider.helseid.extra_request_parameters = acr_values lvl4

# For optional PKCE support, see: https://oauth.net/2/pkce/), default is 'false'
oidc.provider.helseid.enable_pkce = true

```

## Setup JWT bearer token authentication for the DHIS2 Android client { #setup-jwt-bearer-token-authentication-for-the-dhis2-android-client }

For clients that are API-only, setting up authentication with JWT bearer tokens is possible when you have configured an OIDC provider. The DHIS2 Android client is such a type of client and have to use JWT authentication if OIDC login is enabled.

> **Note**
>
> DHIS2 currently only supports the OAuth2 authorization code grant flow for authentication with JWT, (also known as "three-legged OAuth") DHIS2 currently only supports using Google as an OIDC provider when using JWT tokens

### Conditions requises { #requirements }

-   Configure your Google OIDC provider as described above
-   Disable the config parameter `oauth2.authorization.server.enabled` by setting it to 'off'
-   Enable the config parameter `oidc.jwt.token.authentication.enabled` by setting it to 'on'
-   Générez un Id_client pour Android OAuth2 tel que décrit [ici](https://developers.google.com/identity/protocols/oauth2/native-app#creatingcred)

### Example DHIS2 config file with JWT authentication for an API only client { #example-dhis2-config-file-with-jwt-authentication-for-an-api-only-client }

```properties
# ----------------------------------------------------------------------
# Google OIDC Configuration with extra clients using JWT tokens
# ----------------------------------------------------------------------

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)

# Google specific parameters:
oidc.provider.google.client_id = my_client_id
oidc.provider.google.client_secret = my_client_secret

# DHIS 2 instance URL, do not end with a slash, e.g.: https://dhis2.org/demo
oidc.provider.google.redirect_url = (protocol)://(host)/(optional app context)

# Optional, defaults to 'email'
oidc.provider.google.mapping_claim = email


# Enable JWT support
oauth2.authorization.server.enabled = off
oidc.jwt.token.authentication.enabled = on

# Define client 1 using JWT tokens
oidc.provider.google.ext_client.0.client_id = JWT_CLIENT_ID

# Define client 2 using JWT tokens
oidc.provider.google.ext_client.1.client_id = JWT_CLIENT_ID

```

## LDAP configuration { #install_ldap_configuration }

DHIS2 is capable of using an LDAP server for authentication of users. For LDAP authentication it is required to have a matching user in the DHIS2 database per LDAP entry. The DHIS2 user will be used to represent authorities / user roles.

To set up LDAP authentication you need to configure the LDAP server URL, a manager user and an LDAP search base and search filter. This configuration should be done in the main DHIS 2 configuration file (dhis.conf). LDAP users, or entries, are identified by distinguished names (DN from now on). An example configuration looks like this:

```propriétés
# URL du serveur LDAP
ldap.url = ldaps://domain.org:636

# Nom distinctif de l'entrée du gestionnaire LDAP
ldap.manager.dn = cn=johndoe,dc=domain,dc=org

# Mot de passe d'entrée du gestionnaire LDAP
ldap.manager.password = xxxx

# Recherche de base LDAP
ldap.search.base = dc=domaine,dc=org

# Filtre de recherche LDAP
ldap.search.filter = (cn={0})
```

Les propriétés de configuration LDAP sont expliquées ci-dessous :

-   _ldap.url:_ The URL of the LDAP server for which to authenticate against. Using SSL/encryption is strongly recommended in order to make authentication secure. As example URL is _ldaps://domain.org:636_, where ldaps refers to the protocol, _domain.org_ refers to the domain name or IP address, and _636_ refers to the port (636 is default for LDAPS).
-   _ldap.manager.dn:_ An LDAP manager user is required for binding to the LDAP server for the user authentication process. This property refers to the DN of that entry. I.e. this is not the user which will be authenticated when logging into DHIS2, rather the user which binds to the LDAP server in order to do the authentication.
-   _ldap.manager.password:_ The password for the LDAP manager user.
-   _ldap.search.base:_ The search base, or the distinguished name of the search base object, which defines the location in the directory from which the LDAP search begins.
-   _ldap.search.filter:_ The filter for matching DNs of entries in the LDAP directory. The {0} variable will be substituted by the DHIS2 username, or alternatively, the LDAP identifier defined for the user with the supplied username.

DHIS2 will use the supplied username / password and try to authenticate against an LDAP server entry, then look up user roles / authorities from a corresponding DHIS2 user. This implies that a user must have a matching entry in the LDAP directory as well as a DHIS2 user in order to log in.

During authentication, DHIS2 will try to bind to the LDAP server using the configured LDAP server URL and the manager DN and password. Once the binding is done, it will search for an entry in the directory using the configured LDAP search base and search filter.

The {0} variable in the configured filter will be substituted before applying the filter. By default, it will be substituted by the supplied username. You can also set a custom LDAP identifier on the relevant DHIS2 user account. This can be done through the DHIS2 user module user interface in the add or edit screen by setting the "LDAP identifier" property. When set, the LDAP identifier will be substituted for the {0} variable in the filter. This feature is useful when the LDAP common name is not suitable or cannot for some reason be used as a DHIS2 username.

## Encryption configuration { #install_encryption_configuration }

DHIS2 allows for encryption of data. Enabling it requires some extra setup. To provide security to the encryption algorithm you will have to set a password in the _dhis.conf_ configuration file through the _encryption.password_ property:

```properties
encryption.password = xxxx
```

The _encryption.password_ property is the password (key) used when encrypting and decrypting data in the database. Note that the password must not be changed once it has been set and data has been encrypted, as the data can then no longer be decrypted.

The password must be at least **24 characters long**. A mix of numbers and lower- and uppercase letters is recommended. The encryption password must be kept secret.

> **Important**
>
> It is not possible to recover encrypted data if the encryption password is lost or changed. If the password is lost, so is the encrypted data. Conversely, the encryption provides no security if the password is compromised. Hence, great consideration should be given to storing the password in a safe place.

Note that encryption support depends on the _Java Cryptography Extension_ (JCE) policy files to be available. These are included in all versions of OpenJDK and Oracle JDK 8 Update 144 or later.

## Read replica database configuration { #install_read_replica_configuration }

DHIS 2 allows for utilizing read only replicas of the master database (the main DHIS 2 database). The purpose of read replicas is to enhance the performance of database read queries and scale out the capacity beyond the constraints of a single database. Read-heavy operations such as analytics and event queries will benefit from this.

The configuration requires that you have created one or more replicated instances of the master DHIS 2 database. PostgreSQL achieves this through a concept referred to as _streaming replication_. Configuring read replicas for PostgreSQL is not covered in this guide.

Read replicas can be defined in the _dhis.conf_ configuration file. You can specify up to 5 read replicas per DHIS 2 instance. Each read replica is denoted with a number between 1 and 5. The JDBC connection URL must be defined per replica. The username and password can be specified; if not, the username and password for the master database will be used instead.

The configuration for read replicas in _dhis.conf_ looks like the below. Each replica is specified with the configuration key _readN_ prefix, where N refers to the replica number.

```propriétés
# Configuration du réplica en lecture 1

# URL de connexion à la base de données, nom d'utilisateur et mot de passe
read1.connection.url = jdbc:postgresql://127.0.0.11/dbread1
read1.connection.username = dhis
read1.connection.password = xxxx

# Configuration du réplica en lecture 2

# URL de connexion à la base de données, nom d'utilisateur et mot de passe
read2.connection.url = jdbc:postgresql://127.0.0.12/dbread2
read2.connection.username = dhis
read2.connection.password = xxxx

# Configuration du réplica en lecture 3

# URL de connexion à la base de données, retour à la base de données principale pour le nom d'utilisateur et le mot de passe
read3.connection.url = jdbc:postgresql://127.0.0.13/dbread3
```

Note that you must restart your servlet container for the changes to take effect. DHIS 2 will automatically distribute the load across the read replicas. The ordering of replicas has no significance.

## Web server cluster configuration { #install_web_server_cluster_configuration }

This section describes how to set up the DHIS 2 application to run in a cluster.

### Clustering overview { #install_cluster_configuration_introduction }

Clustering is a common technique for improving system scalability and availability. Clustering refers to setting up multiple web servers such as Tomcat instances and have them serve a single application. Clustering allows for _scaling out_ an application in the sense that new servers can be added to improve performance. It also allows for _high availability_ as the system can tolerate instances going down without making the system inaccessible to users.

There are a few aspects to configure in order to run DHIS 2 in a cluster.

-   Each DHIS 2 instance must specify the other DHIS 2 instance members of the cluster in _dhis.conf_.

-   A Redis data store must be installed and connection information must be provided for each DHIS 2 application instance in _dhis.conf_.

-   DHIS 2 instances and servers must share the same _files_ folder used for apps and file uploads, either through the _AWS S3 cloud filestorage_ option or a shared network drive.

-   A load balancer such as nginx must be configured to distribute Web requests across the cluster instances.

### DHIS 2 instance cluster configuration { #install_cluster_configuration }

When setting up multiple Tomcat instances there is a need for making the instances aware of each other. This awareness will enable DHIS 2 to keep the local data (Hibernate) caches in sync and in a consistent state. When an update is done on one instance, the caches on the other instances must be notified so that they can be invalidated and avoid becoming stale.

A DHIS 2 cluster setup is based on manual configuration of each instance. For each DHIS 2 instance one must specify the public _hostname_ as well as the hostnames of the other instances participating in the cluster.

The hostname of the server is specified using the _cluster.hostname_ configuration property. Additional servers which participate in the cluster are specified using the _cluster.members_ configuration property. The property expects a list of comma separated values where each value is of the format _host:port_.

The hostname must be visible to the participating servers on the network for the clustering to work. You might have to allow incoming and outgoing connections on the configured port numbers in the firewall.

The port number of the server is specified using the _cluster.cache.port_ configuration property. The remote object port used for registry receive calls is specified using _cluster.cache.remote.object.port_. Specifying the port numbers is typically only useful when you have multiple cluster instances on the same server or if you need to explicitly specify the ports to match a firewall configuration. When running cluster instances on separate servers it is often appropriate to use the default port number and omit the ports configuration properties. If omitted, 4001 will be assigned as the listener port and a random free port will be assigned as the remote object port.

The _node.id_ configuration property can be used to provide an explicit identification string for an instance. Note that it is up to the administrators to make sure the Node IDs are unique across its cluster. DHIS2 will not enforce uniqueness and will continue to startup even if there are multiple instances in the cluster using the same node ID.

An example setup for a cluster of two web servers is described below. For _server A_ available at hostname _193.157.199.131_ the following can be specified in _dhis.conf_:

```properties
# Cluster configuration for server A

# Hostname for this web server
cluster.hostname = 193.157.199.131

# Ports for cache listener, can be omitted
cluster.cache.port = 4001
cluster.cache.remote.object.port = 5001

# List of Host:port participating in the cluster
cluster.members = 193.157.199.132:4001

#node identification (optional).
node.id = nodeA1
```

For _server B_ available at hostname _193.157.199.132_ the following can be specified in _dhis.conf_ (notice how port configuration is omitted):

```properties
# Cluster configuration for server B

# Hostname for this web server
cluster.hostname = 193.157.199.132

# List of servers participating in cluster
cluster.members = 193.157.199.131:4001

#node identification (optional).
node.id = nodeB1
```

You must restart each Tomcat instance to make the changes take effect. The two instances have now been made aware of each other and DHIS 2 will ensure that their caches are kept in sync.

To understand which node acts as the cluster leader you can access the `/api/36/cluster/leader` web API endpoint. Read more in the web API documentation.

### Redis shared data store cluster configuration { #install_cluster_configuration_redis }

In a cluster setup, a _Redis_ instance is required and will handle shared user sessions, application cache and cluster node leadership.

For optimum performance, _Redis Keyspace events_ for _generic commands_ and _expired events_ need to be enabled in the Redis Server. If you are using a cloud platform-managed Redis server (like _AWS ElastiCache for Redis_ or _Azure Cache for Redis_) you will have to enable keyspace event notifications using the respective cloud console interfaces. If you are setting up a standalone Redis server, enabling keyspace event notifications can be done in the _redis.conf_ file by adding or uncommenting the following line:

```
notify-keyspace-events Egx
```

DHIS2 will connect to Redis if the _redis.enabled_ configuration property in _dhis.conf_ is set to _true_ along with the following properties:

-   _redis.host_: Specifies where the redis server is running. Defaults to _localhost_. Mandatory.

-   _redis.port_: Specifies the port in which the redis server is listening. Defaults to _6379_. Optional.

-   _redis.password_: Specifies the authentication password. If a password is not required it can be left blank.

-   _redis.use.ssl_: Specifies whether the Redis server has SSL enabled. Defaults to false. Optional. Defaults to _false_.

When Redis is enabled, DHIS2 will automatically assign one of the running instances as the leader of the cluster. The leader instance will be used to execute jobs or scheduled tasks that should be run exclusively by one instance. Optionally you can configure the _leader.time.to.live.minutes_ property in _dhis.conf_ to set up how frequently the leader election needs to occur. It also gives an indication of how long it would take for another instance to take over as the leader after the previous leader has become unavailable. The default value is 2 minutes. Note that assigning a leader in the cluster is only done if Redis is enabled. An example snippet of the _dhis.conf_ configuration file with Redis enabled and leader election time configured is shown below.

```properties
# Redis Configuration

redis.enabled = true

redis.host = 193.158.100.111

redis.port = 6379

redis.password = <your password>

redis.use.ssl = false

# Optional, defaults to 2 minutes
leader.time.to.live.minutes=4
```

### Files folder configuration { #files-folder-configuration }

DHIS 2 will store several types of files outside the application itself, such as apps, files saved in data entry and user avatars. When deployed in a cluster, the location of these files must be shared across all instances. On the local filesystem, the location is:

```
{DHIS2_HOME}/files
```

Here, `DHIS2_HOME` refers to the location of the DHIS 2 configuration file as specified by the DHIS 2 environment variable, and `files` is the file folder immediately below.

Il existe deux manières d'obtenir un emplacement partagé :

-   Use the _AWS S3 cloud filestorage_ option. Files will be stored in an S3 bucket which is automatically shared by all DHIS 2 instances in the cluster. See the _File store configuration_ section for guidance.
-   Set up a shared folder which is shared among all DHIS 2 instances and servers in the cluster. On Linux this can be achieved with _NFS_ (Network File System) which is a distributed file system protocol. Note that only the `files` subfolder under `DHIS2_HOME` should be shared, not the parent folder.

### Load balancer configuration { #install_load_balancing }

With a cluster of Tomcat instances set up, a common approach for routing incoming web requests to the backend instances participating in the cluster is using a _load balancer_. A load balancer will make sure that load is distributed evenly across the cluster instances. It will also detect whether an instance becomes unavailable, and if so, stop routine requests to that instance and instead use other available instances.

Load balancing can be achieved in multiple ways. A simple approach is using _nginx_, in which case you will define an _upstream_ element which enumerates the location of the backend instances and later use that element in the _proxy_ location block.

```text
http {

  # Upstream element with sticky sessions

  upstream dhis_cluster {
    ip_hash;
    server 193.157.199.131:8080;
    server 193.157.199.132:8080;
  }

  # Proxy pass to backend servers in cluster

  server {
    listen 80;

    location / {
      proxy_pass   http://dhis_cluster/;
    }
  }
}
```

DHIS 2 keeps server-side state for user sessions to a limited degree. Using "sticky sessions" is a simple approach to avoid replicating the server session state by routing requests from the same client to the same server. The _ip_hash_ directive in the upstream element ensures this.

Note that several instructions have been omitted for brevity in the above example. Consult the reverse proxy section for a detailed guide.

## ActiveMQ Artemis configuration { #webapi_amqp_configuration }

Par défaut, DHIS2 lance une instance intégrée d'ActiveMQ Artemis au démarrage. Pour la plupart des cas d'utilisation, vous n'avez rien à faire. Si vous avez un service ActiveMQ Artemis existant que vous voulez utiliser à la place de l'instance intégrée, vous pouvez changer la configuration par défaut dans votre fichier `dhis.conf` avec les propriétés de configuration du tableau suivant.

| Propriété | Valeur (par défaut en premier) | Description |
| --- | --- | --- |
| amqp.mode | INTÉGRÉ \| NATIF | Le mode par défaut `INTÉGRÉ` lance un service AMQP interne au démarrage de l'instance DHIS2. Si vous voulez vous connecter à un service AMQP externe, définissez le mode sur `NATIF`. |
| amqp.host | 127.0.0.1 | Hôte auquel se connecter. |
| amqp.port | 15672 | Si le mode est défini sur `INTÉGRÉ`, le serveur intégré se connectera à ce port. Si c'est sur `NATIF`, le client utilisera ce port pour se connecter. |
| amqp.username | invité | Nom d'utilisateur auquel se connecter si vous utilisez le mode `NATIVE`. |
| amqp.password | invité | Mot de passe auquel se connecter si vous utilisez le mode `NATIF`. |
| amqp.embedded.persistence | false \| vrai | Si le mode est défini sur `INTÉGRÉ`, cette propriété va contrôlé la persistance de la file d'attente interne. |

## Surveillance { #monitoring }

DHIS 2 peut exporter des métriques compatibles avec Prometheus pour la surveillance des instances DHIS2. L'infrastructure de surveillance de DHIS2 est conçue pour exposer les métriques liées à l'exécution de l'application et d'autres informations relatives à l'application.

Les métriques liées à l'infrastructure (telles que les métriques de l'hôte, Tomcat ou Postgres) ne sont pas directement exposées par le moteur de surveillance de l'application et doivent être collectées séparément. Les métriques actuellement exposées par l'application sont :

-   API DHIS 2 (temps de réponse, nombre d'appels, etc.)
-   JVM (taille du tas, récupération de l'espace mémoire, etc.)
-   Mise en veille prolongée (requêtes, cache, etc.)
-   C3P0 Database pool
-   Disponibilité des applications
-   CPU

La surveillance peut être activé dans `dhis.conf` avec les propriétés suivantes (la valeur par défaut est `désactivé` pour toutes les propriétés) :

```propriétés
surveillance.api.enabled = activé
surveillance.jvm.enabled = activé
surveillance.dbpool.enabled = activé
surveillance.hibernate.enabled = désactivé
surveillance.uptime.enabled = activé
surveillance.cpu.enabled = activé
```

The recommended approach for collecting and visualizing these metrics is through Prometheus and Grafana.

For more information, see the [monitoring infrastructure](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md) page and the [Prometheus and Grafana install](https://docs.dhis2.org/master/en/dhis2_system_administration_guide/monitoring.html) chapter.

## System configuration { #install_system_configuration }

Cette section aborde diverses propriétés de configuration du système.

```propriétés
system.read_only_mode = on | désactivé
```

Définit le système sur le mode lecture seule. Ceci est utile lorsque vous exécutez DHIS 2 sur une base de données réplica en lecture seule, afin d'éviter que DHIS 2 n'effectue des opérations d'écriture sur la base de données. Peut être `activé` ou `désactivé`. La valeur par défaut est `désactivé`.

```properties
system.session.timeout = (seconds)
```

Définit le délai d'expiration de la session utilisateur en secondes. La valeur par défaut est 3 600 secondes (1 heure).

```properties
system.sql_view_table_protection = on | off
```

Active ou désactive la protection des tables de base de données sensibles pour les vues SQL. Grâce à cette protection, les tables de base de données contenant des données sensibles ne pourront pas être interrogées par le biais des vues SQL. La désactivation n'est pas recommandée. Peut être `activé` ou `désactivé`. La valeur par défaut est `on`.

```properties
system.program_rule.server_execution = on | off
```

Active ou désactive l'exécution des règles de programme côté serveur. Il s'agit des règles de programme qui ont des actions d'attribution de valeurs, d'envoi de messages ou de programmation d'envoi de messages. Peut être `activé` ou `désactivé`. La valeur par défaut est `activé`.

## Reverse proxy configuration { #install_reverse_proxy_configuration }

A reverse proxy is a proxy server that acts on behalf of a server. Using a reverse proxy in combination with a servlet container is optional but has many advantages:

-   Requests can be mapped and passed on to multiple servlet containers. This improves flexibility and makes it easier to run multiple instances of DHIS2 on the same server. It also makes it possible to change the internal server setup without affecting clients.

-   The DHIS2 application can be run as a non-root user on a port different than 80 which reduces the consequences of session hijacking.

-   The reverse proxy can act as a single SSL server and be configured to inspect requests for malicious content, log requests and responses and provide non-sensitive error messages which will improve security.

### Basic nginx setup { #install_basic_nginx_setup }

We recommend using [nginx](http://www.nginx.org) as a reverse proxy due to its low memory footprint and ease of use. To install invoke the following:

    sudo apt-get install nginx

nginx can now be started, reloaded and stopped with the following commands:

    sudo /etc/init.d/nginx start
    sudo /etc/init.d/nginx reload
    sudo /etc/init.d/nginx stop

Now that we have installed nginx we will now continue to configure regular proxying of requests to our Tomcat instance, which we assume runs at `http://localhost:8080`. To configure nginx you can open the configuration file by invoking:

    sudo nano /etc/nginx/nginx.conf

nginx configuration is built around a hierarchy of blocks representing http, server and location, where each block inherits settings from parent blocks. The following snippet will configure nginx to proxy pass (redirect) requests from port 80 (which is the port nginx will listen on by default) to our Tomcat instance. Include the following configuration in nginx.conf:

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  server {
    listen               80;
    client_max_body_size 10M;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  http;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

You can now access your DHIS2 instance at _http://localhost_. Since the reverse proxy has been set up we can improve security by making Tomcat only listen for local connections. In _/conf/server.xml_ you can add an _address_ attribute with the value _localhost_ to the Connector element for HTTP 1.1 like this:

```xml
<Connector address="localhost" protocol="HTTP/1.1" />
```

### Enabling SSL with nginx { #install_enabling_ssl_on_nginx }

In order to improve security it is recommended to configure the server running DHIS2 to communicate with clients over an encrypted connection and to identify itself to clients using a trusted certificate. This can be achieved through SSL which is a cryptographic communication protocol running on top of TCP/IP. First, install the required _openssl_ library:

    sudo apt-get install openssl

To configure nginx to use SSL you will need a proper SSL certificate from an SSL provider. The cost of a certificate varies a lot depending on encryption strength. An affordable certificate from [Rapid SSL Online](http://www.rapidsslonline.com) should serve most purposes. To generate the CSR (certificate signing request) you can invoke the command below. When you are prompted for the _Common Name_, enter the fully qualified domain name for the site you are securing.

    openssl req -new -newkey rsa:2048 -nodes -keyout server.key -out server.csr

When you have received your certificate files (.pem or .crt) you will need to place it together with the generated server.key file in a location which is reachable by nginx. A good location for this can be the same directory as where your nginx.conf file is located.

Below is an nginx server block where the certificate files are named server.crt and server.key. Since SSL connections usually occur on port 443 (HTTPS) we pass requests on that port (443) on to the DHIS2 instance running on `http://localhost:8080`. The first server block will rewrite all requests connecting to port 80 and force the use of HTTPS/SSL. This is also necessary because DHIS2 is using a lot of redirects internally which must be passed on to use HTTPS. Remember to replace _\<server-ip\>_ with the IP of your server. These blocks should replace the one from the previous section.

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  # HTTP server - rewrite to force use of SSL

  server {
    listen     80;
    rewrite    ^ https://<server-url>$request_uri? permanent;
  }

  # HTTPS server

  server {
    listen               443 ssl;
    client_max_body_size 10M;

    ssl                  on;
    ssl_certificate      server.crt;
    ssl_certificate_key  server.key;

    ssl_session_cache    shared:SSL:20m;
    ssl_session_timeout  10m;

    ssl_protocols              TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers                RC4:HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

Note the last `https` header value which is required to inform the servlet container that the request is coming over HTTPS. In order for Tomcat to properly produce `Location` URL headers using HTTPS you also need to add two other parameters to the Connector in the Tomcat `server.xml` file:

```xml
<Connector scheme="https" proxyPort="443" />
```

### Enabling caching with nginx { #install_enabling_caching_ssl_nginx }

Requests for reports, charts, maps and other analysis-related resources will often take some time to respond and might utilize a lot of server resources. In order to improve response times, reduce the load on the server and hide potential server downtime we can introduce a cache proxy in our server setup. The cached content will be stored in directory /var/cache/nginx, and up to 250 MB of storage will be allocated. Nginx will create this directory automatically.

```text
http {
  ..
  proxy_cache_path  /var/cache/nginx  levels=1:2  keys_zone=dhis:250m  inactive=1d;


  server {
    ..

    # Proxy pass to servlet container and potentially cache response

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
      proxy_cache               dhis;
    }
  }
}
```

> **Important**
>
> Be aware that a server side cache shortcuts the DHIS2 security features in the sense that requests which hit the server side cache will be served directly from the cache outside the control of DHIS2 and the servlet container. This implies that request URLs can be guessed and reports retrieved from the cache by unauthorized users. Hence, if you capture sensitive information, setting up a server side cache is not recommended.

### Rate limiting with nginx { #install_rate_limiting }

Certains appels d'API web dans DHIS 2, tels que les API d'`analyses`, nécessitent beaucoup de calculs. Par conséquent, il est préférable de limiter le débit de ces API afin d'équilibrer l'utilisation des ressources du serveur par les utilisateurs du système. La limitation de débit peut être effectuée avec `nginx`. Il existe plusieurs approches pour effectuer la limitation de débit et ceci est destiné à documenter l'approche basée sur nginx.

The below nginx configuration will rate limit the `analytics` web API, and has the following elements at the _http_ and _location_ block level (the configuration is shortened for brevity):

```text
http {
  ..
  limit_req_zone $binary_remote_addr zone=limit_analytics:10m rate=5r/s;

  server {
    ..

    location ~ ^/api/(\d+/)?analytics(.*)$ {
      limit_req    zone=limit_analytics burst=20;
      proxy_pass   http://localhost:8080/api/$1analytics$2$is_args$args;
      ..
    }
  }
}
```

Les différents éléments de la configuration peuvent être décrits comme suit :

-   _limit_req_zone $binary_remote_addr_: Rate limiting is done per request IP.
-   _zone=limit_analytics:20m_: A rate limit zone for the analytics API which can hold up to 10 MB of request IP addresses.
-   _rate=20r/s_: Each IP is granted 5 requests per second.
-   _location ~ ^/api/(\d+/)?analytics(.\*)$_: Requests for the analytics API endpoint are rate limited.
-   _burst=20_: Bursts of up to 20 requests will be queued and serviced at a later point; additional requests will lead to a `503`.

Pour obtenir une explication complète, veuillez consulter la [documentation nginx](https://www.nginx.com/blog/rate-limiting-nginx/).

### Making resources available with nginx { #install_making_resources_available_with_nginx }

In some scenarios it is desirable to make certain resources publicly available on the Web without requiring authentication. One example is when you want to make data analysis related resources in the web API available in a Web portal. The following example will allow access to charts, maps, reports, report table and document resources through basic authentication by injecting an _Authorization_ HTTP header into the request. It will remove the Cookie header from the request and the Set-Cookie header from the response in order to avoid changing the currently logged in user. It is recommended to create a user for this purpose given only the minimum authorities required. The Authorization value can be constructed by Base64-encoding the username appended with a colon and the password and prefix it "Basic ", more precisely "Basic base64_encode(username:password)". It will check the HTTP method used for requests and return _405 Method Not Allowed_ if anything but GET is detected.

It can be favorable to set up a separate domain for such public users when using this approach. This is because we don't want to change the credentials for already logged in users when they access the public resources. For instance, when your server is deployed at somedomain.com, you can set a dedicated subdomain at api.somedomain.com, and point URLs from your portal to this subdomain.

```text
http {
  ..

  server {
    listen       80;
    server_name  api.somedomain.com;

    location ~ ^/(api/(charts|chartValues|reports|reportTables|documents|maps|organisationUnits)|dhis-web-commons/javascripts|images|dhis-web-commons-ajax-json|dhis-web-mapping|dhis-web-visualizer) {
    if ($request_method != GET) {
        return 405;
      }

      proxy_pass         http://localhost:8080;
      proxy_redirect     off;
      proxy_set_header   Host               $host;
      proxy_set_header   X-Real-IP          $remote_addr;
      proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto  http;
      proxy_set_header   Authorization      "Basic YWRtaW46ZGlzdHJpY3Q=";
      proxy_set_header   Cookie             "";
      proxy_hide_header  Set-Cookie;
    }
  }
}
```

### Block specific Android App versions with nginx { #install_block_android_versions }

In some scenarios the system administrator might want to block certain Android clients based on its DHIS2 App version. For example, if the users on the field have not updated their Android App version to a specific one and the system administrator wants to block their access to force an update; or completely the opposite scenario when the system administrator wants to block new versions of the App as they have not been yet tested. This can be easily implemented by using specific _User-Agent_ rules in the `nginx` configuration file.

```text
http {

  server {
    listen       80;
    server_name  api.somedomain.com;

    # Block the latest Android App as it has not been tested
    if ( $http_user_agent ~ 'com\.dhis2/1\.2\.1/2\.2\.1/' ) {
        return 403;
    }

    # Block Android 4.4 (API is 19) as all users should have received new tablets
    if ( $http_user_agent ~ 'com\.dhis2/.*/.*/Android_19' ) {
        return 403;
    }
  }
}
```

> **Note** For the implementation of the method described above note the following:
>
> -   Before version 1.1.0 the _User-Agent_ string was not being sent.
> -   From version 1.1.0 to 1.3.2 the _User-Agent_ followed the pattern Dhis2/AppVersion/AppVersion/Android_XX
> -   From version 2.0.0 and above the _User-Agent_ follows the pattern com.dhis2/SdkVersion/AppVersion/Android_XX
> -   Android_XX refers to the Android API level i.e. the Android version as listed [here](https://developer.android.com/studio/releases/platforms).
> -   nginx uses [PCRE](http://www.pcre.org/) for Regular Expression matching .

## DHIS2 configuration reference { #install_dhis2_configuration_reference }

The following describes the full set of configuration options for the _dhis.conf_ configuration file. The configuration file should be placed in a directory which is pointed to by a _DHIS2_HOME_ environment variable.

> **Remarque**
>
> Vous ne devez pas utiliser ce fichier de configuration directement, mais plutôt comme référence pour les options de configuration disponibles. Plusieurs propriétés sont facultatives.

```properties
# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Mandatory]
# ----------------------------------------------------------------------

# Hibernate SQL dialect
connection.dialect = org.hibernate.dialect.PostgreSQLDialect

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password (sensitive)
connection.password = xxxx

# Max size of connection pool (default: 40)
connection.pool.max_size = 40

# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Optional]
# ----------------------------------------------------------------------

# Minimum number of Connections a pool will maintain at any given time (default: 5).
connection.pool.min_size=5

# Initial size of connection pool (default : 5)
#Number of Connections a pool will try to acquire upon startup. Should be between minPoolSize and maxPoolSize
connection.pool.initial_size=5

#Determines how many connections at a time will try to acquire when the pool is exhausted.
connection.pool.acquire_incr=5

#Seconds a Connection can remain pooled but unused before being discarded. Zero means idle connections never expire. (default: 7200)
connection.pool.max_idle_time=7200

#Number of seconds that Connections in excess of minPoolSize should be permitted to remain idle in the pool before being culled (default: 0)
connection.pool.max_idle_time_excess_con=0

#If this is a number greater than 0, dhis2 will test all idle, pooled but unchecked-out connections, every this number of seconds. (default: 0)
connection.pool.idle.con.test.period=0

#If true, an operation will be performed at every connection checkout to verify that the connection is valid. (default: false)
connection.pool.test.on.checkout=false

#If true, an operation will be performed asynchronously at every connection checkin to verify that the connection is valid. (default: true)
connection.pool.test.on.checkin=true

#Defines the query that will be executed for all connection tests. Ideally this config is not needed as postgresql driver already provides an efficient test query. The config is exposed simply for evaluation, do not use it unless there is a reason to.
connection.pool.preferred.test.query=select 1

#Configure the number of helper threads used by dhis2 for jdbc operations. (default: 3)
connection.pool.num.helper.threads=3

# ----------------------------------------------------------------------
# Server [Mandatory]
# ----------------------------------------------------------------------

# Base URL to the DHIS 2 instance
server.base.url = https://play.dhis2.org/dev

# Enable secure settings if system is deployed on HTTPS, can be 'off', 'on'
server.https = off

# ----------------------------------------------------------------------
# System [Optional]
# ----------------------------------------------------------------------

# System mode for database read operations only, can be 'off', 'on'
system.read_only_mode = off

# Session timeout in seconds, default is 3600
system.session.timeout = 3600

# SQL view protected tables, can be 'on', 'off'
system.sql_view_table_protection = on

# Disable server-side program rule execution, can be 'on', 'off'
system.program_rule.server_execution = on

# ----------------------------------------------------------------------
# Encryption [Optional]
# ----------------------------------------------------------------------

# Encryption password (sensitive)
encryption.password = xxxx

# ----------------------------------------------------------------------
# File store [Optional]
# ----------------------------------------------------------------------

# File store provider, currently 'filesystem' and 'aws-s3' are supported
filestore.provider = filesystem

# Directory / bucket name, folder below DHIS2_HOME on file system, 'bucket' on AWS S3
filestore.container = files

# Datacenter location (not required)
filestore.location = eu-west-1

# Public identity / username
filestore.identity = dhis2-id

# Secret key / password (sensitive)
filestore.secret = xxxx

# ----------------------------------------------------------------------
# LDAP [Optional]
# ----------------------------------------------------------------------

# LDAP server URL
ldap.url = ldaps://300.20.300.20:636

# LDAP manager user distinguished name
ldap.manager.dn = cn=JohnDoe,ou=Country,ou=Admin,dc=hisp,dc=org

# LDAP manager user password (sensitive)
ldap.manager.password = xxxx

# LDAP entry distinguished name search base
ldap.search.base = dc=hisp,dc=org

# LDAP entry distinguished name filter
ldap.search.filter = (cn={0})

# ----------------------------------------------------------------------
# Node [Optional]
# ----------------------------------------------------------------------

# Node identifier, optional, useful in clusters
node.id = 'node-1'

# ----------------------------------------------------------------------
# Monitoring [Optional]
# ----------------------------------------------------------------------

# DHIS2 API monitoring
monitoring.api.enabled = on

# JVM monitoring
monitoring.jvm.enabled = on

# Database connection pool monitoring
monitoring.dbpool.enabled = on

# Hibernate monitoring, do not use in production
monitoring.hibernate.enabled = off

# Uptime monitoring
monitoring.uptime.enabled = on

# CPU monitoring
monitoring.cpu.enabled = on

# ----------------------------------------------------------------------
# Analytics [Optional]
# ----------------------------------------------------------------------

# Analytics server-side cache expiration in seconds
analytics.cache.expiration = 3600

# ----------------------------------------------------------------------
# System telemetry [Optional]
# ----------------------------------------------------------------------

# System monitoring URL
system.monitoring.url =

# System monitoring username
system.monitoring.username =

# System monitoring password (sensitive)
system.monitoring.password = xxxx
```

## Changelog { #install_changelog }

Le DHIS2 écrit des entrées dans les changelogs lorsque certaines entités sont modifiées dans le système. Ces entités appartiennent à deux catégories : _Agrégat_ et _Tracker_. La catégorie _Agrégat_ comprend les modifications apportées aux valeurs des données agrégées. Quant à la catégorie _Tracker_, elle comprend les modifications apportées aux instances de programme, aux éléments de propriété temporaire du programme, aux valeurs des attributs des entités suivies et aux valeurs des données des entités suivies.

Le changelog pour les deux catégories est activé par défaut. Vous pouvez contrôler l'activation ou la désactivation du changelog par catégorie par le biais du fichier de configuration `dhis.conf` en utilisant les propriétés décrites ci-dessous. Les options de propriétés sont `on`  (par défaut) et `off`.

L'avantage du changelog réside dans le fait qu'il permet de voir les modifications effectuées sur les données. L'avantage que présente la désactivation du changelog est une amélioration mineure des performances en évitant le coût d'écriture des éléments du changelog dans la base de données, et une réduction de la capacité de stockage de la base de données utilisée. Il est donc recommandé d'activer le changelog, et il faudra faire preuve d'une grande prudence en le désactivant.

```propriétés
# Le changelog de la catégorie Agrégat, peut être défini sur 'on', 'off'
changelog.aggregate = on

# Le changelog de la catégorie Tracker, peut être défini sur 'on', 'off'
changelog.tracker = on
```

## Application logging { #install_application_logging }

Cette section traite de la journalisation des applications dans DHIS 2.

### Log files { #log-files }

La sortie du journal de l'application DHIS2 est dirigée vers plusieurs fichiers et emplacements. Tout d'abord, la sortie du journal est envoyée à la sortie standard. Le conteneur de servlets Tomcat envoie généralement la sortie standard vers un fichier sous "logs" (journaux) :

    <tomcat-dir>/logs/catalina.out

Second, log output is written to a "logs" directory under the DHIS2 home directory as defined by the DHIS2_HOME environment variables. There is a main log file for all output, and separate log files for various background processes. The main file includes the background process logs as well. The log files are capped at 50 Mb and log content is continuously appended.

    <DHIS2_HOME>/logs/dhis.log
    <DHIS2_HOME>/logs/dhis-analytics-table.log
    <DHIS2_HOME>/logs/dhis-data-exchange.log
    <DHIS2_HOME>/logs/dhis-data-sync.log

### Log configuration { #log-configuration }

To override the default log configuration you can specify a Java system property with the name `log4j2.configurationFile` and a value pointing to the [Log4j version 2](https://logging.apache.org/log4j/2.x/manual/configuration.html) configuration file at the file system like this:

```propriétés
-Dlog4j2.configurationFile=/home/dhis/config/log4j2.properties
```

Java system properties can be set e.g. through the _JAVA_OPTS_ environment variable or in the tomcat startup script.

A second approach to overriding the log configuration is to specify logging properties in the _dhis.conf_ configuration file. The supported properties are:

```propriétés
# Taille maximale des fichiers journaux, la valeur par défaut est '100Mo'
journalisation.file.max_size = 250 Mo

# Nombre maximum de fichiers d'archives de journaux glissants, la valeur par défaut est 0
journalisation.file.max_archives = 2
```

DHIS2 will eventually phase out logging to standard out / catalina.out and as a result it is recommended to rely on the logs under DHIS2_HOME.

## Working with the PostgreSQL database { #install_working_with_the_postgresql_database }

Common operations when managing a DHIS2 instance are dumping and restoring databases. To make a dump (copy) of your database, assuming the setup from the installation section, you can invoke the following:

    pg_dump dhis2 -U dhis -f dhis2.sql

The first argument (dhis2) refers to the name of the database. The second argument (dhis) refers to the database user. The last argument (dhis2.sql) is the file name of the copy. If you want to compress the file copy immediately you can do:

    pg_dump dhis2 -U dhis | gzip > dhis2.sql.gz

To restore this copy on another system, you first need to create an empty database as described in the installation section. You also need to gunzip the copy if you created a compressed version. You can invoke:

    psql -d dhis2 -U dhis -f dhis2.sql

# Upgrading { #upgrading-dhis2 }

## Upgrading vs. Updating { #upgrading-vs-updating }

When we talk about upgrading DHIS2, we generally simply mean "moving to a newer version". However, there is an important distinction between _upgrading_ and _updating_.

**Upgrading** : Moving to a newer base version of DHIS2 (for example, from 2.34 to 2.36). Upgrading typically requires planning, testing, training (for new features or interfaces), which may take significant time and effort.

**Updating** : Moving to a newer patch of the current DHIS2 version (for example, from 2.35.1 to 2.35.4). Updating mainly provides bug fixes without changing the functionality of the software. It is lower risk, and we advise everyone to keep their version up to date.

## Before you begin { #upgrading-before-you-begin }

> **Caution**
>
> It is important to note that once you upgrade you will not be able to use the upgraded database with an older version of DHIS2. That is to say **it is not possible to downgrade**.
>
> If you wish to revert to an older version, you must do so with a copy of the database that was created from that older version, or a previous version. Therefore, it is almost always a good idea to make a copy of your database before you uprgrade.

## Performing the upgrade { #upgrading-process }

Regardless of whether you are upgrading or updating, the technical process is more-or-less identical. We will just refer to it as upgrading.

### 1 Safeguard your data { #upgrading-safeguard-your-data }

Depending on what sort of DHIS2 instance you have, and what you use it for, the first step is to make sure that you can recover any important data if anything goes wrong with the upgrade.

This means performing standard system admin tasks, such as:

1. Backing up your database
2. Testing in a development environment
3. Scheduling down time (to avoid data being entered during the upgrade)
4. etc.

### 2 Upgrade the software { #upgrading-upgrade-the-software }

#### From v2.29 or below { #upgrading-pre-230 }

If you are starting from v2.29 or below, you must first upgrade to v2.30 version-by-version, manually, following the upgrade notes you find under the specific version numbers on [our releases site](https://github.com/dhis2/dhis2-releases). When you are at v2.30 you can go to the next section.

#### From v2.30 or above { #upgrading-post-230 }

If you are starting from at least v2.30:

1. **Read all of the upgrade notes from your current version up to the target version on [our releases site](https://github.com/dhis2/dhis2-releases).** Make sure your environment meets all of the requirements
2. Make a copy of your database if you didn't do so in step 1
3. Drop any materialized SQL views from your database
4. Stop the server
5. Replace the war file with the target version (There is no need to upgrade to intermediate versions; in fact, it is not recommended)
6. Start the server

You should now be ready to enjoy the new fixes and features.

# Surveillance { #monitoring }

## Introduction { #monitoring }

DHIS2 can export [Prometheus](https://prometheus.io/) compatible metrics for monitoring DHIS2 nodes.

This section describes the steps required to install Prometheus and [Grafana](https://grafana.com/) using a standard installation procedure (`apt-get`) and Docker and configure Grafana to show DHIS2 metrics.

For a list of the metrics exposed by a DHIS2 instance, please refer to the monitoring guide on [GitHub](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md).

## Setup { #monitoring_setup }

The next sections describe how to set up Prometheus and Grafana and how to set up Prometheus to pull data from one or more DHIS2 instances.

### Installing Prometheus + Grafana on Ubuntu and Debian { #prometheus }

-   Download Prometheus from the official [download](https://prometheus.io/download/) page.

-   Make sure to filter for your operating system and your CPU architecture (Linux and amd64).

-   Make sure to select the latest stable version, and not the “rc” one, as it is not considered stable enough for now.

-   Download the archive, either by clicking on the link or using `wget`.

```
wget https://github.com/prometheus/prometheus/releases/download/v2.15.2/prometheus-2.15.2.linux-amd64.tar.gz
```

-   Untar the zip

```
tar xvzf prometheus-2.15.2.linux-amd64.tar.gz
```

The archive contains many important files, but here is the main ones you need to know.

-   `prometheus.yml`: the configuration file for Prometheus. This is the file that you are going to modify in order to tweak your Prometheus server, for example to change the scraping interval or to configure custom alerts;
-   `prometheus`: the binary for your Prometheus server. This is the command that you are going to execute to launch a Prometheus instance on your Linux box;
-   `promtool`: this is a command that you can run to verify your Prometheus configuration.

### Configuring Prometheus as a service { #prometheus_service }

-   Create a `Prometheus` user with a `Prometheus` group.

```
useradd -rs /bin/false prometheus
```

-   Move the Prometheus binaries to the local bin directory

```
cd prometheus-2.15.2.linux-amd64/
cp prometheus promtool /usr/local/bin
chown prometheus:prometheus /usr/local/bin/prometheus
```

-   Create a folder in the `/etc` folder for Prometheus and move the console files, console libraries and the prometheus configuration file to this newly created folder.

```
mkdir /etc/prometheus
cp -R consoles/ console_libraries/ prometheus.yml /etc/prometheus
```

Create a data folder at the root directory, with a prometheus folder inside.

```
mkdir -p data/prometheus
chown -R prometheus:prometheus /data/prometheus /etc/prometheus/*
```

### Create a Prometheus service { #prometheus_create_service }

To create a Prometheus _systemd_ service, head over to the `/lib/systemd/system` folder and create a new systemd file named `prometheus.service`.

```
cd /lib/systemd/system
touch prometheus.service
```

-   Edit the newly created file, and paste the following content inside:

```properties
[Unit]
Description=Prometheus
Wants=network-online.target
After=network-online.target

[Service]
Type=simple
User=prometheus
Group=prometheus
ExecStart=/usr/local/bin/prometheus \
  --config.file=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path="/data/prometheus" \
  --web.console.templates=/etc/prometheus/consoles \
  --web.console.libraries=/etc/prometheus/console_libraries \
  --web.listen-address=0.0.0.0:9090 \
  --web.enable-admin-api

Restart=always

[Install]
WantedBy=multi-user.target
```

-   Save the file and enable the Prometheus service at startup

```
systemctl enable prometheus
systemctl start prometheus
```

-   Test that the service is running

```
systemctl status prometheus

...
Active: active (running)
```

-   It should be now possible to access the Prometheus UI by accessing `http://localhost:9090`.

### Set-up Nginx reverse proxy { #prometheus_nginx }

Prometheus does not natively support authentication or TLS encryption. If Prometheus has to be exposed outside the boundaries of the local network, it is important to enable authentication and TLS encryption. The following steps show how to use Nginx as a reverse proxy.

-   Install Nginx, if not already installed

```
apt update
apt-get install nginx
```

By default, Nginx will start listening for HTTP requests in the default `http` port, which is `80`.

If there is already an Nginx instance running on the machine and you are unsure on which port it is listening on, run the following command:

```
> lsof | grep LISTEN | grep nginx

nginx   15792   root   8u   IPv4   1140223421   0t0   TCP *:http (LISTEN)
```

The last column shows the port used by Nginx (`http` -> `80`).

By default, Nginx configuration is located in `/etc/nginx/nginx.conf`

Make sure that `nginx.conf` contains the `Virtual Host Config` section

```
##
# Virtual Host Configs
##

include /etc/nginx/conf.d/*.conf;
include /etc/nginx/sites-enabled/*;

```

-   Create a new file in `/etc/nginx/conf.d` called `prometheus.conf`

```
touch /etc/nginx/conf.d/prometheus.conf
```

-   Edit the newly created file, and paste the following content inside:

```
server {
  listen 1234;

  location / {
    proxy_pass           http://localhost:9090/;
  }
}
```

-   Restart Nginx and browse to http://localhost:1234

```
systemctl restart nginx

# in case of start-up errors
journalctl -f -u nginx.service
```

-   Configure Prometheus for reverse proxying, by editing `/lib/systemd/system/prometheus.service` and add the following argument to the list of arguments passed to the Prometheus executable.

```
--web.external-url=https://localhost:1234
```

-   Restart the service

```
systemctl daemon-reload
systemctl restart prometheus


# in case of errors
journalctl -f -u prometheus.service
```

### Enable reverse proxy authentication { #prometheus_auth }

This section shows how to configure basic authentication via the reverse proxy. If you need a different authentication mechanism (SSO, etc.) please check the relevant documentation.

-   Make sure that `htpasswd` is installed on the system

```
apt-get install apache2-utils
```

-   Create an authentication file

```
cd /etc/prometheus
htpasswd -c .credentials admin
```

Choose a strong password, and make sure that the pass file was correctly created.

-   Edit the previously created Nginx configuration file (`/etc/nginx/conf.d/prometheus.conf`), and add the authentication information.

```
server {
  listen 1234;

  location / {
    auth_basic           "Prometheus";
    auth_basic_user_file /etc/prometheus/.credentials;
    proxy_pass           http://localhost:9090/;
  }
}
```

-   Restart Nginx

```
systemctl restart nginx

# in case of errors
journalctl -f -u nginx.service
```

-   `http://localhost:1234` should now prompt for username and password.

### Installing Grafana on Ubuntu and Debian { #grafana }

-   Add a `gpg` key and install the OSS Grafana package from APT repo

```sh
apt-get install -y apt-transport-https

wget -q -O - "https://packages.grafana.com/gpg.key" | sudo apt-key add -

add-apt-repository "deb https://packages.grafana.com/oss/deb stable main"

apt-get update

apt-get install grafana
```

-   If the system is using `systemd`, a new `grafana-service` is automatically created. Check the `systemd` file to gain some insight on the Grafana installation

```
cat /usr/lib/systemd/system/grafana-server.service
```

This file is quite important because it offers information about the newly installed Grafana instance.

The file shows:

The **Grafana server binary** is located at `/usr/sbin/grafana-server`. The file that defines all the **environment variables** is located at `/etc/default/grafana-server` The **configuration file** is given via the `CONF_FILE` environment variable. The **PID of the file** is also determined by the `PID_FILE_DIR` environment variable. **Logging**, **data**, **plugins** and **provisioning** paths are given by environment variables.

-   Start the server

```
systemctl start grafana-server
```

-   Access Grafana web console: http://localhost:3000

The default login for Grafana is `admin` and the default password is also `admin`. You will be prompted to change the password on first access.

-   Configure Prometheus as a Grafana datasource

Access to the datasources panel by clicking on `Configuration` > `Data sources` via the left menu.

Click on `Add a datasource`

Select a Prometheus data source on the next window.

Configure the datasource according to the Prometheus setup (use authentication, TSL, etc.)

### Installing Prometheus + Grafana using Docker { #prometheus_grafana_docker }

This section describes how to start-up a Prometheus stack containing Prometheus and Grafana.

The configuration is based on this project: https://github.com/vegasbrianc/prometheus

-   Clone this Github project: https://github.com/vegasbrianc/prometheus

-   Start the Prometheus stack using:

```
docker stack deploy -c docker-stack.yml prom
```

The above command, may result in the following error:

_This node is not a swarm manager. Use "docker swarm init" or "docker swarm join" to connect this node to swarm and try again_

If that happens, you need to start Swarm. You can use the following command line:

```
docker swarm init --advertise-addr <YOUR_IP>
```

Once this command runs successfully, you should be able to run the previous command without problems.

The stack contains also a Node exporter for Docker monitoring. If you are not interested in Docker monitoring, you can comment out the relevant sections in the `docker-stack.yml` file:

-   `node-exporter`
-   `cadvisor`

-   To stop the Prometheus stack:

```
docker stack rm prom
```

The Prometheus configuration (`prometheus.yml`) file is located in the `prometheus` folder.

-   Access Grafana web console at: http://localhost:3000 with username: `admin` and password: `foobar`

### Configure Prometheus to pull metrics from one or more DHIS2 instances { #prometheus_dhis2 }

Prior to using Prometheus, it needs basic configuring. Thus, we need to create a configuration file named `prometheus.yml`

> **Note**
>
> The configuration file of Prometheus is written in YAML which strictly forbids to use tabs. If your file is incorrectly formatted, Prometheus will not start. Be careful when you edit it.

Prometheus’ configuration file is divided into three parts: `global`, `rule_files`, and `scrape_configs`.

In the global part we can find the general configuration of Prometheus: `scrape_interval` defines how often Prometheus scrapes targets, `evaluation_interval` controls how often the software will evaluate rules. Rules are used to create new time series and for the generation of alerts.

The `rule_files` block contains information of the location of any rules we want the Prometheus server to load.

The last block of the configuration file is named `scape_configs` and contains the information which resources Prometheus monitors.

A simple DHIS2 Prometheus monitoring file looks like this example:

```yaml
global:
    scrape_interval: 15s
    evaluation_interval: 15s

scrape_configs:
    - job_name: "dhis2"
      metrics_path: "/dhis/api/metrics"
      basic_auth:
          username: admin
          password: district
      static_configs:
          - targets: ["localhost:80"]
```

The global `scrape_interval` is set to 15 seconds which is enough for most use cases.

In the `scrape_configs` part we have defined the DHIS2 exporter. The `basic_auth` blocks contains the credentials required to access the `metrics` API: consider creating an ad-hoc user only for accessing the `metrics` endpoint.

Prometheus may or may not run on the same server as DHIS2: in the above configuration, it is assumed that Prometheus monitors only one DHIS2 instance, running on the same server as Prometheus, so we use `localhost`.

### Configure the DHIS2 exporter { #dhis2_metrics_conf }

The monitoring subsystem is disabled by default in DHIS2.

Each metrics cluster has to be explicitly enabled in order for the metrics to be exported. To configure DHIS2 to export one or more metrics, check this [document](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md#dhis2-monitoring-configuration).

# Audit { #audit }

## Introduction { #introduction }

DHIS2 supports a new audit service which is based on Apache ActiveMQ Artemis. Artemis is used as an asynchronous messaging system by DHIS2.

After an entity is saved to database, an audit message will be sent to the Artemis message consumer service. The message will then be processed in a different thread.

Audit logs can be retrieved from the DHIS2 database. Currently there is no UI or API endpoint available for retriving audit entries.

## Single Audit table { #audit_table }

All audit entries will be saved into one single table named `audit`

| Colonne | Type |  |
| --- | --- | --- |
| auditid | integer |  |
| audittype | texte | READ, CREATE, UPDATE, DELETE, SEARCH |
| auditscope | texte | METADATA, AGGREGATE, TRACKER |
| klass | texte | Audit Entity Java class name |
| attributes | jsonb | Json string stores attributes of the audit entity, used for searching. Example: {"valueType":"TEXT", "categoryCombo":"SWQW313FQY", "domainType":"TRACKER"} |
| données | bytea | Compressed Json string of the Audit Entity. It is currently in byte array format and not human-readable. |
| createdat | timestamp without time zone |  |
| createdby | texte |  |
| uid | texte |  |
| code | texte |  |

The new Audit service makes use of two new concepts: Audit Scopes and Audit Type.

## Audit Scope { #audit_scope }

An Audit Scope is a logical area of the application which can be audited. Currently there are three Audit Scopes:

```
Tracker

Metadata

Aggregate
```

-   For the Tracker Audit Scope, the audited objects are: Tracked Entity Instance, Tracked Entity Attribute Value, Enrollment, Event

-   For the Metadata Scope, all "metadata" objects are audited.

-   For the Aggregate Scope, the Aggregate Data Value objects are audited.

## Audit Type { #audit_type }

An Audit Type is an action that triggers an audit operation. Currently we support the following types:

```
READ

CREATE

UPDATE

DELETE
```

As an example, when a new Tracked Entity Instance gets created, and if configured like so, the CREATE action is used to insert a new Audit entry in the audit db table.

> **Caution**
>
> The READ Audit Type will generate a lot of data in database and may have an impact on the performance.

## Setup { #audit_configuration }

The audit system is automatically configured to audit for the following scopes and types:

-   CREATE, UPDATE, DELETE

-   METADATA, TRACKER, AGGREGATE

**No action is required to activate the audit.** The audit can still be configured using the "audit matrix". The audit matrix is driven by 3 properties in dhis.conf:

```
audit.metadata

audit.tracker

audit.aggregate
```

Each property accepts a semicolon delimited list of valid Audit Types:

```
CREATE

UPDATE

DELETE

READ
```

For instance, in order to only audit Tracker related object creation and deletion, the following property should be added to `dhis.conf`:

```
audit.tracker = CREATE;DELETE
```

In order to completely disable auditing, this is the configuration to use:

```
audit.metadata = DISABLED

audit.tracker = DISABLED

audit.aggregate = DISABLED
```

# Using Gateways for SMS reporting { #sms_report_sending }

DHIS2 supports accepting data via [SMS](https://docs.dhis2.org/master/en/dhis2_user_manual_en/mobile.html), however, the SMS needs to be composed in a cryptic way to protect the information. The DHIS2 Android App acts as a transparent layer to send the information via SMS where the user does not have to worry about writing the SMS. To send SMSs with the Android App the SMS gateway need to be properly configured. This section explains the different options available and how to achieve that.

## Sending SMS { #sms_report_sening }

It is important to clarify firstly, that this section mainly concerns the set up of **receiving SMS** (from mobile devices to the DHIS2 server), which is necessary when considering using the App to send (sync) information recorded in the app to the DHIS2 server via SMS. In the App this can be set-up under the _Settings_ > _SMS Settings_

Sending SMS, i.e. from the DHIS2 server to mobile devices, is relatively simple to set up. If all that is required is the sending of notifications to users phones from DHIS2 when certain events occur (messaging, thresholds e.t.c.) only sending SMS is required.

This can all be configured in the SMS Service Configuration page within the [Mobile Configuration section](https://docs.dhis2.org/master/en/user/html/mobile_sms_service.html).

There is out of the box support for common providers such as _Bulk SMS_ and _Clickatell_, and both providers support sending of SMS to numbers in most countries.

Note also, it is possible to use a different SMS Gateway for sending and receiving SMS. So even if you set up a solution for receiving SMS below, it is still possible to use one of the aforementioned solutions above for sending SMS.

## Using an Android device as SMS Gateway { #sms_report_android_gateway }

The simplest solution by far is to use a dedicated Android device as your SMS Gateway. Any phone or tablet running Android OS (4.4, Kitkat or above) should be fine. It will require a constant internet connection, in order to forward messages to your DHIS2 server and it will also need a SIM card to receive the incoming SMS.

You’ll need to download and install the DHIS2 Android SMS Gateway app on the mobile device. See a list of [releases](https://github.com/dhis2/dhis2-sms-android-gateway/releases) where you can download the latest APK file to install. There are instructions on the app page itself, but essentially you’ll just need to start the app and enter the details of your DHIS2 server (URL, username and password).

Once this is set up and running, you then enter the phone number of this gateway device in the configuration page of any other mobile device using the DHIS2 Capture App. Then, when SMS are sent from these reporting devices, they will be received on the gateway device and automatically forwarded to the DHIS2 server where they will be processed.

**Using this gateway device is perfect when testing the SMS functionality.** It would be fine when piloting projects that require SMS reporting. As long as the device is plugged into a power supply and has a constant internet connection it works well for small scale projects.

However, when considering moving a project to production it would be necessary to investigate one of the more permanent and reliable solutions for gateways below.

### Sending SMS using an Android Device Gateway { #sending-sms-using-an-android-device-gateway }

This option is currently not supported nor documented.

## Dedicated SMS Gateways { #sms_report_dedicated_gateway }

This section discusses the use of more permanent and dedicated SMS gateways and the options available. Each of these options below will involve a provider (or yourself) having an SMPP connection to a phone carrier in country and using this connection to receive incoming SMS and forward them on to your DHIS2 server over the internet using HTTP.

These solutions can either use a **long number** or **short code**. A long number is a standard mobile phone number of the type that most private people use, i.e. +61 400123123. A short code is simply a short number, such as 311. Short codes typically cost more to set up and maintain.

### Ensuring incoming SMS to DHIS2 server are formatted correctly { #ensuring-incoming-sms-to-dhis2-server-are-formatted-correctly }

When sending incoming SMS to a DHIS2 server via the API you use the following URL: _https://<DHIS2_server_url>/api/sms/inbound_

In DHIS2 version 2.34 and below, this endpoint requires the format of inbound SMS to be in a very specific format, i.e. the message itself must be a parameter called text, the phone number of the sender must be a parameter called originator.

When using all of the below SMS gateway options, when you configure them to forward incoming SMS on to another web service, they will each have their own format, which will be different to the one expected by the DHIS2 API. For this reason then, it’s necessary to reformat them before sending them on to the DHIS2 server.

One option is to run your own very simple web service, which simply receives the incoming SMS from the gateway provider, reformats it to the one required for DHIS2 and forwards it on to your DHIS2 API. Such a service would need to be written by a software developer.

In DHIS2 version 2.35, it is planned to support these cases with a templating system for incoming SMS, so you can specify the format of the messages which will be sent from your provider. That way, you can configure the DHIS2 server to accept incoming SMS from any other SMS gateway provider and they can directly send incoming SMS to the DHIS2 API, without the need for such a formatting web service.

### Using RapidPro { #using-rapidpro }

[RapidPro](https://rapidpro.io/) is a service run by UNICEF in over 50 countries around the world. It is a collection of software which works with in-country phone carriers to enable organisations to design SMS solutions for their projects, such as SMS reporting or awareness campaigns.

The RapidPro service will involve an SMPP connection to one or more phone carriers in-country, usually via a shortcode, potentially dedicated to Health work for NGOs. It’s then possible to add a webhook so that incoming SMS are forwarded to another web service, such as the formatting web service described above. If the shortcode is used for other purposes as well, it may be necessary to add the phone numbers of your reporting devices to a separate group, so that only the incoming SMS from those devices is forwarded to the webhook.

RapidPro is currently set up and running in roughly half of the countries which are currently using or piloting DHIS2. Before considering one of the solutions below, which can be costly in terms of both finance and time, it is worth getting in contact with Unicef to see if RapidPro is available and if it can be used for health reporting in your country.

### Using commercial SMS gateway providers { #using-commercial-sms-gateway-providers }

Of the commercial SMS gateway providers mentioned in the Sending SMS section above, they will usually have capability to _send_ SMS in most countries but can only support _receiving_ SMS in a limited amount of countries. The majority of countries they support receiving SMS in are not those using DHIS2. Of the countries that are using DHIS2, most are already covered by having a RapidPro service running in-country.

However, it is worth researching what commercial options are available for your country. In some countries there will be small national companies that provide SMS services, they’ll have existing SMPP connections with the phone providers you can use.

### Using phone carriers directly { #using-phone-carriers-directly }

If none of the above solutions are available it would be necessary to approach the phone carriers in your country directly. The first question to ask them would be whether they are aware of any companies which are operating SMPP connections with them which you may be able to approach.

If not, as a final option, you would need to consider setting up and maintaining your own SMPP connection with the phone provider. However, not all phone providers might offer such a service.

You would need to run your own server running software such as [Kannel](https://www.kannel.org/), which connects (usually via a VPN) to an SMPP service running in the phone providers network. With this in place, any incoming SMS for the configured long number or shortcode are sent from the phone carrier to your Kannel server and you can then forward on these messages as above.

### Receiving concatenated or multipart SMS { #receiving-concatenated-or-multipart-sms }

When syncing data via SMS with the DHIS2 Android App, it uses a compressed format to use as little space (characters of text) as possible. Despite this, it will quite often be the case that a message will extend over the 160 character limit of one standard SMS. On most modern mobile devices these messages will still be sent as one concatenated or multipart SMS, and received as one message. When sending between two mobile devices, when an Android device is used as the gateway, this should be handled without issue.

When selecting an SMS gateway then, it is important to confirm that the phone carrier used supports concatenated SMS. Most of them will support this, but it is important to confirm as the SMS functionality will not work if SMS are split. This relies on something called a UDH (User Data Header). When discussing with providers then, ensure you ask if it is supported.
