---
revision_date: '2020-10-30'
template: single.html
---

# Installation { #installation }

<!--DHIS2-SECTION-ID:installation-->

Le chapitre sur l'installation fournit des informations sur comment installer DHIS2 dans différents contextes, notamment sur le serveur central en ligne, le réseau local hors ligne, l'application autonome et le package autonome appelé DHIS2 Live.

## Présentation { #install_introduction }

<!--DHIS2-SECTION-ID:install_introduction-->

DHIS2 runs on all platforms for which there exists a Java Runtime
Environment version 8 or higher, which includes most popular operating
systems such as Windows, Linux and Mac. DHIS2 runs on the PostgreSQL
database system. DHIS2 is packaged as a standard Java Web Archive
(WAR-file) and thus runs on any Servlet containers such as Tomcat and
Jetty.

The DHIS2 team recommends Ubuntu 16.04 LTS operating system, PostgreSQL
database system and Tomcat Servlet container as the preferred
environment for server installations.

Ce chapitre fournit un guide pour la configuration de la teck stack (pile technologique) ci-dessus. Il doit cependant être lu comme un guide opérationnel et non comme une documentation complète pour l'environnement mentionné. Nous nous référons à la documentation officielle d'Ubuntu, PostgreSQL et Tomcat pour des informations détaillées.

The dhis2-tools Ubuntu package automates many of the tasks described in
the guide below and is recommended for most users, especially those who
are not familiar with the command line or administration of servers. It
is described in detail in a separate chapter in this guide.

## Spécifications du serveur { #install_server_specifications }

<!--DHIS2-SECTION-ID:install_server_specifications-->

DHIS2 est une application très exigeante en matière de base de données et nécessite que votre serveur ait suffisamment de mémoire vive, de cœurs d'unité centrale et de disques rapides. Ces recommandations doivent être considérées comme des règles de base et non comme des mesures exactes. DHIS2 évolue de façon linéaire en fonction de la quantité de RAM et du nombre de cœurs de CPU. Plus vous en avez, mieux l'application performe.

  - *RAM:* At least 1 GB memory per 1 million captured data records per
    month or per 1000 concurrent users. At least 4 GB for a small
    instance, 12 GB for a medium instance.

  - *CPU cores:* 4 CPU cores for a small instance, 8 CPU cores for a
    medium or large instance.

  - *Disk:* Ideally use an SSD. Otherwise use a 7200 rpm disk. Minimum
    minimum est de 150 Mb/s ; 200 Mb/s est bon ; 350 Mb/s ou plus est
    ideal. In terms of disk space, at least 60 GB is recommended, but
    cela dépendra entièrement de la quantité de données contenues dans le
    tableaux des valeurs de données. Les tables d'analyse nécessitent une quantité importante
    disk space. Plan ahead and ensure that your server can be upgraded
    with more disk space as it becomes needed.

## Configuration logicielle requise { #install_software_requirements }

<!--DHIS2-SECTION-ID:install_software_requirements-->

Les versions ultérieures de DHIS2 nécessitent les versions logicielles suivantes pour fonctionner.

  - Java JDK or JRE version 8 or later.

  - Any operating system for which a Java JDK or JRE version 8 exists.

  - PostgreSQL database version 9.6 or later.

  - Extension de base de données PostGIS version 2.2 ou plus.

  - Conteneur de servlet Tomcat version 8.5.50 ou plus, ou autre API de servlet
    Conteneurs de servlets compatibles 3.1.

## Configuration du serveur { #install_server_setup }

<!--DHIS2-SECTION-ID:install_server_setup-->

This section describes how to set up a server instance of DHIS2 on
Ubuntu 16.04 64 bit with PostgreSQL as database system and Tomcat as
Servlet container. This guide is not meant to be a step-by-step guide
per se, but rather to serve as a reference to how DHIS2 can be deployed
on a server. There are many possible deployment strategies, which will
differ depending on the operating system and database you are using, and
other factors. The term *invoke* refers to executing a given command in
a terminal.

For a national server the recommended configuration is a quad-core 2 Ghz
processor or higher and 12 Gb RAM or higher. Note that a 64 bit
operating system is required for utilizing more than 4 Gb of RAM.

For this guide we assume that 8 Gb RAM is allocated for PostgreSQL and 8
GB RAM is allocated for Tomcat/JVM, and that a 64-bit operating system
is used. *If you are running a different configuration please adjust the
suggested values accordingly\!* We recommend that the available memory
is split roughly equally between the database and the JVM. Remember to
leave some of the physical memory to the operating system for it to
perform its tasks, for instance around 2 GB. The steps marked as
*optional*, like the step for performance tuning, can be done at a later
stage.

### Création d'un utilisateur pour exécuter DHIS2 { #install_creating_user }

<!--DHIS2-SECTION-ID:install_creating_user-->

Vous devriez créer un utilisateur dédié pour lancer DHIS2

> **Important**
>
> Vous ne devez pas exécuter le serveur DHIS2 en tant qu'utilisateur privilégié tel que super-utilisateur.

Créez un nouvel utilisateur appelé "dhis" en appelant :

```sh
sudo useradd -d /home/dhis -m dhis -s /bin/false
```

Ensuite, pour définir le mot de passe de votre compte, appelez :

```sh
sudo passwd dhis
```

Créez un mot de passe sécurisé comportant au moins 15 caractères aléatoires.

### Création du répertoire de configuration { #install_creating_config_directory }

<!--DHIS2-SECTION-ID:install_creating_config_directory-->

Commencez par créer un répertoire adapté aux fichiers de configuration de DHIS2. Ce répertoire sera également utilisé pour les applications, les fichiers et les fichiers journaux. Voici un exemple de répertoire :

```sh
mkdir /home/dhis/config
chown dhis:dhis /home/dhis/config
```

DHIS2 will look for an environment variable called *DHIS2\_HOME* to
locate the DHIS2 configuration directory. This directory will be
referred to as *DHIS2\_HOME* in this installation guide. We will define
the environment variable in a later step in the installation process.

### Définition du fuseau horaire et de l'emplacement du serveur { #install_setting_server_tz }

<!--DHIS2-SECTION-ID:install_setting_server_tz-->

Il peut être nécessaire de reconfigurer le fuseau horaire du serveur pour qu'il corresponde au fuseau horaire de l'endroit que le serveur DHIS2 couvrira. Si vous utilisez un serveur privé virtuel, le fuseau horaire par défaut peut ne pas correspondre au fuseau horaire de l'emplacement de votre DHIS2. Vous pouvez facilement reconfigurer le fuseau horaire en appelant la commande ci-dessous et en suivant les instructions.

```sh
sudo dpkg-reconfigure tzdata
```

PostgreSQL est sensible aux paramètres régionaux. Vous devrez donc installer votre emplacement en premier. Pour vérifier les paramètres régionaux existants et en installer de nouveaux (par exemple, Norvégien):

```sh
locale -a
sudo locale-gen nb_NO.UTF-8
```

### Installation de PostgreSQL { #install_postgresql_installation }

<!--DHIS2-SECTION-ID:install_postgresql_installation-->

Install PostgreSQL by
    invoking:

```sh
sudo apt-get install postgresql-10 postgresql-contrib-10 postgresql-10-postgis-2.4
```

Créez un utilisateur non privilégié appelé *dhis* en appelant :

```sh
sudo -u postgres createuser -SDRP dhis
```

Entrez un mot de passe sécurisé à l'invite. Créez une base de données en appelant :

```sh
sudo -u postgres createdb -O dhis dhis2
```

Revenez à votre session en appelant `exit` (sortir). Vous avez maintenant un utilisateur PostgreSQL appelé *dhis* et une base de données appelée *dhis2*.

L'extension *PostGIS* est nécessaire au fonctionnement de plusieurs fonctions SIG/cartographie. DHIS 2 tentera d'installer l'extension PostGIS lors du démarrage. Si l'utilisateur de la base de données DHIS 2 n'a pas l'autorisation de créer des extensions, vous pouvez la créer à partir de la console en utilisant l'utilisateur *postgres* avec les commandes suivantes :

```sh
sudo -u postgres psql -c "create extension postgis;" dhis2
```

Quittez la console et revenez à votre utilisateur précédent en entrant *\\q* suivi de *exit* (quitter).

### Optimisation des performances de PostgreSQL { #install_postgresql_performance_tuning }

<!--DHIS2-SECTION-ID:install_postgresql_performance_tuning-->

Tuning PostgreSQL is necessary to achieve a high-performing system but
is optional in terms of getting DHIS2 to run. PostgreSQL is configured
and tuned through the *postgresql.conf* file which can be edited like
this:

```sh
sudo nano /etc/postgresql/10/main/postgresql.conf
```

et modifez la propriété suivante:

```properties
max_connections = 200
```

Détermine le nombre maximum de connexions autorisées par PostgreSQL.

```properties
shared_buffers = 3200MB
```

Détermine la quantité de mémoire à allouer exclusivement à la mise en cache de PostgreSQL. Ce paramètre contrôle la taille de la mémoire partagée du noyau qui doit être réservée à PostgreSQL. Il doit être fixé à environ 40% de la mémoire totale dédiée à PostgreSQL.

```properties
work_mem = 20MB
```

Détermine la quantité de mémoire utilisée pour les opérations internes de tri et de hachage. Ce paramètre s'applique à chaque connexion et à chaque requête, de sorte qu'une grande quantité de mémoire peut être consommée si cette valeur est trop élevée. Il est essentiel de définir correctement cette valeur pour optimiser les performances d'agrégation de DHIS2.

```properties
maintenance_work_mem = 512MB
```

Détermine la quantité de mémoire que PostgreSQL peut utiliser pour les opérations de maintenance telles que la création d'index, l'exécution du vacuum et l'ajout de clés étrangères. Augmenter cette valeur peut améliorer les performances de création d'index pendant les processus de génération d'analyses.

```properties
effective_cache_size = 8000MB
```

An estimate of how much memory is available for disk caching by the
operating system (not an allocation) and isdb.no used by PostgreSQL to
determine whether a query plan will fit into memory or not. Setting it
to a higher value than what is really available will result in poor
performance. This value should be inclusive of the shared\_buffers
setting. PostgreSQL has two layers of caching: The first layer uses the
kernel shared memory and is controlled by the shared\_buffers setting.
PostgreSQL delegates the second layer to the operating system disk cache
and the size of available memory can be given with the
effective\_cache\_size setting.

```properties
checkpoint_completion_target = 0.8
```

Définit la mémoire utilisée pour la mise en mémoire tampon pendant le processus d'écriture WAL. Augmenter cette valeur peut améliorer le débit dans les systèmes à forte densité d'écriture.

```properties
synchronous_commit = off
```

Spécifie si les transactions doivent attendre que les enregistrements WAL soient écrits sur le disque avant d'être renvoyées au client ou non. Si cette option est désactivée, les performances seront considérablement améliorées. Cela implique également qu'il y aura un léger décalage entre le moment où la transaction au client est déclarée réussie et le moment où elle est réellement sûre, mais l'état de la base de données ne peut pas être corrompu et c'est une bonne alternative pour les systèmes exigeants en termes de performances et d'écriture comme DHIS2.

```properties
wal_writer_delay = 10000ms
```

Spécifie le décalage entre les opérations d'écriture WAL. Y définir une valeur élevée permettra d'améliorer les performances des systèmes à forte densité d'écriture, car de nombreuses opérations d'écriture peuvent être exécutées en un seul vidage sur le disque.

```properties
random_page_cost = 1.1
```

*SSD uniquement*: Définit l'estimation par le planificateur de requêtes du coût d'une page de disque non extraite de manière séquentielle. Une valeur faible incitera le système à préférer les scans d'index aux scans séquentiels. Une valeur faible convient aux bases de données qui fonctionnent sur des disques SSD ou qui sont massivement mises en cache dans la mémoire. La valeur par défaut est 4.0, ce qui est raisonnable pour les disques traditionnels.

```properties
max_locks_per_transaction = 96
```

Spécifie le nombre moyen de verrous d'objets alloués pour chaque transaction. Cette valeur est principalement définie pour permettre la réalisation des mises à niveau de routine qui touchent un grand nombre de tableaux.

Redémarrez PostgreSQL en appelant la commande suivante :

```sh
sudo /etc/init.d/postgresql restart
```

### System configuration { #install_database_configuration } 

<!--DHIS2-SECTION-ID:install_database_configuration-->

The database connection information is provided to DHIS2 through a
configuration file called *dhis.conf*. Create this file and save it in
the *DHIS2\_HOME* directory. As an example this location could be:

```sh
/home/dhis/config/dhis.conf
```

Un fichier de configuration pour PostgreSQL correspondant à la configuration ci-dessus a les propriétés suivantes :

```properties
# ---------------------------------------------------------------------- { #- } 
# Database connection { #database-connection } 
# ---------------------------------------------------------------------- { #- } 

# JDBC driver class { #jdbc-driver-class } 
connection.driver_class = org.postgresql.Driver

# Database connection URL { #database-connection-url } 
connection.url = jdbc:postgresql:dhis2

# Database username { #database-username } 
connection.username = dhis

# Database password { #database-password } 
connection.password = xxxx

# ---------------------------------------------------------------------- { #- } 
# Server { #server } 
# ---------------------------------------------------------------------- { #- } 

# Enable secure settings if deployed on HTTPS, default 'off', can be 'on' { #enable-secure-settings-if-deployed-on-https-default-off-can-be-on } 
server.https = on

# Server base URL { #server-base-url } 
server.base.url = https://server.com/
```

It is strongly recommended to enable the `server.https` setting and deploying DHIS 2 over the encrypted HTTPS protocol. This setting will enable e.g. secure cookies. HTTPS deployment is required when this setting is enabled.

Le paramètre `server.base.url` fait référence à l'URL à laquelle les utilisateurs finaux accèdent au système sur le réseau.

Notez que le fichier de configuration prend en charge les variables d'environnement. Cela signifie que vous pouvez définir certaines propriétés comme variables d'environnement et les résoudre. C'est le cas de l'exemple suivant où `DB_PASSWD` est le nom de la variable d'environnement :

```properties
connection.password = ${DB_PASSWD}
```

Note that this file contains the password for your DHIS2 database in clear
text so it needs to be protected from unauthorized access. To do this, 
invoke the following command which ensures that only the *dhis* user
which owns the file is allowed to read it:

```sh
chmod 0600 dhis.conf
```

### Installation de Java { #install_java_installation }

<!--DHIS2-SECTION-ID:install_java_installation-->

The recommended Java JDK for DHIS 2 is OpenJDK 8. OpenJDK is licensed under 
the GPL license and can be run free of charge. You can install it with the
following command:

```
sudo apt-get install openjdk-8-jdk
```

Vérifiez que votre installation est correcte en appelant :

```
java -version
```

### Installation de Tomcat et DHIS2 { #install_tomcat_dhis2_installation }

<!--DHIS2-SECTION-ID:install_tomcat_dhis2_installation-->

Pour installer le conteneur de servlet Tomcat, nous utiliserons le package utilisateur de Tomcat en appelant :

```sh
sudo apt-get install tomcat8-user
```

This package lets us easily create a new Tomcat instance. The instance
will be created in the current directory. An appropriate location is the
home directory of the *dhis* user:

```sh
cd /home/dhis/
sudo tomcat8-instance-create tomcat-dhis
sudo chown -R dhis:dhis tomcat-dhis/
```

This will create an instance in a directory called *tomcat-dhis*. Note
that the tomcat7-user package allows for creating any number of dhis
instances if that is desired.

Next edit the file *tomcat-dhis/bin/setenv.sh* and add the lines below.
The first line will set the location of your Java Runtime Environment,
the second will dedicate memory to Tomcat and the third will set the
location for where DHIS2 will search for the *dhis.conf* configuration
file. Please check that the path the Java binaries are correct as they
might vary from system to system, e.g. on AMD systems you might see
*/java-8-openjdk-amd64* Note that you should adjust this to your
environment:

```sh
export JAVA_HOME='/usr/lib/jvm/java-1.8.0-openjdk-amd64/'
export JAVA_OPTS='-Xmx7500m -Xms4000m'
export DHIS2_HOME='/home/dhis/config'
```

The Tomcat configuration file is located in
*tomcat-dhis/conf/server.xml*. The element which defines the connection
to DHIS is the *Connector* element with port 8080. You can change the
port number in the Connector element to a desired port if necessary. 
The *relaxedQueryChars* attribute is necessary to allow certain characters 
in URLs used by the DHIS2 front-end.

```xml
<Connector port="8080" protocol="HTTP/1.1"
  connectionTimeout="20000"
  redirectPort="8443"
  relaxedQueryChars="[]" />
```

The next step is to download the DHIS2 WAR file and place it into the
webapps directory of Tomcat. You can download the DHIS2 version 2.31 WAR
release like this (replace 2.31 with your preferred version if
necessary):

```sh
wget https://releases.dhis2.org/2.33/dhis.war
```

Alternatively, for patch releases, the folder structure is based on the patch
release ID in a subfolder under the main release. E.g. you can download
the DHIS2 version 2.31.1 WAR release like this (replace 2.31 with your
preferred version, and 2.31.1 with you preferred patch, if necessary):

```
wget https://releases.dhis2.org/2.33/2.33.1/dhis.war
```

Move the WAR file into the Tomcat webapps directory. We want to call the
WAR file ROOT.war in order to make it available at localhost directly
without a context path:

```sh
mv dhis.war tomcat-dhis/webapps/ROOT.war
```

DHIS2 should never be run as a privileged user. After you have modified
the setenv.sh file, modify the startup script to check and verify that the
script has not been invoked as root.

```sh
#!/bin/sh { #binsh } 
set -e

if [ "$(id -u)" -eq "0" ]; then
  echo "This script must NOT be run as root" 1>&2
  exit 1
fi

export CATALINA_BASE="/home/dhis/tomcat-dhis"
/usr/share/tomcat8/bin/startup.sh
echo "Tomcat started"
```

### Fonctionnement de DHIS2 { #install_running_dhis2 }

<!--DHIS2-SECTION-ID:install_running_dhis2-->

DHIS2 peut désormais être lancé en appelant :

    sudo -u dhis tomcat-dhis/bin/startup.sh

> **Important**
>
> Le serveur DHIS2 ne doit jamais être exécuté en mode super-utilisateur ou autre utilisateur privilégié.

DHIS2 peut être arrêté en appelant :

    sudo -u dhis tomcat-dhis/bin/shutdown.sh

Pour surveiller le comportement de Tomcat, le journal est la principale source d'information. Le journal peut être consulté avec la commande suivante :

    tail -f tomcat-dhis/logs/catalina.out

En supposant que le fichier WAR s'appelle ROOT.war, vous pouvez maintenant accéder à votre instance DHIS2 à l'URL suivante :

    http://localhost:8080

## Configuration de l'entrepôt de fichiers { #install_file_store_configuration }

<!--DHIS2-SECTION-ID:install_file_store_configuration-->

DHIS2 is capable of capturing and storing files. By default, files will
be stored on the local file system of the server which runs DHIS2 in a *files*
directory under the *DHIS2\_HOME* external directory location. 

You can also configure DHIS2 to store files on cloud-based storage
providers. AWS S3 is the only supported provider currently. To enable
cloud-based storage you must define the following additional properties
in your *dhis.conf* file:

```properties
# File store provider. Currently 'filesystem' and 'aws-s3' are supported. { #file-store-provider-currently-filesystem-and-aws-s3-are-supported } 
filestore.provider = 'aws-s3'

# Directory in external directory on local file system and bucket on AWS S3 { #directory-in-external-directory-on-local-file-system-and-bucket-on-aws-s3 } 
filestore.container = files

# The following configuration is applicable to cloud storage only (AWS S3) { #the-following-configuration-is-applicable-to-cloud-storage-only-aws-s3 } 

# Datacenter location. Optional but recommended for performance reasons. { #datacenter-location-optional-but-recommended-for-performance-reasons } 
filestore.location = eu-west-1

# Username / Access key on AWS S3 { #username-access-key-on-aws-s3 } 
filestore.identity = xxxx

# Password / Secret key on AWS S3 (sensitive) { #password-secret-key-on-aws-s3-sensitive } 
filestore.secret = xxxx
```

Cette configuration est un exemple qui reflète les paramètres par défaut et doit être modifiée en fonction de vos besoins. En d'autres termes, vous pouvez l'omettre complètement si vous prévoyez d'utiliser les valeurs par défaut. Si vous voulez utiliser un fournisseur externe, le dernier bloc de propriétés doit être défini, et la propriété *fournisseur* doit être réglée sur un fournisseur pris en charge (actuellement, c'est uniquement AWS S3).

> **Remarque**
>
> Si vous avez configuré le stockage SUR cloud dans dhis.conf, tous les fichiers que vous téléchargez
> ou les fichiers générés par le système utiliseront le stockage sur cloud.

Pour un système de production, la configuration initiale de l'entrepôt de fichiers doit être soigneusement étudiée, car le déplacement des fichiers entre les fournisseurs de stockage tout en conservant l'intégrité des références de la base de données peut s'avérer complexe. Gardez à l'esprit que le contenu de l'entrepôt de fichiers peut contenir des informations sensibles et intégrales et qu'il est recommandé de protéger l'accès au dossier et de s'assurer qu'un plan de sauvegarde est prévu dans le cadre d'une implémentation de production.

> **Remarque**
>
> AWS S3 est le seul fournisseur pris en charge, mais d'autres fournisseurs devraient
> être ajoutés à l'avenir, comme Google Cloud Store et Azure Blob Storage.
> Faites-nous savoir si vous avez un cas d'utilisation pour des fournisseurs supplémentaires.

## Configuration du compte de service Google { #install_google_service_account_configuration }

<!--DHIS2-SECTION-ID:install_google_service_account_configuration-->

DHIS2 peut se connecter à plusieurs API de services Google. Par exemple, le SIG de DHIS2 peut utiliser l'API de Google Earth Engine pour charger des couches de cartes. Pour fournir des jetons d'accès à l'API, vous devez configurer un compte de service Google et créer une clé privée :

  - Créez un compte de service Google. Veuillez consulter la [plateforme d'identification
    plateforme](https://developers.google.com/identity/protocols/OAuth2ServiceAccount#overview)
     

  - Visitez la [Console Google Cloud](https://console.cloud.google.com)
    et allez dans API Manager \> Identifiants \> Créer des identifiants \>
    Clé du compte de service. Sélectionnez votre compte de service et JSON comme type de
    clé et cliquez sur Créer.

  - Renommez la clé JSON en *dhis-google-auth.json*.

After downloading the key file, put the *dhis-google-auth.json* file in
the DHIS2\_HOME directory (the same location as the *dhis.conf* file).
As an example this location could be:

    /home/dhis/config/dhis-google-auth.json

## Configuration de LDAP { #install_ldap_configuration }

<!--DHIS2-SECTION-ID:install_ldap_configuration-->

DHIS2 peut utiliser un serveur LDAP pour l'authentification des utilisateurs.
L'authentification LDAP nécessite que chaque entrée corresponde à un utilisateur dans la base de données DHIS2. L'utilisateur DHIS2 sera utilisé pour représenter des autorités / rôles d’utilisateur.

To set up LDAP authentication you need to configure the LDAP server URL,
a manager user and an LDAP search base and search filter. This
configuration should be done in the main DHIS 2 configuration file
(dhis.conf). LDAP users, or entries, are identified by distinguished
names (DN from now on). An example configuration looks like this:

```properties
# LDAP server URL { #ldap-server-url } 
ldap.url = ldaps://domain.org:636

# LDAP manager entry distinguished name { #ldap-manager-entry-distinguished-name } 
ldap.manager.dn = cn=johndoe,dc=domain,dc=org

# LDAP manager entry password { #ldap-manager-entry-password } 
ldap.manager.password = xxxx

# LDAP base search { #ldap-base-search } 
ldap.search.base = dc=domain,dc=org

# LDAP search filter { #ldap-search-filter } 
ldap.search.filter = (cn={0})
```

Les propriétés de configuration LDAP sont expliquées ci-dessous :

  - *ldap.url :* L'URL du serveur LDAP avec lequel s'authentifier
    L'utilisation du SSL ou du cryptage est fortement recommandée afin de
    sécuriser l’authentification. Prenons l'exemple de l'URL suivant
    *ldaps://domain.org:636*, où ldaps fait référence au protocole,
    *domain.org* fait référence au nom de domaine ou à l'adresse IP, et *636*
    fait référence au port (636 est la valeur par défaut pour LDAPS).

  - *ldap.manager.dn:* Un utilisateur du gestionnaire LDAP doit être relié au 
    serveur LDAP pour permettre le processus d'authentification des utilisateurs. 
    fait référence au DN de cette entrée, c'est à dire que ce n'est pas l'utilisateur qui va
    authentifié lors de la connexion à DHIS2, mais plutôt l'utilisateur qui
    est relié au serveur LDAP afin d'effectuer l'authentification.

  - *ldap.manager.password :* Le mot de passe de l'utilisateur du gestionnaire LDAP.

  - *ldap.search.base :* La base de recherche ou le nom unique de
    l'objet de la base de recherche, qui définit l'emplacement dans le répertoire
    à partir duquel commence la recherche LDAP.

  - *ldap.search.filter :* Le filtre permettant de faire correspondre les DN des entrées dans le
    répertoire LDAP. La variable {0} sera remplacée par le nom d'utilisateur DHIS2,
    ou autrement, l'identifiant LDAP défini pour l'utilisateur
    avec le nom d'utilisateur fourni.

DHIS2 utilisera le nom d'utilisateur et le mot de passe fournis pour essayer de s'authentifier avec une entrée du serveur LDAP, puis recherchera des rôles/autorités d'utilisateur auprès d'un utilisateur DHIS2 correspondant. Cela implique qu'un utilisateur doit avoir une entrée correspondante dans le répertoire LDAP ainsi qu'un utilisateur DHIS2 pour pouvoir se connecter.

Lors de l'authentification, DHIS2 essaiera de se connecter au serveur LDAP en utilisant l'URL du serveur LDAP configuré ainsi que le DN et le mot de passe du gestionnaire. Une fois la connexion établie, il recherche une entrée dans le répertoire à l'aide de la base de recherche LDAP et du filtre de recherche configurés.

La variable {0} du filtre configuré sera remplacée avant l'application du filtre. Par défaut, elle sera remplacée par le nom d'utilisateur fourni. Vous pouvez également définir un identifiant LDAP personnalisé pour le compte utilisateur DHIS2 concerné. Vous pouvez le faire via l'interface utilisateur du module utilisateur DHIS2 sur l'écran d'ajout ou d'édition en définissant la propriété "Identifiant LDAP". Une fois définie, l'identifiant LDAP remplacera la variable {0} dans le filtre. Cette fonction est utile lorsque le nom commun LDAP ne convient pas ou ne peut pas, pour une raison quelconque, être utilisé comme nom d'utilisateur DHIS2.

## Configuration du cryptage{ #install_encryption_configuration }

<!--DHIS2-SECTION-ID:install_encryption_configuration-->

DHIS2 allows for encryption of data. This however requires some extra
setup. To provide security to the encryption algorithm you will have to set a
password in the *dhis.conf* configuration file through the
*encryption.password* property:

```properties
encryption.password = xxxx
```

The *encryption.password* property is the password used when encrypting
and decrypting data in the database. Note that the password must not be
changed once it has been set and data has been encrypted as the data can
then no longer be decrypted. 

The password must be at least **24 characters long**. A mix of numbers 
and lower- and uppercase letters are recommended. The encryption password 
must be kept secret.

> **Important**
>
> A word of caution: It is not possible to recover encrypted data if the
> encryption password is lost or changed. If the password is lost, so is 
> the encrypted data.Conversely, the encryption provides no security if 
> the password is compromised. Hence, great consideration should be given 
> to storing the password in a safe place.

## Configuration de la base de données réplica en lecture { #install_read_replica_configuration }

<!--DHIS2-SECTION-ID:install_read_replica_configuration-->

DHIS 2 permet d'utiliser des réplicas en lecture seule de la base de données principale (la base de données principale de DHIS 2). L'objectif des réplicas en lecture est d'améliorer les performances des requêtes en lecture de la base de données et d'augmenter les capacités au-delà des contraintes d'une seule base de données. Les opérations à forte intensité de lecture en bénéficieront, notamment les requêtes d'analyse et les requêtes d'événements.

La configuration exige que vous ayez créé une ou plusieurs instances répliquées de la base de données principale de DHIS 2. PostgreSQL permet de le faire grâce à un concept appelé *réplication en flux*. La configuration des réplicas en lecture pour PostgreSQL n'est pas abordée dans ce guide.

Read replicas can be defined in the *dhis.conf* configuration file. You
can specify up to 5 read replicas per DHIS 2 instance. Each read replica
is denoted with a number between 1 and 5. The JDBC connection URL must
be defined per replica. The username and password can be specified; if
not, the username and password for the master database will be used
instead.

The configuration for read replicas in *dhis.conf* looks like the below.
Each replica is specified with the configuration key *readN* prefix,
where N refers to the replica number.

```properties
# Read replica 1 configuration { #read-replica-1-configuration } 

# Database connection URL, username and password { #database-connection-url-username-and-password } 
read1.connection.url = jdbc:postgresql://127.0.0.11/dbread1
read1.connection.username = dhis
read1.connection.password = xxxx

# Read replica 2 configuration { #read-replica-2-configuration } 

# Database connection URL, username and password { #database-connection-url-username-and-password } 
read2.connection.url = jdbc:postgresql://127.0.0.12/dbread2
read2.connection.username = dhis
read2.connection.password = xxxx

# Read replica 3 configuration { #read-replica-3-configuration } 

# Database connection URL, fallback to master for username and password { #database-connection-url-fallback-to-master-for-username-and-password } 
read3.connection.url = jdbc:postgresql://127.0.0.13/dbread3
```

Vous devez redémarrer votre conteneur de servlets pour que les modifications s'appliquent. DHIS 2 répartira automatiquement la charge entre les réplicas en lecture. L'ordre des réplicas n'a pas d'importance.

## Configuration du cluster de serveur Web { #install_web_server_cluster_configuration }

<!--DHIS2-SECTION-ID:install_web_server_cluster_configuration-->

Cette section décrit comment configurer l'application  DHIS 2 pour qu'elle s'exécute dans un cluster.

### Présentation du clustering { #install_cluster_configuration_introduction }

<!--DHIS2-SECTION-ID:install_cluster_configuration_introduction-->

Le clustering est une technique courante permettant d'améliorer l'évolutivité et la disponibilité du système. Elle consiste à installer plusieurs serveurs web, par exemple des instances Tomcat, pour qu'ils servent une seule application. Le clustering permet d'*étendre* une application de manière à ce que de nouveaux serveurs puissent être ajoutés afin d'améliorer ses performances. Elle garantit également une *grande disponibilité*, car le système peut tolérer que des instances tombent en panne sans pour autant rendre le système inaccessible aux utilisateurs.

Quelques paramètres doivent être configurés pour que DHIS 2 s'exécute dans un cluster.

* Each DHIS 2 instance must specify the other DHIS 2 instance members of 
the cluster in *dhis.conf*.

* Un entrepôt de données Redis doit être installé et les informations de connexion doivent
be provided for each DHIS 2 application instance in *dhis.conf*.

* Les instances et les serveurs DHIS 2 doivent partager le même dossier *fichiers* utilisé pour 
les applications et les téléchargements de fichiers, soit par l'intermédiaire de l'option de *stockage de fichiers cloud AWS S3*, 
soit par un lecteur réseau partagé.

* A load balancer such as nginx must be configured to distribute Web requests
dans les instances du cluster.

### DHIS 2 instance cluster configuration { #install_cluster_configuration } 

<!--DHIS2-SECTION-ID:install_cluster_configuration-->

When setting up multiple Tomcat instances there is a need for making the
instances aware of each other. This awareness will enable DHIS 2 to keep
the local data (Hibernate) caches in sync and in a consistent state.
When an update is done on one instance, the caches on the other
instances must be notified so that they can be invalidated and avoid
becoming stale.

A DHIS 2 cluster setup is based on manual configuration of each
instance. For each DHIS 2 instance one must specify the public
*hostname* as well as the hostnames of the other instances participating
in the cluster.

The hostname of the server is specified using the *cluster.hostname*
configuration property. Additional servers which participate in the
cluster are specified using the *cluster.members* configuration
property. The property expects a list of comma separated values where
each value is of the format *host:port*.

The hostname must be visible to the participating servers on the network
for the clustering to work. You might have to allow incoming and
outgoing connections on the configured port numbers in the firewall.

The port number of the server is specified using the *cluster.cache.port*
configuration property. The remote object port used for registry receive
calls is specified using *cluster.cache.remote.object.port*. Specifying
the port numbers is typically only useful when you have multiple cluster
instances on the same server or if you need to explicitly specify the ports 
to match a firewall configuration. When running cluster instances on separate 
servers it is often appropriate to use the default port number and omit 
the ports configuration properties. If omitted, 4001 will be assigned as 
the listener port and a random free port will be assigned as the remote 
object port.

An example setup for a cluster of two web servers is described below.
For *server A* available at hostname *193.157.199.131* the following can
be specified in *dhis.conf*:

```properties
# Cluster configuration for server A { #cluster-configuration-for-server-a } 

# Hostname for this web server { #hostname-for-this-web-server } 
cluster.hostname = 193.157.199.131

# Ports for cache listener, can be omitted { #ports-for-cache-listener-can-be-omitted } 
cluster.cache.port = 4001
cluster.cache.remote.object.port = 5001

# List of Host:port participating in the cluster { #list-of-hostport-participating-in-the-cluster } 
cluster.members = 193.157.199.132:4001
```

For *server B* available at hostname *193.157.199.132* the following can
be specified in *dhis.conf* (notice how port configuration is omitted):

```properties
# Cluster configuration for server B { #cluster-configuration-for-server-b } 

# Hostname for this web server { #hostname-for-this-web-server } 
cluster.hostname = 193.157.199.132

# List of servers participating in cluster { #list-of-servers-participating-in-cluster } 
cluster.members = 193.157.199.131:4001
```

You must restart each Tomcat instance to make the changes take effect.
The two instances have now been made aware of each other and DHIS 2 will
ensure that their caches are kept in sync.

### Configuration du cluster de stockage de données partagé Redis { #install_cluster_configuration_redis }

<!--DHIS2-SECTION-ID:install_cluster_configuration_redis-->

In a cluster setup, a *Redis* instance is required and will handle
shared user sessions, application cache and cluster node leadership.

For optimum performance, *Redis Keyspace events* for _generic commands_ 
and _expired events_ need to be enabled in the Redis Server. If you are 
using a cloud platform-managed Redis server (like *AWS ElastiCache for Redis* 
or *Azure Cache for Redis*) you will have to enable keyspace event notifications 
using the respective cloud console interfaces. If you are setting up a standalone 
Redis server, enabling keyspace event notifications can be done in the 
*redis.conf* file by adding or uncommenting the following line:

```
notify-keyspace-events Egx
```

DHIS2 will connect to Redis if the *redis.enabled* configuration
property in *dhis.conf* is set to *true* along with the following properties:

- *redis.host* : Spécifie où le serveur Redis est exécuté. La valeur par défaut est *localhost*. Obligatoire.

- *redis.port* : Spécifie le port sur lequel le serveur Redis écoute. La valeur par défaut est *6379*. Facultatif.

- *redis.password* : Spécifie le mot de passe d'authentification. Si un mot de passe n'est pas nécessaire, il peut rester vide.

- *redis.use.ssl* : Spécifie si SSL est activé sur le serveur Redis. La valeur par défaut est *faux*. Facultatif.

When Redis is enabled, DHIS2 will automatically assign one of the
running instances as the leader of the cluster. The leader instance will
be used to execute jobs or scheduled tasks that should be run
exclusively by one instance. Optionally you can configure the
*leader.time.to.live.minutes* property in *dhis.conf* to set up how
frequently the leader election needs to occur. It also gives an
indication of how long it would take for another instance to take over
as the leader after the previous leader has become unavailable. The
default value is 2 minutes. Note that assigning a leader in the cluster
is only done if Redis is enabled. An example snippet of the *dhis.conf*
configuration file with Redis enabled and leader election time
configured is shown below.

```properties
# Redis Configuration { #redis-configuration } 

redis.enabled = true

redis.host = 193.158.100.111

redis.port = 6379

redis.password = <your password>

redis.use.ssl = false

# Optional, defaults to 2 minutes { #optional-defaults-to-2-minutes } 
leader.time.to.live.minutes=4 
```

### Configuration du dossier de fichiers { #files-folder-configuration }

DHIS 2 va stocker plusieurs types de fichiers hors de l'application elle-même, tels que des applications, des fichiers sauvegardés lors de saisies de données et des avatars d'utilisateurs. Lorsqu'il est déployé dans un cluster, l'emplacement de ces fichiers doit être partagé entre toutes les instances. Sur le système de fichiers local, l'emplacement est le suivant :

```
{DHIS2_HOME}/files
```

Ici, `DHIS2_HOME` fait référence à l'emplacement du fichier de configuration DHIS 2 tel que spécifié par la variable d'environnement DHIS 2, et `fichiers` est le dossier de fichiers immédiatement en dessous.

Il existe deux manières d'obtenir un emplacement partagé :

* Utiliser l'option *Stockage de fichiers cloud AWS S3*. Les fichiers seront stockés dans un
compartiment S3 qui est automatiquement partagé entre toutes les instances DHIS 2 présentes dans le cluster.
Consulter la section *Configuration de l'entrepôt de fichiers* pour obtenir des conseils.
* Configurer un dossier partagé entre toutes les instances et tous les serveurs DHIS 2 
présents dans le cluster. Sur Linux, cela peut être réalisé avec *NFS* (Network File System)
qui est un protocole de système de fichiers en réseau. Notez que seuls les sous-dossiers `fichiers`
sous `DHIS2_HOME` doit être partagé, pas le dossier parent.

### Configuration de l'équilibreur de charge { #install_load_balancing }

<!--DHIS2-SECTION-ID:install_load_balancing-->

Lorsqu'un cluster d'instances Tomcat est installé, un *équilibreur de charge* peut être utilisé pour acheminer les requêtes web entrantes vers les instances backend du cluster. Un équilibreur de charge veille à ce que la charge soit répartie uniformément entre les instances du cluster. Il détectera également l'indisponibilité d'une instance et, le cas échéant, arrêtera les requêtes de routine vers cette instance et utilisera les autres instances disponibles.

L'équilibrage de la charge peut être réalisé de plusieurs manières. *nginx* est une approche simple. En l'utilisant, vous devrez définir un élément *upstream* qui énumère l'emplacement des instances backend, puis utiliser cet élément dans le bloc d'emplacement *proxy*.

```text
http {

  # Upstream element with sticky sessions

  upstream dhis_cluster {
    ip_hash;
    server 193.157.199.131:8080;
    server 193.157.199.132:8080;
  }

  # Proxy pass to backend servers in cluster

  server {
    listen 80;

    location / {
      proxy_pass   http://dhis_cluster/;
    }
  }
}  
```

DHIS 2 conserve l'état des sessions utilisateur côté serveur dans une certaine mesure. L'utilisation de "sessions persistantes" est une approche simple qui permet d'éviter de reproduire l'état de la session du serveur en acheminant les demandes d'un même client vers le même serveur. La directive *ip\_hash* de l'élément upstream garantit cette fonction.

Plusieurs instructions ont été omises par souci de concision dans l'exemple ci-dessus. Consultez la section proxy inverse pour obtenir un guide détaillé.

## Analytics cache configuration { #install_analytics_cache_configuration } 

<!--DHIS2-SECTION-ID:install_analytics_cache_configuration-->

DHIS 2 supports a server-side cache for analytics API responses, used by all of the analytics web apps. This cache sits within the DHIS 2 application and hence is protected by the DHIS 2 authentication and security layer. You can configure the expiration of cached entries in seconds. To enable the cache you can define the `analytics.cache.expiration` property in `dhis.conf`. The example below enabled the cache and sets expiration to one hour.

```properties
analytics.cache.expiration = 3600
```

## Surveillance { #monitoring }

DHIS 2 peut exporter des métriques compatibles avec Prometheus pour la surveillance des instances DHIS2. L'infrastructure de surveillance de DHIS2 est conçue pour exposer les métriques liées à l'exécution de l'application et d'autres informations relatives à l'application.

Les métriques liées à l'infrastructure (telles que les métriques de l'hôte, Tomcat ou Postgres) ne sont pas directement exposées par le moteur de surveillance de l'application et doivent être collectées séparément. Les métriques actuellement exposées par l'application sont :

- API DHIS 2 (temps de réponse, nombre d'appels, etc.)
- JVM (taille du tas, récupération de l'espace mémoire, etc.)
- Mise en veille prolongée (requêtes, cache, etc.)
- C3P0 Database pool
- Disponibilité des applications
- CPU

La surveillance peut être activé dans `dhis.conf` avec les propriétés suivantes (la valeur par défaut est `désactivé` pour toutes les propriétés) :

```propriétés
surveillance.api.enabled = activé
surveillance.jvm.enabled = activé
surveillance.dbpool.enabled = activé
surveillance.hibernate.enabled = désactivé
surveillance.uptime.enabled = activé
surveillance.cpu.enabled = activé
```

The recommended approach for collecting and visualizing these metrics is through Prometheus and Grafana. For more information, see the [monitoring infrastructure](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md) page and the [Prometheus and Grafana install](https://docs.dhis2.org/master/en/dhis2_system_administration_guide/monitoring.html) chapter.

## Configuration du proxy inverse { #install_reverse_proxy_configuration }

<!--DHIS2-SECTION-ID:install_reverse_proxy_configuration-->

Un proxy inverse est un serveur proxy qui agit pour le compte d'un autre serveur. L'utilisation d'un proxy inverse en combinaison avec un conteneur de servlets n'est pas obligatoire mais présente de nombreux avantages :

  - Les requêtes peuvent être mises en correspondance et transmises à plusieurs conteneurs de servlets.
    Cela rend le système plus flexible et facilite l'exécution de plusieurs
    instances DHIS2 sur un même serveur. Cela permet également de
    modifier la configuration du serveur interne sans affecter les clients.

  - L'application DHIS2 peut être exécutée dans un mode autre que super-utilisateur sur un port
    différent de 80, ce qui réduit la vulnérabilité face au piratage de
    détournement.

  - Le proxy inverse peut agir comme un serveur SSL unique et être configuré
    pour inspecter les demandes de contenu malveillant, enregistrer les demandes et
    les réponses et fournir des messages d'erreur non sensibles qui
    améliorer la sécurité.

### Configuration de base de Nginx { #install_basic_nginx_setup }

<!--DHIS2-SECTION-ID:install_basic_nginx_setup-->

Nous vous recommandons d'utiliser [nginx](http://www.nginx.org) comme proxy inverse en raison de sa faible empreinte mémoire et sa facilité d'utilisation. Pour l'installer, appelez la commande suivante :

    sudo apt-get install nginx

nginx peut maintenant être lancé, rechargé et arrêté avec les commandes suivantes :

    sudo /etc/init.d/nginx start
    sudo /etc/init.d/nginx reload
    sudo /etc/init.d/nginx stop

Now that we have installed nginx we will now continue to configure
regular proxying of requests to our Tomcat instance, which we assume
runs at *http://localhost:8080*. To configure nginx you can open the
configuration file by invoking:

    sudo nano /etc/nginx/nginx.conf

La configuration de nginx se fait autour d'une hiérarchie de blocs représentant le http, le serveur et l'emplacement, où chaque bloc hérite des paramètres des blocs parents. L'extrait suivant va configurer nginx pour qu'il passe (redirige) les requêtes du port 80 (qui est le port sur lequel nginx écoute par défaut) vers notre instance Tomcat. Ajoutez la configuration suivante dans le fichier nginx.conf :

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  server {
    listen               80;
    client_max_body_size 10M;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  http;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

Vous pouvez désormais accéder à votre instance DHIS2 à l'adresse *http://localhost*. Etant donné que le proxy inverse a été installé, nous pouvons améliorer la sécurité en configurant Tomcat pour qu'il n'écoute que les connexions locales. Dans */conf/server.xml*, vous pouvez ajouter un attribut *address* avec la valeur *localhost* à l'élément Connector pour HTTP 1.1 comme suit :

```xml
<Connector address="localhost" protocol="HTTP/1.1" />
```

### Activation de SSL avec nginx { #install_enabling_ssl_on_nginx }

<!--DHIS2-SECTION-ID:install_enabling_ssl_on_nginx-->

Afin d'améliorer la sécurité, il est recommandé de configurer le serveur qui exécute DHIS2 de manière à ce qu'il communique avec les clients via une connexion cryptée et de s'identifier auprès des clients à l'aide d'un certificat de confiance. Ceci peut être réalisé via SSL qui est un protocole de communication cryptographique fonctionnant sur TCP/IP. Tout d’abord, installez la bibliothèque *openssl* requise :

    sudo apt-get install openssl

Pour configurer nginx de manière à ce qu'il utilise SSL, vous aurez besoin d'un certificat SSL approprié provenant d'un fournisseur SSL. Le coût d'un certificat varie en fonction de la puissance du cryptage. Un certificat abordable de [Rapid SSL Online (http://www.rapidsslonline.com) devrait répondre à la plupart des besoins. Pour générer le CSR (demande de signature de certificat), vous pouvez appeler la commande ci-dessous. À l'invite du *Nom commun*, entrez le nom du domaine qualifié pour le site que vous sécurisez.

    openssl req -new -newkey rsa:2048 -nodes -keyout server.key -out server.csr

Après avoir reçu vos fichiers de certificat (.pem ou .crt), vous devez les placer avec le fichier server.key généré, dans un emplacement accessible par nginx. Le répertoire où se trouve votre fichier nginx.conf peut servir d'emplacement à cet effet.

Below is an nginx server block where the certificate files are named
server.crt and server.key. Since SSL connections usually occur on port
443 (HTTPS) we pass requests on that port (443) on to the DHIS2 instance
running on *http://localhost:8080* The first server block will rewrite
all requests connecting to port 80 and force the use of HTTPS/SSL. This
is also necessary because DHIS2 is using a lot of redirects internally
which must be passed on to use HTTPS. Remember to replace
*\<server-ip\>* with the IP of your server. These blocks should replace
the one from the previous section.

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  # HTTP server - rewrite to force use of SSL

  server {
    listen     80;
    rewrite    ^ https://<server-url>$request_uri? permanent;
  }

  # HTTPS server

  server {
    listen               443 ssl;
    client_max_body_size 10M;

    ssl                  on;
    ssl_certificate      server.crt;
    ssl_certificate_key  server.key;

    ssl_session_cache    shared:SSL:20m;
    ssl_session_timeout  10m;

    ssl_protocols              TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers                RC4:HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

Notez la dernière valeur de l'en-tête `https` qui est nécessaire pour informer le conteneur de servlets que la requête arrive par HTTPS. Pour que Tomcat produise correctement les en-têtes d'URL d'`Emplacement` en utilisant HTTPS, vous devez également ajouter deux autres paramètres au Connector dans le fichier `server.xml` de Tomcat :

```xml
<Connector scheme="https" proxyPort="443" />
```

### Activation de la mise en cache avec nginx { #install_enabling_caching_ssl_nginx }

<!--DHIS2-SECTION-ID:install_enabling_caching_ssl_nginx-->

Les demandes de rapports, de graphiques, de cartes et d'autres ressources liées à l'analyse mettent souvent un certain temps avant de recevoir des réponses et peuvent utiliser une grande partie des ressources du serveur. Afin d'améliorer les temps de réponse, de réduire la charge sur le serveur et d'éviter d'éventuels temps d'arrêt, nous pouvons introduire un proxy de cache dans notre configuration de serveur. Le contenu mis en cache sera stocké dans le répertoire /var/cache/nginx, et jusqu'à 250 Mo de stockage y seront alloués. Nginx créera ce répertoire automatiquement.

```text
http {
  ..
  proxy_cache_path  /var/cache/nginx  levels=1:2  keys_zone=dhis:250m  inactive=1d;


  server {
    ..

    # Proxy pass to servlet container and potentially cache response

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
      proxy_cache               dhis;
    }
  }
}
```

**Important**
> >>>>>>>>
Sachez qu'un cache côté serveur court-circuite les fonctions de sécurité de DHIS2 dans le sens où les requêtes qui atteignent le cache côté serveur seront servies directement à partir du cache hors de contrôle de DHIS2 et du conteneur de servlets. Cela signifie que les URL des requêtes peuvent être devinées de même que les rapports récupérés dans le cache par des utilisateurs non autorisés. Par conséquent, si vous collectez des informations sensibles, la mise en place d'un cache côté serveur n'est pas recommandée.

### Limitation de débit avec nginx { #install_rate_limiting }

<!--DHIS2-SECTION-ID:install_rate_limiting-->

Certains appels d'API web dans DHIS 2, tels que les API d'`analyses`, nécessitent beaucoup de calculs. Par conséquent, il est préférable de limiter le débit de ces API afin d'équilibrer l'utilisation des ressources du serveur par les utilisateurs du système. La limitation de débit peut être effectuée avec `nginx`. Il existe plusieurs approches pour effectuer la limitation de débit et ceci est destiné à documenter l'approche basée sur nginx.

La configuration nginx ci-dessous limitera le débit de l'API Web des `analyses` et comporte les éléments suivants au niveau des blocs *http* et *emplacement* (la configuration est abrégée par souci de concision) :

```text
http {
  ..
  limit_req_zone $binary_remote_addr zone=limit_analytics:10m rate=5r/s;

  server {
    ..

    location ~ ^/api/(\d+/)?analytics(.*)$ {
      limit_req    zone=limit_analytics burst=20;
      proxy_pass   http://localhost:8080/api/$1analytics$2$is_args$args;
      ..
    }
  }
}
```

Les différents éléments de la configuration peuvent être décrits comme suit :

- *limit_req_zone $binary_remote_addr* : la limitation du débit est effectuée par adresse IP de requête.
- *zone=limit_analytics:20m* : une zone de limite de débit pour l'API des analyses qui peut contenir jusqu'à 10 Mo d'adresses IP de requête.
- *taux=20r/s* : Chaque IP reçoit 5 requêtes par seconde.
- *emplacement ~ ^/api/(\d+/)?analytics(.\*)$* : les requêtes pour le point d'extrémité de l'API des analyses sont limitées en débit.
- *burst=20* : des rafales contenant jusqu'à 20 requêtes seront mises en file d'attente et traitées ultérieurement ; des demandes supplémentaires conduiront à un `503`.

Pour obtenir une explication complète, veuillez consulter la [documentation nginx](https://www.nginx.com/blog/rate-limiting-nginx/).

### Rendre les ressources disponibles avec nginx { #install_making_resources_available_with_nginx }

<!--DHIS2-SECTION-ID:install_making_resources_available_with_nginx-->

Dans certains cas, il est souhaitable de rendre certaines ressources accessibles au public sur le web sans exiger une quelconque authentification. C'est le cas, par exemple, lorsque vous souhaitez rendre les ressources liées à l'analyse des données de l'API Web disponibles dans un portail Web. L'exemple suivant permet d'accéder aux graphiques, aux cartes, aux rapports, aux tableaux de rapports et aux ressources documentaires par le biais d'une authentification de base en insérant un en-tête HTTP d'*Autorisation* dans la demande. Il supprimera l'en-tête Cookie de la requête et l'en-tête Set-Cookie de la réponse afin d'éviter de modifier l'utilisateur connecté. Il est recommandé de créer un utilisateur à cette fin, en ne lui accordant que les autorisations minimales requises. La valeur d'autorisation peut être construite en codant le nom d'utilisateur avec base64, suivi de deux points et le mot de passe et en lui ajoutant le préfixe "Basic", plus précisément "Basic base64_encode(nom d'utilisateur:mot de passe)". Il vérifiera la méthode HTTP utilisée pour les requêtes et renverra *405 Method Not Allowed* s'il détecte autre chose que GET.

En utilisant cette approche, il peut être avantageux de créer un domaine séparé pour les utilisateurs publics. En effet, nous ne voulons pas modifier les informations d'identification des utilisateurs déjà connectés lorsqu'ils accèdent aux ressources publiques. Par exemple, si votre serveur est déployé à l'adresse somedomain.com, vous pouvez créer un sous-domaine dédié à api.somedomain.com et orienter les URL de votre portail vers ce sous-domaine.

```text
http {
  ..

  server {
    listen       80;
    server_name  api.somedomain.com;

    location ~ ^/(api/(charts|chartValues|reports|reportTables|documents|maps|organisationUnits)|dhis-web-commons/javascripts|images|dhis-web-commons-ajax-json|dhis-web-mapping|dhis-web-visualizer) {
    if ($request_method != GET) {
        return 405;
      }

      proxy_pass         http://localhost:8080;
      proxy_redirect     off;
      proxy_set_header   Host               $host;
      proxy_set_header   X-Real-IP          $remote_addr;
      proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto  http;
      proxy_set_header   Authorization      "Basic YWRtaW46ZGlzdHJpY3Q=";
      proxy_set_header   Cookie             "";
      proxy_hide_header  Set-Cookie;
    }
  }
}
```

## DHIS2 configuration reference { #install_dhis2_configuration_reference } 

<!--DHIS2-SECTION-ID:install_dhis2_configuration_reference-->

The following describes the full set of configuration options for the *dhis.conf* configuration file. The configuration file should be placed in a directory which is pointed to by a *DHIS2\_HOME* environment variable.

> **Remarque**
>
> Vous ne devez pas utiliser ce fichier de configuration directement, mais plutôt comme référence pour les options de configuration disponibles. Plusieurs propriétés sont facultatives.

```properties
# ---------------------------------------------------------------------- { #- } 
# Database connection for PostgreSQL [Mandatory] { #database-connection-for-postgresql-mandatory } 
# ---------------------------------------------------------------------- { #- } 

# Hibernate SQL dialect { #hibernate-sql-dialect } 
connection.dialect = org.hibernate.dialect.PostgreSQLDialect

# JDBC driver class { #jdbc-driver-class } 
connection.driver_class = org.postgresql.Driver

# Database connection URL { #database-connection-url } 
connection.url = jdbc:postgresql:dhis2

# Database username { #database-username } 
connection.username = dhis

# Database password (sensitive) { #database-password-sensitive } 
connection.password = xxxx

# Database schema behavior, can be 'validate', 'update', 'create', 'create-drop' { #database-schema-behavior-can-be-validate-update-create-create-drop } 
connection.schema = update

# Max size of connection pool (default: 40) { #max-size-of-connection-pool-default-40 } 
connection.pool.max_size = 40

# ---------------------------------------------------------------------- { #- } 
# Server [Mandatory] { #server-mandatory } 
# ---------------------------------------------------------------------- { #- } 

# Base URL to the DHIS 2 instance { #base-url-to-the-dhis-2-instance } 
server.base.url = https://play.dhis2.org/dev 

# Enable secure settings if system is deployed on HTTPS, can be 'off', 'on' { #enable-secure-settings-if-system-is-deployed-on-https-can-be-off-on } 
server.https = off

# ---------------------------------------------------------------------- { #- } 
# System [Optional] { #system-optional } 
# ---------------------------------------------------------------------- { #- } 

# System mode for database read operations only, can be 'off', 'on' { #system-mode-for-database-read-operations-only-can-be-off-on } 
system.read_only_mode = off

# Session timeout in seconds, default is 3600 { #session-timeout-in-seconds-default-is-3600 } 
system.session.timeout = 3600

# SQL view protected tables, can be 'on', 'off' { #sql-view-protected-tables-can-be-on-off } 
system.sql_view_table_protection = on

# ---------------------------------------------------------------------- { #- } 
# Encryption [Optional] { #encryption-optional } 
# ---------------------------------------------------------------------- { #- } 

# Encryption password (sensitive) { #encryption-password-sensitive } 
encryption.password = xxxx

# ---------------------------------------------------------------------- { #- } 
# File store [Optional] { #file-store-optional } 
# ---------------------------------------------------------------------- { #- } 

# File store provider, currently 'filesystem' and 'aws-s3' are supported { #file-store-provider-currently-filesystem-and-aws-s3-are-supported } 
filestore.provider = filesystem

# Directory / bucket name, folder below DHIS2_HOME on file system, 'bucket' on AWS S3 { #directory-bucket-name-folder-below-dhis2_home-on-file-system-bucket-on-aws-s3 } 
filestore.container = files

# Datacenter location (not required) { #datacenter-location-not-required } 
filestore.location = eu-west-1

# Public identity / username { #public-identity-username } 
filestore.identity = dhis2-id

# Secret key / password (sensitive) { #secret-key-password-sensitive } 
filestore.secret = xxxx

# ---------------------------------------------------------------------- { #- } 
# LDAP [Optional] { #ldap-optional } 
# ---------------------------------------------------------------------- { #- } 

# LDAP server URL { #ldap-server-url } 
ldap.url = ldaps://300.20.300.20:636

# LDAP manager user distinguished name { #ldap-manager-user-distinguished-name } 
ldap.manager.dn = cn=JohnDoe,ou=Country,ou=Admin,dc=hisp,dc=org

# LDAP manager user password (sensitive) { #ldap-manager-user-password-sensitive } 
ldap.manager.password = xxxx

# LDAP entry distinguished name search base { #ldap-entry-distinguished-name-search-base } 
ldap.search.base = dc=hisp,dc=org

# LDAP entry distinguished name filter { #ldap-entry-distinguished-name-filter } 
ldap.search.filter = (cn={0})

# ---------------------------------------------------------------------- { #- } 
# Node [Optional] { #node-optional } 
# ---------------------------------------------------------------------- { #- } 

# Node identifier, optional, useful in clusters { #node-identifier-optional-useful-in-clusters } 
node.id = 'node-1'

# ---------------------------------------------------------------------- { #- } 
# Analytics [Optional] { #analytics-optional } 
# ---------------------------------------------------------------------- { #- } 

# Analytics server-side cache expiration in seconds { #analytics-server-side-cache-expiration-in-seconds } 
analytics.cache.expiration = 3600

# ---------------------------------------------------------------------- { #- } 
# System monitoring [Optional] { #system-monitoring-optional } 
# ---------------------------------------------------------------------- { #- } 

# System monitoring URL { #system-monitoring-url } 
system.monitoring.url = 

# System monitoring username { #system-monitoring-username } 
system.monitoring.username = 

# System monitoring password (sensitive) { #system-monitoring-password-sensitive } 
system.monitoring.password = xxxx
```

## Journalisation des applications { #install_application_logging }

<!--DHIS2-SECTION-ID:install_application_logging-->

Cette section traite de la journalisation des applications dans DHIS 2.

### Fichiers journaux { #log-files }

La sortie du journal de l'application DHIS2 est dirigée vers plusieurs fichiers et emplacements. Tout d'abord, la sortie du journal est envoyée à la sortie standard. Le conteneur de servlets Tomcat envoie généralement la sortie standard vers un fichier sous "logs" (journaux) :

    <tomcat-dir>/logs/catalina.out

Second, log output is written to a "logs" directory under the DHIS2 home directory as defined by the DHIS2\_HOME environment variables. There is a main log file for all output, and separate log files for various
background processes. The main file includes the background process logs as well. The log files are capped at 50 Mb and log content is continuously appended.

    <DHIS2_HOME>/logs/dhis.log    
    <DHIS2_HOME>/logs/dhis-analytics-table.log
    <DHIS2_HOME>/logs/dhis-data-exchange.log
    <DHIS2_HOME>/logs/dhis-data-sync.log

### Configuration des journaux { #log-configuration }

In order to override the default log configuration you can specify a Java system property with the name *log4j.configuration* and a value pointing to the Log4j configuration file on the classpath. If you want to point to a
file on the file system (i.e. outside Tomcat) you can use the *file* prefix e.g. like this:

```properties
-Dlog4j.configuration=file:/home/dhis/config/log4j.properties
```

Les propriétés du système Java peuvent être définies, par exemple via la variable d'environnement *JAVA\_OPTS* ou dans le script de démarrage Tomcat.

A second approach to overriding the log configuration is to specify logging properties in the *dhis.conf* configuration file. The supported properties are:

```properties
# Max size for log files, default is '100MB' { #max-size-for-log-files-default-is-100mb } 
logging.file.max_size = 250MB

# Max number of rolling log archive files, default is 0 { #max-number-of-rolling-log-archive-files-default-is-0 } 
logging.file.max_archives = 2
```

DHIS2 will eventually phase out logging to standard out / catalina.out and as a result it is recommended to rely on the logs under DHIS2\_HOME.

## Travailler avec la base de données PostgreSQL { #install_working_with_the_postgresql_database }

<!--DHIS2-SECTION-ID:install_working_with_the_postgresql_database-->

Common operations when managing a DHIS2 instance are dumping and
restoring databases. To make a dump (copy) of your database, assuming
the setup from the installation section, you can invoke the following:

    pg_dump dhis2 -U dhis -f dhis2.sql

The first argument (dhis2) refers to the name of the database. The
second argument (dhis) refers to the database user. The last argument
(dhis2.sql) is the file name of the copy. If you want to compress the
file copy immediately you can do:

    pg_dump dhis2 -U dhis | gzip > dhis2.sql.gz

To restore this copy on another system, you first need to create an
empty database as described in the installation section. You also need
to gunzip the copy if you created a compressed version. You can
invoke:

    psql -d dhis2 -U dhis -f dhis2.sql


# Surveillance { #monitoring }

## Introduction { #monitoring } 

<!--DHIS2-SECTION-ID:monitoring-->

DHIS2 peut exporter des mesures compatibles avec [Prometheus] (https://prometheus.io/) pour surveiller les nœuds de DHIS2.

Cette section décrit les étapes nécessaires pour installer Prometheus et [Grafana] (https://grafana.com/) à l'aide d'une procédure d'installation standard (`apt-get`) et de Docker, et pour configurer Grafana afin qu'il affiche les mesures de DHIS2.

Pour une liste des mesures exposées par une instance DHIS2, veuillez vous référer au guide du suivi sur [GitHub] (https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md).

## Configuration { #monitoring_setup } 

<!--DHIS2-SECTION-ID:monitoring_setup-->

Les sections suivantes décrivent comment configurer Prometheus et Grafana et comment configurer Prometheus pour extraire des données d'une ou plusieurs instances DHIS2.

### Installation de Prometheus + Grafana sur Ubuntu et Debian { #prometheus } 

<!--DHIS2-SECTION-ID:prometheus-->

- Téléchargez Prometheus depuis la page officielle [download](https://prometheus.io/download/).

- Veillez à appliquer un filtre à votre système d'exploitation et à l'architecture de votre processeur (Linux et amd64).

- Veillez à sélectionner la dernière version stable, et non la version "rc", car elle n'est pas considérée comme suffisamment stable pour l'instant.

- Téléchargez l'archive, soit en cliquant sur le lien, ou en utilisant `wget`.

```
wget https://github.com/prometheus/prometheus/releases/download/v2.15.2/prometheus-2.15.2.linux-amd64.tar.gz
```

- Décompresser le zip

```
tar xvzf prometheus-2.15.2.linux-amd64.tar.gz
```

L'archive contient de nombreux fichiers importants, mais voici les principaux que vous devez connaître.

- `prometheus.yml` : le fichier de configuration de Prometheus. C'est ce fichier que vous allez modifier afin d'ajuster votre serveur Prometheus, par exemple pour changer l'intervalle de récupération ou pour configurer des alertes personnalisées ;
- `prometheus` : le binaire de votre serveur Prometheus. C'est la commande que vous allez exécuter pour lancer une instance de Prometheus sur votre boîte Linux ;
- `promtool` : il s'agit d'une commande que vous pouvez exécuter pour vérifier votre configuration Prometheus.

### Configurer Prometheus comme un service { #prometheus_service } 

<!--DHIS2-SECTION-ID:prometheus_service-->

- Créer un utilisateur `Prometheus` avec un groupe `Prometheus`.

```
useradd -rs /bin/false prometheus
```

- Déplacer les binaires Prometheus dans un répertoire bin local

```
cd prometheus-2.15.2.linux-amd64/ 
cp prometheus promtool /usr/local/bin
chown prometheus:prometheus /usr/local/bin/prometheus
```

- Créez un dossier dans le dossier `/etc` pour Prometheus et déplacez les fichiers de la console, les bibliothèques de la console et le fichier de configuration de Prometheus dans ce dossier nouvellement créé.

```
mkdir /etc/prometheus
cp -R consoles/ console_libraries/ prometheus.yml /etc/prometheus
```

Créez un dossier de données à la racine du répertoire, avec un dossier prometheus à l'intérieur.

```
mkdir -p data/prometheus
chown -R prometheus:prometheus /data/prometheus /etc/prometheus/*
```

### Créer un service Prometheus { #prometheus_create_service } 

<!--DHIS2-SECTION-ID:prometheus_create_service-->

Pour créer un service _systemd_ Prometheus, rendez-vous dans le dossier `/lib/systemd/system` et créez un nouveau fichier systemd nommé `prometheus.service`.

```
cd /lib/systemd/system
touch prometheus.service
```

- Modifiez le fichier nouvellement créé et coller le contenu suivant à l'intérieur :

```propriétés
[Unité]
Description=Prometheus
Souhaite=réseau-cible.en ligne
Après=éseau-cible.en ligne

[Service]
Type=simple
Utilisateur=prometheus
Groupe=prometheus
ExecStart=/usr/local/bin/prometheus \
  --fichier.de configuration=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path="/data/prometheus" \
  --web.console.modèles=/etc/prometheus/consoles \
  --web.console.bibliothèque=/etc/prometheus/console_libraries \
  --web.adresse-écoute=0.0.0.0:9090 \
  --web. activer-l'api de-l'administrateur

Redémarrer=toujours

[Installer]
Requis par=multi-utilisateur.cible
```

- Enregistrer le fichier et activer le service Prometheus au démarrage

```
systemctl enable prometheus
systemctl start prometheus
```

- Tester que le service est en cours d'exécution

```
systemctl status prometheus

...
Active : active (en cours d'exécution)
```

- Il devrait maintenant être possible d'accéder à l'interface utilisateur de Prometheus en accédant à `http://localhost:9090`.


### Mise en place du proxy inverse Nginx { #prometheus_nginx } 

<!--DHIS2-SECTION-ID:prometheus_nginx-->

Prometheus ne prend pas en charge l'authentification ou le cryptage TLS de manière automatique. Si Prometheus doit être exposé en dehors des limites du réseau local, il est important d'activer l'authentification et le cryptage TLS. Les étapes suivantes montrent comment utiliser Nginx comme proxy inverse.

- Installer Nginx, s'il n'est pas déjà installé

```
apt mise à jour
apt-installer nginx
```

Par défaut, Nginx commence à écouter les requêtes HTTP sur le port `http` par défaut, qui est `80`.

Si une instance Nginx fonctionne déjà sur la machine et que vous ne savez pas sur quel port elle est à l'écoute, exécutez la commande suivante :

```
> lsof | grep LISTEN | grep nginx

nginx   15792   root   8u   IPv4   1140223421   0t0   TCP *:http (LISTEN)
```

La dernière colonne indique le port utilisé par Nginx (`http` -> `80`).

Par défaut, la configuration de Nginx est située dans `/etc/nginx/nginx.conf`

Assurez-vous que `nginx.conf` contient la section `Virtual Host Config`

```
## { # } 
# Virtual Host Configs { #virtual-host-configs } 
## { # } 

include /etc/nginx/conf.d/*.conf;
include /etc/nginx/sites-enabled/*;

```

- Créez un nouveau fichier dans `/etc/nginx/conf.d` du nom de `prometheus.conf`

```
touch /etc/nginx/conf.d/prometheus.conf
```

- Modifiez le fichier nouvellement créé et coller le contenu suivant à l'intérieur :

```
serveur {
  écoute 1234;

  localisation / {
    proxy_pass           http://localhost:9090/;
  }
}
```

- Redémarrez Nginx et accédez à http://localhost:1234

```
systemctl restart nginx

# in case of start-up errors { #in-case-of-start-up-errors } 
journalctl -f -u nginx.service
```

- Configure Prometheus for reverse proxying, by editing `/lib/systemd/system/prometheus.service` and add the following argument
to the list of arguments passed to the Prometheus executable

```
--web.externe-url=https://localhost:1234
```

- Redémarrer le service

```
systemctl daemon-reload
systemctl restart prometheus


# in case of errors { #in-case-of-errors } 
journalctl -f -u prometheus.service
```

### Activer l'authentification du proxy inverse { #prometheus_auth } 

<!--DHIS2-SECTION-ID:prometheus_auth-->

Cette section montre comment configurer l'authentification de base via le proxy inverse. Si vous avez besoin d'un mécanisme d'authentification différent (SSO, etc.), veuillez consulter la documentation correspondante.

- Assurez-vous que `htpasswd` est installé sur le système

```
apt-get install apache2-utils
```

- Créer un fichier d'authentification

```
cd /etc/prometheus
htpasswd -c .credentials admin 
```

Choisissez un mot de passe efficace et assurez-vous que le fichier pass a été correctement créé.

- Editez le fichier de configuration Nginx créé précédemment (`/etc/nginx/conf.d/prometheus.conf`), et ajoutez les informations d'authentification.

```
serveur {
 écoute 1234;

  localisation / {
    auth_basic           "Prometheus";
    auth_basic_user_file /etc/prometheus/.credentials;
    proxy_pass           http://localhost:9090/;
  }
}
```

- Redémarrer Nginx

```
systemctl restart nginx

# in case of errors { #in-case-of-errors } 
journalctl -f -u nginx.service
```

- `http://localhost:1234` devrait maintenant vous demander votre nom d'utilisateur et votre mot de passe.

### Installer Grafana sur Ubuntu et Debian { #grafana } 

<!--DHIS2-SECTION-ID:grafana-->

- Ajouter une clé `gpg` et installer le paquet OSS Grafana depuis le repo APT

```sh
apt-installer -y apt-transport-https

wget -q -O - "https://packages.grafana.com/gpg.key" | sudo apt-key add -

add-apt-repositoire "deb https://packages.grafana.com/oss/deb stable main"

apt-mettre à jour

apt-installer grafana
```

- Si le système utilise `systemd`, un nouveau `grafana-service` est automatiquement créé. Vérifiez le fichier `systemd` pour avoir un aperçu de l'installation de Grafana.

```
cat /usr/lib/systemd/system/grafana-server.service
```

Ce fichier est très important car il fournit des informations sur l'instance Grafana nouvellement installée.

Le fichier affiche :

Le **serveur binaire de Grafana** est situé dans `/usr/sbin/grafana-server`.
Le fichier qui définit toutes les **variables d'environnement** est situé dans `/etc/default/grafana-server`
Le **fichier de configuration** est donné par la variable d'environnement `CONF_FILE`.
Le **PID du fichier** est également déterminé par la variable d'environnement `PID_FILE_DIR`.
Les chemins de **logging**(enregistrement), **data** (données), **plugins** (extensions) et **provisioning** (approvisionnement) sont donnés par des variables d'environnement.

- Démarrer le serveur

```
systemctl start grafana-server
```

- Accéder à la console web Grafana : http://localhost:3000

Le nom d'utilisateur par défaut pour Grafana est `admin` et le mot de passe par défaut est également `admin`.
Vous serez invité à changer le mot de passe lors de votre premier accès.

- Configurer Prometheus comme source de données Grafana

Accédez au panneau des sources de données en cliquant sur `Configuration` > `Sources de données` dans le menu à gauche.

Cliquez sur `Add a datasource` (Ajouter une source de données)

Sélectionnez une source de données Prometheus dans la fenêtre suivante.

Configurer la source de données en fonction de la configuration de Prometheus (utiliser l'authentification, TSL, etc.)

### Installation de Prometheus + Grafana à l'aide de Docker { #prometheus_grafana_docker } 

<!--DHIS2-SECTION-ID:prometheus_grafana_docker-->

Cette section décrit comment démarrer une pile Prometheus contenant Prometheus et Grafana.

La configuration est basée sur ce projet : https://github.com/vegasbrianc/prometheus

- Cloner ce projet Github : https://github.com/vegasbrianc/prometheus

- Démarrer la pile Prometheus en utilisant :

```
déploiement de la pile docker -c docker-stack.yml prom
```

La commande ci-dessus peut entraîner l'erreur suivante :

*Ce nœud n'est pas un gestionnaire swarm. Utilisez "docker swarm init" ou "docker swarm join" pour connecter ce noeud au swarm et réessayez*.

Identifier les valeurs qui diffèrent significativement des autres dans les ensembles de données 

```
docker swarm init --advertise-addr <YOUR_IP>
```

Une fois cette commande exécutée avec succès, vous devriez pouvoir exécuter la commande précédente sans problème.

La pile contient également un exportateur Node pour le suivi de Docker. Si vous n'êtes pas intéressé par le suivi de Docker, vous pouvez commenter les sections concernées dans le fichier `docker-stack.yml` :

- `node-exporter`
- `cadvisor`

- Pour arrêter la pile Prometheus :

```
docker stack rm prom
```

Le fichier de configuration de Prometheus (`prometheus.yml`) est situé dans le dossier `prometheus`.

- Accédez à la console web de Grafana à l'adresse suivante : http://localhost:3000 avec le nom d'utilisateur : `admin` et le mot de passe : `foobar`.

### Configurer Prometheus pour obtenir des indicateurs à partir d'une ou plusieurs instances DHIS2 { #prometheus_dhis2 } 

<!--DHIS2-SECTION-ID:prometheus_dhis2-->

Avant d'utiliser Prometheus, il faut le configurer. Nous devons donc créer un fichier de configuration nommé `prometheus.yml`

> **Remarque**
>
> Le fichier de configuration de Prometheus est écrit en YAML ce qui interdit formellement l'utilisation de tabulations. Si votre fichier est mal formaté, Prometheus ne démarrera pas. Faites attention lorsque vous l'éditez.

Le fichier de configuration de Prometheus est divisé en trois parties : `global`, `rule_files`, et `scrape_configs`.

Dans la partie générale, on trouve la configuration générale de Prometheus : `scrape_interval`(intervalle d'analyse) définit la fréquence à laquelle Prometheus analyse les cibles, `evaluation_interval` (intervalle d'évaluation) contrôle la fréquence à laquelle le logiciel évalue les règles. Les règles sont utilisées pour créer de nouvelles séries temporelles et pour générer des alertes.

Le bloc `rule_files`(dossiers de règles) contient des informations sur l'emplacement de toutes les règles que nous voulons que le serveur Prometheus charge.

Le dernier bloc du fichier de configuration est nommé `scape_configs` (configuration du cadre) et contient les informations sur les ressources que Prometheus suit.

Un fichier de suivi simple de DHIS2 Prometheus ressemble à cet exemple :

```yaml
global :
scrape_interval : 15s
Evaluation_interval : 15s 

scrape_configs :
- nom_de l'emploi : 'dhis2'
metrics_path : '/dhis/api/metrics'
basic_auth :
nom d'utilisateur : admin
mot de passe : district
static_configs :
- cibles : ['localhost:80']
```

L'intervalle général `scrape_interval` est fixé à 15 secondes, ce qui est suffisant pour la plupart des cas d'utilisation.

Dans la partie `scrape_configs` nous avons défini l'exportateur DHIS2.
Le bloc `basic_auth` contient les informations d'identification requises pour accéder à l'API `metrics` : envisagez de créer un utilisateur ad-hoc uniquement pour accéder au point de terminaison `metrics`.

Prometheus peut ou non fonctionner sur le même serveur que DHIS2 : dans la configuration ci-dessus, on suppose que Prometheus ne suit qu'une seule instance de DHIS2, fonctionnant sur le même serveur que Prometheus, nous utilisons donc `localhost`.

### Configurer l'exportateur DHIS2 { #dhis2_metrics_conf } 

<!--DHIS2-SECTION-ID:dhis2_metrics_conf-->

Le sous-système de suivi est désactivé par défaut dans DHIS2.

Chaque groupe de mesures doit être explicitement activé pour que les mesures puissent être exportées. Pour configurer DHIS2 afin d'exporter une ou plusieurs mesures, consultez ce [document] (https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md#dhis2-monitoring-configuration).



# Audit { #audit }

## Introduction { #introduction } 

DHIS2 supports a new audit service which is based on Apache ActiveMQ Artemis. Artemis is used as an asynchronous messaging system by DHIS2.

After an entity is saved to database, an audit message will be sent to the Artemis message consumer service. The message will then be processed in a different thread.

Audit logs can be retrieved from the DHIS2 database. Currently there is no UI or API endpoint available for retriving audit entries.


## Table d'audit unique { #audit_table }

<!--DHIS2-SECTION-ID:audit_table-->

All audit entries will be saved into one single table named `audit`

| Colonne     | Type                        |                                                                                                                                                   |   |
|------------|-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|---|
| Identifiant de l'audit    | entier                     |                                                                                                                                                   |   |
| type d'audit  | texte                        | LIRE, CRÉER, METTRE À JOUR, SUPPRIMER, RECHERCHER                                                                                                                  |   |
| champ d'application de l'audit | texte                        | MÉTADONNÉES, AGRÉGÉ, TRACKER                                                                                                                        |   |
| classe      | texte                        | Audit Entity Java class name                                                                                                                      |   |
| les attributs | jsonb                       | Json string stores attributes of the audit entity, used for searching. Example: {"valueType":"TEXT", "categoryCombo":"SWQW313FQY", "domainType":"TRACKER"} |   |
| données       | bytea                       | Compressed Json string of the Audit Entity. It is currently in byte array format and not human-readable.                                                                                                        |   |
| créé à  | horodatage sans fuseau horaire |                                                                                                                                                   |   |
| créé par  | texte                        |                                                                                                                                                   |   |
| uid        | texte                        |                                                                                                                                                   |   |
| code       | texte                        |                                                                                                                                                   |   |
|            |                             |   



The new Audit service makes use of two new concepts: Audit Scopes and Audit Type.

## Champ d'application de l'audit { #audit_scope }

<!--DHIS2-SECTION-ID:audit_scope-->

An Audit Scope is a logical area of the application which can be audited. Currently there are three Audit Scopes:

```
Tracker

Metadata

Aggregate
```

- For the Tracker Audit Scope, the audited objects are:
Tracked Entity Instance, Tracked Entity Attribute Value, Enrollment, Event

- For the Metadata Scope, all "metadata" objects are audited.

- For the Aggregate Scope, the Aggregate Data Value objects are audited.


## Type d'audit { #audit_type }

<!--DHIS2-SECTION-ID:audit_type-->

An Audit Type is an action that triggers an audit operation. Currently we support the following types:

```
READ

CREATE

UPDATE

DELETE
```

As an example, when a new Tracked Entity Instance gets created, and if configured like so, the CREATE action is used to insert a new Audit entry in the audit db table.

``` Note: the READ Audit Type will generate a lot of data in database and may have an impact on the performance. ```

## Configuration { #audit_configuration }

<!--DHIS2-SECTION-ID:audit_configuration-->

The audit system is automatically configured to audit for the following scopes and types:

- CREATE, UPDATE, DELETE

- METADATA, TRACKER, AGGREGATE

**No action is required to activate the audit.**
The audit can still be configured using the "audit matrix". The audit matrix is driven by 3 properties in dhis.conf:

```
audit.metadata

audit.tracker

audit.aggregate
```

Each property accepts a semicolon delimited list of valid Audit Types:

```
CREATE

UPDATE

DELETE

READ
```

For instance, in order to only audit Tracker related object creation and deletion, the following property should be added to `dhis.conf`:

```
audit.tracker = CREATE;DELETE
```

In order to completely disable auditing, this is the configuration to use:
```
audit.metadata = DISABLED

audit.tracker = DISABLED

audit.aggregate = DISABLED
```


# Utilisation de passerelles pour l'établissement de rapports SMS { #sms_report_sending }

<!--DHIS2-SECTION-ID:sms_report_sending-->

DHIS2 supports accepting data via [SMS](https://docs.dhis2.org/master/en/dhis2_user_manual_en/mobile.html), however, the SMS needs to be composed in a cryptic way to protect the information. The DHIS2 Android App acts as a transparent layer to send the information via SMS where the user does not have to worry about writing the SMS. To send SMSs with the Android App the SMS gateway need to be properly configured. This section explains the different options available and how to achieve that.

## Envoi de SMS { #sms_report_sening }

<!--DHIS2-SECTION-ID:sms_report_sening-->

It is important to clarify firstly, that this section mainly concerns the set up of **receiving SMS** (from mobile devices to the DHIS2 server), which is necessary when considering using the App to send (sync) information recorded in the app to the DHIS2 server via SMS. In the App this can be set-up under the *Settings* > *SMS Settings*

L’envoi de SMS, du serveur DHIS2 vers les appareils mobiles, est relativement simple à configurer. S'il s'agit juste d'envoyer des notifications aux téléphones des utilisateurs depuis DHIS2 lorsque certains événements se produisent (messagerie, seuils, etc.), seul l'envoi de SMS est requis.

Tout ceci peut être configuré sur la page de configuration du service SMS dans la [section Configuration mobile](https://docs.dhis2.org/master/en/user/html/mobile_sms_service.html).

Les fournisseurs habituels tels que *Bulk SMS* et *Clickatell* sont pris en charge par défaut, et ces deux fournisseurs permettent d'envoyer des SMS vers des numéros de la plupart des pays.

Notez également qu'il est possible d'utiliser différentes passerelles SMS pour l'envoi et la réception de SMS. Ainsi, même si vous mettez en place une des solutions ci-dessous pour la réception de SMS, vous pouvez toujours utiliser l'une des solutions susmentionnées pour l'envoi.

## Utilisation d'un appareil Android comme passerelle SMS { #sms_report_android_gateway }

<!--DHIS2-SECTION-ID:sms_report_android_gateway-->

La solution la plus simple, et de loin, consiste à utiliser un appareil Android comme passerelle SMS. Tout téléphone ou tablette fonctionnant sous Android OS (4.4, Kitkat ou supérieur) devrait faire l'affaire. L'appareil aura besoin d'une connexion internet permanente pour transférer les messages vers votre serveur DHIS2 et d'une carte SIM pour recevoir les SMS.

Il vous faudra télécharger et installer l'application Passerelle SMS Android de DHIS2 sur l'appareil mobile. Vous trouverez une liste des [versions] disponibles à cette adresse : (https://github.com/dhis2/dhis2-sms-android-gateway/releases). Vous pourrez y télécharger le fichier APK le plus récent et l'installer. Des instructions sont fournies sur la page de l'application elle-même, mais il suffit de lancer l'application et d'entrer les informations de votre serveur DHIS2 (URL, nom d'utilisateur et mot de passe).

Une fois l'application installée et opérationnelle, entrez le numéro de téléphone de cette passerelle sur la page de configuration des appareils mobiles qui utilisent l'application DHIS2 Capture. Ainsi, lorsque des SMS seront envoyés à partir de ces appareils, ils sont reçus par la passerelle et automatiquement transmis au serveur DHIS2 où ils sont traités.

**Using this gateway device is perfect when testing the SMS functionality.** It would be fine when piloting projects that require SMS reporting. As long as the device is plugged into a power supply and has a constant internet connection it works well for small scale projects.

However, when considering moving a project to production it would be necessary to investigate one of the more permanent and reliable solutions for gateways below.

### Envoi de SMS à l'aide d'une passerelle Android { #sending-sms-using-an-android-device-gateway }

Cette option n'est actuellement ni prise en charge ni documentée.

## Passerelles SMS dédiées { #sms_report_dedicated_gateway }

<!--DHIS2-SECTION-ID:sms_report_dedicated_gateway-->

Cette section traite de l'utilisation de passerelles SMS plus permanentes et dédiées, ainsi que des options disponibles. Chacune des options ci-dessous suppose qu'un fournisseur (ou vous-même) dispose d'une connexion SMPP avec un opérateur téléphonique dans le pays et utilise cette connexion pour recevoir des SMS et les transmettre à votre serveur DHIS2 via Internet à l'aide du protocole HTTP.

Ces solutions peuvent utiliser un **numéro long** ou un **code court**. Un numéro long est un numéro de téléphone mobile standard du type que la plupart des particuliers utilisent, par exemple +61 400123123. Un code court est simplement un numéro court, tel que 311. La configuration et la gestion des codes courts sont généralement plus coûteuses.

### S'assurer que les SMS entrants vers le serveur DHIS2 sont correctement formatés { #ensuring-incoming-sms-to-dhis2-server-are-formatted-correctly }

Lors de l'envoi de SMS vers un serveur DHIS2 via l'API, utilisez l'URL suivante : *https://<DHIS2_server_url>/api/sms/inbound*

Dans la version 2.34 et les versions antérieures de DHIS2, ce point d'extrémité exige que le format des SMS entrants soient très spécifique, c'est-à-dire que le message lui-même doit être un paramètre appelé "texte" et le numéro de téléphone de l'expéditeur doit être un paramètre appelé "expéditeur".

Lorsque vous utilisez toutes les options de passerelle SMS ci-dessous, et que vous les configurez pour transmettre les SMS à un autre service Web, elles auront chacune leur propre format, lequel sera différent de celui attendu par l'API DHIS2. Voilà pourquoi il est nécessaire de les reformater avant de les envoyer au serveur DHIS2.

Une option consiste à exécuter simplement votre propre service Web, qui reçoit le SMS du fournisseur de la passerelle, le reformate au format requis pour DHIS2 et le transmet à votre API DHIS2. Un tel service devrait être écrit par un développeur de logiciels.

Dans la version 2.35 de DHIS2, il est prévu de prendre en charge ces cas avec un système de template pour les SMS entrants, de sorte que vous puissiez spécifier le format des messages qui seront envoyés depuis votre fournisseur. De cette manière, vous pouvez configurer le serveur DHIS2 pour qu'il accepte les SMS entrants de tout autre fournisseur de passerelle SMS. Ces derniers pourrons alors envoyer directement des SMS entrants à l'API DHIS2, sans avoir besoin d'un service Web de formatage.

### Utilisation de RapidPro { #using-rapidpro }

[RapidPro] (https://rapidpro.io/) est un service géré par l'UNICEF dans plus de 50 pays à travers le monde. Il s'agit d'un ensemble de logiciels qui travaille avec les opérateurs téléphoniques nationaux pour permettre aux organisations de concevoir des solutions SMS pour leurs projets, tels que des rapports SMS ou des campagnes de sensibilisation.

Le service RapidPro implique une connexion SMPP avec un ou plusieurs opérateurs téléphoniques nationaux, généralement par le biais d'un code court, qui peut être dédié aux activités liées à la santé des ONG. Il est alors possible d'ajouter un webhook (crochet Web) pour que les SMS entrants soient transmis à un autre service Web, tel que le service Web de formatage décrit ci-dessus. Si le code court est également utilisé à d'autres fins, il peut être nécessaire d'ajouter les numéros de téléphone de vos appareils d'établissement de rapports à un groupe distinct, de sorte que seuls les SMS entrants provenant de ces appareils soient transmis au webhook.

RapidPro est actuellement opérationnel dans près de la moitié des pays qui utilisent DHIS2 ou qui sont à une phase pilote. Avant d'envisager l'une des solutions ci-dessous, qui peuvent être coûteuses en termes de temps et d'argent, il convient de prendre contact avec l'Unicef pour voir si RapidPro est disponible et s'il peut être utilisé pour l'établissement de rapports sur la santé dans votre pays.

### Utilisation de fournisseurs de passerelles SMS commerciales { #using-commercial-sms-gateway-providers }

Les fournisseurs de passerelles SMS commerciaux mentionnés dans la section « Envoi de SMS » ci-dessus sont généralement en mesure d'*envoyer* des SMS dans la plupart des pays, mais ne peuvent *recevoir* des SMS que dans un nombre limité de pays. La majorité des pays dans lesquels ils prennent en charge la réception de SMS n'utilisent pas le système DHIS2. Parmi les pays qui utilisent DHIS2, la plupart sont déjà couverts par un service RapidPro opérationnel dans le pays.

Toutefois, il est utile de se renseigner sur les options commerciales disponibles pour votre pays. Dans certains pays, il existe de petites entreprises nationales qui fournissent des services SMS et qui disposent de connexions SMPP avec les opérateurs téléphoniques que vous pouvez contacter.

### Utilisation des opérateurs téléphoniques { #using-phone-carriers-directly }

Si aucune des solutions ci-dessus n'est disponible, vous devrez vous adresser directement aux opérateurs téléphoniques de votre pays. La première question à leur poser est de savoir s'ils connaissent des entreprises qui exploitent des connexions SMPP avec eux et que vous pourriez contacter.

Sinon, comme dernière option, vous devrez envisager de configurer et de gérer votre propre connexion SMPP avec l'opérateur téléphonique. Cependant, tous ne proposent pas un tel service.

Il vous faudra faire fonctionner votre propre serveur avec un logiciel tel que [Kannel] (https://www.kannel.org/), qui se connecte (généralement via un VPN) à un service SMPP fonctionnant sur le réseau de l'opérateur téléphonique. Ainsi, tout SMS entrant pour le numéro long ou le code court configuré est envoyé par l'opérateur téléphonique à votre serveur Kannel et vous pouvez ensuite transférer ces messages tel que décrit plus haut.

### Réception de SMS concaténés ou en plusieurs parties { #receiving-concatenated-or-multipart-sms }

When syncing data via SMS with the DHIS2 Android App, it uses a compressed format to use as little space (characters of text) as possible. Despite this, it will quite often be the case that a message will extend over the 160 character limit of one standard SMS. On most modern mobile devices these messages will still be sent as one concatenated or multipart SMS, and received as one message. When sending between two mobile devices, when an Android device is used as the gateway, this should be handled without issue.

Lors de la sélection d'une passerelle SMS, il est important de confirmer que l'opérateur téléphonique utilisé prend en charge les SMS concaténés. La plupart d'entre eux le prendront en charge, mais il est important de confirmer que la fonctionnalité SMS ne fonctionnera pas si les SMS sont fractionnés. Cela repose sur quelque chose appelé UDH (User Data Header). Lorsque vous discutez avec les fournisseurs, assurez-vous de demander si cela est pris en charge.
