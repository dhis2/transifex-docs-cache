---
revision_date: "2021-09-07"
template: single.html
---

# Installation { #installation }

Le chapitre d'installation donne des informations sur comment installer DHIS2 dans des des contextes variables, incluant serveur central en ligne, application autonome et paquet auto-contenu appellé DHIS2 Live.

## Introduction { #install_introduction }

DHIS2 runs on all platforms for which there exists a Java JDK, which includes most popular operating systems such as Windows, Linux and Mac. DHIS2 runs on the PostgreSQL database system. DHIS2 is packaged as a standard Java Web Archive (WAR-file) and thus runs on any Servlet containers such as Tomcat and Jetty.

L'equipe de DHIS2 recommande le systèmes d'exploitation Ubuntu 18.04 LTS, le système de base de donnné PostgreSQL et le conteneur Tomcay Servlet comme environnement favoris pour l'installation de serveur.

This chapter provides a guide for setting up the above technology stack. It should however be read as a guide for getting up and running and not as an exhaustive documentation for the mentioned environment. We refer to the official Ubuntu, PostgreSQL and Tomcat documentation for in-depth reading.

The `dhis2-tools` Ubuntu package automates many of the tasks described in the guide below and is recommended for most users, especially those who are not familiar with the command line or administration of servers. It is described in detail in a separate chapter in this guide.

## Server specifications { #install_server_specifications }

DHIS2 is a database intensive application and requires that your server has an appropriate amount of RAM, number of CPU cores and a fast disk. These recommendations should be considered as rules-of-thumb and not exact measures. DHIS2 scales linearly on the amount of RAM and number of CPU cores so the more you can afford, the better the application will perform.

-   _RAM:_ At least 1 GB memory per 1 million captured data records per month or per 1000 concurrent users. At least 4 GB for a small instance, 12 GB for a medium instance.

-   _CPU cores:_ 4 CPU cores for a small instance, 8 CPU cores for a medium or large instance.

-   _Disk:_ Ideally use an SSD. Otherwise use a 7200 rpm disk. Minimum read speed is 150 Mb/s, 200 Mb/s is good, 350 Mb/s or better is ideal. In terms of disk space, at least 60 GB is recommended, but will depend entirely on the amount of data which is contained in the data value tables. Analytics tables require a significant amount of disk space. Plan ahead and ensure that your server can be upgraded with more disk space as it becomes needed.

## Software requirements { #install_software_requirements }

Les versions ultérieures de DHIS2 nécessitent les versions logicielles suivantes pour fonctionner.

-   Un système d'exploitation pour lequel un Java JDK ou JRE version 8 ou 11 existe. Linux est recommandé.
-   Java JDK. OpenJDK is recommended.
    -   For DHIS 2 version 2.35 version and later, JDK 11 is recommended and JDK 8 or later is required.
    -   Pour les versions DHIS 2 antérieures à 2.35, JDK 8 est requis.
-   PostgreSQL database version 9.6 or later. A later PostgreSQL version such as version 13 is recommended.
-   Extension de base de données PostGIS version 2.2 ou plus.
-   Tomcat servlet container version 8.5.50 or later, or other Servlet API 3.1 compliant servlet containers.

## Server setup { #install_server_setup }

This section describes how to set up a server instance of DHIS2 on Ubuntu 16.04 64 bit with PostgreSQL as database system and Tomcat as Servlet container. This guide is not meant to be a step-by-step guide per se, but rather to serve as a reference to how DHIS2 can be deployed on a server. There are many possible deployment strategies, which will differ depending on the operating system and database you are using, and other factors. The term _invoke_ refers to executing a given command in a terminal.

For a national server the recommended configuration is a quad-core 2 Ghz processor or higher and 12 Gb RAM or higher. Note that a 64 bit operating system is required for utilizing more than 4 Gb of RAM.

For this guide we assume that 8 Gb RAM is allocated for PostgreSQL and 8 GB RAM is allocated for Tomcat/JVM, and that a 64-bit operating system is used. _If you are running a different configuration please adjust the suggested values accordingly\!_ We recommend that the available memory is split roughly equally between the database and the JVM. Remember to leave some of the physical memory to the operating system for it to perform its tasks, for instance around 2 GB. The steps marked as _optional_, like the step for performance tuning, can be done at a later stage.

### Creating a user to run DHIS2 { #install_creating_user }

Vous devriez créer un utilisateur dédié pour lancer DHIS2

> **Important**
>
> Vous ne devez pas exécuter le serveur DHIS2 en tant qu'utilisateur privilégié tel que super-utilisateur.

Créez un nouvel utilisateur appelé "dhis" en appelant :

```sh
sudo useradd -d /home/dhis -m dhis -s /bin/false
```

Ensuite, pour définir le mot de passe de votre compte, appelez :

```sh
sudo passwd dhis
```

Créez un mot de passe sécurisé comportant au moins 15 caractères aléatoires.

### Creating the configuration directory { #install_creating_config_directory }

Start by creating a suitable directory for the DHIS2 configuration files. This directory will also be used for apps, files and log files. An example directory could be:

```sh
mkdir /home/dhis/config
chown dhis:dhis /home/dhis/config
```

DHIS2 will look for an environment variable called _DHIS2_HOME_ to locate the DHIS2 configuration directory. This directory will be referred to as _DHIS2_HOME_ in this installation guide. We will define the environment variable in a later step in the installation process.

### Setting server time zone and locale { #install_setting_server_tz }

It may be necessary to reconfigure the time zone of the server to match the time zone of the location which the DHIS2 server will be covering. If you are using a virtual private server, the default time zone may not correspond to the time zone of your DHIS2 location. You can easily reconfigure the time zone by invoking the below and following the instructions.

```sh
sudo dpkg-reconfigure tzdata
```

PostgreSQL is sensitive to locales so you might have to install your locale first. To check existing locales and install new ones (e.g. Norwegian):

```sh
locale -a
sudo locale-gen nb_NO.UTF-8
```

### PostgreSQL installation { #install_postgresql_installation }

Installez PostgreSQL en appelant :

```sh
sudo apt-get install postgresql-10 postgresql-contrib-10 postgresql-10-postgis-2.4
```

Create a non-privileged user called _dhis_ by invoking:

```sh
sudo -u postgres createuser -SDRP dhis
```

Entrez un mot de passe sécurisé à l'invite. Créez une base de données en appelant :

```sh
sudo -u postgres createdb -O dhis dhis2
```

Return to your session by invoking `exit` You now have a PostgreSQL user called _dhis_ and a database called _dhis2_.

The _PostGIS_ extension is needed for several GIS/mapping features to work. DHIS 2 will attempt to install the PostGIS extension during startup. If the DHIS 2 database user does not have permission to create extensions you can create it from the console using the _postgres_ user with the following commands:

```sh
sudo -u postgres psql -c "create extension postgis;" dhis2
```

Exit the console and return to your previous user with _\\q_ followed by _exit_.

### PostgreSQL performance tuning { #install_postgresql_performance_tuning }

Tuning PostgreSQL is necessary to achieve a high-performing system but is optional in terms of getting DHIS2 to run. PostgreSQL is configured and tuned through the _postgresql.conf_ file which can be edited like this:

```sh
sudo nano /etc/postgresql/10/main/postgresql.conf
```

et modifez la propriété suivante:

```properties
max_connections = 200
```

Détermine le nombre maximum de connexions autorisées par PostgreSQL.

```properties
shared_buffers = 3200MB
```

Determines how much memory should be allocated exclusively for PostgreSQL caching. This setting controls the size of the kernel shared memory which should be reserved for PostgreSQL. Should be set to around 40% of total memory dedicated for PostgreSQL.

```properties
work_mem = 20MB
```

Determines the amount of memory used for internal sort and hash operations. This setting is per connection, per query so a lot of memory may be consumed if raising this too high. Setting this value correctly is essential for DHIS2 aggregation performance.

```properties
maintenance_work_mem = 512MB
```

Determines the amount of memory PostgreSQL can use for maintenance operations such as creating indexes, running vacuum, adding foreign keys. Increasing this value might improve performance of index creation during the analytics generation processes.

```properties
effective_cache_size = 8000MB
```

An estimate of how much memory is available for disk caching by the operating system (not an allocation) and isdb.no used by PostgreSQL to determine whether a query plan will fit into memory or not. Setting it to a higher value than what is really available will result in poor performance. This value should be inclusive of the shared_buffers setting. PostgreSQL has two layers of caching: The first layer uses the kernel shared memory and is controlled by the shared_buffers setting. PostgreSQL delegates the second layer to the operating system disk cache and the size of available memory can be given with the effective_cache_size setting.

```properties
checkpoint_completion_target = 0.8
```

Sets the memory used for buffering during the WAL write process. Increasing this value might improve throughput in write-heavy systems.

```properties
synchronous_commit = off
```

Specifies whether transaction commits will wait for WAL records to be written to the disk before returning to the client or not. Setting this to off will improve performance considerably. It also implies that there is a slight delay between the transaction is reported successful to the client and it actually being safe, but the database state cannot be corrupted and this is a good alternative for performance-intensive and write-heavy systems like DHIS2.

```properties
wal_writer_delay = 10000ms
```

Specifies the delay between WAL write operations. Setting this to a high value will improve performance on write-heavy systems since potentially many write operations can be executed within a single flush to disk.

```properties
random_page_cost = 1.1
```

_SSD only._ Sets the query planner's estimate of the cost of a non-sequentially-fetched disk page. A low value will cause the system to prefer index scans over sequential scans. A low value makes sense for databases running on SSDs or being heavily cached in memory. The default value is 4.0 which is reasonable for traditional disks.

```properties
max_locks_per_transaction = 96
```

Spécifie le nombre moyen de verrous d'objets alloués pour chaque transaction. Cette valeur est principalement définie pour permettre la réalisation des mises à niveau de routine qui touchent un grand nombre de tableaux.

Redémarrez PostgreSQL en appelant la commande suivante :

```sh
sudo /etc/init.d/postgresql restart
```

### Java installation { #install_java_installation }

The recommended Java JDK for DHIS 2 is OpenJDK 11. OpenJDK is licensed under the GPL license and can be run free of charge. You can install it with the following command:

```
sudo apt-get install openjdk-11-jdk
```

Si vous préférez OpenJDK 8 (pour les versions antérieures à la 2.35), vous pouvez l'installer avec cette commande :

```
sudo apt-get install openjdk-8-jdk
```

Vérifiez que votre installation est correcte en appelant :

```
java -version
```

### DHIS2 configuration { #install_database_configuration }

The database connection information is provided to DHIS2 through a configuration file called `dhis.conf`. Create this file and save it in the `DHIS2\_HOME` directory. As an example this location could be:

```sh
/home/dhis/config/dhis.conf
```

A configuration file for PostgreSQL corresponding to the above setup has these properties:

```properties
# ----------------------------------------------------------------------
# Database connection
# ----------------------------------------------------------------------

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password
connection.password = xxxx

# ----------------------------------------------------------------------
# Server
# ----------------------------------------------------------------------

# Enable secure settings if deployed on HTTPS, default 'off', can be 'on'
# server.https = on

# Server base URL
# server.base.url = https://server.com/
```

Il est fortement recommandé d'activer le paramètre `server.https` et de déployer DHIS 2 avec un protocole HTTPS crypté. Ce paramètre activera par exemple des cookies sécurisés. Le déploiement HTTPS est requis lorsque ce paramètre est activé.

Le paramètre `server.base.url` fait référence à l'URL à laquelle les utilisateurs finaux accèdent au système sur le réseau.

Note that the configuration file supports environment variables. This means that you can set certain properties as environment variables and have them resolved, e.g. like this where `DB\_PASSWD` is the name of the environment variable:

```properties
connection.password = ${DB_PASSWD}
```

Note that this file contains the password for your DHIS2 database in clear text so it needs to be protected from unauthorized access. To do this, invoke the following command which ensures only the _dhis_ user is allowed to read it:

```sh
chmod 600 dhis.conf
```

### Tomcat and DHIS2 installation { #install_tomcat_dhis2_installation }

To install the Tomcat servlet container we will utilize the Tomcat user package by invoking:

```sh
sudo apt-get install tomcat8-user
```

This package lets us easily create a new Tomcat instance. The instance will be created in the current directory. An appropriate location is the home directory of the _dhis_ user:

```sh
cd /home/dhis/
sudo tomcat8-instance-create tomcat-dhis
sudo chown -R dhis:dhis tomcat-dhis/
```

This will create an instance in a directory called _tomcat-dhis_. Note that the tomcat7-user package allows for creating any number of dhis instances if that is desired.

Next edit the file _tomcat-dhis/bin/setenv.sh_ and add the lines below. The first line will set the location of your Java Runtime Environment, the second will dedicate memory to Tomcat and the third will set the location for where DHIS2 will search for the _dhis.conf_ configuration file. Please check that the path the Java binaries are correct as they might vary from system to system, e.g. on AMD systems you might see _/java-8-openjdk-amd64_ Note that you should adjust this to your environment:

```sh
export JAVA_HOME='/usr/lib/jvm/java-11-openjdk-amd64/'
export JAVA_OPTS='-Xmx7500m -Xms4000m'
export DHIS2_HOME='/home/dhis/config'
```

The Tomcat configuration file is located in _tomcat-dhis/conf/server.xml_. The element which defines the connection to DHIS is the _Connector_ element with port 8080. You can change the port number in the Connector element to a desired port if necessary. The _relaxedQueryChars_ attribute is necessary to allow certain characters in URLs used by the DHIS2 front-end.

```xml
<Connector port="8080" protocol="HTTP/1.1"
  connectionTimeout="20000"
  redirectPort="8443"
  relaxedQueryChars="[]" />
```

The next step is to download the DHIS2 WAR file and place it into the webapps directory of Tomcat. You can download DHIS2 WAR files from the following location:

```sh
https://releases.dhis2.org/
```

Alternatively, for patch releases, the folder structure is based on the patch release ID in a subfolder under the main release. E.g. you can download the DHIS2 version 2.31.1 WAR release like this (replace 2.31 with your preferred version, and 2.31.1 with you preferred patch, if necessary):

```
wget https://releases.dhis2.org/2.33/2.33.1/dhis.war
```

Move the WAR file into the Tomcat webapps directory. We want to call the WAR file ROOT.war in order to make it available at localhost directly without a context path:

```sh
mv dhis.war tomcat-dhis/webapps/ROOT.war
```

DHIS2 should never be run as a privileged user. After you have modified the setenv.sh file, modify the startup script to check and verify that the script has not been invoked as root.

```sh
#!/bin/sh
set -e

if [ "$(id -u)" -eq "0" ]; then
  echo "This script must NOT be run as root" 1>&2
  exit 1
fi

export CATALINA_BASE="/home/dhis/tomcat-dhis"
/usr/share/tomcat8/bin/startup.sh
echo "Tomcat started"
```

### Running DHIS2 { #install_running_dhis2 }

DHIS2 peut désormais être lancé en appelant :

    sudo -u dhis tomcat-dhis/bin/startup.sh

> **Important**
>
> The DHIS2 server should never be run as root or other privileged user.

DHIS2 peut être arrêté en appelant :

    sudo -u dhis tomcat-dhis/bin/shutdown.sh

To monitor the behavior of Tomcat the log is the primary source of information. The log can be viewed with the following command:

    tail -f tomcat-dhis/logs/catalina.out

Assuming that the WAR file is called ROOT.war, you can now access your DHIS2 instance at the following URL:

    http://localhost:8080

## File store configuration { #install_file_store_configuration }

DHIS2 is capable of capturing and storing files. By default, files will be stored on the local file system of the server which runs DHIS2 in a _files_ directory under the _DHIS2_HOME_ external directory location.

You can also configure DHIS2 to store files on cloud-based storage providers. AWS S3 is the only supported provider currently. To enable cloud-based storage you must define the following additional properties in your _dhis.conf_ file:

```propriétés
# Fournisseur d'entrepôts de fichiers. Actuellement, 'filesystem' et 'aws-s3' sont pris en charge.
filestore.provider = 'aws-s3'

# Répertoire dans le répertoire externe sur le système de fichiers local et le compartiment sur AWS S3
filestore.container = fichiers

# La configuration suivante s'applique uniquement au stockage sur cloud (AWS S3)

# Emplacement du centre de données. Facultatif mais recommandé pour des raisons de performances.
filestore.emplacement = eu-west-1

# Nom d'utilisateur / Clé d'accès sur AWS S3
filestore.identité = xxxx

# Mot de passe / Clé secrète sur AWS S3 (sensible)
filestore.secret = xxxx
```

This configuration is an example reflecting the defaults and should be changed to fit your needs. In other words, you can omit it entirely if you plan to use the default values. If you want to use an external provider the last block of properties needs to be defined, as well as the _provider_ property is set to a supported provider (currently only AWS S3).

> **Note**
>
> If you’ve configured cloud storage in dhis.conf, all files you upload or the files the system generates will use cloud storage.

For a production system the initial setup of the file store should be carefully considered as moving files across storage providers while keeping the integrity of the database references could be complex. Keep in mind that the contents of the file store might contain both sensitive and integral information and protecting access to the folder as well as making sure a backup plan is in place is recommended on a production implementation.

> **Note**
>
> AWS S3 is the only supported provider but more providers are likely to be added in the future, such as Google Cloud Store and Azure Blob Storage. Let us know if you have a use case for additional providers.

## Google service account configuration { #install_google_service_account_configuration }

DHIS2 can connect to various Google service APIs. For instance, the DHIS2 GIS component can utilize the Google Earth Engine API to load map layers. In order to provide API access tokens you must set up a Google service account and create a private key:

-   Create a Google service account. Please consult the [Google identify platform](https://developers.google.com/identity/protocols/OAuth2ServiceAccount#overview) documentation.

-   Visit the [Google cloud console](https://console.cloud.google.com) and go to API Manager \> Credentials \> Create credentials \> Service account key. Select your service account and JSON as key type and click Create.

-   Rename the JSON key to _dhis-google-auth.json_.

After downloading the key file, put the _dhis-google-auth.json_ file in the DHIS2_HOME directory (the same location as the _dhis.conf_ file). As an example this location could be:

    /home/dhis/config/dhis-google-auth.json

## Configuration d'OpenID Connect (OIDC) { #install_oidc_configuration }

DHIS2 prend en charge la couche d'identité de l'OpenID Connect (OIDC) pour une identification unique (IU). L'OIDC est un protocole d'authentification standard qui permet aux utilisateurs de se connecter à un fournisseur d'identité (IdP) comme Google. Une fois que les utilisateurs parviennent à se connecter à leur IdP, ils sont donc automatiquement connectés à DHIS2.

Cette section présente des informations générales sur l'utilisation du DHIS2 avec l'OIDC, ainsi que les options de configuration de l'IdP et du DHIS2. Le déroulement de l'authentification se présente comme suit.

1. Un utilisateur tente de se connecter à DHIS2 à partir d'un ordinateur client.

2. Le DHIS2 redirige la requête d'authentification vers la passerelle IdP.

3. Le système demande à l'utilisateur de fournir des informations d'identification et l'authentifie auprès de l'IdP. L'IdP répond par une URL permettant de rediriger l'utilisateur vers le DHIS2. L'URL de redirection comprend un code d'autorisation spécifique destiné à l'utilisateur.

4. Le client est redirigé vers le DHIS2 et présente le code d'autorisation.

5. Le DHIS2 présente le code d'autorisation du client à l'IdP en même temps que ses propres références client.

6. The IdP returns an access token and an ID token to DHIS2. DHIS2 performs a validation of the IdP token (JWT). The ID token is a set of attribute key pairs for the user. The key pairs are called claims.

7. DHIS2 identifies the user from the IdP claims and completes the authentication request from Step 1. DHIS2 searches for a user that matches the `email` claim from the IdP. DHIS2 can be configured to use different claims for this process.

8. Le DHIS2 autorise l'utilisateur.

### Exigences requises pour l'OIDC { #requirements-for-oidc }

#### Compte IdP { #idp-account }

Vous devez avoir accès à un fournisseur d'identité (IdP) pris en charge par le DHIS2.

Voici donc les IdP actuellement pris en charge :

-   Google
-   Azure AD
-   WSO2
-   Generic provider

#### Compte de l'utilisateur local { #local-user-account }

Vous devez créer expressément des utilisateurs dans l'instance DHIS2. L'importation à partir d'un répertoire externe tel qu'Active Directory n'est actuellement pas prise en charge. La gestion des utilisateurs avec un magasin d'identité externe n'est pas prise en charge par l'OIDC.

#### Requêtes d'IdP et cartographie des utilisateurs { #idp-claims-and-mapping-of-users }

Pour se connecter au DHIS2, l'utilisateur doit être enregistré dans l'IdP et ensuite connecté à un compte d'utilisateur dans le DHIS2. L'OIDC utilise une méthode basée sur les requêtes pour partager les attributs des comptes utilisateurs avec d'autres applications. Les requêtes comportent des attributs de compte d'utilisateur tels que l'adresse électronique, le numéro de téléphone, le nom, etc. DHIS2 utilise les requêtes IdP pour établir des liens de correspondance entre les comptes d'utilisateurs de l'IdP et ceux hébergés dans DHIS2. Par défaut, DHIS2 exige que l'IdP transmette la requête _email_. En fonction de votre IdP, vous devrez peut-être configurer DHIS2 de manière à ce qu'il utilise une requête IdP différente.

If you are using Google or Azure AD as an IdP, the default behavior is to use the email claim to map IdP identities to DHIS2 user accounts.

In order for a DHIS2 user to be able to login with an IdP, the user profile checkbox _External authentication only (OpenID or LDAP)_ must be checked and _OpenID_ field must match the claim (mapping claim) returned by the IdP. Email is used by default by both Google and Azure AD.

### Configurer le fournisseur d'identité pour l'OIDC { #configure-the-identity-provider-for-oidc }

Cette rubrique fournit des informations sur comment configurer un fournisseur d'identité (IdP) de manière à utiliser l'OIDC avec le DHIS2. Il s'agit d'une étape d'un processus en plusieurs étapes. Les rubriques suivantes sont consacrées à la configuration et à l'utilisation de l'OIDC avec le DHIS2.

#### Configuration de l'IdP { #configure-the-idp }

Avant de pouvoir utiliser l'OIDC avec le DHIS2, vous devez disposer d'un compte chez un fournisseur d'identité pris en charge (IdP) et d'un projet ou d'une application avec l'IdP. Lorsque vous configurez le DHIS2, vous devez fournir les informations suivantes :

-   **Identifiant du client du fournisseur :** Il s'agit de l'identifiant que l'IdP a attribué à votre demande.

-   **Client secret du fournisseur :** Cette valeur est un secret et doit être gardée en toute sécurité.

#### Rediriger l'URL { #redirect-url }

Certains IdP nécessitent une URL de redirection pour votre instance DHIS2. Vous pouvez définir votre URL pour l'IdP en utilisant la syntaxe suivante :

```
(protocole):/(votre hébergeur DHIS2)/oauth2/code/(code IdP)
```

Voici donc un exemple :

```
https://dhis2.org/oauth2/code/google
```

#### Exemple de procédure IdP (Google) { #example-idp-process-google }

La procédure ci-après présente un aperçu des étapes à suivre avec le prestataire. À titre d'exemple, la procédure explique comment utiliser Google comme fournisseur d'identité. Cependant, chaque fournisseur a un flux quelque peu différent, de sorte que les détails des étapes ( ainsi que leur ordre) peuvent varier en fonction de votre fournisseur.

1. Register at the provider's developer site and sign in. For example, for Google, you can go to the Google [developer console](https://console.developers.google.com).

2. Créer un nouveau projet ou une nouvelle application.

3. Dans le tableau de bord du développeur, suivez les étapes de création d'un client ID et d'un client secret OAuth 2.0. Enregistrez ces valeurs pour une utilisation ultérieure.

4. Set your Authorized redirect URIs to: `(protocol):/(host)/oauth2/code/google` Keep the client secret in a secure place.

Suivez les instructions de votre service IdP pour la configuration de votre IdP :

-   [Google](https://developers.google.com/identity/protocols/oauth2/openid-connect)

-   [Azure AD](https://medium.com/xebia-engineering/authentication-and-authorization-using-azure-active-directory-266980586ab8)

> **Note**
>
> Azure AD Authorized redirect URIs must have this form: `(protocol):/(host)/oauth2/code/my_azure_ad_tenant_id`

### Configurer le DHIS2 pour l'OIDC { #configure-dhis2-for-oidc }

> **N.B.**
>
> Avant d'effectuer les étapes décrites ici, vous devez configurer le fournisseur d'identité (IdP) de l'OIDC tel que décrit dans Configuration du fournisseur d'identité de l'OIDC.

Cette rubrique présente les options de configuration à définir dans `dhis.conf`. N'oubliez pas de redémarrer DHIS 2 pour que les changements prennent effet.

To enable OIDC, start by setting the following property in `dhis.conf`.

```properties
oidc.oauth2.login.enabled = on
```

The following sections cover provider-specific configuration.

#### Google { #google }

```properties
# ----------------------------------------------------------------------
# Example of Google OIDC Configuration
# ----------------------------------------------------------------------

# Generic config parameters

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)

# Google specific parameters:
oidc.provider.google.client_id = my_client_id
oidc.provider.google.client_secret = my_client_secret

# DHIS 2 instance URL, do not end with a slash, e.g.: https://dhis2.org/demo
oidc.provider.google.redirect_url = (protocol)://(host)/(optional app context)

# Optional, defaults to 'email'
oidc.provider.google.mapping_claim = email

```

#### Azure AD { #azure-ad }

Note that Azure AD supports having multiple tenants, hence the numbering scheme `oidc.provider.azure.NUMBER.VARIABLE` below.

Make sure your Azure AD account in the Azure portal is configured with a redirect URL like `(protocol):/(host)/oauth2/code/my_azure_ad_tenant_id`. To register DHIS 2 as an "app" in the Azure portal, follow these steps:

1. Search for and select _App registrations_.

2. Click _New registration_.

3. In the _Name_ field, enter a descriptive name for your DHIS 2 instance.

4. In the _Redirect URI_ field, enter the redirect URL as specified above.

5. Click _Register_.

```properties
# ----------------------------------------------------------------------
# Example of Azure OIDC Configuration
# ----------------------------------------------------------------------

# Generic config parameters

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)

# Azure AD specific parameters:

# First provider (0)
oidc.provider.azure.0.tenant = my_azure_ad_tenant_id
oidc.provider.azure.0.client_id = my_azure_ad_client_id
oidc.provider.azure.0.client_secret = my_azure_ad_client_secret

# DHIS 2 instance URL, do not end with a slash, e.g.: https://dhis2.org/demo
oidc.provider.azure.0.redirect_url = (protocol)://(host)/(optional app context)

# Optional, defaults to 'email'
oidc.provider.azure.0.mapping_claim = email

# Optional, defaults to 'true'
oidc.provider.azure.0.support_logout = true

# Second provider (1)
oidc.provider.azure.1.tenant = my_other_azure_ad_tenant_id
...
```

#### Generic Providers { #generic-providers }

The "generic" provider can be used to configure any OIDC provider that uses the "default" features in Spring Security.

In the example below we configure the Norwegian governmental health service OIDC provider.

The client name here is _helseid_ and will automatically show up on the login page as a button with the same name or the name of the _display_alias_ if defined.

The DHIS2 generic providers uses the following hard coded defaults for:

-   Client Authentication: https://tools.ietf.org/html/rfc6749#section-2.3 > ClientAuthenticationMethod.BASIC

-   Authenticated Requests: https://tools.ietf.org/html/rfc6750#section-2 > AuthenticationMethod.HEADER

> **Note**
>
> The following client names are reserved for non-generic provider use and can not be used here: "google","azure","wso2".

```properties
# ----------------------------------------------------------------------
# Example of Generic OIDC Configuration
# ----------------------------------------------------------------------

# Generic config parameters

# Enable OIDC
oidc.oauth2.login.enabled = on

# DHIS 2 instance URL, do not end with a slash, not all IdPs support logout (Where to end up after calling end_session_endpoint on the IdP)
oidc.logout.redirect_url = (protocol)://(host)/(optional app context)


# This is the name displayed on the DHIS2 login page
oidc.provider.helseid.display_alias = HelseID

oidc.provider.helseid.client_id = CLIENT_ID
oidc.provider.helseid.client_secret = CLIENT_SECRET
oidc.provider.helseid.mapping_claim = helseid://claims/identity/email
oidc.provider.helseid.authorization_uri = https://helseid.no/connect/authorize
oidc.provider.helseid.enable_logout = true
oidc.provider.helseid.token_uri = https://helseid.no/connect/token
oidc.provider.helseid.user_info_uri = https://helseid.no/connect/userinfo
oidc.provider.helseid.jwk_uri = https://helseid.no/.well-known/openid-configuration/jwks
oidc.provider.helseid.end_session_endpoint = https://helseid.no/connect/endsession
oidc.provider.helseid.scopes = helseid://scopes/identity/email
oidc.provider.helseid.redirect_url = {baseUrl}/oauth2/code/{registrationId}

# (You can link to an url for any logo here as long as it is served from the same domain as the DHIS2 server.)
oidc.provider.helseid.logo_image = ../security/btn_helseid.svg
oidc.provider.helseid.logo_image_padding = 0px 1px

# (These values are appended to the request, they must be key/value pairs like: "KEY1 VALUE1,KEY2 VALUE2,...")
oidc.provider.helseid.extra_request_parameters = acr_values lvl4

# (This is for optional PKCE support see: https://oauth.net/2/pkce/) Default value is: FALSE
oidc.provider.helseid.enable_pkce = true

```

## LDAP configuration { #install_ldap_configuration }

DHIS2 is capable of using an LDAP server for authentication of users. For LDAP authentication it is required to have a matching user in the DHIS2 database per LDAP entry. The DHIS2 user will be used to represent authorities / user roles.

To set up LDAP authentication you need to configure the LDAP server URL, a manager user and an LDAP search base and search filter. This configuration should be done in the main DHIS 2 configuration file (dhis.conf). LDAP users, or entries, are identified by distinguished names (DN from now on). An example configuration looks like this:

```propriétés
# URL du serveur LDAP
ldap.url = ldaps://domain.org:636

# Nom distinctif de l'entrée du gestionnaire LDAP
ldap.manager.dn = cn=johndoe,dc=domain,dc=org

# Mot de passe d'entrée du gestionnaire LDAP
ldap.manager.password = xxxx

# Recherche de base LDAP
ldap.search.base = dc=domaine,dc=org

# Filtre de recherche LDAP
ldap.search.filter = (cn={0})
```

Les propriétés de configuration LDAP sont expliquées ci-dessous :

-   _ldap.url:_ The URL of the LDAP server for which to authenticate against. Using SSL/encryption is strongly recommended in order to make authentication secure. As example URL is _ldaps://domain.org:636_, where ldaps refers to the protocol, _domain.org_ refers to the domain name or IP address, and _636_ refers to the port (636 is default for LDAPS).

-   _ldap.manager.dn:_ An LDAP manager user is required for binding to the LDAP server for the user authentication process. This property refers to the DN of that entry. I.e. this is not the user which will be authenticated when logging into DHIS2, rather the user which binds to the LDAP server in order to do the authentication.

-   _ldap.manager.password:_ The password for the LDAP manager user.

-   _ldap.search.base:_ The search base, or the distinguished name of the search base object, which defines the location in the directory from which the LDAP search begins.

-   _ldap.search.filter:_ The filter for matching DNs of entries in the LDAP directory. The {0} variable will be substituted by the DHIS2 username, or alternatively, the LDAP identifier defined for the user with the supplied username.

DHIS2 will use the supplied username / password and try to authenticate against an LDAP server entry, then look up user roles / authorities from a corresponding DHIS2 user. This implies that a user must have a matching entry in the LDAP directory as well as a DHIS2 user in order to log in.

During authentication, DHIS2 will try to bind to the LDAP server using the configured LDAP server URL and the manager DN and password. Once the binding is done, it will search for an entry in the directory using the configured LDAP search base and search filter.

The {0} variable in the configured filter will be substituted before applying the filter. By default, it will be substituted by the supplied username. You can also set a custom LDAP identifier on the relevant DHIS2 user account. This can be done through the DHIS2 user module user interface in the add or edit screen by setting the "LDAP identifier" property. When set, the LDAP identifier will be substituted for the {0} variable in the filter. This feature is useful when the LDAP common name is not suitable or cannot for some reason be used as a DHIS2 username.

## Encryption configuration { #install_encryption_configuration }

DHIS2 allows for encryption of data. Enabling it requires some extra setup. To provide security to the encryption algorithm you will have to set a password in the _dhis.conf_ configuration file through the _encryption.password_ property:

```properties
encryption.password = xxxx
```

The _encryption.password_ property is the password (key) used when encrypting and decrypting data in the database. Note that the password must not be changed once it has been set and data has been encrypted, as the data can then no longer be decrypted.

The password must be at least **24 characters long**. A mix of numbers and lower- and uppercase letters is recommended. The encryption password must be kept secret.

> **Important**
>
> It is not possible to recover encrypted data if the encryption password is lost or changed. If the password is lost, so is the encrypted data. Conversely, the encryption provides no security if the password is compromised. Hence, great consideration should be given to storing the password in a safe place.

Note that encryption support depends on the _Java Cryptography Extension_ (JCE) policy files to be available. These are included in all versions of OpenJDK and Oracle JDK 8 Update 144 or later.

## Read replica database configuration { #install_read_replica_configuration }

DHIS 2 allows for utilizing read only replicas of the master database (the main DHIS 2 database). The purpose of read replicas is to enhance the performance of database read queries and scale out the capacity beyond the constraints of a single database. Read-heavy operations such as analytics and event queries will benefit from this.

The configuration requires that you have created one or more replicated instances of the master DHIS 2 database. PostgreSQL achieves this through a concept referred to as _streaming replication_. Configuring read replicas for PostgreSQL is not covered in this guide.

Read replicas can be defined in the _dhis.conf_ configuration file. You can specify up to 5 read replicas per DHIS 2 instance. Each read replica is denoted with a number between 1 and 5. The JDBC connection URL must be defined per replica. The username and password can be specified; if not, the username and password for the master database will be used instead.

The configuration for read replicas in _dhis.conf_ looks like the below. Each replica is specified with the configuration key _readN_ prefix, where N refers to the replica number.

```propriétés
# Configuration du réplica en lecture 1

# URL de connexion à la base de données, nom d'utilisateur et mot de passe
read1.connection.url = jdbc:postgresql://127.0.0.11/dbread1
read1.connection.username = dhis
read1.connection.password = xxxx

# Configuration du réplica en lecture 2

# URL de connexion à la base de données, nom d'utilisateur et mot de passe
read2.connection.url = jdbc:postgresql://127.0.0.12/dbread2
read2.connection.username = dhis
read2.connection.password = xxxx

# Configuration du réplica en lecture 3

# URL de connexion à la base de données, retour à la base de données principale pour le nom d'utilisateur et le mot de passe
read3.connection.url = jdbc:postgresql://127.0.0.13/dbread3
```

Note that you must restart your servlet container for the changes to take effect. DHIS 2 will automatically distribute the load across the read replicas. The ordering of replicas has no significance.

## Web server cluster configuration { #install_web_server_cluster_configuration }

This section describes how to set up the DHIS 2 application to run in a cluster.

### Clustering overview { #install_cluster_configuration_introduction }

Clustering is a common technique for improving system scalability and availability. Clustering refers to setting up multiple web servers such as Tomcat instances and have them serve a single application. Clustering allows for _scaling out_ an application in the sense that new servers can be added to improve performance. It also allows for _high availability_ as the system can tolerate instances going down without making the system inaccessible to users.

There are a few aspects to configure in order to run DHIS 2 in a cluster.

-   Each DHIS 2 instance must specify the other DHIS 2 instance members of the cluster in _dhis.conf_.

-   A Redis data store must be installed and connection information must be provided for each DHIS 2 application instance in _dhis.conf_.

-   DHIS 2 instances and servers must share the same _files_ folder used for apps and file uploads, either through the _AWS S3 cloud filestorage_ option or a shared network drive.

-   A load balancer such as nginx must be configured to distribute Web requests across the cluster instances.

### DHIS 2 instance cluster configuration { #install_cluster_configuration }

When setting up multiple Tomcat instances there is a need for making the instances aware of each other. This awareness will enable DHIS 2 to keep the local data (Hibernate) caches in sync and in a consistent state. When an update is done on one instance, the caches on the other instances must be notified so that they can be invalidated and avoid becoming stale.

A DHIS 2 cluster setup is based on manual configuration of each instance. For each DHIS 2 instance one must specify the public _hostname_ as well as the hostnames of the other instances participating in the cluster.

The hostname of the server is specified using the _cluster.hostname_ configuration property. Additional servers which participate in the cluster are specified using the _cluster.members_ configuration property. The property expects a list of comma separated values where each value is of the format _host:port_.

The hostname must be visible to the participating servers on the network for the clustering to work. You might have to allow incoming and outgoing connections on the configured port numbers in the firewall.

The port number of the server is specified using the _cluster.cache.port_ configuration property. The remote object port used for registry receive calls is specified using _cluster.cache.remote.object.port_. Specifying the port numbers is typically only useful when you have multiple cluster instances on the same server or if you need to explicitly specify the ports to match a firewall configuration. When running cluster instances on separate servers it is often appropriate to use the default port number and omit the ports configuration properties. If omitted, 4001 will be assigned as the listener port and a random free port will be assigned as the remote object port.

An example setup for a cluster of two web servers is described below. For _server A_ available at hostname _193.157.199.131_ the following can be specified in _dhis.conf_:

```properties
# Cluster configuration for server A

# Hostname for this web server
cluster.hostname = 193.157.199.131

# Ports for cache listener, can be omitted
cluster.cache.port = 4001
cluster.cache.remote.object.port = 5001

# List of Host:port participating in the cluster
cluster.members = 193.157.199.132:4001
```

For _server B_ available at hostname _193.157.199.132_ the following can be specified in _dhis.conf_ (notice how port configuration is omitted):

```properties
# Cluster configuration for server B

# Hostname for this web server
cluster.hostname = 193.157.199.132

# List of servers participating in cluster
cluster.members = 193.157.199.131:4001
```

You must restart each Tomcat instance to make the changes take effect. The two instances have now been made aware of each other and DHIS 2 will ensure that their caches are kept in sync.

### Redis shared data store cluster configuration { #install_cluster_configuration_redis }

In a cluster setup, a _Redis_ instance is required and will handle shared user sessions, application cache and cluster node leadership.

For optimum performance, _Redis Keyspace events_ for _generic commands_ and _expired events_ need to be enabled in the Redis Server. If you are using a cloud platform-managed Redis server (like _AWS ElastiCache for Redis_ or _Azure Cache for Redis_) you will have to enable keyspace event notifications using the respective cloud console interfaces. If you are setting up a standalone Redis server, enabling keyspace event notifications can be done in the _redis.conf_ file by adding or uncommenting the following line:

```
notify-keyspace-events Egx
```

DHIS2 will connect to Redis if the _redis.enabled_ configuration property in _dhis.conf_ is set to _true_ along with the following properties:

-   _redis.host_: Specifies where the redis server is running. Defaults to _localhost_. Mandatory.

-   _redis.port_: Specifies the port in which the redis server is listening. Defaults to _6379_. Optional.

-   _redis.password_: Specifies the authentication password. If a password is not required it can be left blank.

-   _redis.use.ssl_: Specifies whether the Redis server has SSL enabled. Defaults to false. Optional. Defaults to _false_.

When Redis is enabled, DHIS2 will automatically assign one of the running instances as the leader of the cluster. The leader instance will be used to execute jobs or scheduled tasks that should be run exclusively by one instance. Optionally you can configure the _leader.time.to.live.minutes_ property in _dhis.conf_ to set up how frequently the leader election needs to occur. It also gives an indication of how long it would take for another instance to take over as the leader after the previous leader has become unavailable. The default value is 2 minutes. Note that assigning a leader in the cluster is only done if Redis is enabled. An example snippet of the _dhis.conf_ configuration file with Redis enabled and leader election time configured is shown below.

```properties
# Redis Configuration

redis.enabled = true

redis.host = 193.158.100.111

redis.port = 6379

redis.password = <your password>

redis.use.ssl = false

# Optional, defaults to 2 minutes
leader.time.to.live.minutes=4
```

### Files folder configuration { #files-folder-configuration }

DHIS 2 will store several types of files outside the application itself, such as apps, files saved in data entry and user avatars. When deployed in a cluster, the location of these files must be shared across all instances. On the local filesystem, the location is:

```
{DHIS2_HOME}/files
```

Here, `DHIS2_HOME` refers to the location of the DHIS 2 configuration file as specified by the DHIS 2 environment variable, and `files` is the file folder immediately below.

Il existe deux manières d'obtenir un emplacement partagé :

-   Use the _AWS S3 cloud filestorage_ option. Files will be stored in an S3 bucket which is automatically shared by all DHIS 2 instances in the cluster. See the _File store configuration_ section for guidance.
-   Set up a shared folder which is shared among all DHIS 2 instances and servers in the cluster. On Linux this can be achieved with _NFS_ (Network File System) which is a distributed file system protocol. Note that only the `files` subfolder under `DHIS2_HOME` should be shared, not the parent folder.

### Load balancer configuration { #install_load_balancing }

With a cluster of Tomcat instances set up, a common approach for routing incoming web requests to the backend instances participating in the cluster is using a _load balancer_. A load balancer will make sure that load is distributed evenly across the cluster instances. It will also detect whether an instance becomes unavailable, and if so, stop routine requests to that instance and instead use other available instances.

Load balancing can be achieved in multiple ways. A simple approach is using _nginx_, in which case you will define an _upstream_ element which enumerates the location of the backend instances and later use that element in the _proxy_ location block.

```text
http {

  # Upstream element with sticky sessions

  upstream dhis_cluster {
    ip_hash;
    server 193.157.199.131:8080;
    server 193.157.199.132:8080;
  }

  # Proxy pass to backend servers in cluster

  server {
    listen 80;

    location / {
      proxy_pass   http://dhis_cluster/;
    }
  }
}
```

DHIS 2 keeps server-side state for user sessions to a limited degree. Using "sticky sessions" is a simple approach to avoid replicating the server session state by routing requests from the same client to the same server. The _ip_hash_ directive in the upstream element ensures this.

Note that several instructions have been omitted for brevity in the above example. Consult the reverse proxy section for a detailed guide.

## Analytics cache configuration { #install_analytics_cache_configuration }

DHIS 2 supports a server-side cache for analytics API responses, used by all of the analytics web apps. This cache sits within the DHIS 2 application and hence is protected by the DHIS 2 authentication and security layer. You can configure the expiration of cached entries in seconds. To enable the cache you can define the `analytics.cache.expiration` property in `dhis.conf`. The example below enabled the cache and sets expiration to one hour.

```properties
analytics.cache.expiration = 3600
```

## Surveillance { #monitoring }

DHIS 2 peut exporter des métriques compatibles avec Prometheus pour la surveillance des instances DHIS2. L'infrastructure de surveillance de DHIS2 est conçue pour exposer les métriques liées à l'exécution de l'application et d'autres informations relatives à l'application.

Les métriques liées à l'infrastructure (telles que les métriques de l'hôte, Tomcat ou Postgres) ne sont pas directement exposées par le moteur de surveillance de l'application et doivent être collectées séparément. Les métriques actuellement exposées par l'application sont :

-   API DHIS 2 (temps de réponse, nombre d'appels, etc.)
-   JVM (taille du tas, récupération de l'espace mémoire, etc.)
-   Mise en veille prolongée (requêtes, cache, etc.)
-   C3P0 Database pool
-   Disponibilité des applications
-   CPU

La surveillance peut être activé dans `dhis.conf` avec les propriétés suivantes (la valeur par défaut est `désactivé` pour toutes les propriétés) :

```propriétés
surveillance.api.enabled = activé
surveillance.jvm.enabled = activé
surveillance.dbpool.enabled = activé
surveillance.hibernate.enabled = désactivé
surveillance.uptime.enabled = activé
surveillance.cpu.enabled = activé
```

The recommended approach for collecting and visualizing these metrics is through Prometheus and Grafana.

For more information, see the [monitoring infrastructure](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md) page and the [Prometheus and Grafana install](https://docs.dhis2.org/master/en/dhis2_system_administration_guide/monitoring.html) chapter.

## Reverse proxy configuration { #install_reverse_proxy_configuration }

A reverse proxy is a proxy server that acts on behalf of a server. Using a reverse proxy in combination with a servlet container is optional but has many advantages:

-   Requests can be mapped and passed on to multiple servlet containers. This improves flexibility and makes it easier to run multiple instances of DHIS2 on the same server. It also makes it possible to change the internal server setup without affecting clients.

-   The DHIS2 application can be run as a non-root user on a port different than 80 which reduces the consequences of session hijacking.

-   The reverse proxy can act as a single SSL server and be configured to inspect requests for malicious content, log requests and responses and provide non-sensitive error messages which will improve security.

### Basic nginx setup { #install_basic_nginx_setup }

We recommend using [nginx](http://www.nginx.org) as a reverse proxy due to its low memory footprint and ease of use. To install invoke the following:

    sudo apt-get install nginx

nginx can now be started, reloaded and stopped with the following commands:

    sudo /etc/init.d/nginx start
    sudo /etc/init.d/nginx reload
    sudo /etc/init.d/nginx stop

Now that we have installed nginx we will now continue to configure regular proxying of requests to our Tomcat instance, which we assume runs at _http://localhost:8080_. To configure nginx you can open the configuration file by invoking:

    sudo nano /etc/nginx/nginx.conf

nginx configuration is built around a hierarchy of blocks representing http, server and location, where each block inherits settings from parent blocks. The following snippet will configure nginx to proxy pass (redirect) requests from port 80 (which is the port nginx will listen on by default) to our Tomcat instance. Include the following configuration in nginx.conf:

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  server {
    listen               80;
    client_max_body_size 10M;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  http;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

You can now access your DHIS2 instance at _http://localhost_. Since the reverse proxy has been set up we can improve security by making Tomcat only listen for local connections. In _/conf/server.xml_ you can add an _address_ attribute with the value _localhost_ to the Connector element for HTTP 1.1 like this:

```xml
<Connector address="localhost" protocol="HTTP/1.1" />
```

### Enabling SSL with nginx { #install_enabling_ssl_on_nginx }

In order to improve security it is recommended to configure the server running DHIS2 to communicate with clients over an encrypted connection and to identify itself to clients using a trusted certificate. This can be achieved through SSL which is a cryptographic communication protocol running on top of TCP/IP. First, install the required _openssl_ library:

    sudo apt-get install openssl

To configure nginx to use SSL you will need a proper SSL certificate from an SSL provider. The cost of a certificate varies a lot depending on encryption strength. An affordable certificate from [Rapid SSL Online](http://www.rapidsslonline.com) should serve most purposes. To generate the CSR (certificate signing request) you can invoke the command below. When you are prompted for the _Common Name_, enter the fully qualified domain name for the site you are securing.

    openssl req -new -newkey rsa:2048 -nodes -keyout server.key -out server.csr

When you have received your certificate files (.pem or .crt) you will need to place it together with the generated server.key file in a location which is reachable by nginx. A good location for this can be the same directory as where your nginx.conf file is located.

Below is an nginx server block where the certificate files are named server.crt and server.key. Since SSL connections usually occur on port 443 (HTTPS) we pass requests on that port (443) on to the DHIS2 instance running on _http://localhost:8080_ The first server block will rewrite all requests connecting to port 80 and force the use of HTTPS/SSL. This is also necessary because DHIS2 is using a lot of redirects internally which must be passed on to use HTTPS. Remember to replace _\<server-ip\>_ with the IP of your server. These blocks should replace the one from the previous section.

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  # HTTP server - rewrite to force use of SSL

  server {
    listen     80;
    rewrite    ^ https://<server-url>$request_uri? permanent;
  }

  # HTTPS server

  server {
    listen               443 ssl;
    client_max_body_size 10M;

    ssl                  on;
    ssl_certificate      server.crt;
    ssl_certificate_key  server.key;

    ssl_session_cache    shared:SSL:20m;
    ssl_session_timeout  10m;

    ssl_protocols              TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers                RC4:HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

Note the last `https` header value which is required to inform the servlet container that the request is coming over HTTPS. In order for Tomcat to properly produce `Location` URL headers using HTTPS you also need to add two other parameters to the Connector in the Tomcat `server.xml` file:

```xml
<Connector scheme="https" proxyPort="443" />
```

### Enabling caching with nginx { #install_enabling_caching_ssl_nginx }

Requests for reports, charts, maps and other analysis-related resources will often take some time to respond and might utilize a lot of server resources. In order to improve response times, reduce the load on the server and hide potential server downtime we can introduce a cache proxy in our server setup. The cached content will be stored in directory /var/cache/nginx, and up to 250 MB of storage will be allocated. Nginx will create this directory automatically.

```text
http {
  ..
  proxy_cache_path  /var/cache/nginx  levels=1:2  keys_zone=dhis:250m  inactive=1d;


  server {
    ..

    # Proxy pass to servlet container and potentially cache response

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
      proxy_cache               dhis;
    }
  }
}
```

> **Important**
>
> Be aware that a server side cache shortcuts the DHIS2 security features in the sense that requests which hit the server side cache will be served directly from the cache outside the control of DHIS2 and the servlet container. This implies that request URLs can be guessed and reports retrieved from the cache by unauthorized users. Hence, if you capture sensitive information, setting up a server side cache is not recommended.

### Rate limiting with nginx { #install_rate_limiting }

Certains appels d'API web dans DHIS 2, tels que les API d'`analyses`, nécessitent beaucoup de calculs. Par conséquent, il est préférable de limiter le débit de ces API afin d'équilibrer l'utilisation des ressources du serveur par les utilisateurs du système. La limitation de débit peut être effectuée avec `nginx`. Il existe plusieurs approches pour effectuer la limitation de débit et ceci est destiné à documenter l'approche basée sur nginx.

The below nginx configuration will rate limit the `analytics` web API, and has the following elements at the _http_ and _location_ block level (the configuration is shortened for brevity):

```text
http {
  ..
  limit_req_zone $binary_remote_addr zone=limit_analytics:10m rate=5r/s;

  server {
    ..

    location ~ ^/api/(\d+/)?analytics(.*)$ {
      limit_req    zone=limit_analytics burst=20;
      proxy_pass   http://localhost:8080/api/$1analytics$2$is_args$args;
      ..
    }
  }
}
```

Les différents éléments de la configuration peuvent être décrits comme suit :

-   _limit_req_zone $binary_remote_addr_: Rate limiting is done per request IP.
-   _zone=limit_analytics:20m_: A rate limit zone for the analytics API which can hold up to 10 MB of request IP addresses.
-   _rate=20r/s_: Each IP is granted 5 requests per second.
-   _location ~ ^/api/(\d+/)?analytics(.\*)$_: Requests for the analytics API endpoint are rate limited.
-   _burst=20_: Bursts of up to 20 requests will be queued and serviced at a later point; additional requests will lead to a `503`.

Pour obtenir une explication complète, veuillez consulter la [documentation nginx](https://www.nginx.com/blog/rate-limiting-nginx/).

### Making resources available with nginx { #install_making_resources_available_with_nginx }

In some scenarios it is desirable to make certain resources publicly available on the Web without requiring authentication. One example is when you want to make data analysis related resources in the web API available in a Web portal. The following example will allow access to charts, maps, reports, report table and document resources through basic authentication by injecting an _Authorization_ HTTP header into the request. It will remove the Cookie header from the request and the Set-Cookie header from the response in order to avoid changing the currently logged in user. It is recommended to create a user for this purpose given only the minimum authorities required. The Authorization value can be constructed by Base64-encoding the username appended with a colon and the password and prefix it "Basic ", more precisely "Basic base64_encode(username:password)". It will check the HTTP method used for requests and return _405 Method Not Allowed_ if anything but GET is detected.

It can be favorable to set up a separate domain for such public users when using this approach. This is because we don't want to change the credentials for already logged in users when they access the public resources. For instance, when your server is deployed at somedomain.com, you can set a dedicated subdomain at api.somedomain.com, and point URLs from your portal to this subdomain.

```text
http {
  ..

  server {
    listen       80;
    server_name  api.somedomain.com;

    location ~ ^/(api/(charts|chartValues|reports|reportTables|documents|maps|organisationUnits)|dhis-web-commons/javascripts|images|dhis-web-commons-ajax-json|dhis-web-mapping|dhis-web-visualizer) {
    if ($request_method != GET) {
        return 405;
      }

      proxy_pass         http://localhost:8080;
      proxy_redirect     off;
      proxy_set_header   Host               $host;
      proxy_set_header   X-Real-IP          $remote_addr;
      proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto  http;
      proxy_set_header   Authorization      "Basic YWRtaW46ZGlzdHJpY3Q=";
      proxy_set_header   Cookie             "";
      proxy_hide_header  Set-Cookie;
    }
  }
}
```

### Blocking specific Android App versions with nginx { #install_making_resources_available_with_nginx }

In some scenarios the system administrator might want to block certain Android clients based on its DHIS2 App version. For example, if the users on the field have not updated their Android App version to a specific one and the system administrator wants to block their access to force an update; or completely the opposite scenario when the system administrator wants to block new versions of the App as they have not been yet tested. This can be easily implemented by using specific _User-Agent_ rules in the `nginx` configuration file.

```text
http {
  ..

  server {
    listen       80;
    server_name  api.somedomain.com;

    ..


    # Block the latest Android App as it has not been tested (August 2020 - Last version is 2.2.1)
    if ( $http_user_agent ~ 'com\.dhis2/1\.2\.1/2\.2\.1/' ) {
        return 403;
    }

    # Block Android 4.4 (API is 19) as all the users should have received the new tablets
    if ( $http_user_agent ~ 'com\.dhis2/.*/.*/Android_19' ) {
        return 403;
    }
    ..

    }

    ..
}
```

> Note
>
> For the implementation of the method described above note the following:
>
> -   Before version 1.1.0 the _User-Agent_ string was not being sent
> -   From version 1.1.0 to 1.3.2 the _User-Agent_ followed the pattern Dhis2/AppVersion/AppVersion/Android_XX
> -   From version 2.0.0 and above the _User-Agent_ follows the pattern com.dhis2/SdkVersion/AppVersion/Android_XX
>
> Android_XX refers to the Android API level i.e. the Android version as listed [here](https://developer.android.com/studio/releases/platforms).
>
> nginx uses [PCRE](http://www.pcre.org/) for Regular Expression matching

## DHIS2 configuration reference { #install_dhis2_configuration_reference }

The following describes the full set of configuration options for the _dhis.conf_ configuration file. The configuration file should be placed in a directory which is pointed to by a _DHIS2_HOME_ environment variable.

> **Remarque**
>
> Vous ne devez pas utiliser ce fichier de configuration directement, mais plutôt comme référence pour les options de configuration disponibles. Plusieurs propriétés sont facultatives.

```properties
# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Mandatory]
# ----------------------------------------------------------------------

# Hibernate SQL dialect
connection.dialect = org.hibernate.dialect.PostgreSQLDialect

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password (sensitive)
connection.password = xxxx

# Max size of connection pool (default: 40)
connection.pool.max_size = 40

# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Optional]
# ----------------------------------------------------------------------

# Minimum number of Connections a pool will maintain at any given time (default: 5).
connection.pool.min_size=5

# Initial size of connection pool (default : 5)
#Number of Connections a pool will try to acquire upon startup. Should be between minPoolSize and maxPoolSize
connection.pool.initial_size=5

#Determines how many connections at a time will try to acquire when the pool is exhausted.
connection.pool.acquire_incr=5

#Seconds a Connection can remain pooled but unused before being discarded. Zero means idle connections never expire. (default: 7200)
connection.pool.max_idle_time=7200

#Number of seconds that Connections in excess of minPoolSize should be permitted to remain idle in the pool before being culled (default: 0)
connection.pool.max_idle_time_excess_con=0

#If this is a number greater than 0, dhis2 will test all idle, pooled but unchecked-out connections, every this number of seconds. (default: 0)
connection.pool.idle.con.test.period=0

#If true, an operation will be performed at every connection checkout to verify that the connection is valid. (default: false)
connection.pool.test.on.checkout=false

#If true, an operation will be performed asynchronously at every connection checkin to verify that the connection is valid. (default: true)
connection.pool.test.on.checkin=true

#Defines the query that will be executed for all connection tests. Ideally this config is not needed as postgresql driver already provides an efficient test query. The config is exposed simply for evaluation, do not use it unless there is a reason to.
connection.pool.preferred.test.query=select 1

#Configure the number of helper threads used by dhis2 for jdbc operations. (default: 3)
connection.pool.num.helper.threads=3

# ----------------------------------------------------------------------
# Server [Mandatory]
# ----------------------------------------------------------------------

# Base URL to the DHIS 2 instance
server.base.url = https://play.dhis2.org/dev

# Enable secure settings if system is deployed on HTTPS, can be 'off', 'on'
server.https = off

# ----------------------------------------------------------------------
# System [Optional]
# ----------------------------------------------------------------------

# System mode for database read operations only, can be 'off', 'on'
system.read_only_mode = off

# Session timeout in seconds, default is 3600
system.session.timeout = 3600

# SQL view protected tables, can be 'on', 'off'
system.sql_view_table_protection = on

# ----------------------------------------------------------------------
# Encryption [Optional]
# ----------------------------------------------------------------------

# Encryption password (sensitive)
encryption.password = xxxx

# ----------------------------------------------------------------------
# File store [Optional]
# ----------------------------------------------------------------------

# File store provider, currently 'filesystem' and 'aws-s3' are supported
filestore.provider = filesystem

# Directory / bucket name, folder below DHIS2_HOME on file system, 'bucket' on AWS S3
filestore.container = files

# Datacenter location (not required)
filestore.location = eu-west-1

# Public identity / username
filestore.identity = dhis2-id

# Secret key / password (sensitive)
filestore.secret = xxxx

# ----------------------------------------------------------------------
# LDAP [Optional]
# ----------------------------------------------------------------------

# LDAP server URL
ldap.url = ldaps://300.20.300.20:636

# LDAP manager user distinguished name
ldap.manager.dn = cn=JohnDoe,ou=Country,ou=Admin,dc=hisp,dc=org

# LDAP manager user password (sensitive)
ldap.manager.password = xxxx

# LDAP entry distinguished name search base
ldap.search.base = dc=hisp,dc=org

# LDAP entry distinguished name filter
ldap.search.filter = (cn={0})

# ----------------------------------------------------------------------
# Node [Optional]
# ----------------------------------------------------------------------

# Node identifier, optional, useful in clusters
node.id = 'node-1'

# ----------------------------------------------------------------------
# Monitoring [Optional]
# ----------------------------------------------------------------------

# DHIS2 API monitoring
monitoring.api.enabled = on

# JVM monitoring
monitoring.jvm.enabled = on

# Database connection pool monitoring
monitoring.dbpool.enabled = on

# Hibernate monitoring, do not use in production
monitoring.hibernate.enabled = off

# Uptime monitoring
monitoring.uptime.enabled = on

# CPU monitoring
monitoring.cpu.enabled = on

# ----------------------------------------------------------------------
# Analytics [Optional]
# ----------------------------------------------------------------------

# Analytics server-side cache expiration in seconds
analytics.cache.expiration = 3600

# ----------------------------------------------------------------------
# System telemetry [Optional]
# ----------------------------------------------------------------------

# System monitoring URL
system.monitoring.url =

# System monitoring username
system.monitoring.username =

# System monitoring password (sensitive)
system.monitoring.password = xxxx
```

## Changelog { #install_changelog }

Le DHIS2 écrit des entrées dans les changelogs lorsque certaines entités sont modifiées dans le système. Ces entités appartiennent à deux catégories : _Agrégat_ et _Tracker_. La catégorie _Agrégat_ comprend les modifications apportées aux valeurs des données agrégées. Quant à la catégorie _Tracker_, elle comprend les modifications apportées aux instances de programme, aux éléments de propriété temporaire du programme, aux valeurs des attributs des entités suivies et aux valeurs des données des entités suivies.

Le changelog pour les deux catégories est activé par défaut. Vous pouvez contrôler l'activation ou la désactivation du changelog par catégorie par le biais du fichier de configuration `dhis.conf` en utilisant les propriétés décrites ci-dessous. Les options de propriétés sont `on`  (par défaut) et `off`.

L'avantage du changelog réside dans le fait qu'il permet de voir les modifications effectuées sur les données. L'avantage que présente la désactivation du changelog est une amélioration mineure des performances en évitant le coût d'écriture des éléments du changelog dans la base de données, et une réduction de la capacité de stockage de la base de données utilisée. Il est donc recommandé d'activer le changelog, et il faudra faire preuve d'une grande prudence en le désactivant.

```propriétés
# Le changelog de la catégorie Agrégat, peut être défini sur 'on', 'off'
changelog.aggregate = on

# Le changelog de la catégorie Tracker, peut être défini sur 'on', 'off'
changelog.tracker = on
```

## Application logging { #install_application_logging }

Cette section traite de la journalisation des applications dans DHIS 2.

### Log files { #log-files }

La sortie du journal de l'application DHIS2 est dirigée vers plusieurs fichiers et emplacements. Tout d'abord, la sortie du journal est envoyée à la sortie standard. Le conteneur de servlets Tomcat envoie généralement la sortie standard vers un fichier sous "logs" (journaux) :

    <tomcat-dir>/logs/catalina.out

Second, log output is written to a "logs" directory under the DHIS2 home directory as defined by the DHIS2_HOME environment variables. There is a main log file for all output, and separate log files for various background processes. The main file includes the background process logs as well. The log files are capped at 50 Mb and log content is continuously appended.

    <DHIS2_HOME>/logs/dhis.log
    <DHIS2_HOME>/logs/dhis-analytics-table.log
    <DHIS2_HOME>/logs/dhis-data-exchange.log
    <DHIS2_HOME>/logs/dhis-data-sync.log

### Log configuration { #log-configuration }

In order to override the default log configuration you can specify a Java system property with the name _log4j.configuration_ and a value pointing to the Log4j configuration file on the classpath. If you want to point to a file on the file system (i.e. outside Tomcat) you can use the _file_ prefix e.g. like this:

```properties
-Dlog4j.configuration=file:/home/dhis/config/log4j.properties
```

Java system properties can be set e.g. through the _JAVA_OPTS_ environment variable or in the tomcat startup script.

A second approach to overriding the log configuration is to specify logging properties in the _dhis.conf_ configuration file. The supported properties are:

```propriétés
# Taille maximale des fichiers journaux, la valeur par défaut est '100Mo'
journalisation.file.max_size = 250 Mo

# Nombre maximum de fichiers d'archives de journaux glissants, la valeur par défaut est 0
journalisation.file.max_archives = 2
```

DHIS2 will eventually phase out logging to standard out / catalina.out and as a result it is recommended to rely on the logs under DHIS2_HOME.

## Working with the PostgreSQL database { #install_working_with_the_postgresql_database }

Common operations when managing a DHIS2 instance are dumping and restoring databases. To make a dump (copy) of your database, assuming the setup from the installation section, you can invoke the following:

    pg_dump dhis2 -U dhis -f dhis2.sql

The first argument (dhis2) refers to the name of the database. The second argument (dhis) refers to the database user. The last argument (dhis2.sql) is the file name of the copy. If you want to compress the file copy immediately you can do:

    pg_dump dhis2 -U dhis | gzip > dhis2.sql.gz

To restore this copy on another system, you first need to create an empty database as described in the installation section. You also need to gunzip the copy if you created a compressed version. You can invoke:

    psql -d dhis2 -U dhis -f dhis2.sql

# Upgrading { #upgrading-dhis2 }

## Upgrading vs. Updating { #upgrading-vs-updating }

When we talk about upgrading DHIS2, we generally simply mean "moving to a newer version". However, there is an important distinction between _upgrading_ and _updating_.

**Upgrading** : Moving to a newer base version of DHIS2 (for example, from 2.34 to 2.36). Upgrading typically requires planning, testing, training (for new features or interfaces), which may take significant time and effort.

**Updating** : Moving to a newer patch of the current DHIS2 version (for example, from 2.35.1 to 2.35.4). Updating mainly provides bug fixes without changing the functionality of the software. It is lower risk, and we advise everyone to keep their version up to date.

## Before you begin { #upgrading-before-you-begin }

> **Caution**
>
> It is important to note that once you upgrade you will not be able to use the upgraded database with an older version of DHIS2. That is to say **it is not possible to downgrade**.
>
> If you wish to revert to an older version, you must do so with a copy of the database that was created from that older version, or a previous version. Therefore, it is almost always a good idea to make a copy of your database before you uprgrade.

## Performing the upgrade { #upgrading-process }

Regardless of whether you are upgrading or updating, the technical process is more-or-less identical. We will just refer to it as upgrading.

### 1 Safeguard your data { #upgrading-safeguard-your-data }

Depending on what sort of DHIS2 instance you have, and what you use it for, the first step is to make sure that you can recover any important data if anything goes wrong with the upgrade.

This means performing standard system admin tasks, such as:

1. Backing up your database
2. Testing in a development environment
3. Scheduling down time (to avoid data being entered during the upgrade)
4. etc.

### 2 Upgrade the software { #upgrading-upgrade-the-software }

#### From v2.29 or below { #upgrading-pre-230 }

If you are starting from v2.29 or below, you must first upgrade to v2.30 version-by-version, manually, following the upgrade notes you find under the specific version numbers on [our releases site](https://github.com/dhis2/dhis2-releases). When you are at v2.30 you can go to the next section.

#### From v2.30 or above { #upgrading-post-230 }

If you are starting from at least v2.30:

1. **Read all of the upgrade notes from your current version up to the target version on [our releases site](https://github.com/dhis2/dhis2-releases).** Make sure your environment meets all of the requirements
2. Make a copy of your database if you didn't do so in step 1
3. Drop any materialized SQL views from your database
4. Stop the server
5. Replace the war file with the target version (There is no need to upgrade to intermediate versions; in fact, it is not recommended)
6. Démarrer le serveur

You should now be ready to enjoy the new fixes and features.

# Surveillance { #monitoring }

## Introduction { #monitoring }

DHIS2 peut exporter des mesures compatibles avec [Prometheus] (https://prometheus.io/) pour surveiller les nœuds de DHIS2.

Cette section décrit les étapes nécessaires pour installer Prometheus et [Grafana] (https://grafana.com/) à l'aide d'une procédure d'installation standard (`apt-get`) et de Docker, et pour configurer Grafana afin qu'il affiche les mesures de DHIS2.

Pour une liste des mesures exposées par une instance DHIS2, veuillez vous référer au guide du suivi sur [GitHub] (https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md).

## Setup { #monitoring_setup }

Les sections suivantes décrivent comment configurer Prometheus et Grafana et comment configurer Prometheus pour extraire des données d'une ou plusieurs instances DHIS2.

### Installing Prometheus + Grafana on Ubuntu and Debian { #prometheus }

-   Téléchargez Prometheus depuis la page officielle [download](https://prometheus.io/download/).

-   Veillez à appliquer un filtre à votre système d'exploitation et à l'architecture de votre processeur (Linux et amd64).

-   Veillez à sélectionner la dernière version stable, et non la version "rc", car elle n'est pas considérée comme suffisamment stable pour l'instant.

-   Téléchargez l'archive, soit en cliquant sur le lien, ou en utilisant `wget`.

```
wget https://github.com/prometheus/prometheus/releases/download/v2.15.2/prometheus-2.15.2.linux-amd64.tar.gz
```

-   Untar the zip

```
tar xvzf prometheus-2.15.2.linux-amd64.tar.gz
```

L'archive contient de nombreux fichiers importants, mais voici les principaux que vous devez connaître.

-   `prometheus.yml` : le fichier de configuration de Prometheus. C'est ce fichier que vous allez modifier afin d'ajuster votre serveur Prometheus, par exemple pour changer l'intervalle de récupération ou pour configurer des alertes personnalisées ;
-   `prometheus` : le binaire de votre serveur Prometheus. C'est la commande que vous allez exécuter pour lancer une instance de Prometheus sur votre boîte Linux ;
-   `promtool` : il s'agit d'une commande que vous pouvez exécuter pour vérifier votre configuration Prometheus.

### Configuring Prometheus as a service { #prometheus_service }

-   Créer un utilisateur `Prometheus` avec un groupe `Prometheus`.

```
useradd -rs /bin/false prometheus
```

-   Déplacer les binaires Prometheus dans un répertoire bin local

```
cd prometheus-2.15.2.linux-amd64/
cp prometheus promtool /usr/local/bin
chown prometheus:prometheus /usr/local/bin/prometheus
```

-   Créez un dossier dans le dossier `/etc` pour Prometheus et déplacez les fichiers de la console, les bibliothèques de la console et le fichier de configuration de Prometheus dans ce dossier nouvellement créé.

```
mkdir /etc/prometheus
cp -R consoles/ console_libraries/ prometheus.yml /etc/prometheus
```

Créez un dossier de données à la racine du répertoire, avec un dossier prometheus à l'intérieur.

```
mkdir -p data/prometheus
chown -R prometheus:prometheus /data/prometheus /etc/prometheus/*
```

### Create a Prometheus service { #prometheus_create_service }

Pour créer un service _systemd_ Prometheus, rendez-vous dans le dossier `/lib/systemd/system` et créez un nouveau fichier systemd nommé `prometheus.service`.

```
cd /lib/systemd/system
touch prometheus.service
```

-   Modifiez le fichier nouvellement créé et coller le contenu suivant à l'intérieur :

```propriétés
[Unité]
Description=Prometheus
Souhaite=réseau-cible.en ligne
Après=éseau-cible.en ligne

[Service]
Type=simple
Utilisateur=prometheus
Groupe=prometheus
ExecStart=/usr/local/bin/prometheus \
  --fichier.de configuration=/etc/prometheus/prometheus.yml \
  --storage.tsdb.path="/data/prometheus" \
  --web.console.modèles=/etc/prometheus/consoles \
  --web.console.bibliothèque=/etc/prometheus/console_libraries \
  --web.adresse-écoute=0.0.0.0:9090 \
  --web. activer-l'api de-l'administrateur

Redémarrer=toujours

[Installer]
Requis par=multi-utilisateur.cible
```

-   Enregistrer le fichier et activer le service Prometheus au démarrage

```
systemctl enable prometheus
systemctl start prometheus
```

-   Tester que le service est en cours d'exécution

```
systemctl status prometheus

...
Active : active (en cours d'exécution)
```

-   Il devrait maintenant être possible d'accéder à l'interface utilisateur de Prometheus en accédant à `http://localhost:9090`.

### Set-up Nginx reverse proxy { #prometheus_nginx }

Prometheus ne prend pas en charge l'authentification ou le cryptage TLS de manière automatique. Si Prometheus doit être exposé en dehors des limites du réseau local, il est important d'activer l'authentification et le cryptage TLS. Les étapes suivantes montrent comment utiliser Nginx comme proxy inverse.

-   Installer Nginx, s'il n'est pas déjà installé

```
apt mise à jour
apt-installer nginx
```

Par défaut, Nginx commence à écouter les requêtes HTTP sur le port `http` par défaut, qui est `80`.

Si une instance Nginx fonctionne déjà sur la machine et que vous ne savez pas sur quel port elle est à l'écoute, exécutez la commande suivante :

```
> lsof | grep LISTEN | grep nginx

nginx   15792   root   8u   IPv4   1140223421   0t0   TCP *:http (LISTEN)
```

La dernière colonne indique le port utilisé par Nginx (`http` -> `80`).

Par défaut, la configuration de Nginx est située dans `/etc/nginx/nginx.conf`

Assurez-vous que `nginx.conf` contient la section `Virtual Host Config`

```
##
# Configurations du serveur virtuel
##

Inclut  /etc/nginx/conf.d/*.conf;
Inclut  /etc/nginx/sites-enabled/*;

```

-   Créez un nouveau fichier dans `/etc/nginx/conf.d` du nom de `prometheus.conf`

```
touch /etc/nginx/conf.d/prometheus.conf
```

-   Modifiez le fichier nouvellement créé et coller le contenu suivant à l'intérieur :

```
serveur {
  écoute 1234;

  localisation / {
    proxy_pass           http://localhost:9090/;
  }
}
```

-   Restart Nginx and browse to http://localhost:1234

```
systemctl redémarrer nginx

# en cas d'erreurs de démarrage
journalctl -f -u nginx.service
```

-   Configurez Prometheus pour le proxy inverse, en éditant `/lib/systemd/system/prometheus.service` et ajoutez l'argument suivant à la liste des arguments transmis à la commande  Prometheus.

```
--web.externe-url=https://localhost:1234
```

-   Redémarrer le service

```
systemctl daemon-reload
systemctl redémarrer prometheus


# en cas d'erreurs
journalctl -f -u prometheus.service
```

### Enable reverse proxy authentication { #prometheus_auth }

Cette section montre comment configurer l'authentification de base via le proxy inverse. Si vous avez besoin d'un mécanisme d'authentification différent (SSO, etc.), veuillez consulter la documentation correspondante.

-   Assurez-vous que `htpasswd` est installé sur le système

```
apt-get install apache2-utils
```

-   Créer un fichier d'authentification

```
cd /etc/prometheus
htpasswd -c .credentials admin
```

Choisissez un mot de passe efficace et assurez-vous que le fichier pass a été correctement créé.

-   Editez le fichier de configuration Nginx créé précédemment (`/etc/nginx/conf.d/prometheus.conf`), et ajoutez les informations d'authentification.

```
serveur {
 écoute 1234;

  localisation / {
    auth_basic           "Prometheus";
    auth_basic_user_file /etc/prometheus/.credentials;
    proxy_pass           http://localhost:9090/;
  }
}
```

-   Redémarrer Nginx

```
systemctl redémarrer nginx

# en cas d'erreurs
journalctl -f -u nginx.service
```

-   `http://localhost:1234` devrait maintenant vous demander votre nom d'utilisateur et votre mot de passe.

### Installing Grafana on Ubuntu and Debian { #grafana }

-   Ajouter une clé `gpg` et installer le paquet OSS Grafana depuis le repo APT

```sh
apt-installer -y apt-transport-https

wget -q -O - "https://packages.grafana.com/gpg.key" | sudo apt-key add -

add-apt-repositoire "deb https://packages.grafana.com/oss/deb stable main"

apt-mettre à jour

apt-installer grafana
```

-   Si le système utilise `systemd`, un nouveau `grafana-service` est automatiquement créé. Vérifiez le fichier `systemd` pour avoir un aperçu de l'installation de Grafana.

```
cat /usr/lib/systemd/system/grafana-server.service
```

Ce fichier est très important car il fournit des informations sur l'instance Grafana nouvellement installée.

Le fichier affiche :

The **Grafana server binary** is located at `/usr/sbin/grafana-server`. The file that defines all the **environment variables** is located at `/etc/default/grafana-server` The **configuration file** is given via the `CONF_FILE` environment variable. The **PID of the file** is also determined by the `PID_FILE_DIR` environment variable. **Logging**, **data**, **plugins** and **provisioning** paths are given by environment variables.

-   Démarrer le serveur

```
systemctl start grafana-server
```

-   Accéder à la console web Grafana : http://localhost:3000

The default login for Grafana is `admin` and the default password is also `admin`. You will be prompted to change the password on first access.

-   Configurer Prometheus comme source de données Grafana

Accédez au panneau des sources de données en cliquant sur `Configuration` > `Sources de données` dans le menu à gauche.

Cliquez sur `Add a datasource` (Ajouter une source de données)

Sélectionnez une source de données Prometheus dans la fenêtre suivante.

Configurer la source de données en fonction de la configuration de Prometheus (utiliser l'authentification, TSL, etc.)

### Installing Prometheus + Grafana using Docker { #prometheus_grafana_docker }

Cette section décrit comment démarrer une pile Prometheus contenant Prometheus et Grafana.

La configuration est basée sur ce projet : https://github.com/vegasbrianc/prometheus

-   Cloner ce projet Github : https://github.com/vegasbrianc/prometheus

-   Démarrer la pile Prometheus en utilisant :

```
déploiement de la pile docker -c docker-stack.yml prom
```

La commande ci-dessus peut entraîner l'erreur suivante :

_This node is not a swarm manager. Use "docker swarm init" or "docker swarm join" to connect this node to swarm and try again_

Identifier les valeurs qui diffèrent significativement des autres dans les ensembles de données 

```
docker swarm init --advertise-addr <YOUR_IP>
```

Une fois cette commande exécutée avec succès, vous devriez pouvoir exécuter la commande précédente sans problème.

La pile contient également un exportateur Node pour le suivi de Docker. Si vous n'êtes pas intéressé par le suivi de Docker, vous pouvez commenter les sections concernées dans le fichier `docker-stack.yml` :

-   `node-exporter`
-   `cadvisor`

-   Pour arrêter la pile Prometheus :

```
docker stack rm prom
```

Le fichier de configuration de Prometheus (`prometheus.yml`) est situé dans le dossier `prometheus`.

-   Accédez à la console web de Grafana à l'adresse suivante : http://localhost:3000 avec le nom d'utilisateur : `admin` et le mot de passe : `foobar`.

### Configure Prometheus to pull metrics from one or more DHIS2 instances { #prometheus_dhis2 }

Avant d'utiliser Prometheus, il faut le configurer. Nous devons donc créer un fichier de configuration nommé `prometheus.yml`

> **Remarque**
>
> Le fichier de configuration de Prometheus est écrit en YAML ce qui interdit formellement l'utilisation de tabulations. Si votre fichier est mal formaté, Prometheus ne démarrera pas. Faites attention lorsque vous l'éditez.

Le fichier de configuration de Prometheus est divisé en trois parties : `global`, `rule_files`, et `scrape_configs`.

Dans la partie générale, on trouve la configuration générale de Prometheus : `scrape_interval`(intervalle d'analyse) définit la fréquence à laquelle Prometheus analyse les cibles, `evaluation_interval` (intervalle d'évaluation) contrôle la fréquence à laquelle le logiciel évalue les règles. Les règles sont utilisées pour créer de nouvelles séries temporelles et pour générer des alertes.

Le bloc `rule_files`(dossiers de règles) contient des informations sur l'emplacement de toutes les règles que nous voulons que le serveur Prometheus charge.

Le dernier bloc du fichier de configuration est nommé `scape_configs` (configuration du cadre) et contient les informations sur les ressources que Prometheus suit.

Un fichier de suivi simple de DHIS2 Prometheus ressemble à cet exemple :

```yaml
global:
    scrape_interval: 15s
    evaluation_interval: 15s

scrape_configs:
    - job_name: "dhis2"
      metrics_path: "/dhis/api/metrics"
      basic_auth:
          username: admin
          password: district
      static_configs:
          - targets: ["localhost:80"]
```

L'intervalle général `scrape_interval` est fixé à 15 secondes, ce qui est suffisant pour la plupart des cas d'utilisation.

In the `scrape_configs` part we have defined the DHIS2 exporter. The `basic_auth` blocks contains the credentials required to access the `metrics` API: consider creating an ad-hoc user only for accessing the `metrics` endpoint.

Prometheus peut ou non fonctionner sur le même serveur que DHIS2 : dans la configuration ci-dessus, on suppose que Prometheus ne suit qu'une seule instance de DHIS2, fonctionnant sur le même serveur que Prometheus, nous utilisons donc `localhost`.

### Configure the DHIS2 exporter { #dhis2_metrics_conf }

Le sous-système de suivi est désactivé par défaut dans DHIS2.

Chaque groupe de mesures doit être explicitement activé pour que les mesures puissent être exportées. Pour configurer DHIS2 afin d'exporter une ou plusieurs mesures, consultez ce [document] (https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md#dhis2-monitoring-configuration).

# Audit { #audit }

## Introduction { #introduction }

DHIS2 supports a new audit service which is based on Apache ActiveMQ Artemis. Artemis is used as an asynchronous messaging system by DHIS2.

After an entity is saved to database, an audit message will be sent to the Artemis message consumer service. The message will then be processed in a different thread.

Audit logs can be retrieved from the DHIS2 database. Currently there is no UI or API endpoint available for retriving audit entries.

## Single Audit table { #audit_table }

All audit entries will be saved into one single table named `audit`

| Colonne | Type |  |  |
| --- | --- | --- | --- |
| Identifiant de l'audit | entier |  |  |
| type d'audit | texte | LIRE, CRÉER, METTRE À JOUR, SUPPRIMER, RECHERCHER |  |
| champ d'application de l'audit | texte | MÉTADONNÉES, AGRÉGÉ, TRACKER |  |
| classe | texte | Audit Entity Java class name |  |
| les attributs | jsonb | Json string stores attributes of the audit entity, used for searching. Example: {"valueType":"TEXT", "categoryCombo":"SWQW313FQY", "domainType":"TRACKER"} |  |
| données | bytea | Compressed Json string of the Audit Entity. It is currently in byte array format and not human-readable. |  |
| créé à | horodatage sans fuseau horaire |  |  |
| créé par | texte |  |  |
| uid | texte |  |  |
| code | texte |  |  |
|  |  |

The new Audit service makes use of two new concepts: Audit Scopes and Audit Type.

## Audit Scope { #audit_scope }

An Audit Scope is a logical area of the application which can be audited. Currently there are three Audit Scopes:

```
Tracker

Metadata

Aggregate
```

-   For the Tracker Audit Scope, the audited objects are: Tracked Entity Instance, Tracked Entity Attribute Value, Enrollment, Event

-   For the Metadata Scope, all "metadata" objects are audited.

-   For the Aggregate Scope, the Aggregate Data Value objects are audited.

## Audit Type { #audit_type }

An Audit Type is an action that triggers an audit operation. Currently we support the following types:

```
READ

CREATE

UPDATE

DELETE
```

As an example, when a new Tracked Entity Instance gets created, and if configured like so, the CREATE action is used to insert a new Audit entry in the audit db table.

> **Caution**
>
> The READ Audit Type will generate a lot of data in database and may have an impact on the performance.

## Setup { #audit_configuration }

The audit system is automatically configured to audit for the following scopes and types:

-   CREATE, UPDATE, DELETE

-   METADATA, TRACKER, AGGREGATE

**No action is required to activate the audit.** The audit can still be configured using the "audit matrix". The audit matrix is driven by 3 properties in dhis.conf:

```
audit.metadata

audit.tracker

audit.aggregate
```

Each property accepts a semicolon delimited list of valid Audit Types:

```
CREATE

UPDATE

DELETE

READ
```

For instance, in order to only audit Tracker related object creation and deletion, the following property should be added to `dhis.conf`:

```
audit.tracker = CREATE;DELETE
```

In order to completely disable auditing, this is the configuration to use:

```
audit.metadata = DISABLED

audit.tracker = DISABLED

audit.aggregate = DISABLED
```

# Using Gateways for SMS reporting { #sms_report_sending }

DHIS2 supports accepting data via [SMS](https://docs.dhis2.org/master/en/dhis2_user_manual_en/mobile.html), however, the SMS needs to be composed in a cryptic way to protect the information. The DHIS2 Android App acts as a transparent layer to send the information via SMS where the user does not have to worry about writing the SMS. To send SMSs with the Android App the SMS gateway need to be properly configured. This section explains the different options available and how to achieve that.

## Sending SMS { #sms_report_sening }

It is important to clarify firstly, that this section mainly concerns the set up of **receiving SMS** (from mobile devices to the DHIS2 server), which is necessary when considering using the App to send (sync) information recorded in the app to the DHIS2 server via SMS. In the App this can be set-up under the _Settings_ > _SMS Settings_

L’envoi de SMS, du serveur DHIS2 vers les appareils mobiles, est relativement simple à configurer. S'il s'agit juste d'envoyer des notifications aux téléphones des utilisateurs depuis DHIS2 lorsque certains événements se produisent (messagerie, seuils, etc.), seul l'envoi de SMS est requis.

Tout ceci peut être configuré sur la page de configuration du service SMS dans la [section Configuration mobile](https://docs.dhis2.org/master/en/user/html/mobile_sms_service.html).

There is out of the box support for common providers such as _Bulk SMS_ and _Clickatell_, and both providers support sending of SMS to numbers in most countries.

Notez également qu'il est possible d'utiliser différentes passerelles SMS pour l'envoi et la réception de SMS. Ainsi, même si vous mettez en place une des solutions ci-dessous pour la réception de SMS, vous pouvez toujours utiliser l'une des solutions susmentionnées pour l'envoi.

## Using an Android device as SMS Gateway { #sms_report_android_gateway }

La solution la plus simple, et de loin, consiste à utiliser un appareil Android comme passerelle SMS. Tout téléphone ou tablette fonctionnant sous Android OS (4.4, Kitkat ou supérieur) devrait faire l'affaire. L'appareil aura besoin d'une connexion internet permanente pour transférer les messages vers votre serveur DHIS2 et d'une carte SIM pour recevoir les SMS.

Il vous faudra télécharger et installer l'application Passerelle SMS Android de DHIS2 sur l'appareil mobile. Vous trouverez une liste des [versions] disponibles à cette adresse : (https://github.com/dhis2/dhis2-sms-android-gateway/releases). Vous pourrez y télécharger le fichier APK le plus récent et l'installer. Des instructions sont fournies sur la page de l'application elle-même, mais il suffit de lancer l'application et d'entrer les informations de votre serveur DHIS2 (URL, nom d'utilisateur et mot de passe).

Une fois l'application installée et opérationnelle, entrez le numéro de téléphone de cette passerelle sur la page de configuration des appareils mobiles qui utilisent l'application DHIS2 Capture. Ainsi, lorsque des SMS seront envoyés à partir de ces appareils, ils sont reçus par la passerelle et automatiquement transmis au serveur DHIS2 où ils sont traités.

**Using this gateway device is perfect when testing the SMS functionality.** It would be fine when piloting projects that require SMS reporting. As long as the device is plugged into a power supply and has a constant internet connection it works well for small scale projects.

However, when considering moving a project to production it would be necessary to investigate one of the more permanent and reliable solutions for gateways below.

### Sending SMS using an Android Device Gateway { #sending-sms-using-an-android-device-gateway }

Cette option n'est actuellement ni prise en charge ni documentée.

## Dedicated SMS Gateways { #sms_report_dedicated_gateway }

Cette section traite de l'utilisation de passerelles SMS plus permanentes et dédiées, ainsi que des options disponibles. Chacune des options ci-dessous suppose qu'un fournisseur (ou vous-même) dispose d'une connexion SMPP avec un opérateur téléphonique dans le pays et utilise cette connexion pour recevoir des SMS et les transmettre à votre serveur DHIS2 via Internet à l'aide du protocole HTTP.

Ces solutions peuvent utiliser un **numéro long** ou un **code court**. Un numéro long est un numéro de téléphone mobile standard du type que la plupart des particuliers utilisent, par exemple +61 400123123. Un code court est simplement un numéro court, tel que 311. La configuration et la gestion des codes courts sont généralement plus coûteuses.

### Ensuring incoming SMS to DHIS2 server are formatted correctly { #ensuring-incoming-sms-to-dhis2-server-are-formatted-correctly }

When sending incoming SMS to a DHIS2 server via the API you use the following URL: _https://<DHIS2_server_url>/api/sms/inbound_

Dans la version 2.34 et les versions antérieures de DHIS2, ce point d'extrémité exige que le format des SMS entrants soient très spécifique, c'est-à-dire que le message lui-même doit être un paramètre appelé "texte" et le numéro de téléphone de l'expéditeur doit être un paramètre appelé "expéditeur".

Lorsque vous utilisez toutes les options de passerelle SMS ci-dessous, et que vous les configurez pour transmettre les SMS à un autre service Web, elles auront chacune leur propre format, lequel sera différent de celui attendu par l'API DHIS2. Voilà pourquoi il est nécessaire de les reformater avant de les envoyer au serveur DHIS2.

Une option consiste à exécuter simplement votre propre service Web, qui reçoit le SMS du fournisseur de la passerelle, le reformate au format requis pour DHIS2 et le transmet à votre API DHIS2. Un tel service devrait être écrit par un développeur de logiciels.

Dans la version 2.35 de DHIS2, il est prévu de prendre en charge ces cas avec un système de template pour les SMS entrants, de sorte que vous puissiez spécifier le format des messages qui seront envoyés depuis votre fournisseur. De cette manière, vous pouvez configurer le serveur DHIS2 pour qu'il accepte les SMS entrants de tout autre fournisseur de passerelle SMS. Ces derniers pourrons alors envoyer directement des SMS entrants à l'API DHIS2, sans avoir besoin d'un service Web de formatage.

### Using RapidPro { #using-rapidpro }

[RapidPro] (https://rapidpro.io/) est un service géré par l'UNICEF dans plus de 50 pays à travers le monde. Il s'agit d'un ensemble de logiciels qui travaille avec les opérateurs téléphoniques nationaux pour permettre aux organisations de concevoir des solutions SMS pour leurs projets, tels que des rapports SMS ou des campagnes de sensibilisation.

Le service RapidPro implique une connexion SMPP avec un ou plusieurs opérateurs téléphoniques nationaux, généralement par le biais d'un code court, qui peut être dédié aux activités liées à la santé des ONG. Il est alors possible d'ajouter un webhook (crochet Web) pour que les SMS entrants soient transmis à un autre service Web, tel que le service Web de formatage décrit ci-dessus. Si le code court est également utilisé à d'autres fins, il peut être nécessaire d'ajouter les numéros de téléphone de vos appareils d'établissement de rapports à un groupe distinct, de sorte que seuls les SMS entrants provenant de ces appareils soient transmis au webhook.

RapidPro est actuellement opérationnel dans près de la moitié des pays qui utilisent DHIS2 ou qui sont à une phase pilote. Avant d'envisager l'une des solutions ci-dessous, qui peuvent être coûteuses en termes de temps et d'argent, il convient de prendre contact avec l'Unicef pour voir si RapidPro est disponible et s'il peut être utilisé pour l'établissement de rapports sur la santé dans votre pays.

### Using commercial SMS gateway providers { #using-commercial-sms-gateway-providers }

Of the commercial SMS gateway providers mentioned in the Sending SMS section above, they will usually have capability to _send_ SMS in most countries but can only support _receiving_ SMS in a limited amount of countries. The majority of countries they support receiving SMS in are not those using DHIS2. Of the countries that are using DHIS2, most are already covered by having a RapidPro service running in-country.

Toutefois, il est utile de se renseigner sur les options commerciales disponibles pour votre pays. Dans certains pays, il existe de petites entreprises nationales qui fournissent des services SMS et qui disposent de connexions SMPP avec les opérateurs téléphoniques que vous pouvez contacter.

### Using phone carriers directly { #using-phone-carriers-directly }

Si aucune des solutions ci-dessus n'est disponible, vous devrez vous adresser directement aux opérateurs téléphoniques de votre pays. La première question à leur poser est de savoir s'ils connaissent des entreprises qui exploitent des connexions SMPP avec eux et que vous pourriez contacter.

Sinon, comme dernière option, vous devrez envisager de configurer et de gérer votre propre connexion SMPP avec l'opérateur téléphonique. Cependant, tous ne proposent pas un tel service.

Il vous faudra faire fonctionner votre propre serveur avec un logiciel tel que [Kannel] (https://www.kannel.org/), qui se connecte (généralement via un VPN) à un service SMPP fonctionnant sur le réseau de l'opérateur téléphonique. Ainsi, tout SMS entrant pour le numéro long ou le code court configuré est envoyé par l'opérateur téléphonique à votre serveur Kannel et vous pouvez ensuite transférer ces messages tel que décrit plus haut.

### Receiving concatenated or multipart SMS { #receiving-concatenated-or-multipart-sms }

When syncing data via SMS with the DHIS2 Android App, it uses a compressed format to use as little space (characters of text) as possible. Despite this, it will quite often be the case that a message will extend over the 160 character limit of one standard SMS. On most modern mobile devices these messages will still be sent as one concatenated or multipart SMS, and received as one message. When sending between two mobile devices, when an Android device is used as the gateway, this should be handled without issue.

Lors de la sélection d'une passerelle SMS, il est important de confirmer que l'opérateur téléphonique utilisé prend en charge les SMS concaténés. La plupart d'entre eux le prendront en charge, mais il est important de confirmer que la fonctionnalité SMS ne fonctionnera pas si les SMS sont fractionnés. Cela repose sur quelque chose appelé UDH (User Data Header). Lorsque vous discutez avec les fournisseurs, assurez-vous de demander si cela est pris en charge.
