---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.39/src/developer/web-api/data-validation.md"
revision_date: '2022-06-21'
tags:
- DHIS version 2.39
- Développement
---

# Validation des données { #data-validation }

## Validation { #webapi_validation }

Pour générer un résumé de validation des données, vous pouvez interagir avec la ressource de validation. La ressource "ensemble de données" est optimisée pour les clients chargés de la saisie des données et de la validation d'un ensemble de données ou d'un formulaire. Elle est accessible de la manière suivante :

    GET /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

En plus de la validation des règles basées sur un ensemble de données, il existe deux méthodes supplémentaires de validation : validation personnalisée et validation programmée.

La première variable path (de chemin) est un identifiant qui fait référence à l'ensemble de données à valider. Les représentations XML et JSON des ressources sont prises en charge. La réponse contient les violations des règles de validation. Cette fonction sera étendue à d'autres types de validation dans les versions à venir.

Pour récupérer les règles de validation relatives à un ensemble de données spécifique, c'est-à-dire les règles de validation avec des formules où tous les éléments de données font partie de l'ensemble de données en question, vous pouvez lancer une requête GET à la ressource `validationRules` de la manière suivante :

    GET /api/validationRules?dataSet=<dataset-id>

Les règles de validation ont un côté gauche et un côté droit, dont la validité est comparée en fonction d'un opérateur. Les valeurs valides de l'opérateur sont indiquées dans le tableau ci-dessous.



Tableau : Opérateurs

| Valeur | Description |
|---|---|
| égal_à | Egale à |
| pas_égale_à | Pas égal à |
| supérieure_à | Supérieure à |
| supérieure_ou_égale_à_ | Supérieure ou égal à |
| inférieure_à | Inférieur à |
| inférieure_ou_égale_à_ | inférieur ou égal à |
| paire_obligatoire | Si l’un des côtés est présent, l’autre doit également l’être. |
| paire_exclusive | Si l’un des côtés est présent, l’autre ne doit pas être |

Les expressions du côté gauche et du côté droit sont des expressions mathématiques qui peuvent contenir des références à des éléments de données et à des combinaisons d'options de catégorie au format suivant :

    ${<dataelement-id>.<catoptcombo-id>}

Les expressions du côté gauche et du côté droit ont une *stratégie de valeur manquante*. Cette stratégie indique comment le système doit traiter les valeurs de données manquantes pour les références d'éléments de données ou de combinaisons d'options de catégorie dans la formule, en déterminant si la règle de validation doit être vérifiée ou ignorée. Les stratégies de valeurs manquantes valides sont présentées dans le tableau ci-dessous.



Tableau : Stratégies de valeur manquante

| Valeur | Description |
|---|---|
| IGNORER_SI_UNE_VALEUR_MANQUE | Ignore la règle de validation si une valeur de données est manquante |
| IGNORER_SI_TOUTES-LES_VALEURS_MANQUENT | Ignore la règle de validation si toutes les valeurs de données sont manquantes |
| NE-JAMAIS_IGNORER | N'ignore jamais la règle de validation, quelles que soient les valeurs de données manquantes |

## Résultats de la validation { #webapi_validation_results }

Les résultats de validation sont les résultats des violations constatées lors d'une analyse de validation. Si vous choisissez "conserver les résultats" lorsque vous lancez ou programmez une analyse de validation, toutes les violations constatées seront stockées dans la base de données. Lorsqu'un résultat est stocké dans la base de données, il est utilisé à trois fins :

1.  Générer des analyses basées sur les résultats stockés.

2.  Les résultats qui n'ont pas généré de notification le feront,
    une fois.

3.  Garder la trace des résultats qui ont généré ou non une
    notification.

4.  Ignorer les règles déjà vérifiées lors de
    l'analyse de validation.

Cela signifie que si vous ne conservez pas vos résultats, vous ne pourrez pas générer d'analyses pour les résultats de validation. Si cette option est sélectionnée, les résultats généreront des notifications à chaque fois qu'il y en aura et l'analyse de validation pourrait être plus lente.

### Résultats de la validation de la requête { #query-validation-results }

Les résultats de validation conservés peuvent être consultés au point d'extrémité suivant :

    GET /api/33/validationResults

Vous pouvez également inspecter un résultat individuel à l'aide de l'identifiant du résultat de validation dans ce point d'extrémité :

    GET /api/33/validationResults/<id>

Les résultats de validation peuvent également être filtrés par les propriétés suivantes :

* Unité organisationnelle : `ou=<UID>`
* Règle de validation : `vr=<UID>`
* Période : `pe=<ISO-expression>`

Chacune des propriétés de filtre ci-dessus peut apparaître plusieurs fois, par exemple :

    GET /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

Plusieurs valeurs pour le même filtre sont combinées avec OR, les résultats doivent correspondre à l'une des valeurs données.

Si plusieurs propriétés de filtre sont utilisées et qu'elles sont combinées avec AND, les résultats devront correspondre à l'une des valeurs de chacune des propriétés.

Pour le filtre de période, les résultats doivent se superposer à l'une des périodes spécifiées.

De plus, les résultats de validation peuvent également être filtrés en fonction de leur date de création :

    GET /api/36/validationResults?createdDate=<date>

Ce filtre peut être combiné avec n’importe quel autre filtre.

### Déclencher des notifications de résultats de validation { #trigger-validation-result-notifications }

Les résultats de la validation sont envoyés aux utilisateurs concernés une fois par jour. Ils peuvent également être déclenchés manuellement pour être exécutés sur demande, à l'aide du point d'extrémité de l'API suivant :

    POST /api/33/validation/sendNotifications

Seuls les résultats non envoyés sont envoyés via ce point d'extrémité.

### Supprimer les résultats de validation { #delete-validation-results }

Les résultats de validation peuvent être supprimés manuellement en utilisant l'ID,

    DELETE /api/36/validationResults/<id>

ou les filtres

    DELETE /api/36/validationResults?<filters>

Les paramètres de filtre pris en charge sont :

* `ou=<UID>` pour faire correspondre tous les résultats de validation d'une unité d'organisation. Plusieurs unités utilisent 'OU' lorsque le paramètre est fourni plus d'une fois
* `vr=<UID>` pour faire correspondre tous les résultats de validation d'une règle de validation. Plusieurs règles utilisent 'OU' lorsque le paramètre est fourni plus d'une fois
* `pe=<ISO-expression>` pour faire correspondre tous les résultats de validation liés à une période qui se superpose à la période spécifiée
* `created=<ISO-expression>` pour faire correspondre tous les résultats de validation créés au cours de la période fournie
* `notificationSent=<boolean>` pour faire correspondre uniquement les résultats de validation pour lesquels une notification a été ou n'a pas été envoyée

Si les filtres sont combinés, toutes les conditions doivent être vraies (AND logic (ET logique)).

Quelques exemples:

Pour supprimer tous les résultats de validation liés à l'unité d'organisation dont l'UID est `NqwvaQC1ni4` pour le premier trimestre (Q1) 2020, utilisez :

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

Pour supprimer tous les résultats de validation créés au cours de la semaine 1 de 2019 et pour lesquels une notification a été envoyée, utilisez :

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

Toute opération de suppression nécessitera l'autorité _Effectuer des tâches de maintenance_.


## Détection des valeurs atypiques { #outlier-detection }

Le point d'extrémité de détection des valeurs atypiques permet de détecter les valeurs atypiques dans les valeurs de données agrégées.

```
GET /api/36/outlierDetection
```

Ce point d'extrémité prend en charge deux algorithmes pour détecter les valeurs atypiques :

* **Z-score :** Le z-score est défini comme l'écart absolu entre le score et la moyenne divisé par l'écart type. Un paramètre de seuil faisant référence au nombre d'écarts types par rapport à la moyenne doit être spécifié avec l'algorithme z-score pour définir les limites supérieure et inférieure de ce qui est considéré comme une valeur atypique.
* **Z-score modifié :** Identique au z-score, à la différence qu'il utilise la médiane au lieu de la moyenne comme mesure de la tendance centrale. Les paramètres sont les mêmes que pour le Z-score.
* **Min-max :** Les valeurs des éléments de données min-max (minimales et maximales) font référence aux limites personnalisées qui peuvent être insérées dans DHIS 2 en fonction de la combinaison d'éléments de données, d'unités d'organisation et d'options de catégorie.

Les valeurs atypiques seront *classées selon leur importance*, par défaut selon l'écart absolu par rapport à la moyenne, avec la valeur la plus importante en premier. Ceci permet d'identifier rapidement les valeurs atypiques qui ont le plus grand impact sur la qualité et l’analyse des données.

### Paramètres de requête{ #request-query-parameters }

Les paramètres de requête suivants sont pris en charge.

| Paramètre de requête | Description                                                  | Obligatoire | Options (par défaut en premier)                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | Ensemble de données, peut être spécifié plusieurs fois.                   | No [*]    | Identifiant de l'ensemble de données.                      |
| de              | Élément de données, peut être spécifié plusieurs fois.               | No [*]    | Identifiant de l'élément de données.                  |
| date de début       | Date en début de l'intervalle pour contrôler les valeurs atypiques.               | Oui       | Date (aaaa-MM-jj).                        |
| date de fin         | Date en fin de l'intervalle pour vérifier les valeurs aberrantes.                 | Oui       | Date (aaaa-MM-jj).                        |
| ou              | Unité d'organisation, peut être spécifiée plusieurs fois.          | Oui       | Identifiant de l’unité d’organisation.             |
| algorithme       | Algorithme à utiliser pour la détection des valeurs atypiques.                      | Non        | `Z_SCORE`, `MIN_MAX`, `MOD_Z_SCORE`       |
| seuil       | Seuil pour les valeurs atypiques. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Numérique, supérieur à zéro. Par défaut : 3.0. |
| Date de début des données   | Date en début de l'intervalle pour le calcul de la moyenne et de l'écart type. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Date (aaaa-MM-jj). |
| Date de fin des données     | Date en fin de l'intervalle pour le calcul de la moyenne et de l'écart type. Algorithmes `Z_SCORE` et `MOD_Z_SCORE` uniquement. | Non        | Date (aaaa-MM-jj).   |
| orderBy         | Field to order by. `Z_SCORE` and `MOD_Z_SCORE`algorithm only.| Non        | `MEAN_ABS_DEV`, `Z_SCORE`                 |
| Résultats maximum      | Limite maximale pour la sortie.                                    | Non        | Entier, supérieur à zéro. Par défaut : 500. |

[*] Vous devez spécifier soit des ensembles de données avec le paramètre `ds`, qui inclura tous les éléments de données dans les ensembles de données, _ou_ spécifier des éléments de données avec le paramètre `de`.

Au moins un ensemble de données ou élément de données, une date de début et une date de fin, et au moins une unité d'organisation doivent être définis.

Les paramètres `Date de début` et `Date de fin` sont obligatoires et font référence à l'intervalle de temps dans lequel vous voulez détecter les valeurs atypiques. Les paramètres `Date de début des données` et `Date de fin des données` sont facultatifs et font référence à l'intervalle de temps à utiliser pour les données lors du calcul de la moyenne et de l'écart type. Ils sont utilisés pour calculer éventuellement le z-score.

### Utilisation et exemples { #usage-and-examples }

Obtenez les valeurs atypiques à l'aide de l'algorithme z-score par défaut :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
```

Obtenez des valeurs atypiques à l'aide d'un algorithme et d'un seuil spécifiques :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=Z_SCORE&threshold=2.5
```

Obtenez les valeurs atypiques classées par z-score :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &orderBy=Z_SCORE
```

Obtenez les 10 principales valeurs atypiques :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &maxResults=10
```

Obtenez des valeurs atypiques avec un intervalle défini pour les données à utiliser lors du calcul de la moyenne et de l'écart type :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &dataStartDate=2018-01-01&dataEndDate=2020-12-31
```

Obtenez les valeurs atypiques à l'aide de l'algorithme min-max :

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=MIN_MAX
```

### Format de réponse { #response-format }

Les formats de réponse suivants sont pris en charge.

| Format | Format API                                                   |
| ------ | ------------------------------------------------------------ |
| JSON   | `/api/36/outlierDetection.json` or `Accept: application/json` (default format) |
| CSV    | `/api/36/outlierDetection.csv` or `Accept: application/csv`  |

La réponse contient les champs suivants :

| Champ      | Description                                                  |
| ---------- | ------------------------------------------------------------ |
| de         | Identifiant de l'élément de données.                                     |
| Nom de l'élément de données     | Nom de l'élément de données.                                           |
| pe         | Identifiant ISO de la période.                                       |
| ou         | Identifiant de l’unité d’organisation.                                |
| ouName     | Nom de l'unité d'organisation.                                      |
| coc        | Identifiant de la combinaison d’options de catégorie.                      |
| cocName    | Nom de la combinaison d’options de catégorie.                            |
| aoc        | Identifiant de la combinaison d’options d’attribut.                     |
| aocName    | Nom de la combinaison d’options d’attribut.                           |
| valeur      | Valeur de données.                                                  |
| moyenne       | Moyenne des valeurs de données dans la dimension de temps.                   |
| stdDev     | Écart-type.                                          |
| absDev     | Pour le z-score, il s'agit de l'écart absolu par rapport à la moyenne. Pour min-max, il s'agit de l'écart absolu par rapport à la limite min ou max. |
| zScore     | Le z-score. Algorithme du z-score uniquement.                         |
| lowerBound | La limite inférieure.                                          |
| upperBound | La limite supérieure.                                          |
| suivi   | Si la valeur de données est marquée pour le suivi.                  |

Les champs de `moyenne`, `écart type` et `z-score` ne sont présents que lorsque l'`algorithme` est `Z_SCORE`.

La réponse ressemblera à ceci. La section `métadonnées` contient des métadonnées de requête et de réponse. La section `Valeurs atypique` contient les valeurs atypiques.

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### Contraintes et validation { #constraints-and-validation }

Les contraintes suivantes s'appliquent lors de la validation de la requête. Chaque erreur de validation a un code d'erreur correspondant.

| Code d'erreur | Message                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | Au moins un élément de données doit être spécifié                  |
| E2201      | La date de début et la date de fin doivent être précisées                    |
| E2202      | La date de début doit être antérieure à la date de fin                           |
| E2203      | Au moins une unité d'organisation doit être spécifiée             |
| E2204      | Le seuil doit être un nombre positif                          |
| E2205      | Les résultats maximum doivent être exprimés en nombres positifs                        |
| E2206      | Le nombre maximum de résultats dépasse la limite autorisée : {d}               |
| E2207      | La date de début des données doit être antérieure à la date de fin des données                 |
| E2208      | Valeurs de données non numériques rencontrées lors de la détection des valeurs atypiques |

## Analyse des données { #webapi_data_analysis }

Plusieurs ressources permettant d'effectuer des analyses de données et de détecter les problèmes de qualité et de validation des données sont fournies.

**Remarque :** Ce point d'extrémité est obsolète et sera supprimé dans la version 2.38. Utilisez plutôt le point d'extrémité  `outlierAnalysis`.

### Analyse des règles de validation { #webapi_data_analysis_validation_rules } 

Pour exécuter des règles de validation et extraire les violations :

    GET /api/dataAnalysis/validationRules

Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'analyse des règles de validation

| Paramètre de requête | Description | Option |
|---|---|---|
| vrg | Groupe de règles de validation | Identifiant |
| ou | Unité d’organisation | Identifiant |
| date de début | Date de début de la période | Date |
| date de fin | Date de fin de la période | Date |
| conserver | S'il faut conserver les violations dans le système | faux &#124; vrai |
| notification | S'il faut envoyer des notifications sur les violations | faux &#124; vrai |

Exemple de sortie :
```json
[{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### Analyse des valeurs atypiques sur la base de l'écart type { #webapi_data_analysis_std_dev_outlier }

Pour identifier les valeurs atypiques parmi les données en fonction des écarts types de la valeur  moyenne :

    GET /api/dataAnalysis/stdDevOutlier

Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'analyse des valeurs atypiques de l'écart type

| Paramètre de requête | Description | Option |
|---|---|---|
| ou | Unité d’organisation | Identifiant |
| date de début | Date de début de la période | Date |
| date de fin | Date de fin de la période | Date |
| ds | Ensembles de données, le paramètre peut être répété | Identifiant |
| écart type | Nombre d'écarts types par rapport à la moyenne | Valeur numérique |

### Analyse des valeurs aberrantes basée sur les valeurs min/max { #webapi_data_analysis_min_max_outlier }

Pour identifier les valeurs atypiques sur la base des valeurs min/max :

    GET /api/dataAnalysis/minMaxOutlier

Les paramètres de requête pris en charge équivalent à la ressource *analyse des valeurs atypiques en fonction de l'écart type* décrite ci-dessus.

### Analyse des données de suivi { #follow-up-data-analysis }

Pour identifier les données marquées pour le suivi :

    GET /api/dataAnalysis/followup

Au moins un ensemble de données ou élément de données, une date ou période de début et de fin, et au moins une unité d'organisation doivent être définis.

Les paramètres de requête suivants sont pris en charge.

| Paramètre  | Description                                                  | Obligatoire | Options (par défaut en premier)                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ou         | Unité d'organisation, peut être spécifiée plusieurs fois.          | Oui       | Identifiant de l’unité d’organisation.             |
| ds         | Ensemble de données, peut être spécifié plusieurs fois.                   | No [*]    | Identifiant de l'ensemble de données.                      |
| de         | Élément de données, peut être spécifié plusieurs fois.               | No [*]    | Identifiant de l'élément de données.                  |
| date de début  | Date en début de l'intervalle pour contrôler les valeurs atypiques.               | No [*]    | Date (aaaa-MM-jj).                        |
| date de fin    | Date en fin de l'intervalle pour vérifier les valeurs aberrantes.                 | No [*]    | Date (aaaa-MM-jj).                        |
| pe         | ID de période ISO.                                               | No [*]    | ID ISO de la période.                        |
| peType     | Période ISO.                                                  | No [*]    | Chaîne ISO de la période.                        |
| coc        | Les combinaisons d’options de catégorie peuvent être spécifiées plusieurs fois.     | Non        | Identifiant de la combinaison d’options de catégorie.         |
| Résultats maximum | Limite maximale pour la sortie.                                    | Non        | Entier, supérieur à zéro. Par défaut : 50.  |

[*] Vous devez spécifier soit des ensembles de données avec le paramètre `ds`, qui intégrera tous les éléments de données dans les ensembles de données, _ou_ spécifier des éléments de données avec le paramètre `de`.
     De même, `Date de début` et `date de fin` _ou_ `période` doivent être spécifiés.

Les paramètres `Date de début` et `Date de fin` font référence à l'intervalle de temps au cours duquel vous voulez détecter les valeurs atypiques.
Si une période `pe` est fournie à la place, le début et la fin de l'intervalle sont également ceux de la période.

Si aucune combinaison d'options `coc` n'est fournie, tous les éléments de données de type valeur numérique seront pris en compte.


## Intégrité des données { #webapi_data_integrity } 
The data integrity capabilities of the data administration module are
available through the web API. This section describes how to run the
data integrity process as well as retrieving the result. The details of
the analysis performed are described in the user manual.

### Liste des vérifications d'intégrité des données disponibles { #webapi_data_integrity_list }
A description of the available checks is returned by

    GET /api/dataIntegrity

L'élément `nom` parmi les éléments de contrôle renvoyés est l'identifiant utilisé pour le paramètre des `contrôles` pour déclarer l’ensemble des contrôles à exécuter.

Les contrôles sont regroupés sémantiquement par l'élément `section` et classés dans l'un des quatre niveaux de `sévérité` :

| Gravité | Description |
| -------- | ----------- |
| INFO     | Indique qu'il s'agit uniquement d'une information. |
| AVERTISSEMENT  | A warning indicates that this may be a problem, but not necessarily an error. It is however recommended triaging these issues. |
| SEVERE   | An error which should be fixed, but which may not necessarily lead to the system not functioning. |
| CRITIQUE | An error which must be fixed, and which may lead to end-user error or system crashes. |

Les contrôles disponibles peuvent être filtrés à l'aide du paramètre `contrôles`.

    GET /api/dataIntegrity?checks=<pattern1>,<pattern2>

One or more exact names or patterns using `*` as wildcard can be provided.

Additional results can be filtered using `section` parameter.

    GET /api/dataIntegrity?section=Categories

If filter using `section` checks must have an exact match for the provided section name.

### Running a selection of data integrity checks { #webapi_data_integrity_run }
Since 2.38 data integrity checks have two levels, the summary level giving 
statistical overview, and the details level giving a list of issues each 
pointing to an individual data integrity violation.

Pour déclencher une analyse récapitulative pour un ensemble de contrôles exécutés :

    POST /api/dataIntegrity/summary?checks=<name1>,<name2>

This triggers a job that runs the check(s) asynchronously. 
The job details are given in the POST response that returns immediately once the job is scheduled.
The response's `Localtion` header points to the URL where the results can be fetched (see below). 

Pour récupérer le résumé sur l'intégrité des données du ou des contrôle(s) déclenchés, utilisez :

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>

When the `checks` parameter is omitted all checks are run/fetched.

The response is a "map" of check results, one for each check that has completed already.
This information is cached for 1h or until the check is rerun.
To wait for the summary to be available in the cache a `timeout` in milliseconds can be added:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>&timeout=500

Une réponse récapitulative pourrait ressembler à  ceci :
```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 12,
    "percentage": 2.3
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "finishedTime": "2022-02-15 14:58",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 4,
    "percentage": 5.1
  }
}
```
Alongside the check's information of `name`, `section`, `severity`, 
`description` and optionally `introduction` and `recommendation` the summary 
contains the number of issues found as `count` and when possible how large 
this count is in relation to all relevant entries as `percentage`.
The `finishedTime` indicates when the analysis of the check finished.
The cache will hold the result for 1h from this moment.

> **Note**
> 
> If a summary (or details) response "map" does not contain any data (field) for
> a check included in the `checks` parameter list it is likely the case that
> the check either never ran or has not yet finished running.
> You can either use client side polling or add the `timeout` parameter to use
> server side waiting for the requested results.

Similarly to run a selection of details checks first trigger them using `POST`:

    POST /api/dataIntegrity/details?checks=<name1>,<name2>

Récupérez ensuite les résultats du cache en utilisant :

    GET /api/dataIntegrity/details?checks=<name1>,<name2>&timeout=500

Again, not providing the `checks` parameter will run all checks.
Omitting the `timeout` will not wait for results to be found in the cache 
but instead not have a result for the requested check.

The `/details` response returns a similar map again, just that each entry 
does not have a `count` and `percentage` member but a list of `issues`.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "issues": [{
      "id": "<id-or-other-identifier>",
      "name": "<name-of-the-id-obj>",
      "comment": "optional plain text description or hint of the issue",
      "refs": ["<id1>", "<id2>"]
    }]
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "finishedTime": "2022-02-15 14:59",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issues": []
  }
}
```
The issue objects always have `id` and `name` members. Often the `issuesIdType`
is available to point out the type of objects the `id` refers to. If the 
`issuesIdType` is not available the `id` often is not available either and the
`name` is used for a aggregate key of an issue that has no object equivalent.

Sometimes an additional `comment` is available that gives more context or
insight into why the data integrity is violated. In addition, the `refs` list
might sometimes also give the ids of other objects that contributed to the violation.
The `finishedTime` indicates when the analysis of the check finished.
The cache will hold the result for 1h from this moment.

> **Tip**
>
> A set of checks can also be specified using wild-cards. To include all 
> checks with _element_ in the name use `checks=*element*`. Like full names 
> such patterns can be used in a comma separated list and be mixed with full 
> names as well. Duplicates will be eliminated. 

Should a check analysis fail due to programming error or unforeseen data inconsistencies
both the summary and the details will have an `error` field describing the error that occurred.
In such case no data is available for the check.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "error": "what has happened",
    "issues": []
  }
}
```

### Running full data integrity report (legacy) { #webapi_data_integrity_run_legacy } 

The operation of performing data integrity analysis is a resource (and
time) demanding task. It is therefore run as an asynchronous process and
only when explicitly requested. Starting the task is done by forming an
empty POST request to the *dataIntegrity* endpoint:

    POST /api/dataIntegrity

If successful the request will return HTTP 202 immediately. The location
header of the response points to the resource used to check the status
of the request. The payload also contains a json object of the job
created. Forming a GET request to the given location yields an empty
JSON response if the task has not yet completed and a JSON taskSummary
object when the task is done. Polling (conservatively) to this resource
can hence be used to wait for the task to finish.

### Fetching asynchronous integrity summary (legacy) { #webapi_data_integrity_fetch_results } 

Once data integrity is finished running the result can be fetched from
the `system/taskSummaries` resource like so:

    GET /api/system/taskSummaries/DATA_INTEGRITY

The returned object contains a summary for each point of analysis,
listing the names of the relevant integrity violations. As stated in the
leading paragraph for this section the details of the analysis (and the
resulting data) can be found in the user manual chapter on Data
Administration.

## Enregistrements des ensembles de données complets{ #webapi_complete_data_set_registrations }

Cette section traite de l'enregistrement d'ensembles de données complétés en tant qu'ensembles de données. Un enregistrement marque un ensemble de données comme étant complètement capturé.

### Compléter les ensembles de données { #webapi_completing_data_sets }

Cette section explique comment enregistrer des ensembles de données comme étant complets. Cela s'obtient en interagissant avec la ressource *completeDataSetRegistrations*:

    GET /api/33/completeDataSetRegistrations

Le point d'extrémité utilise la méthode *POST* pour enregistrer les ensembles de données complets. De façon pratique, ce point d'extrémité est très similaire à celui de *dataValueSets* (ensembles de valeurs de données), avec la possibilité d'importer des enregistrements complets en bloc.

L'importation de charges utiles au format *XML* et *JSON* est prise en charge. Le format de base de cette charge utile, donné en *XML* dans cet exemple, ressemble à ceci :

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

L'attribut *storedBy* (stocké par) est facultatif (car il peut être retiré de l'objet d'enregistrement complet). Vous pouvez également définir la propriété *date* (heure de l'enregistrement) en tant qu'attribut. Si l'heure n'est pas définie, l'heure actuelle sera utilisée.

Le processus d'importation prend en charge les paramètres de requête suivants :



Tableau : Paramètres de requête d'enregistrement d'ensembles de données complets

| Paramètre | Valeurs | Description |
|---|---|---|
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'ensemble de données permettant de mettre en correspondance les enregistrements complets. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de l'unité d'organisation permettant de mettre en correspondance les enregistrements complets. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de la combinaison d'options d'attribut permettant de mettre en correspondance les enregistrements complets. |
| idScheme | identifiant &#124; nom &#124; code &#124; attribut:ID | Propriété de tous les objets, y compris les ensembles de données, les unités d'organisation et les combinaisons d'options d'attribut, qui permettent de mettre en correspondance enregistrements complets. |
| preheatCache | faux &#124; vrai | Pour sauvegarder les modifications sur le serveur ou pour renvoyer le résumé de l'importation. |
| dryRun | faux &#124; vrai | Si l'enregistrement s'applique aux sous-unités |
| importStrategy (stratégie d'importation) | CRÉER &#124; METTRE À JOUR &#124; CRÉER _ET_METTRE À JOUR &#124; SUPPRIMER | Sauvegarde des objets de tous les statuts d'importation, nouveaux ou mis à jour, sur le serveur. |
| skipExistingCheck (ignorer les contrôles existants) | faux &#124; vrai | Ne contrôle pas les enregistrements complets existants. Améliore les performances. À utiliser uniquement pour les bases de données vides ou lorsque les enregistrements à importer n'existent pas encore. |
| async | faux &#124; vrai | Indique si l'importation doit être effectuée de manière asynchrone ou synchrone. La première option (asynchrone) est adapté aux importations très volumineuses car il garantit que la requête n’expire pas, bien qu’il entraîne une surcharge de performances. La deuxième (synchrone) est plus rapide mais nécessite que la connexion soit maintenue jusqu'à la fin du processus. |

Les éléments `idScheme` (schéma de l'identifiant), `dataSetIdScheme`  (schéma de l'identifiant de l'ensemble de données), `orgUnitIdScheme` (schéma de l'identifiant de l'unité d'organisation), `attributeOptionComboIdScheme` (schéma de l'identifiant de la combinaison d'options d'attribut),
`dryRun` (essai) et `strategy` (stratégie) (notez la dénomination différente du paramètre `importStrategy` (stratégie d'importation))
peuvent également être définis dans le cadre de la charge utile.
Avec XML, ce sont des attributs ; avec JSON, ce sont des éléments du nœud `completeDataSetRegistrations` (enregistrements des ensembles de données complets).

Par exemple :
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

Si le paramètre URL et la charge utile définissent un schéma, la charge utile est prioritaire.

### Lecture des enregistrements d'ensembles de données complets { #webapi_reading_complete_data_sets }

Cette section explique comment récupérer les enregistrements d'ensembles de données complets. Nous utiliserons la ressource *completeDataSetRegistrations*. Les paramètres de requête à utiliser sont les suivants :



Tableau : Paramètres de requête d'ensemble de valeurs de données

| Paramètre | Description |
|---|---|
| dataSet (ensemble de données) | Identifiant de l'ensemble de données, plusieurs ensembles de données sont autorisés |
| période | Identifiant de la période au format ISO. Plusieurs périodes sont autorisées. |
| date de début | Date de début de la période des valeurs à exporter |
| date de fin | Date de fin de la période des valeurs à exporter |
| créé | Inclut uniquement les enregistrements créées depuis l'horodatage donné |
| Durée de la création | Inclut uniquement les enregistrements créées pendant la durée indiquée. Le format est <value\><unité-de-temps\>, où les unités de temps prises en charge sont "d", "h", "m", "s " *(jours, heures, minutes, secondes).* L'unité de temps est liée à l'heure actuelle. |
| orgUnit (Unité d'organisation) | Identifiant de l'unité d'organisation ; peut être spécifié plusieurs fois. Non applicable si un groupe d'unités d'organisation est fourni. |
| orgUnitGroup (groupe d'unités d'organisation) | Identifiant du groupe d’unités d’organisation ; peut être spécifié plusieurs fois. Non applicable si une unité d'organisation est fournie. |
| subordonnées | Permet de spécifier s'il faut inclure les unités d’organisation subordonnées dans la hiérarchie des unités d'organisation |
| limite | Le nombre maximum d'enregistrements à inclure dans la réponse. |
| idScheme | Propriété d'identifiant utilisée pour les objets de métadonnées dans la réponse. |
| dataSetIdScheme (Schéma de l'identifiant de l'ensemble de données) | Propriété d'identifiant utilisée pour les ensembles de données dans la réponse. Elle remplace le schéma de l'identifiant. |
| orgUnitIdScheme (Schéma de l'identifiant de l'unité d'organisation) | Propriété d'identifiant utilisée pour les unités d'organisation dans la réponse. Elle remplace le schéma de l'identifiant. |
| attributOptionComboIdScheme (Schéma de l'identifiant de la combinaison d'options de catégorie) | Propriété d'identifiant utilisée pour les combinaisons d'options d'attribut dans la réponse. Elle remplace le schéma de l'identifiant. |
Les paramètres `ensemble de données` et `unité d'organisation` peuvent être répétés afin d'inclure plusieurs ensembles de données et unités d'organisation.

Les paramètres `période`, `date de début`, `date de fin`, `créé` et `durée de création` fournissent plusieurs façons de définir la dimension temporelle de la requête, donc un seul peut être utilisé. Par exemple, cela n'a pas de sens de définir à la fois la date de début/fin et les périodes.

Voici donc un exemple de requête :

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX&dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

Vous pouvez obtenir la réponse au format *xml* et *json*. Vous pouvez indiquer le format de réponse que vous préférez via l'en-tête HTTP *Accepter* comme dans l'exemple ci-dessus. Pour xml, utilisez *application/xml* ; pour json, utilisez *application/json*.

### Annuler la finalisation des ensembles de données { #webapi_uncompleting_data_sets }

Cette section explique comment annuler l'enregistrement de la complétude d'un ensemble de données. Pour annuler la finalisation d'un ensemble de données, vous interagirez avec la ressource completeDataSetRegistrations :

    GET /api/33/completeDataSetRegistrations

Cette ressource prend en charge la fonction *DELETE* pour annuler l'inscription. Les paramètres de requête suivants sont pris en charge :



Tableau : Paramètres de requête d'enregistrement d'ensembles de données complets

| Paramètre de requête | Obligatoire | Description |
|---|---|---|
| ds | Oui | Identifiant de l'ensemble de données |
| pe | Oui | Identifiant de période |
| ou | Oui | Identifiant de l'unité d'organisation |
| cc | Non (doit combiner avec cp) | Identifiant de la combinaison d'attributs (pour la vérification du verrouillage) |
| cp | Non (doit combiner avec cp) | Identifiants d'options d'attribut, séparés par ; pour plusieurs valeurs (pour le contrôle du verrouillage) |
| multiOu (unités d'organisation multiples) | Non (faux par défaut) | Si l'enregistrement s'applique aux sous-unités |

