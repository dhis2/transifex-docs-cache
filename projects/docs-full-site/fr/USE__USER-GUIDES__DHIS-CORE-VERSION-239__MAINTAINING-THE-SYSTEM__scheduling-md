---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.39/src/user/scheduling.md"
revision_date: '2022-03-19'
tags:
- DHIS version 2.39
- Utilisation
---

# Programmation { #scheduling } 

Le Programmateur est une application qui permet de gérer les tâches d'arrière-plan dans DHIS2. Les tâches d'arrière-plan peuvent effectuer certaines fonctions, telles que l'exécution d'analyses, la synchronisation de données et de méta-données, ou l'envoi d'un rapport d'analyse "push". L'application permet de créer, de modifier et de supprimer de telles tâches.

Le Programmateur est fourni avec le DHIS2 et est accessible via le menu App.

![La page de démarrage de l'application Programmateur](resources/images/scheduler/overview.png)

La page d'accueil de l'application Programmateur présente un aperçu des tâches existantes. Par défaut, les tâches du système prédéfinies sont masquées. Pour les afficher, cliquez sur *Inclure les tâches du système dans la liste* dans l'angle supérieur droit.

Lorsque vous créez ou modifiez une tâche, elle sera programmée en fonction de la programmation sélectionnée. Pour exécuter une tâche à la demande, accédez à la liste des tâches, cliquez sur le bouton "Actions" de la tâche que vous voulez exécuter et cliquez sur "Exécuter manuellement". Cette action n'est disponible que pour les tâches activées.

## Créer une tâche { #scheduling_create_job } 

1.  Ouvrez l'application **Programmateur** et cliquez sur le bouton "Nouvelle tâche" dans l'angle 
    supérieur droit.

1.  Choisissez un **Nom** approprié pour le nouvel emploi.

1.  Sélectionnez le **Type de tâche** que vous voulez programmer à l'aide du menu déroulant.
    menu déroulant.

1.  Sélectionnez un calendrier pour la tâche. Chaque type de tâche possède son propre type de programmation,
    soit la programmation **Cron**, soit la programmation **Delay**.

    1.  Pour les types de tâches programmés**Cron**, vous pouvez définir une planification à l'aide de la
        [Programmation du printemps](https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/scheduling/support/CronSequenceGenerator.html)
        syntaxe. Vous pouvez également sélectionner une **expression Cron** prédéfinie en cliquant sur
        "Choisir parmi les horaires prédéfinis". Cette programmation démarrera uniquement une nouvelle exécution de tâche 
        si l'exécution de la tâche précédente est terminée, ceci afin d'empêcher le système de reproduire
        trop de tâches.

    1.  Pour les tâches planifiées **Delay**, vous pouvez définir un délai en secondes. Contrairement aux
        tâches planifiées **Cron**, ces tâches ne sont pas exécutées en fonction d'un calendrier
        défini, mais avec un délai spécifique entre les exécutions des tâches. Le temporisateur
        démarre à la fin d'une tâche, ce qui démarre l'exécution d'une nouvelle tâche lorsque le temporisateur atteint
        zéro. Cela continuera tant que la tâche sera activée.

1.  Si le type de tâche est personnalisable, une section **Paramètres** apparaîtra sous 
    les paramètres de planification. Ces options supplémentaires précisent les informations de la
    tâche planifiée et vont varier en fonction du type de tâche.

1.  Cliquez sur le bouton **Sauvegarder** pour confirmer la création de la tâche. Après la création de la tâche, 
    vous serez redirigé vers l'aperçu des tâches, où la nouvelle 
    tâche créée sera désormais répertoriée.

![Création d'une nouvelle tâche de programmateur](resources/images/scheduler/add_new_job.png)

Les tâches nouvellement créées sont activées par défaut.

## Modifier une tâche{ #scheduling_configure_job }

Avec les autorisations appropriées, vous pouvez modifier les informations des tâches créées par l'utilisateur. Pour activer ou désactiver rapidement l'exécution d'une tâche créée par un utilisateur, utilisez les boutons de la colonne **Activer/Désactiver** sur la page d'accueil de l'application Programmateur. Notez que les tâches du système sont toujours activées et ne peuvent être désactivées.

Modification ultérieure des tâches utilisateur :

1.  Cliquez sur le bouton "Actions" de la tâche que vous voulez modifier et cliquez sur "Modifier" (seules 
    les tâches utilisateur peuvent être modifiées).

1.  Lorsque vous avez terminé la modification, cliquez sur le bouton **Enregistrer les modifications** pour poursuivre les modifications.

## Supprimer une tâche { #dataAdmin_scheduler_delete } 

1.  Cliquez sur le bouton "Actions" de la tâche que vous voulez supprimer et cliquez sur "Supprimer" (seules 
    (seules les tâches d'utilisateur peuvent être modifiées).

1.  Confirmez en cliquant à nouveau sur **Supprimer** dans la fenêtre pop-up.

Les tâches utilisateur peuvent également être supprimées sur la page de modification.

![Suppression d'une nouvelle tâche de programmateur](resources/images/scheduler/delete_job.png)

## Types de tâches { #job-types } 

La section suivante décrit les différents types de tâches.

### Désactiver les utilisateurs inactifs { #scheduling_disable_inactive_users }
Les utilisateurs n'ayant pas été actifs - non connectés - pendant plusieurs mois peuvent être automatiquement désactivés. Comme paramètre de tâche, choisissez le nombre de mois d'inactivité. Tous les utilisateurs qui ne se sont pas connectés pendant ce nombre de mois ou plus seront désactivés par la tâche. Les utilisateurs désactivés ne pourront plus se connecter au système.

Le paramètre _Jours restant avant_ peut être réglé de sorte à envoyer un e-mail de rappel aux utilisateurs qui spécifie le nombre de jours restant avant l'expiration de leur compte. Si les utilisateurs ne se connectent pas, d'autres e-mails de rappel seront envoyés, chacun réduisant de moitié le nombre de jours précédent. Par exemple si le nombre de jours est fixé à 7, le premier e-mail est envoyé 7 jours à l'avance, le second 3 jours à l'avance et le troisième et dernier 1 jour à l'avance. Si aucune valeur n'est pas définie (vide), aucun rappel ne sera envoyé.


### Tableau des ressources { #scheduling_resource_table } 

Le tableau de ressources à pour tâche de générer et de metter à jour des tables de la base de données des ressources. Ces tables sont utilisées par différents composants de DHIS 2 et sont destinées à simplifier les recherches dans la base de données.

Notez que lorsque vous spécifiez l'une des tâches de la table analytique, les tables de ressources peuvent faire partie du processus et il n'est pas nécessaire de spécifier également une tâche de la table de ressources.

### Tableau analytique { #scheduling_analytics_table } 

Les tableaux analytiques permettent de générer et de mettre à jour les tableaux analytiques. Les tableaux analytiques sont utilisés comme base pour les requêtes d'analyse de données dans le DHIS2. Les applications telles que Tableau de bord, Visualiseur et Cartes récupèrent les données de ces tableaux via l'API analytique du DHIS2, et elles doivent être mises à jour pour que les données analytiques deviennent disponibles. Vous pouvez programmer ce processus de façon à ce qu'il s'exécute régulièrement par le biais d'un type de tâche de table analytique.

La tâche du tableau analytique remplira par défaut les champs de données pour toutes les années et tous les éléments de données. Les paramètres suivants sont disponibles :

- **Dernières années:** Le nombre de dernières années pour lesquelles il faut remplir les tableaux d'analyse. Par exemple, si vous indiquez 2 années, le processus mettra à jour les données des deux dernières années, mais pas les données plus anciennes. Ce paramètre est utile pour réduire le temps nécessaire au processus, et est approprié si les données plus anciennes n'ont pas changé, et lorsque l'on souhaite mettre à jour les données récentes.
- **Sauter les tableaux de ressources:** Sauter les tableaux de ressources pendant le processus de mise à jour du tableau analytique. Cela réduit le temps nécessaire à l'exécution du processus, mais entraine une situation dans laquelle les modifications des métadonnées ne sont pas prises en compte dans les données analytiques.
- **Sauter les types de tableaux : ** Sauter un ou plusieurs types de tableaux analytiques. Cela réduit le temps nécessaire à l'exécution du processus, mais conduit à ce que ces types de données ne soient pas mis à jour dans les données analytiques.

### Tableau d'analyse (Suite) { #scheduling_continuous_analytics_table } 

Les tableaux analytiques permettent de générer et de mettre à jour les tableaux analytiques. Les tableaux analytiques sont utilisés comme base pour les requêtes d'analyse de données dans le DHIS2. Les applications telles que Tableau de bord, Visualiseur et Cartes récupèrent les données de ces tableaux via l'API analytique du DHIS2, et elles doivent être mises à jour pour que les données analytiques deviennent disponibles. Vous pouvez programmer ce processus de façon à ce qu'il s'exécute régulièrement par le biais d'un type de tâche de table analytique.

La tâche de la table d'analyse continue est basé sur deux phases :

- _Dernière mise à jour :_ mise à jour des données récentes, où récente renvoie aux données qui ont été ajoutées, mises à jour ou supprimées depuis la dernière mise à jour des données récentes ou des données complètes. Ce processus pourra être fréquent.
- _Mise à jour complète :_ mise à jour de toutes les données sur toutes les années. Ce processus aura lieu une fois par jour.

Le tâche de la table d'analyse continue mettra fréquemment à jour les dernières données. Le processus de mise à jour des données utilise une partition spéciale de la base de données qui ne contient que les données les plus récentes. Cette partition peut être rapidement actualisée en raison de la quantité relativement faible de données. La taille de la partition augmentera jusqu'à ce qu'une mise à jour complète soit effectuée. Toutes les données de toutes les années seront mises à jour une fois par jour,. La dernière partition sera ainsi effacée.

La tâche du tableau analytique remplira par défaut les champs de données pour toutes les années et tous les éléments de données. Les paramètres suivants sont disponibles :

- **Heure du jour de la mise à jour complète:** Heure du jour à laquelle la mise à jour complète sera effectuée. Par exemple, si vous indiquez 1, la mise à jour complète sera effectuée à 1 heure du matin.
- **Dernières années:** Le nombre de dernières années pour lesquelles il faut remplir les tableaux d'analyse. Par exemple, si vous indiquez 2 années, le processus mettra à jour les données des deux dernières années, mais pas les données plus anciennes. Ce paramètre est utile pour réduire le temps nécessaire au processus, et est approprié si les données plus anciennes n'ont pas changé, et lorsque l'on souhaite mettre à jour les données récentes.
- **Sauter les tableaux de ressources:** Sauter les tableaux de ressources pendant le processus de mise à jour du tableau analytique. Cela réduit le temps nécessaire à l'exécution du processus, mais entraine une situation dans laquelle les modifications des métadonnées ne sont pas prises en compte dans les données analytiques.

### Optimisation de la recherche Tracker { #scheduling_tracker_search_optimization }

La tâche d'optimisation de la recherche tracker est responsable de la génération et de la mise à jour des index trigrammes pour les attributs d'entité suivie pertinents. Les index trigrammes améliorent les performances de la recherche d'instances d'entité suivie en fonction de valeurs d'attributs d'entités suivies spécifiques. L'utilité des index trigrammes dépend du fait que l'attribut  soit configuré comme unique ou comme pouvant faire l'objet de recherches (lorsqu'ils sont connectés au type de programme ou d'entité suivie). Vous pouvez configurer la tâche pour choisir les attributs d'entité suivie qui doivent être indexés par trigramme. La tâche prend également en charge la suppression de tous les index obsolètes qui ont été créés précédemment mais qui ne sont plus nécessaires en raison d'une modification de la configuration des métadonnées.

Les paramètres suivants sont disponibles :

- **Attributs :** La liste des attributs qui nécessitent la création d'un index trigramme. Pour chaque attribut, un index trigramme partiel sera créé. Par exemple, si vous spécifiez les attributs "prénom" et "nom", le processus créera deux index trigrammes distincts pour les attributs correspondants à "prénom" et "nom". Notez que, si l'attribut fourni dans ce paramètre n'est pas indexable (soit parce qu'il n'est pas unique ou parce qu'il n'est pas recherchable), ces attributs sont simplement ignorés par le processus et aucun index trigramme ne sera créé pour eux.
- **Ignorer la suppression de l'index :** Ignorer la suppression des index obsolètes pendant le processus d'indexation des trigrammes. S'ils sont définis sur vrai, les index jugés obsolètes ne seront pas supprimés.

### Synchronisation des données { #scheduling_data_sync } 

DHIS2 permet la synchronisation des données entre des instances réparties à distance et une instance centrale de DHIS2. Cela peut être utile, par exemple, lorsque vous avez déployé plusieurs instances autonomes de DHIS2 qui doivent soumettre des valeurs de données à une instance centrale. La synchronisation des données tracker et des données agrégées est prise en charge.

Voici les étapes à suivre pour activer la synchronisation des données :

- Accédez aux paramètres de synchronisation, saisissez l'URL du serveur à distance,
  le nom d'utilisateur et le mot de passe. Appuyez sur le bouton TAB pour enregistrer automatiquement
  le nouveau mot de passe. Actualisez la page et vérifiez que les valeurs renseignées
  sont toujours présentes. Notez que le champ du mot de passe sera vide après
  l'actualisation, puisque cette valeur est cryptée. Vous pouvez donc la considérer comme
  sauvegardée.

- À l'aide de l'application Planificateur, créez une nouvelle tâche à l'aide des types de tâche "Synchronisation des données des programmes d'événements"
  et/ou "Synchronisation des données des programmes Tracker". Assurez-vous qu'elle
  soit activée lorsque vous avez terminé. (Remarque : si la tâche "Synchronisation des données de programme",
  disponible dans les versions précédentes, a déjà été configurée dans l'application Planificateur,
  elle a été automatiquement remplacée par les deux nouvelles tâches "Synchronisation des données des programmes d'évènements"
  et "Synchronisation des données des programmes Tracker" avec les mêmes paramètres.)

Quelques aspects de la fonction de synchronisation des données à prendre en compte :

- L'instance DHIS2 locale stockera le mot de passe du compte utilisateur
  sur l'instance à distance cryptée dans la base de données locale. Le compte
  à distance est utilisé pour l'authentification lors du transfert des données. Pour
  Pour des raisons de sécurité, assurez-vous que le paramètre de configuration _encryption.password_ (mot de passe de cryptage)
  dans _hibernate.properties_ (propriétés Hibernate) est un mot de passe fort.
   

- Deploying the remote server on SSL/HTTPS is strongly recommended as
  the username and password are sent in clear text using basic
  authentication and could be intercepted by an attacker.

- The data synchronization uses the UID property of data elements,
  category option combos and organisation units to match the
  meta-data. Hence the synchronization is dependent on these three
  meta-data objects being harmonized on the local and remote instance
  in order to work appropriately.

- The first time DHIS2 runs the synchronization job, it will include
  any data available. The subsequent synchronization jobs will only
  include data added and changed since the last successful job. A
  synchronization job is considered successful only if all the data
  was saved successfully on the remote server (Any data successfully
  synced will remain on the receiving instance, regardless if the job
  eventually fails). Whether the job was successful or not can be
  decided from the import summary returned from the central server.

- The initial synchronization job may take a significant amount of
  time, possibly slowing down your instance, depending on how much
  data is being synchronized. It could be a good idea to configure the
  job to run when there are few online users, then later change this
  to your own preference. If you do not want or need to synchronize all 
  the data, there is a possibility to <a href="#skip_changed_before">skip 
  some of the data being synchronised</a>.

  When DHIS2 synchronizes tracker data, it determines the set of data
  to synchronize based on the last time it was synchronized. Each of
  the tracked entity instances and events have their own records of
  when they where last successfully synchronized.

- The system will start a synchronization job based on the rules set
  in the configuration of the job. If the synchronization job starts
  while there is no connection to the remote server, it will retry up
  to three times before it aborts. The job will run again at a
  scheduled time.

- The server handles each set of programs separately, which means one
  set of programs can be synchronized successfully, while the other
  fails. The failure or success of one doesn't influence the other, as
  the last successful synchronization time is tracked individually for
  each item as previously mentioned.

- The attributes of TrackedEntityInstances (TrackedEntityAttribute)
  and the data elements of ProgramStages (ProgramStageDataElement)
  which have an option "Skip synchronization" turned on will not be
  synchronized. This feature allows you to decide to not synchronize
  some sensitive or not relevant data and to keep them only locally.

- The authority `Ignore validation of required fields in Tracker and Event Capture`
  (`F\_IGNORE\_TRACKER\_REQUIRED\_VALUE\_VALIDATION`) should be used when
  there is a requirement that some mandatory attribute / data element
  has at the same time a "Skip synchronization" property turned on.
  Such a setting will lead to validation failure on the central server
  as the given attribute / data element will not be present in the
  payload.

  The validation won't fail for the user with this authority. The
  authority should be assigned to the user, on the central server,
  that will be used for synchronization job.

- In specific cases, **the initial synchronization of all the data can be undesirable**; 
  for example, when a database on the local instance is a fresh copy of the 
  database present on the central instance, or when it is preferred to not 
  synchronize old data in favor of initial synchronization taking less 
  time. 

  The *syncSkipSyncForDataChangedBefore* SettingKey can be used to skip 
  the synchronisation of all the data (data values, Event and Tracker 
  program data, complete data set registrations) that were *last 
  changed before the specified date*. The `SettingKey` is used in the 
  synchronization job all the time. Therefore, if you need to synchronize 
  the old data, you should change the `SettingKey`.

- Both Tracker Programs and Event Programs synchronization job supports 
  paging in order to avoid timeouts and to deal with unstable network.
  Default page size for "Event Programs Data Sync" job is set to 60. 
  Default page size for "Tracker Programs Data Sync" job is set to 20.

  If default values do not fit your purpose, own page size can be specified 
  via parameter in particular sync job in Scheduler app.

### Planification de la synchronisation des métadonnées { #scheduling_metadata_sync } 

DHIS2 provides a feature for synchronizing meta data from a remote
instance to a local instance of DHIS2. This can be useful when you have
deployed multiple stand-alone instances of DHIS2 and you need to create
meta data in all the local instances similar to the central DHIS2
instance.

Voici les étapes à suivre pour activer la synchronisation des meta-données :

- Go to Settings \> Synchronization, enter the remote server URL,
  username and password and click Save.

- Go to Metadata administration \> Scheduling. Under Metadata
  synchronization set strategy to Enabled, select the time-period and
  click Start.

Quelques aspects de la fonction de synchronisation des meta-données à prendre en compte :

- L'instance DHIS2 locale stockera le mot de passe du compte utilisateur
  of the remote instance in its database. The remote user account is
  used for authentication when transferring/downloading data. For
  Pour des raisons de sécurité, assurez-vous que le paramètre de configuration _encryption.password_ (mot de passe de cryptage)
  dans _hibernate.properties_ (propriétés Hibernate) est un mot de passe fort.
   

- Deploying the remote server on SSL/HTTPS is strongly recommended as
  the username and password are sent in clear text using basic
  authentication and could be intercepted by an attacker.

- Also ensure that the remote user is not having ALL authority,
  instead simply create a user with F\_METADATA\_MANAGE authority so
  that even if these details are intercepted by a hacker, one cannot
  have full control of the remote system.

- The meta data synchronization relies on the underlying import layer.
  Each meta data version is an export of meta data between two given
  timestamps. Each sync of meta data version is an attempt to import
  that meta data snapshot into the local instance. The sync of
  versions is incremental. The local instance will try to download the
  meta data versions from the central instance one after the other.
  Failure to sync a specific meta data version will not let the sync
  proceed to further versions. In case of failures, appropriate
  changes must be made to meta data at central to ensure that the
  error gets resolved. Metadata configuration is critical and the
  user should be careful while rolling out the updates to the
  production. It's always recommended to have staging environments in
  place to ensure the sanity of the meta data versions and their
  impact thereafter. The local instance will sync the meta data from
  first version so that harmony is maintained and local and central
  instance will work appropriately.

- The system will attempt a synchronization at the scheduled time. If
  the local or remote server does not have a working Internet
  connection at the time, the synchronization will be aborted and
  re-attempted after as per the retry count as mentioned in the
  _dhis.conf_ file.

- You can see the time of last successful synchronization with remote
  server in the scheduling screen next to the "Last success" label.

### Predictor { #scheduling_predictor } 

Cette fonction exécute les prédicteurs et/ou groupes de prédicteurs sélectionnés.

The relative start and end parameters determine the periods in
which data will be predicted, corresponding to the date on which the
predictor job is run:

- **Relative start** counts the days from the job date to the
earliest date on which a predicted period may start. It can be positive
or negative. For example, a value of 3 means predict into periods that
start at least 3 days after the predictor run. A value of -3 means
predict into periods that start at least 3 days before the predictor run.

- **Relative end** counts the days from the job date to the
latest date on which a predicted period may end. It can be positive
or negative. For example, a value of 9 means predict into periods that
end at least 9 days after the predictor run. A value of -9 means
predict into periods that end at least 9 days before the predictor run.

Setting these values can give you very flexible control over when
predictions will be made, especially if your predictor job is set to
run daily or more frequently. Before you set these values, you should
think carefully about when you want predictions for a period to start
being made, and when you want them to stop being made. Then you
need to compute the appropriate relative start
and end dates.

Exemples:

1. **Requirement**: A predictor uses data from the same week
as the predicted value. (No past sampled data are used.)
After the week ends on Sunday, you expect the data
to be entered in the following two days (Monday and Tuesday).
You don't want to start predicting data until Wednesday after the
week ends because you don't want partial results to be shown.
However, data may still be adjusted on Wednesday, so you want to
update the predictions also on Thursday. After that, the
data are frozen and you don't want to predict for that period anymore.

    **Solution:** For a job running daily or more frequently, define the
    relative start as -10 and the relative end as -2 (for periods
    within 10 to 2 days before the job runs).

    - Before Wednesday of the following week, the period end is
    greater than 2 days before, so no predictions are made.

    - On Wednesday of the following week, the period started 9 days
    before and ended 2 days before. Predictions are made because -9 to -2
    are within the range -10 to -2.

    - On Thursday of the following week, the period started 10 days
    before and ended 3 days before. Predictions are made because -10 to -3
    are within the range -10 to -2.

    - After Thursday, the previous week started more than
    10 days before, so no predictions are made.

    - Predictions are made only on Wednesday and Thursday. On Friday through
    Tuesday, no predictions are made (and the job finishes very quickly).

2. **Requirement**: A predictor is used to forecast a limit (average plus twice
the standard deviation)
for expected non-seasonally varying disease cases based on data from the
previous five weeks. Weeks are Monday through Sunday. Predictions should start
being made from the previous Tuesday, using available data at that time, and
continue being made through Tuesday of the week that the predictions are being
made for (by which time it is assumed that the previous week's data are final).

    **Solution:** For a job running daily or more frequently,
    define the relative start as -1 and the relative end as 12.

    - Before Tuesday, predictions will not be made for the following week because it
    ends more than 12 days later.

    - On Tuesday, predictions will be made for the following week which starts
    in 6 days and ends in 12 days.

    - On Wednesday through the following Tuesday, predictions will be made for
    the week whose start-to-end dates are Wed: 5 to 11, Thu: 4 to 10,
    Fri: 3 to 9, Sat: 2 to 8, Sun: 1 to 7, Mon: 0 to 6, and Tue: -1 to 5.

    - Note that on Tuesday, predictions are made for the current week with
    start-to-end dates -1 to 5, and also for the following week
    with start-to-end dates 6 to 12. On all other days of the week
    predictions are made for one week.

Vous pouvez sélectionner les prédicteurs et les groupes de prédicteurs qui opéreront pendant l'exécution de la tâche :

- **Predictors** runs individual predictors.
They run in the order added.

- **Predictor groups** runs predictor groups.
They run in the order added. The predictors within each group run in the
order of their names (comparing Unicode character values).

If both individual predictors and predictor groups are selected in the same
job, the individual predictors run first, followed by the predictor groups.

