---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.37/src/developer/web-api/scheduling.md"
revision_date: '2021-10-26'
tags:
- Développement
- DHIS core version 2.37
---

# Programmation { #webapi_scheduling } 

DHIS2 permet de programmer des tâches de différents types. Chaque type de tâche possède des propriétés de configuration différentes, ce qui vous permet de contrôler plus finement la façon dont les tâches sont exécutées. En outre, vous pouvez configurer une même tâche de manière à ce qu'elle s'exécute avec différentes configurations et à différents intervalles, si nécessaire.



Tableau : Principales propriétés

| Propriété | Description | Type |
|---|---|---|
| nom | Nom de la tâche. | Chaîne |
| expression cron | L'expression cron qui définit l'intervalle d'exécution de la tâche. | Chaîne (expression Cron) |
| type de tâches | Le type de tâche représente la tâche qui est exécutée. Le tableau suivant donne un aperçu des types de tâches existants. Chaque type de tâche peut avoir un ensemble spécifique de paramètres pour la configuration de la tâche. | Chaîne (Enum) |
| paramètres de tâches | Paramètres de tâches, le cas échéant pour le type de tâche. | (Voir la liste des types de tâches) |
| activé | Une tâche peut être ajoutée au système sans être programmée en mettant `enabled` à false dans la charge utile JSON. Utilisez ceci si vous voulez arrêter temporairement la programmation d'une tâche, ou si la configuration d'une tâche n'est pas encore terminée. | Booléen |



Table: Available job types

| Job type | Paramètres | Param(Type:Default) |
|---|---|---|
| DATA_INTEGRITY | AUCUNE ||
| ANALYTICS_TABLE | * lastYears: Number of years back to include<br> * skipTableTypes: Skip generation of tables<br>Possible values: DATA_VALUE, COMPLETENESS, COMPLETENESS_TARGET, ORG_UNIT_TARGET, EVENT, ENROLLMENT, VALIDATION_RESULT<br> * skipResourceTables: Skip generation of resource tables | * lastYears (int:0)<br> * skipTableTypes (Array of String (Enum):None )<br> * skipResourceTables (Boolean) |
| CONTINUOUS_ANALYTICS_TABLE | * fullUpdateHourOfDay: Hour of day for full update of analytics tables (0-23)<br> * lastYears: Number of years back to include<br> * skipTableTypes: Skip generation of tables<br>Possible values: DATA_VALUE, COMPLETENESS, COMPLETENESS_TARGET, ORG_UNIT_TARGET, EVENT, ENROLLMENT, VALIDATION_RESULT<br> * skipResourceTables: Skip generation of resource tables | * lastYears (int:0)<br> * skipTableTypes (Array of String (Enum):None )<br> * skipResourceTables (Boolean) |
| DATA_SYNC | AUCUNE ||
| META_DATA_SYNC | AUCUNE ||
| SEND_SCHEDULED_MESSAGE | AUCUNE ||
| PROGRAM_NOTIFICATIONS | AUCUNE ||
| MONITORING (Validation rule analysis) | * relativeStart: A number related to date of execution which resembles the start of the period to monitor<br> * relativeEnd: A number related to date of execution which resembles the end of the period to monitor<br> * validationRuleGroups: Validation rule groups(UIDs) to include in job<br> * sendNotification: Set "true" if job should send notifications based on validation rule groups<br> * persistsResults: Set "true" if job should persist validation results | * relativeStart (int:0)<br> * relativeEnd (int:0)<br> * validationRuleGroups (Array of String (UIDs):None )<br> * sendNotification (Boolean:false)<br> * persistsResults (Boolean:false) |
| PUSH_ANALYSIS | * pushAnalysis: The uid of the push analysis you want to run | * pushAnalysis (String:None) |
| PREDICTOR | * relativeStart: A number related to date of execution which resembles the start of the period to monitor<br> * relativeEnd: A number related to date of execution which resembles the start of the period to monitor<br> * predictors: Predictors(UIDs) to include in job | * relativeStart (int:0)<br> * relativeEnd (int:0)<br> * predictors (Array of String (UIDs):None ) |

### Get available job types { #get-available-job-types } 

Pour obtenir une liste de tous les types de travaux disponibles, vous pouvez utiliser le point d'extrémité suivant :

    GET /api/jobConfigurations/jobTypes

La réponse contient des informations sur chaque type de travail, notamment le nom, le type de travail, la clé, le type de programmation et les paramètres disponibles. Le type de programmation peut être soit `CRON`, ce qui signifie que les travaux peuvent être programmés en utilisant une expression cron avec le champ `cronExpression`, soit `FIXED_DELAY`, ce qui signifie que les travaux peuvent être programmés pour s'exécuter avec un délai fixe entre les deux avec le champ `delay`. Le champ delay est donné en secondes.

Une réponse ressemblera à ceci :

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

### Create job { #create-job } 

Pour configurer les tâches, vous pouvez envoyer une requête POST à la ressource suivante :

    /api/jobConfigurations

Une tâche sans paramètres au format JSON ressemble à ceci :

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

Exemple d'un tableau d'analyse de tâches avec des paramètres au format JSON :

```json
{
  "name": "Analytics tables last two years",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * * ? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

Exemple d'une tâche d'analyse push avec des paramètres au format JSON :

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

Exemple de tâche avec le type de programmation `FIXED_DELAY` et un délai de 120 secondes :

```json
{
  "name": "Continuous analytics table",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "delay": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
```

### Get jobs { #get-jobs } 

Liste de toutes les configurations de tâches :

    GET /api/jobConfigurations

Retrouver une tâche :

    GET /api/jobConfigurations/{id}

Le contenu de la réponse se présente comme suit :

```json
{
  "lastUpdated": "2018-02-22T15:15:34.067",
  "id": "KBcP6Qw37gT",
  "href": "http://localhost:8080/api/jobConfigurations/KBcP6Qw37gT",
  "created": "2018-02-22T15:15:34.067",
  "name": "analytics last two years",
  "jobStatus": "SCHEDULED",
  "displayName": "analytics last two years",
  "enabled": true,
  "externalAccess": false,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "2018-02-26T03:00:00.000",
  "cronExpression": "0 0 3 ? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorite": false,
  "configurable": true,
  "access": {
    "read": true,
    "update": true,
    "externalize": true,
    "delete": true,
    "write": true,
    "manage": true
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favorites": [],
  "translations": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
```

### Update job { #update-job } 

Update a job with parameters using the following endpoint and JSON payload format:

    PUT /api/jobConfiguration/{id}

```json
{
  "name": "analytics last two years",
  "enabled": true,
  "cronExpression": "0 0 3 ? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
```

### Delete job { #delete-job } 

Delete a job using:

    DELETE /api/jobConfiguration/{id}

Notez que certaines tâches avec des paramètres de configuration personnalisés peuvent ne pas être ajoutées si 
les paramètres système requis ne sont pas configurés. C'est le cas par exemple de la synchronisation des 
données, qui nécessite la configuration d'un serveur distant.

## Synchronization { #webapi_synchronization } 

This section covers pull and push of data and metadata.

### Data value push { #webapi_sync_data_push } 

To initiate a data value push to a remote server one must first configure the
URL and credentials for the relevant server from System settings >
Synchronization, then make a POST request to the following resource:

    /api/33/synchronization/dataPush

### Metadata pull { #webapi_sync_metadata_pull } 

To initiate a metadata pull from a remote JSON document you can make a
POST request with a *url* as request payload to the following resource:

    /api/33/synchronization/metadataPull

### Availability check { #webapi_sync_availability_check } 

To check the availability of the remote data server and verify user
credentials you can make a GET request to the following resource:

    /api/33/synchronization/availability

