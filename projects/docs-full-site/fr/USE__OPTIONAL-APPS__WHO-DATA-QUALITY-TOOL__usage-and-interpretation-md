---
edit_url: "https://github.com/pamod-dev/dhis2-doc-support/blob/master/docs/en/dq-use.md"
revision_date: '2021-09-15'
tags:
- Utilisation
---

<font size="2">

# Comment utiliser et interpréter l'outil de Qualité des données de l'OMS { #how-to-use-and-interpret-whos-data-quality-tool }

[À l'attention de l'animateur : Pour mieux présenter cette section, faites une projection en ligne et en direct de l'instance DQ TrainingLand de DHIS2 ([https://who.-demos.dhis2.org/dq](https://who.-demos.dhis2.org/dq) ). Le document peut être présenté dans son intégralité, suivi des trois exercices. Les consignes des 3 exercices doivent être imprimées en un seul document dont un exemplaire doit être remis à chaque participant. Des conseils sur la configuration des numérateurs pour l'outil sont fournis dans un document nommé "Comment configurer l'outil de Qualité des données de l'OMS.docx". La présentation sur l'évaluation des dénominateurs et la comparaison avec les estimations d'enquête se trouve dans un document nommé "Dénominateurs de la Qualité.ppt".]

#Contenu { #contents } 

**Contenu**

* [Lancer l'outil](#launch-the-tool)
* [Utiliser le tableau de bord de complétude](#use-the-completeness-dashboard)
* [Utiliser le tableau de bord "Cohérence-temporelle"](#use-the-consistency-time-dashboard)
* [Utiliser l'outil pour effectuer une analyse de la qualité des données, propre au programme](#use-the-tool-for-a-program-specific-review-of-data-quality)
* [Utiliser le tableau de bord "Cohérence-données"](#use-the-consistency-data-dashboard)
* [Utiliser le tableau de bord "Valeurs atypiques"](#use-the-outliers-dashboard)
* [Utiliser la fonction "Analyse-Cohérence"](#use-the-analysis-consistency-function)
* [Utiliser la fonction "Analyse des Valeurs atypiques et Données manquantes"](#use-the-analysis--outliers-and-missing-data-function)
* [Exercice 1 : Utiliser le tableau de bord et les fonctions d'analyse pour identifier les valeurs suspectes dans votre DHIS2](#exercise-1-use-the-dashboard-and-the-analysis-functions-to-identify-supicious-values-with-your -dhis2)
* [Exercice 2 : Discuter de comment traiter les valeurs très suspectes](#exercise-2-discuss-how-to-deal-with-very-suspicious-values)
* [Utiliser la fonction "Rapport annuel"](#use-the-annual-report-function)
* [Exercice 3 : Utiliser l'outil pour préparer un rapport annuel sur la qualité des données](#exercise-3-use-the-tool-to-prepare-an-annual-data-quality-report)
* [Annexe 1 : Comment configurer les dénominateurs, les relations entre dénominateurs, et les comparaisons avec des données externes](#annex-1--how-to-configure-denominators-denominator-relations-and-external-data-comparisons)
* [Notes](#notes)
* ["Doses de DPT-HepB-Hib 3 administrées < 1 an" est rapporté avec l'ensemble de données du PEV tandis que "Doses de Penta 3 administrées" est rapporté avec l'ensemble de données du HMIS.](#dpt-hepb-hib-3-doses-given--1-year-is-reported-with-the-epi-dataset-whereas-penta-3-doses-given-is-reported-with-the-hmis-dataset)


<font size="2">

# Lancer l'outil { #launch-the-tool } 


<font size="2">

1. **Connectez-vous à l'instance DHIS2** <https://who.-demos.dhis2.org/dq> 
`Nom d'utilisateur : demo Mot de passe :  District1#`


2. Entrez "OMS" dans le champ de recherche des applications située en haut à droite de la page d'accueil DHIS2. Cliquez sur **Outil de Qualité des données de l'OMS**.


    ![alt_text](resources/images/dqinfo/image001.png "image_tooltip")


3. **Examinez rapidement le menu principal de l'outil de QD** : Après avoir lancer l'outil, vous verrez les 5 onglets en haut de la page. Ils permettent de choisir entre plusieurs fonctionnalités différentes. Le mot "Tableau de bord" est mis en surbrillance et la fonction Tableau de bord est sélectionnée par défaut.


     ![alt_text](resources/images/dqinfo/image002.png "image_tooltip")



4. **Examinez rapidement le menu du tableau de bord** : Le tableau de bord a 4 onglets. L'onglet Complétude est sélectionné par défaut.



   ![alt_text](resources/images/dqinfo/image003.png "image_tooltip")



# Utiliser le tableau de bord Complétude { #use-the-completeness-dashboard } 

5. **Examinez le tableau de bord Complétude** : Défilez vers le bas et examinez la page Complétude du tableau de bord de la qualité des données. La page montre la complétude de chacun des 5 "ensembles de données de base".

> **Remarque :** Lorsque vous examinez la complétude avec votre instance DHIS2, si vous constatez qu'il est de 0% pour un ou plusieurs ensembles de données, il est probable que les données aient été importées. DHIS2 ne permet pas de surveiller la complétude des données importées à moins que vous n'importiez également les métadonnées de complétude.
> Pour l'instance de formation de DHIS2, l'ensemble de données sur la vaccination est assez incomplet. Il est préférable d'examiner la qualité des données de CPN qui sont plus complètes.


   ![alt_text](resources/images/dqinfo/image004.png "image_tooltip")


   **a. Examinez les graphiques situés sur le côté gauche de la page :** Les graphiques de gauche montrent, pour chaque ensemble de données, la complétude et la ponctualité par mois pour chacun des 12 derniers mois. ![alt_text](ressources/images/dqinfo/image005.png "image_tooltip")




   **b. Examinez les graphiques situés sur le côté droit de la page :** Les graphiques sur la droite montrent, pour chaque ensemble de données, la complétude par région <span style="text-decoration:underline;"> et pour le dernier mois </span> de la période analysée. Remarque : Avec cette instance DHIS2, le pays est divisé en 4 régions, chacune subdivisée en plusieurs districts. La complétude du mois le plus récent est en réalité une évaluation de la ponctualité. Présenter la complétude de l'avant-dernier mois est souvent plus révélateur. Cliquez sur l'icône de menu.![alt_text](resources/images/dqinfo/image006.png "image_tooltip") dans l'angle supérieur droit de l'écran pour afficher un menu sur le côté droit de l'écran. La période analysée, représentée sur le graphique, peut être changée en cliquant sur un autre mois. _ <span style="text-decoration:underline;"> Après avoir changé le mois, réinitialisez-le en considérant le mois d'avril de cette année. </span> _


   **c. Modifiez l'"unité d'organisation" en cours d'analyse :** Par défaut, l'outil de QD analyse toutes les données à l'échelle nationale, désagrégées par région. L'outil de QD peut également être utilisé au niveau du district avec des données désagrégées par établissement de santé. Dans la section Unité d'organisation du menu, cliquez sur **Autre** et sélectionnez "District D" de la région A. Les graphiques du côté gauche de la page de complétude affichent désormais la tendance sur 12 mois de la complétude des rapports du district D. Par défaut, les graphiques du côté droit de la page de complétude affichent les résultats désagrégés pour un niveau inférieur - établissement. **Question** : Quels établissements n'ont pas encore déclaré de données relatives aux CPN pour le mois dernier ? Depuis 3 mois ? Depuis 6 mois ? _ <span style="text-decoration:underline;"> Après avoir modifié l'unité d'organisation et le mois, procédez à une réinitialisation au niveau national avec **désagrégation par district** et période = avril de cette année </span> _[^1]_ <span style="text-decoration:underline;"> . </span> _

![alt_text](resources/images/dqinfo/image007.png "image_tooltip")

# Utiliser le tableau de bord "Cohérence-temporelle" { #use-the-consistency-time-dashboard }

6. **Examinez le tableau de bord "Cohérence-temporelle"** : Cliquez sur l'onglet "Cohérence-temporelle". Défilez vers le bas et examinez la page. Placez le curseur sur chaque graphique pour afficher les détails de la fenêtre contextuelle.

![alt_text](ressources/images/dqinfo/image008.png "image_tooltip")

  a. **Examinez les graphiques situés sur le côté gauche de la page :** Les graphiques de gauche montrent, pour chaque numérateur de base, la tendance de la valeur du numérateur pour les 1 à 12 mois précédents (bleu foncé sur le graphique ci-dessus), les 13 à 24 mois précédents (bleu clair sur le graphique ci-dessus) et les 25 à 36 mois précédents (orange sur le graphique ci-dessus). Notez la nette augmentation de la valeur de CPN 1 en mai 2018 et à nouveau en janvier 2019. Une telle augmentation au niveau national est certainement suspecte.



  b. **Examinez les graphiques situés du côté droit de la page :** Chaque graphique de droite est un exemple de "diagramme de dispersion". Lorsque l'outil est défini sur 'Désagrégé par district', chaque point représente la valeur d'un seul district. Sur ce graphique, la position du point sur l'axe vertical représente la valeur du numérateur pour le mois sélectionné (rappelez-vous que nous avons réinitialisé le menu pour afficher les résultats de la Période = avril 2020). La position du point sur l'axe horizontal représente la valeur moyenne dans le même district pour les 11 mois précédents. Les points qui apparaissent au-dessus de la ligne grise inférieure ou au-dessus de la ligne grise supérieure sont des points suspects (par exemple, dans l'exemple ci-dessous, le nombre de 1<sup>ères</sup> visites de CPN dans le district F était de 1 425 en avril 2020 contre une moyenne de 4 596 / mois de Mai 2019 à mars 2020.

  ![alt_text](resources/images/dqinfo/image009.png "image_tooltip")


Par conséquent, le "tableau de bord du temps de complétude" peut permettre d'identifier certaines valeurs suspectes. Cependant, d'autres composants de l'outil sont plus efficaces dans la détection de valeurs suspectes, raison pour laquelle cette page est moins utilisée que les autres[^2].


# Utiliser l'outil pour effectuer une analyse de la qualité des données, propre au programme{ #use-the-tool-for-a-program-specific-review-of-data-quality } 


7. **Examinez la liste des éléments/indicateurs de données "de base" :** Dans le menu de l'outil, "Données" est désormais défini sur "de base". Par conséquent, l'outil présente les résultats pour les éléments de données/indicateurs définis sur "de base"[^3]. Faites défiler la page "Temps de complétude" pour consulter la liste. Notez que seuls deux indicateurs de vaccination[^4] sont présentés.


8. **Changez les données par "Vaccination"**– Dans le menu (cliquez sur l'icône si le menu n'est pas ouvert), remplacez "de base" par "Vaccination". Observez ce qui se passe avec la liste des éléments de données/indicateurs présentés : 10 indicateurs de vaccination sont désormais présentés sur la page "Temps de complétude". Ainsi, l'outil peut être utilisé pour mener un examen sur la qualité des données, spécifique au programme - afin d'analyser la gamme complète des indicateurs spécifiques au programme. Avant de passer à l'étape suivante, ramenez les données sur "de base" à partir du menu.


# Utiliser le tableau de bord "Cohérence-données"{ #use-the-consistency-data-dashboard } 



9. **Examinez le tableau de bord "Cohérence-données"** : Cliquez sur l'onglet "Cohérence-données". Cette page indique s'il existe une relation plausible entre des numérateurs associés. Ce sont les "relations du numérateur" qui sont configurées dans : Plus-Administration-Relations du numérateur. Défilez vers le bas et examinez la page. Placez le curseur sur chaque graphique pour afficher les détails de la fenêtre contextuelle.


    a. **Review any scatterplots:** The graph comparing ANC 1 to ANC 4 is a scatterplot with each dot representing the total values, over the last 12 months, for one district.  Districts with values that fall outside of the grey threshold lines are represented with a diamond shape.  As one example, for District F (represented by the enlarged diamond), over the last 12 months, ANC 4 was only 2,641 while ANC 1 was 51,976.  The discrepancy is suspicious and should be investigated.

    ![alt_text](resources/images/dqinfo/image010.png "image_tooltip")


    b. **Review any graphs assessing dropout rates:** The graph comparing DPT1 to DPT3 assesses for any “negative dropout rate”.  The graph shows that there are 5 districts which, over the 12 months up to and including April 2020, had a negative DPT 1 to DPT 3 dropout rate.  In other words, these 5 districts reported a higher value of DPT 3 than DPT 1.  A negative DPT dropout rate for a district for an entire year is usually a sign of poor data quality.  This should be investigated.

    ![alt_text](resources/images/dqinfo/image011.png "image_tooltip")


# Utiliser le tableau de bord "Valeurs atypiques" { #use-the-outliers-dashboard }


10. **Use the “Outliers” dashboard to identify suspicious district-level values:** Click on the tab for “Outliers”. If necessary, use the menu to set Disaggregation to District. To free up space on the page, click on the menu icon to make the menu disappear. The page shows a “Result” table with a large number of rows.  Each row has one or more values highlighted in red. How are the values highlighted in red different from the other values in the same row?  The Tool finds the values highlighted in red to be suspicious because they are either significantly higher or significantly lower than the other values in the row. The rows are sorted in order of “weight”.  The “weight” can be thought of as the difference between the suspicious value and the average of other values in the row.
There are so many rows that the table will not fit on a single page.  You can view the subsequent pages by clicking on the controls at the bottom of the page.


    ![alt_text](resources/images/dqinfo/image012.png "image_tooltip")



    a. **Investigate outliers with a weight that exceeds 5% of a district’s annual total**. With so many outliers, how can you decide which ones are most important?  One approach is to focus on the rows at the top which have the largest weight. As a rule of thumb, all values with a weight that is more than 5% of the district’s expected annual total should be carefully investigated because they can significantly distort the district statistic. Consider, as examples, the 1<sup>st</sup> and 2<sup>nd</sup> rows in the above table showing extreme outliers in the values of ANC 1.  The expected annual number of pregnancies in districts F is 20,000 while the expected number of pregnancies in district E is 110,000. In both cases the extreme outliers must be investigated because the outlier weights greatly exceed 5% of the district’s expected annual pregnancies.  





    b. **Investigate outliers with an extreme Z-score**. There is another way to identify the outliers which are most suspicious by using their “Z-score”[^5]. To use this method, click on the Options button to open the Options window. To see the Z-score for each row, click on the box “Include Z-score”.  Review the Standard Z-score values in the Result table.  Notice that the values range from less than 2 to more than 3.  Next, click on the following buttons: 1) Outliers; 2) Standard Score; and 3) Extreme.  If the Result table has no rows at all or only 1 or 2 rows, click on “Modified Z-Score”[^6] to identify more outliers.

    ![alt_text](resources/images/dqinfo/image013.png "image_tooltip")


    c. **Inspect each row**– **Questions**:  Review the Standard Z-scores.  Notice how the Result table reduces to only a few rows. Notice that the Z-score for each row is greater than 3.0.  Do you think _these_ suspicious value might be due to an error? How would you investigate to determine whether a highlighted value is due to an error? Click on the menu icon at the end of the first row and select “Visualize” from the drop-down menu.


    ![alt_text](resources/images/dqinfo/image014.png "image_tooltip")


    d. **“Drill down” to investigate the source of the suspicious value** – Click on the Close button to close the graph, click again on the menu icon and select “Drill down” from the drop-down menu.  If necessary, again use the Options feature to filter the table to Outliers, Standard Score and Extreme.  Do you think _these_ suspicious value might be due to an error? Very large extreme outliers such as the one in the first row are very likely to be due to errors. Extreme outliers which are much less than the average monthly value, such as the one seen in the second row, may be due to missing data if they are seen at district or higher level.  A small but extreme outlier seen at facility level is also likely to be due to an error.


    ![alt_text](resources/images/dqinfo/image015.png "image_tooltip")


    If there is another level of the organizational hierarchy below this level, you can drill down further. If, however, this is the lowest level in the hierarchy then you get a message such as the following:


    ![alt_text](resources/images/dqinfo/image016.png "image_tooltip")



    e. **Consider sending a message**[^7] to the person responsible.  Click again on the menu icon and select “Contact” from the drop-down menu.  A window should appear showing the Contact person for notifying of the extreme outlier.  Click on “Write message”.  Use the drop-down menus to fill in the information below Recipient, write a message and click on “Send message”.  A message will then be sent via the DHIS2 internal messaging service.



    ![alt_text](resources/images/dqinfo/image017.png "image_tooltip")



    ![alt_text](resources/images/dqinfo/image018.png "image_tooltip")




    As we have seen, the dashboard of the DQ Tool is easy to use.  A limitation of the dashboard, however, is that it can only be used to review those data elements/indicators for which the dashboard has been configured (see “How to configure the WHO Data Quality Tool”).  Next we will learn how the Analysis function of the DQ Tool can be used to review the quality of _<span style="text-decoration:underline;">any</span>_ data element or indicator for which DHIS2 has data.


# Utiliser la fonction "Analyse-Cohérence" { #use-the-analysis-consistency-function } 



11. **Examinez la fonction "Analyse-Cohérence"** : En plus du tableau de bord, l'outil offre un moyen pratique pour personnaliser votre analyse de la qualité des données.

   * Cliquez sur l'onglet Analyse en haut de la page, puis sélectionnez Cohérence.

   ![alt_text](resources/images/dqinfo/image019.png "image_tooltip")

Une fenêtre apparaît et vous permet de configurer une évaluation personnalisée de la cohérence au fil du temps ou de la cohérence entre les numérateurs associés. Par défaut, la cohérence "Entre les indicateurs" (entre les numérateurs associés) est sélectionnée de même que Comparer les unités d'organisation au "Résultat général". Avec ce paramètre, A = B, A > B et Abandon ne peuvent être sélectionnés[^8]. Laissez "Type d'analyse de cohérence" défini sur "Entre les indicateurs" mais cliquez sur "Résultat attendu" et sélectionnez "Abandon" (voir la figure).

  *  Cliquez sur Données pour choisir vos numérateurs. Configurez la fenêtre tel qu'indiqué sur la figure. (Notez que "Indicateur" est sélectionné pour les deux numérateurs. Cela tient au fait que, pour cette instance DHIS2, les données du DPT 1 sont désagrégées en deux éléments de données distincts : DPT1 des sites fixes et DPT1 des services de proximité. Un indicateur a été configuré pour examiner simultanément les données de ces deux éléments. De même, un indicateur a été configuré pour la somme de DPT3 des sites fixes et DPT3 des services de proximité.



  *   Cliquez sur Période pour personnaliser la période tel qu'indiqué sur la figure - définie sur l'année dernière.


![alt_text](resources/images/dqinfo/image021.png "image_tooltip")

* Cliquez sur Unité d'organisation et définissez la désagrégation sur District.

  ![alt_text](resources/images/dqinfo/image022.png "image_tooltip")

Cliquez sur le bouton bleu Analyser, situé en bas à droite de la page et les résultats apparaîtront. Notez les points suivants :

 1. Le graphique du côté gauche de la page est similaire à celui du tableau de bord "Cohérence-données". 6 districts avaient un taux d'abandon négatif du DPT 1 au DPT 3 en 2017. Pour voir plus de détails, vous pouvez placer le curseur sur les barres rouges.

 2. Le tableau du côté droit de la page comporte une ligne pour tout le pays suivie d'une ligne pour chaque district. Les districts sont classés en fonction de leurs taux d'abandon. Les 6 districts avec un taux d'abandon négatif sont en haut de cette liste. Les lignes se prolongent sur deux pages supplémentaires mais leur consultation est moins importante car les taux d'abandon y sont tous positifs.


    ![alt_text](resources/images/dqinfo/image023.png "image_tooltip")

 3. Si vous cliquez sur une ligne, sa couleur passe au jaune pâle et un tableau avec une ligne plus un autre graphique apparaissent au bas de la page. Le graphique vous montre les résultats par mois. Dans cet exemple, la valeur du DPT 3 était supérieure à celle du DPT1 pendant 7 mois sur 12, pour le compte de l'année dernière. Ainsi, le taux d'abandon négatif n'est pas uniquement dû à une seule valeur atypique - en 2019 et pour le district G, le problème était persistant.


    ![alt_text](resources/images/dqinfo/image024.png "image_tooltip")


 4. Vous pouvez cliquer sur l'icône de menu à la fin de cette ligne unique pour "explorer" et visualiser les résultats désagrégés à un niveau inférieur. Le graphique montre que le taux d'abandon négatif n'est pas uniquement dû à la déclaration de données par un seul établissement de santé -  en 2018, 11 établissements de santé sur 18 dans le district G ont déclaré une valeur de DPT 3 supérieure à celle du DPT 1. Conclusion : le district G semble avoir un problème de surévaluation du DPT 3. Le problème a affecté la déclaration de données par plusieurs établissements de santé et sur plusieurs mois. Cela peut être dû au fait que certains établissements du district G ont pris l'habitude de classer par erreur les premières doses de DPT comme troisièmes doses.

![alt_text](resources/images/dqinfo/image025.png "image_tooltip")


12.  **Utiliser la fonction "Analyse-Cohérence" pour identifier toutes les valeurs fournies par des établissements qui méritent d'être étudiées**

  *   Définissez le type d'analyse tel qu'indiqué sur la figure : Type d'analyse de cohérence = "Au fil du temps" ; Comparez les unités d'organisation à = "Résultat attendu" ; Tendance attendue = "Constante" ; Critère = 0 %.

  ![alt_text](resources/images/dqinfo/image026.png "image_tooltip")

  *   Cliquez sur Données et sélectionnez un seul élément de données ou indicateur. Par exemple, sélectionnez "doses de Penta 3  administrées (HMIS)" dans le groupe d'éléments de données "HMIS"

  ![alt_text](resources/images/dqinfo/image027.png "image_tooltip")

  *   Cliquez sur Période pour paramétrer la période tel qu'indiqué sur la figure. Avec ces paramètres, la valeur de février 2020 sera comparée à celles des 12 mois précédents.

  ![alt_text](resources/images/dqinfo/image028.png "image_tooltip")

  *   Cliquez sur Unité d'organisation, sélectionnez un district spécifique et définissez la désagrégation sur Établissement.

  ![alt_text](resources/images/dqinfo/image029.png "image_tooltip")

 Avec ces paramètres, les valeurs du Penta 3 pour le compte de février 2020 et pour tous les établissements de santé du District E seront comparées aux valeurs moyennes rapportées par ces mêmes établissements au cours des 12 mois précédents.


  *   Cliquez sur "Analyser" et attendez que le graphique apparaisse.

  ![alt_text](resources/images/dqinfo/image030.png "image_tooltip")


Comment comprendre ce tableau ?

  *    Chaque point représente les données rapportées par un établissement de santé du district sélectionné (District E) ;
  *   Le graphique compare la valeur rapportée en février 2020 à la valeur moyenne rapportée par le même établissement au cours des 12 mois précédents ;
  *   La ligne représente l'égalité. Pratiquement aucun des points ne se trouve exactement sur la ligne. La distance de chaque point par rapport à la ligne est déterminée par son poids. La plupart des points sont si proches de la ligne que leur poids est faible. Nous pouvons donc les ignorer.
   *   Chaque mois, le district rapporte un total de 6 536 doses de Penta <sup> 3 </sup> sur le formulaire du HMIS. Ce nombre peut être utilisé pour déterminer un seuil dans le cadre d'une enquête sur les valeurs atypiques. Il peut être décidé, par exemple, qu'une enquête doit être menée pour toute valeur atypique qui s'écarte de la ligne à plus de 5 % du total du district qui est 325.
  *   Seuls les deux premiers points ont un poids supérieur à 325. Pouvez-vous repérer ces deux points sur le graphique ? :
       * L'établissement 567 a rapporté le chiffre 961 alors qu'il avait précédemment rapporté une moyenne de 146/mois. Cette valeur suspecte se voit donc attribuer un poids de 803 ;
       * L'établissement 222 n'a rapporté aucune donnée alors qu'il avait précédemment rapporté une moyenne de 349 par mois. Cette valeur manquante se voit donc attribuée un poids de 349 ;
  *   Ces deux valeurs nécessite une enquête

La première étape de notre enquête va consister à cliquer sur chaque ligne. La ligne sélectionnée passe au jaune et un graphique apparaît au bas de l'écran de DHIS2.

![alt_text](resources/images/dqinfo/image031.png "image_tooltip")

Le graphique nous montre la nette différence entre la valeur de février 2020 pour l'établissement 567 et les valeurs rapportées précédemment. Cela est probablement dû à la présence de données erronées. Comment pouvons-nous utiliser DHIS2 pour approfondir notre enquête ? Que pouvez-vous faire d'autre pour enquêter sur cette valeur ? ` Voici ce que nous obtenons lorsque nous cliquons sur la ligne de l'établissement 222.

![alt_text](resources/images/dqinfo/image032.png "image_tooltip")

Non seulement la valeur de février 2020 est manquante, mais celle de mai 2019 est aussi anormalement élevée. Cela montre comment cette analyse permet non seulement d'identifier les valeurs atypiques extrêmes pour le mois sélectionné (février 2020), mais elle peut aussi identifier les valeurs atypiques des mois précédents (si la valeur en question est si élevé qu'elle augmente considérablement la moyenne sur 12 mois).

En résumé, avec ce type d'analyse, un district peut examiner les valeurs les plus récentes de tous les établissements de santé et identifier un sous-ensemble de valeurs qui nécessite une enquête approfondie. L'analyse doit être effectuée sur un élément de données à la fois.

# Utiliser la fonction "Analyse-Valeurs atypiques et Données manquantes"{ #use-the-analysis-outliers-and-missing-data-function }


13. **Examinez la fonction "Valeurs atypiques et Données manquantes" :** Cliquez sur l'onglet Analyse en haut de la page, puis sélectionnez "Valeurs atypiques et Données manquantes". La fonction "Analyse-Valeurs atypiques" fonctionne de la même manière que le tableau de bord des Valeurs atypiques. Sa flexibilité la rend plus avantageuse que le tableau de bord. Vous pouvez la configurer pour évaluer <span style="text-decoration:underline;">tous</span> les éléments de données ou indicateurs [^9] - pas seulement les éléments de données/indicateurs pour lesquels le tableau de bord de l'outil de QD a été configuré. En effet, vous pouvez la configurer pour qu'elle évalue simultanément toutes les _combinaisons_ d'éléments de données et d'indicateurs. Vous pouvez aussi évaluer simultanément tous les éléments de données ou indicateurs d'un ensemble de données, d'un groupe d'éléments de données et/ou d'un groupe d'indicateurs.

    ![alt_text](resources/images/dqinfo/image033.png "image_period")

Vous pouvez également l'utiliser pour évaluer les données de n'importe quelle période.

![alt_text](resources/images/dqinfo/image034.png "image_calender")

... et pour tout regroupement d'établissements de santé.[^10]

![alt_text](resources/images/dqinfo/image035.png "image_selectou")

# Exercice 1 : Utiliser le tableau de bord et les fonctions d'analyse pour identifier les valeurs suspectes dans votre DHIS2{ #exercise-1-use-the-dashboard-and-the-analysis-functions-to-identify-suspicious-values-with-your-dhis2 }



14. **Examinez le tableau de bord "Cohérence-temporelle** – Cliquez sur l'onglet du tableau de bord "Cohérence-temporelle". Examinez les graphiques de gauche et de droite pour le premier élément de données/indicateur (CPN1).

    a.Définissez les données sur [de base], la période sur avril de cette année et la désagrégation sur District.

    b. Examinez le graphique de gauche.

    L'élément de données/l'indicateur a-t-il eu une valeur stable d'une année à l'autre et d'un mois à l'autre ? Si non, comment expliquez-vous l'incohérence ?

    c. Accédez rapidement au tableau de bord 'Complétude' pour examiner le niveau de complétude de l'ensemble de données CPN au cours des 12 derniers mois (le graphique situé sur le côté gauche de la page).

     Dans quelle mesure l'incohérence avec la valeur de l'élément de données/indicateur est due à un changement dans les rapports sur la complétude ?

    d. Revenez au tableau de bord 'Cohérence'-

    Tableau de bord et examen du graphique du côté droit pour la CPN 1. Ce graphique est un diagramme de dispersion où chaque point représente un district. La position du point sur l'axe vertical indique la valeur de la CPN 1 en avril de cette année pour le compte d'un district. La position du point sur l'axe horizontal indique la valeur moyenne de la CPN 1 pour ce district au cours des 11 mois précédant avril (c'est-à-dire de mai 2019 à mars 2020). Placez le curseur sur les points situés au-dessus ou en dessous des deux lignes grises pour afficher les valeurs suspectes.

    **Question** : Énumérez les districts dont les valeurs pour le mois dernier sont les plus incohérentes par rapport à leur valeur moyenne au cours des 11 mois précédents. Comment pouvez-vous expliquer l'incohérence des données de ces districts au fil du temps ? Les données rapportées pour le mois dernier seraient-elles incomplètes ? Est-ce dû à de réels changements dans la prestation de services au cours du mois dernier ? Sachez que plusieurs raisons peuvent expliquer l'incohérence des valeurs au fil du temps. De ce fait, une telle incohérence ne met pas nécessairement en cause un problème de qualité des données.

15. **Examinez le tableau de bord "Cohérence-données"** - Cliquez sur l'onglet qui conduit au tableau de bord "Cohérence-données". Chaque graphique sur ce tableau de bord évalue la relation entre une paire d'éléments de données/indicateurs associés.

    a. **Examinez le premier graphique qui compare la CPN 1 à la CPN 4 :**

    Ce graphique est également un diagramme de dispersion, où chaque point représente les valeurs de la CPN 1 et de la CPN 4 pour le compte d'un district, au cours des 12 mois précédents y compris le mois d'avril de cette année. Les districts dont les valeurs se situent hors des lignes de seuil grises sont représentés sous forme de losange. Placez le curseur sur ces points pour examiner les valeurs suspectes des éléments de données/indicateurs associés.

     **Questions** : Comprenez-vous pourquoi l'outil a signalé ces valeurs associées comme suspectes ? Enumérez les districts avec des valeurs suspectes. Comment pouvez-vous expliquer la présence des valeurs suspectes pour ces districts particuliers ? Pourquoi est-ce que des rapports incomplets ne pourrait expliquer ces valeurs suspectes ?

    b. **Examinez le graphique qui évalue les taux d'abandon du Penta :**

    Questions : Quels districts ont un taux d'abandon négatif du Penta 1 au Penta 3 ? Quel district a le taux d'abandon le plus négatif ? Pourquoi pensez-vous que ce district en particulier a le taux d'abandon de Penta le plus négatif ? Le taux d'abandon négatif pourrait-il être dû à une seule valeur importante erronée, pour le compte d'un seul établissement de santé et pour un seul mois ? Ou est-ce dû à plusieurs valeurs provenant de plusieurs établissements de santé et de plusieurs mois ? Le tableau de bord "Cohérence-données" ne permet pas vraiment de répondre à cette question.

    c. **Utilisez la fonction Analyse-Cohérence pour évaluer les taux d'abandon du Penta** : cliquez sur l'onglet '"Analyse", puis sélectionnez "Cohérence" dans le menu déroulant. Dans "Type d'analyse", cliquez sur chacun des éléments suivants : "Entre les indicateurs", "Résultat attendu" et "Abandon".

    ![alt_text](resources/images/dqinfo/image036.png "image_selectou")

    Ouvrez la fenêtre Données puis configurez-la tel qu'indiqué sur la figure à droite de l'écran. Remarque : Avec votre DHIS2, Penta 1 < 1 an (ou Penta 1 < 1 an) et Penta 3 < 1 an (ou Penta 3 < 1 an) peuvent être des éléments de données plutôt que des indicateurs.

    ![alt_text](resources/images/dqinfo/image037.png "image_selectou")


    Open the Period window and set it to year = 2019.  


    Open the Organisation unit window and set it to National (or the equivalent ) with disaggregation to District.  Click the Analyze button.


     i. Review the chart and the table (note:  the top row of the table will not be shaded yellow until you complete the next step).  Move the cursor over the vertical red bars in the chart to view the details. Compare the names of the districts with vertical red bars to the names of the districts in the table with Dropout rate shaded in red. 

      **Questions**: Which district has the most negative dropout rate?  Find it in the chart and find it in the table.  For that district, during 2019, what was the value of DPT 1 and what was the value of DPT 3 (see table)? 

     ![alt_text](resources/images/dqinfo/image038.png "image_selectou")

     ii. Click on the row of the table for the district with the most negative dropout rate. A new table and chart should appear at the bottom of the page.  

     **Question**: Is the negative dropout rate due to a value for a single month or is it due to values for multiple months?

      ![alt_text](resources/images/dqinfo/image039.png "image_selectou")

     iii. Click on the menu icon at the right end of the small table and select “Drill down” (due to a bug in the Tool, the words may not all show on the screen).  A new chart and table should appear showing the dropout rates for 2019 for each org sub-unit (for example, each health facility if they are immediately beneath district in the organizational hierarchy).

      **Questions**: For the district which you have selected, is the negative dropout rate due to a value from a single facility or is it due to values from multiple facilities?  Does it appear that the district you have selected has a systematic problem with over-reporting of DPT 3 – for multiple months and multiple sub-districts?  How do you explain this?

    ![alt_text](resources/images/dqinfo/image040.png "image_selectou")


16. **Utilisez le tableau de bord "Valeurs atypiques" pour identifier les valeurs atypiques majeures**-- Cliquez sur l'onglet du tableau de bord "Valeurs atypiques". Examinez la fenêtre du menu pour confirmer que la  Désagrégation est défini sur District. Cliquez sur l'icône du menu pour masquer la fenêtre et libérer de l'espace sur l'écran. Cliquez sur le bouton Options puis cochez la case "Inclure le Z-score" et cliquez sur "Valeurs atypiques", "Score standard" et "Extrême". Si le tableau des "Résultats" ne contient pas de lignes ou n'a qu'une seule ligne, cliquez sur "Z-score modifié".

    ![alt_text](resources/images/dqinfo/image041.png "image_selectou")


     Click on the menu icon at the end of the first row of the table and select “Visualize”.  Review the graph.  **Question**:  Do you think this extreme outlier is due to an error in the data?  After you have finished viewing the graph, click “Close”.  

     Click again on the menu icon at the end of the first row of the table and select “Drill down”.  A new “Result” table should appear with 1 row for each facility in the selected district which has an extreme outlier during the 12-month period.  Consider the outlier in the first row of this new table.  Repeat the process of visualizing the outlier.  If you want, try to drill down further. **Question**:  Do you think this extreme outlier is due to an error in the data?

17. **Utilisez la fonction "Analyse-Valeurs atypiques" pour identifier les valeurs atypiques extrêmes d'éléments de données supplémentaires**—

    Click on the tab for Analysis, then select “Outliers and Missing Data”. Select a data element or indicator of your choice.  Then set Period to 2019 and set Orgunit to national with Disaggregation by district. Click on Analyze then proceed to use the Tool to identify extreme outliers using the same steps as with the Outliers dashboard. 

    ![alt_text](resources/images/dqinfo/image042.png "image_selectou")

# Exercise 2: Discuss how to deal with very suspicious values { #exercise-2-discuss-how-to-deal-with-very-suspicious-values } 

18. **List the measures that you would take** if you identified a value that was very suspicious and so large that it probably has a significant effect on a nationwide statistic.[^11] 

19. **Who has authority to edit** the data of your DHIS2? 

20. **Comment prévoyez-vous utiliser l'Outil** pour identifier les valeurs atypiques extrêmes- au niveau du district et au niveau national - pour chaque mois ou trimestre et pour chaque année.


# Use the “Annual Report” function { #use-the-annual-report-function } 


21. **Produire le rapport annuel :**

     Go to the menu at the top of the DQ Tool and click on the Annual Report.  Use the drop down menu to select “[Core]” under <span style="text-decoration:underline;">Data – Group</span>.  Under Period, select the last calendar year, then specify the number of years for which you have at least one data set with completeness greater than 50%. Ideally this would be 2 or 3 years[^12].  Under <span style="text-decoration:underline;">Organization unit</span> set<span style="text-decoration:underline;"> Disaggregation </span>to the equivalent of district.  It is not recommended that you leave Disaggregation set to the equivalent of Region (e.g. Province), because the Annual Report will then fail to identify many important data quality problems. Click on “Generate” to view the report. 

       ![alt_text](resources/images/dqinfo/image043.png "image_selectou")


22. **Quickly review the SUMMARY of the Annual Report:**  

     The report begins with a SUMMARY section followed by a more detailed report which includes much more information.  <span style="text-decoration:underline;">Quickly</span> scroll through the SUMMARY and note the sub-sections devoted to Domain 1 (Completeness), Domain 2 (Internal consistency), Domain 3 (External comparisons) and Domain 4 (Consistency of population data).

23. **Review the detailed report on 1a:  Completeness of facility reporting**:  

     The detailed report begins about 1/3<sup>rd</sup> of the way through the Annual Report.

     ![alt_text](resources/images/dqinfo/image044.png "image_selectou") 




    **Note** that table 1a shows an “Overall score” for each of the core datasets.  This is the nationwide completeness of reporting for the dataset, during 2018.  The column labeled “Percent” shows the percent of districts which had completeness below the threshold. The table identifies the specific districts with apparent problems with data quality. 

    **Question**:  What is the threshold for ANC Reporting rate? How many and what percentage of districts had a completeness below this threshold?

24. **Entrer une donnée dans la case Interprétation :**

    Note the box where interpretations and notes on follow-up actions should be typed. 

    **_LE RAPPORT ANNUEL N'EST FINALISÉ QUE SI LES CASES RÉSERVÉS AUX INTERPRETATIONS ET AUX MESURES DE SUIVI SONT REMPLIES POUR LES SECTIONS CLÉS DU RAPPORT._**

25. **Review the graph of Reporting completeness over time:**  Scroll down to the graph showing “Reporting completeness over time”.  For robust analysis, a dataset should be at least 75% complete.  If the completeness of a dataset changes by more than 5%, then the data should be adjusted before analyzing for a year-to-year trend.

    **Questions**:  1) For which datasets can robust analysis of 2019 data be performed?  2) To assess for trend from 2018 to 2019, should the ANC data be adjusted for a change in completeness?

    ![alt_text](resources/images/dqinfo/image045.png "image_selectou")

26. **Review table 2a: Extreme outliers:** 

    The table shows the Threshold for an extreme outlier - A monthly value that is more than 3 SD (standard deviations) from the mean monthly value for the period being review.  The table cites an “Overall score (%)”.  This is the percentage of reports expected during the year (12 times the number of facilities that are expected to report) for which the value of the indicator was an extreme outlier. The “Number” is the number of districts and the “Percent” is the % of districts which, during 2019, reported an extreme outlier for the indicator.

    ![alt_text](resources/images/dqinfo/image046.png "image_selectou")

27. **Review 2d:  Consistency of indicator values over time**:

    Scroll down to section 2d. This section compares, for the 5 core indicators, the total value reported in 2019 to the average annual total value for preceding years.  For [https://who.dhis2.net/dq](https://who.dhis2.net/dq)<span style="text-decoration:underline;"> </span>, we have data that are at least 50% complete only for 2018 and 2019. So we compare the 2019 value to the 2018 value.  When values of an indicator are consistent from year to year, this is reassuring.  If values jump up and down erratically from year to year it can be a sign of real changes in program performance (e.g. as a result of a stock out).  However, inconsistency from year to year may be a sign of a data quality problem. 

    **Examen du nuage de points montrant la cohérence des visites de CPN 1 au fil du temps** :

    Each dot represents the data from one district.  The position of the dot on the vertical axis is the number of 1<sup>st</sup> ANC visits reported by the district in 2019.  Notice from the small graph in the lower left corner that there has been a nationwide increase in reporting of ANC 1<sup>st</sup> visits (mostly due to an increase in completeness of reporting).  Hence, we don’t expect the 2019 value to be equal to the 2018 value.  The “Overall score” of 125% indicates that the 2019 nationwide total value of ANC 1 was 125% of the value for the preceding year. The difference between the 2018 value and the 2019 value is also reflected in the slope of the black line which represents the national relationship (e.g. when the black line crosses 60,000 on the horizontal axis, it is at roughly 67,000 on the vertical axis).  The grey lines show +/- 15% from the national ratio.  The dots that fall outside of the grey lines have a different shape because they have suspicious values.  For example, District C reported 19,988 ANC 1<sup>st</sup> visits in 2018 but the value increased to 32,522 in 2019.  This increase is significantly more than the nationwide increase.  This suspicious value should be investigated.  Notice that District C is included in the box listing districts with “divergent scores”.


    ![alt_text](resources/images/dqinfo/image047.png "image_selectou")


    **Interpret your findings-**

    Ask yourself whether there have been any sub-national changes in program operations (e.g. stock outs, new interventions) or reporting completeness or changes to administrative boundaries (i.e. splitting of districts) which affected the districts with divergent scores.   

    **Consider changing the threshold for assessment of consistency over time**

    For some indicators, you may wish to change the threshold to identify a larger or smaller number of units with inconsistencies over time.  For example, as an <span style="text-decoration:underline;">optional exercise</span>, perhaps you want to focus only on the districts with the most extreme inconsistency over time.  Click on “More” in the menu at the top of the DQ Tool, then “Administration” then “Numerator quality parameters” then scroll down to “Indicator parameters” and use the control arrows to raise the consistency threshold to +/- 33%.

    **Click on the “Save changes” button**. Return to the Annual Report (set up as previously – with Period set to compare to the same number of years and with district dis-aggregations), again scroll down to section 2d (about 60% of the way through the Annual Report).  Note the new Quality threshold in the table on the left.  Note how the grey lines of the chart are now spread further apart and more of the dots now fall between the grey lines.  

    **Question:**  How many districts now have divergent scores? 

    ![alt_text](resources/images/dqinfo/image048.png "image_selectou")


    **Review the scatterplot showing consistency over time of DPT 3**

    Scroll down and find the table and chart for this indicator.  Note how the dots are more scattered than for ANC 1.  Ordinarily, we would not expect for DPT 3 values to be so unpredictable.  However, as shown by the graph in the lower right corner, reporting of EPI data has risen dramatically.  With data that are less 70% complete we should not expect consistency from year to year even in indicators such at immunizations and ANC visits which normally should be quite stable.

    ![alt_text](resources/images/dqinfo/image049.png "image_selectou")


    **In summary**, there are many reasons that data may not be consistent from year to year.  However, when we find consistency-over-time, it is reassuring that the data are of better quality.

28. **Review 2e:  Consistency between related indicators**

    Scroll down to section 2e.  The graphs in this section are the same as those which appear on the “Consistency-data” dashboard.  The only difference is that the period is the last calendar year (i.e. 2019) rather than the last 12 months or whichever other 12-month period you selected from the dashboard menu.  The Annual Report provides you with an opportunity to explain your findings and summarize your follow-up actions.  For example, what will you do to supervise and support the districts which have negative DPT dropout rates?

29. **Utilisez l'Outil pour effectuer des comparaisons externes (section 3.a)**

    “Domain 3” of a data quality desk review involves comparison of estimates based upon routine data with estimates obtained from other sources.  In particular, routine data are used to estimate coverage with maternal and infant health services: antenatal care, institutional delivery, postnatal care and immunization.  These “routine estimates” of coverage can be compared with estimates obtained from surveys of representative samples of households:  Demographic and Health Surveys (DHS), Multiple Indicator Cluster Survey (MICS), immunization coverage surveys and other. 

    Such survey estimates are sometimes considered the “gold standard” for assessing the reliability of routine data.  However, it is important to keep in mind that **discrepancies between routine estimates and survey estimates may be due to several factors other than problems with the reliability and completeness of routine data**:

    a. <span style="text-decoration:underline;"> Autres raisons pour lesquelles l'estimation basée sur des données de routine peut ne pas être fiable </span> :
    1. Le dénominateur (c'est-à-dire l'objectif) ne peut être ni surestimé ni sous-estimé ;
    2. Une personne peut vivre dans un district et avoir recours à des services de santé dans un autre district ;
    3. Person may obtain health services from private providers who do not report.  For example, antenatal care and delivery services may be provided by private midwives.

    b. <span style="text-decoration:underline;"> Raisons pour lesquelles les estimations d'enquêtes peuvent ne pas être fiables </span> :
    1. Sampling error – too small a sample for precise estimation.  Even with the largest of samples, it is seldom practical to estimate at district level.
    2. Échantillonnage non aléatoire - ce problème s'est posé pour les enquêtes réalisées avec l'ancienne méthode du PEV de l'OMS.
    3. Non-sampling error –e.g. recall bias.  This is a special problem where a home-based record is not available and immunization status is assessed based on recall of the care provider. 

     **Review Section 3a of the Annual Report**– 

     >**Note:** Before the Tool can generate findings for section 3a, several steps must be completed. 

    Ces étapes sont évoquées à l'annexe 1 :

     1. New DHIS2 data elements must be configured for the survey estimates and the survey estimate data must be imported.  This data is typically disaggregated by region.
     2. The Denominators and the External comparisons pages of the Tool must be configured.  

    Scroll down to Section 3a to see how some coverage estimates based upon routine data compare to survey estimates.  In the example, notice that the findings are now disaggregated by region rather than by district.  Notice that the “Routine” estimates of coverage are each reasonably close to the “Survey” estimates. The match will seldom be this good.  However, even in this example the match is not perfect.  The routine estimates are consistently less than the survey estimates. The “Overall score” is 92.2%, meaning that the routine estimate at national level is 92.2% of the survey estimate at national level.  Can you think of any reasons that the routine estimates would be lower?  One reason is that, as we have seen, the completeness of reporting of ANC data is only about 92%.  We shall see when we examine Domain 4 whether over-estimation of the denominator may be another reason.

     ![alt_text](resources/images/dqinfo/image050.png "image_selectou")

    In our example, the match is poor for the DPT 3 coverage.  The reason, over course, is the low completeness of the EPI data set.

    ![alt_text](resources/images/dqinfo/image051.png "image_selectou")

    As shown by the figure below, the match is considerably better if we use as the numerator the data on Penta 3<sup>rd</sup> doses that is reported on the HMIS form rather than the data on DPT 3 that is reported on the EPI form.  Again, we note some tendency for the routine estimate to be slightly lower than the survey estimate.

    ![alt_text](resources/images/dqinfo/image052.png "image_selectou")

30. **Use the Tool to assess denominators (Section 4a)**– 

    Note:  before the Tool can generate findings for section 4a, a couple of steps must be completed.  Both of these steps are discussed in Annex 1:



    1. A new indicator or data element must be configured for the UN estimate of live births[^13].


    2. The denominator relations page of the Tool must be properly configured.  

    “Domain 4” of a data quality desk review assesses the denominators used by DHIS2.  Here we discuss findings related to section 4a which compares the official estimate of the live births to the U.N. estimate of live births.  


    ![alt_text](resources/images/dqinfo/image053.png "image_selectou")


    Here, with our example, we have identified one more reason why the estimates of coverage based on routine data (and based on the official estimates of pregnancies, live births or population &lt; 1 year) are somewhat lower than the survey estimates – if we believe the U.N. estimate, the official estimate of live births may be too high.  If we used the U.N. estimate as the denominator, then the routine coverage estimate would be higher.


# Exercise 3: Use the Tool to prepare an Annual Data Quality Report { #exercise-3-use-the-tool-to-prepare-an-annual-data-quality-report } 

31. **Générer un rapport annuel sur l'examen de la qualité des données pour l'année 2019**

    a. Click on Annual Report.  Set Data to Core.  Set Period to 2019.  Set Preceding years for reference to as many preceding years as you have a core data set that is at least 50% complete. Set Disaggregation to the equivalent of district. Click Generate.

    b. Review the following sections of the detailed report.  For each of these sections, in the box for Interpretations, type your interpretation and summarize your follow-up actions:

    1. 1.a (complétude des rapports)
    2. Examinez et interprétez <span style="text-decoration:underline;"> le graphique </span> affiché à la fin de la section de 1.d (cohérence de la complétude de l'ensemble de données au fil du temps)
    3. 2.a (valeurs atypiques extrêmes)
    4. 2d (consistency of indicator values over time).  Comment on at least the following two indicators:

        I. 1 <sup>ères</sup> visites CPN

        ii. 3<sup>èmes</sup> doses de DTC

    5. 2e (consistency between related indicators).  Comment on at least the DPT 1 to DPT 3 dropout rate

# Annex 1:  How to configure Denominators, Denominator relations and External data comparisons { #annex-1-how-to-configure-denominators-denominator-relations-and-external-data-comparisons } 

Before the Tool can generate findings for section 3a (external data comparisons) and 4a (consistency of denominator estimates) of the Annual Report the Tool must be configured properly.  Configuration of Tool numerators is discussed in a separate document.  This Annex explains how to configure Denominators, Denominator relations and External data comparisons.


 1. **New DHIS2 data elements must be configured for the survey  estimates and the survey estimate data must be imported**.  This data is typically disaggregated by region.  These data elements can be assigned to a new data element group with an appropriate name such as “External data”

 2. **A new data element or indicator must be configured for the UN estimate of live births**.[^14] One approach would be to define a new indicator which calculated the live births by multiplying the official estimate of the total population times the U.N. estimate of the crude birth rate (available from [https://data.worldbank.org/indicator](https://data.worldbank.org/indicator) ) divided by 1,000.  This assumes that the official estimate of the total population is reliable.  This new indicator can be assigned to an appropriate indicator group (either an existing group or a new one such as “Population estimates”. The other approach would be to create a new data element then for the UN estimate of live births then use the Data Entry screen to enter the value for each year.  Only a single nationwide value is needed for each year – no disaggregation is required. This new data element can be assigned to the same new data element group that you created for the survey estimates.

 3. **Configurer les dénominateurs utilisés par l'Outil**– Cliquez sur Plus, ensuite sur Administration, puis sur Dénominateurs.

     ![alt_text](resources/images/dqinfo/image054.png "image_selectou")

    There are no denominators set up by default.  The ones you see in the example above had to be added one-at-a-time by clicking on the Add button.  A window will appear for configuring the denominator (see figure to the right). Notice that a special data element group has been configured for “Population estimates”.  This includes the data element “Expected pregnant women”.  Data for this data element have been imported as part of the standard configuration of DHIS2 denominators.  Notice that “Lowest available level” has been set to “Region”.  This is because reliable DHS survey estimates are not available below the level of region.  Even if you configure other outputs of the Tool to disaggregate findings by district, the external comparison findings will only be disaggregated by region.

    ![alt_text](resources/images/dqinfo/image055.png "image_selectou")

     Make sure that you add to this the following denominators:

    a) Expected pregnancies, 

    b) Live births; 

    c) Population &lt; 1; and 

    d) le nouvel indicateur ou élément de données que vous avez créé pour l'estimation des naissances vivantes de l'ONU.


    4.**Configure the Tool to make external comparisons** – Click on “More” then “Administration” then “External data comparison”.

     ![alt_text](resources/images/dqinfo/image056.png "image_selectou")

    There are no default settings.  The ones shown above had to be added one at a time by clicking on the Add button. A window will appear for configuring the comparison (see figure to the right).  The DHS coverage estimates and the UN population estimates have been imported as part of the newly configured “External data”  data set.  These same data elements have also been assigned to a newly configured “External data” data element group.  You see in the exmaple that this data element group has been selected, then “ANC 1 coverage (DHS 2014)” can be selected from the drop-down menu.


    ![alt_text](resources/images/dqinfo/image057.png "image_selectou")


     The “Routine data numerator” must be selected from the list of numerators that have already been configured for the Tool.  The “Routine data denominator” must be selected from the list of denominators already configured for the tool.  Notice that the Survey level has been set to “Region”.


       ![alt_text](resources/images/dqinfo/image058.png "image_selectou")

     5.**Configure Denominator relations**– When you click on More-Administration –Denominator relations, you should find that the table has one default row labeled “Total population – census to UN projection.

    ![alt_text](resources/images/dqinfo/image059.png "image_selectou")

    To configure this relation, click on Edit. Edit the Name to read “Live births – official to UN estimate”.  Leave Type set to “UN population projection”.  Click on the down arrows to the left of Denominator A and Denominator B to select from the list. The list is limited to the denominators which you configured in step 3 above.  For Denominator A, choose the official estimate of live births (or the best available equivalent).  For Denominator B, choose the UN estimate of live births.  Save your configuration.

       ![alt_text](resources/images/dqinfo/image060.png "image_selectou")

       ![alt_text](resources/images/dqinfo/image061.png "image_selectou")







 <!-- Les notes de bas de page se trouvent en bas. -->
## Remarques { #notes }

[^1]:

     Avec la période définie de cette façon, l'affichage devrait correspondre aux captures d'écran présentées dans ce guide.

[^2]:
     The Outliers dashboard is usually more sensitive and more specific for identifying erroneous values.  Also, as we will soon see, the Outliers dashboard permits “drilling down” to identify the specific health facility and month that was responsible for each suspicious value.  The outliers tool would tell us that the suspicious rise in ANC 1 in January 2020 is an extreme outlier.  We could drill down to learn that this extreme outlier is to an erroneous value reported by 1 health facility in district F.  This extreme outlier is also responsible for the dot for district F that falls below the light blue line of the chart on the right above.  The dot falls below the blue line because the average for value from May 2019 to March 2020 is raised by the extreme outlier for January 2020.

[^3]:

     Pour plus d'informations sur la configuration de l'Outil, voir la section "Comment configurer l'outil de qualité des données de l'OMS".

[^4]:

     Les "doses de DPT-HepB-Hib 3 administrées < 1 an" sont rapportées avec l'ensemble de données du PEV tandis que les "doses de Penta 3 administrées" sont rapportées avec l'ensemble de données SNIS.

[^5]:

     The Z-score measures how different an outlier is compared to the “standard deviation” (variation or fluctuation) seen in the monthly values.  Extreme outliers based on standard Z-scores are more than 3 standard deviations from the average value for the same health facility over the previous 12 months (i.e. Z > 3.0).

[^6]:
     The standard Z-score method relies on the mean and standard deviation of values over the previous 12 months. This is problematic, because the mean and standard deviation are highly affected by outliers. Another drawback of the standard Z-score method is that it behaves strangely when there are values for only a few months – in fact, the standard Z-score method will almost never detect an outlier if values are missing for several months. The modified Z-score method does not suffer from these limitations. It uses the median (half of values are above the median and half of values are below the median) as a substitute for the mean and it uses the median absolute deviation (median difference between each value and the sample median) as a substitute for the standard deviation.  As a result, the modified Z-scores are not as affected by one or two extreme outliers.  The few extreme values therefore stand out better and have higher modified Z scores.  The Tool classifies an outlier as extreme if it has a modified Z-score greater than 5. 

[^7]:

     [Des instructions sur la configuration de la messagerie DHIS2 seront fournies.]

[^8]:

     Leave “Compare organization units” set to “Overall result” in order to assess a ratio such as ANC1/IPT1.  This is equivalent to setting numerator relations on the DQ Tool dashboard to “Equal across orgunits”.  With this setting, the slope of the reference line will show the ratio of the indicators at national level and this slope will be roughly equal to the slope of the dots representing the ratio for each individual district or region.  Hence, “equal across orgunits” means that the slope at national level is equal to the average slope at sub-national level.

[^9]:

     It is simpler if the data element is part of a data element group or the indicator is part of an indicator group.  However, as an alternative, you can also select one or more data elements from any data set.

[^10]:
     Pour sélectionner un « Groupe d'unités d'organisation » (par exemple, pour sélectionner « Hôpitaux »), vous devez d'abord supprimer toute sélection par défaut de « Niveau d'unité d'organisation »

[^11]:

     Note to the facilitator – some possible steps to take:


    1. Conduct further desk review.  For example, use DHIS2 to compare the suspicious value with the value for related data elements (e.g. OPV 3, DPT 1) for the same facility and same month;
    2. Utilisez DHIS2 pour envoyer un message à la personne responsable des données »
    3. Si vous êtes au niveau du district, vous pouvez consulter le formulaire papier ;
    4. Contactez le responsable de l'établissement sanitaire et demandez lui de vérifier le formulaire papier ;
    5. Si vous en avez l'autorisation, modifiez la valeur.

[^12]:

     Unfortunately, with [https://who.-demos.dhis2.org/dq](https://who.-demos.dhis2.org/dq) , the reporting rates of all data sets are below 50% prior to 2017.  Data from years with such incomplete reporting should not be used to assess year-to-year consistency.

[^13]:

     L'annexe 1 explique pourquoi il est plus important de comparer les estimations des naissances vivantes que les estimations de la population totale.

[^14]:

     Note to the editors:  With the current version of the Tool, section 4a is entitled “Consistency with UN population projection – Ratio of population projection from the Bureau of Statistics to a UN projection”.  This wording is hard coded into the Tool, so it cannot be re-configured.  This wording suggests that 4a is comparing the official estimate of total population to the UN estimate of total population.  This differs from the Excel-based version of the DQR tool which compares the official estimate of live births to the UN estimate of live births. Estimates of live births are more useful to compare for several reasons:  a) Estimates of live births are more likely to differ due to the challenge of estimating the crude birth rate; b) Estimated live births (and the closely related estimates of pregnancies and population < 1) are the denominators used for calculating coverage with maternal and infant services.  As such coverage may approach 100%, it is essential to estimate these denominators with considerable precision.  This issue has been discussed with the developers of the DHIS2-based Tool, who plan to modify accordingly the title of section 4a.

