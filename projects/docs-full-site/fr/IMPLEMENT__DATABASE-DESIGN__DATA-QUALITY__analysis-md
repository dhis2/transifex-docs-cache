---
edit_url: "https://github.com/dhis2/dhis2-docs-implementation/blob/data-quality-toolkit/content/database_design/data-quality-03-analysis.md"
revision_date: '2023-10-22'
tags:
- Implémentation
---

# Évaluation de la qualité des données { #assessing-data-quality }

DHIS2 dispose d'une large gamme de fonctions pour l'évaluation de la qualité des données, disponibles dans différentes applications et fonctions. Cette section en donne un aperçu. Elle est structurée selon trois types de mesures de la qualité des données :

* Complétude et ponctualité des données
* Cohérence des données entre variables associées
* Cohérence des données au fil du temps

## Complétude et ponctualité{ #completeness-and-timeliness }

***La complétude*** des rapports renseigne sur la proportion des données attendues qui ont été effectivement rapportées. Dans DHIS2, la plupart des contrôles de complétude sont basés sur l'évaluation de la complétude des _ensembles de données_, c'est-à-dire le nombre d'ensembles de données (formulaires) qui ont été soumis par unité d'organisation et par période. Pour déterminer si les données ont été transmises dans les délais, le système utilise un paramètre appelé "Jours après la fin de la période pour une transmission des données dans les délais".

La fonctionnalité intégrée pour la complétude et la ponctualité des données dans DHIS2, par exemple ce qui est intégré dans les applications Visualiseur de données, Rapports et Cartes, se réfère aux *taux de déclaration des ensembles de données*. Cependant, nous pouvons également configurer DHIS2 pour évaluer la proportion d'établissements qui _produisent régulièrement des rapports_, ainsi que *la complétude des éléments de données individuels*.

### Complétude et ponctualité des ensembles de données { #data-set-completeness-and-timeliness }

Les rapports de complétude montreront également les unités d'organisation d'une zone qui déclarent leurs données à temps, ainsi que le pourcentage d'établissements qui déclarent leurs données dans les délais et dans une zone donnée.

La complétude et la ponctualité des données peuvent être examinées dans l'application Rapports ainsi que dans les applications de visualisation de base (Visualiseur de données et Cartes). Les applications de visualisation de base vous permettent d'examiner la complétude et la ponctualité des données de manière plus détaillée à travers plusieurs unités d'organisation et périodes. Cependant, l'application Rapports offre une expérience utilisateur simplifiée qui a été validée par son utilisation très répandue par rapport à d'autres applications de DHIS2.

#### Utilisation de l'application Rapports { #using-the-reports-app }

Afin de vérifier la complétude et la ponctualité des données dans l'application Rapports, accédez à Applications -> Rapports.

![](resources/images/dq_image67.png)

À partir de là, sélectionnez "Obtenir un rapport" sous l'en-tête Récapitulatif du Taux de Déclaration.

![](resources/images/dq_image42.png)

Commencez par la sélection de vos entrées :

1. Les unités d'organisation que vous voulez examiner. Lorsque vous sélectionnez l'unité d'organisation racine, toutes ses unités filles seront également sélectionnées (ainsi que le résultat global de l'unité d'organisation sélectionnée).

2. Sélectionnez l’ensemble de données dont vous voulez examiner la complétude et la ponctualité des informations.

3. Sélection de la période de déclaration, suivie de la période elle-même/

![](resources/images/dq_image96.png)

Si vous sélectionnez Afficher plus d'options, vous pouvez utiliser un ensemble de groupes d'unités d'organisation pour sélectionner des groupes d'unités d'organisation afin de filtrer davantage votre rapport ; cependant, cela est facultatif.

![](resources/images/dq_image111.png)

Après avoir sélectionné toutes vos entrées, sélectionnez "Obtenir un rapport" pour produire le rapport.

![](resources/images/dq_image13.png)

Cela produira un rapport avec les colonnes suivantes

1. Nom : le nom de l'unité d'organisation

2. [Nom de l'ensemble de données] - Rapports produits : il s'agit du nombre de rapports marqués comme terminés au cours de la période que vous avez sélectionnée.

3. [Nom de l'ensemble de données] - Rapports attendus : il s'agit du nombre de rapports attendus au cours de la période que vous avez sélectionnée. Ce nombre est automatiquement calculé en fonction de la dimension temporelle et de l'affectation de l'ensemble de données aux unités d'organisation.

4. [Nom de l'ensemble de données] - Taux de déclaration : Il s'agit du taux de déclaration : rapports produits/rapports attendus x 100 %

5. [Nom de l'ensemble de données] - Rapports produits à temps : il s'agit du nombre de rapports au cours de la période que vous avez sélectionnée qui ont été marqués comme terminés **_dans l'intervalle de temps défini comme "à temps" pour l'ensemble de données sélectionné_**

6. [Nom de l'ensemble de données] - Taux de déclaration à temps : Ce taux = rapports produits + rapports à temps / rapports attendus x 100 %

#### Utilisation de Visualiseur de données { #using-data-visualizer }

Dans Visualiseur de données, vous pourrez examiner les mesures de complétude et de ponctualité des ensembles de données de la même manière que dans l'application Rapports. Mais ici, vous pouvez sélectionner plusieurs ensembles de données, périodes et unités d'organisation à la fois. Vous pouvez également ajouter des mesures de complétude et de ponctualité aux graphiques et aux tableaux qui incluent d'autres données, telles que les données relatives à la fourniture de services de santé, afin de vérifier que les données que vous examinez reflètent la situation dans le pays avec lequel vous travaillez. Cette application vous offre plus de flexibilité que l'application "Rapports" ; cependant, les options supplémentaires peuvent la rendre moins accessible que l'application "Rapports". En principe, ces visualisations sont préparées à l'avance et placées sur un tableau de bord que les utilisateurs peuvent consulter régulièrement. Toutefois, certains utilisateurs doivent savoir créer des sorties à l'aide de ces mesures dans Visualiseur de données.

Dans Visualiseur de données, sélectionnez "Données" comme entrée, et "Ensemble de données" comme type de données. Cela vous permettra de rechercher ou d'ajouter des filtres pour l'ensemble de données et le type de mesure que vous voulez ajouter à votre visualisation.

![](resources/images/dq_image94.png)

Voici un exemple de graphique qui compare les doses de BCG administrées avec le taux de déclaration de l'ensemble de données de vaccination.

![](resources/images/dq_image52.png)

Nous pouvons tout de suite constater que plusieurs districts ont des taux de déclaration < 80 % et que, par conséquent, les données affichées peuvent ne pas refléter entièrement la situation du pays. Il peut s'avérer important de vérifier cela au moyen d’une analyse plus détaillée où sont examinés les établissements qui attribuent cette valeur et/ou en utilisant la complétude des éléments de données.

Nous pouvons passer en revue quelques exemples de tableaux et de graphiques que vous pourriez créer lors de l'examen de la complétude et de la ponctualité dans l'application Visualisation de données.

##### Exemple 1 : Tableau croisé dynamique comparant la complétude et la ponctualité sur plusieurs ensembles de données, périodes et unités d'organisation { #example-1-pivot-table-comparing-completeness-and-timeliness-over-several-datasets-periods-and-organisation-units }

Sélectionnez "Tableau croisé dynamique" comme type de sortie

![](resources/images/dq_image115.png)


* Sélectionnez "Données" et définissez le type de données sur "Ensembles de données"
* Sélectionnez les mesures que vous voulez ajouter à votre tableau

![](resources/images/dq_image14.png)

Masquez ou actualisez le sélecteur de données et procédez à la modification de vos périodes et unités d'organisation.

![](resources/images/dq_image62.png)

![](resources/images/dq_image76.png)

Après avoir effectué toutes vos sélections, modifiez la présentation de votre tableau et mettez ce dernier à jour

![](resources/images/dq_image107.png)

Le tableau devrait maintenant s'afficher avec les entrées que vous avez sélectionnées.

![](resources/images/dq_image57.png)


##### Exemple 2 : Graphique linéaire comparant la complétude et la ponctualité sur plusieurs périodes { #example-2-line-chart-comparing-completeness-and-timeliness-over-several-periods }

Sélectionnez "Linéaire" comme type de sortie

![](resources/images/dq_image19.png)

* Sélectionnez "Données" et modifiez le type de données en "Ensembles de données"
* Sélectionnez les mesures que vous voulez ajouter à votre graphique. Une seule est sélectionnée ici mais vous pouvez en utiliser autant que nécessaire.

![](resources/images/dq_image84.png)

* Masquez ou actualisez le sélecteur de données et procédez à la modification de vos périodes et unités d'organisation.

![](resources/images/dq_image62.png)
![](resources/images/dq_image76.png)

* Modifiez la présentation de votre graphique et mettez-le à jour lorsque vous avez terminé.

![](resources/images/dq_image1.png)

##### Exemple 3 : Un graphique à 2 axes comparant les données de service avec la complétude de l'ensemble de données { #example-3-a-2-axes-chart-comparing-service-data-with-dataset-completeness }

Sélectionnez "Colonne" comme type de sortie

![](resources/images/dq_image35.png)

* Sélectionnez "Données" et définissez le type de données sur "Ensembles de données". Sélectionnez la ou les mesure(s) que vous voulez ajouter à votre graphique

![](resources/images/dq_image84.png)

* Changez le type de données. Les éléments de données sont utilisés dans cet exemple, mais vous pouvez combiner la mesure de la complétude et de la ponctualité avec n'importe quel type de données DHIS2 existants dans le Visualiseur de données.

![](resources/images/dq_image114.png)


* Masquez ou actualisez le sélecteur de données et procédez à la modification de vos périodes et unités d'organisation.

![](resources/images/dq_image40.png)
![](resources/images/dq_image76.png)

* Modifiez la présentation de votre graphique et mettez-le à jour lorsque vous avez terminé.

![](resources/images/dq_image17.png)

* Pour déplacer l'un des éléments vers le 2nd axe, sélectionnez Options, puis Série. Modifiez les éléments de données pour qu'ils apparaissent sur les axes souhaités en utilisant le type de visualisation approprié et mettez à jour votre graphique.

![](resources/images/dq_image82.png)

![](resources/images/dq_image36.png)


* Des options supplémentaires, telles que le classement des éléments du graphique et l'ajout de titres aux graphiques, peuvent ensuite être ajoutées au graphique à l'aide du bouton Options dans l'application Visualiseur de données.

![](resources/images/dq_image27.png)
![](resources/images/dq_image109.png)
![](resources/images/dq_image52.png)

#### Configuration de la complétude de l'ensemble de données { #configuring-data-set-completeness }

La complétude de l'Ensemble de Données est basée sur l'affectation de votre ensemble de données aux unités d'organisation. Cela détermine la valeur de vos rapports attendus, en fonction de la périodicité de l'ensemble de données. La configuration se fait dans l'application Maintenance.

Accédez à Maintenance -> Ensemble de données -> et sélectionnez ou créez l'ensemble de données souhaité. Dans cet ensemble de données, défilez vers le bas pour trouver l'unité ou les unités d'organisation d'affectation.


![](resources/images/dq_image99.png)

Vous pouvez affecter votre ensemble de données à des unités d'organisation en les sélectionnant individuellement ou en utilisant des niveaux ou des groupes.

Ce qui compte ici, c'est de s'assurer que l'ensemble de données **_NE SOIT PAS_** affecté à des unités d'organisation qui ne sont pas censées produire des rapports sur cet ensemble de données. Dans le cas contraire, le nombre de rapports attendus sera systématiquement erroné. Par exemple, dans la capture d'écran ci-dessus, cet ensemble de données est affecté à 185 unités d'organisation. Supposons que cet ensemble de données fasse l'objet d'un rapport mensuel. Chaque mois, 185 rapports sont attendus. Si seules 160 unités d'organisation produisent des rapports sur cet ensemble de données, votre taux de complétude ne dépassera jamais 160/185 x 100 % = 86 % par mois. Cela est dû au fait que les 25 autres unités d'organisation ne produiront pas de rapports sur cet ensemble de données, car elles ne sont pas sensées le faire. C'est un aspect important à prendre en considération afin de garantir une affectation correcte des ensembles de données aux unités d'organisation.


#### Configuration de la ponctualité des ensembles de données { #configuring-data-set-timeliness }

La ponctualité est également configurée dans l'application Maintenance lors de la création ou de la modification d'un ensemble de données. pour ce faire, utilisez le champ "Jours après la période pour une transmission des données dans les délais".

![](resources/images/dq_image43.png)

Dans l'exemple ci-dessus, l'ensemble de données est collecté mensuellement et la ponctualité est fixée à 15. Cela signifie que l'ensemble de données doit être terminé dans les 15 jours suivant la fin du mois précédent pour que sa soumission soit dans les délais.


### Complétude des éléments de données { #data-element-completeness }

La complétude et la ponctualité des ensembles de données sont des mesures permettant de surveiller la performance globale du système en matière de déclaration des données. Cependant, plusieurs conditions doivent être remplies pour que la complétude d'un ensemble de données donne une indication qui reflète la complétude des données au sein de cet ensemble de données :


* Les utilisateurs doivent marquer l'ensemble de données comme "terminé" après que les données soient saisies.

* Les utilisateurs doivent effectivement saisir les données dans le formulaire avant de les marquer comme terminés

* L'affectation des ensembles de données aux unités d'organisation (établissements) doit être correcte.

Souvent, une ou plusieurs de ces conditions ne sont _pas_ remplies, ce qui signifie qu'il faut également procéder à une analyse supplémentaire de la complétude du rapport. Dans cette section, nous montrons

* Comment analyser la proportion d'établissements qui _produisent régulièrement des rapports_ sur les valeurs des éléments de données au cours d'une période de temps donnée, et

* Comment analyser la complétude d'un élément de données individuel

Le point commun des approches décrites est qu'elles nous obligent à configurer des métadonnées supplémentaires pour chaque variable que nous voulons évaluer. En pratique, cela signifie qu’elles ne s'appliquent qu'à un ensemble limité d’éléments de données. La section Implémentation traite du sujet plus en détail.

#### Rapports réguliers des unités d'organisation { #orgunits-consistently-reporting }

L'évaluation de la proportion d'établissements qui _produisent régulièrement des rapports_ au cours d'une période de temps donnée est une mesure de la complétude qui ajoute une nouvelle dimension à notre compréhension de la complétude des données par rapport à la complétude des ensembles de données. Lorsqu'un sous-ensemble d'établissements ne déclare leurs données que par intermittence, il est important de connaître le pourcentage d'établissements de santé qui _produisent régulièrement des rapports_ au cours d'une période de temps donnée, par exemple sur une année. Par exemple, si au cours d'un mois, un dispensaire déclare ses données et qu'un hôpital de district ne le fait pas, et que le mois suivant, c'est l'inverse, les chiffres concernant la complétude resteront constants, mais les données sur la prestation de services seront probablement très différentes au sein de ce district.

Nous avons défini les établissements qui produisent régulièrement des rapports comme suit : 100 X (établissements qui produisent des rapports pour chaque période au cours d'une période de temps donnée)/(établissements qui produisent des rapports pour une période donnée au cours d'une période de temps donnée)

Cette vérification pourrait en principe être effectuée sur la base du rapport général de l'ensemble de données ou sur la base d'un élément de données au sein de l'ensemble de données. Dans l'exemple fourni ici, nous montrons comment procéder, car l'évaluation au niveau de l'ensemble de données pourrait être réalisée en examinant le taux de déclaration annuel des ensembles de données pour chaque établissement.


#### Configuration de la cohérence des rapports { #configuring-reporting-consistency }

Nous montrerons comment créer un indicateur pour le _pourcentage d'unités d'organisation (établissements) qui produisent régulièrement des rapports_ pour un élément de données particulier. Il n’est pas possible de le calculer directement comme indicateur, nous utiliserons donc des prédicteurs.

Cela signifie que nous allons configurer :

Éléments de données :

* Etablissements produisant des rapports pour toutes les périodes au cours de la période de temps
* Etablissements produisant des rapports pour une période donnée au cours de la période temps

Prédicteurs :

* Etablissements produisant des rapports pour toutes les périodes au cours de la période de temps
* Etablissements produisant des rapports pour une période donnée au cours de la période temps

Indicateur :

* Etablissements produisant régulièrement des rapports sur l'élément de données au cours de la période de temps (%), par exemple "CPN 1 - établissements produisant régulièrement des rapports au cours des 12 derniers mois (%)

De plus, des visualisations doivent être crées et partagées avec les utilisateurs, et nous suggérons d'organiser les métadonnées en groupes, et si possible les éléments de données en ensembles de données. L'appartenance de ces groupes à des groupes dédiés à la qualité des données ou à des groupes existants pour chaque programme de santé (ou les deux) dépend des normes de configuration et des PON en vigueur pour une implémentation particulière. Pour plus de clarté, l'[instance de démonstration](demos.dhis2.org/hmis) où un exemple de cette configuration peut être examiné utilise des groupes dédiés.

Dans ce qui suit, nous utiliserons comme exemple la CPN 1 (c’est-à-dire les femmes enceintes effectuant leur première visite de soins prénatals).


#### Création d'éléments de données { #creating-data-elements }

Les éléments de données sont nécessaires pour contenir les données agrégées générées par les deux prédicteurs qui effectuent les calculs pour cet indicateur. Les éléments de données doivent être nommés conformément à la convention d'appellation en vigueur dans la localité, être dans le domaine des données agrégées et (dans la plupart des cas) avoir une valeur de type Positive ou Entier (zéro inclus).

![](resources/images/dq_image43.png)

Pour La CPN 1, nous pourrions créer ces deux éléments de données :

* DQ - CPN 1 ayant fait l'objet d'un rapport par les unités d'organisation pour chacun des 12 derniers mois
* DQ - CPN 1 ayant fait l'objet d'un rapport par les unités d'organisation pour un des 12 derniers mois


#### Création de prédicteurs { #creating-predictors }

Ensuite, nous devons configurer deux prédicteurs pour le calcul des données pour nos deux éléments de données. La documentation sur les prédicteurs est disponible [ici](#manage-predictors)

1. Donnez un nom (obligatoire), un nom court, un code et une description au prédicteur

   ![](resources/images/dq_image95.png)

2. Spécifiez l'élément de données de sortie ; il doit se rapporter aux éléments de données que nous avons créés à l'étape précédente

   ![](resources/images/dq_image72.png)

3. Spécifiez le type de période du prédicteur ; il doit correspondre au type de période de l’élément de données que nous évaluons. Dans cet exemple, nous évaluons la CPN 1, que nous supposons être collecté mensuellement.

    ![](resources/images/dq_image70.png)

4. Spécifiez le niveau de l'unité d'organisation. Pour cet indicateur de la qualité des données, il doit s'agir du niveau où les données sont collectées, généralement au niveau de l'établissement. \
Nous devons également effectuer une sélection dans "Unités d'organisation fournissant des données", qui doit être "Au(x) niveau(x) sélectionné(s) uniquement", puisque nous calculons la cohérence des rapports uniquement sur la base du niveau que nous avons sélectionné comme niveau de collecte des données.

    ![](resources/images/dq_image23.png)

5. Ensuite, nous devons spécifier le Générateur. C'est ici que nous allons définir l'expression utilisée pour calculer la cohérence des rapports.

    ![](resources/images/dq_image49.png)

    1. Pour calculer le prédicteur de "nombre d'unités organisations ayant produit des rapports pour _chacun_ des 12 derniers mois", nous utilisons la formule "si( somme( si(n'estPasNul([élément de données]), 1, 0)) == 12, 1, 0)"
        1. **si**(**n'estPasNul(**[élément de données]**), 1, 0)**, et produit un 1 si une valeur existe, et un 0 sinon
        2. **somme**( si(n'estPasNul([élément de données]), 1, 0)** )** additionne le nombre de périodes pour lesquelles l'instruction si(n'estPasNul()) renvoie 1. Il ajoute donc 1 pour chaque période au cours de laquelle une valeur a été déclarée.
        3. **si**( somme(si(n'estPasNul([élément de données]), 1, 0))** == 12, 1, 0) **vérifie si le nombre de périodes additionnées par 'somme()' est égal au nombre de périodes que nous évaluons. Si nous évaluons un ensemble de données qui nécessite un rapport chaque mois, pour une période d'un an, nous le comparons à 12. Si le nombre de périodes avec une valeur correspond à 12, le prédicteur produit un 1, ce qui indique que l'unité d'organisation a produit des rapports au cours des 12 mois précédents.


        ![](resources/images/dq_image80.png)


    2. Pour calculer le prédicteur de "nombre d'unités d'organisation déclaré des données pour _un_ des 12 derniers mois", nous utilisons la formule "si(n'estPasNul([éléments de données]),1,0) »
        4. **si**(**n'estPasNul(**[élément de données]**), 1, 0)**, et produit un 1 si une valeur existe pour l'une des périodes, et un 0 sinon. 1 indique que l'unité d'organisation a déclaré des données pour _au moins un _des 12 mois précédents.

       ![](resources/images/dq_image45.png)


6. Enfin, nous devons spécifier le nombre d'échantillons et de sauts (skip). Le test de saut d'échantillon ne doit pas être activé. Le nombre d'échantillons séquentiels doit correspondre au nombre de périodes pour lesquelles nous voulons calculer la cohérence des rapports. Pour les données mensuelles que nous voulons évaluer pendant un an, nous devons fixer le nombre d'échantillons séquentiels à 12. Cela signifie que les 12 mois précédant la période pour laquelle nous générons le prédicteur seront examinés. \
Le nombre d'échantillons annuels et le nombre d'échantillons séquentiels doivent tous deux être égaux à 0.

   ![](resources/images/dq_image77.png)

#### Création de l'indicateur { #creating-the-indicator }

Lorsque les deux éléments de données et les deux prédicteurs ont été définis, nous pouvons définir l'indicateur qui produit la mesure de la qualité des données qui nous intéresse : le pourcentage d'établissements qui ont régulièrement produit des rapports sur un élément de données spécifique au cours de la dernière année.


1. Le nom de l’indicateur, le nom court, le code et la description doivent être spécifiés conformément aux conventions locales d'appellation et de codage.

![](resources/images/dq_image53.png)


2. L'indicateur ne doit** pas** être annualisé et le type d'indicateur doit être Pourcentage (facteur = 100)

3. L'expression du numérateur doit être Établissements ayant produit des rapports pour tous les 12 mois précédents (en partant du principe que les données sont mensuelles).

4. L'expression du dénominateur doit être : Établissements ayant produit des rapports pour un des 12 mois précédents (en partant du principe que que les données sont mensuelles).

![](resources/images/dq_image28.png)
![](resources/images/dq_image54.png)

Après la génération des prédicteurs et la réalisation des analyses générales ([voir ci-dessous](#programmation), l'indicateur peut être utilisé dans les applications Visualiseur de données et Cartes.

#### Calcul de la complétude des éléments de données { #calculating-data-element-completeness }

Dans certaines implémentations de DHIS2, il a été observé que les rapports sur tous les éléments de données au sein d'un ensemble de données n'étaient pas cohérents. Par défaut, DHIS2 n'évalue que les taux de déclaration des ensembles de données et non des éléments de données individuels de cet ensemble. L'objectif du taux de déclaration d'un élément de données est d'évaluer la cohérence de la déclaration d'une valeur unique. Ceci ne concerne que les éléments de données agrégés.

Le calcul du taux de déclaration se décline comme suit : 100 x (Nombre de valeurs reçues / Nombre de valeurs attendues)

Pour calculer le taux de déclaration d'un élément de données, nous devons définir un indicateur avec un numérateur (nombre de valeurs reçues), un dénominateur (nombre de valeurs attendues) et un facteur de 100 (type d'indicateur de pourcentage). Alors que le numérateur est toujours le nombre de données, il existe différentes options pour définir le dénominateur, et le choix de l'option appropriée doit se faire en fonction de la situation locale.

La configuration de la complétude des éléments de données dans DHIS2 dépend également de la version de DHIS2 : pour définir le numérateur et le dénominateur, l'on utilise souvent les prédicteurs comme étape intermédiaire dans le calcul, en particulier dans les versions 2.37 et inférieures. Notez que les prédicteurs devront être programmés pour s'exécuter sur le serveur. Consultez la [section finale](#programmation) pour obtenir des instructions à ce sujet.

#### Configuration du numérateur - valeurs reçues { #configuring-the-numerator-values-received }

Revoyons d'abord comment définir le _numérateur_ de notre indicateur de complétude d'éléments de données. Comme expliqué ci-dessus, il s'agit toujours du nombre de données qui ont été déclarées pour un élément de données spécifique. Certains paramètres doivent toutefois être pris en compte.

**Stockage des valeurs nulles**

Pour plusieurs raisons, il est généralement recommandé de _ne pas_ enregistrer les valeurs nulles rapportées pour les éléments de données, à moins qu'il n'y ait une raison claire à cela (par exemple, avec un "type d'agrégation" pour lequel les valeurs nulles sont pertinentes, comme avec la moyenne). Cela a des implications sur l'examen de la complétude des éléments de données, puisqu'avec les éléments de données pour lesquels les valeurs nulles ne sont pas saisies et enregistrées, nous ne pouvons pas faire la différence entre les établissements qui n'ont rien à déclarer et ceux qui ne l'ont pas fait. Une option consiste à activer l'enregistrement des valeurs nulles pour les éléments de données pour lesquels vous voulez définir des indicateurs de complétude d'éléments de données. Toutefois, cette option est difficile à appliquer dans la pratique, car les utilisateurs chargés de la saisie des données doivent savoir pour quels champs spécifiques un 0 est attendu. Une option plus pratique consiste à axer la configuration de la complétude des éléments de données sur les éléments de données pour lesquels tous ou presque tous les établissements sont censés avoir une valeur > 0 à déclarer, et à indiquer explicitement dans les descriptions de l'indicateur et les visualisations que l'on ne s'attend pas nécessairement à ce que la complétude des éléments de données atteigne les 100 %.

**Désagrégations**

Il est essentiel de prendre en considération toute désagrégation susceptible d'être appliquée à l'élément de données, car cela affecte la configuration des expressions d'indicateurs et l'utilisation ou non de prédicteurs. Par exemple, si un élément de données pour une campagne de vaccination d'enfants comme le BCG est désagrégé par < 1 an et 1+ an, la complétude de l'élément de données doit-elle être basée sur :

* Une combinaison d’options de catégorie spécifique. Par exemple, "déclaré" signifie avoir déclaré des données pour "BCG doses < 1 an".

* Les deux combinaisons d’options de catégorie. Par exemple, "déclaré" signifie avoir déclaré des données pour "BCG doses < 1 an" ou "BCG doses < 1 an".

* L’une ou l’autre des combinaisons d’options de catégorie. Par exemple, "déclaré" signifie avoir déclaré des données pour "BCG doses < 1 an" ou "BCG doses < 1 an".

Le choix dépend de l'élément de données et de la désagrégation. Pour les vaccinations d'enfants, la tranche d'âge ciblée est < 1 an, et il peut arriver qu'il n'y ait pas de données à déclarer pour la tranche d'âge de 1+ an. Il serait donc logique de définir une complétude spécifique pour la tranche d'âge 1+ an. D'autre part, si les "cas confirmés de paludisme" sont désagrégés en < 5 ans et 5+ ans, on peut s'attendre à ce que les établissements disposent de valeurs pour chaque tranche d'âge et il serait logique de considérer ces deux valeurs comme attendues. Dans ce cas, le dénominateur doit être ajusté en conséquence.

La même considération s'applique lorsque les ensembles de données sont désagrégés avec une [combinaison d'options d'attribut] (#à-propos-de-dimensions-de-données-supplémentaires), bien que cela soit moins courant.

Le tableau suivant présente les approches alternatives de configuration du numérateur, en tenant compte du fait que l'élément de données est désagrégé ou non, de la manière d'évaluer la complétude des désagrégations, le cas échéant, et de la possibilité de les configurer directement dans les indicateurs ou d'utiliser d'abord des prédicteurs.

|                                                                                                                           | Version 2.38 et les versions supérieures                                                                            | Version 2.37 et les versions inférieures    |
|------------------------------------------------------------------------------------------------------------------------   |------------------------------------------------------------------------------------------ |----------------   |
| Élément de données sans désagrégation                                                                                       | Indicateur (avec sousExpression)                                                            | Prédicteur         |
| Élément de données avec désagrégation - analyse d'une combinaison d'options de catégorie                                                  | Indicateur (avec sousExpression)                                                            | Prédicteur         |
| Élément de données avec désagrégations - chaque combinaison d'options de catégorie avec une valeur comme est considérée comme "déclarée"                        | Indicateur (avec sousExpression) ; multiplication du dénominateur par le nombre de combinaisons d'options de catégorie  | Prédicteur         |
| Élément de données avec désagrégation - toutes les combinaisons d'options de catégorie doivent avoir une valeur pour que l'élément de données soit considéré comme "déclaré"           | Prédicteur                                                                                 | Prédicteur         |
| Élément de données avec désagrégation : si une combinaison d'options de catégorie a une valeur, l'élément de données est considéré comme "déclaré"    | Prédicteur                                                                                 | Prédicteur         |





Nous allons d'abord expliquer comment configurer les options qui peuvent l'être directement avec les indicateurs, puis nous nous pencherons sur la configuration avec les prédicteurs


#### Configuration du numérateur avec indicateur et sousExpressions { #numerator-configuration-with-indicator-and-subexpressions }

Comme expliqué ci-dessus, le numérateur doit être le nombre de valeurs pour un élément de données (avec ou sans désagrégation). A partir de la version 2.38, la configuration peut être effectuée directement dans un indicateur agrégé en utilisant une sousExpression avec une instruction conditionnelle n'estPasNul dans l'expression. Une valeur 1 sera renvoyée chaque fois qu'un nombre (y compris zéro) est saisi pour cet élément de données. Ci-dessous, un exemple.

![](resources/images/dq_image39.png)

* **si(n'estPasNul(**[Identifiant de l'élément de données]**), 1, 0) ** elle renverra 1 pour chaque valeur de cet élément de données, 0 sinon.
    * Si l'élément de données n'a pas de désagrégation, elle renverra 1 ou 0 selon que les données ont été déclarées.

    * Si l'_identifiant_ spécifié dans n'estPasNul() inclut une combinaison d'options de catégorie spécifique (par exemple n'estPasNul(#{TWWbtMMWD51.JKuWbG5bWAu})), l'expression renverra 1 ou 0 selon que des données ont été déclarées pour cet élément de données et cette combinaison d'options de catégorie spécifiques.

    * Si l'élément de données est désagrégé, mais qu'aucune combinaison d'options de catégorie n'est spécifiée, l'expression renverra 1 _pour chaque donnée dans la combinaison d'options de catégorie_. Ainsi, si un élément de données a une désagrégation > 1 an, 1 + an et qu'un établissement a déclaré une valeur pour les deux désagrégations, l'expression renverra 2. Dans ce cas, le dénominateur doit être ajusté adéquatement.

* **sousExpression** si(n'estPasNul([Identifiant de l'élément de données])** ) **garantit l'exécution de l'instruction si(n'estPasNul()) au niveau de collecte de données, avant que l'expression ne soit agrégée au fil du temps et au sein de la hiérarchie des unités d'organisation.

Pour résumer, ce qu’il faut utiliser comme expression pour le numérateur est :

|                                                                                                       | Méthode                                    | Expression avec exemple d'élément de données                              |
|----------------------------------------------------------------------------------------------------   |-----------------------------------------  |------------------------------------------------------------------ |
| Élément de données sans désagrégation                                                                   | Indicateur                                 | sousExpression( si( n'estPasnul(#{TWWbtMMWD51}), 1, 0))              |
| Élément de données avec désagrégation - analyse d'une combinaison d'options de catégorie                              | Indicateur                                 | sousExpression (si (n'estPasNul (#{TWWbtMMWD51.JKuWbG5bWAu}), 1, 0))  |
| Élément de données avec désagrégations - chaque combinaison d'options de catégorie avec une valeur comme est comptée comme "déclarée"    | Indicateur; le dénominateur doit être ajusté   | sousExpression( si( n'estPasNul(#{TWWbtMMWD51}), 1, 0))              |


#### Configuration du numérateur - avec prédicteur { #numerator-configuration-with-predictor }

Les versions 2.37 et les versions inférieures ne prennent pas en charge les sousExpressions dans les indicateurs. Il vous faudra donc créer un prédicteur qui utilise les instructions conditionnelles n'estPasNul() dans le générateur.

Comme expliqué ci-dessus, le fait que l'élément de données soit désagrégé ou non et la manière de représenter la désagrégation en termes de complétude, dictent exactement la manière dont l'expression du générateur doit être définie. Le tableau suivant présente chacune des approches alternatives et l'expression de générateur à utiliser :


|                                                                                                                           | Expression de générateur avec exemple d'élément de données                                                         |
|------------------------------------------------------------------------------------------------------------------------   |------------------------------------------------------------------------------------------------------ |
| Élément de données sans désagrégation                                                                                       | si( n'estPasNul(#{OWk2WulfJYQ}), 1, 0)                                                                  |
| Élément de données avec désagrégation - analyse d'une combinaison d'options de catégorie                                                  | si( n'estPasNul(#{TWWbtMMWD51.JKuWbG5bWAu}), 1, 0)                                                      |
| Élément de données avec désagrégations - chaque combinaison d'options de catégorie avec une valeur comme est comptée comme "déclarée"                        | si( n'estPasNul(#{TWWbtMMWD51.JKuWbG5bWAu}), 1, 0) + si( n'estPasNul(#{TWWbtMMWD51.UIQxmxgioxH}), 1, 0)  |
| Élément de données avec désagrégation - toutes les combinaisons d'options de catégorie doivent avoir une valeur pour que l'élément de données soit considéré comme "déclaré"           | si( n'estPasNul(#{TWWbtMMWD51.JKuWbG5bWAu}) && n'estPasNul(#{TWWbtMMWD51.UIQxmxgioxH}), 1, 0)          |
| Élément de données avec désagrégation : si une combinaison d'options de catégorie a une valeur, l'élément de données est considéré comme "déclaré"    | si( n'estPasNul(#{OWk2WulfJYQ}), 1, 0)                                                                  |


Après avoir décidé de l'approche à suivre, suivez ces étapes pour créer le prédicteur :


5. Créez votre élément de données de sortie.

6. Attribuez l'élément de données de sortie à votre prédicteur.

7. Définissez le type de période (généralement mensuelle).

8. Attribuez le niveau d'unité d'organisation pour l'analyse (généralement l'établissement).

9. Configurez le générateur comme suit.

10. Réglez le nombre d’échantillons séquentiels sur 0

11. Réglez le nombre d’échantillons annuels sur 0

12. N'inscrivez rien dans le champ consacré au nombre de sauts séquentiels.

13. Définissez le générateur à l'aide de l'une des expressions décrites ci-dessus.

![](resources/images/dq_image8.png)


14. Créez un groupe de prédicteurs et ajoutez ce prédicteur à ce groupe.


#### Configuration du dénominateur - valeurs attendues { #configuring-the-denominator-expected-values }

Bien que le numérateur d’un indicateur sur la complétude des éléments de données corresponde toujours au nombre de données reçues (avec quelques variations dans la gestion des désagrégations), il existe plusieurs façons de définir le dénominateur des "rapports attendus reçus". Ces options sont :


1. Nombre d'unités d'organisation auxquelles le ou les ensembles de données dont l'élément de données fait partie, est (sont) attribué(s)

2. Nombre d'unités d'organisations pour lesquelles le ou les ensembles de données dont fait partie l'élément de données, a ou ont été marqué(s) comme "terminés" (déclarés)

3. Nombre de valeurs d'un autre élément de données déclarées faisant partie du même ensemble de données

4. Nombre d'unités d'organisation ayant déjà produit des rapports sur l'élément de données

![](resources/images/dq_image38.png)

Le choix de ces options dépend de plusieurs facteurs contextuels, tels que le degré d'exactitude et de mise à jour de l'affectation de l'ensemble de données et le fait de savoir si l'objectif est d'examiner la complétude globale de l'élément de données (quelle proportion de la valeur réelle a été saisie) ou la complétude au sein d'un ensemble de données (quel est le degré de complétude du formulaire de rapport rempli par le personnel de l'établissement et les employés chargés de la saisie des données). Chaque option est décrite ci-dessous, avec des instructions pour la configuration dans les versions 2.38 et supérieures, et 2.37 et inférieures.


##### Option 1 – Nombre d'unités d'organisation auxquelles le ou les ensembles de données dont l'élément de données fait partie, est (sont) attribué(s) { #option-1-count-of-orgunits-to-which-the-data-sets-the-data-element-is-part-of-is-assigned }

La première option consiste à utiliser l’affectation de l’ensemble de données dont fait partie l’élément de données comme base de calcul de la complétude. Cette mesure est assez similaire au fonctionnement de la complétude de l'ensemble de données (taux de déclaration) [décrit ci-dessus] (#configuration-de-la-complétude-de-l'élément-de-données). Cette option est facile à configurer, puisque les "rapports attendus" d'un ensemble de données sont disponibles pour être utilisés directement dans les expressions d'indicateurs. La principale contrainte à l'utilisation des rapports attendus pour un ensemble de données comme dénominateur pour la complétude des éléments de données est que l'affectation de l'ensemble de données est supposée correcte et à jour.

Pour utiliser ceci comme dénominateur, choisissez simplement la variable _rapports attendus_ qui est disponible lors de la configuration du dénominateur de l'indicateur :


![](resources/images/dq_image93.png)

L'expression du dénominateur est R{[identifiant de l'élément de données].RAPPORTS_ATTENDUS}, par exemple R{tQc4Gv2Jwco.RAPPORTS_ATTENDUS}

Des précautions particulières doivent être prises dans les cas où le même élément de données est déclaré dans plusieurs ensembles de données. Si les ensembles de données ne sont pas utilisés dans les mêmes unités d'organisation, l'addition des rapports attendus pour chaque ensemble de données donnera un dénominateur correct. Toutefois, s'il est possible que les mêmes unités d'organisation se voient attribuer deux ensembles de données contenant un même élément de données, cette option ne fournira pas de dénominateur fiable.


##### Option 2 – Nombre d'unités d'organisation pour lesquelles le ou les ensembles de données ont été reçus { #option-2-count-of-orgunits-for-which-the-data-sets-has-been-received }

L'option 2 est similaire à l'option 1, à la différence qu'elle utilise les rapports réels comme dénominateur plutôt que les rapports attendus. En choisissant les rapports réels, on obtient un indicateur qui évalue la complétude de l'élément de données parmi les unités d'organisation qui ont déclaré des données, c'est-à-dire une mesure de la fréquence à laquelle un élément de données particulier est alimenté dans les ensembles de données soumis.

![](resources/images/dq_image103.png)

![](resources/images/dq_image71.png)


ici aussi, des précautions particulières doivent être prises dans les cas où le même élément de données est déclaré dans plusieurs ensembles de données. Si les ensembles de données ne sont pas utilisés dans les mêmes unités d'organisation, l'addition des rapports attendus pour chaque ensemble de données donnera un dénominateur correct. Toutefois, s'il est possible que les mêmes unités d'organisation se voient attribuer deux ensembles de données contenant un même élément de données, cette option ne fournira pas de dénominateur fiable.


##### Option 3 – Nombre de valeurs d'un autre élément de données déclarées { #option-3-count-of-reported-values-of-another-data-element }

Cette option repose sur l'utilisation du nombre de valeurs déclarées pour un autre élément de données comme "valeurs attendues" dans le calcul de la complétude. Cet autre élément de données peut être choisi en fonction de différents critères, décrits ci-dessous. Il convient de noter que lorsque l'on examine la complétude d'un élément de données sur la base d'autres éléments de données, les résultats doivent être analysés en même temps que la complétude globale de l'ensemble des données.

_En fonction d'un élément de données dans le même ensemble de données_

Cette option est similaire à la précédente, à la différence qu'elle utilise un élément de données déclaré dans le même ensemble de données ou la même section d'ensemble de données que l'élément de données pour lequel vous calculez le taux de déclaration (numérateur) - sans qu'il y ait nécessairement un lien logique entre eux. Avec cette approche, vous devez choisir un élément de données qui est toujours (ou souvent) déclaré dans le même ensemble de données. Par exemple, dans un ensemble de données sur la santé maternelle, il est probable que le nombre d'établissements de santé qui déclarent un élément de données pour les "premières visites de soins prénatals" soit plus élevé que celui de l'"accouchement assisté", et les "premières visites de soins prénatals" constituent donc une meilleure estimation du nombre de déclarations attendues.

_En fonction d'un indicateur de base_

Si l'élément de données pour lequel vous souhaitez obtenir un taux de déclaration est utilisé dans le calcul d'un indicateur de performance clé avec des données régulièrement déclarées dans le dénominateur, il est recommandé d'utiliser le nombre de valeurs déclarées pour le dénominateur afin de calculer leur complétude. Cette option n'est pas viable si l'élément de données n'est pas utilisé dans le calcul d'un indicateur ou si le dénominateur repose sur une estimation de la population ou une autre valeur qui n'est pas déclarée avec la même périodicité que le numérateur.

À titre d'exemple, considérons l'indicateur Cas suspects de Paludisme testés (%) :

100 x (Paludisme cas testés / Cas suspects)

Dans ce cas, il peut être utile d'examiner la complétude de "Paludisme cas testés" avec le nombre de cas suspects comme dénominateur.

L’avantage de cette option est qu’elle fournit une bonne indication de la complétude/cohérence des données utilisées pour calculer un indicateur de base particulier.

_En fonction d'un élément de données associé_

Cette option est similaire à la précédente, à la différence qu'elle utilise un élément de données étroitement lié à l'élément de données du numérateur pour calculer le dénominateur. Par exemple, si vous voulez obtenir un taux de déclaration pour les cas de paludisme chez les patients hospitalisés de moins de 5 ans (numérateur), vous pouvez envisager d'utiliser en guise de dénominateur le nombre de cas de paludisme chez les patients hospitalisés de 5 ans et plus, de décès dus au paludisme chez les patients hospitalisés, de cas de paludisme chez les patients non hospitalisés ou d'autres éléments similaires.

**Configuration**

Veuillez vous référer à la section qui traite de la configuration du numérateur[LIEN] si vous utilisez un élément de données associé en guise de dénominateur. Les mêmes considérations et étapes de configuration s’appliquent.


##### Option 4 – Nombre d'unités d'organisation ayant déjà produit des rapports sur l'élément de données { #option-4-count-of-orgunits-that-have-previously-reported-on-the-data-element-itself }

La dernière option consiste à utiliser en guise de dénominateur le nombre d'établissements qui ont déjà produit des rapports sur l'élément de données en question dans un délai donné. Ce dénominateur est similaire à celui utilisé pour l'indicateur ["établissements produisant des rapports réguliers"] (#unités-d'organisation-produisant-des rapports-réguliers). Il peut s'agir d'une bonne estimation du nombre de rapports attendus, en particulier dans les cas où l'affectation de l'ensemble des données n'est pas précise : si un établissement a déjà produit un rapport sur un élément de données particulier, cela signifie généralement que l'établissement fournit le service/diagnostic représenté par l'élément de données et que l'on peut s'attendre à ce qu'il produise régulièrement des rapports sur cet élément. Toutefois, les résultats doivent être analysés en même temps que la complétude de l'ensemble des données, car ils n'incluront pas les établissements _censés_ produire des rapports, mais qui ne l'ont pas fait au cours de la période donnée.

Pour calculer le nombre de fois qu'une unité d'organisation a déclaré l'élément de données que vous évaluez au cours de l'un des 12 derniers mois, nous devons utiliser un prédicteur et un élément de données supplémentaire. Il s'agit du même calcul que pour le dénominateur décrit ci-dessus dans la section  [Etablissements produisant des rapports réguliers] (#unités-d'organisation-produisant-des rapports-réguliers). En résumé, un prédicteur disposant d'un générateur 

**si**(**n'estPasNul(**[élément de données]**), 1, 0) **

et d'un nombre d'échantillons séquentiels défini en fonction du nombre de périodes précédentes que vous voulez évaluer produira le nombre à utiliser comme dénominateur.

#### Analyse ad hoc de la complétude de plusieurs éléments de données { #ad-hoc-analysis-of-completeness-for-multiple-data-elements }

Les approches de calcul de la complétude des éléments de données décrites ci-dessus offrent plusieurs possibilités quant à la définition exacte du numérateur et du dénominateur, et nous permettent de générer des indicateurs pouvant être utilisés dans des graphiques, des cartes et des tableaux sur un tableau de bord. Toutefois, étant donné que nous devons ajouter au moins un nouvel objet de métadonnées pour chaque variable que nous voulons évaluer, il est préférable de les configurer pour un sous-ensemble d'éléments de données clés.

Pour mieux comprendre la complétude des éléments de données pour un grand nombre d'éléments de données au sein d'un ensemble de données, nous pouvons produire ceci dans l'application Visualiseur de données sous forme de tableau croisé dynamique ou de graphique en suivant les étapes suivantes :


1. Ouvrez Visualiseur de données et choisissez Tableau croisé dynamique comme type de graphique
2. Comme Dimension de données, choisissez :
    1. Les rapports attendus ou existants pour un ensemble de données particulier
    2. Tout ou partie des éléments de données au sein du même ensemble de données, utilisant l'option "Détails uniquement" pour la désagrégation
3. Modifiez la présentation en plaçant les Périodes sous forme de colonnes (par exemple pour les 12 derniers mois) et les Données sous forme de lignes.


![](resources/images/dq_image56.png)


4. Ouvrez le menu Options et
   1. Activez les Totaux de ligne
   2. Dans la section Avancé, définissez le type d'agrégation sur "Nombre"

5. Mettez à jour la visualisation et triez éventuellement la colonne des totaux de haut en bas (remarque : le total des "rapports attendus" indiquera NaN, mais restera en haut).

![](resources/images/dq_image113.png)


Le tableau obtenu affiche désormais sur la ligne supérieure le "dénominateur" de la complétude des éléments de données, c'est-à-dire les rapports attendus pour l'ensemble de données (les rapports existants peuvent également être utilisés). Les autres lignes affichent le "numérateur" de la complétude des éléments de données pour chaque élément de données (avec désagrégation). Ce tableau vous permet d'examiner rapidement la complétude d'un grand nombre d'éléments de données au sein d'un ensemble de données.

En suivant la même approche (en utilisant le type d'agrégation "Nombre"), si vous examinez une seule période, un graphique à barres trié de haut en bas donnera un aperçu rapide de la complétude des éléments de données.

![](resources/images/dq_image50.png)

## Cohérence de données associées { #consistency-of-related-data }

### Nuages de points dans Visualiseur de données { #scatter-plots-in-data-visualizer }

![](resources/images/dq_image25.png)

Il s'agit d'un nuage de points dans lequel une analyse est effectuée pour les valeurs atypiques ou pour deux variables associées au niveau de l'établissement. Les deux variables sur ce graphique sont liées l'une à l'autre - CPN 1 et CPN 4 - et c'est la raison pour laquelle plusieurs valeurs sont étroitement regroupées en vert.

L'analyse des valeurs atypiques dans Visualiseur de données à l'aide de nuages de points vous permet de savoir si des valeurs associées s'inscrivent dans un modèle attendu ou si elles s'en écartent d'une manière ou d'une autre. Les valeurs en rouge sur le graphique ne correspondent pas au modèle attendu, et plus ces valeurs en rouge sont éloignées des lignes de valeurs atypiques, plus il est probable qu'un problème sous-jacent empêche ces valeurs de correspondre correctement au modèle attendu.

Ces nuages de points peuvent utiliser différentes méthodes pour identifier ces valeurs atypiques, et chacune de ces méthodes a différents niveaux de sensibilité (c'est-à-dire que chacune détectera plus ou moins les valeurs atypiques en fonction de leur calcul). Les différentes méthodes actuellement disponibles sont

* Écart interquartile
* Z-score
* Z-score modifié

Le Z-score a été inclus car il s'agit d'une méthode bien comprise ; cependant, c'est la moins sensible des 3 méthodes.

#### Créer un nuage de points { #create-a-scatter-plot }

Des nuages de points peuvent être créés dans l'application Visualiseur de données.

Démarrez le processus en sélectionnant le nuage de points dans le sélecteur de visualisation dans Visualiseur de données.

![](resources/images/dq_image26.png)

Vérifiez la présentation après avoir sélectionné ce type de graphique. Certains éléments sont verrouillés, ce qui le différencie d'autres graphiques. Vous devez sélectionner des éléments de données pour les axes vertical (Y) et horizontal (X) du graphique. Les points représenteront toujours les unités d'organisation. Comme indiqué, pour ce type de graphique, vous devez sélectionner des éléments de données associés. Si vous sélectionnez des éléments de données non associés, il est peu probable que votre résultat soit pertinent.

Sélectionnez vos données verticales et horizontales. Nous sélectionnerons CPN 1 et CPN 4 car ils sont associés (par exemple, vous verrez généralement moins de CPN 4 que de CPN 1 sur une période identifiée).

![](resources/images/dq_image74.png)
![](resources/images/dq_image100.png)


Sélectionnez votre unité d'organisation (dans ce cas, tous les établissements)

![](resources/images/dq_image31.png)

Sélectionnez votre période

![](resources/images/dq_image83.png)

Mettez à jour votre graphique.

![](resources/images/dq_image5.png)

Vous verrez maintenant le nuage de points entre ces deux éléments liés. Nous pouvons voir à quel point elles sont étroitement regroupées dans le coin inférieur gauche du graphique, car c’est là que se trouvent la majorité des valeurs. Nous n'avons pas encore ajouté nos valeurs atypiques à ce graphique ; nous pouvons le faire comme prochaine étape.


#### Ajouter des valeurs atypiques { #add-outlier-details }

Pour ajouter des valeurs atypiques, sélectionnez les options du graphique et la section "valeurs atypiques"

![](resources/images/dq_image9.png)

Activez à la fois l’analyse des valeurs atypiques et les lignes extrêmes.

Pour l’analyse des valeurs atypiques, nous utiliserons la méthode de l'écart interquartile. Il s'agit d'une méthode de détection des valeurs atypiques qui peut être appliquée aux données de nuages de points. Pour plus d'informations, consultez la référence ci-après : [https://medium.com/analytics-vidhya/outliers-in-data-and-ways-to-detect-them-1c3a5f2c6b1e](https://medium.com/analytics-vidhya/outliers-in-data-and-ways-to-detect-them-1c3a5f2c6b1e)

Vous n’avez pas besoin de comprendre complètement cette méthode de détection de valeurs atypiques. Notez simplement que les 3 méthodes détecterons les valeurs atypiques en vérifiant si elles correspondent à un modèle tel que décrit par les différentes méthodes sélectionnées.

Vous pouvez également sélectionner l’option "Lignes extrêmes". Cela vous aidera à identifier les valeurs atypiques les plus extrêmes, lesquelles contiennent souvent des erreurs.

![](resources/images/dq_image41.png)

Après avoir sélectionné ces options, mettez à jour votre graphique.

![](resources/images/dq_image25.png)

Voyons comment nous pouvons interpréter notre sortie. Tout d’abord, agrandissons l'écran (zoom) sur notre groupe de valeurs pour les examiner de plus près. Nous pouvons le faire en faisant glisser le curseur de notre souris sur la zone que nous voulons agrandir.

![](resources/images/dq_image33.png)

Nous pouvons revenir à l'écran normal si nécessaire en sélectionnant "réinitialiser le zoom".

Examinez l’une des valeurs atypiques mise en évidence en rouge

![](resources/images/dq_image112.png)

Le modèle de ces données est très étroit (c'est-à-dire que la plupart des valeurs sont étroitement regroupées). Cependant, certaines valeurs sont très éloignées des limites des valeurs atypiques. Aucune de ces valeurs ne peut être considérée comme atypique en soi (il existe d'autres valeurs de CPN 1 et de CPN 4 qui sont plus élevées). Cependant, cette paire de valeurs que nous avons mise en évidence sur le graphique ci-dessus se situe en dehors de la fourchette de 1 % du total des valeurs y (qui représente la CPN 1). Cela s'explique par le fait qu'une valeur de CPN 4 typique dans cette fourchette a une valeur de CPN 1 beaucoup plus faible par rapport à la majorité des autres données.

En examinant ce type de graphique, vous devez donc examiner la relation entre les deux éléments comparés et également comparer les valeurs au groupe qui se situe dans les limites du modèle des valeurs atypiques. Dans ce cas, les valeurs de CPN 1 ou de CPN 4 pourraient être incorrectes (si nous diminuons les valeurs de CPN 1 OU si nous augmentons les valeurs de CPN 4, cet établissement s'intégrera probablement dans le modèle en conséquence) ; ou il pourrait simplement s'agir d'une anomalie caractérisée par un ratio différent entre CPN 1 et CPN 4, supérieur au seuil de l'écart interquartile de 1,5 qui a été défini (c'est-à-dire que ces valeurs sont correctes et n'ont pas besoin d'être modifiées). Il est cependant plus probable que la valeur de CPN 1 soit à l'origine du problème, car la majorité des valeurs de CPN 4 dans cette fourchette ont une valeur de CPN 1 inférieure. Cependant, comme il s'agit d'une valeur atypique très élevée par rapport au reste des données (étant donné sa distance par rapport à la limite des valeurs atypiques et le fait qu'elle se situe en dehors de la ligne de 1% des valeurs y), il convient de vérifier si ces valeurs sont correctes au sein de cet établissement.

### Analyse des règles de validation { #validation-rule-analysis }

Les règles de validation sont intégrées dans les applications de saisie de données de DHIS2 et peuvent être consultées pendant la saisie des données [LIEN vers la section ci-dessus]. Les violations des règles de validation peuvent également être visualisées dans la section Analyse des règles de validation de l'application Qualité des données. Au lieu de les examiner pour une unité d'organisation, une période et un ensemble de données spécifiques, vous pouvez les examiner pour un grand nombre d'unités d'organisation sur une période donnée. Cela permet également aux utilisateurs qui ne saisissent pas de données, ou qui n'ont même pas accès à l'application Saisie de données, d'analyser et de contrôler les violations des règles de validation.

Lorsque vous examinez les règles de validation avec cette méthode, il est préférable de diviser vos règles de validation en groupes de règles de validation. La configuration de ces groupes est présentée dans la section consacrée aux groupes de règles de validation.

Pour exécuter l'analyse des règles de validation, ouvrez l'application Qualité des données et sélectionnez "Exécuter la validation"

Applications -> Qualité des données

![](resources/images/dq_image22.png)

Sélectionnez "Exécuter la validation" sous l'en-tête "Analyse des règles de validation"

![](resources/images/dq_image24.png)

À partir de là, vous devrez sélectionner vos entrées. Cela comprend les éléments suivants :

* L'unité d'organisation
* La date de début et la date de fin. Elles définissent la période que vous examinez.
    * Pour la période, les dates de début et de fin doivent couvrir entièrement la période que vous voulez examiner. Si vous voulez consulter des données mensuelles, votre date de début devra être le 1er du mois, et votre date de fin le 1er du mois suivant. Par exemple, sur cette capture d'écran, les données de juin 2023 à août 2023 sont en cours d'examen.
* Le groupe de règles de validation. Il doit contenir les règles de validation que vous voulez examiner
* Envoyer des notifications : cela enverra toutes les notifications de validation en fonction des violations de validation trouvées
* Conserver les nouveaux résultats

![](resources/images/dq_image88.png)

Une fois les données d'entrée sélectionnées, cliquez sur "Valider". L'exécution de l'analyse de validation peut prendre un certain temps en fonction de la quantité de données que vous avez choisi d'examiner. Si vous prévoyez d'examiner beaucoup de données à la fois (par exemple, plusieurs unités d'organisation sur plusieurs périodes, y compris plusieurs règles de validation), l'analyse des règles de validation prendra plus de temps que si vous l'exécutez pour moins de données.

Si aucune violation des règles de validation n'a été détectée, vous verrez un message "Validation réussie". Par contre, si des violations sont détectées, elles seront présentées dans une liste comme suit :

![](resources/images/dq_image66.png)


Pour consulter les détails de la validation, sélectionnez le bouton d'information sous la colonne des détails.

![](resources/images/dq_image61.png)

Une fenêtre contextuelle s'ouvrira avec plus d'informations sur la violation.

![](resources/images/dq_image85.png)

Nous pouvons voir l'importance de l'analyse des règles de validation dans l'examen des violations pour plusieurs unités d'organisation/périodes à la fois, car tous les éléments constitutifs de la violation sont également présentés. Cela peut nous permettre d'identifier exactement quelle valeur est incorrecte et nécessite un suivi plus approfondi.

Les détails de validation affichent le nom et la description de la violation ainsi que tous les éléments de données qui font partie de la règle de validation ainsi que leurs valeurs.

Vous pouvez également télécharger ces violations de règles de validation. Vous pourrez vous y référer et effectuer un suivi des valeurs pour les corriger au fil du temps. Pour ce faire, sélectionnez l'un des types de fichiers dans l'angle supérieur droit après avoir exécuté l'analyse de validation.

![](resources/images/dq_image58.png)



## Cohérence au fil du temps { #consistency-over-time }

[section à venir]


### Graphiques annuels { #year-over-year-charts }

![](resources/images/dq_image12.png)


Il s'agit d'un graphique annuel (linéaire). Ce type de graphique est utilisé pour évaluer la cohérence au fil du temps pour un type de données spécifique (élément de données, indicateur, etc.). Dans cet exemple, nous affichons les données relatives aux visites de CPN 1 pour les 12 mois de l'année pour les années 2023, 2022 et 2021. Ce graphique nous permet d'identifier facilement les valeurs atypiques évidentes, car nous sommes en mesure de voir les augmentations ou les diminutions (si elles existent) assez facilement par rapport aux données actuelles et précédentes. À titre d'exemple, vous pouvez voir des valeurs atypiques évidentes en janvier 2023, mai 2022 et septembre 2023 en examinant chacune des lignes de ce graphique et en les comparant à leurs propres tendances historiques. L'étape suivante consistera à prendre ce graphique et à approfondir la hiérarchie pour ces périodes spécifiques afin de trouver la source de ces valeurs atypiques. Ces graphiques pourraient être placés sur un tableau de bord pour les principales variables de votre flux de travail afin de permettre au personnel de les examiner régulièrement en fonction de la fréquence à laquelle les données sont collectées.

Pour créer cette visualisation, vous utiliserez l'application Visualiseur de données

![](resources/images/dq_image78.png)


Sélectionnez "d'une année sur l'autre" (linéaire) pour commencer à créer ce graphique

![](resources/images/dq_image19.png)

#### L'interface - Sélection des périodes et filtre { #the-interface-period-selection-and-filter }

Après avoir sélectionné ce type de graphique, nous constatons que la catégorie et la série sont automatiquement renseignées avec des types de période. La sélection des périodes dans le menu de gauche, où d'autres dimensions sont sélectionnées, est également grisée. Les unités d'organisation et les données sont automatiquement placées dans le filtre. C'est pourquoi ce type de graphique fonctionne mieux lorsqu'un seul élément de données est sélectionné pour comparaison. Toutefois, plusieurs unités d'organisation peuvent être utilisées dans le filtre en fonction de ce que vous voulez afficher (les données appartenant à ces unités d'organisation seront filtrées).

![](resources/images/dq_image64.png)

#### L'interface - Catégorie { #the-interface-category }

Dans cet exemple, la catégorie détermine les périodes qui seront affichées le long de l'axe des x et regroupera les données. Ainsi, en sélectionnant "mois par an", tous les mois d'une année, de janvier à décembre, seront affichés. Si nous sélectionnons "Trimestres par an", les 4 trimestres d'une année seront affichés le long de l'axe des x.

![](resources/images/dq_image73.png)


Vous remarquerez que les sélections dans les catégories sont toutes des périodes relatives. Vous ne pouvez donc pas sélectionner par exemple des mois spécifiques dans la catégorie dans ce type de graphique.

![](resources/images/dq_image16.png)

#### L'interface - Série { #the-interface-series }

La série détermine les années pour lesquelles vous afficherez les données. Si je sélectionne cette année et l'année dernière, elles seront affichées respectivement en fonction de la date actuelle. Je peux également spécifier des années plutôt qu'une période relative, par exemple 2021, 2022 et 2023.

![](resources/images/dq_image47.png)

Avec ces deux options sélectionnées, je peux maintenant créer un graphique qui affichera les données de janvier à décembre (en raison de la sélection de catégorie) le long de l'axe des x. Et avec 2021, 2022 et 2023 sélectionnés comme série, les données de ces 3 années seront affichées par mois sur le graphique "annuel".

#### L'interface - Données { #the-interface-data }

Lors de la sélection des données, il est préférable de ne sélectionner qu'un seul élément de données. Vous pouvez aussi choisir des groupes ou des désagrégations pour filtrer davantage les données. Cependant, étant donné que les données sélectionnées  sont automatiquement ajoutées au filtre et ne peuvent pas être déplacées, l'ajout de plus d'une donnée n'affectera pas le graphique.

![](resources/images/dq_image74.png)

**Mettre à jour et réviser le graphique**

Nous pouvons maintenant mettre à jour notre graphique. Dans ce cas, nous utilisons l'unité d'organisation du pays par défaut, mais nous pouvons la modifier si nécessaire.

Nous pouvons voir comment le graphique a été généré sur la base de notre sélection de catégorie et de période de série ainsi que de la sélection de notre élément de données (dans ce cas, CPN 1ère visite).

La série détermine les années pour lesquelles nous affichons les données, tandis que la catégorie détermine comment regrouper les données le long de l'axe des x.

![](resources/images/dq_image12.png)

### Valeurs statistiques atypiques dans les séries chronologiques { #statistical-outliers-in-time-series }

Les "valeurs atypiques extrêmes" sont des valeurs très suspectes dont l'exactitude doit être vérifiée. Elles diffèrent des valeurs normalement déclarées par un établissement de santé. Si les valeurs atypiques extrêmes s'avèrent incorrectes, elles doivent être modifiées conformément aux procédures locales qui définissent la manière dont les valeurs des données doivent être modifiées. Dans cette section, nous montrons comment les valeurs atypiques *dans la dimension temporelle* peuvent être identifiées dans DHIS2 à l'aide de [prédicteurs]( #gestion_des-prédicteurs) et de la fonction [analyse des valeurs atypiques]( #détection_des-valeurs-atypiques). Nous précisons *au fil du temps* pour marquer la différence avec les valeurs atypiques décrites dans la section sur les [nuages de points] (#nuages-de-points dans-Visualiseur-de-données), lesquelles identifient les unités d'organisation qui sont des valeurs atypiques pour une seule période.

Les deux fonctions présentées pour identifier les valeurs atypiques présentent chacune certains avantages. L'application *DHIS2 Qualité des données* permet d'effectuer des analyses en masse (c'est-à-dire pour un grand nombre de variables en même temps) sans configuration préalable. Elle permet aux utilisateurs de choisir différentes méthodes statistiques pour le calcul des valeurs atypiques et de les exécuter sur tout ensemble de données et toute combinaison de périodes. Elle est donc à la fois flexible et puissante, mais les utilisateurs doivent ouvrir l'application, choisir les paramètres appropriés et attendre que l'analyse se termine. En utilisant les *prédicteurs* pour calculer les seuils des valeurs atypiques et les éléments de données et indicateurs associés, nous pouvons générer des notifications, consulter ces valeurs sur le tableau de bord ou les utiliser en combinaison avec d'autres fonctionnalités de DHIS2, telles que les règles de validation. Il en résulte une plus grande flexibilité dans la manière de mettre les résultats de l'analyse des valeurs atypiques à la disposition des utilisateurs, mais cela nécessite la configuration de plusieurs objets de métadonnées pour *chaque* variable que nous voulons évaluer. Les deux méthodes doivent donc être considérées comme complémentaires.

#### Analyse des valeurs atypiques avec des prédicteurs et des indicateurs { #outlier-analysis-with-predictors-and-indicators }


> **Note**
>
> Dans le cadre d'une implémentation réelle, les prédicteurs peuvent nécessiter beaucoup de ressources et il convient de prendre des précautions particulières pour tester le système DHIS2 afin de s'assurer qu'il est en mesure de générer des prédicteurs de manière continue et régulière, à mesure que de nouvelles données sont ajoutées, avant l'implémentation réelle. En outre, même après la génération de nouvelles données par le prédicteur, les données ne seront pas visibles tant que le système d'analyse n'aura pas été mis à jour ; il s'agit là d'une autre étape qui peut prendre beaucoup de temps en fonction de la taille du système. Par conséquent, il faudra probablement faire preuve de patience et marquer de longues pauses la première fois que vous suivrez ces instructions. ***Il est important de reproduire et de tester les prédicteurs sur des systèmes de développement en premier lieu, afin qu'ils puissent être testés en profondeur*** ***sans affecter un système de production***.

[Prédicteurs](#gestion-des-prédicteurs) fournit des fonctionnalités génériques dans DHIS2, et nous montrerons comment les appliquer à des fins de détection et d'analyse de valeurs atypiques. Bien que le processus initial de création de prédicteurs puisse prendre du temps, une fois que vous avez configuré avec succès un élément de données/indicateur et confirmé que les sorties résultantes sont correctes, le processus de configuration de chaque élément de données ou indicateur subséquent devrait prendre moins de temps.

La configuration des prédicteurs pour la détection des valeurs atypiques nécessite deux ensembles de prédicteurs :

-   un prédicteur pour calculer le *seuil de valeurs atypiques*. Ceci est défini à partir de l'analyse des données précédemment déclarées et de la définition de seuils au-delà desquels les valeurs sont considérées comme atypiques (pour une combinaison d'éléments de données et d'unités d'organisation).

-   un ou plusieurs prédicteurs qui utilisent le seuil de valeurs atypiques dans d'autres calculs, par exemple dans le comptage du nombre d'établissements qui ont déclaré des valeurs atypiques, dans l'attribution de valeurs atypiques ou non à des éléments de données distincts pour analyse, etc.

Étant donné que les prédicteurs produisent des valeurs de données qui doivent être stockées avant d'être utilisées dans d'autres calculs, chaque nouveau prédicteur doit être associé à un élément de données. Ces éléments de données pourraient être organisés en un ou plusieurs nouveaux ensembles de données.

Il existe plusieurs possibilités concernant les prédicteurs, les éléments de données et les indicateurs qui peuvent être configurés pour chacune des variables que vous voudriez analyser/surveiller :

-   Seuil de valeurs atypiques (prédicteur/élément de données)

-   Nombre de valeurs qui *sont* atypiques (prédicteur/élément de données)

-   Nombre de valeurs qui ne sont *pas* atypiques (prédicteur/élément de données)

-   Valeurs atypiques (%) (indicateur)

-   Valeurs qui *sont* atypiques (prédicteur/élément de données)

-   Valeurs qui ne sont *pas* atypiques (prédicteur/élément de données)

-   Données excluant des valeurs atypiques (indicateur)

Ils sont définis et expliqués plus en détail ci-dessous. Tout d'abord, il est important de comprendre comment se déroule le flux de données pour ces objets de métadonnées, comme le montre la figure ci-dessous.

![](resources/images/dq_outlier_image11.png)

Les prédicteurs doivent être programmés par le système, tout comme le processus *analytique*. La programmation est donc essentielle pour que cela fonctionne. Pour que les indicateurs soient disponibles pour les utilisateurs finaux, nous devons d'abord exécuter le premier ensemble de prédicteurs (calcul des seuils), puis le deuxième ensemble de prédicteurs, et enfin le processus d'analyse normal pour que les ensembles de données et les indicateurs soient disponibles dans Visualiseur de données et d'autres outils d'analyse. Ce point est abordé plus en détail [ici] (#programmation).

##### Prédicteur du seuil de valeurs aberrantes { #predictor-for-outlier-threshold }

Nous commençons par la configuration du prédicteur et de l'élément de données qui calcule le seuil de valeurs atypiques pour une variable particulière, qu'il s'agisse d'un élément de données (par défaut/total) ou d'une désagrégation particulière (combinaison d'options de catégorie). Dans l'exemple suivant, nous utiliserons *Paludisme cas confirmés*.

**Étapes de configuration**

1.  Créez un élément de données pour stocker la valeur du seuil de valeur atypique :

    -   Nom : "DQ - Paludisme seuil de valeurs atypiques des cas confirmés (moyenne + 3 écarts-types)"

    -   Description : "Généré automatiquement à partir du prédicteur. Seuil de valeurs atypiques pour l'élément de données Paludisme cas confirmés (total pour toutes les désagrégations), basé sur la moyenne + 3 écarts-types au cours des 12 mois précédents. Cela peut être utilisé pour identifier les potentielles valeurs atypiques.

    -   Type : Agrégé

    -   Type de valeur : Entier positif ou nul

2.  Créez un nouveau prédicteur avec des propriétés de base :

    -   Nom : "DQ - Paludisme seuil de valeurs atypiques des cas confirmés (moyenne + 3 écarts-types)"

    -   Description : "Génère le seuil de valeurs atypiques pour Paludisme cas confirmés, défini comme la moyenne + 3 écarts-types, sans compter les valeurs du mois dernier."

3.  Définissez l’Élément de données de sortie pour qu’il renvoie à l’élément de données créé à l’étape 1.

4.  Définissez le Type de période pour qu'il corresponde à la fréquence de collecte de données de l'élément de données que nous évaluons. Pour notre exemple Paludisme cas confirmés, la collecte est Mensuelle.

5.  Définissez les Niveaux d'unités d'organisation sur le niveau où les données sont collectées. Dans la plupart des cas, ce sera Établissement.

![](resources/images/dq_outlier_image10.png)

6.  Configurez le *Générateur*, qui est l'expression qui définit le calcul effectué par le prédicteur.

    -   Définissez la Stratégie de valeurs manquantes sur Ignorer si toutes les valeurs sont manquantes.

    -   L'expression dans ce cas devrait être :

*avg({élément_de données_uid}) + (3 \* stddevPop({élément_de données_uid}))*

*avg()* nous donne la moyenne de l'élément de données au cours des périodes que nous évaluons (définies à l'étape suivante). *stddevPop()* nous donne l'écart-type basé sur la population pour l'élément de données au cours des périodes que nous évaluons, et nous le multiplions par 3 puisque nous voulons que les seuils soient de 3 écarts-types au-dessus de la moyenne. Nous utilisons 3 ici parce qu'il est souvent utilisé comme définition des valeurs atypiques extrêmes, mais d'autres valeurs peuvent être utilisées.

![](resources/images/dq_outlier_image9.png)

7.  Enfin, définissez le Nombre d'échantillons séquentiels. Ceci définit le nombre de périodes de données antérieures à inclure dans le calcul. Dans ce cas, les données sont mensuelles (définies à l'étape 4), et nous voulons utiliser 1 an de données antérieures pour calculer le seuil. Nous fixons donc cette valeur à 12. Le nombre d'échantillons annuels et le nombre de sauts séquentiels doivent être 0 (valeur par défaut).

![](resources/images/dq_outlier_image3.png)

##### Prédicteurs pour les mesures de valeurs atypiques { #predictors-for-outlier-metrics }

Lorsque le seuil de valeurs atypiques est défini et stocké en tant que valeur d'élément de données, nous pouvons créer des prédicteurs supplémentaires pour effectuer des calculs plus spécifiques. Ces prédicteurs sont configurés de la même manière, à l'exception de l'expression du générateur. Nous décrivons les étapes générales de la création des prédicteurs une fois, tandis que l'expression réelle pour chacun des prédicteurs spécifiques est fournie dans le tableau ci-dessous.

Nous verrons comment créer quatre prédicteurs/éléments de données différents à l'aide du seuil de valeurs atypiques :

  ---------------------------------------------------------------------------------------
  Élément de données excluant les valeurs atypiques  Valeurs d'éléments de données qui ne sont pas atypiques
  --------------------------------- -----------------------------------------------------
  Valeurs atypiques d'éléments de données Valeurs d'éléments de données qui *sont* atypiques.

  Nombre de valeurs non atypiques d'éléments de données Nombre de valeurs d'éléments de données qui ne sont pas atypiques.

  Nombre de valeurs atypiques d’éléments de données Nombre de valeurs d’éléments de données qui sont atypiques.
  -------------------------------------------------- ----------------------------------------------------

L'exemple suivant (avec CPN 1ère visite comme élément de données que nous évaluons) montre pour une série chronologique quel résultat les différents prédicteurs sont censés produire

| | **Jan** | **Fév** | **Mar** | **Avr** | **Mai** | **juin** | **Juillet** |
| :-- | :-- | :-- | :-- | :-- | :-- | :-- | :-- | 
| CPN 1 | 165 | 196 | 214 | 204 | 219 | 4243 | 195 | 
| CPN 1 seuil de valeurs atypiques | 253 | 265 | 253 | 244 | 242 | 246 | 4716 | 
| CPN 1 excluant les valeurs atypiques | 165 | 196 | 214 | 204 | 219 | | 195 | 
| CPN 1 valeurs atypiques | | | | | | 4243 | | 
| CPN 1 nombre de valeurs non atypiques | 1 | 1 | 1 | 1 | 1 | | 1 | 
| CPN 1 nombre de valeurs atypiques | | | | | | 1 | | 

Pour configurer ces prédicteurs, suivez ces étapes générales après avoir créé des éléments de données auxquels les valeurs peuvent être attribuées :

1.  Créez un nouveau prédicteur

2.  Définissez l'Élément de données de sortie pour qu'il renvoie à l'élément de données qui a été créé.

3.  Définissez le Type de période pour qu'il corresponde à la fréquence de collecte de données de l'élément de données que nous évaluons.

4.  Définissez les Niveaux d'unités d'organisation sur le niveau où les données sont collectées. Dans la plupart des cas, ce sera Établissement.

5.  Configurez le *Générateur*, en utilisant l'expression appropriée du tableau ci-dessous

6.  Définissez le Nombre d'échantillons séquentiels sur **1**, le Nombre d'échantillons annuels sur 0 et le Nombre de sauts séquentiels sur 0.

Ce tableau fournit les expressions qui doivent être utilisées dans le Générateur des différents prédicteurs :


| Prédicteur | Expression | Exemple | Explication |
| :-- | :-- | :-- | :-- | 
| Élément de données excluant les valeurs atypiques | si ({DE} <= {DE seuil}, {DE}, 0) | si(#{KV1LlPytf4f}<=#{dx8Y0ZrHji7}, #{KV1LlPytf4f}, 0) | Si la valeur de l'élément de données est inférieure au seuil, utilisez la valeur de l'élément de données, sinon 0. | 
| Valeurs atypiques d'éléments de données | si( {DE} > {DE seuil}, {DE}, 0) | si(#{KV1LlPytf4f} > #{dx8Y0ZrHji7}, #{KV1LlPytf4f}, 0) | Si la valeur de l'élément de données est supérieure au seuil, utilisez la valeur de l'élément de données, sinon 0. | 
| Nombre de valeurs non-atypiques d'éléments de données | si ({DE} <= {DE seuil}, 1, 0) | si(#{KV1LlPytf4f}<=#{dx8Y0ZrHji7}, 1, 0) | Si la valeur de l'élément de données est inférieure au seuil, renvoyez 1, sinon 0. | 
| Nombre de valeurs atypiques d'éléments de données | si ({DE} > {DE seuil }, 1, 0) | si(#{KV1LlPytf4f}>#{dx8Y0ZrHji7}, 1, 0) | Si la valeur de l'élément de données est supérieure au seuil, renvoyez 1, sinon 0. | 


Les éléments de données alimentés par ces prédicteurs peuvent être utilisés directement dans les visualisations et les tableaux de bord, par exemple en comparant les valeurs déclarées au seuil, en affichant un compteur du nombre de valeurs atypiques signalées au cours du mois précédent ou en générant des tableaux qui mettent en évidence les valeurs atypiques spécifiques par établissement.

![](resources/images/dq_outlier_image4.png)

##### Indicateurs pour l'analyse des valeurs atypiques{ #indicators-for-outlier-analysis }

Lorsque les prédicteurs et les éléments de données sont configurés pour la mesure de la qualité de ces éléments de données de base présents ci-dessus, nous pouvons définir deux indicateurs :

**Pourcentage de valeurs atypiques** pour un élément de données particulier :

Numérateur : nombre de valeurs atypiques

Dénominateur : nombre de valeurs atypiques + nombre de valeurs non atypiques

Facteur : 100

Objectif : mesure de la qualité des données ; peut être utilisé pour examiner des comparaisons géographiques ou des changements au fil du temps

**Valeur excluant les valeurs atypiques en pourcentage de la valeur globale** pour un élément de données particulier.

Numérateur : les valeurs de l'élément de données qui ne sont pas atypiques

Dénominateur : toutes les valeurs de l'élément de données

Facteur : 100

Objectif : mesure de l'*importance* des valeurs atypiques sur la valeur globale d'un élément de données. Elle peut être utilisée à la fois pour les tendances temporelles et les comparaisons géographiques. Elle montre également l'importance des valeurs atypiques sur les données en général, ce qui est un aspect à prendre en compte lors de l'analyse des données.

La configuration de ces indicateurs est simple une fois que les prédicteurs/éléments de données sous-jacents sont disponibles (les options a et b ci-dessous font référence à chacun des indicateurs ci-dessus)

1.  Créez un nouvel indicateur avec un nom et une description appropriés. La description est importante ici car ces indicateurs peuvent être nouveaux pour la plupart des utilisateurs.

2.  Définissez le type d'indicateur sur Pourcentage (le nom exact peut varier, mais le facteur du type d'indicateur doit être 100)

3.  Configurez le numérateur

    a. Nombre de valeurs atypiques (exemple : Paludisme nombre de valeurs atypiques pour les cas confirmés)

    b. Valeurs excluant les valeurs atypiques (exemple : Paludisme cas confirmés excluant les valeurs atypiques)

4.  Configurez le dénominateur

    a. Nombre de valeurs atypiques + nombre de valeurs non atypiques (exemple : Paludisme nombre de valeurs atypiques pour les cas confirmés + Paludisme nombre de valeurs non atypiques pour les cas confirmés)

    b. Valeurs des éléments de données (exemple : Paludisme cas confirmés)

5.  Sauvegardez l'indicateur et attribuez-le aux groupes appropriés

Ces indicateurs peuvent désormais être utilisés dans des visualisations et des tableaux de bord. Les utilisateurs peuvent ainsi surveiller facilement les tendances des valeurs atypiques, effectuer des comparaisons géographiques et  surveiller l'impact global des valeurs atypiques sur l'élément de données en question.

#### Analyse des valeurs atypiques dans DHIS2 { #dhis2-outlier-analysis }

Il n’est pas réaliste de configurer un ensemble de prédicteurs, d’éléments de données et d’indicateurs pour chaque élément de données. L'analyse des valeurs atypiques dans l'application Qualité des Données permet d'exécuter une analyse des valeurs atypiques sur des ensembles de données et constitue donc un complément utile aux contrôles des valeurs atypiques sur la base des prédicteurs.

Pour exécuter une analyse des valeurs atypiques, ouvrez l'application Qualité des Données et cliquez sur "Analyser" situé sous "Détection des valeurs atypiques".

![](resources/images/dq_outlier_image6.png)

Commencez par sélectionner les paramètres clés pour l’analyse :

-   Ensemble de données : choisissez un ou plusieurs ensembles de données à inclure dans l'analyse.

-   Unités d'organisation : choisissez une ou plusieurs unités d'organisation à inclure dans l'analyse. Toutes les unités d'organisation situées en dessous des unités sélectionnées seront incluses.

-   Dates de début et de fin - les périodes comprises dans cette fourchette de dates seront incluses. Notez que ce sont les périodes que nous analysons pour détecter les données atypiques. Les données de *toutes* les périodes pour une unité d'organisation et un élément de données particuliers sont incluses dans le calcul de la moyenne et de l'écart-type, sauf indication contraire (voir les options avancées ci-dessous).

![](resources/images/dq_outlier_image5.png)

Ensuite, spécifiez les méthodes et paramètres statistiques à utiliser pour l’analyse.

-   Algorithme :

    -   Z-score - détection des valeurs atypiques sur la base des écarts types par rapport à la moyenne. Pour plus d'informations [[sur le z-score]{.ul}], visitez cette page (https://en.wikipedia.org/wiki/Standard_score).

    -   Z-score modifié - détection des valeurs atypiques sur la base des écarts types par rapport à la médiane.

    -   Min-max - basées sur les valeurs minimum et maximum, abordées [ici](#review-min-max-values-in-the-data-quality-app)

-   Seuil - le nombre d'écarts types qu'une valeur doit avoir par rapport à la moyenne/médiane avant qu'elle soit considérée comme atypique. La valeur par défaut est 3, qui est souvent utilisée comme définition par défaut d'une valeur atypique "extrême".

-   Max results - le nombre maximum de valeurs atypiques qui seront incluses dans le tableau des résultats.

![](resources/images/dq_outlier_image2.png)

À titre facultatif, modifiez les options avancées :

-   Dates de début et de fin des données : elles vous permettent de limiter les données utilisées comme base pour calculer la moyenne/médiane et les écarts types, en remplaçant les options par défaut qui elles incluent toutes les données. A noter qu'un certain nombre de périodes sont nécessaires pour que les calculs statistiques soient significatifs.

-   Trier par – spécifie comment les résultats sont triés, avec deux options

    -   Écart absolu par rapport à la médiane/moyenne (par défaut) - ceci permet de trier le tableau des valeurs atypiques en fonction de l'écart absolu entre la valeur atypique et la médiane/moyenne. En général, cela signifie que les valeurs atypiques les plus significatives/ayant le plus d'impact sur le résultat sont affichées en premier.

    -   Z-score/Z-score modifié - cette fonction trie le tableau en fonction du z-score, c'est-à-dire du " caractère extrême " de la valeur atypique. Cela signifie qu'une valeur relativement faible (provenant d'un petit établissement) peut être affichée avant une valeur beaucoup plus importante (provenant d'un grand établissement), si la valeur la plus faible est plus éloignée de la moyenne/ médiane.

![](resources/images/dq_outlier_image8.png)

Enfin, cliquez sur "Démarrer" pour exécuter l'analyse. En fonction des paramètres sélectionnés et de la taille de la base de données, cela peut prendre un certain temps. Le tableau de résultats répertorie toutes les valeurs atypiques qui ont été détectées (jusqu'aux résultats maximaux autorisés), avec des informations sur :

-   Élément de données

-   Période

-   Unité d'organisation

-   Valeur - la valeur qui a été identifiée comme étant atypique

-   Z-score - le z-score de la valeur atypique

-   Déviation - la déviation de la valeur atypique, c'est-à-dire la différence entre la moyenne/médiane et la valeur réelle

-   Std Dev (écart-type) - la valeur d'un écart type.

-   Médiane/moyenne - valeur médiane/moyenne, selon la méthode utilisée

-   Min et Max - valeurs minimales et maximales de l'élément de données, basées sur le nombre d'écarts types défini dans la section des paramètres.

-   Suivi - case à cocher qui permet de marquer les valeurs pour le suivi, ce qui signifie qu'elles peuvent être listées à l'aide de la fonction "Analyse de suivi" de l'application Qualité des données.

![](resources/images/dq_outlier_image1.png)



## Outil de Qualité des Données de l'OMS { #who-data-quality-tool }

L'Outil de qualité des données de l'OMS est une application disponible dans [DHIS2 App Hub] (https://apps.dhis2.org/), qui prend en charge un ensemble de fonctionnalités d'analyse de la qualité des données basées sur le cadre d'Examen de la qualité des données de l'OMS. Lors de sa sortie en 2016, la plupart des fonctionnalités d'analyse de la qualité des données n'étaient pas disponibles dans les applications de DHIS2 Central. Mais la situation a changé au fil des années. Désormais, la plupart des analyses peuvent être effectuées dans DHIS2 Central. D'ici un à deux ans, l'application de Qualité des données de l'OMS ne sera plus mise à jour pour les nouvelles versions de DHIS2. Une nouvelle application moderne est en cours de développement pour combler les lacunes de fonctionnalité restantes, notamment en ce qui concerne la génération automatique des rapports annuels sur la qualité des données.

Le tableau ci-dessous donne un aperçu des fonctionnalités disponibles dans l'Outil de qualité des données de l'OMS et dans DHIS2 Central (à partir de la version 2.38).

| Fonctionnalité d'analyse                                | Outil de qualité de données de l'OMS                     | Applications de DHIS2 Central   |
|----------------------------------------------------   |-----------------------------------------  |-----------------  |
| Complétude et ponctualité des ensembles de données              | Pris en charge                                 | Pris en charge         |
| Complétude et ponctualité des éléments de données          | Prise en charge limitée (dans le rapport annuel uniquement)   | Pris en charge         |
| Analyse des règles de validation                              | Pas pris en charge                             | Pris en charge         |
| Analyse des valeurs atypiques minimales et maximales                              | Pas pris en charge                             | Pris en charge         |
| Cohérence des données associées à l'aide de nuages de points        | Pris en charge                                 | Pris en charge         |
| Analyse des taux d'abandon négatifs                    | Pris en charge                                 | Pris en charge         |
| Graphiques annuels                                 | Pris en charge                                 | Pris en charge         |
| Analyse des valeurs atypiques (séries chronologiques)                        | Pris en charge                                 | Pris en charge         |
| Cohérence au fil du temps à l'aide de nuages de points              | Pris en charge                                 | Pas pris en charge     |
| Génération automatique du rapport annuel sur la qualité des données    | Pris en charge                                 | Pas pris en charge     |

Un [manuel d'utilisation] dédié (https://docs.dhis2.org/en/use/optional-apps/who-data-quality-tool/installation-and-configuration.html#how-to-configure-the-dhis2 -based-who-data-quality-tool) ainsi qu'un [package de formation](https://www.who.int/publications/i/item/9789240036475) sont disponibles pour l'Outil de qualité des données de l'OMS. Ses fonctionnalités ne sont donc pas abordées dans ce guide.

