---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.41/src/user/scheduling.md"
revision_date: '2024-05-27'
tags:
- DHIS Version 2.41
- Utilisation
---

# Programmation { #scheduling }

Le Programmateur est une application qui permet de gérer les tâches d'arrière-plan dans DHIS2. Les tâches d'arrière-plan peuvent effectuer certaines fonctions, telles que l'exécution d'analyses, la synchronisation de données et de métadonnées, ou l'envoi d'un rapport d'analyse "push". L'application permet de créer, de modifier et de supprimer de telles tâches.

Les tâches peuvent être programmées pour être exécutées dans un ordre spécifique à l'aide d'une file d'attente. Une file d'attente de tâches se compose de deux tâches ou plus et peut être programmée selon un calendrier de type cron. À l'heure spécifiée, la file d'attente démarre la première tâche et attend qu'elle soit terminée avant de lancer la seconde. Les tâches sont exécutées dans l'ordre jusqu'à ce qu'elles le soient toutes.

Le Programmateur est fourni avec DHIS2 et est accessible depuis le menu des applications.

![La page de démarrage de l'application Programmateur](resources/images/scheduler/overview.png)

La page d'accueil de l'application Programmateur présente un aperçu des tâches existantes. Par défaut, les tâches prédéfinies du système sont masquées. Pour les afficher, cliquez sur _Inclure les tâches du système dans la liste_ dans l'angle supérieur droit.

Lorsque vous créez ou modifiez une tâche ou une file d'attente, elle sera programmée selon le calendrier sélectionné. Pour exécuter une tâche ou une file d'attente à la demande, accédez à l'aperçu, cliquez sur le bouton "Actions" de la tâche ou de la file d'attente que vous voulez exécuter puis sur "Exécuter manuellement". Cette action n'est disponible que pour les tâches et les files d'attente activées.

## Créer une tâche { #scheduling_create_job }

1.  Ouvrez l'application **Programmateur** et cliquez sur le bouton "Nouvelle tâche" dans l'angle supérieur
    droit.

1.  Choisissez un **Nom** approprié pour la nouvelle tâche.

1.  Sélectionnez le **Type de tâche** que vous voulez programmer depuis le menu déroulant.

1.  Sélectionnez un calendrier pour la tâche. Chaque type de tâche a son propre type de planification,
    soit la planification **Cron**, soit la planification**Delay**.

    1.  Pour les types de tâches planifiées **Cron**, vous pouvez définir un calendrier à l'aide de la syntaxe
        [Programmation du printemps](https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/scheduling/support/CronSequenceGenerator.html)
        Vous pouvez également sélectionner une **expression Cron** prédéfinie en cliquant sur
        "Choisir parmi les horaires prédéfinis". Avec cette planification, l'exécution d'une nouvelle tâche ne commence que 
        si l'exécution de la tâche précédente est terminée, ceci afin d'empêcher le système de reproduire
        trop de tâches.

    1.  Pour les tâches planifiées **Delay**, vous pouvez définir un délai en secondes. Contrairement aux
        tâches planifiées **Cron**, ces tâches ne sont pas exécutées en fonction d'un calendrier
        défini, mais avec un délai spécifique entre les exécutions des tâches. Le temporisateur
        démarre à la fin d'une tâche, ce qui démarre l'exécution d'une nouvelle tâche lorsque le temporisateur
        atteint zéro. Cela continuera tant que la tâche sera activée.

1.  Si le type de tâche est personnalisable, une section **Paramètres** apparaîtra sous 
    les paramètres de planification. Ces options supplémentaires précisent les informations de la
    tâche planifiée et vont varier en fonction du type de tâche.

1.  Cliquez sur le bouton **Sauvegarder** pour confirmer la création de la tâche. Après la création de la tâche, 
    vous serez redirigé vers l'aperçu des tâches, où la nouvelle 
    tâche créée sera désormais répertoriée.

![Création d'une nouvelle tâche du Programmateur](resources/images/scheduler/add_new_job.png)

Les tâches nouvellement créées sont activées par défaut.

## Modifier une tâche{ #scheduling_configure_job }

Avec les autorisations appropriées, vous pouvez modifier les détails des tâches créées par l'utilisateur. Pour activer ou désactiver rapidement l'exécution d'une tâche créée par un utilisateur, utilisez les boutons de la colonne **Activer/Désactiver** sur la page d'accueil de l'application Programmateur. Notez que les tâches du système sont toujours activées et ne peuvent être désactivées.

Modification supplémentaire des tâches d'utilisateur :

1.  Cliquez sur le bouton "Actions" de la tâche que vous voulez modifier puis sur "Modifier"
    (seules les tâches d'utilisateur peuvent être modifiées).

1.  Lorsque vous avez terminé, cliquez sur le bouton **Sauvegarder** pour appliquer les modifications.

## Supprimer une tâche { #dataAdmin_scheduler_delete }

1.  Cliquez sur le bouton "Actions" de la tâche que vous voulez supprimer puis sur "Supprimer".
    (seules les tâches d'utilisateur peuvent être modifiées).

1.  Confirmez en cliquant à nouveau sur **Supprimer** dans la fenêtre contextuelle.

Les tâches d'utilisateur peuvent également être supprimées depuis la page de modification.

![Suppression d'une nouvelle tâche du Programmateur](resources/images/scheduler/delete_job.png)

## Types de tâches { #job-types } 

La section suivante décrit les différents types de tâches.

### Désactiver les utilisateurs inactifs { #scheduling_disable_inactive_users }

Les utilisateurs n'ayant pas été actifs - non connectés - pendant plusieurs mois peuvent être automatiquement désactivés. Comme paramètre de tâche, choisissez le nombre de mois d'inactivité. Tous les utilisateurs qui ne se sont pas connectés pendant ce nombre de mois ou plus seront désactivés par la tâche. Les utilisateurs désactivés ne pourront plus se connecter au système.

Le paramètre _Jours restant avant_ peut être réglé de sorte à envoyer un e-mail de rappel aux utilisateurs qui spécifie le nombre de jours restant avant l'expiration de leur compte. Si les utilisateurs ne se connectent pas, d'autres e-mails de rappel seront envoyés, chacun réduisant de moitié le nombre de jours précédent. Par exemple si le nombre de jours est fixé à 7, le premier e-mail est envoyé 7 jours à l'avance, le second 3 jours à l'avance et le troisième et dernier 1 jour à l'avance. Si aucune valeur n'est pas définie (vide), aucun rappel ne sera envoyé.

### Tableau des ressources { #scheduling_resource_table }

Le tableau des ressources à pour tâche de générer et de mettre à jour des tableaux de la base de données des ressources. Ces tableaux sont utilisées par différents composants de DHIS2 et sont destinées à simplifier les recherches dans la base de données.

Notez que lorsque vous spécifiez l'une des tâches de la table analytique, les tableaux de ressources peuvent être inclus dans le processus et il n'est pas nécessaire de spécifier également une tâche de ces tableaux de ressources

### Table analytique { #scheduling_analytics_table }

Les tables analytiques permettent de générer et de mettre à jour les tableaux analytiques. Les tableaux analytiques sont utilisés comme base pour les requêtes d'analyse de données dans DHIS2. Les applications telles que Tableau de bord, Visualiseur et Cartes récupèrent les données de ces tableaux via l'API analytique de DHIS2, et elles doivent être mises à jour pour que les données analytiques deviennent disponibles. Vous pouvez planifier ce processus de façon à ce qu'il s'exécute régulièrement par le biais d'un type de tâche de tableau analytique.

La tâche du tableau analytique remplira par défaut les champs de données pour toutes les années et tous les éléments de données. Les paramètres suivants sont disponibles :

- **Années dernières :** Le nombre d'années passées pour lesquelles les tableaux analytiques doivent être remplis. Par 
  exemple, si vous indiquez 2 ans, le processus mettra à jour les données des deux dernières années, 
  sans inclure les données plus anciennes. Ce paramètre permet de réduire 
  la durée du processus, et peut être utilisé lorsque les données plus anciennes n'ont 
  pas été modifiées et que l'on souhaite actualiser les données les plus récentes.
- **Ignorer les tableaux de ressources:** Ignorer les tableaux de ressources pendant le processus de mise à jour de 
  la table analytique. Ce paramètre permet de réduire la durée du processus, mais conduit également à des 
  changements dans les métadonnées qui ne sont pas reflétés dans les données analytiques.
- **Ignorer des types de tableaux:** Ignorer un ou plusieurs types de tableaux analytiques. Ce paramètre permet de réduire la
  la durée du processus, mais ces types de données ne seront pas mis à jour 
  dans les données analytiques.

### Table analytique (Suite) { #scheduling_continuous_analytics_table }

Les tables analytiques permettent de générer et de mettre à jour les tableaux analytiques. Les tableaux analytiques sont utilisés comme base pour les requêtes d'analyse de données dans DHIS2. Les applications telles que Tableau de bord, Visualiseur et Cartes récupèrent les données de ces tableaux via l'API analytique de DHIS2, et elles doivent être mises à jour pour que les données analytiques deviennent disponibles. Vous pouvez planifier ce processus de façon à ce qu'il s'exécute régulièrement par le biais d'un type de tâche de tableau analytique.

La tâche de la table analytique continue est basé sur deux phases :

- _Dernière mise à jour :_ Mise à jour des données les plus récentes, c'est-à-dire les données 
  qui ont été ajoutées, mises à jour ou supprimées depuis la dernière fois que les données les plus récentes 
  ou toutes les données ont été mises à jour. Ce processus est fréquent.
- _Mise à jour complète :_ mise à jour de toutes les données sur toutes les années. Ce processus aura lieu 
  une fois par jour.

Le tâche de la table analytique continue mettra régulièrement à jour les données récentes. Le processus de mise à jour des données utilise une partition spéciale de la base de données qui ne contient que les données les plus récentes. Cette partition peut être rapidement actualisée en raison de la quantité relativement faible des données. La taille de la partition augmentera jusqu'à ce qu'une mise à jour complète soit effectuée. Toutes les données de toutes les années seront mises à jour une fois par jour. La dernière partition sera ainsi effacée.

La tâche du tableau analytique remplira par défaut les champs de données pour toutes les années et tous les éléments de données. Les paramètres suivants sont disponibles :

- **Heure de la mise à jour complète:** Heure de la journée à laquelle la mise à jour complète sera 
  effectuée. Par exemple, si vous indiquez 1, la mise à jour complète sera effectuée à
  1h du matin.
- **Années dernières :** Le nombre d'années passées pour lesquelles les tableaux analytiques doivent être remplis. Par 
  exemple, si vous indiquez 2 ans, le processus mettra à jour les données des deux dernières années, 
  sans inclure les données plus anciennes. Ce paramètre permet de réduire 
  la durée du processus, et peut être utilisé lorsque les données plus anciennes n'ont 
  pas été modifiées et que l'on souhaite actualiser les données les plus récentes.
- **Ignorer les tableaux de ressources:** Ignorer les tableaux de ressources pendant le processus de mise à jour de 
  la table analytique. Ce paramètre permet de réduire la durée du processus, mais conduit également à des 
  changements dans les métadonnées qui ne sont pas reflétés dans les données analytiques.

### Optimisation de la recherche du Tracker { #scheduling_tracker_search_optimization }

La tâche d'optimisation de la recherche du Tracker est responsable de la génération et de la mise à jour des index trigrammes pour les attributs d'entité suivie pertinents. Les index trigrammes améliorent les performances de la recherche d'instances d'entité suivie en fonction de valeurs d'attributs d'entités suivies spécifiques. L'utilité des index trigrammes dépend du fait que l'attribut soit configuré comme unique ou recherchable (lorsqu'ils sont connectés au type de programme ou d'entité suivie). Vous pouvez configurer la tâche pour choisir les attributs d'entité suivie qui doivent être indexés par trigramme. La tâche prend également en charge la suppression de tous les index obsolètes qui ont été créés précédemment mais qui ne sont plus nécessaires en raison d'une modification de la configuration des métadonnées.

Les paramètres suivants sont disponibles :

- **Attributs:** La liste des attributs pour lesquels un index de trigramme doit être créé. Pour 
  chaque attribut, un index de trigramme partiels sera créé. Par exemple, si vous
  spécifiez les attributs "prénom" et "nom", le processus créera deux
  index de trigramme distincts pour les attributs correspondants "prénom" et 
  "nom". Notez que, si l'attribut fourni dans ce paramètre n'est pas
  indexable (soit parce qu'il n'est pas unique, soit parce qu'il n'est pas recherchable), 
  il sera ignoré par le processus et aucun index de trigramme ne sera
  créé pour lui.
- **Ignorer la suppression de l'index:** Ignorer la suppression de l'index obsolète lors du processus d'indexation du trigramme.
  Si ce paramètre est défini sur "true", les index considérés obsolètes ne seront pas supprimés.

### Synchronisation des données { #scheduling_data_sync }

DHIS2 permet la synchronisation des données entre des instances distantes et une instance centrale de DHIS2. Cette fonctionnalité peut être utile, par exemple, lorsque vous avez déployé plusieurs instances autonomes de DHIS2 qui doivent soumettre des valeurs de données à une instance centrale de DHIS2. La synchronisation des données tracker et des données agrégées est prise en charge.

Voici les étapes à suivre pour activer la synchronisation des données :

- Accédez aux paramètres de synchronisation, saisissez l'URL du serveur distant, le nom d'utilisateur et 
  le mot de passe. Appuyez sur la touche TAB pour enregistrer automatiquement le nouveau mot de passe. Actualisez 
  la page et vérifiez que les valeurs remplies sont toujours présentes. Notez que le 
  champ du mot de passe sera vide après l'actualisation, car cette valeur est cryptée ;
  vous pouvez donc considérer qu'elle est enregistrée.

- À l'aide de l'application Programmateur, créez une nouvelle tâche à partir des types de tâche "Synchronisation des données des programmes Évènement"
  et/ou "Synchronisation des données des programmes Tracker". Assurez-vous qu'elle soit activée lorsque vous 
  terminez. (Remarque : Si la tâche "Synchronisation des données du programme", disponible dans les 
  versions précédentes, était configurée dans l'application Programmateur, elle sera automatiquement 
  remplacée par les deux nouvelles fonctions "Synchronisation des données des programmes Évènement" et "Synchronisation des données des programmes Tracker"
  avec les mêmes paramètres.)

Quelques aspects de la fonction de synchronisation des données à prendre en compte :

- L'instance DHIS2 locale stockera le mot de passe du compte utilisateur sur 
  l'instance distante cryptée dans la base de données locale. Le compte à distance est utilisée
  à des fins d'authentification lors du transfert de données. Pour des raisons de sécurité, veillez à 
  définir le paramètre de configuration _encryption.password_ dans la section
  _hibernate.properties_ sur un mot de passe fort.

- Il est fortement recommandé de déployer le serveur distant sur SSL/HTTPS car 
  le nom d'utilisateur et le mot de passe sont envoyés en texte clair lors de l'authentification de base 
  et peuvent être interceptés par un pirate.

- La synchronisation des données utilise la propriété UID des éléments de données,
  des combinaisons d'options de catégorie et des unités d'organisation pour établir une correspondance entre les métadonnées. Par conséquent, la
  synchronisation dépend de l'harmonisation de ces trois objets de métadonnées
  sur l'instance locale et distante pour un bon fonctionnement.

- La première fois que DHIS2 exécute la tâche de synchronisation, toutes les données disponibles seront incluses.
  Les tâches de synchronisation suivantes n'incluront que les données  ajoutées 
  et modifiées depuis la dernière tâche réussie. Une tâche de synchronisation n'est considérée comme
  réussie que si toutes les données ont été sauvegardées avec succès sur le serveur distant 
  (Toutes les données synchronisées avec succès resteront sur l'instance réceptrice,
  échoue éventuellement). Le résumé de l'importation renvoyé par le serveur central 
  permet de déterminer si la tâche a réussi ou non.

- La tâche de synchronisation initiale peut prendre beaucoup de temps, 
  ce qui pourrait ralentir votre instance, selon la quantité de données 
  synchronisées. Vous pouvez configurer la tâche pour qu'elle s'exécute lorsqu'il 
  y'a peu d'utilisateurs en ligne, puis revenir ultérieurement à vos préférences. Si vous
  ne voulez pas ou n'avez pas besoin de synchroniser toutes les données, vous pouvez 
  <a href="#skip_changed_before"> ignorer une partie des données synchronisées</a>.

  Lorsque DHIS2 synchronise les données tracker, il détermine les données à 
  à synchroniser en se basant sur la dernière fois où elles ont été synchronisées. Chaque
  instance d'entité suivie et événement enregistre la date de sa dernière
   synchronisation réussie.

- Le système démarrera une tâche de synchronisation en fonction des règles définies dans la 
  configuration de la tâche. Si la tâche de synchronisation démarre alors qu'il n'y a pas de 
  connexion avec le serveur distant, elle réessayera jusqu'à trois fois avant 
  d'échouer. La tâche sera à nouveau exécutée à une date programmée.

- Le serveur gère chaque ensemble de programmes séparément, ce qui signifie qu'un ensemble de 
  programmes peut être synchronisé avec succès, tandis que l'autre échoue. L'échec
  ou la réussite de l'un n'a pas d'influence sur l'autre, car la date de la dernière synchronisation réussie 
  est suivie séparément pour chaque élément tel qu'indiqué précédemment.
   

- Les attributs des instances d'entités suivies (attributs d'instances suivies) et les éléments
  de données des étapes de programme (élément de données d'étape de programme) qui ont une option "Ignorer 
  la synchronisation" activée ne seront pas synchronisés. Cette fonction vous permet
  de décider de ne pas synchroniser certaines données sensibles ou non pertinentes et de ne les conserver 
  que localement.

- L'autorité
  `Ignorer la validation des champs obligatoires dans Tracker et Capture Événement`
  (`F\_IGNORE\_TRACKER\_REQUIRED\_VALUE\_VALIDATION`) doit être utilisée lorsqu'il
  est exigé que certains attributs ou éléments de données obligatoires aient au même 
  moment la propriété "Ignorer la synchronisation" activée. Un tel paramétrage conduira à
  un échec de la validation sur le serveur central car ni l'attribut, ni l'élément de données
  ne seront présents dans la charge.

  La validation n'échouera pas pour l'utilisateur qui dispose de cette autorité. L'autorité
  doit être attribué à l'utilisateur, sur le serveur central qui sera utilisé pour la 
  tâche de synchronisation.

- Dans des cas spécifiques, **la synchronisation initiale de toutes les données peut être 
  indésirable** ; par exemple, lorsqu'une base de données sur l'instance locale est une nouvelle 
  copie de la base de données présente sur l'instance centrale, ou lorsqu'il est préférable 
  de ne pas synchroniser les anciennes données pour gagner 
  en temps.

  La clé de réglage _syncSkipSyncForDataChangedBefore_ peut être utilisée pour ignorer
  la synchronisation de toutes les données (valeurs de données, données de programmes Évènement et Tracker, 
  complete data set registrations) that were _last changed before the specified
  date_. The `SettingKey` is used in the synchronization job all the time.
  Therefore, if you need to synchronize the old data, you should change the
  `SettingKey`.

- Both Tracker Programs and Event Programs synchronization job supports paging
  in order to avoid timeouts and to deal with unstable network. Default page
  size for "Event Programs Data Sync" job is set to 60. Default page size for
  "Tracker Programs Data Sync" job is set to 20.

  If default values do not fit your purpose, own page size can be specified via
  parameter in particular sync job in Scheduler app.

### Planification de la synchronisation des métadonnées { #scheduling_metadata_sync }

DHIS2 provides a feature for synchronizing meta data from a remote instance to a
local instance of DHIS2. This can be useful when you have deployed multiple
stand-alone instances of DHIS2 and you need to create meta data in all the local
instances similar to the central DHIS2 instance.

Voici les étapes à suivre pour activer la synchronisation des métadonnées :

- Go to Settings \> Synchronization, enter the remote server URL, username and
  password and click Save.

- Using the Scheduler app, create a new job using the "Metadata synchronization" job type. 

Quelques aspects de la fonctionnalité de synchronisation des métadonnées à prendre en compte :

- The local DHIS2 instance will store the password of the user account of the
  remote instance in its database. The remote user account is used for
  authentication when transferring/downloading data. For security purposes make
  sure you set the _encryption.password_ configuration parameter in
  _hibernate.properties_ sur un mot de passe fort.

- Il est fortement recommandé de déployer le serveur distant sur SSL/HTTPS car 
  le nom d'utilisateur et le mot de passe sont envoyés en texte clair lors de l'authentification 
  de base et peuvent être interceptés par un pirate.

- Also ensure that the remote user is not having ALL authority, instead simply
  create a user with F_METADATA_MANAGE authority so that even if these details
  are intercepted by a hacker, one cannot have full control of the remote
  system.

- The meta data synchronization relies on the underlying import layer. Each meta
  data version is an export of meta data between two given timestamps. Each sync
  of meta data version is an attempt to import that meta data snapshot into the
  local instance. The sync of versions is incremental. The local instance will
  try to download the meta data versions from the central instance one after the
  other. Failure to sync a specific meta data version will not let the sync
  proceed to further versions. In case of failures, appropriate changes must be
  made to meta data at central to ensure that the error gets resolved. Metadata
  configuration is critical and the user should be careful while rolling out the
  updates to the production. It's always recommended to have staging
  environments in place to ensure the sanity of the meta data versions and their
  impact thereafter. The local instance will sync the meta data from first
  version so that harmony is maintained and local and central instance will work
  appropriately.

- The system will attempt a synchronization at the scheduled time. If the local
  or remote server does not have a working Internet connection at the time, the
  synchronization will be aborted and re-attempted after as per the retry count
  as mentioned in the _dhis.conf_ file.

- You can see the time of last successful synchronization with remote server in
  the scheduling screen next to the "Last success" label.

### Prédicteur { #scheduling_predictor }

Cette fonction exécute les prédicteurs et/ou groupes de prédicteurs sélectionnés.

The relative start and end parameters determine the periods in which data will
be predicted, corresponding to the date on which the predictor job is run:

- **Relative start** counts the days from the job date to the earliest date on
  which a predicted period may start. It can be positive or negative. For
  example, a value of 3 means predict into periods that start at least 3 days
  after the predictor run. A value of -3 means predict into periods that start
  at least 3 days before the predictor run.

- **Relative end** counts the days from the job date to the latest date on which
  a predicted period may end. It can be positive or negative. For example, a
  value of 9 means predict into periods that end at least 9 days after the
  predictor run. A value of -9 means predict into periods that end at least 9
  days before the predictor run.

Setting these values can give you very flexible control over when predictions
will be made, especially if your predictor job is set to run daily or more
frequently. Before you set these values, you should think carefully about when
you want predictions for a period to start being made, and when you want them to
stop being made. Then you need to compute the appropriate relative start and end
dates.

Exemples:

1.  **Requirement**: A predictor uses data from the same week as the predicted
    value. (No past sampled data are used.) After the week ends on Sunday, you
    expect the data to be entered in the following two days (Monday and
    Tuesday). You don't want to start predicting data until Wednesday after the
    week ends because you don't want partial results to be shown. However, data
    may still be adjusted on Wednesday, so you want to update the predictions
    also on Thursday. After that, the data are frozen and you don't want to
    predict for that period anymore.

        **Solution:** For a job running daily or more frequently, define the
        relative start as -10 and the relative end as -2 (for periods
        within 10 to 2 days before the job runs).

        - Before Wednesday of the following week, the period end is
        greater than 2 days before, so no predictions are made.

        - On Wednesday of the following week, the period started 9 days
        before and ended 2 days before. Predictions are made because -9 to -2
        are within the range -10 to -2.

        - On Thursday of the following week, the period started 10 days
        before and ended 3 days before. Predictions are made because -10 to -3
        are within the range -10 to -2.

        - After Thursday, the previous week started more than
        10 days before, so no predictions are made.

        - Predictions are made only on Wednesday and Thursday. On Friday through
        Tuesday, no predictions are made (and the job finishes very quickly).

2.  **Exigence** : Un prédicteur est utilisé pour prévoir une limite (moyenne plus deux fois 
    the standard deviation) for expected non-seasonally varying disease cases
    based on data from the previous five weeks. Weeks are Monday through Sunday.
    Predictions should start being made from the previous Tuesday, using
    available data at that time, and continue being made through Tuesday of the
    week that the predictions are being made for (by which time it is assumed
    that the previous week's data are final).

        **Solution:** For a job running daily or more frequently,
        define the relative start as -1 and the relative end as 12.

        - Before Tuesday, predictions will not be made for the following week because it
        ends more than 12 days later.

        - On Tuesday, predictions will be made for the following week which starts
        in 6 days and ends in 12 days.

        - On Wednesday through the following Tuesday, predictions will be made for
        the week whose start-to-end dates are Wed: 5 to 11, Thu: 4 to 10,
        Fri: 3 to 9, Sat: 2 to 8, Sun: 1 to 7, Mon: 0 to 6, and Tue: -1 to 5.

        - Note that on Tuesday, predictions are made for the current week with
        start-to-end dates -1 to 5, and also for the following week
        with start-to-end dates 6 to 12. On all other days of the week
        predictions are made for one week.

Vous pouvez sélectionner les prédicteurs et les groupes de prédicteurs qui opéreront pendant l'exécution de la tâche :

- **Prédicteurs** exécute les prédicteurs individuels. Ils s'exécutent dans l'ordre spécifié.

- **Predictor groups** runs predictor groups. They run in the order added. The
  predictors within each group run in the order of their names (comparing
  Unicode character values).

Si des prédicteurs individuels et des groupes de prédicteurs sont sélectionnés pour la même tâche, les prédicteurs individuels s'exécutent en premier, suivis des groupes de prédicteurs.

### Intégrité des données { #scheduling_data_integrity }

Le type de tâche "Intégrité des données" est responsable de la planification des contrôles d'intégrité des données. DHIS2 peut effectuer une série de contrôles d'intégrité sur les données contenues dans la base de données. Il est extrêmement important d'identifier et de corriger les problèmes d'intégrité des données pour garantir la validité des données utilisées à des fins d'analyse. Chacun des contrôles d'intégrité de données effectués par le système sera décrit, ainsi que les procédures générales peuvent être appliquées pour la résolution de ces problèmes.

The result of the data integrity checks can be viewed in the Data Administration app. As of 2.41 the result of the data integrity checks are only available for up to *one hour* after the job has completed.

Some data integrity checks are marked as *slow*. Users should be cautious about running these checks on production systems as they could lead to decreased performance. It's generally not recommended to run more than one of these at the same time.

Les paramètres suivants sont disponibles :

- **Report type** the level of specificity of the result. The available options are:
  - **Summary** - a summary of the number of issues will be available.
  - **Details** - a list of issues pointing to individual data integrity violations will be available for each integrity check.
- **Checks to run** specify the data integrity checks to run. If *only run selected checks* is selected, a list of checks where you will be able to select only the checks to run will be displayed. If *run all standard checks* is selected, all *standard* checks will be executed. Note that this will not run checks that are marked as *slow* - these checks must be selected manually using *only run selected checks*.

See [Data Administration](#data_admin_data_integrity) for more information about the available data integrity checks.

## Schedule Queues { #schedule_queues }

### Creating a queue { #scheduling_create_queue }

1.  Open the **Scheduler** app and click the "New queue" button in the top right
    angle.

1.  Choose a suitable **Name** for the new queue.

1.  Select a cron schedule for the queue. Queues can be scheduled using the
    [Programmation du printemps](https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/scheduling/support/CronSequenceGenerator.html)
    syntax, just like jobs. You can also select a predefined **Cron expression**
    by clicking "Choose from preset times".

1.  Select the jobs that should be part of the queue. The available jobs can be
    added to the queue with the arrow buttons. The queue will run the jobs in
    the order specified here.

1.  Press the **Save** button to confirm the queue creation. On successful queue
    creation you will be redirected to the jobs and queue overview, where the
    newly created queue will now be listed. The queue will have a dropdown arrow
    that can be clicked to show the jobs that are part of the queue.

![Creating a new scheduler queue](resources/images/scheduler/add_new_queue.png)

Newly created queues are enabled by default.

### Editing a queue { #scheduling_configure_queue }

With the proper permissions, you can modify the details of queues. To quickly
enable or disable a queue from running, use the switches in the **On/off**
column on the landing page of the Scheduler app.

Further editing of queues:

1.  Click the "Actions" button of the queue you want to edit and click "Edit".

1.  Après avoir terminé la modification, cliquez sur le bouton **Sauvegarder** pour appliquer les modifications.

1.  If jobs were removed from the queue, they will be displayed again in the
    overview. But since they were part of a queue, they will be disabled and
    without a schedule.

### Deleting a queue { #scheduling_delete_queue }

1.  Click the "Actions" button of the queue you want to delete and click
    "Delete".

1.  Confirmez en cliquant à nouveau sur **Supprimer** dans la fenêtre contextuelle.

1.  All jobs that were part of the queue will be displayed again in the
    overview. But since they were part of a queue, they will be disabled and
    without a schedule.

Queues can also be deleted from the editing screen.

![Deleting a scheduler queue](resources/images/scheduler/delete_queue.png)

