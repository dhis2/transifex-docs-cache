---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/master/src/developer/web-api/data-validation.md"
revision_date: '2023-07-31'
tags:
- Hlavní verze jádra DHIS
- Vývoj
---

# Ověření dat { #data-validation } 

## Ověření { #webapi_validation } 

To generate a data validation summary you can interact with the
validation resource. The dataSet resource is optimized for data entry
clients for validating a data set / form, and can be accessed like this:

    GET /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

In addition to validate rules based on data set, there are two
additional methods for performing validation: Custom validation and
Scheduled validation.

The first path variable is an identifier referring to the data set to
validate. XML and JSON resource representations are supported. The
response contains violations of validation rules. This will be extended
with more validation types in the coming versions.

To retrieve validation rules which are relevant for a specific data set,
meaning validation rules with formulas where all data elements are part
of the specific data set, you can make a GET request to to
`validationRules` resource like this:

    GET /api/validationRules?dataSet=<dataset-id>

The validation rules have a left side and a right side, which is
compared for validity according to an operator. The valid operator
values are found in the table below.



Tabulka: Operátoři

| Hodnota | Popis |
|---|---|
| equal_to | Rovno |
| not_equal_to | Nerovná se |
| greater_than | Větší než |
| greater_than_or_equal_to | Větší než nebo rovno |
| less_than | Menší než |
| less_than_or_equal_to | Menší nebo rovno |
| compulsory_pair | Pokud je přítomna kterákoli strana, musí být přítomna i druhá |
| exclusive_pair | Pokud je přítomna kterákoli strana, druhá nesmí být přítomna |

The left side and right side expressions are mathematical expressions
which can contain references to data elements and category option
combinations on the following format:

    ${<dataelement-id>.<catoptcombo-id>}

The left side and right side expressions have a *missing value
strategy*. This refers to how the system should treat data values which
are missing for data elements / category option combination references
in the formula in terms of whether the validation rule should be checked
for validity or skipped. The valid missing value strategies are found in
the table below.



Tabulka: Chybějící hodnotové strategie

| Hodnota | Popis |
|---|---|
| SKIP_IF_ANY_VALUE_MISSING | Pokud chybí nějaká datová hodnota, přeskočte ověřovací pravidlo |
| SKIP_IF_ALL_VALUES_MISSING | Pokud chybí všechny hodnoty dat, přeskočte ověřovací pravidlo |
| NEVER_SKIP | Nikdy nepřeskakujte ověřovací pravidlo bez ohledu na chybějící datové hodnoty |

## Validation results { #webapi_validation_results } 

Validation results are persisted results of violations found during a
validation analysis. If you choose "persist results" when starting or
scheduling a validation analysis, any violations found will be stored in
the database. When a result is stored in the database it will be used
for 3 things:

1.  Generování analytiky na základě uložených výsledků.

2.  Persisted results that have not generated a notification, will do so,
    jednou.

3.  Keeping track of whether or not the result has generated a
    notification.

4.  Přeskakování pravidel, která již byla zkontrolována při spuštění
    validační analýza.

This means if you don't persist your results, you will be unable to
generate analytics for validation results, if checked, results will
generate notifications every time it's found and running validation
analysis might be slower.

### Query validation results { #query-validation-results } 

The validation results persisted can be viewed at the following
endpoint:

    GET /api/33/validationResults

You can also inspect an individual result using the validation result id
in this endpoint:

    GET /api/33/validationResults/<id>

Výsledky ověření lze filtrovat také podle následujících vlastností:

* Organizační jednotka: `ou=<UID>`
* Pravidlo ověření: `vr=<UID>`
* Období: `pe=<ISO-expression>`

Každá z výše uvedených vlastností filtru se může vyskytnout několikrát, například:

    GET /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

Více hodnot pro stejný filtr je kombinováno s OR, výsledky musí odpovídat jedné z daných hodnot.

Pokud je použito více než jedné vlastnosti filtru, jsou kombinovány s AND, výsledky musí odpovídat jedné z hodnot pro každou z vlastností.

U filtru období se musí výsledky shody překrývat s některým ze zadaných období.

Kromě toho lze výsledky ověření filtrovat také k datu jejich vytvoření:

    GET /api/36/validationResults?createdDate=<date>

Tento filtr lze kombinovat s jakýmkoli z ostatních filtrů.

### Trigger validation result notifications { #trigger-validation-result-notifications } 

Validation results are sent out to the appropriate users once every day,
but can also be manually triggered to run on demand using the following
API endpoint:

    POST /api/33/validation/sendNotifications

Pomocí tohoto koncového bodu se odesílají pouze neodeslané výsledky.

### Delete validation results { #delete-validation-results } 

Výsledky ověření lze ručně odstranit pomocí ID,

    DELETE /api/36/validationResults/<id>

nebo pomocí filtrů

    DELETE /api/36/validationResults?<filters>

Mezi podporované parametry filtru patří:

* `ou=<UID>`, aby odpovídal všem výsledkům ověření organizační jednotky; více jednotek kombinuje OR, pokud je parametr poskytnut více než jednou
* `vr=<UID>`, aby odpovídal všem výsledkům ověření pravidla ověření; kombinuje více pravidel NEBO pokud je parametr poskytnut více než jednou
* `pe=<ISO-expression>`, aby se shodovaly všechny výsledky ověření týkající se období, které se překrývá se zadaným obdobím
* `created=<ISO-expression>`, aby odpovídalo všem výsledkům ověření, které byly vytvořeny v zadaném období
* `notificationSent=<boolean>`, aby odpovídal pouze výsledkům ověření, pro které bylo nebo nebylo odesláno oznámení

Pokud jsou filtry kombinovány, musí být splněny všechny podmínky (logika AND).

Nějaké příklady:

Chcete-li odstranit všechny výsledky ověření související s organizační jednotkou s UID `NqwvaQC1ni4` pro 1. čtvrtletí roku 2020, použijte:

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

Chcete-li odstranit všechny výsledky ověření, které byly vytvořeny v 1. týdnu 2019 a pro které bylo odesláno oznámení, použijte:

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

Jakákoli operace odstranění bude vyžadovat oprávnění _Provádět úlohy údržby_.


## Detekce odlehlých hodnot { #outlier-detection } 

Koncový bod detekce odlehlých hodnot umožňuje detekci odlehlých hodnot v agregovaných hodnotách dat.

```
GET /api/36/outlierDetection
```

Tento koncový bod podporuje dva algoritmy pro zjišťování odlehlých hodnot:

* **Z-skóre:** Z-skóre je definováno jako absolutní odchylka mezi skóre a průměrem děleno standardní odchylkou. Parametr prahové hodnoty vztahující se k počtu standardních odchylek od střední hodnoty musí být zadán pomocí algoritmu z-skóre, aby bylo možné definovat horní a dolní hranici pro to, co je považováno za odlehlou hodnotu.
* **Upravené Z-skóre:** Stejné jako z-skóre s tím rozdílem, že jako měřítko centrální tendence používá medián místo průměru. Parametry jsou stejné jako u Z-skóre.
* **Min-max:** Min-max hodnoty datových prvků odkazují na vlastní hranice, které lze vložit do DHIS 2 na základě kombinace datových prvků, organizačních jednotek a kategorií.

The outlier values will be *ordered according to significance*, by default by the absolute deviation from the mean, with the most significant value first. This is helpful to quickly identify the outlier values which have the biggest impact on data quality and data analytics.

### Parametry požadavku databázového dotazu { #request-query-parameters } 

Jsou podporovány následující parametry dotazu.

| Parametr dotazu | Popis                                                  | Povinné | Možnosti (nejprve výchozí)                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | Datová sada, lze zadat vícekrát.                   | č. [*]    | Identifikátor datové sady.                      |
| de              | Datový prvek, lze zadat vícekrát.               | č. [*]    | Identifikátor datového prvku.                  |
| startDate       | Datum zahájení intervalu pro kontrolu odlehlých hodnot.               | Ano       | Datum (rrrr-MM-dd).                        |
| endDate         | Datum ukončení intervalu pro kontrolu odlehlých hodnot.                 | Ano       | Datum (rrrr-MM-dd).                        |
| ou              | Organizační jednotka, lze zadat vícekrát.          | Ano       | Identifikátor organizační jednotky.             |
| algoritmus       | Algoritmus pro detekci odlehlých hodnot.                      | Ne        | `Z_SCORE`, `MIN_MAX`, `MOD_Z_SCORE`       |
| práh       | Prahová hodnota pro odlehlé hodnoty. Pouze algoritmus `Z_SCORE` a `MOD_Z_SCORE`. | Ne        | Číselné, větší než nula. Výchozí: 3.0. |
| dataStartDate   | Počáteční datum intervalu pro výpočet střední hodnoty a standardního vývoje. Pouze algoritmus `Z_SCORE` a `MOD_Z_SCORE`. | Ne        | Datum (rrrr-MM-dd). |
| dataEndDate     | Koncové datum pro interval pro výpočet střední hodnoty a standardního vývoje. Pouze algoritmus `Z_SCORE` a `MOD_Z_SCORE`. | Ne        | Datum (rrrr-MM-dd).   |
| orderBy         | Pole na objednávku. Pouze algoritmus `Z_SCORE` a `MOD_Z_SCORE`.| Ne        | `MEAN_ABS_DEV`, `Z_SCORE`                 |
| maxResults      | Maximální limit pro výstup.                                    | Ne        | Celé číslo, větší než nula. Výchozí: 500. |

[*] Musíte zadat buď datové sady s parametrem `ds`, který bude zahrnovat všechny datové prvky v datových sadách, _nebo_ specifikovat datové prvky s parametrem `de`.

Musí být definován alespoň jeden datový soubor nebo datový prvek, datum zahájení a datum ukončení a alespoň jedna organizační jednotka.

Parametry `startDate` a `endDate` jsou povinné a odkazují na časový interval, ve kterém chcete zjistit odlehlé hodnoty. Parametry `dataStartDate` a `dataEndDate` jsou volitelné a odkazují na časový interval, který mají data použít při výpočtu střední hodnoty a std dev, které se použijí k případnému výpočtu z-skóre.

### Použití a příklady { #usage-and-examples } 

Získejte hodnoty odlehlých hodnot pomocí výchozího algoritmu z-skóre:

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
```

Získejte hodnoty odlehlých hodnot pomocí konkrétního algoritmu a konkrétní prahové hodnoty:

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=Z_SCORE&threshold=2.5
```

Získejte hodnoty odlehlých hodnot seřazené podle z-skóre:

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &orderBy=Z_SCORE
```

Získejte 10 nejlepších hodnot odlehlých hodnot:

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &maxResults=10
```

Získejte odlehlé hodnoty s definovaným intervalem pro data, která se mají použít při výpočtu střední hodnoty a standardní hodnoty:

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt
  &ou=O6uvpzGd5pu&startDate=2020-01-01&endDate=2020-12-31
  &dataStartDate=2018-01-01&dataEndDate=2020-12-31
```

Získejte hodnoty odlehlých hodnot pomocí algoritmu min-max:

```
GET /api/36/outlierDetection?ds=BfMAe6Itzgt&ds=QX4ZTUbOt3a
  &ou=O6uvpzGd5pu&ou=fdc6uOvgoji&startDate=2020-01-01&endDate=2020-12-31
  &algorithm=MIN_MAX
```

### Formát odpovědi { #response-format } 

Podporovány jsou následující formáty odpovědí.

| Formát | Formát API                                                   |
| ------ | ------------------------------------------------------------ |
| JSON   | `/api/36/outlierDetection.json` or `Accept: application/json` (výchozí formát) |
| CSV    | `/api/36/outlierDetection.csv` nebo `Accept: application/csv`  |

Odpověď obsahuje následující pole:

| Pole      | Popis                                                  |
| ---------- | ------------------------------------------------------------ |
| de         | Identifikátor datového prvku.                                     |
| deName     | Název datového prvku.                                           |
| pe         | Identifikátor období ISO.                                       |
| ou         | Identifikátor organizační jednotky.                                |
| ouName     | Název organizační jednotky.                                      |
| coc        | Identifikátor kombinace možnosti kategorie.                      |
| cocName    | Název kombinace možnosti kategorie.                            |
| aoc        | Identifikátor kombinace možnosti atributu.                     |
| aocName    | Název kombinace možnosti atributu.                           |
| value      | Hodnota dat.                                                  |
| mean       | Průměr hodnot dat v časové dimenzi.                   |
| stdDev     | Standardní odchylka.                                          |
| absDev     | Pro z-skóre absolutní odchylka od průměru. Pro min-max, absolutní odchylka od minimální nebo maximální hranice. |
| zScore     | Z-skóre. Pouze algoritmus Z-skóre.                         |
| lowerBound | Dolní hranice.                                          |
| upperBound | Horní hranice.                                          |
| followUp   | Zda je datová hodnota označena pro následnou kontrolu.                  |

Pole `mean`, `stdDev` a `zScore` jsou přítomny pouze když `algorithm` je `Z_SCORE`.

Odpověď bude vypadat podobně. Sekce `metadata` obsahuje metadata pro požadavek a odpověď. Sekce `outlierValues` obsahuje hodnoty odlehlých hodnot.

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### Omezení a validace { #constraints-and-validation } 

Během ověřování dotazu platí následující omezení. Každá chyba ověření má odpovídající kód chyby.

| Chybový kód | Zpráva                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | Musí být zadán alespoň jeden datový prvek                  |
| E2201      | Musí být uvedeno datum zahájení a datum ukončení                    |
| E2202      | Datum zahájení musí být před datem ukončení                           |
| E2203      | Musí být uvedena alespoň jedna organizační jednotka             |
| E2204      | Prahová hodnota musí být kladné číslo                          |
| E2205      | Maximální počet výsledků musí být kladné číslo                        |
| E2206      | Maximální počet výsledků překračuje povolený maximální limit: {d}               |
| E2207      | Datum zahájení dat musí být před datem ukončení dat                 |
| E2208      | Při detekci odlehlých hodnot došlo k nečíselným datovým hodnotám |

## Analýza dat { #webapi_data_analysis } 

Several resources for performing data analysis and finding data quality
and validation issues are provided.

**Poznámka:** Tento koncový bod je zastaralý a bude odstraněn ve verzi 2.38. Místo toho použijte koncový bod `outlierAnalysis`.

### Analýza ověřovacích pravidel { #webapi_data_analysis_validation_rules } 

Spuštění ověřovacích pravidel a načtení porušení pravidel:

    GET /api/dataAnalysis/validationRules

Jsou podporovány následující parametry dotazu:



Tabulka: Parametry dotazu analýzy ověřovacích pravidel

| Parametr dotazu | Popis | Možnost |
|---|---|---|
| vrg | Skupina ověřovacích pravidel | ID |
| ou | Organizační jednotka | ID |
| startDate | Datum zahájení pro časové období | Datum |
| endDate | Datum ukončení pro časové období | Datum |
| trvalé | Zda přetrvávat porušení v systému | false &#124; true |
| oznámení | Zda se mají zasílat oznámení o porušení | false &#124; true |

Ukázkový výstup:
```json
[{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### Analýza odlehlých hodnot založená na směrodatné odchylce { #webapi_data_analysis_std_dev_outlier } 

To identify data outliers based on standard deviations of the average
value:

    GET /api/dataAnalysis/stdDevOutlier

Jsou podporovány následující parametry dotazu:



Tabulka: Parametry dotazu analýzy odlehlých hodnot standardní odchylky

| Parametr dotazu | Popis | Možnost |
|---|---|---|
| ou | Organizační jednotka | ID |
| startDate | Datum zahájení pro časové období | Datum |
| endDate | Datum ukončení pro časové období | Datum |
| ds | Datové sady, parametr lze opakovat | ID |
| standardní odchylka | Počet směrodatných odchylek od průměru | Číselná hodnota |

### Analýza odlehlých hodnot založená na minimální / maximální hodnotě { #webapi_data_analysis_min_max_outlier } 

Identifikace odlehlých dat na základě min / max hodnot:

    GET /api/dataAnalysis/minMaxOutlier

The supported query parameters are equal to the *std dev based outlier
analysis* resource described above.

### Následná analýza dat { #follow-up-data-analysis } 

Identifikace údajů označených pro následnou kontrolu:

    GET /api/dataAnalysis/followup

Musí být definována alespoň jedna datová sada nebo datový prvek, počáteční a koncové datum nebo období a alespoň jedna organizační jednotka.

Jsou podporovány následující parametry dotazu.

| Parametr  | Popis                                                  | Povinné | Možnosti (nejprve výchozí)                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ou         | Organizační jednotka, lze zadat vícekrát.          | Ano       | Identifikátor organizační jednotky.             |
| ds         | Datová sada, lze zadat vícekrát.                   | č. [*]    | Identifikátor datové sady.                      |
| de         | Datový prvek, lze zadat vícekrát.               | č. [*]    | Identifikátor datového prvku.                  |
| startDate  | Datum zahájení intervalu pro kontrolu odlehlých hodnot.               | č. [*]    | Datum (rrrr-MM-dd).                        |
| endDate    | Datum ukončení intervalu pro kontrolu odlehlých hodnot.                 | č. [*]    | Datum (rrrr-MM-dd).                        |
| pe         | ID období ISO.                                               | č. [*]    | Období ISO ID.                        |
| peType     | ISO období.                                                  | č. [*]    | Řetězec ISO období.                        |
| coc        | Kombinace možností kategorie, lze zadat vícekrát.     | Ne        | Kombinovaný identifikátor možností kategorie.         |
| maxResults | Maximální limit pro výstup.                                    | Ne        | Celé číslo větší než nula. Výchozí: 50.  |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.
     Equally, either `startDate` and `endDate` _or_ `period` must be specified.

The `startDate` and `endDate` parameters refer to the time interval for which you want to detect outliers.
If a period `pe` is provided instead the interval start and end is that of the period.

Pokud nejsou zadány žádné kombinace voleb `coc`, berou se v úvahu všechny datové prvky typu číselné hodnoty.


## Integrita dat { #webapi_data_integrity } 

The data integrity capabilities of the data administration module are
available through the web API. This section describes how to run the
data integrity process and retrieve the results. The specific
details regarding each check are described in the user manual.

### Výpis dostupných kontrol integrity dat { #webapi_data_integrity_list }
A description of the available checks is returned by a request to:

    GET /api/dataIntegrity

```
[
    {
        "name": "data_elements_without_groups",
        "displayName": "Data elements lacking groups",
        "section": "Data Elements",
        "severity": "WARNING",
        "description": "Lists all data elements that have no data element groups",
        "issuesIdType": "dataElements",
        "isSlow": false
    }
]
```

The `name` member of the returned check elements is the identifier used for the
`checks` parameter to declare the set of checks to run.

> **Note**
> 
> Each check will indicate whether it may require significant time and resources to complete with the `isSlow` field. 
> Users should be cautious about running these
> checks on production systems as they could lead to decreased performance. 
> These checks can be run individually, but will 
> not be run unless specifically requested.

Checks are grouped semantically by the `section` member and categorised in 
one of four `severity` levels:

| Závažnost | Popis                                                                                                                   |
| -------- |-------------------------------------------------------------------------------------------------------------------------------|
| INFO     | Označuje, že toto je pouze pro informaci.                                                                                  |
| VAROVÁNÍ  | A warning indicates that this may be a problem, but not necessarily an error. It is however recommended to triage these issues. |
| TĚŽKÉ   | An error that should be fixed but which may not necessarily lead to the system not functioning.                               |
| KRITICKÉ | An error that must be fixed and which may lead to end-user error or system crashes.                                           |

Dostupné kontroly lze filtrovat pomocí parametru `checks`.

    GET /api/dataIntegrity?checks=<pattern1>,<pattern2>

One or more exact names or patterns using `*` as a wildcard can be provided.

Additional results can be filtered using a `section` parameter.

    GET /api/dataIntegrity?section=Categories

The `section` filter will return all exact matches which have the specified section. 

### Running data integrity summaries { #webapi_data_integrity_run_summary }

Since version 2.38, data integrity checks have two levels of specificity: 
- a `summary` level that provides an overview of the number of issues
- a `details` level that provides a list of issues pointing to individual data integrity violations.

Chcete-li spustit souhrnnou analýzu pro sadu kontrol:

    POST /api/dataIntegrity/summary?checks=<name1>,<name2>

This triggers a job that runs the check(s) asynchronously. Individual check results
will be returned to the application cache as soon as the check has completed.

Alternatively the list of checks can also be given as BODY of the POST request.
This can be useful if the list becomes to long to be used in the URL.

Chcete-li načíst souhrn dat o integritě spuštěných kontrol(y), použijte:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>

When the `checks` parameter is omitted, all checks are fetched from the server cache.

The response is a "map" of check results, one for each check that has completed already.
This information is cached for one hour or until the check is rerun.

To wait for the summary to be available in the cache a `timeout` in milliseconds can be added:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>&timeout=500

An example of a summary response could look like: 
```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 12,
    "percentage": 2.3
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 4,
    "percentage": 5.1
  }
}
```

Each summary response will contain the `name`, `section`, `severity`, 
`description` and optionally  an `introduction` and `recommendation`.  
Each summary contains the number of issues found in the `count` field. When possible,
an optional `percentage` field will provide the percentage of objects with data
integrity issues when compared to all objects of the same type.
The `startTime` field indicates when the check was initiated. Using the `finishedTime`
the duration which was required to execute the check can be calculated.

Should a check analysis fail due to programming error or unforeseen data inconsistencies
both the summary and the details will have an `error` field describing the error that occurred.
The `count` of any checks which failed will be set to -1. 
No `percentage` will be returned in such cases.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "error": "what has happened",
    "issues": []
  }
}
```

> **Note**
> 
> Each metadata check is run asynchronously on the server.  Results
> will be returned as soon as each check completes. The safest way to ensure 
> that you have retrieved the latest set of results which has been 
> requested is to compare the timestamp of when the request was made
> with the `finishedTime` in the response.

To get a list of the names of checks that are currently being performed by the 
server use:

    GET /api/dataIntegrity/summary/running

To get a list of the names of checks for which results are available already use:

    GET /api/dataIntegrity/summary/completed


### Running data integrity details { #webapi_data_integrity_run_details }

To run a selection of details checks first trigger them using a  `POST` request:

    POST /api/dataIntegrity/details?checks=<name1>,<name2>

Similar to the summary the list of checks can also be given as the POST body.

Poté načtěte výsledky z mezipaměti pomocí:

    GET /api/dataIntegrity/details?checks=<name1>,<name2>&timeout=500

When the `checks` parameter is not provided,  all checks which 
have not been marked as `isSlow` will be scheduled to be run on the server.

Omitting the `timeout` will not wait for results to be found in the cache, 
but instead not have a result for the requested check.

The `/details` response returns a map similar to the `summary`, but does not contain
a `count` or `percentage`. Instead, a list of `issues` is returned.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": [{
      "id": "<id-or-other-identifier>",
      "name": "<name-of-the-id-obj>",
      "comment": "optional plain text description or hint of the issue",
      "refs": ["<id1>", "<id2>"]
    }]
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": []
  }
}
```
Each issue will always have `id` and `name` members.  Often the `issuesIdType`
is available to indicate the type of objects the `id` refers to. If the 
`issuesIdType` is not available, the `id` often is not available either and the
`name` is used for an aggregate key of an issue that has no object equivalent.

The `comment` and `refs` fields are optional for each issue.
A `comment` may provide more context or
insight into why this particular issue is regarded to be a data integrity problem. 
The `refs` list may also give the identifiers of other objects that contributed to the violation.
The `finishedTime` field shows when the particular check finished processing on the server.
The cache will store the result of each completed check for one hour.

> **Tip**
>
> A set of checks can also be specified using wild-cards. To include all 
> checks with _element_ in the name use `checks=*element*`. Like full names 
> such patterns can be used in a comma-separated list and be mixed with full 
> names as well. Duplicates will be eliminated. 
> Also a check can be given by its code. A code consists of the first letters
> of each word in the name as upper case letter. 
> For example, `orgunits_invalid_geometry` has the code `OIG`.

Similar to the summary a set of names of the currently performed and the
already completed details checks can be obtained using:

    GET /api/dataIntegrity/details/running
    GET /api/dataIntegrity/details/completed

### Custom Data Integrity Checks { #custom_data_integrity_checks } 

Users of DHIS2 can now create and supply their own Data Integrity Checks. This can be useful if users 
want to avail of this functionality and extend upon the supplied set of core data integrity checks.  

An example of a custom check could be for determining if certain users are members of specific user groups. This 
type of check would be very specific to an implementation, and not generally applicable across all installs.  

Custom checks can be implemented by satisfying the following requirements, each of which we will go into detail:  
- Supplying your own list of custom data integrity checks in a list file named `custom-data-integrity-checks.yaml`
 in your `DHIS2_HOME` directory
- Having a directory named `custom-data-integrity-checks` in your `DHIS2_HOME` directory 
- Supplying your valid custom data integrity check yaml files

#### Custom Data Integrity Check List File { #custom-data-integrity-check-list-file } 

DHIS2 will only try to load data integrity files when they are needed. e.g. when making a call to view all
data integrity checks:

    GET /api/dataIntegrity

DHIS2 will look for a file named `custom-data-integrity-checks.yaml` in your `DHIS2_HOME` directory when loading
data integrity files. If you are not using custom checks and the file is not present, a warning log like this will 
be present:

```text
08:29:57.729  WARN o.h.d.d.DataIntegrityYamlReader: Failed to load data integrity check from YAML. Error message `{DHIS2_HOME}/custom-data-integrity-checks.yaml (No such file or directory)
```

If you are implementing custom data integrity checks then this file must be present. To see what the core data integrity checks
file looks like as an example, check out [this file](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks.yaml). 


The `custom-data-integrity-checks.yaml` file should list all of your custom data integrity checks.
As an example, it could look something like this: 

```yaml
checks:
  - categories/my_custom_check.yaml
  - users/my_user_group_check.yaml
  - base_check.yaml
```

Check names in this file can be preceded with a directory name for logical grouping. From the 3 example checks listed 
above, the directory structure should look like this:

```
├── DHIS2_HOME
│   ├── dhis.conf
│   ├── custom-data-integrity-checks.yaml
│   ├── custom-data-integrity-checks
│   │   ├── categories
│   │   │   ├── my_custom_check.yaml
│   │   ├── users
│   │   │   ├── my_user_group_check.yaml
│   │   ├── base_check.yaml
```

#### Name and Code constraints { #name-and-code-constraints } 

Each data integrity check `name` and `code` must be unique. If there are any clashes then the violating custom
check will not be loaded.

> **Note**
>
> System data integrity checks are always loaded first. Any name or code clashes resulting from
> custom checks will not affect these core system checks.

An example data integrity check yaml file is located [here](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks/orgunits/orgunits_orphaned.yaml)
for reference. Note the `name` property.  

The data integrity `code` is calculated dynamically by using the first letter of each word in the `name`. Some examples:

| Název                   | Kód |
|------------------------|------|
| my_custom_check        | MCC  |
| my_second_custom_check | MSCC |
| another_custom_check   | ACC  |

If there is a `name` clash, a warning log like this will be present:
```text
09:48:43.138  WARN o.h.d.d.DefaultDataIntegrityService: Data Integrity Check `my_custom_check` not added as a check with that name already exists
```

If there is a `code` clash, a warning log like this will be present:
```text
09:48:43.138  WARN o.h.d.d.DefaultDataIntegrityService: Data Integrity Check `my_custom_check` not added as a check with the code `MCC` already exists
```

#### Data Integrity Check Schema { #data-integrity-check-schema } 

A data integrity check file must comply with this [JSON schema](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks/integrity_check_schema.json).
If a check does not comply with the schema then a warning like this will be present:
```text
09:48:43.136  WARN o.h.d.d.DataIntegrityYamlReader: JsonSchema validation errors found for Data Integrity Check `categories/my_custom_check.yaml`. Errors: [$.name: is missing but it is required]
```

Any schema violations must be fixed before that check can be loaded and used.

If a data integrity check file contains invalid yaml then a warning log like this could be present:
```text
10:30:37.858  WARN o.h.d.d.DataIntegrityYamlReader: JsonSchema validation errors found for Data Integrity Check `my_custom_check.yaml`. Errors: [$: string found, object expected]
```

To view and use the custom checks please refer to the main [Data Integrity section](#webapi_data_integrity)

> **Note**
>
> It is recommended to follow any naming and format conventions seen in the provided examples above when implementing
> your own custom checks to help avoid any issues

#### Data Integrity File { #data-integrity-file } 

Details of the data integrity check yaml file, taken from the JSON schema file

| property        | Vyžadováno | info                                                                                                                          |
|-----------------|----------|-------------------------------------------------------------------------------------------------------------------------------|
| název            | yes      | unique name of the check                                                                                                      |
| popis     | yes      | popis                                                                                                                   |
| sekce         | yes      | used for logical grouping of checks e.g. categories, users                                                                    |
| section_order   | yes      | the order of the check when displayed in the UI                                                                               |
| summary_sql     | yes      | an SQL query which should return a single result which represents the total count of issues                                   |
| details_sql     | yes      | an SQL query which should return a list of identified objects from this particular issue. Should return at least uid and name |
| details_id_type | yes      | a short string which identifies the section of the details SQL                                                                |
| severity        | yes      | level of severity of the issue. One of [INFO, WARNING, SEVERE, CRITICAL]                                                      |
| introduction    | yes      | outlining the objective of the check                                                                                          |
| recommendation  | yes      | outlining how to resolve identified issues                                                                                    |

## Dokončená registrace datových sad { #webapi_complete_data_set_registrations } 

This section is about complete data set registrations for data sets. A
registration marks as a data set as completely captured.

### Dokončení datových sad { #webapi_completing_data_sets } 

This section explains how to register data sets as complete. This is
achieved by interacting with the *completeDataSetRegistrations*
resource:

    GET /api/33/completeDataSetRegistrations

The endpoint supports the *POST* method for registering data set
completions. The endpoint is functionally very similar to the
*dataValueSets* endpoint, with support for bulk import of complete
registrations.

Importing both *XML* and *JSON* formatted payloads are supported. The
basic format of this payload, given as *XML* in this example, is like
so:

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP"
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

The *storedBy* attribute is optional (as it is a nullable property on
the complete registration object). You can also optionally set the
*date* property (time of registration) as an attribute. It the time is
not set, the current time will be used.

Proces importu podporuje následující parametry dotazu:



Tabulka: Parametry dotazu na registraci kompletní datové sady

| Parametr | Hodnoty | Popis |
|---|---|---|
| dataSetIdScheme | id &#124; jméno &#124; kód &#124; atribut:ID | Vlastnost datové sady, která se má použít k mapování úplných registrací. |
| orgUnitIdScheme | id &#124; jméno &#124; kód &#124; atribut:ID | Vlastnost organizační jednotky, která se má použít k mapování úplných registrací. |
| attributeOptionComboIdScheme | id &#124; jméno &#124; kód &#124; atribut:ID | Vlastnost kombinací možností atributů, které se mají použít k mapování úplných registrací. |
| idScheme | id &#124; jméno &#124; kód &#124; atribut:ID | Vlastnost všech objektů včetně datových sad, organizačních jednotek a kombinací možností atributů, které se mají použít k mapování kompletních registrací. |
| preheatCache | false &#124; true | Zda uložit změny na serveru nebo jen vrátit souhrn importu. |
| dryRun | false &#124; true | Zda se registrace vztahuje na dílčí jednotky |
| importStrategy | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | Uložit objekty všech, nový nebo aktualizovat stav importu na server. |
| skipExistingCheck | false &#124; true | Přeskočit kontroly existujících úplných registrací. Zlepšuje výkon. Použijte pouze pro prázdné databáze nebo když registrace k importu ještě neexistují. |
| async | false &#124; true | Označuje, zda má být import proveden asynchronně nebo synchronně. První z nich je vhodný pro velmi velké importy, protože zajišťuje, že požadavek nevyprší, ačkoli má značnou režii na výkon. Druhý je rychlejší, ale vyžaduje, aby připojení přetrvávalo, dokud nebude proces dokončen. |

The `idScheme`, `dataSetIdScheme`, `orgUnitIdScheme`, `attributeOptionComboIdScheme`, 
`dryRun` and `strategy` (note the dissimilar naming to parameter `importStrategy`) 
can also be set as part of the payload.
In case of XML these are attributes, in case of JSON these are members in the
`completeDataSetRegistrations` node.

Například:
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

Should both URL parameter and payload set a scheme the payload takes precedence. 

### Čtení registrací úplných datových sad { #webapi_reading_complete_data_sets } 

This section explains how to retrieve data set completeness
registrations. We will be using the *completeDataSetRegistrations*
resource. The query parameters to use are these:



Tabulka: Parametry dotazu sady hodnot dat

| Parametr | Popis |
|---|---|
| dataSet | Identifikátor datové sady, více datových sad je povoleno |
| period | Identifikátor období ve formátu ISO. Je povoleno více období. |
| startDate | Datum zahájení pro časové rozpětí hodnot k exportu |
| endDate | Datum ukončení pro časové rozpětí hodnot k exportu |
| created | Zahrňte pouze registrace, které byly vytvořeny od daného časového razítka |
| createdDuration | Include only registrations which were created within the given duration. The format is <value\><time-unit\>, where the supported time units are "d", "h", "m", "s" *(days, hours, minutes, seconds).* The time unit is relative to the current time. |
| orgUnit | Identifikátor organizační jednotky, lze zadat vícekrát. Nelze použít, pokud je zadáno orgUnitGroup. |
| orgUnitGroup | Identifikátor skupiny organizační jednotky, lze zadat vícekrát. Nelze použít, pokud je uvedena orgUnit. |
| children | Zda zahrnout podřazené do hierarchie organizačních jednotek |
| limit | Maximální počet registrací, které lze zahrnout do odpovědi. |
| idScheme | Vlastnost identifikátoru použitá pro objekty metadat v odpovědi. |
| dataSetIdScheme | Vlastnost identifikátoru použitá pro datové sady v odpovědi. Přepíše idScheme. |
| orgUnitIdScheme | Vlastnost identifikátoru použitá pro organizační jednotky v odpovědi. Přepíše idScheme. |
| attributeOptionComboIdScheme | Vlastnost identifikátoru použitá pro kombinace možností atributu v odpovědi. Přepíše idScheme. |
Parametry `dataSet` a `orgUnit` lze opakovat, aby bylo možné zahrnout více sad dat a organizačních jednotek.

The `period`, `startDate`,  `endDate`, `created` and `createdDuration` parameters provide multiple ways to set the time dimension for the request, thus only
one can be used. For example, it doesn't make sense to both set the start/end date and to set the periods.

Příklad požadavku vypadá takto:

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX&dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

You can get the response in *xml* and *json* format. You can indicate which response format you prefer through the *Accept* HTTP header like
in the example above. For xml you use *application/xml*; for json you use *application/json*.

### Zrušení dokončení datových sad { #webapi_uncompleting_data_sets } 

Tato část vysvětluje, jak můžete zrušit registraci úplnosti datové sady. Chcete-li zrušit dokončení datové sady, budete pracovat s prostředkem completeDataSetRegistrations:

    GET /api/33/completeDataSetRegistrations

This resource supports *DELETE* for un-registration. The following query
parameters are supported:



Tabulka: Parametry dotazu na registraci kompletní datové sady

| Parametr dotazu | Požadované | Popis |
|---|---|---|
| ds | Ano | Identifikátor datové sady |
| pe | Ano | Identifikátor období |
| ou | Ano | Identifikátor organizační jednotky |
| cc | Ne (nutno kombinovat s cp) | Kombinovaný identifikátor atributů (pro kontrolu uzamčení) |
| cp | Ne (nutno kombinovat s cp) | Identifikátory možností atributů oddělené ; pro více hodnot (pro kontrolu uzamčení) |
| multiOu | Ne (výchozí hodnota false) | Zda se registrace vztahuje na dílčí jednotky |

