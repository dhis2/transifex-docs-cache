---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.41/src/user/control-data-quality.md"
revision_date: '2021-11-04'
tags:
- DHIS core version 2.41
- Uso
---

# Control data quality { #control_data_quality } 

## About data quality checks { #about_data_quality } 

The **Data Quality** app contains tools to validate the accuracy and
reliability of the data in the system. You can assess different dimensions of 
data quality as outlined in the table below: 


| Dimensión | Descripción |
|---|---|
| Exactitud | Los datos deben estar dentro del rango normal para los datos recopilados en ese establecimiento. No debe haber grandes discrepancias en comparación con los datos de los elementos de datos relacionados. |
| Completitud | Deberían haberse presentado los datos de todos los elementos de datos de todas las unidades organizativas informantes. |
| Consistencia | Los datos deben ser consistentes con los datos introducidos ​​durante meses y años anteriores, permitiendo al mismo tiempo cambios con la reorganización, aumento de la carga de trabajo, etc. y consistencia con otras instalaciones similares. |
| Puntualidad | Todos los datos de todas las unidades organizativas informantes deben enviarse a la hora especificada. |

Puede verificar la calidad de los datos de diferentes maneras, por ejemplo:

  - At point of data entry, DHIS 2 can check the data entered to see if
    it falls within the minimum maximum value ranges of that data
    element (based on all previous data registered).

  - By defining validation rules, which can be run once the user has
    finished data entry. The user can also check the entered data for a
    particular period and organization unit(s) against the validation
    rules, and display the violations for these validation rules.

  - Al analizar conjuntos de datos, es decir, examinar las lagunas de los datos.

  - By data triangulation, that is, comparing the same data or indicator
    from different sources.

## Validation rule analysis { #validation_rule_analysis } 

### About validation rule analysis { #about-validation-rule-analysis } 

A validation rule is based on an expression which defines a numeric relationship
between data element values. The expression forms a condition which
should assert that certain logical criteria are met.

La expresión consiste en:

  - Un lado izquierdo

  - Un lado derecho

  - Un operador

A validation rule could assert that "Suspected malaria cases tested" \>=
"Confirmed malaria cases".

Los lados izquierdo y derecho deben devolver valores numéricos.

The validation rule analysis tests validation rules against the data
registered in the system. Validation violations are reported when the
condition defined in the validation rule expression is not met, which
means when the condition is false.

You can configure a validation rule analysis to automatically send out
information about validation violations to selected user groups. These
messages are called *validation notifications* and you create them in
the **Maintenance** app. Validation notifications are sent via the
internal DHIS 2 messaging system.

### Workflow { #workflow } 

1.  In the **Maintenance** app, create validation rules and validation
    rule groups.

2.  (Optional) In the **Maintenance** app, create validation
    notifications.

3.  Ejecutar el análisis por reglas de validación, de forma automática o manual.

      - In the **Scheduler** app, you schedule the validation
        rule analysis to run automatically for all validation rules
        included in one or several validation rule groups. After the
        system has run the analysis, you'll see the validation
        violations (if any) in the validation notifications sent via the
        internal DHIS 2 messaging system.

      - In the **Data Quality** app, you run the validation rule
        analysis manually for selected validation rules. After the
        analysis process has finished, you'll see a list of validation
        violations (if any).

### Schedule a validation rule analysis to run automatically { #schedule-a-validation-rule-analysis-to-run-automatically } 

> **Note**
>
> Only validation rules that are included in one or several validation
> notifications will be a part of the validation rule analysis. If
> there is no corresponding validation notification for a validation
> rule, no notification will be sent.

> **Note**
>
> While running validation rule analysis automatically, any results not
> already persisted, will be persisted during this run. Persisted
> results can currently only be accessed trough the API. Consult
> the developers guide for more information about how persisted
> validation rule violations can be accessed.

1.  Verify that you have created all the validation rules, validation
    rule groups and validation notifications you need.

2.  Abrir la aplicación **Planificador** y click en el botón de añadir en la esquina inferior derecha.

3.  Elija un nombre adecuado para el nuevo trabajo.

4. Select the **Monitoring** Job type using the drop-down menu. 

5. Seleccionar una frecuencia de ejecución para el trabajo, es decir, cuándo y con qué frecuencia debe ejecutarse el trabajo.

6. Llene la sección **Parámetros**, incluyendo los grupos de reglas de validación.

7. Presione el botón **Agregar trabajo** para confirmar la creación del trabajo. Para obtener más información sobre cómo agregar trabajos, consulte [Planificador](data-administration.html # scheduling).

### Run a validation rule analysis manually { #run-a-validation-rule-analysis-manually } 

![](resources/images/data_quality/validation_rule_analysis.png)

1.  Verify that you have created all the validation rules, validation
    rule groups and validation notifications you need.

2.  Open the **Data Quality** app and click **Validation rule
    analysis**.

3.  Seleccionar una **Fecha de inicio** y **Fecha de fin**.

4.  Select which **Validation rule group** you want to include in the
    analysis.

    You can select all validation rules or all validation rules from a
    single validation rule group.

5.  (Optional) Select **Send notifications** to trigger validation
    notifications.

    > **Note**
    >
    > If you want to send out validation notifications, you must first
    > create them in the **Maintenance** app.

6.  (Optional) Select *Persist new results* to persist any non-persisted
    results found during the analysis

7.  Seleccionar **padre de unidad organizativa**.

8.  Click en **Validar**.

    The analysis process duration depends on the amount of data that is
    being analysed. If there are no violations of the validation rules,
    you'll see a message saying *Validation passed successfully*. If
    there are validation violations, they will be presented in a
    list.

    ![](resources/images/data_quality/validation_rule_analysis_result.png)

9.  (Optional) Click the show details icon to get more information about
    a validation violation. In the pop-up window you'll find information
    about the data elements included in the validation rules and their
    corresponding data values. You can use this information to identify
    the source of the validation rule violation.

10. (Optional) Click **Download as PDF**, **Download as Excel** or
    **Download as CSV** to download the validation violations list in
    PDF, Excel or CSV formats.

### See also { #see-also } 

  - [Manage validation
    rules](https://docs.dhis2.org/master/en/user/html/manage_validation_rule.html)

  - [Data Administration
    app](https://docs.dhis2.org/master/en/user/html/data_admin.html)

## Outlier detection { #outlier_detection } 

### About outlier detection { #about-outlier-detection } 

The outlier detection tool identifies values which are
numerically distant from the rest of the data, potentially indicating that they are outliers.
The analysis is based on the standard normal distribution. DHIS 2 calculates the mean of
all values for an organisation unit, data element, category option
combination and attribute option combination.

> **Note**
>
>  As indicated above, this data quality analysis is only appropriate for 
>  data which is normally distributed. Data with large seasonal
>  variation, or which may be distributed according to other statistical models
>  (e.g. logistical ) may lead values being flagged which actually should be considered valid. 
>  It is therefore recommended to first confirm whether the data actually is normally 
>  distributed before running a standard deviation outlier analysis.

### Run outlier detection { #run-outlier-detection } 

![](resources/images/data_quality/std_dev_analysis.png)

1.  Abrir la aplicación **Calidad de datos** y click en **Detección de valores atípicos**.

2.  Seleccionar uno o varios sets de datos.

3.  Seleccionar **Unidad organizativa**.

    Se pueden seleccionar varias unidades organizativas. El análisis se realiza sobre datos brutos para todas las unidades organizativas en la sub-jerarquía de las unidades seleccionadas, no sobre datos agregados.

4.  Seleccionar **Desde la fecha** y **Hasta la fecha**.

5.  Set the **Algorithm** to use. 

    **Z-score** (basado en la media de los valores de datos), **Z-score modificado** (basado en la mediana de los valores de datos) y **Valores mín-máx** (basado en valores de datos mínimo-máximo almacenados) son algoritmos disponibles.

6. Seleccionar un **Umbral**.

   Esto se refiere al número de desviaciones estándar que los datos pueden desviarse de la media antes de clasificarlos como valores atípicos.

7. Seleccionar **Resultados máximos**

   Esto se refiere al número máximo de valores atípicos enumerados en los resultados.

8. (Opcional) Seleccione una **Fecha de inicio de datos** y **Fecha de fin de datos**.

   Estos campos se pueden utilizar para realizar análisis de detección de valores atípicos en un subconjunto de datos dentro del rango de fechas proporcionado. Cuando se deja en blanco, se utilizará la fecha natural de inicio y fin del set de datos _(en la sección avanzada)_.

9. (Opcional) Seleccione una medida para **Ordenar por**.

   Los valores atípicos se pueden ordenar por **Z-score** o por **Desviación absoluta de la media** _(En la sección avanzada)_.

10. Click en **Iniciar**
    The analysis process duration depends on the amount of data that is    being analysed. If there are standard deviations outliers, they will be presented in a list.
    ![](resources/images/data_quality/std_dev_analysis_outlier_result.png)
    For each outlier, you will see the data element, period, organisation unit, value, z-score, deviation, standard deviation, mean, min, and max. The minimum and maximum values refer to the border values derived from the number of standard deviations selected for the analysis.

11. (Opcional) Click en **Descargar como CSV** para descargar la lista en formato CSV.

> **Consejo**
>
> Click en la casilla de verificación para marcar un valor atípico para su posterior seguimiento.

## Minimum maximum outlier detection { #min_max_outlier_detection } 

### About minimum maximum value based outlier detection { #about-minimum-maximum-value-based-outlier-detection } 

You can verify the data quality at the point of data entry by setting a
minimun/maximum value range for each data value. You can define the value
ranges manually or generate them automatically.

The auto-generated minimum maximum value range is suitable only for
normally distributed data. DHIS2 will determine the arithmetic mean and
standard deviation of all values for a given data element, category
option, organisation unit and attribute combination. Then the system
will calculate the minimum maximum value range based on the **Data
analysis std dev factor** specified in the **System Settings** app.

For data which is highly-skewed or zero inflated (as is often the case
with aggregate data), the values which DHIS2 auto-generates may not
provide an accurate minimum maximum value range. This can lead to
excessive false violations, for example if you analyse values related to
seasonal diseases.

> **Note**
>
> Minimum maximum value ranges are calculated across all attribute
> combination options for a given data element, category option and
> organisation unit combination.

### Workflow { #workflow } 

1.  Create a minimum maximum value range, either automatically or
    manually.

      - In the **Data Administration** app, you generate value ranges
        automatically.

      - In the **Data Entry** app, you may set value ranges manually. 

2.  En la aplicación **Calidad de datos**, ejecute el **Análisis de valores atípicos mín.-máx.**.

### Configure a minimum maximum outlier detection { #configure-a-minimum-maximum-outlier-detection } 

#### Create minimum maximum value range automatically { #create-minimum-maximum-value-range-automatically } 

> **Note**
>
> Auto-generated minimum maximum value ranges can be useful for many
> situations, but it's recommended to verify that the data is actually
> normally distributed prior to using this function.

You generate minimum maximum value ranges calculated by data set in the
**Data Administration** app. The new value ranges override any value
ranges that the system has calculated previously.

1.  Establezca el **factor de desviación estándar de análisis de datos (std dev)**:

    1.  Abrir la aplicación **Configuración del sistema** y click en **General**.

    2.  En el campo **Factor de desviación estándar de análisis de datos** (Data analysis std dev factor), introduzca un valor.

        This sets the number of standard deviations to use in the
        outlier analysis. The default value is 2. Higher values
        indicate a broader distribution, which may lead to outliers
        not being flagged correctly by the analysis. 

2.  Abrir la aplicación **Administración de datos** y click en **Generación de valor mínimo-máximo**.

3.  Seleccionar el (los) set(s) de dato(s).

4.  Seleccionar una **Unidad organizativa**.

5.  Click en **Generar**.

    New minimum maximum value ranges for all data elements in the
    selected data sets for all organisation units (including
    descendants) of the selected organisation units are generated.

#### Create minimum/maximum value range manually { #create-minimummaximum-value-range-manually } 

![](resources/images/data_quality/set_min_max_manually.png)

1.  En la aplicación **Entrada de datos**, abra un formulario de entrada de datos.

2.  Haga doble click en el campo para el que desea establecer el rango de valor mínimo/máximo.

3.  Introduzca **límite mínimo** y **límite máximo** en el cuadro de diálogo que aparece.

4.  Click en **Guardar**.

    If values don't fall within the new value range the next time you
    enter data, the data entry cell will appear with an orange
    background.

5.  (Optional) Type a comment to explain the reason for the discrepancy,
    for example an event at a facility which may have generated a large
    number of clients.

6.  (Opcional) Click en **Guardar comentario**.

> **Consejo**
>
> Click en el icono de estrella para marcar el valor para seguimiento posterior.

#### Delete minimum maximum value range { #delete-minimum-maximum-value-range } 

You can permanently delete all minimum maximum value ranges for selected
data sets and organisation units in the **Data Administration** app.

1.  Abrir la aplicación **Administración de datos** y click en **Generación de valor mínimo-máximo**.

2.  Seleccionar el (los) set(s) de dato(s).

3.  Select an **Organisation unit**. Note, that the selection cascades to 
    descendant organisation units!

4.  Click en **Eliminar**.

### Run a minimum maximum outlier detection { #run-a-minimum-maximum-outlier-detection } 

![](resources/images/data_quality/min_max_analysis.png)

1.  Verifique que haya creado rangos de valores mínimos y máximos.

2.  Abrir la aplicación **Calidad de datos** y click en **Detección de valores atípicos**.

3.  Seleccionar el (los) set(s) de dato(s).

4.  Seleccionar **padre de unidad organizativa**.

    Se pueden seleccionar varias unidades organizativas. El análisis se realiza sobre datos brutos para todas las unidades organizativas en la sub-jerarquía de las unidades seleccionadas, no sobre datos agregados.

5.  Seleccionar **Desde la fecha** y **Hasta la fecha**.

6.  Establecer **Algoritmo** en **Valores mínimo-máximo**.

7.  Seleccionar **Resultados máximos**

    Esto se refiere al número máximo de valores atípicos enumerados en los resultados.

8.  Click en **Iniciar**

    The analysis process duration depends on the amount of data that is
    being analysed. If there are standard deviations outliers, they will
    be presented in a list.

    ![](resources/images/data_quality/min_max_result.png)

    For each outlier, you will see the data element, period, organisation unit,
    value, deviation, min, and max.

9.  (Opcional) Click en **Descargar como CSV** para descargar la lista en formato CSV.

> **Consejo**
>
> Click en la casilla de verificación para marcar el valor para un seguimiento posterior.

## Follow-up analysis { #follow_up_analysis } 

### About follow-up analysis { #about-follow-up-analysis } 

The follow-up analysis creates a list of all data values marked for
follow-up. You can mark a data value for follow-up in the **Data Entry**
app and in the result list you get from a standard deviation outlier or
minimum maximum outlier analysis.

### Create list of data values marked for follow-up { #create-list-of-data-values-marked-for-follow-up } 

![](resources/images/data_quality/follow_up_analysis.png)

1.  Abrir la aplicación **Calidad de datos** y click en **Análisis por seguimiento**.

2.  Seleccionar un set de datos o varios sets de datos.

3.  Seleccionar **Unidad organizativa**.

    Se pueden seleccionar varias unidades organizativas. El análisis se realiza sobre datos brutos "bajo" la unidad organizativa, no sobre datos agregados.

4. Select a **Start Date** and **End Date** which defines the periods which you are interested in looking for values which have been marked for follow up. 

4. Press **Follow up** to generate a list of values which have been marked for follow up. 

5.  (Opcional) Haga click en **Descargar como PDF**, **Descargar como Excel** o **Descargar como CSV** para descargar la lista de infracciones de validación en formato PDF, Excel o CSV.

![](resources/images/data_quality/follow_up_analysis_result.png)

> **Tip**
>
> Check the **Unfollow** checkbox in the list and click the **Unfollow**-button to remove the follow-up tags from the marked data values.
> You can also enter a comment in the field to indicate any additional 
> information regarding the value.

