---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/master/src/sysadmin/installation.md"
revision_date: '2024-04-05'
tags:
- DHIS核心 主版
- Manage
---

# 安装 { #installation } 

安装章节提供了有关如何在以下位置安装DHIS2的信息
各种环境，包括在线中央服务器，离线本地
网络，独立应用程序和称为DHIS2的自包含程序包
生活。

## 介绍 { #install_introduction } 

DHIS2 可以在所有存在 Java JDK 的平台上运行，其中包括最流行的操作
Windows、Linux 和 Mac 等系统。 DHIS2 在 PostgreSQL 上运行
数据库系统。 DHIS2 被打包为标准 Java Web Archive
（WAR 文件），因此可以在任何 Servlet 容器（例如 Tomcat 和
码头。

DHIS2 团队推荐 Ubuntu 18.04 LTS 操作系统、PostgreSQL
数据库系统和Tomcat Servlet容器为首选
服务器安装环境。

本章提供了设置上述技术堆栈的指南。
但是，应将其作为起步和运行的指南，而不是
作为上述环境的详尽文档。我们提到
到官方的Ubuntu，PostgreSQL和Tomcat文档进行深入了解
阅读。

`dhis2-tools` Ubuntu 软件包可以自动执行中描述的许多任务
以下指南推荐给大多数用户，尤其是那些
不熟悉命令行或服务器管理。它
本指南的单独章节中对此进行了详细描述。

## 服务器规格 { #install_server_specifications } 

DHIS2是数据库密集型应用程序，需要您的服务器
具有适当数量的RAM，CPU核心数量和快速磁盘。
这些建议应被视为经验法则，而不是
确切的措施。 DHIS2在RAM的数量和数量上线性扩展
CPU内核，因此您负担得起的费用越多，应用程序的性能就会越好。

- * RAM：*小型实例至少2 GB，中型实例至少12 GB，大型实例至少64 GB。
- *CPU 核心数：* 小型实例 4 个 CPU 核心，中型实例 8 个 CPU 核心，大型实例 16 个或更多 CPU 核心。
- *磁盘：*建议将SSD用作存储设备。最低要求
  读取速度为150 Mb / s，200 Mb / s好，350 Mb / s或更高
  理想的。建议至少 100 GB 存储空间，但是
  将完全取决于其中包含的数据量
  数据值表。 Analytics（分析）表格需要大量
  储存空间。提前计划并确保您的服务器可以升级
  根据需要具有更多的磁盘空间。

## 软件需求 { #install_software_requirements } 

更高版本的DHIS2需要以下软件版本才能运行。

- An operating system for which a Java JDK or JRE version 17 exists. Linux is recommended.
- Java JDK。推荐使用OpenJDK。


Table: DHIS2 JDK compatibility

| DHIS2 version | JDK recommended | JDK required |
|---------------|-----------------|--------------|
| 2.41          | 17              | 17           |
| 2.40          | 17              | 11           |
| 2.38          | 11              | 11           |
| 2.35          | 11              | 8            |
| pre 2.35      | 8               | 8            |


- PostgreSQL database version 9.6 or later. A later PostgreSQL version such as version 14 is recommended.
- PostGIS数据库扩展版本2.2或更高版本。
- Tomcat Servlet容器版本8.5.50或更高版本，或其他Servlet API
  3.1兼容的servlet容器。
- 仅群集设置（可选）：Redis数据存储版本4或更高版本。

## 服务器设置 { #install_server_setup } 

This section describes how to set up a server instance of DHIS2 on
Ubuntu 18.04 64 bit with PostgreSQL as database system and Tomcat as
Servlet container. This guide is not meant to be a step-by-step guide
per se, but rather to serve as a reference to how DHIS2 can be deployed
on a server. There are many possible deployment strategies, which will
differ depending on the operating system and database you are using, and
other factors. The term *invoke* refers to executing a given command in
a terminal.

For this guide we assume that 8 Gb RAM is allocated for PostgreSQL and 8
GB RAM is allocated for Tomcat/JVM, and that a 64-bit operating system
is used. *If you are running a different configuration please adjust the
suggested values accordingly\!*

We recommend that the available memory
is split roughly equally between the database and the JVM. Remember to
leave some of the physical memory to the operating system for it to
perform its tasks, for instance around 2 GB. The steps marked as
*optional*, like the step for performance tuning, can be done at a later
stage.

### 创建一个用户来运行DHIS2 { #install_creating_user } 

您应该创建一个专用用户来运行DHIS2。

> **重要**
>
>您不应以root用户等特权用户身份运行DHIS2服务器。

通过调用以下命令创建一个名为dhis的新用户：

```sh
sudo useradd -d / home / dhis -m dhis -s / bin / false
```

然后为您的帐户调用设置密码：

```sh
须藤密码
```

确保设置了一个安全密码，该密码至少包含15个随机字符。

### 创建配置目录 { #install_creating_config_directory } 

首先为DHIS2配置创建合适的目录
文件。此目录还将用于应用程序，文件和日志文件。
示例目录可以是：

```sh
sudo mkdir /home/dhis/config
sudo chown dhis:dhis /home/dhis/config
```

DHIS2 will look for an environment variable called `DHIS2_HOME` to
locate the DHIS2 configuration directory. This directory will be
referred to as `DHIS2_HOME` in this installation guide. We will define
the environment variable in a later step in the installation process.

If no environment variable `DHIS2_HOME` is found, the default 
configuration file location `/opt/dhis2` is used.

### 设置服务器时区和语言环境 { #install_setting_server_tz } 

可能需要重新配置服务器的时区以匹配
DHIS2服务器将覆盖的位置的时区。
如果您使用的是虚拟专用服务器，则默认时区可能不会
对应于您的DHIS2位置的时区。您可以轻松地
通过调用以下内容并按照以下说明重新配置时区
说明。

```sh
sudo dpkg-重新配置tzdata
```

PostgreSQL对语言环境敏感，因此您可能必须安装
地区优先。要检查现有的语言环境并安装新的语言环境（例如
挪威）：

```sh
语言环境-a
须藤locale-gen nb_NO.UTF-8
```

### PostgreSQL安装 { #install_postgresql_installation } 

通过以下方式安装PostgreSQL
    调用：

```sh
sudo apt-get install -y postgresql-12 postgresql-12-postgis-3
```

通过调用以下命令创建一个名为* dhis *的非特权用户：

```sh
须藤-u postgres createuser -SDRP dhis
```

在提示符下输入安全密码。通过调用创建数据库：

```sh
须藤-u postgres createdb -O dhis dhis2
```

通过调用`exit`返回您的会话现在您有一个PostgreSQL用户
称为* dhis *和一个名为* dhis2 *的数据库。

* PostGIS *扩展是多种GIS /映射功能所必需的
工作。 DHIS 2将尝试在安装过程中安装PostGIS扩展
启动。如果DHIS 2数据库用户没有创建权限
您可以使用* postgres *用户从控制台创建扩展
使用以下命令：

```sh
sudo -u postgres psql -c“创建扩展名postgis;” dhis2
```

For adding trigram indexes and compounding it with primitive column types, two extensions have to be created in the database for DHIS 2 verision 2.38 and later. The extensions are already part of the default posgresql installation:

```sh
sudo -u postgres psql -c "create extension btree_gin;" dhis2
sudo -u postgres psql -c "create extension pg_trgm;" dhis2
```

退出控制台，并使用* \\ q *并返回到先前的用户
*出口*。

### PostgreSQL性能调优 { #install_postgresql_performance_tuning } 

Tuning PostgreSQL is required to achieve a high-performing system but
is optional in terms of getting DHIS2 to run. The various settings can be
specified in the `postgresql.conf` configuration file or, preferably, in a specific
file in the `conf.d` directory. The settings is based on allocating 8 GB RAM to
PostgreSQL and should be adjusted accordingly to the environment.

```sh
须藤nano /etc/postgresql/12/main/postgresql.conf
```

Set the following properties.

```properties
jit = off
```

This is important to set for postgresql versions 12 and greater.  The jit compiler 
functionality causes a significant slowdown on many DHIS2 specific queries, eg 
Program Indicator queries.  For versions 11 and below, the setting is off by default.

```属性
max_connections = 200
```

确定PostgreSQL允许的最大连接数。

```properties
shared_buffers = 3GB
```

确定应专门分配多少内存
PostgreSQL缓存。此设置控制共享内核的大小
应该为PostgreSQL保留的内存。应该设置为
PostgreSQL专用内存的40％。

```properties
work_mem = 24MB
```

确定用于内部排序和哈希的内存量
操作。此设置是针对每个连接，针对每个查询的，因此需要大量内存
如果将其提高得太高，可能会被消耗掉。正确设置该值
对于DHIS2聚合性能至关重要。

```properties
maintenance_work_mem = 1GB
```

确定PostgreSQL可用于维护的内存量
创建索引，运行真空，添加外部文件等操作
键。增大此值可能会提高索引创建的性能
在分析生成过程中。

```properties
temp_buffers = 16MB
```

Sets the maximum number of temporary buffers used by each database 
session. These are session-local buffers used only for access to temporary 
tables. 

```properties
effective_cache_size = 8GB
```

An estimate of how much memory is available for disk caching by the
operating system (not an allocation) and is used by PostgreSQL to
determine whether a query plan will fit into memory or not. Setting it
to a higher value than what is really available will result in poor
performance. This value should be inclusive of the `shared_buffers`
setting. PostgreSQL has two layers of caching: The first layer uses the
kernel shared memory and is controlled by the shared\_buffers setting.
PostgreSQL delegates the second layer to the operating system disk cache
and the size of available memory can be given with the
`effective_cache_size` setting.

```属性
checkpoint_completion_target = 0.8
```

设置WAL写过程中用于缓冲的内存。
增大此值可能会提高大量写入系统的吞吐量。

```属性
sync_commit =关
```

指定事务提交是否将等待WAL记录
是否将其写入磁盘，然后再返回客户端。设定这个
关闭将大大提高性能。这也意味着那里
交易之间的轻微延迟被报告为成功
客户端，它实际上是安全的，但是数据库状态不能为
已损坏，这是性能密集型和
像DHIS2这样的重写入系统。

```properties
wal_writer_delay = 10s
```

指定WAL写操作之间的延迟。将此设置为较高
价值可能会提高大量写入系统的性能，因为
一次刷新到磁盘就可以执行许多写操作。

```属性
random_page_cost = 1.1
```

*仅SSD。*设置查询计划程序对非连续获取的磁盘页面的成本的估计。较低的值将导致系统比顺序扫描更喜欢索引扫描。对于在SSD上运行的数据库或在内存中大量缓存的数据库，较低的值有意义。默认值为4.0，这对于传统磁盘而言是合理的。

```属性
max_locks_per_transaction = 96
```

指定为每个事务分配的对象锁的平均数量。设置该参数主要是为了允许完成涉及大量表的升级例程。

```properties
track_activity_query_size = 8192
```

Specifies the number of bytes reserved to track the currently executing command for each active session. Useful to view the full query string for monitoring of currently running queries.

```properties
jit = off
```

This setting turns the jit optimizer off.  It should be set to off for postgresql versions 12 and upwards.  Many queries, particularly program indicator queries, perform very badly with the default enabled jit setting.  Turning it off can improve response times by up to 100x with resulting significant improvement in dashboard performance.

通过调用以下命令来重新启动PostgreSQL：

```sh
sudo systemctl restart postgresql
```

### Java安装 { #install_java_installation } 

The recommended Java JDK for DHIS 2 is OpenJDK 17 (for version 2.40 and later). You can install it with the following command:

```
sudo apt-get install -y openjdk-17-jdk
```

通过调用以下命令来验证安装是否正确：

```
Java版本
```

### DHIS2配置 { #install_database_configuration } 

The database connection information is provided to DHIS2 through a
configuration file called `dhis.conf`. Create this file and save it in
the `DHIS2_HOME` directory. As an example this location could be:

```sh
/home/dhis/config/dhis.conf
```

与上述设置相对应的PostgreSQL配置文件具有
这些属性：

```properties
# ----------------------------------------------------------------------
# Database connection
# ----------------------------------------------------------------------

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password
connection.password = xxxx

# ----------------------------------------------------------------------
# Server
# ----------------------------------------------------------------------

# Enable secure settings if deployed on HTTPS, default 'off', can be 'on'
# server.https = on

# Server base URL
# server.base.url = https://server.com
```

强烈建议启用`server.https`设置并使用加密的HTTPS协议部署DHIS 2。此设置将启用例如安全cookie。启用此设置后，需要进行HTTPS部署。

`server.base.url`设置是指最终用户通过网络访问系统的URL。

Note that the configuration file supports environment variables. This
means that you can set certain properties as environment variables and
have them resolved, e.g. like this where `DB\_PASSWD` is the
name of the environment variable:

```属性
connection.password = $ {DB_PASSWD}
```

请注意，此文件包含您的DHIS2数据库的密码（以明文形式）
文本，因此需要对其进行保护，以防止未经授权的访问。去做这个，
调用以下命令，以确保仅允许* dhis *用户读取它：

```sh
chmod 600 dhis.conf
```

### Tomcat和DHIS2安装 { #install_tomcat_dhis2_installation } 

要安装Tomcat Servlet容器，我们将利用Tomcat用户
通过调用打包：

```sh
sudo apt-get install -y tomcat8-user
```

这个包让我们可以轻松创建一个新的 Tomcat 实例。实例
将在当前目录中创建。合适的位置是
`dhis` 用户的主目录：

```sh
sudo tomcat8-instance-create /home/dhis/tomcat-dhis
sudo chown -R dhis:dhis /home/dhis/tomcat-dhis/
```

This will create an instance in a directory called `tomcat-dhis`. Note
that the `tomcat8-user` package allows for creating any number of DHIS2
instances if that is desired.

Next edit the file `tomcat-dhis/bin/setenv.sh` and add the lines below.

* `JAVA_HOME` 设置 JDK 安装的位置。
* `JAVA_OPTS` 将参数传递给 JVM。
    * `-Xms` 将内存的初始分配设置为 Java 堆内存空间。
    * `-Xmx` 设置向 Java 堆内存空间分配的最大内存。这应该反映出您希望分配给服务器上的 DHIS 2 软件应用程序的内存量。
* `DHIS2_HOME` 设置 DHIS 2 的 `dhis.conf` 配置文件的位置。

检查 Java 二进制文件的路径是否正确，因为它们可能因系统而异，例如在 AMD 系统上您可能会看到
`/java-11-openjdk-amd64`。请注意，您应该根据您的环境调整这些值。

```sh
JAVA_HOME='/usr/lib/jvm/java-11-openjdk-amd64/'
JAVA_OPTS='-Xms4000m -Xmx7000m'
DHIS2_HOME='/home/dhis/config'
```

Tomcat的配置文件位于
`tomcat-dhis/conf/server.xml`。定义连接的元素
DHIS 是端口 8080 的 *Connector* 元素。您可以更改
如有必要，将连接器元素中的端口号更改为所需端口。
`relaxedQueryChars` 属性是允许某些字符所必需的
在 DHIS2 前端使用的 URL 中。

```xml
<Connector port="8080" protocol="HTTP/1.1"
  connectionTimeout="20000"
  redirectPort="8443"
  relaxedQueryChars="[]" />
```

下一步是下载 DHIS2 WAR 文件并将其放入
Tomcat 的 _webapps_ 目录。您可以从以下位置下载 DHIS2 WAR 文件：

```sh
https://releases.dhis2.org/
```

Move the WAR file into the Tomcat `webapps` directory. We want to call the
WAR file `ROOT.war` in order to make it available at `localhost` directly
without a context path:

```sh
mv dhis.war tomcat-dhis / webapps / ROOT.war
```

DHIS2 决不应该作为特权用户运行。修改后
`setenv.sh 文件`，修改启动脚本以检查并验证
脚本尚未以 root 身份调用。

```sh
＃！/ bin / sh
设置-e

如果[“ $（id -u）” -eq“ 0”];然后
  回声“此脚本不能以root用户身份运行” 1>＆2
  1号出口
科幻

导出CATALINA_BASE =“ / home / dhis / tomcat-dhis”
/usr/share/tomcat8/bin/startup.sh
回显“ Tomcat启动”
```

### 运行DHIS2 { #install_running_dhis2 } 

DHIS2现在可以通过调用来启动：

    须藤-u dhis tomcat-dhis / bin / startup.sh

> **重要**
>
>绝对不要以root或其他特权用户身份运行DHIS2服务器。

DHIS2可以通过调用来停止：

    须藤-u dhis tomcat-dhis / bin / shutdown.sh

要监视Tomcat的行为，日志是该日志的主要来源
信息。可以使用以下命令查看日志：

    尾巴-f tomcat-dhis / logs / catalina.out

假设WAR文件名为ROOT.war，您现在可以访问
DHIS2实例位于以下URL：

    http://localhost:8080

## 文件存储配置 { #install_file_store_configuration } 

DHIS2 能够捕获和存储文件。默认情况下，文件将
存储在运行 DHIS2 的服务器的本地文件系统上的 *files* 中
`DHIS2_HOME` 外部目录位置下的目录。

您还可以配置 DHIS2 将文件存储在基于云的存储上
提供商。 AWS S3 是当前唯一受支持的提供商。启用
基于云的存储您必须定义以下附加属性
在你的 `dhis.conf` 文件中：

```属性
＃文件存储提供者。当前支持“文件系统”和“ aws-s3”。
filestore.provider ='aws-s3'

＃本地文件系统上外部目录中的目录，AWS S3上存储桶
filestore.container =文件

＃以下配置仅适用于云存储（AWS S3）

＃数据中心位置。可选，但出于性能原因建议使用。
filestore.location = eu-west-1

＃AWS S3上的用户名/访问密钥
filestore.identity = xxxx

＃AWS S3上的密码/密钥（敏感）
filestore.secret = xxxx
```

此配置是反映默认设置的示例，应为
根据您的需要进行了更改。换句话说，如果
您计划使用默认值。如果您想使用外部
提供者，需要定义最后一个属性块，以及
* provider *属性设置为受支持的提供程序（仅当前
AWS S3）。

> **注意**
>
>如果您在dhis.conf中配置了云存储，则上传的所有文件
>或系统生成的文件将使用云存储。

对于生产系统，文件存储的初始设置应为
被仔细考虑为在存储提供商之间移动文件，而
保持数据库引用的完整性可能很复杂。保持
请记住，文件存储的内容可能包含敏感内容，
以及完整的信息，并保护对文件夹以及
建议在生产中确保备份计划到位
实施。

> **注意**
>
> AWS S3是唯一受支持的提供商，但可能会有更多提供商
>将来添加，例如Google Cloud Store和Azure Blob存储。
>让我们知道您是否还有其他提供商的用例。

## Google服务帐户配置 { #install_google_service_account_configuration } 

DHIS2 can connect to various Google service APIs. For instance, the
DHIS2 Maps app can utilize the Google Earth Engine API to load Earth Engine map
layers. There are 2 ways to obtain the Google API key.

### Set it up yourself { #set-it-up-yourself } 

Set up a Google service account and create a private key:

  - 创建一个Google服务帐户。请咨询[Google身份
    平台]（https://developers.google.com/identity/protocols/OAuth2ServiceAccount#overview）
    文档。

  - 访问[Google云控制台]（https://console.cloud.google.com）
    并转到API Manager \>凭据\>创建凭据\>
    服务帐户密钥。选择您的服务帐户和JSON作为密钥
    键入并单击创建。

  - 将JSON密钥重命名为* dhis-google-auth.json *。

After downloading the key file, put the `dhis-google-auth.json` file in
the `DHIS2_HOME` directory (the same location as the `dhis.conf` file).
As an example this location could be:

    /home/dhis/config/dhis-google-auth.json

### Send an email to set up the Google Earth Engine API key { #send-an-email-to-set-up-the-google-earth-engine-api-key } 

If you only intend to use the key for the Google Earth Engine map layers,
you can simply send an email. See the [Google Earth Engine API key documentation](https://docs.dhis2.org/en/topics/tutorials/google-earth-engine-sign-up.html).

## Bing Maps API key { #install_bing_maps_api_key }

To enable use of Bing Maps basemap layers, you need to set up the Bing Maps API key. See [Bing Maps API key documentation](https://www.microsoft.com/en-us/maps/bing-maps/create-a-bing-maps-key) for information on setting up the key.

## OpenID Connect（OIDC）配置 { #install_oidc_configuration } 

DHIS2 supports the OpenID Connect (OIDC) identity layer for single sign-in (SSO). OIDC is a standard authentication protocol that lets users sign in with an identity provider (IdP) such as for example Google. After users have successfully signed in to their IdP, they will be automatically signed in to DHIS2.

This section provides general information about using DHIS2 with an OIDC provider, as well as complete configuration examples.

The DHIS2 OIDC 'authorization code' authentication flow:

1. A user attempts to log in to DHIS2 and clicks the OIDC provider button on the login page.

2. DHIS2 redirects the browser to the IdP's login page.

3. If not already logged in, the user is prompted for credentials. When successfully authenticated, the IdP responds with a redirect back to the DHIS2 server. The redirect includes a unique authorization code generated for the user.

4. The DHIS2 server internally sends the user's authorization code back to the IdP server along with its own client id and client secret credentials.

5. The IdP returns an ID token back to the DHIS2 server. DHIS2 server performs validation of the token.

6. The DHIS2 server looks up the internal DHIS2 user with the mapping claims found in the ID token (defaults to email), authorizes the user and completes the login process.

### Requirements for using OIDC with DHIS2: { #requirements-for-using-oidc-with-dhis2 } 

#### IdP server account { #idp-server-account } 

You must have an admin account on an online identity provider (IdP) or on a standalone server that are supported by DHIS2.

The following IdPs are currently supported and tested:

* 谷歌
* Azure AD
* WSO2
* Okta (See separate tutorial: [here](#configure-openid-connect-with-okta))

There is also a **generic provider** config which can support "any" OIDC compatible provider.

#### DHIS2 user account { #dhis2-user-account } 

You must explicitly create the users in the DHIS2 server before they can log in with the identity provider. Importing them from an external directory such as Active Directory is currently not supported. Provisioning and management of users with an external identity store is not supported by the OIDC standard.

#### 用户的IdP声明和映射 { #idp-claims-and-mapping-of-users } 

To sign in to DHIS2 with OIDC, a given user must be provisioned in the IdP and then mapped to a pre created user account in DHIS2. OIDC uses a method that relies on claims to share user account attributes with other applications. Claims include user account attributes such as email, phone number, name, etc. DHIS2 relies on a IdP claim to map user accounts from the IdP to those in the DHIS2 server. By default, DHIS2 expects the IdP to pass the _email_ claim. Depending on your IdP, you may need to configure DHIS2 to use a different IdP claim.

If you are using Google or Azure AD as an IdP, the default behavior is to use the _email_ claim to map IdP identities to DHIS2 user accounts.

> **Note**
>
> In order for a DHIS2 user to be able to log in with an IdP, the user profile checkbox: *External authentication only OpenID or LDAP* must be checked and *OpenID* field must match the claim (mapping claim) returned by the IdP. Email is the default claim used by both Google and Azure AD.

### 为OIDC配置身份提供者 { #configure-the-identity-provider-for-oidc } 

This topic provides general information about configuring an identity provider (IdP) to use OIDC with DHIS2. This is one step in a multi-step process. Each IdP has slightly different ways to configure it. Check your IdP's own documentation for how to create and configure an OIDC application. Here we refer to the DHIS2 server as the OIDC "application".

#### 重定向网址 { #redirect-url } 

All IdPs will require a redirect URL to your DHIS2 server. 
You can construct it using the following pattern:

```
(protocol):/(your DHIS2 host)/oauth2/code/PROVIDER_KEY
```

Example when using Google IdP:

```
https://mydhis2-server.org/oauth2/code/google
```

External links to instructions for configuring your IdP:

* [Google](https://developers.google.com/identity/protocols/oauth2/openid-connect)
* [Azure AD tutorial](https://medium.com/xebia-engineering/authentication-and-authorization-using-azure-active-directory-266980586ab8)


### Example setup for Google { #example-setup-for-google } 

1. Register an account and sign in. For example, for Google, you can go to the Google [developer console](https://console.developers.google.com).
2. In the Google developer dashboard, click 'create a new project'.
3. Follow the instructions for creating an OAuth 2.0 client ID and client secret.
4. Set your "Authorized redirect URL" to: `https://mydhis2-server.org/oauth2/code/google`
5. Copy and keep the "client id" and "client secret" in a secure place.

> **Tip**
>
> When testing on a local DHIS2 instance running for example on your laptop, you can use localhost as the redirect URL, like this: `https://localhost:8080/oauth2/code/google`
> *Remember to also add the redirect URL in the Google developer console*

#### Google dhis.conf example: { #google-dhisconf-example } 
```properties

# Enables OIDC login
oidc.oauth2.login.enabled = on

# Client id, given to you in the Google developer console
oidc.provider.google.client_id = my client id

# Client secret, given to you in the Google developer console
oidc.provider.google.client_secret = my client secret

# [Optional] Authorized redirect URI, the same as set in the Google developer console 
# If your public hostname is different from what the server sees internally, 
# you need to provide your full public url, like the example below.
oidc.provider.google.redirect_url = https://mydhis2-server.org/oauth2/code/google

# [Optional] Where to redirect after logging out.
# If your public hostname is different from what the server sees internally, 
# you need to provide your full public url, like the example below. 
oidc.logout.redirect_url = https://mydhis2-server.org

```

### Example setup for Azure AD { #example-setup-for-azure-ad } 

Make sure your Azure AD account in the Azure portal is configured with a redirect URL like: `(protocol):/(host)/oauth2/code/PROVIDER_KEY`. 
To register your DHIS2 server as an "application" in the Azure portal, follow these steps:

> **Note**
>
> PROVIDER_KEY is the "name" part of the configuration key, example: "oidc.provider.PROVIDER_KEY.tenant = My Azure SSO"
> If you have multiple Azure providers you want to configure, you can use this name form: (azure.0), (azure.1) etc.
> Redirect URL example: https://mydhis2-server.org/oauth2/code/azure.0

1. 搜索并选择*应用程序注册*。
2. 点击*新注册*。
3. In the *Name* field, enter a descriptive name for your DHIS2 instance.
4. In the *Redirect URI* field, enter the redirect URL as specified above.
5. 点击*注册*。

#### Azure AD dhis.conf example: { #azure-ad-dhisconf-example } 
```properties

# Enables OIDC login
oidc.oauth2.login.enabled = on

# First provider (azure.0):

# Alias, or name that will show on the login button in the DHIS2 login screen.
oidc.provider.azure.0.tenant = organization name

# Client id, given to you in the Azure portal
oidc.provider.azure.0.client_id = my client id

# Client secret, given to you in the Azure portal
oidc.provider.azure.0.client_secret = my client secret

# [Optional] Authorized redirect URI, the as set in Azure portal 
# If your public hostname is different from what the server sees internally, 
# you need to provide your full public url, like the example below.
oidc.provider.azure.0.redirect_url = https://mydhis2-server.org/oauth2/code/azure.0

# [Optional] Where to redirect after logging out.
# If your public hostname is different from what the server sees internally, 
# you need to provide your full public URL, like the example below.
oidc.logout.redirect_url = https://mydhis2-server.org

# [Optional], defaults to 'email'
oidc.provider.azure.0.mapping_claim = email

# [Optional], defaults to 'on'
oidc.provider.azure.0.support_logout = on


# Second provider (azure.1):

oidc.provider.azure.1.tenant = other organization name
...
```

### Generic providers { #generic-providers } 

The generic provider can be used to configure "any" standard OIDC provider which are compatible with "Spring Security".

在下面的示例中，我们将使用提供商密钥`helseid`配置挪威政府 _HelseID_ OIDC 提供商。

The defined provider will appear as a button on the login page with the provider key as the default name, 
or the value of the `display_alias` if defined. The provider key is arbitrary and can be any alphanumeric string, 
except for the reserved names used by the specific providers (`google`, `azure.0,azure.1...`, `wso2`).

> **Note**
> The generic provider uses the following hardcoded configuration defaults:
> **(These are not possible to change)**
> * Client Authentication, `ClientAuthenticationMethod.BASIC`: [rfc](https://tools.ietf.org/html/rfc6749#section-2.3)
> * Authenticated Requests, `AuthenticationMethod.HEADER`: [rfc](https://tools.ietf.org/html/rfc6750#section-2) 

#### Generic (helseid) dhis.conf example: { #generic-helseid-dhisconf-example } 

```properties

# Enables OIDC login
oidc.oauth2.login.enabled = on

# Required variables:
oidc.provider.helseid.client_id = CLIENT_ID
oidc.provider.helseid.client_secret = CLIENT_SECRET
oidc.provider.helseid.mapping_claim = helseid://claims/identity/email
oidc.provider.helseid.authorization_uri = https://helseid.no/connect/authorize
oidc.provider.helseid.token_uri = https://helseid.no/connect/token
oidc.provider.helseid.user_info_uri = https://helseid.no/connect/userinfo
oidc.provider.helseid.jwk_uri = https://helseid.no/.well-known/openid-configuration/jwks
oidc.provider.helseid.end_session_endpoint = https://helseid.no/connect/endsession
oidc.provider.helseid.scopes = helseid://scopes/identity/email

# [Optional] Authorized redirect URI, the as set in Azure portal 
# If your public hostname is different from what the server sees internally, 
# you need to provide your full public url, like the example below.
oidc.provider.helseid.redirect_url = https://mydhis2-server.org/oauth2/code/helseid

# [Optional], defaults to 'on'
oidc.provider.helseid.enable_logout = on

# [Optional] Where to redirect after logging out.
# If your public hostname is different from what the server sees internally, 
# you need to provide your full public URL, like the example below.
oidc.logout.redirect_url = https://mydhis2-server.org

# [Optional] PKCE support, see: https://oauth.net/2/pkce/), default is 'false'
oidc.provider.helseid.enable_pkce = on

# [Optional] Extra variables appended to the request. 
# Must be key/value pairs like: "KEY1 VALUE1,KEY2 VALUE2,..."
oidc.provider.helseid.extra_request_parameters = acr_values lvl4,other_key value2

# [Optional] This is the alias/name displayed on the login button in the DHIS2 login page
oidc.provider.helseid.display_alias = HelseID

# [Optional] Link to an url for a logo. (Can use absolute or relative URLs)
oidc.provider.helseid.logo_image = ../security/btn_helseid.svg
# [Optional] CSS padding for the logo image
oidc.provider.helseid.logo_image_padding = 0px 1px
```

### JWT bearer token authentication { #jwt-bearer-token-authentication } 

Authentication with *JWT bearer tokens* can be enabled for clients which API-based when OIDC is configured. 
The DHIS2 Android client is such a type of client and have to use JWT authentication if OIDC login is enabled.

> **Note**
>
> DHIS2 currently only supports the OAuth2 authorization code grant flow for authentication with JWT, (also known as "three-legged OAuth")
> DHIS2 currently only supports using Google as an OIDC provider when using JWT tokens


### 要求 { #requirements } 
* Configure your Google OIDC provider as described above 
* Disable the config parameter ```oauth2.authorization.server.enabled``` by setting it to 'off'
* Enable the config parameter ```oidc.jwt.token.authentication.enabled``` by setting it to 'on'
* Generate an Android OAuth2 client_id as described [here](https://developers.google.com/identity/protocols/oauth2/native-app#creatingcred)

### JWT authentication example { #jwt-authentication-example } 

以下`dhis.conf`部分显示了如何为基于 API 的客户端启用 JWT 身份验证的示例。

```properties

# Enables OIDC login
oidc.oauth2.login.enabled = on

# Minimum required config variables:
oidc.provider.google.client_id = my_client_id
oidc.provider.google.client_secret = my_client_secret

# Enable JWT support
oauth2.authorization.server.enabled = off
oidc.jwt.token.authentication.enabled = on

# Define client 1 using JWT tokens
oidc.provider.google.ext_client.0.client_id = JWT_CLIENT_ID

# Define client 2 using JWT tokens
oidc.provider.google.ext_client.1.client_id = JWT_CLIENT_ID

```

> **Note**
>
> [Check out our tutorial for setting up Okta as a generic OIDC provider.](../../../topics/tutorials/configure-oidc-with-okta.md)

### Connecting a single identity provider account to multiple DHIS2 accounts { #connecting-a-single-identity-provider-account-to-multiple-dhis2-accounts } 

DHIS2 has the ability to map a single identity provider account to multiple DHIS2 accounts. API calls are available to list the linked accounts and also switch between then.

When this option is selected, the `openid` database field in the `userinfo` table does not need to be unique.  When presented with an `openid` value from the identity provider, DHIS2 will log in the user that most recently logged in.

The following `dhis.conf` section shows how to enable linked accounts.

```properties
# Enable a single OIDC account to log in as one of several DHIS2 accounts
linked_accounts.enabled = on
```

For instructions on how to list linked accounts and switch between them, see [*Switching between user accounts connected to the same identity provider account* in the Users chapter of the developer documentation.](../../../develop/using-the-api/dhis-core-version-master/users.html#switching-between-user-accounts-connected-to-the-same-identity-provider-account)

## LDAP配置 { #install_ldap_configuration } 

DHIS2能够使用LDAP服务器进行用户身份验证。
对于LDAP身份验证，要求在
每个LDAP条目的DHIS2数据库。 DHIS2用户将用于代表
权限/用户角色。

To set up LDAP authentication you need to configure the LDAP server URL,
a manager user and an LDAP search base and search filter. This
configuration should be done in the DHIS 2 configuration file `dhis.conf`. 
LDAP users, or entries, are identified by distinguished names 
(DN from now on). An example configuration looks like this:

```属性
＃LDAP服务器网址
ldap.url = ldaps：//domain.org：636

＃LDAP管理器条目专有名称
ldap.manager.dn = cn = johndoe，dc = domain，dc = org

＃LDAP管理员输入密码
ldap.manager.password = xxxx

＃LDAP基本搜索
ldap.search.base = dc = domain，dc = org

＃LDAP搜索过滤器
ldap.search.filter =（cn = {0}）
```

LDAP配置属性说明如下：

- * ldap.url：*要对其进行身份验证的LDAP服务器的URL
  反对。强烈建议使用SSL /加密，以便
  确保身份验证的安全性。例如，URL是
  * ldaps：//domain.org：636 *，其中ldaps是指协议，
  * domain.org *是指域名或IP地址，* 636 *
  指端口（LDAPS默认为636）。
- * ldap.manager.dn：*绑定到LDAP管理器用户是必需的
  用于用户身份验证过程的LDAP服务器。这个性质
  指该条目的DN。即这不是将
  登录DHIS2时需要认证，而不是
  绑定到LDAP服务器以进行身份验证。
- * ldap.manager.password：* LDAP管理器用户的密码。
- * ldap.search.base：*的搜索基础或专有名称
  搜索基础对象，它定义目录中的位置
  LDAP搜索从此开始。
- * ldap.search.filter：*用于匹配条目中DN的过滤器
  LDAP目录。 {0}变量将由DHIS2替换
  用户名，或者为用户定义的LDAP标识符
  使用提供的用户名。

DHIS2将使用提供的用户名/密码并尝试进行身份验证
针对LDAP服务器条目，然后从中查找用户角色/权限
相应的DHIS2用户。这意味着用户必须具有
LDAP目录中的匹配条目以及DHIS2用户，以便
登录。

在身份验证期间，DHIS2将尝试使用以下方式绑定到LDAP服务器：
配置的LDAP服务器URL以及管理员DN和密码。一旦
绑定完成后，它将使用以下命令在目录中搜索条目
配置的LDAP搜索库和搜索过滤器。

配置的过滤器中的{0}变量将在替换之前
应用过滤器。默认情况下，它将被提供的
用户名。您还可以在相关的
DHIS2用户帐户。可以通过DHIS2用户模块用户来完成
通过设置“ LDAP标识符”，在添加或编辑屏幕中找到界面
属性。设置后，LDAP标识符将替换为{0}
过滤器中的变量。 LDAP通用名称时，此功能很有用
不适合或由于某种原因不能用作DHIS2用户名。

## 加密配置 { #install_encryption_configuration } 

DHIS2 allows for encryption of data. Enabling it requires some extra
setup. To provide security to the encryption algorithm you will have to set a
password (key) in the `dhis.conf` configuration file through the
*encryption.password* property:

```属性
加密密码= xxxx
```

The *encryption.password* property is the password (key) used when encrypting
and decrypting data in the database.

If an encryption password is not defined in `dhis.conf`, a default password will be
used. Note that using the default password does not offer any added security due to 
the open source nature of DHIS 2.

Note that the password must not be changed once it has been set and data has been encrypted, as the data can then no longer be decrypted by the application.

密码必须至少为** 24个字符长**。混合数字
建议使用大小写字母。加密密码
必须保密。

> **重要**
>
>如果丢失或更改了加密密码，则无法恢复加密的数据。如果密码丢失，则加密的数据也会丢失。相反，如果
>密码已泄露。因此，应考虑将密码存储在安全的地方。

Note that since the encryption key is stored in the `dhis.conf` configuration file and not
within the database, when moving a database between server environments thorugh a dump and restore, the encryption key must be the same across environments to allow DHIS 2 to
decrypt database content.

Note that encryption support depends on the *Java Cryptography Extension* (JCE) policy files to be available. These are included in all versions of OpenJDK and Oracle JDK 8 Update 144 or later.

## 读取副本数据库配置 { #install_read_replica_configuration } 

DHIS 2允许利用主数据库的只读副本
（主DHIS 2数据库）。只读副本的目的是为了增强
数据库读取查询的性能并扩展容量
超越了单个数据库的限制。大量读取操作，例如
因为分析和事件查询将从中受益。

The configuration requires that you have created one or more replicated
instances of the master DHIS 2 database. PostgreSQL achieves this
through a concept referred to as *streaming replication*. Configuring
read replicas for PostgreSQL is not covered in this guide.

Read replicas can be defined in the `dhis.conf` configuration file. You
can specify up to 5 read replicas per DHIS 2 instance. Each read replica
is denoted with a number between 1 and 5. The JDBC connection URL must
be defined per replica. The username and password can be specified; if
not, the username and password for the master database will be used
instead.

The configuration for read replicas in `dhis.conf` looks like the below.
Each replica is specified with the configuration key *readN* prefix,
where N refers to the replica number.

```属性
＃读取副本1的配置

＃数据库连接URL，用户名和密码
read1.connection.url = jdbc：postgresql：//127.0.0.11/dbread1
read1.connection.username = dhis
read1.connection.password = xxxx

＃读取副本2的配置

＃数据库连接URL，用户名和密码
read2.connection.url = jdbc：postgresql：//127.0.0.12/dbread2
read2.connection.username = dhis
read2.connection.password = xxxx

＃读取副本3的配置

＃数据库连接URL，后退到主用户名和密码
read3.connection.url = jdbc：postgresql：//127.0.0.13/dbread3
```

请注意，您必须重新启动servlet容器才能更改
生效。 DHIS 2将自动在
读取副本。副本的顺序没有任何意义。

## Web服务器群集配置 { #install_web_server_cluster_configuration } 

本节介绍如何设置DHIS 2应用程序以在
簇。

### 群集概述 { #install_cluster_configuration_introduction } 

Clustering is a common technique for improving system scalability and
availability. Clustering refers to setting up multiple web servers such
as Tomcat instances and have them serve a single application. Clustering
allows for *scaling out* an application in the sense that new servers
can be added to improve performance. It also allows for *high
availability* as the system can tolerate instances going down without
making the system inaccessible to users.

有一些方面需要配置才能运行DHIS 2
在集群中。

* 必须安装Redis数据存储，并且必须提供连接信息
be provided for each DHIS 2 application instance in`dhis.conf`.

* DHIS 2 instances and servers must share the same *files* folder used for 
应用程序和文件上传，通过* AWS S3云文件存储*选项
或共享的网络驱动器。

* DHIS 2 instance cache invalidation must be enabled.

* A load balancer such as nginx should be configured to distribute Web requests
跨集群实例。

### DHIS 2 instance cache invalidation with Redis { #install_cluster_cache_invalidation_redis }

DHIS 2 can invalidate the various instance's caches by listening for events sent and emitted from a Redis server, when configured to do so.

This is considered the easiest and preferred way to enable cache invalidation, if you already plan to use [Redis for
shared data store cluster configuration](#install_cluster_configuration_redis), it will share this Redis server for both purposes.

#### Prerequisites { #prerequisites } 

* Redis server

#### Redis configuration { #redis-configuration } 

No specific configuration in Redis is needed for DHIS 2 cache invalidation to work.

When you chose to enable shared data store cluster configuration with Redis, you will share the Redis host/port
configuration with the cache invalidation system. In other words you can only have **one** shared Redis server configured.

#### DHIS 2 configuration { #dhis-2-configuration } 

The following properties must be specified in the DHIS 2 `dhis.conf` configuration file:

```properties
# Cache invalidation config

redis.cache.invalidation.enabled = on

# Shared Redis configuration
redis.host = REDIS_HOST
redis.port = REDIS_PORT
redis.password = PASSWORD (Optional, only if enabled on Redis server)
redis.use.ssl = true (Optional, only if enabled on Redis server) 
```

### Redis共享数据存储集群配置 { #install_cluster_configuration_redis } 

In a cluster setup, a Redis server is required and will handle
shared user sessions, application cache and cluster node leadership.

For optimum performance, *Redis Keyspace events* for _generic commands_ 
and _expired events_ need to be enabled in the Redis Server. If you are 
using a cloud platform-managed Redis server (like *AWS ElastiCache for Redis* 
or *Azure Cache for Redis*), you will have to enable keyspace event notifications 
using the respective cloud console interfaces. If you are setting up a standalone 
Redis server, enabling keyspace event notifications can be done in the 
*redis.conf* file by adding or uncommenting the following line:

```
notify-keyspace-events Egx
```

DHIS2 will connect to Redis if the *redis.enabled* configuration
property in `dhis.conf` is set to *on* along with the following properties:

- * redis.host *：指定Redis服务器在何处运行。默认为* localhost *。必选

- * redis.port *：指定Redis服务器正在侦听的端口。默认为* 6379 *。可选的。

- * redis.password *：指定身份验证密码。如果不需要密码，可以将其留空。

- * redis.use.ssl *：指定Redis服务器是否启用了SSL。默认为false。可选的。默认为* false *。

When Redis is enabled, DHIS2 will automatically assign one of the
running instances as the leader of the cluster. The leader instance will
be used to execute jobs or scheduled tasks that should be run
exclusively by one instance. Optionally you can configure the
*leader.time.to.live.minutes* property in `dhis.conf` to set up how
frequently the leader election needs to occur. It also gives an
indication of how long it would take for another instance to take over
as the leader after the previous leader has become unavailable. The
default value is 2 minutes. Note that assigning a leader in the cluster
is only done if Redis is enabled. An example snippet of the `dhis.conf`
configuration file with Redis enabled and leader election time
configured is shown below.

```properties
# Redis Configuration

redis.enabled = on

# Shared Redis configuration
redis.host = REDIS_HOST
redis.port = REDIS_PORT
redis.password = PASSWORD (Optional, only if enabled on Redis server)
redis.use.ssl = true (Optional, only if enabled on Redis server)

# Optional, defaults to 2 minutes
leader.time.to.live.minutes=4 
```

### 文件文件夹配置 { #files-folder-configuration } 

DHIS 2将在应用程序本身之外存储几种类型的文件，
例如应用程序，保存在数据输入中的文件和用户头像。部署时
在群集中，这些文件的位置必须在所有实例之间共享。
在本地文件系统上，位置为：

```
{DHIS2_HOME} /文件
```

Here, `DHIS2_HOME` refers to the location of the DHIS 2 configuration file
as specified by the DHIS 2 environment variable, and `files` is the file
folder immediately below.

有两种方法可以实现共享位置：

* 使用* AWS S3云文件存储*选项。文件将存储在
S3存储桶，由群集中的所有DHIS 2实例自动共享。
请参阅*文件存储配置*部分以获取指导。
* 设置一个在所有DHIS 2实例之间共享的共享文件夹，并且
集群中的服务器。在Linux上，可以使用* NFS *（网络文件系统）来实现
这是一个分布式文件系统协议。注意只有`files`
subfolder under `DHIS2_HOME` should be shared, not the parent folder. 

### 负载均衡器配置 { #install_load_balancing } 

设置了Tomcat实例集群，这是路由的常用方法
传入Web请求到参与
集群正在使用*负载均衡器*。负载均衡器将确保
负载在群集实例之间平均分配。它也会
检测实例是否不可用，如果是，则停止例程
对该实例的请求，而是使用其他可用实例。

负载平衡可以通过多种方式实现。一个简单的方法是
使用* nginx *，在这种情况下，您将定义一个* upstream *元素，
枚举后端实例的位置，以后再使用
* proxy *位置块中的元素。

```text
http {

  # Upstream element with sticky sessions

  upstream dhis_cluster {
    ip_hash;
    server 193.157.199.131:8080;
    server 193.157.199.132:8080;
  }

  # Proxy pass to backend servers in cluster

  server {
    listen 80;

    location / {
      proxy_pass   http://dhis_cluster/;
    }
  }
}
```

DHIS 2在一定程度上将用户会话的服务器端状态保持不变。
使用“粘性会话”是避免复制
服务器会话状态，方法是将请求从同一客户端路由到
同一台服务器。上游元素中的* ip \ _hash *指令可确保
这个。

请注意，为简洁起见，已省略了几条说明
上面的例子。请查阅反向代理部分以获取详细指南。

## ActiveMQ Artemis configuration { #webapi_artemis_configuration } 

By default DHIS2 will start an embedded instance of ActiveMQ Artemis when booting up. For most use-cases, you do not need to do anything. If you have an existing ActiveMQ Artemis service you want to use instead of the embedded instance you can change the default configuration in your `dhis.conf` file with the configuration properties in the following table.

| Property                  | Value (default first) | 描述                                                  |
| ------------------------- | --------------------- | ------------------------------------------------------------ |
| artemis.mode                 | EMBEDDED \| NATIVE    | 默认的`EMBEDDED`模式会在 DHIS2 实例启动时启动内部 AMQP 服务。如果要连接到外部 AMQP 服务，请将模式设置为`NATIVE`。 |
| artemis.host                 | 127.0.0.1             | Host to bind to.                                             |
| artemis.port                 | 15672                 | 如果 mode 为`EMBEDDED`，则嵌入式服务器将绑定到此端口。如果模式为`NATIVE`，客户端将使用此端口进行连接。 |
| artemis.username             | guest                 | 使用`NATIVE`模式时要连接的用户名。               |
| artemis.password             | guest                 | 如果使用`NATIVE`模式连接到的密码。               |
| artemis.embedded.persistence | off \| on         | 如果 mode 为`EMBEDDED`，则此属性控制内部队列的持久性。 |


## 监控 { #monitoring } 

DHIS 2可以导出Prometheus兼容的度量标准以监视DHIS2实例。 DHIS2监视基础结构旨在公开与应用程序运行时相关的指标以及其他与应用程序相关的信息。

与基础架构相关的指标（例如主机指标，Tomcat或Postgres）不会直接由应用程序监视引擎公开，因此必须分别收集它们。该应用程序当前公开的指标是：

- DHIS 2 API（响应时间，调用次数等）
- JVM（堆大小，垃圾回收等）
- 休眠（查询，缓存等）
- C3P0数据库池
- 应用正常运行时间
- 中央处理器

可以使用以下属性在`dhis.conf`中启用监视（所有属性默认为`off`）：

```属性
monitoring.api.enabled =开
monitoring.jvm.enabled =开
monitoring.dbpool.enabled =开
monitoring.hibernate.enabled =关
monitoring.uptime.enabled =开
monitoring.cpu.enabled =开
```

推荐使用Prometheus和Grafana收集和可视化这些指标的方法。

For more information, see the [monitoring infrastructure](https://github.com/dhis2/wow-backend/blob/master/guides/monitoring.md) page and the [Prometheus and Grafana install](#monitoring) chapter.

## 系统配置 { #install_system_configuration } 

This section covers various system configuration properties.

```properties
system.read_only_mode = on | off
```

将系统设置为只读模式。当您在只读副本数据库上运行 DHIS 2 时，这很有用，以避免 DHIS 2 执行数据库写入操作。可以是`开`或`关`。默认为`关闭`。

```properties
system.session.timeout = (seconds)
```

Sets the user session timeout in seconds. Default is 3600 seconds (1 hour).

```properties
system.sql_view_table_protection = on | off
```

启用或禁用 SQL 视图的敏感数据库表保护。这将禁止通过 SQL 视图查询包含敏感数据的数据库表。不建议禁用。可以是`开`或`关`。默认为`开`。

```properties
system.system.sql_view_write_enabled = on | off
```

Enables or disables write permissions for SQL views. This will prohibit SQL view performing underlying writes (query can be a select which requires write permission). Enabling is not recommended. Can be `on` or `off`. Default is `off`.

```properties
system.program_rule.server_execution = on | off
```

启用或禁用服务器端项目规则的执行。这是指具有分配值、发送消息或安排要发送的消息的操作的项目规则。可以是`开`或`关`。默认为`开`。

```properties
system.remote_servers_allowed = https://server1.org/,https://server2.org/
```

Sets the allowed list of servers to be called in relation to the [metadata pull](../developer/web-api/synchronization.md#webapi_sync_metadata_pull) functionality. It accepts comma-separated values, and it's recommended that each server end with a `/` for enhanced security. Default value is empty.


## 反向代理配置 { #install_reverse_proxy_configuration } 

反向代理是代表服务器运行的代理服务器。使用
反向代理与Servlet容器结合使用是可选的，但
有很多优点：

  - 可以将请求映射并传递到多个servlet容器。
    这提高了灵活性，并使其更易于运行
    同一台服务器上的DHIS2实例。这也使得
    在不影响客户端的情况下更改内部服务器设置。

  - DHIS2应用程序可以作为非root用户在端口上运行
    不同于80，这减少了会话的后果
    劫持。

  - 反向代理可以充当单个SSL服务器并进行配置
    检查恶意内容请求，日志请求和
    响应并提供不敏感的错误消息，这将
    提高安全性。

### 基本的Nginx设置 { #install_basic_nginx_setup } 

由于以下原因，我们建议使用[nginx]（http://www.nginx.org）作为反向代理
其低内存占用和易用性。要安装，请调用
以下：

    sudo apt-get install -y nginx

现在可以使用以下命令启动，重新加载和停止nginx
命令：

    sudo /etc/init.d/nginx开始
    须藤/etc/init.d/nginx重新加载
    sudo /etc/init.d/nginx停止

Now that we have installed nginx we will now continue to configure
regular proxying of requests to our Tomcat instance, which we assume
runs at `http://localhost:8080`. To configure nginx you can open the
configuration file by invoking:

    须藤nano /etc/nginx/nginx.conf

nginx配置围绕代表以下内容的块层次结构构建
http，服务器和位置，其中每个块都从父级继承设置
块。以下代码段将nginx配置为通过代理
（重定向）来自端口80的请求（该端口是nginx监听的端口
默认情况下）到我们的Tomcat实例。包括以下配置
在nginx.conf中：

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  server {
    listen               80;
    client_max_body_size 10M;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  http;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

现在，您可以通过* http：// localhost *访问DHIS2实例。自从
已经设置了反向代理，我们可以通过使Tomcat来提高安全性
只监听本地连接。在* / conf / server.xml *中，您可以添加一个
连接器元素的* address *属性值为* localhost *
对于HTTP 1.1像这样：

```xml
<Connector address="localhost" protocol="HTTP/1.1" />
```

### 使用nginx {#install_enabling_ssl_on_nginx}启用SSL { #install_enabling_ssl_on_nginx } 

为了提高安全性，建议配置服务器
运行DHIS2以通过加密连接与客户端进行通信
并使用受信任的证书向客户端标识自己。这个可以
通过SSL（一种加密通信协议）来实现
在TCP / IP上运行。首先，安装所需的* openssl *库：

    sudo apt-get install -y openssl

To configure nginx to use SSL you will need a proper SSL certificate
from an SSL provider. The cost of a certificate varies a lot depending
on encryption strength. An affordable certificate from [Rapid SSL
Online](http://www.rapidsslonline.com) should serve most purposes. To
generate the CSR (certificate signing request) you can invoke the
command below. When you are prompted for the *Common Name*, enter the
fully qualified domain name for the site you are
    securing.

    openssl req -new -newkey rsa：2048 -nodes -keyout server.key -out server.csr

收到证书文件（.pem或.crt）后，您将
需要将其与生成的server.key文件放在一起
nginx可以到达的位置。一个好的位置可以是
与您的nginx.conf文件所在的目录相同。

Below is an nginx server block where the certificate files are named
server.crt and server.key. Since SSL connections usually occur on port
443 (HTTPS) we pass requests on that port (443) on to the DHIS2 instance
running on `http://localhost:8080`. The first server block will rewrite
all requests connecting to port 80 and force the use of HTTPS/SSL. This
is also necessary because DHIS2 is using a lot of redirects internally
which must be passed on to use HTTPS. Remember to replace
*\<server-ip\>* with the IP of your server. These blocks should replace
the one from the previous section.

```text
http {
  gzip on; # Enables compression, incl Web API content-types
  gzip_types
    "application/json;charset=utf-8" application/json
    "application/javascript;charset=utf-8" application/javascript text/javascript
    "application/xml;charset=utf-8" application/xml text/xml
    "text/css;charset=utf-8" text/css
    "text/plain;charset=utf-8" text/plain;

  # HTTP server - rewrite to force use of SSL

  server {
    listen     80;
    rewrite    ^ https://<server-url>$request_uri? permanent;
  }

  # HTTPS server

  server {
    listen               443 ssl;
    client_max_body_size 10M;

    ssl                  on;
    ssl_certificate      server.crt;
    ssl_certificate_key  server.key;

    ssl_session_cache    shared:SSL:20m;
    ssl_session_timeout  10m;

    ssl_protocols              TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers                RC4:HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # Proxy pass to servlet container

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
    }
  }
}
```

请注意最后一个`https`标头值，该值是通知
servlet容器，该请求通过HTTPS发出。为了
Tomcat还需要使用HTTPS正确生成`Location` URL头
在Tomcat`server.xml`文件中向连接器添加其他两个参数：

```xml
<Connector scheme="https" proxyPort="443" />
```

### 使用Nginx启用缓存 { #install_enabling_caching_ssl_nginx } 

要求提供报告，图表，地图和其他与分析相关的资源
通常会花费一些时间来响应，并且可能会占用大量服务器
资源。为了缩短响应时间，请减少
服务器并隐藏潜在的服务器停机时间，我们可以引入缓存代理
在我们的服务器设置中。缓存的内容将存储在目录中
/ var / cache / nginx，最多将分配250 MB的存储空间。 Nginx的
将自动创建此目录。

```text
http {
  ..
  proxy_cache_path  /var/cache/nginx  levels=1:2  keys_zone=dhis:250m  inactive=1d;


  server {
    ..

    # Proxy pass to servlet container and potentially cache response

    location / {
      proxy_pass                http://localhost:8080/;
      proxy_redirect            off;
      proxy_set_header          Host               $host;
      proxy_set_header          X-Real-IP          $remote_addr;
      proxy_set_header          X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header          X-Forwarded-Proto  https;
      proxy_buffer_size         128k;
      proxy_buffers             8 128k;
      proxy_busy_buffers_size   256k;
      proxy_cookie_path         ~*^/(.*) "/$1; SameSite=Lax";
      proxy_cache               dhis;
    }
  }
}
```

> **重要**
>
>请注意，服务器端缓存会缩短DHIS2安全性
>从某种意义上说是功能，这些请求命中了服务器端缓存
>将直接从DHIS2控制范围之外的缓存中提供
>和servlet容器。这意味着请求URL可以是
>猜测并由未经授权的用户从缓存中检索报告。
>因此，如果您捕获敏感信息，请设置服务器端
>不建议使用缓存。

### 使用Nginx进行速率限制 { #install_rate_limiting } 

DHIS 2中的某些Web API调用,如`analytics` API,是计算密集型的。因此，最好对这些API进行速率限制，以允许系统的所有用户充分利用服务器资源。速率限制可以通过`nginx`实现。有多种实现速率限制的方法，这旨在记录基于nginx的方法。

The below nginx configuration will rate limit the `analytics` web API, and has the following elements at the *http* and *location* block level (the configuration is shortened for brevity):

```text
http {
  ..
  limit_req_zone $binary_remote_addr zone=limit_analytics:10m rate=5r/s;

  server {
    ..

    location ~ ^/api/(\d+/)?analytics(.*)$ {
      limit_req    zone=limit_analytics burst=20;
      proxy_pass   http://localhost:8080/api/$1analytics$2$is_args$args;
      ..
    }
  }
}
```

配置的各个元素可以描述为：

- * limit_req_zone $ binary_remote_addr *：速率限制是针对每个请求IP进行的。
- * zone = limit_analytics：20m *：Analytics API的速率限制区域，最多可容纳10 MB的请求IP地址。
- * rate = 20r / s *：每个IP每秒被授予5个请求。
- *location ~ ^/api/(\d+/)?analytics(.\*)$*: Requests for the analytics API endpoint are rate limited.
- *burst=20*: Bursts of up to 20 requests will be queued and serviced at a later point; additional requests will lead to a `503`.

有关完整说明，请查阅[nginx文档]（https://www.nginx.com/blog/rate-limiting-nginx/）。

### 使用Nginx使资源可用 { #install_making_resources_available_with_nginx } 

在某些情况下，希望公开发布某些资源
无需身份验证即可在Web上使用。一个例子是
当您想在Web API中进行与数据分析相关的资源时
在Web门户中可用。以下示例将允许访问
基本的图表，地图，报告，报告表和文档资源
通过将* Authorization * HTTP标头注入
请求。它将从请求中删除Cookie标头，
从响应中获取Set-Cookie标头，以避免更改
当前登录的用户。建议为此创建一个用户
目的仅给出所需的最低权限。授权
值可以通过Base64编码，并在用户名后附加一个
冒号和密码，并以“ Basic”作为前缀，更准确地说是“ Basic”
base64 \ _encode（username：password）“。它将检查使用的HTTP方法
用于请求并返回* 405方法不允许*（如果不是GET，则为其他方法）
检测到。

为此类公共用户设置一个单独的域可能是有利的
使用这种方法时。这是因为我们不想更改
已登录用户访问公共帐户时的凭据
资源。例如，当您的服务器部署在somedomain.com上时，
您可以在api.somedomain.com上设置专用的子域，并指向URL
从您的门户到此子域。

```text
http {
  ..

  server {
    listen       80;
    server_name  api.somedomain.com;

    location ~ ^/(api/(charts|chartValues|reports|reportTables|documents|maps|organisationUnits)|dhis-web-commons/javascripts|images|dhis-web-commons-ajax-json|dhis-web-mapping|dhis-web-visualizer) {
    if ($request_method != GET) {
        return 405;
      }

      proxy_pass         http://localhost:8080;
      proxy_redirect     off;
      proxy_set_header   Host               $host;
      proxy_set_header   X-Real-IP          $remote_addr;
      proxy_set_header   X-Forwarded-For    $proxy_add_x_forwarded_for;
      proxy_set_header   X-Forwarded-Proto  http;
      proxy_set_header   Authorization      "Basic YWRtaW46ZGlzdHJpY3Q=";
      proxy_set_header   Cookie             "";
      proxy_hide_header  Set-Cookie;
    }
  }
}
```


### Block specific Android App versions with nginx { #install_block_android_versions } 

In some scenarios the system administrator might want to block certain Android clients based on its DHIS2 App version. For example, if the users on the field have not updated their Android App version to a specific one and the system administrator wants to block their access to force an update; or completely the opposite scenario when the system administrator wants to block new versions of the App as they have not been yet tested. This can be easily implemented by using specific *User-Agent* rules in the `nginx` configuration file.

```text
http {

  server {
    listen       80;
    server_name  api.somedomain.com;

    # Block the latest Android App as it has not been tested
    if ( $http_user_agent ~ 'com\.dhis2/1\.2\.1/2\.2\.1/' ) {
        return 403;
    }

    # Block Android 4.4 (API is 19) as all users should have received new tablets
    if ( $http_user_agent ~ 'com\.dhis2/.*/.*/Android_19' ) {
        return 403;
    }
  }
}
```

> **Note**
> For the implementation of the method described above note the following: 
> * Before version 1.1.0 the *User-Agent* string was not being sent.
> * From version 1.1.0 to 1.3.2 the *User-Agent* followed the pattern Dhis2/AppVersion/AppVersion/Android_XX
> * From version 2.0.0 and above the *User-Agent* follows the pattern com.dhis2/SdkVersion/AppVersion/Android_XX
> * Android_XX refers to the Android API level i.e. the Android version as listed [here](https://developer.android.com/studio/releases/platforms).
> * nginx uses [PCRE](http://www.pcre.org/) for Regular Expression matching .

## DHIS2 configuration reference (dhis.conf) { #install_dhis2_configuration_reference } 

The following describes the full set of configuration options for the `dhis.conf` configuration file. The configuration file should be placed in a directory which is pointed to by a `DHIS2_HOME` environment variable.

> **注意**
>
>您不应尝试直接使用此配置文件，而应将其用作可用配置选项的参考。许多属性是可选的。

```properties
# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Mandatory]
# ----------------------------------------------------------------------

# Hibernate SQL dialect
connection.dialect = org.hibernate.dialect.PostgreSQLDialect

# JDBC driver class
connection.driver_class = org.postgresql.Driver

# Database connection URL
connection.url = jdbc:postgresql:dhis2

# Database username
connection.username = dhis

# Database password (sensitive)
connection.password = xxxx

# Max size of connection pool (default: 40)
connection.pool.max_size = 40

# ----------------------------------------------------------------------
# Database connection for PostgreSQL [Optional]
# ----------------------------------------------------------------------

# Minimum number of Connections a pool will maintain at any given time (default: 5).
connection.pool.min_size=5

# Initial size of connection pool (default : 5)
#Number of Connections a pool will try to acquire upon startup. Should be between minPoolSize and maxPoolSize
connection.pool.initial_size=5

#Determines how many connections at a time will try to acquire when the pool is exhausted.
connection.pool.acquire_incr=5

#Seconds a Connection can remain pooled but unused before being discarded. Zero means idle connections never expire. (default: 7200)
connection.pool.max_idle_time=7200

#Number of seconds that Connections in excess of minPoolSize should be permitted to remain idle in the pool before being culled (default: 0)
connection.pool.max_idle_time_excess_con=0

#If this is a number greater than 0, dhis2 will test all idle, pooled but unchecked-out connections, every this number of seconds. (default: 0)
connection.pool.idle.con.test.period=0

#If on, an operation will be performed at every connection checkout to verify that the connection is valid. (default: false)
connection.pool.test.on.checkout=false

#If on, an operation will be performed asynchronously at every connection checkin to verify that the connection is valid. (default: on)
connection.pool.test.on.checkin=on

#Defines the query that will be executed for all connection tests. Ideally this config is not needed as postgresql driver already provides an efficient test query. The config is exposed simply for evaluation, do not use it unless there is a reason to.
connection.pool.preferred.test.query=select 1

#Configure the number of helper threads used by dhis2 for jdbc operations. (default: 3)
connection.pool.num.helper.threads=3

# Database datasource pool type. Supported pool types are: 
#
# * c3p0 (default): For information see https://www.mchange.com/projects/c3p0/
# 
# * hikari: For information see https://github.com/brettwooldridge/HikariCP
#
# * unpooled: Some implementations might want to have more control over the pooling and database cluster architecture 
# (e.g., using PgBouncer as pool manager behind HAProxy for load balancing). In these cases, the internal pool is un-necessary 
# and gets in the way.
db.pool.type=c3p0

# ----------------------------------------------------------------------
# Server [Mandatory]
# ----------------------------------------------------------------------

# Base URL to the DHIS 2 instance
server.base.url = https://play.dhis2.org/dev 

# Enable secure settings if system is deployed on HTTPS, can be 'off', 'on'
server.https = off

# ----------------------------------------------------------------------
# System [Optional]
# ----------------------------------------------------------------------

# System mode for database read operations only, can be 'off', 'on'
system.read_only_mode = off

# Session timeout in seconds, default is 3600
system.session.timeout = 3600

# SQL view protected tables, can be 'on', 'off'
system.sql_view_table_protection = on

# SQL view write enabled, can be 'on', 'off'
system.sql_view_write_enabled = off

# Disable server-side program rule execution, can be 'on', 'off'
system.program_rule.server_execution = on

# Remote servers which the server is allowed to call
# Accepts comma-separated values
# Servers should end with '/' for enhanced security
# Default is empty
system.remote_servers_allowed = https://server1.org/,https://server2.org/

# ----------------------------------------------------------------------
# Encryption [Optional]
# ----------------------------------------------------------------------

# Encryption password (sensitive)
encryption.password = xxxx

# ----------------------------------------------------------------------
# File store [Optional]
# ----------------------------------------------------------------------

# File store provider, currently 'filesystem' and 'aws-s3' are supported
filestore.provider = filesystem

# Directory / bucket name, folder below DHIS2_HOME on file system, 'bucket' on AWS S3
filestore.container = files

# Datacenter location (not required)
filestore.location = eu-west-1

# Public identity / username
filestore.identity = dhis2-id

# Secret key / password (sensitive)
filestore.secret = xxxx

# ----------------------------------------------------------------------
# LDAP [Optional]
# ----------------------------------------------------------------------

# LDAP server URL
ldap.url = ldaps://300.20.300.20:636

# LDAP manager user distinguished name
ldap.manager.dn = cn=JohnDoe,ou=Country,ou=Admin,dc=hisp,dc=org

# LDAP manager user password (sensitive)
ldap.manager.password = xxxx

# LDAP entry distinguished name search base
ldap.search.base = dc=hisp,dc=org

# LDAP entry distinguished name filter
ldap.search.filter = (cn={0})

# ----------------------------------------------------------------------
# Node [Optional]
# ----------------------------------------------------------------------

# Node identifier, optional, useful in clusters
node.id = 'node-1'

# ----------------------------------------------------------------------
# Monitoring [Optional]
# ----------------------------------------------------------------------

# DHIS2 API monitoring
monitoring.api.enabled = on

# JVM monitoring
monitoring.jvm.enabled = on

# Database connection pool monitoring
monitoring.dbpool.enabled = on

# Hibernate monitoring, do not use in production
monitoring.hibernate.enabled = off

# Uptime monitoring
monitoring.uptime.enabled = on

# CPU monitoring
monitoring.cpu.enabled = on

# ----------------------------------------------------------------------
# Analytics [Optional]
# ----------------------------------------------------------------------

# Analytics server-side cache expiration in seconds
analytics.cache.expiration = 3600

# Analytics unlogged tables. Accepts on/off. It's `on` by default. If enabled, this will boost the analytics table export process significantly.
# But this comes with a cost: "unlogged" tables cannot be replicated. It means that clustering won't be possible. Also, analytics tables will be automatically truncated if PostgreSQL is suddenly reset (abrupt reset/crash). If PostgreSQL is reset gracefully, it won't impact any table. In this case, the analytics tables will remain in place accordingly. If you cannot afford the costs mentioned above, you should disable it (set to `off`).
analytics.table.unlogged = on

# ----------------------------------------------------------------------
# System telemetry [Optional]
# ----------------------------------------------------------------------

# System monitoring URL
system.monitoring.url = 

# System monitoring username
system.monitoring.username = 

# System monitoring password (sensitive)
system.monitoring.password = xxxx

# ----------------------------------------------------------------------
# System update notifications [Optional]
# ----------------------------------------------------------------------

system.update_notifications_enabled = on

# ----------------------------------------------------------------------
# App Hub [Optional]
# ----------------------------------------------------------------------

# Base URL to the DHIS2 App Hub service
apphub.base.url = https://apps.dhis2.org"
# Base API URL to the DHIS2 App Hub service, used for app updates
apphub.api.url = https://apps.dhis2.org/api


# Number of possible concurrent sessions on different computers or browsers for each user. If configured to 1, the
# user will be logged out from any other session when a new session is started.
max.sessions.per_user = 10
```

## 变更日志 { #install_changelog } 

当某些实体在系统中更改时，DHIS2将条目写入更改日志。实体分为两类：_Aggregate_和_tracker_。 _aggregate_类别包括对汇总数据值的更改。 _tracker_类别包括对项目实例，项目临时所有权项，跟踪的实体属性值和跟踪的实体数据值的更改。

The changelog for both categories are enabled by default. You can control whether to enable or disable the changelog by category through the `dhis.conf` configuration file using the properties described below. Property options are `on` (default) and `off`.

更改日志的好处是能够查看已对数据执行的更改。禁用更改日志的好处是，通过避免将更改日志项写入数据库的成本以及较少使用的数据库存储，可以对性能进行较小的改进。建议启用变更日志，如果禁用它，则应格外小心。

```属性
＃汇总变更日志，可以为“ on”，“ off”
changelog.aggregate =开启

＃Tracker changelog，可以为“ on”，“ off”
changelog.tracker =开
```

## 应用程序日志记录 { #install_application_logging } 

本节介绍DHIS 2中的应用程序日志记录。

### 日志文件 { #log-files } 

DHIS2应用程序日志输出定向到多个文件和位置。首先，将日志输出发送到标准输出。 Tomcat Servlet容器通常将标准输出输出到“ logs”下的文件：

     <tomcat-dir> /logs/catalina.out

Second, log output is written to a "logs" directory under the DHIS2 home directory as defined by the `DHIS2_HOME` environment variables. There is a main log file for all output, and separate log files for various
background processes. The main file includes the background process logs as well. The log files are capped at 50 Mb and log content is continuously appended.

     <DHIS2_HOME> /logs/dhis.log
     <DHIS2_HOME> /logs/dhis-analytics-table.log
     <DHIS2_HOME> /logs/dhis-data-exchange.log
     <DHIS2_HOME> /logs/dhis-data-sync.log

### 日志配置 { #log-configuration } 

To override the default log configuration you can specify a Java system
property with the name `log4j2.configurationFile` and a value pointing to the
[Log4j version 2](https://logging.apache.org/log4j/2.x/manual/configuration.html)
configuration file at the file system like this:

```properties
-Dlog4j2.configurationFile=/home/dhis/config/log4j2.properties
```

可以设置Java系统属性，例如通过* JAVA \ _OPTS *环境变量或tomcat启动脚本中。

A second approach to overriding the log configuration is to specify logging properties in the `dhis.conf` configuration file. The supported properties are:

```属性
＃日志文件的最大大小，默认为'100MB'
logging.file.max_size = 250MB

＃最大滚动日志归档文件数，默认为0
logging.file.max_archives = 2
```

DHIS2 will eventually phase out logging to standard out / catalina.out and as a result it is recommended to rely on the logs under `DHIS2_HOME`.

DHIS2 will provide the following context values:

* `sessionId`: Current user's session ID
* `xRequestID`: An alphanumeric ID as send by the `X-Request-ID` HTTP header for the currently processed request; empty if not provided

To use the context variables in the log add them using `-X{<name>}` to your log pattern as in this example:

    * %-5p %d{ISO8601} %m (%F [%t]) %X{sessionId} %X{xRequestID}%n

### Log level configuration { #log-level-configuration } 

To set the log level of individual packages you can specify properties on the format  `logging.level.{package-names}` in `dhis.conf`. For example, to set the the log level for the entire Spring Framework to DEBUG and up, you can specify:

```
logging.level.org.springframework = DEBUG
```
To set the log level to DEBUG for the DHIS2 services, you can specify:

```
logging.level.org.hisp.dhis = DEBUG
```

常见的日志级别是`DEBUG`、`INFO`、`WARN`和`ERROR`。

> **Note**
> 
> Log level configuration is not supported for the embedded DHIS2 Jetty version.

## 使用PostgreSQL数据库 { #install_working_with_the_postgresql_database } 

Common operations when managing a DHIS2 instance are dumping and restoring databases. Note that when making backups of the DHIS 2 database, it is good practise to exclude tables which are generated by the system, such as the resource and analytics tables. To make a dump (copy) of your database to a file,  you can invoke the following command.

```bash
pg_dump {database} -U {user} -T "_*" -T "analytics*"  -f {filename}
```
In the following example, the database name is `dhis2`, the user is `dhis` and the output filename is `dhis2.sql`:

```bash
pg_dump dhis2 -U dhis -T "analytics*" -T "_*" -f dhis2.sql
```

It is good practice to compress the If you want to compress the output file with `gzip`, which can be done like this:

```bash
pg_dump dhis2 -U dhis -T "analytics*" -T "_*" | gzip > dhis2.sql.gz
```

要在另一个系统上恢复数据库副本，您首先需要创建一个空数据库，如安装部分所述。如果您创建了压缩版本，还需要`gunzip`副本。要恢复副本，您可以调用以下命令：

```bash
psql -d dhis2 -U dhis -f dhis2.sql
```

