---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/master/src/developer/web-api/data-validation.md"
revision_date: '2024-03-13'
tags:
- Develop
- DHIS核心 主版
---

# 数据验证 { #data-validation } 

## 验证方式 { #webapi_validation } 

要生成数据验证摘要，您可以与
验证资源。数据集资源针对数据输入进行了优化
用于验证数据集/表单的客户端，可以像这样访问：

    获取 /api/33/validation/dataSet/QX4ZTUbOt3a.json?pe=201501&ou=DiszpKrYNg8

除了基于数据集验证规则外，还有两种
执行验证的其他方法：自定义验证和
预定验证。

第一个路径变量是引用数据集的标识符
证实。支持 XML 和 JSON 资源表示。这
响应包含违反验证规则。这将延长
在即将到来的版本中有更多的验证类型。

要检索与特定数据集相关的验证规则，
意思是所有数据元素都是一部分的带有公式的验证规则
的特定数据集，您可以向
`validationRules` 资源如下：

    GET /api/validationRules?dataSet=<dataset-id>

验证规则有左边和右边，也就是
根据运营商比较有效性。有效的运算符
值见下表。



表：运算符

| 值 | 描述 |
|---|---|
| equal_to | 等于 |
| not_equal_to | 不等于 |
| greater_than | 比...更棒 |
| greater_than_or_equal_to | 大于或等于 |
| less_than | 少于 |
| less_than_or_equal_to | 小于或等于 |
| compulsory_pair | 如果任何一方在场，另一方也必须在场 |
| exclusive_pair | 如果任何一方在场，则另一方不得在场 |

左边和右边的表达式是数学表达式
其中可以包含对数据元素和类别选项的引用
以下格式的组合：

    $ {<dataelement-id>。 <catoptcombo-id>}

左侧和右侧表达式有一个 *missing 值
战略*。这是指系统应该如何处理数据值
缺少数据元素/类别选项组合引用
在公式中是否应该检查验证规则
为有效性或跳过。有效的缺失值策略见于
下表。



表：缺失值策略

| 值 | 描述 |
|---|---|
| SKIP_IF_ANY_VALUE_MISSING | 如果缺少任何数据值，则跳过验证规则 |
| SKIP_IF_ALL_VALUES_MISSING | 如果所有数据值均缺失，则跳过验证规则 |
| 从不_跳过 | 无论缺少数据值，都不要跳过验证规则 |

## 验证结果{ #webapi_validation_results }

验证结果是在执行期间发现的违规的持久结果
验证分析。如果您在开始时选择“持久结果”或
安排验证分析，发现的任何违规将存储在
数据库。当结果存储在数据库中时，它将被使用
对于 3 件事：

1.  根据存储的结果生成分析。

2.  未生成通知的持久结果将这样做，
    一次。

3.  跟踪结果是否产生了
    通知。

4.  跳过运行时已经检查过的规则
    验证分析。

这意味着如果你不坚持你的结果，你将无法
为验证结果生成分析，如果选中，结果将
每次找到并运行验证时生成通知
分析可能会更慢。

### 查询验证结果{ #query-validation-results }

持久化的验证结果可以在下面查看
端点：

    获取 /api/33/validationResults

您还可以使用验证结果 ID 检查单个结果
在这个端点：

    GET /api/33/validationResults/<id>

验证结果也可以通过以下属性过滤：

* 组织单位：`ou = <UID>`
* 验证规则：`vr = <UID>`
* 期间：`pe = <ISO-expression>`

上面的每个过滤器属性可以多次出现，例如：

    获取 /api/36/validationResults?ou=jNb63DIHuwU&ou=RzgSFJ9E46G

同一过滤器的多个值与OR组合，结果必须匹配给定值之一。

如果使用了一个以上的过滤器属性，则将它们与AND组合在一起，结果必须与每个属性的值之一匹配。

对于时段过滤器，匹配结果必须与任何指定的时段重叠。

此外，验证结果还可以按其创建日期进行过滤：

    GET /api/36/validationResults?createdDate=<date>

该过滤器可以与其他任何过滤器结合使用。

### 触发验证结果通知{ #trigger-validation-result-notifications }

验证结果每天发送给适当的用户一次，
但也可以使用以下命令手动触发以按需运行
API端点：

    POST / api / 33 / validation / sendNotifications

使用此端点仅发送未发送的结果。

### 删除验证结果{ #delete-validation-results }

验证结果可以通过ID手动删除，

    删除/ api / 36 / validationResults / <id>

或使用过滤器

    删除/ api / 36 / validationResults？ <filters>

支持的过滤器参数包括：

* `ou = <UID>`以匹配组织单位的所有验证结果；提供多个参数时，多个单元组合或
* `vr = <UID>`以匹配验证规则的所有验证结果；提供多个参数时，多个规则组合或
* `pe = <ISO-expression>`以匹配与与指定时期重叠的时期相关的所有验证结果
* `created = <ISO-expression>`以匹配在规定时间内创建的所有验证结果
* `notificationSent=<boolean>` 仅匹配已发送或未发送通知的验证结果

如果组合了过滤器，则所有条件都必须为真（AND逻辑）。

一些例子：

要删除 2020 年第一季度与 UID 为`NqwvaQC1ni4`的组织单位相关的所有验证结果，请使用：

```
DELETE /api/36/validationResults?ou=NqwvaQC1ni4&pe=2020Q1
```

要删除在2019年第1周创建的且已发送通知的所有验证结果，请使用：

```
DELETE /api/36/validationResults?created=2019W1&notificationSent=true
```

任何删除操作都需要_执行维护任务_权限。


## 离群值检测 { #outlier-detection } 

异常值检测端点允许检测聚合数据值中的异常值。

```
GET / api / 36 / outlierDetection
```

该端点支持两种用于检测离群值的算法：

* ** Z分数：** Z分数定义为分数与平均值之间的绝对偏差除以标准偏差。必须使用z分数算法指定一个阈值参数，该阈值参数表示与平均值之间的标准偏差，以定义异常值的上限和下限。
* **修改后的 Z 分数：** 与 z 分数相同，只是它使用中位数而不是均值作为集中趋势的度量。参数与 Z 分数相同。
* ** Min-max：** Min-max数据元素值是指可以根据数据元素，组织单位和类别选项组合插入DHIS 2的自定义边界。

离群值将*根据显着性*排序，默认情况下是与均值的绝对偏差，最高有效值在前。这有助于快速识别对数据质量和数据分析影响最大的离群值。

### 请求查询参数 { #request-query-parameters } 

支持以下查询参数。

| 查询参数 | 描述                                                  | 强制的 | 选项（默认为默认）                   |
| --------------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| ds              | 数据集，可以多次指定。                   | 不 [*]    | 数据集标识符。                      |
| 德              | 数据元素，可以多次指定。               | 不 [*]    | 数据元素标识符。                  |
| 开始日期       | 间隔的开始日期，以检查异常值。               | 是的       | 日期（yyyy-MM-dd）。                        |
| 结束日期         | 检查异常值的时间间隔的结束日期。                 | 是的       | 日期（yyyy-MM-dd）。                        |
| 欧              | 组织单位，可以多次指定。          | 是的       | 组织单位标识符。             |
| 算法       | 用于离群值检测的算法。                      | 不        | `Z_SCORE`、`MIN_MAX`、`MOD_Z_SCORE`       |
| 临界点       | 异常值阈值。仅限于 `Z_SCORE` 和 `MOD_Z_SCORE` 算法。 | 不        | 数值，大于零。默认值：3.0。 |
| 数据开始日期   | 计算均值和 std dev 的区间起始日期。仅限于 `Z_SCORE` 和 `MOD_Z_SCORE` 算法。 | 不        | 日期（yyyy-MM-dd）。 |
| 数据结束日期     | 平均值和 std dev 计算间隔的结束日期。仅限于 `Z_SCORE` 和 `MOD_Z_SCORE` 算法。 | 不        | 日期（yyyy-MM-dd）。   |
| 订购         | 按字段排序。仅限`Z_SCORE`和`MOD_Z_SCORE`算法。| 不        | `MEAN_ABS_DEV`，`Z_SCORE`                 |
| 最大结果      | 输出的最大限制。                                    | 不        | 整数，大于零。默认值：500。 |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.

必须定义至少一个数据集或数据元素，开始日期和结束日期以及至少一个组织单位。

The `startDate` and `endDate` parameters are mandatory and refer to the time interval for which you want to detect outliers. The `dataStartDate` and `dataEndDate` parameters are optional and refer to the time interval for the data to use when calculating the mean and std dev, which are used to eventually calculate the z-score.

### 用法和示例 { #usage-and-examples }

使用默认的z分数算法获取异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆ou = fdc6uOvgoji＆startDate = 2020-01-01＆endDate = 2020-12-31
```

使用特定算法和特定阈值获取异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆algorithm = Z_SCORE＆threshold = 2.5
```

获取按z分数排序的异常值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆orderBy = Z_SCORE
```

获取前10个离群值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆maxResults = 10
```

获取具有定义间隔的离群值，以供在计算均值和标准差开发数据时使用的数据：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt
  ＆ou = O6uvpzGd5pu＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆dataStartDate = 2018-01-01＆dataEndDate = 2020-12-31
```

使用最小-最大算法获取离群值：

```
GET / api / 36 / outlierDetection？ds = BfMAe6Itzgt＆ds = QX4ZTUbOt3a
  ＆ou = O6uvpzGd5pu＆ou = fdc6uOvgoji＆startDate = 2020-01-01＆endDate = 2020-12-31
  ＆algorithm = MIN_MAX
```

### 回应格式 { #response-format } 

支持以下响应格式。

| 格式 | API格式                                                   |
| ------ | ------------------------------------------------------------ |
| JSON格式   | `/ api / 36 / outlierDetection.json`或`Accept：application / json`（默认格式） |
| CSV    | `/ api / 36 / outlierDetection.csv`或`接受：application / csv`  |

响应包含以下字段：

| 领域      | 描述                                                  |
| ---------- | ------------------------------------------------------------ |
| 德         | 数据元素标识符。                                     |
| 取消命名     | 数据元素名称。                                           |
| 聚乙烯         | 期间ISO标识符。                                       |
| 欧         | 组织单位标识符。                                |
| 组织名称     | 组织单位名称。                                      |
| 可可        | 类别选项组合标识符。                      |
| coc名称    | 类别选项组合名称。                            |
| 冠捷        | 属性选项组合标识符。                     |
| aoc名称    | 属性选项组合名称。                           |
| 价值      | 数据值。                                                  |
| 意思是       | 时间维度中数据值的平均值。                   |
| 标准差     | 标准偏差。                                          |
| 绝对值     | 对于z得分，与均值的绝对偏差。对于最小-最大，与最小或最大边界的绝对偏差。 |
| 分数     | Z分数。仅Z分数算法。                         |
| 下界 | 下边界。                                          |
| 上限 | 上限。                                          |
| 跟进   | 数据值是否标记为后续。                  |

The `mean`, `stdDev` and `zScore` fields are only present when `algorithm` is `Z_SCORE`.

响应将与此类似。 `元数据`部分包含请求和响应的元数据。 `outlierValues` 部分包含异常值。

```json
{
  "metadata": {
    "algorithm": "Z_SCORE",
    "threshold": 2.5,
    "orderBy": "MEAN_ABS_DEV",
    "maxResults": 10,
    "count": 10
  },
  "outlierValues": [
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202011",
      "ou": "Pae8DR7VmcL",
      "ouName": "MCH (Kakua) Static",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 9000.0,
      "mean": 1524.5555,
      "stdDev": 2654.4661,
      "absDev": 7475.4444,
      "zScore": 2.8161,
      "lowerBound": -5111.6097,
      "upperBound": 8160.7208,
      "followUp": false
    },
    {
      "de": "rbkr8PL0rwM",
      "deName": "Iron Folate given at ANC 3rd",
      "pe": "202010",
      "ou": "vELbGdEphPd",
      "ouName": "Jimmi CHC",
      "coc": "pq2XI5kz2BY",
      "cocName": "Fixed",
      "aoc": "HllvX50cXC0",
      "aocName": "default",
      "value": 8764.0,
      "mean": 1448.0833,
      "stdDev": 2502.3031,
      "absDev": 7315.9166,
      "zScore": 2.9236,
      "lowerBound": -4807.6745,
      "upperBound": 7703.8412,
      "followUp": false
    }
  ]
}
```

### 约束与验证 { #constraints-and-validation } 

在查询验证期间，以下约束适用。每个验证错误都有一个对应的错误代码。

| 错误代码 | 信息                                                      |
| ---------- | ------------------------------------------------------------ |
| E2200      | 必须至少指定一个数据元素                  |
| E2201      | 必须指定开始日期和结束日期                    |
| E2202      | 开始日期必须早于结束日期                           |
| E2203      | 必须至少指定一个组织单位             |
| E2204      | 阈值必须为正数                          |
| E2205      | 最高结果必须为正数                        |
| E2206      | 最大结果超出了允许的最大限制：{d}               |
| E2207      | 数据开始日期必须早于数据结束日期                 |
| E2208      | 离群值检测期间遇到的非数字数据值 |

## 数据分析 { #webapi_data_analysis } 

用于执行数据分析和查找数据质量的多种资源
并提供验证问题。

**注意：**不建议使用此端点，该端点将在2.38中删除。请改用`outlierAnalysis`端点。

### 验证规则分析 { #webapi_data_analysis_validation_rules } 

要运行验证规则并检索违规：

    GET /api/dataAnalysis/validationRules

支持以下查询参数：



表：验证规则分析查询参数

| 查询参数 | 描述 | 选项 |
|---|---|---|
| 弗格 | 验证规则组 | ID |
| 欧 | 组织单位 | ID |
| 开始日期 | 时间跨度的开始日期 | 日期 |
| 结束日期 | 时间跨度的结束日期 | 日期 |
| 坚持 | 是否将违规行为保留在系统中 | 假的&#124;真的 |
| 通知 | 是否发送违规通知 | 假的&#124;真的 |

样本输出：
```json
    [{
    "validationRuleId": "kgh54Xb9LSE",
    "validationRuleDescription": "Malaria outbreak",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 10.0,
    "operator": ">",
    "rightSideValue": 14.0
}, {
    "validationRuleId": "ZoG4yXZi3c3",
    "validationRuleDescription": "ANC 2 cannot be higher than ANC 1",
    "organisationUnitId": "DiszpKrYNg8",
    "organisationUnitDisplayName": "Ngelehun CHC",
    "organisationUnitPath": "/ImspTQPwCqd/O6uvpzGd5pu/YuQRtpLP10I/DiszpKrYNg8",
    "organisationUnitAncestorNames": "Sierra Leone / Bo / Badjia / ",
    "periodId": "201901",
    "periodDisplayName": "January 2019",
    "attributeOptionComboId": "HllvX50cXC0",
    "attributeOptionComboDisplayName": "default",
    "importance": "MEDIUM",
    "leftSideValue": 22.0,
    "operator": "<=",
    "rightSideValue": 19.0
}]
```

### 基于标准差的离群分析 { #webapi_data_analysis_std_dev_outlier } 

根据平均值的标准偏差识别数据异常值
价值：

    GET /api/dataAnalysis/stdDevOutlier

支持以下查询参数：



表：标准差异常值分析查询参数

| 查询参数 | 描述 | 选项 |
|---|---|---|
| 欧 | 组织单位 | ID |
| 开始日期 | 时间跨度的开始日期 | 日期 |
| 结束日期 | 时间跨度的结束日期 | 日期 |
| ds | 数据组、参数可重复 | ID |
| 标准差 | 与平均值的标准差数 | 数值 |

### 基于最小值/最大值的离群值分析 { #webapi_data_analysis_min_max_outlier } 

要基于最小/最大值来识别数据离群值：

    GET /api/dataAnalysis/minMaxOutlier

支持的查询参数等于基于 *std dev 的异常值
上面描述的分析*资源。

### 后续数据分析 { #follow-up-data-analysis } 

要识别标记为后续的数据：

    GET /api/dataAnalysis/followup

必须定义至少一个数据集或数据元素、开始日期和结束日期或期间，以及至少一个组织单位。

支持以下查询参数。

| 范围  | 描述                                                  | 强制的 | 选项（默认为默认）                   |
| ---------- | ------------------------------------------------------------ | --------- | ----------------------------------------- |
| 欧         | 组织单位，可以多次指定。          | 是的       | 组织单位标识符。             |
| ds         | 数据集，可以多次指定。                   | 不 [*]    | 数据集标识符。                      |
| 德         | 数据元素，可以多次指定。               | 不 [*]    | 数据元素标识符。                  |
| 开始日期  | 间隔的开始日期，以检查异常值。               | 不 [*]    | 日期（yyyy-MM-dd）。                        |
| 结束日期    | 检查异常值的时间间隔的结束日期。                 | 不 [*]    | 日期（yyyy-MM-dd）。                        |
| 聚乙烯         | ISO 周期 ID。                                               | 不 [*]    | 周期 ISO ID。                        |
| pe类型     | ISO 时期。                                                  | 不 [*]    | 句点 ISO 字符串。                        |
| 可可        | 类别选项组合，可以指定多次。     | 不        | 类别选项组合标识符。         |
| 最大结果 | 输出的最大限制。                                    | 不        | 整数，大于零。默认值：50。  |

[*]  You must specify either data sets with the `ds` parameter, which will include all data elements in the data sets, _or_ specify data elements with the `de` parameter.
     Equally, either `startDate` and `endDate` _or_ `period` must be specified.

The `startDate` and `endDate` parameters refer to the time interval for which you want to detect outliers.
If a period `pe` is provided instead the interval start and end is that of the period.

如果未提供选项组合`coc`，则考虑所有数值类型的数据元素。


## 数据的完整性 { #webapi_data_integrity } 

数据管理模块的数据完整性功能是
可通过 Web API 获取。本节介绍如何运行
数据完整性处理并检索结果。具体的
用户手册中描述了有关每项检查的详细信息。

### 列出可用的数据完整性检查{ #webapi_data_integrity_list }
可用检查的描述由以下请求返回：

    获取 /api/dataIntegrity

```
[
    {
        "名称"："data_elements_without_groups"、
        "displayName"（显示名称）："缺少分组的数据元素"、
        "部分"："数据元素"、
        "严重性"："警告"、
        "描述"："列出没有数据元素组的所有数据元素"、
        "issuesIdType"："dataElements"、
        "isSlow": false
    }
]
```

The `name` member of the returned check elements is the identifier used for the
`checks` parameter to declare the set of checks to run.

> **注**
> 
> 每项检查都会通过 `isSlow` 字段说明完成检查是否需要大量时间和资源。 
> 用户在生产系统上运行这些
> 检查，因为它们可能导致性能下降。 
> 这些检查可以单独运行，但除非特别要求，否则不会运行。 
> 除非特别要求，否则不会运行。

Checks are grouped semantically by the `section` member and categorised in 
one of four `severity` levels:

| 严重性 | 描述                                                                                                                   |
| -------- |-------------------------------------------------------------------------------------------------------------------------------|
| 信息     | 表明这仅供参考。                                                                                  |
| 警告  | 警告表明这可能是一个问题，但不一定是错误。不过，建议对这些问题进行分类。 |
| 严重   | 应该修复但不一定会导致系统无法运行的错误。                               |
| 批判的 | 必须修复的错误，该错误可能会导致最终用户错误或系统崩溃。                                           |

可使用 `checks` 参数过滤可用的检查。

    GET /api/dataIntegrity?checks=<pattern1>,<pattern2>

可提供一个或多个精确名称或使用 `*` 作为通配符的模式。

Additional results can be filtered using a `section` parameter.

    GET /api/dataIntegrity?section=类别

The `section` filter will return all exact matches which have the specified section. 

此外，要只过滤（选择）标记为 `isSlow` 的校验，请使用 `slow=true`、

    GET /api/dataIntegrity?slow=true

或仅过滤（选择）不通过数据库查询执行的检查 
(程序化检查）时使用 `programmatic=true`：

    GET /api/dataIntegrity?programmatic=true

The `slow`, `programmatic` and `section` filters can be combined in which case
all conditions must be met.

### 运行数据完整性汇总{ #webapi_data_integrity_run_summary }

自 2.38 版起，数据完整性检查有两个特定级别： 
- a `summary` level that provides an overview of the number of issues
- a `details` level that provides a list of issues pointing to individual data integrity violations.

要对运行的一组检查触发汇总分析：

    POST /api/dataIntegrity/summary?checks=<name1> 、<name2>

这将触发一个异步运行检查的作业。单个检查结果
将在检查完成后立即返回应用程序缓存。

另外，检查列表也可以作为 POST 请求的 BODY 提供。
如果列表过长，无法在 URL 中使用，这将非常有用。

要获取已触发检查的数据完整性摘要，请使用

    GET /api/dataIntegrity/summary?checks=<name1> 、<name2>

When the `checks` parameter is omitted, all checks are fetched from the server cache.

响应是检查结果的 "映射"，每个已完成的检查结果都有一个 "映射"。
这些信息将缓存一小时或直到重新运行检查。

To wait for the summary to be available in the cache a `timeout` in milliseconds can be added:

    GET /api/dataIntegrity/summary?checks=<name1>,<name2>&timeout=500

简要回复的示例如下 
```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 12,
    "percentage": 2.3
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "count": 4,
    "percentage": 5.1
  }
}
```

Each summary response will contain the `name`, `section`, `severity`, 
`description` and optionally  an `introduction` and `recommendation`.  
Each summary contains the number of issues found in the `count` field. When possible,
an optional `percentage` field will provide the percentage of objects with data
integrity issues when compared to all objects of the same type.
The `startTime` field indicates when the check was initiated. Using the `finishedTime`
the duration which was required to execute the check can be calculated.

Should a check analysis fail due to programming error or unforeseen data inconsistencies
both the summary and the details will have an `error` field describing the error that occurred.
The `count` of any checks which failed will be set to -1. 
No `percentage` will be returned in such cases.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "finishedTime": "2022-02-15 14:55",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "error": "what has happened",
    "issues": []
  }
}
```

> **注**
> 
> 每次元数据检查都在服务器上异步运行。  结果
> 每次检查完成后都会立即返回结果。最安全的方法是确保 
> 确保已检索到最新结果集的最安全方法是 
> 最安全的方法是将发出请求的时间戳
> 与响应中的 `finishedTime` 进行比较。

要获取当前由 
使用

    GET /api/dataIntegrity/summary/running

要获取已有结果的检查名称列表，请使用

    GET /api/dataIntegrity/summary/completed


### 运行数据完整性详情{ #webapi_data_integrity_run_details }

To run a selection of details checks first trigger them using a  `POST` request:

    POST /api/dataIntegrity/details?checks=<name1> 、<name2>

与摘要类似，检查列表也可以作为 POST 主体提供。

然后从缓存中获取结果：

    GET /api/dataIntegrity/details?checks=<name1>,<name2>&timeout=500

When the `checks` parameter is not provided,  all checks which 
have not been marked as `isSlow` will be scheduled to be run on the server.

省略 `timeout` 将不会等待在缓存中找到结果、 
而是不会有请求检查的结果。

The `/details` response returns a map similar to the `summary`, but does not contain
a `count` or `percentage`. Instead, a list of `issues` is returned.

```json
{
  "<name1>": {
    "name": "<name1>",
    "displayName": "<displayName1>",
    "startTime": "2023-01-11T06:12:56.436",
    "finishedTime": "2023-01-11T06:12:57.021",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": [{
      "id": "<id-or-other-identifier>",
      "name": "<name-of-the-id-obj>",
      "comment": "optional plain text description or hint of the issue",
      "refs": ["<id1>", "<id2>"]
    }]
  },
  "<name2>": {
    "name": "<name2>",
    "displayName": "<displayName2>",
    "startTime": "2023-01-11T06:12:57.345",
    "finishedTime": "2023-01-11T06:12:58.007",
    "section": "...",
    "severity": "WARNING",
    "description": "...",
    "issuesIdType": "<object-type-plural>",
    "isSlow": false,
    "issues": []
  }
}
```
Each issue will always have `id` and `name` members.  Often the `issuesIdType`
is available to indicate the type of objects the `id` refers to. If the 
`issuesIdType` is not available, the `id` often is not available either and the
`name` is used for an aggregate key of an issue that has no object equivalent.

The `comment` and `refs` fields are optional for each issue.
A `comment` may provide more context or
insight into why this particular issue is regarded to be a data integrity problem. 
The `refs` list may also give the identifiers of other objects that contributed to the violation.
The `finishedTime` field shows when the particular check finished processing on the server.
The cache will store the result of each completed check for one hour.

> **Tip**
>
> A set of checks can also be specified using wild-cards. To include all 
> checks with _element_ in the name use `checks=*element*`. Like full names 
> such patterns can be used in a comma-separated list and be mixed with full 
> names as well. Duplicates will be eliminated. 
> Also a check can be given by its code. A code consists of the first letters
> of each word in the name as upper case letter. 
> For example, `orgunits_invalid_geometry` has the code `OIG`.

与摘要类似，当前执行的和已完成的详细检查的名称集也可以用
可以使用

    GET /api/dataIntegrity/details/running
    GET /api/dataIntegrity/details/completed

### 自定义数据完整性检查{ #custom_data_integrity_checks } 

DHIS2 的用户现在可以创建和提供自己的数据完整性检查。如果用户
如果用户希望利用这一功能，并扩展所提供的核心数据完整性检查集，这将非常有用。

> **Tip**
> 
> Users are also encouraged to share their custom checks with others by opening a pull request in the 
> [dhis2-core](https://github.com/dhis2/dhis2-core) repository containing their `.yaml` file(s).
> Please select `platform-backend` as reviewer to put the PR on our radar early on. The team will 
> take care of checking and linking the check correctly, so it becomes part of the provided suite of 
> checks with the next release. 

自定义检查的一个例子是确定某些用户是否是特定用户组的成员。
这种类型的检查对实施非常具体，一般不适用于所有安装。
这些类型的元数据检查可用于扩展 DHIS2 中的默认检查。

自定义校验可以通过满足以下要求来实现，我们将对每个要求进行详细说明：
- Supplying your own list of custom data integrity checks in a list file named `custom-data-integrity-checks.yaml`
 in your `DHIS2_HOME` directory
- 在您的 `DHIS2_HOME` 目录中建立名为 `custom-data-integrity-checks` 的目录
- 提供有效的自定义数据完整性检查 yaml 文件

#### 自定义数据完整性检查列表文件{ #custom-data-integrity-check-list-file } 

DHIS2 只在需要时才会尝试加载数据完整性文件。
数据完整性检查时：

    GET /api/dataIntegrity

加载数据完整性文件时，DHIS2 会在您的 `DHIS2_HOME` 目录中查找名为 `custom-data-integrity-checks.yaml` 的文件。
数据完整性文件。如果不使用自定义检查，且该文件不存在，则会出现如下警告日志
的警告日志：

```text
08:29:57.729  WARN o.h.d.d.DataIntegrityYamlReader: Failed to load data integrity check from YAML. Error message `{DHIS2_HOME}/custom-data-integrity-checks.yaml (No such file or directory)
```

如果要执行自定义数据完整性检查，则必须有该文件。要查看核心数据完整性检查
文件的示例，请查看 [this file](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks.yaml)。


The `custom-data-integrity-checks.yaml` file should list all of your custom data integrity checks.
As an example, it could look something like this:

```yaml
检查
  - categories/my_custom_check.yaml
  - users/my_user_group_check.yaml
  - base_check.yaml
```

该文件中的检查名称前面可以加上一个目录名称，以便进行逻辑分组。从上面列出的 3 个检查示例 
目录结构应如下所示：

```
├── DHIS2_HOME
├── dhis.conf
├── custom-data-integrity-checks.yaml
│ ├─── custom-data-integrity-checks
类别
│ │ ├── my_custom_check.yaml
│ ├── 用户
│ │ ├── my_user_group_check.yaml
│ ├─── base_check.yaml
```

#### 名称和代码限制{ #name-and-code-constraints } 

每个数据完整性检查 `name` 和 `code` 必须是唯一的。如果有任何冲突，则违反的自定义
检查将不会被加载。

> **注**
>
> 系统数据完整性检查总是先加载。因
> 自定义检查不会影响这些核心系统检查。

数据完整性检查 yaml 文件示例位于 [此处](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks/orgunits/orgunits_orphaned.yaml)
供参考。请注意 `name` 属性。

The data integrity `code` is calculated dynamically by using the first letter of each word in the `name`. Some examples:

| 名称                   | 码 |
|------------------------|------|
| my_custom_check        | MCC  |
| my_second_custom_check | MSCC |
| another_custom_check   | ACC  |

If there is a `name` clash, a warning log like this will be present:
```text
09:48:43.138  WARN o.h.d.d.DefaultDataIntegrityService: Data Integrity Check `my_custom_check` not added as a check with that name already exists
```

If there is a `code` clash, a warning log like this will be present:
```text
09:48:43.138  WARN o.h.d.d.DefaultDataIntegrityService: Data Integrity Check `my_custom_check` not added as a check with the code `MCC` already exists
```

#### 数据完整性检查模式{ #data-integrity-check-schema } 

数据完整性检查文件必须符合[JSON 模式](https://github.com/dhis2/dhis2-core/blob/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks/integrity_check_schema.json)。
如果检查不符合该模式，则会出现如下警告：
```text
09:48:43.136  WARN o.h.d.d.DataIntegrityYamlReader: JsonSchema validation errors found for Data Integrity Check `categories/my_custom_check.yaml`. Errors: [$.name: is missing but it is required]
```

在加载和使用该检查之前，必须纠正任何违反模式的行为。

如果数据完整性检查文件包含无效的 yaml，就会出现类似这样的警告日志：
```text
10:30:37.858  WARN o.h.d.d.DataIntegrityYamlReader: JsonSchema validation errors found for Data Integrity Check `my_custom_check.yaml`. Errors: [$: string found, object expected]
```

要查看和使用自定义检查，请参阅主 [数据完整性部分](#webapi_data_integrity)

> **注**
>
> 建议在实施自定义检查时遵循上述示例中的命名和格式约定。
> 自己的自定义检查，以避免出现任何问题

#### 数据完整性文件{ #data-integrity-file } 

数据完整性检查 yaml 文件的详细信息，摘自 JSON 模式文件

| 财产        | 所需 | 信息                                                                                                                          |
|-----------------|----------|-------------------------------------------------------------------------------------------------------------------------------|
| 名称            | 是的      | 支票的唯一名称                                                                                                      |
| 描述     | 是的      | 描述                                                                                                                   |
| 部分         | 是的      | 用于对检查（如类别、用户）进行逻辑分组                                                                    |
| section_order   | 是的      | 在用户界面中显示时的检查顺序                                                                               |
| 摘要_sql     | 是的      | SQL 查询，该查询应返回代表问题总数的单一结果                                   |
| 详情_sql     | 是的      | SQL 查询，该查询应返回该特定问题中已识别对象的列表。至少应返回 uid 和名称 |
| details_id_type | 是的      | 一个短字符串，用于标识详细信息 SQL 的部分                                                                |
| 严重性        | 是的      | 问题的严重程度。INFO、WARNING、SEVERE、CRITICAL] 中的一个                                                      |
| 导言    | 是      | 概述检查目标                                                                                          |
| 建议  | 是      | 概述如何解决发现的问题                                                                                    |

### 自定义数据完整性检查示例{ #example-custom-data-integrity-check } 


自定义检查的一个例子是确定用户是否有电子邮件。电子邮件对于
与用户沟通、向他们发送通知以及找回密码。因此，在某些
因此，在 DHIS2 的某些系统中，可以规定所有用户都必须有电子邮件。这种类型的
如下所示。

```
---
name: users_should_have_emails
描述：用户应该有电子邮件。
section：用户
section_order：6
summary_sql：>-
  WITH users_noo_email as (
  SELECT uid,username from
  userinfo where email IS NULL)
  SELECT COUNT(*) as value、
  100*COUNT(*) / NULLIF( ( select COUNT(*) from userinfo), 0) as percent
  from users_no_email；
details_sql：>-
  WITH users_noo_email as (
  SELECT uid,username from
  userinfo 中 SELECT uid,username where email IS NULL)
  SELECT uid,username as from users_no_email；
严重性：警告
介绍：>
  用户应定义电子邮件。这对找回密码和向用户发送通知都很重要。
  向用户发送通知。
建议>
  确保所有用户都已定义电子邮件。
details_id_type: 用户
```

关于不同类型元数据完整性检查的更多示例，请参阅 DHIS2 源代码[此处](https://github.com/dhis2/dhis2-core/tree/master/dhis-2/dhis-services/dhis-service-administration/src/main/resources/data-integrity-checks)。

## 完整的数据集注册 { #webapi_complete_data_set_registrations }

本节是关于数据集的完整数据集注册。一种
注册标记作为完全捕获的数据集。

### 完成数据集 { #webapi_completing_data_sets }

本节说明如何将数据集注册为完整。这是
通过与 *completeDataSetRegistrations* 交互实现
资源：

    GET /api/33/completeDataSetRegistrations

端点支持*POST*方法注册数据集
完成。端点在功能上非常类似于
*dataValueSets* 端点，支持批量导入完整
注册。

支持导入 *XML* 和 *JSON* 格式的有效负载。这
这个有效负载的基本格式，在这个例子中以 *XML* 给出，就像
所以：

```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0">
  <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP" 
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
  <completeDataSetRegistration period="200811" dataSet="eZDhcZi6FLP" 
    organisationUnit="qhqAxPSTUXp" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

*storedBy* 属性是可选的（因为它是
完整的注册对象）。您还可以选择设置
*date* 属性（注册时间）作为属性。是时候了
未设置，将使用当前时间。

导入过程支持以下查询参数：



表：完整数据集登记查询参数

| 参数 | 价值观 | 描述 |
|---|---|---|
| dataSetIdScheme | id | name | code | attribute:ID | 用于映射完整注册信息的数据集属性。 |
| orgUnitIdScheme | id | name | code | attribute:ID | 组织单位的属性，用于映射完整的注册信息。 |
| 属性 OptionComboIdScheme | id | name | code | attribute:ID | 用于映射完整注册的属性选项组合的属性。 |
| 方案 | id | name | code | attribute:ID | 所有对象（包括数据集、组织单位和属性选项组合）的属性，用于映射完整的注册。 |
| 预热缓存 | 假 | 真 | 是在服务器上保存更改，还是只返回导入摘要。 |
| 干运行 | 假 | 真 | 登记是否适用于次级单位 |
| 导入策略 | CREATE &#124; UPDATE &#124; CREATE_AND_UPDATE &#124; DELETE | 在服务器上保存所有、新增或更新导入状态的对象。 |
| 跳过现有检查 | 假 | 真 | 跳过对现有完整注册的检查。提高性能。仅用于空数据库或要导入的注册信息不存在时。 |
| 异步 | 假 | 真 | 表示导入是以异步方式还是同步方式进行。前者适用于非常大的导入，因为它能确保请求不会超时，但性能开销很大。后者速度更快，但要求连接持续到进程结束。 |

The `idScheme`, `dataSetIdScheme`, `orgUnitIdScheme`, `attributeOptionComboIdScheme`, 
`dryRun` and `strategy` (note the dissimilar naming to parameter `importStrategy`) 
can also be set as part of the payload.
In case of XML these are attributes, in case of JSON these are members in the
`completeDataSetRegistrations` node.

例如：
```xml
<completeDataSetRegistrations xmlns="http://dhis2.org/schema/dxf/2.0"
      orgUnitIdScheme="CODE">
    <completeDataSetRegistration period="200810" dataSet="eZDhcZi6FLP"
    organisationUnit="OU_559" attributeOptionCombo="bRowv6yZOF2" storedBy="imported"/>
</completeDataSetRegistrations>
```

如果 URL 参数和有效载荷都设置了方案，则有效载荷优先。 

### 读取完整的数据集注册 { #webapi_reading_complete_data_sets } 

本节说明如何检索数据集完整性
注册。我们将使用 *completeDataSetRegistrations*
资源。要使用的查询参数如下：



表：数据值集查询参数

| 参数 | 描述 |
|---|---|
| 数据集 | 数据集标识符，允许多个数据集 |
| 时间 | ISO 格式的句号标识符。允许使用多个句号。 |
| 开始日期 | 要导出的数值时间跨度的起始日期 |
| 结束日期 | 要导出的数值时间跨度的结束日期 |
| 创建 | 只包括给定时间戳后创建的注册 |
| 创建持续时间 | 只包括在给定时间内创建的注册。格式为<value\><time-unit\> ，其中支持的时间单位为 "d"、"h"、"m"、"s" *（天、小时、分钟、秒）。* 时间单位相对于当前时间。 |
| orgUnit | 组织单位标识符，可多次指定。如果给出 orgUnitGroup，则不适用。 |
| 组织单位组 | 组织单位组标识符，可多次指定。如果给出 orgUnit，则不适用。 |
| 儿童 | 是否将子女纳入组织单位的层级结构中 |
| 限额 | 要包含在回复中的最大注册数。 |
| 方案 | 用于响应中元数据对象的标识符属性。 |
| dataSetIdScheme | 用于响应中数据集的标识符属性。重载 idScheme。 |
| orgUnitIdScheme | 响应中用于组织单位的标识符属性。重载 idScheme。 |
| 属性 OptionComboIdScheme | 用于响应中属性选项组合的标识符属性。重载 idScheme。 |
The `dataSet` and `orgUnit` parameters can be repeated in order to include multiple data sets and organisation units.

The `period`, `startDate`,  `endDate`, `created` and `createdDuration` parameters provide multiple ways to set the time dimension for the request, thus only
one can be used. For example, it doesn't make sense to both set the start/end date and to set the periods.

请求示例如下所示：

```bash
GET /api/33/completeDataSetRegistrations?dataSet=pBOMPrpg1QX
  &startDate=2014-01-01&endDate=2014-01-31&orgUnit=YuQRtpLP10I
  &orgUnit=vWbkYPRmKyS&children=true
```

您可以获得 *xml* 和 *json* 格式的响应。你可以指出
通过 *Accept* HTTP 标头，您更喜欢哪种响应格式
在上面的例子中。对于 xml，您使用 *application/xml*；对于 json 你
使用*应用程序/json*。

### 未完成的数据集 { #webapi_uncompleting_data_sets } 

本节说明如何取消注册数据的完整性
放。要取消完成数据集，您将与
completeDataSetRegistrations 资源：

    GET /api/33/completeDataSetRegistrations

此资源支持*DELETE* 取消注册。以下查询
支持参数：



表：完整数据集登记查询参数

| 查询参数 | 需要 | 描述 |
|---|---|---|
| ds | 是的 | 数据集标识符 |
| 聚乙烯 | 是的 | 期间标识符 |
| 欧 | 是的 | 组织单位标识符 |
| cc | 否（必须与 cp 结合） | 属性组合标识符（用于锁定检查） |
| cp | 否（必须与 cp 结合） | 属性选项标识符，多个值用 ; 分隔（用于锁定检查） |
| 多欧 | 否（默认为假） | 登记是否适用于次级单位 |

