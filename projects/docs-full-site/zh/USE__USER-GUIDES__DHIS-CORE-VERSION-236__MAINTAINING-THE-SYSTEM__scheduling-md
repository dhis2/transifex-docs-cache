---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.36/src/user/scheduling.md"
revision_date: "2021-06-14"
tags:
    - 使用
    - DHIS 核心 2.36 版
---

# 排程 { #scheduling }

计划程序是用于管理DHIS2中的后台作业的应用程序。
后台作业可以执行许多任务，例如运行分析，
同步数据和元数据，或发送推送分析报告。的
应用程序提供了创建，修改和删除此类作业的功能。

调度程序与DHIS2捆绑在一起，可以通过应用程序进行访问
菜单。

![The start page of the Scheduler app](resources/images/scheduler/overview.png)

日程安排程序的起始页显示现有工作的概览。默认情况下，预定义的系统作业是隐藏的。要查看这些工作，请单击右上角的_在列表中包含系统工作_。

创建或修改作业时，将根据所选计划安排作业。要按需运行作业，请进入作业列表，单击要运行作业的 "操作 "按钮，然后单击 "手动运行"。此操作仅适用于已启用的作业。

## 创造工作 { #scheduling_create_job }

1.  打开**日程安排**应用程序，点击右上角的 "新任务 "按钮。

1.  Choose a suitable **Name** for the new job.

1.  Select the **Job type** you want to schedule using the drop-down menu.

1.  为作业选择计划。每个作业类型都有自己的调度类型，可以是 **Cron** 调度，也可以是 **Delay** 调度。

    1.  对于 **Cron** 计划作业类型，您可以使用 [Spring scheduling](https://docs.spring.io/spring/docs/current/javadoc-api/org/springframework/scheduling/support/CronSequenceGenerator.html) 语法设置计划。您也可以点击 "从预设时间中选择 "来选择预定义的**Cron 表达式**。该计划只有在前一个作业运行结束后才会启动新的作业运行，以防止系统产生过多作业。

    1.  对于 **Delay** 计划任务，您可以设置以秒为单位的延迟时间。与**Cron**计划作业不同的是，这些作业不是按照设定的时间表执行，而是在作业运行之间有特定的延迟。延迟计时器在作业结束时开始计时，当延迟计时器计时到零时开始新的作业运行。只要作业启用，这种情况就会持续。

1.  如果作业类型是可定制的，则调度设置下方会出现**参数**部分。这些附加选项指定了计划作业的详细信息，并根据作业类型而有所不同。

1.  按下**保存**按钮确认创建工作。作业创建成功后，您将跳转到作业概览，新创建的作业将列在其中。

![Creating a new scheduler job](resources/images/scheduler/add_new_job.png)

新创建的工作默认为启用。

## 编辑工作{ #scheduling_configure_job }

有了适当的权限，您就可以修改用户创建的作业的详细信息。要快速启用或禁用用户创建的作业，请使用日程安排程序着陆页上**开/关**列中的开关。请注意，系统作业始终处于启用状态，无法禁用。

进一步编辑用户工作：

1.  单击要编辑的作业的 "操作 "按钮，然后单击 "编辑"（只能编辑用户作业）。

1.  编辑完成后，按下**保存**按钮以保留更改。

## 删除工作 { #dataAdmin_scheduler_delete }

1.  单击要删除的作业的 "操作 "按钮，然后单击 "删除"（只能删除用户作业）。

1.  在弹出窗口中再次按** Delete **进行确认。

也可以从编辑屏幕删除用户任务。

![Deleting a scheduler job](resources/images/scheduler/delete_job.png)

## 工作类型 { #job-types }

以下部分描述了各种作业类型。

### 禁用非活动用户{ #scheduling_disable_inactive_users }

可以自动禁用几个月未活动（未登录）的用户。选择不活动月数作为任务参数。所有在该月数或更长时间内未登录的用户都将被任务禁用。被禁用的用户将无法再登录系统。

### 资源表 { #scheduling_resource_table }

资源表作业负责生成和更新资源数据库表。这些表由DHIS 2中的各个组件使用，旨在简化针对数据库的查询。

请注意，当指定任何分析表作业时，资源表可以是该过程的一部分，并且也不必指定资源表作业。

### 分析表 { #scheduling_analytics_table }

分析表作业负责生成和更新分析表。分析表用作DHIS2中数据分析查询的基础。仪表板，可视化工具和地图等应用程序通过DHIS2分析API从这些表中检索数据，并且必须对其进行更新才能使分析数据可用。您可以安排此过程通过分析表作业类型定期运行。

默认情况下，分析表作业将填充所有年份和数据元素的数据。可以使用以下参数：

-   **过去几年：**为其填充分析表的最后几年的数量。例如，如果您指定2年，则该过程将更新最近两年的数据，而不更新较旧的数据。此参数对减少过程完成所需的时间很有用，并且如果旧数据没有更改，并且需要更新最新数据，则该参数非常适用。
-   **跳过资源表：**在分析表更新过程中跳过资源表。这减少了过程完成所需的时间，但导致元数据的更改未反映在分析数据中。
-   **跳过表类型：**跳过一种或多种分析表类型。这减少了过程完成所需的时间，但导致这些数据类型未在分析数据中更新。

### 连续分析表 { #scheduling_continuous_analytics_table }

分析表作业负责生成和更新分析表。分析表用作DHIS2中数据分析查询的基础。仪表板，可视化工具和地图等应用程序通过DHIS2分析API从这些表中检索数据，并且必须对其进行更新才能使分析数据可用。您可以安排此过程通过分析表作业类型定期运行。

连续分析表作业基于两个阶段：

-   _最新更新：_最新数据的更新，其中最新是指自上次更新最新数据或完整数据以来已添加，更新或删除的数据。此过程将经常发生。
-   _完整更新：_多年来所有数据的更新。此过程每天进行一次。

连续分析表作业将经常更新最新数据。最新数据处理使用特殊的数据库分区，该分区仅用于保存最新数据。由于数据量相对较少，因此可以快速刷新此分区。分区的大小将增加，直到执行完全更新。每天一次，将更新所有年份的所有数据。这将清除最新的分区。

默认情况下，分析表作业将填充所有年份和数据元素的数据。可以使用以下参数：

-   **一天中的完整更新时间：**一天中的完整更新将在这一小时完成。例如，如果您指定1，则将在凌晨1点执行完整更新。
-   **过去几年：**为其填充分析表的最后几年的数量。例如，如果您指定2年，则该过程将更新最近两年的数据，而不更新较旧的数据。此参数对减少过程完成所需的时间很有用，并且如果旧数据没有更改，并且需要更新最新数据，则该参数非常适用。
-   **跳过资源表：**在分析表更新过程中跳过资源表。这减少了过程完成所需的时间，但导致元数据的更改未反映在分析数据中。

### 数据同步 { #scheduling_data_sync }

DHIS2 提供远程分布式实例与 DHIS2 中央实例之间的数据同步。例如，当您部署了多个独立的 DHIS2 实例，需要向中央 DHIS2 实例提交数据值时，这就非常有用。DHIS2 支持跟踪数据和汇总数据同步。

这些是启用数据同步的步骤：

-   转到同步设置，输入远程服务器 URL、用户名和密码。按 TAB 键自动保存新密码。刷新页面，检查已填写的值是否仍然存在。请注意，刷新后密码字段将为空，因为该值已加密，所以可以认为已保存。

-   使用 "日程安排程序 "应用程序，使用 "事件程序数据同步 "和/或 "跟踪程序数据同步 "作业类型创建新作业。完成后确保已启用。(注意：如果以前版本中的 "程序数据同步 "作业已在日程安排程序中设置，则会自动被设置相同的两个新作业 "事件程序数据同步 "和 "跟踪程序数据同步 "取代。)

数据同步功能的某些方面需要注意：

-   本地 DHIS2 实例将在本地数据库中加密存储远程实例上用户账户的密码。远程账户用于传输数据时的身份验证。为安全起见，请确保将 _hibernate.properties_ 中的 _encryption.password_ 配置参数设置为高强度密码。

-   强烈建议在 SSL/HTTPS 上部署远程服务器，因为用户名和密码是使用基本身份验证以明文发送的，可能会被攻击者截获。

-   数据同步使用数据元素、类别选项组合和组织单位的 UID 属性来匹配元数据。因此，同步取决于这三个元数据对象在本地和远程实例上是否一致，以便正常工作。

-   DHIS2 首次运行同步作业时，将包括所有可用数据。随后的同步作业将只包括上次成功作业后添加和更改的数据。只有当所有数据都成功保存在远程服务器上时，同步作业才算成功（无论作业最终是否失败，任何成功同步的数据都将保留在接收实例中）。任务是否成功可以从中央服务器返回的导入摘要中判断。

-   初始同步工作可能会耗费大量时间，可能会降低实例的运行速度，这取决于同步数据的数量。最好先将任务配置为在线用户较少时运行，然后再根据自己的偏好进行更改。如果不想或不需要同步所有数据，可以通过<a href="#skip_changed_before">跳过正在同步的部分数据</a> 。

    DHIS2 同步跟踪器数据时，会根据上次同步的时间确定要同步的数据集。每个被跟踪的实体实例和事件都有自己的记录，说明它们上次成功同步的时间。

-   系统将根据同步作业配置中设置的规则启动同步作业。如果同步作业在没有连接到远程服务器的情况下启动，系统最多会重试三次，然后中止。任务将在预定时间再次运行。

-   服务器会单独处理每组程序，这意味着一组程序可以成功同步，而另一组则会失败。其中一个程序的失败或成功不会影响另一个程序，因为如前所述，最后一次成功同步的时间是为每个项目单独跟踪的。

-   已打开 "跳过同步 "选项的 TrackedEntityInstances（TrackedEntityAttribute）属性和 ProgramStage（ProgramStageDataElement）数据元素将不会同步。通过这项功能，您可以决定不同步某些敏感或不相关的数据，而仅在本地保存这些数据。

-   The authority `Ignore validation of required fields in Tracker and Event Capture` (`F\_IGNORE\_TRACKER\_REQUIRED\_VALUE\_VALIDATION`) should be used when there is a requirement that some mandatory attribute / data element has at the same time a "Skip synchronization" property turned on. Such a setting will lead to validation failure on the central server as the given attribute / data element will not be present in the payload.

    拥有此权限的用户不会出现验证失败。该权限应分配给用于同步工作的中央服务器上的用户。

-   在特定情况下，**初始同步所有数据可能并不可取**；例如，当本地实例上的数据库是中央实例上数据库的新副本时，或者当希望不同步旧数据以节省初始同步时间时。

    The _syncSkipSyncForDataChangedBefore_ SettingKey can be used to skip the synchronisation of all the data (data values, Event and Tracker program data, complete data set registrations) that were _last changed before the specified date_. The `SettingKey` is used in the synchronization job all the time. Therefore, if you need to synchronize the old data, you should change the `SettingKey`.

-   跟踪程序和事件程序同步作业都支持分页，以避免超时和应对不稳定的网络。事件程序数据同步 "任务的默认页面大小设为 60。跟踪程序数据同步 "任务的默认页面大小设为 20。

    如果默认值不符合您的要求，可以通过 "日程安排程序 "应用程序中特定同步作业的参数指定自己的页面大小。

### 元数据同步调度 { #scheduling_metadata_sync }

DHIS2提供了用于同步远程元数据的功能
实例到DHIS2的本地实例。当您有
部署了DHIS2的多个独立实例，您需要创建
所有本地实例中的元数据都类似于中央DHIS2
实例。

这些是启用元数据同步的步骤：

-   转到设置 \> 同步，输入远程服务器 URL、用户名和密码，然后单击保存。

-   转到 Metadata administration （元数据管理）\> Scheduling（日程安排）。在元数据同步下将策略设为启用，选择时间段并单击开始。

元数据同步功能的某些方面需要注意：

-   本地 DHIS2 实例将在其数据库中存储远程实例用户账户的密码。远程用户账户用于传输/下载数据时的身份验证。为安全起见，请确保将 _hibernate.properties_ 中的 _encryption.password_ 配置参数设置为高强度密码。

-   强烈建议在 SSL/HTTPS 上部署远程服务器，因为用户名和密码是使用基本身份验证以明文发送的，可能会被攻击者截获。

-   还要确保远程用户不具有 ALL 权限，而只需创建一个具有 F_METADATA_MANAGE 权限的用户，这样即使黑客截获了这些详细信息，也无法完全控制远程系统。

-   元数据同步依赖于底层导入层。每个元数据版本都是两个给定时间戳之间元数据的输出。元数据版本的每次同步都是尝试将该元数据快照导入本地实例。版本同步是增量式的。本地实例会尝试一个接一个地从中心实例下载元数据版本。如果无法同步特定元数据版本，则无法继续同步其他版本。如果出现故障，必须对中心的元数据进行适当更改，以确保错误得到解决。元数据配置至关重要，用户在向生产系统推出更新时应小心谨慎。建议始终建立暂存环境，以确保元数据版本的正确性及其后续影响。本地实例将同步第一个版本的元数据，以保持和谐，并使本地和中央实例正常工作。

-   系统将在预定时间尝试同步。如果本地或远程服务器当时没有正常的互联网连接，同步将被中止，然后根据_dhis.conf_文件中提到的重试次数重新尝试。

-   您可以在日程安排屏幕中 "上次成功 "标签旁边看到上次与远程服务器同步成功的时间。
