---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.39/src/developer/web-api/scheduling.md"
revision_date: '2022-09-13'
tags:
- DHIS core version 2.39
- Desenvolver
---

# Agendamento { #webapi_scheduling }

O DHIS2 permite o agendamento de trabalhos de vários tipos. Cada tipo de trabalho possui propriedades diferentes para configuração, oferecendo um controle mais preciso sobre como os trabalhos são executados. Além disso, você pode configurar o mesmo trabalho para ser executado com configurações diferentes e em intervalos diferentes, se necessário.



Table: Main properties

| Property | Descrição | Modelo |
|---|---|---|
| nome | Name of the job. | Corda |
| cronExpression | The cron expression which defines the interval for when the job should run. | String (Cron expression) |
| jobType | The job type represent which task is run. In the next table, you can get an overview of existing job types. Each job type can have a specific set of parameters for job configuration. | String (Enum) |
| jobParameters | Job parameters, if applicable for job type. | (See list of job types) |
| enabled | A job can be added to the system without it being scheduled by setting `enabled` to false in the JSON payload. Use this if you want to temporarily stop scheduling for a job, or if a job configuration is not complete yet. | Boolean |



### Job Parameters { #job-parameters } 

Table: `DATA_INTEGRITY` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `checks` | array of string | `[]` = all | names of the checks to run in order of execution |
| `type`   | enum            | `REPORT`   | REPORT, SUMMARY or DETAILS                       |

Table: `ANALYTICS_TABLE` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `lastYears` | int  | 0       | Number of years back to include |
| `skipTableTypes` | array of enum  | `[]`    | Skip generation of tables; Possible values: `DATA_VALUE`, `COMPLETENESS`, `COMPLETENESS_TARGET`, `ORG_UNIT_TARGET`, `EVENT`, `ENROLLMENT`, `VALIDATION_RESULT` |
| `skipResourceTables` | boolean | `false`   | Skip generation of resource tables |
| `skipPrograms` | array of string | `[]`    | Optional list of programs (IDs) that should be skipped |

Table: `CONTINUOUS_ANALYTICS_TABLE` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `lastYears` | int           | `0`     | Number of years back to include |
| `skipTableTypes` | array of enum | `[]`    | Skip generation of tables; Possible values: `DATA_VALUE`, `COMPLETENESS`, `COMPLETENESS_TARGET`, `ORG_UNIT_TARGET`, `EVENT`, `ENROLLMENT`, `VALIDATION_RESULT` |
| `fullUpdateHourOfDay` | int           | `0`     | Hour of day for full update of analytics tables (0-23) |

Table: `DATA_SYNC` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `pageSize` | int | `10000` | number of data values processed as a unit |

Table: `META_DATA_SYNC` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `trackerProgramPageSize` | int | `20` | number of tracked entities processed as a unit |
| `eventProgramPageSize` | int | `60` | number of events processed as a unit           |
| `dataValuesPageSize` | int | `10000` | number of data values processed as a unit  |

Table: `MONITORING` (Validation rule analysis) job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `relativeStart` | int | `0` | A number related to date of execution which resembles the start of the period to monitor |
| `relativeEnd` | int | `0` | A number related to date of execution which resembles the end of the period to monitor |
| `validationRuleGroups` | array of string | `[]` | Validation rule groups (UIDs) to include in job |
| `sendNotification` | boolean | `false` | Set `true` if job should send notifications based on validation rule groups |
| `persistsResults` | boolean | `false` | Set `true` if job should persist validation results |

Table: `PUSH_ANALYSIS` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `pushAnalysis` | array of string | `[]` |  The UIDs of the push analysis you want to run |

Table: `PREDICTOR` job parameters

| Nome          | Modelo          | Padrão | Descrição                                      |
|---------------|---------------|---------|--------------------------------------------------|
| `relativeStart` | int | `0` | A number related to date of execution which resembles the start of the period to monitor |
| `relativeEnd` | int | `0` | A number related to date of execution which resembles the start of the period to monitor |
| `predictors` | array of string | `[]` | Predictors (UIDs) to include in job                                                      |
| `predictorGroups` | array of string | `[]` | Predictor groups (UIDs) to include in job                                                |


### Obtenha os tipos de trabalho disponíveis { #get-available-job-types } 

Para obter uma lista de todos os tipos de trabalho disponíveis, você pode usar o seguinte endpoint:

    GET /api/jobConfigurations/jobTypes

A resposta contém informações sobre cada tipo de trabalho, incluindo nome, tipo de trabalho, chave, tipo de agendamento e parâmetros disponíveis. O tipo de agendamento pode ser `CRON`, o que significa que as tarefas podem ser agendadas usando uma expressão cron com o campo` cronExpression`, ou `FIXED_DELAY`, o que significa que as tarefas podem ser agendadas para serem executadas com um atraso fixo entre o campo` delay` . O atraso do campo é dado em segundos.

Uma resposta será semelhante a esta:

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

### Create a Job Configuration { #create-a-job-configuration } 

Para configurar trabalhos, você pode fazer uma solicitação POST para o seguinte recurso:

    / api / jobConfigurations

Um trabalho sem parâmetros no formato JSON se parece com isto:

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

Um exemplo de trabalho de tabela analítica com parâmetros no formato JSON:

`` `json
{
  "name": "Tabelas analíticas nos últimos dois anos",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * *? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
`` `

Como exemplo de um trabalho de análise push com parâmetros no formato JSON:

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

Um exemplo de trabalho com tipo de programação `FIXED_DELAY` e 120 segundos de atraso:

`` `json
{
  "nome": "Tabela de análise contínua",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "atraso": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
`` `

### Get Job Configurations { #get-job-configurations } 

Liste todas as configurações de trabalho:

    GET /api/jobConfigurations

Recupere um trabalho:

    GET /api/jobConfigurations/{id}

A carga útil da resposta é semelhante a esta:

`` `json
{
  "lastUpdated": "2018-02-22T15: 15: 34.067",
  "id": "KBcP6Qw37gT",
  "href": "http: // localhost: 8080 / api / jobConfigurations / KBcP6Qw37gT",
  "criado": "22-02-2018T15: 15: 34.067",
  "nome": "análise dos últimos dois anos",
  "jobStatus": "SCHEDULED",
  "displayName": "análises nos últimos dois anos",
  "ativado": verdadeiro,
  "externalAccess": falso,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "26/02/2018T03: 00: 00.000",
  "cronExpression": "0 0 3? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorito": falso,
  "configurável": verdadeiro,
  "Acesso": {
    "ler": verdadeiro,
    "update": verdadeiro,
    "externalizar": verdadeiro,
    "delete": verdadeiro,
    "verdade Branca,
    "gerenciar": verdadeiro
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favoritos": [],
  "traduções": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
`` `

### Update a Job Configuration { #update-a-job-configuration } 

Atualizar um trabalho com parâmetros usando o seguinte endpoint e formato de carga útil JSON:

    PUT /api/jobConfiguration/{id}

`` `json
{
  "nome": "análise dos últimos dois anos",
  "ativado": verdadeiro,
  "cronExpression": "0 0 3? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
`` `

### Delete a Job Configuration { #delete-a-job-configuration } 

Exclua um trabalho usando:

    DELETE / api / jobConfiguration / {id}

Note that some jobs with custom configuration parameters may not be added if the
required system settings are not configured. An example of this is data
synchronization, which requires remote server configuration.

### Run Jobs Manually { #run-jobs-manually } 

Jobs can be run manually using:

    POST /api/jobConfiguration/{id}/execute


### Observe Running Jobs { #observe-running-jobs } 
The execution steps and state can be observed while the job is running.
A list of all types of jobs that are currently running is provided by:

    GET /api/scheduling/running/types

To get an overview of all running jobs by job type use:

    GET /api/scheduling/running

As there only can be one job running for each type at a time the status of a
running job can be viewed in details using:

    GET /api/scheduling/running/{type}

For example, to see status of a running `ANALYTICS_TABLE` job use

    GET /api/scheduling/running/ANALYTICS_TABLE

A job is a sequence of processes. Each process has a sequence of `stages`.
Within each stage there might be zero, one or many `items`. Items could be
processed strictly sequential or parallel, n items at a time. Often the
number of `totalItems` is known up-front.

In general the stages in a process and the items in a stage are "discovered"
as a "side effect" of processing the data. While most processes have a fixed
sequence of stages some processed might have varying stages depending on the
data processed. Items are usually data dependent. Most jobs just include a
single process.

Each of the nodes in the process-stage-item tree has a status that is either
* `RUNNING`: is currently processed (not yet finished)
* `SUCCESS`: when completed successful
* `ERROR`: when completed with errors or when an exception has occurred
* `CANCELLED`: when cancellation was requested and the item will not complete

### See Completed Job Runs { #see-completed-job-runs } 
Once a job has completed successful or with a failure as a consequence of an
exception or cancellation the status moves from the set of running states to
the completed job states. This set keeps only the most recent execution
state for each job type. The overview is available at:

    GET /api/scheduling/completed

Details on a particular job type are accordingly provided at:

    GET /api/scheduling/completed/{type}

In case of the `ANALYTICS_TABLE` job this would be:

    GET /api/scheduling/completed/ANALYTICS_TABLE

### Request Cancelling a Running Jobs { #request-cancelling-a-running-jobs } 
Once a job is started it works through a sequence of steps. Each step might
in turn have collections of items that are processed. While jobs usually
cannot be stopped at any point in time we can request cancellation and the
process gives up cooperatively once it has completed an item or step and
recognises that a cancellation was requested. This means jobs do not stop
immediately and leave at an unknown point right in the middle of some
processing. Instead, they give up when there is an opportunity to skip to
the end. This still means that the overall process is unfinished and is not
rolled back. It might just have done a number of steps and skipped others at
the end.

To cancel a running job use:

    POST /api/scheduling/cancel/{type}

For example, to cancel the `ANALYTICS_TABLE` job run:

    POST /api/scheduling/cancel/ANALYTICS_TABLE

Depending on the current step and item performed this can take from
milliseconds to minutes before the cancellation becomes effective.
However, the status of the overall process will be shown as `CANCELLED`
immediately when check using

    GET /api/scheduling/running/ANALYTICS_TABLE

Only jobs that have been split into processes, stages and items can be
cancelled effectively. Not all jobs have been split yet. These will run till
completion even if cancellation has been requested.

