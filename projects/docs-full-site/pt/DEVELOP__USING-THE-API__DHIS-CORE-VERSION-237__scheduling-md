---
edit_url: "https://github.com/dhis2/dhis2-docs/blob/2.37/src/developer/web-api/scheduling.md"
revision_date: '2021-10-26'
tags:
- DHIS core version 2.37
- Desenvolver
---

# Agendamento { #webapi_scheduling } 

O DHIS2 permite o agendamento de trabalhos de vários tipos. Cada tipo de trabalho possui propriedades diferentes para configuração, oferecendo um controle mais preciso sobre como os trabalhos são executados. Além disso, você pode configurar o mesmo trabalho para ser executado com configurações diferentes e em intervalos diferentes, se necessário.



Table: Main properties

| Property | Descrição | Modelo |
|---|---|---|
| nome | Name of the job. | Corda |
| cronExpression | The cron expression which defines the interval for when the job should run. | String (Cron expression) |
| jobType | The job type represent which task is run. In the next table, you can get an overview of existing job types. Each job type can have a specific set of parameters for job configuration. | String (Enum) |
| jobParameters | Job parameters, if applicable for job type. | (See list of job types) |
| enabled | A job can be added to the system without it being scheduled by setting `enabled` to false in the JSON payload. Use this if you want to temporarily stop scheduling for a job, or if a job configuration is not complete yet. | Boolean |



Table: Available job types

| Job type | Parameters | Param(Type:Default) |
|---|---|---|
| DATA_INTEGRITY | NONE ||
| ANALYTICS_TABLE | * lastYears: Number of years back to include<br> * skipTableTypes: Skip generation of tables<br>Possible values: DATA_VALUE, COMPLETENESS, COMPLETENESS_TARGET, ORG_UNIT_TARGET, EVENT, ENROLLMENT, VALIDATION_RESULT<br> * skipResourceTables: Skip generation of resource tables | * lastYears (int:0)<br> * skipTableTypes (Array of String (Enum):None )<br> * skipResourceTables (Boolean) |
| CONTINUOUS_ANALYTICS_TABLE | * fullUpdateHourOfDay: Hour of day for full update of analytics tables (0-23)<br> * lastYears: Number of years back to include<br> * skipTableTypes: Skip generation of tables<br>Possible values: DATA_VALUE, COMPLETENESS, COMPLETENESS_TARGET, ORG_UNIT_TARGET, EVENT, ENROLLMENT, VALIDATION_RESULT<br> * skipResourceTables: Skip generation of resource tables | * lastYears (int:0)<br> * skipTableTypes (Array of String (Enum):None )<br> * skipResourceTables (Boolean) |
| DATA_SYNC | NONE ||
| META_DATA_SYNC | NONE ||
| SEND_SCHEDULED_MESSAGE | NONE ||
| PROGRAM_NOTIFICATIONS | NONE ||
| MONITORING (Validation rule analysis) | * relativeStart: A number related to date of execution which resembles the start of the period to monitor<br> * relativeEnd: A number related to date of execution which resembles the end of the period to monitor<br> * validationRuleGroups: Validation rule groups(UIDs) to include in job<br> * sendNotification: Set "true" if job should send notifications based on validation rule groups<br> * persistsResults: Set "true" if job should persist validation results | * relativeStart (int:0)<br> * relativeEnd (int:0)<br> * validationRuleGroups (Array of String (UIDs):None )<br> * sendNotification (Boolean:false)<br> * persistsResults (Boolean:false) |
| PUSH_ANALYSIS | * pushAnalysis: The uid of the push analysis you want to run | * pushAnalysis (String:None) |
| PREDICTOR | * relativeStart: A number related to date of execution which resembles the start of the period to monitor<br> * relativeEnd: A number related to date of execution which resembles the start of the period to monitor<br> * predictors: Predictors(UIDs) to include in job | * relativeStart (int:0)<br> * relativeEnd (int:0)<br> * predictors (Array of String (UIDs):None ) |

### Obtenha os tipos de trabalho disponíveis { #get-available-job-types } 

Para obter uma lista de todos os tipos de trabalho disponíveis, você pode usar o seguinte endpoint:

    GET /api/jobConfigurations/jobTypes

A resposta contém informações sobre cada tipo de trabalho, incluindo nome, tipo de trabalho, chave, tipo de agendamento e parâmetros disponíveis. O tipo de agendamento pode ser `CRON`, o que significa que as tarefas podem ser agendadas usando uma expressão cron com o campo` cronExpression`, ou `FIXED_DELAY`, o que significa que as tarefas podem ser agendadas para serem executadas com um atraso fixo entre o campo` delay` . O atraso do campo é dado em segundos.

Uma resposta será semelhante a esta:

```json
{
  "jobTypes": [
    {
      "name": "Data integrity",
      "jobType": "DATA_INTEGRITY",
      "key": "dataIntegrityJob",
      "schedulingType": "CRON"
    }, {
      "name": "Resource table",
      "jobType": "RESOURCE_TABLE",
      "key": "resourceTableJob",
      "schedulingType": "CRON"
    }, {
      "name": "Continuous analytics table",
      "jobType": "CONTINUOUS_ANALYTICS_TABLE",
      "key": "continuousAnalyticsTableJob",
      "schedulingType": "FIXED_DELAY"
    }
  ]
}
```

### Criar trabalho { #create-job } 

Para configurar trabalhos, você pode fazer uma solicitação POST para o seguinte recurso:

    / api / jobConfigurations

Um trabalho sem parâmetros no formato JSON se parece com isto:

```json
{
  "name": "",
  "jobType": "JOBTYPE",
  "cronExpression": "0 * * ? * *",
}
```

Um exemplo de trabalho de tabela analítica com parâmetros no formato JSON:

`` `json
{
  "name": "Tabelas analíticas nos últimos dois anos",
  "jobType": "ANALYTICS_TABLE",
  "cronExpression": "0 * *? * *",
  "jobParameters": {
    "lastYears": "2",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
`` `

Como exemplo de um trabalho de análise push com parâmetros no formato JSON:

```json
{
   "name": "Push anlysis charts",
   "jobType": "PUSH_ANALYSIS",
   "cronExpression": "0 * * ? * *",
   "jobParameters": {
     "pushAnalysis": [
       "jtcMAKhWwnc"
     ]
    }
 }
```

Um exemplo de trabalho com tipo de programação `FIXED_DELAY` e 120 segundos de atraso:

`` `json
{
  "nome": "Tabela de análise contínua",
  "jobType": "CONTINUOUS_ANALYTICS_TABLE",
  "atraso": "120",
  "jobParameters": {
    "fullUpdateHourOfDay": 4
  }
}
`` `

### Arranja empregos { #get-jobs } 

Liste todas as configurações de trabalho:

    GET /api/jobConfigurations

Recupere um trabalho:

    GET /api/jobConfigurations/{id}

A carga útil da resposta é semelhante a esta:

`` `json
{
  "lastUpdated": "2018-02-22T15: 15: 34.067",
  "id": "KBcP6Qw37gT",
  "href": "http: // localhost: 8080 / api / jobConfigurations / KBcP6Qw37gT",
  "criado": "22-02-2018T15: 15: 34.067",
  "nome": "análise dos últimos dois anos",
  "jobStatus": "SCHEDULED",
  "displayName": "análises nos últimos dois anos",
  "ativado": verdadeiro,
  "externalAccess": falso,
  "jobType": "ANALYTICS_TABLE",
  "nextExecutionTime": "26/02/2018T03: 00: 00.000",
  "cronExpression": "0 0 3? * MON",
  "jobParameters": {
    "lastYears": 2,
    "skipTableTypes": [],
    "skipResourceTables": false
  },
  "favorito": falso,
  "configurável": verdadeiro,
  "Acesso": {
    "ler": verdadeiro,
    "update": verdadeiro,
    "externalizar": verdadeiro,
    "delete": verdadeiro,
    "verdade Branca,
    "gerenciar": verdadeiro
  },
  "lastUpdatedBy": {
    "id": "GOLswS44mh8"
  },
  "favoritos": [],
  "traduções": [],
  "userGroupAccesses": [],
  "attributeValues": [],
  "userAccesses": []
}
`` `

### Trabalho de atualização { #update-job } 

Atualizar um trabalho com parâmetros usando o seguinte endpoint e formato de carga útil JSON:

    PUT /api/jobConfiguration/{id}

`` `json
{
  "nome": "análise dos últimos dois anos",
  "ativado": verdadeiro,
  "cronExpression": "0 0 3? * MON",
  "jobType": "ANALYTICS_TABLE",
  "jobParameters": {
    "lastYears": "3",
    "skipTableTypes": [],
    "skipResourceTables": false
  }
}
`` `

### Excluir trabalho { #delete-job } 

Exclua um trabalho usando:

    DELETE / api / jobConfiguration / {id}

Note that some jobs with custom configuration parameters may not be added if the
required system settings are not configured. An example of this is data
synchronization, which requires remote server configuration.

## Sincronização { #webapi_synchronization } 

Esta seção cobre pull e push de dados e metadados.

### Push de valor de dados { #webapi_sync_data_push } 

To initiate a data value push to a remote server one must first configure the
URL and credentials for the relevant server from System settings >
Synchronization, then make a POST request to the following resource:

    / api / 33 / synchronization / dataPush

### Metadata pull { #webapi_sync_metadata_pull } 

To initiate a metadata pull from a remote JSON document you can make a
POST request with a *url* as request payload to the following resource:

    / api / 33 / synchronization / metadataPull

### Verificação de disponibilidade { #webapi_sync_availability_check } 

To check the availability of the remote data server and verify user
credentials you can make a GET request to the following resource:

    / api / 33 / sincronização / disponibilidade

